{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b6006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 14:22:21,803 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\n",
      "2023-07-07 14:22:26,601 - \u001b[1;32mINFO\u001b[1;0m - Loaded 677694 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\n",
      "2023-07-07 14:22:27,300 - \u001b[1;32mINFO\u001b[1;0m - Found 578718 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\n",
      "2023-07-07 14:22:27,342 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 578718/578718 [01:18<00:00, 7362.77it/s]\n",
      "2023-07-07 14:23:45,969 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 578718/578718 [00:01<00:00, 336590.39it/s]\n",
      "2023-07-07 14:23:49,424 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-07-07 14:23:49,424 - \u001b[1;32mINFO\u001b[1;0m - First fact: A BENIGN CALCIFICATION IN LUNG OR RIB, OR VESSEL, EITHER ON END OR CROSSING in the right lower lung\n",
      "2023-07-07 14:23:49,424 - \u001b[1;32mINFO\u001b[1;0m - Last fact: right\n",
      "2023-07-07 14:23:49,677 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 20000\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 1. bibasilar atelectases greater on the left side\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 2223. Dobbhoff tube coiled within the body of the stomach\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 4445. very little of previous multi focal pulmonary abnormality\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 6667. no relevant change in the distribution of the pre-existing parenchymal opacities\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 8889. lower lobes are largely obscured\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 11111. heterogeneous peribronchial opacification in the lower lungs\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 13333. subacute appearance\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 15555. slight increase of interstitial lung markings\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 17777. mildly abnormal left lower lobe\n",
      "2023-07-07 14:23:49,678 - \u001b[1;32mINFO\u001b[1;0m - 20000. moderate central pulmonary vascular congestion\n",
      "2023-07-07 14:23:50,177 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230707_142350.jsonl\n",
      "2023-07-07 14:23:50,177 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230707_142350.jsonl\n",
      "2023-07-07 14:23:50,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-07 14:23:51,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-07-07 14:23:51,159 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-07-07 14:23:51,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-07-07 14:23:51,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-07-07 14:23:53,260 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-07 14:24:05,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-07-07 14:24:17,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #140\n",
      "2023-07-07 14:24:30,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #160\n",
      "2023-07-07 14:24:42,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #180\n",
      "2023-07-07 14:24:54,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #200\n",
      "2023-07-07 14:24:58,085 - \u001b[1;33mWARNING\u001b[1;0m - Request 156 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d05418da2471363e1a3b614d6590f7bd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:25:07,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #219\n",
      "2023-07-07 14:25:19,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #239\n",
      "2023-07-07 14:25:31,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #259\n",
      "2023-07-07 14:25:44,285 - \u001b[1;32mINFO\u001b[1;0m - Starting request #279\n",
      "2023-07-07 14:25:56,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #299\n",
      "2023-07-07 14:26:08,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #319\n",
      "2023-07-07 14:26:21,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #339\n",
      "2023-07-07 14:26:33,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #359\n",
      "2023-07-07 14:26:45,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #379\n",
      "2023-07-07 14:26:58,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #399\n",
      "2023-07-07 14:27:10,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #419\n",
      "2023-07-07 14:27:22,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #439\n",
      "2023-07-07 14:27:35,283 - \u001b[1;32mINFO\u001b[1;0m - Starting request #459\n",
      "2023-07-07 14:27:47,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #479\n",
      "2023-07-07 14:27:59,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #499\n",
      "2023-07-07 14:28:12,285 - \u001b[1;32mINFO\u001b[1;0m - Starting request #519\n",
      "2023-07-07 14:28:24,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #539\n",
      "2023-07-07 14:28:36,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #559\n",
      "2023-07-07 14:28:49,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #579\n",
      "2023-07-07 14:28:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10 failed with Exception \n",
      "2023-07-07 14:29:01,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #598\n",
      "2023-07-07 14:29:13,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #618\n",
      "2023-07-07 14:29:23,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 149 failed with Exception \n",
      "2023-07-07 14:29:26,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #637\n",
      "2023-07-07 14:29:38,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #657\n",
      "2023-07-07 14:29:50,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #677\n",
      "2023-07-07 14:30:03,277 - \u001b[1;32mINFO\u001b[1;0m - Starting request #697\n",
      "2023-07-07 14:30:15,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #717\n",
      "2023-07-07 14:30:27,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #737\n",
      "2023-07-07 14:30:40,282 - \u001b[1;32mINFO\u001b[1;0m - Starting request #757\n",
      "2023-07-07 14:30:52,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #777\n",
      "2023-07-07 14:31:04,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #797\n",
      "2023-07-07 14:31:17,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #817\n",
      "2023-07-07 14:31:29,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #837\n",
      "2023-07-07 14:31:41,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #857\n",
      "2023-07-07 14:31:46,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 379 failed with Exception \n",
      "2023-07-07 14:31:54,266 - \u001b[1;32mINFO\u001b[1;0m - Starting request #876\n",
      "2023-07-07 14:32:03,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 843 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 33a483a8b78aef4bf5c74e73baf0a772 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:32:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 411 failed with Exception \n",
      "2023-07-07 14:32:06,586 - \u001b[1;32mINFO\u001b[1;0m - Starting request #895\n",
      "2023-07-07 14:32:18,910 - \u001b[1;32mINFO\u001b[1;0m - Starting request #914\n",
      "2023-07-07 14:32:28,855 - \u001b[1;33mWARNING\u001b[1;0m - Request 883 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d64403135c6b7db07de5707fa84a635a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:32:31,232 - \u001b[1;32mINFO\u001b[1;0m - Starting request #933\n",
      "2023-07-07 14:32:43,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #953\n",
      "2023-07-07 14:32:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 485 failed with Exception \n",
      "2023-07-07 14:32:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 489 failed with Exception \n",
      "2023-07-07 14:32:55,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #971\n",
      "2023-07-07 14:33:08,230 - \u001b[1;32mINFO\u001b[1;0m - Starting request #991\n",
      "2023-07-07 14:33:20,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1011\n",
      "2023-07-07 14:33:32,888 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1031\n",
      "2023-07-07 14:33:45,234 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1051\n",
      "2023-07-07 14:33:57,587 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1071\n",
      "2023-07-07 14:34:09,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1091\n",
      "2023-07-07 14:34:22,262 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1111\n",
      "2023-07-07 14:34:34,600 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 14:34:46,930 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1151\n",
      "2023-07-07 14:34:59,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1171\n",
      "2023-07-07 14:35:11,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1191\n",
      "2023-07-07 14:35:23,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1211\n",
      "2023-07-07 14:35:36,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1231\n",
      "2023-07-07 14:35:48,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1251\n",
      "2023-07-07 14:36:00,930 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1271\n",
      "2023-07-07 14:36:13,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1291\n",
      "2023-07-07 14:36:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 822 failed with Exception \n",
      "2023-07-07 14:36:25,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1310\n",
      "2023-07-07 14:36:37,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1330\n",
      "2023-07-07 14:36:38,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 851 failed with Exception \n",
      "2023-07-07 14:36:50,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1349\n",
      "2023-07-07 14:37:02,631 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1369\n",
      "2023-07-07 14:37:14,948 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1389\n",
      "2023-07-07 14:37:16,811 - \u001b[1;33mWARNING\u001b[1;0m - Request 1343 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b9c04b572b3412ab3d2ada422c81a6b5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:37:27,291 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1408\n",
      "2023-07-07 14:37:39,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1428\n",
      "2023-07-07 14:37:42,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 950 failed with Exception \n",
      "2023-07-07 14:37:51,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1447\n",
      "2023-07-07 14:38:04,284 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1467\n",
      "2023-07-07 14:38:16,621 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1487\n",
      "2023-07-07 14:38:28,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1507\n",
      "2023-07-07 14:38:33,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 1465 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f8805029cdb3d112b0968dc5396e598 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:38:41,307 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1526\n",
      "2023-07-07 14:38:53,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1546\n",
      "2023-07-07 14:39:05,968 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1566\n",
      "2023-07-07 14:39:18,288 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1586\n",
      "2023-07-07 14:39:30,610 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1606\n",
      "2023-07-07 14:39:42,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1626\n",
      "2023-07-07 14:39:55,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1646\n",
      "2023-07-07 14:40:07,550 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1666\n",
      "2023-07-07 14:40:19,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1686\n",
      "2023-07-07 14:40:32,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1706\n",
      "2023-07-07 14:40:44,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1726\n",
      "2023-07-07 14:40:56,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1746\n",
      "2023-07-07 14:41:09,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1766\n",
      "2023-07-07 14:41:21,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1786\n",
      "2023-07-07 14:41:33,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1806\n",
      "2023-07-07 14:41:46,171 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1826\n",
      "2023-07-07 14:41:58,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1846\n",
      "2023-07-07 14:42:10,841 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1866\n",
      "2023-07-07 14:42:18,953 - \u001b[1;33mWARNING\u001b[1;0m - Request 1830 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d8c0aec3116883ab4049f63f81745705 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:42:23,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1885\n",
      "2023-07-07 14:42:26,256 - \u001b[1;33mWARNING\u001b[1;0m - Request 1842 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5fc616aa1b8e599687d164c0e9e8db06 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:42:35,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1904\n",
      "2023-07-07 14:42:47,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1924\n",
      "2023-07-07 14:43:00,187 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1944\n",
      "2023-07-07 14:43:12,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1964\n",
      "2023-07-07 14:43:16,243 - \u001b[1;33mWARNING\u001b[1;0m - Request 1921 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dc2b9e22f5f83dee9b06db7ca2465f1e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:43:24,873 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1983\n",
      "2023-07-07 14:43:29,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1507 failed with Exception \n",
      "2023-07-07 14:43:29,862 - \u001b[1;33mWARNING\u001b[1;0m - Request 1943 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 737f455a64b4b03e6fb0c63a104254bf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:43:30,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 1944 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d19f133c3047665c5affbeb6f2b5c4f9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:43:37,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2000\n",
      "2023-07-07 14:43:49,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2020\n",
      "2023-07-07 14:44:01,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2040\n",
      "2023-07-07 14:44:14,195 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2060\n",
      "2023-07-07 14:44:26,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2080\n",
      "2023-07-07 14:44:38,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2100\n",
      "2023-07-07 14:44:51,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2120\n",
      "2023-07-07 14:45:03,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2140\n",
      "2023-07-07 14:45:15,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2160\n",
      "2023-07-07 14:45:28,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2180\n",
      "2023-07-07 14:45:40,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2200\n",
      "2023-07-07 14:45:52,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2220\n",
      "2023-07-07 14:46:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1757 failed with Exception \n",
      "2023-07-07 14:46:05,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1757\n",
      "2023-07-07 14:46:17,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2259\n",
      "2023-07-07 14:46:29,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2279\n",
      "2023-07-07 14:46:42,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2299\n",
      "2023-07-07 14:46:54,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2319\n",
      "2023-07-07 14:46:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1847 failed with Exception \n",
      "2023-07-07 14:47:06,748 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2338\n",
      "2023-07-07 14:47:19,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2358\n",
      "2023-07-07 14:47:31,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2378\n",
      "2023-07-07 14:47:43,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2398\n",
      "2023-07-07 14:47:56,061 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2418\n",
      "2023-07-07 14:48:08,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2438\n",
      "2023-07-07 14:48:20,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2458\n",
      "2023-07-07 14:48:33,020 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2478\n",
      "2023-07-07 14:48:45,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2498\n",
      "2023-07-07 14:48:57,689 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2518\n",
      "2023-07-07 14:49:10,013 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2538\n",
      "2023-07-07 14:49:22,352 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 14:49:33,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2090 failed with Exception \n",
      "2023-07-07 14:49:34,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2090\n",
      "2023-07-07 14:49:47,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2597\n",
      "2023-07-07 14:49:59,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2617\n",
      "2023-07-07 14:50:11,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2637\n",
      "2023-07-07 14:50:24,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2657\n",
      "2023-07-07 14:50:36,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2677\n",
      "2023-07-07 14:50:48,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2697\n",
      "2023-07-07 14:50:53,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2221 failed with Exception \n",
      "2023-07-07 14:50:55,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2224 failed with Exception \n",
      "2023-07-07 14:51:01,060 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2715\n",
      "2023-07-07 14:51:13,406 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2735\n",
      "2023-07-07 14:51:25,741 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2755\n",
      "2023-07-07 14:51:38,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2775\n",
      "2023-07-07 14:51:50,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2795\n",
      "2023-07-07 14:52:02,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2815\n",
      "2023-07-07 14:52:15,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2835\n",
      "2023-07-07 14:52:27,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2855\n",
      "2023-07-07 14:52:39,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2875\n",
      "2023-07-07 14:52:52,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2895\n",
      "2023-07-07 14:53:04,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2915\n",
      "2023-07-07 14:53:16,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2935\n",
      "2023-07-07 14:53:29,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2955\n",
      "2023-07-07 14:53:41,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2975\n",
      "2023-07-07 14:53:53,163 - \u001b[1;33mWARNING\u001b[1;0m - Request 2945 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e5c46c3873aca5bd968a8656fd5fc703 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:53:53,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2995\n",
      "2023-07-07 14:54:06,072 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3014\n",
      "2023-07-07 14:54:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2542 failed with Exception \n",
      "2023-07-07 14:54:18,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3033\n",
      "2023-07-07 14:54:30,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3053\n",
      "2023-07-07 14:54:35,072 - \u001b[1;33mWARNING\u001b[1;0m - Request 3012 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a34f7cc665b837fc6d830c1ec7cbfac9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 14:54:43,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3072\n",
      "2023-07-07 14:54:55,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3092\n",
      "2023-07-07 14:55:07,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3112\n",
      "2023-07-07 14:55:20,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3132\n",
      "2023-07-07 14:55:32,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3152\n",
      "2023-07-07 14:55:44,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3172\n",
      "2023-07-07 14:55:57,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3192\n",
      "2023-07-07 14:56:09,448 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3212\n",
      "2023-07-07 14:56:21,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3232\n",
      "2023-07-07 14:56:34,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3252\n",
      "2023-07-07 14:56:46,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3272\n",
      "2023-07-07 14:56:58,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3292\n",
      "2023-07-07 14:57:11,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3312\n",
      "2023-07-07 14:57:23,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3332\n",
      "2023-07-07 14:57:35,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3352\n",
      "2023-07-07 14:57:48,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3372\n",
      "2023-07-07 14:58:00,444 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3392\n",
      "2023-07-07 14:58:12,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3412\n",
      "2023-07-07 14:58:25,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3432\n",
      "2023-07-07 14:58:37,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3452\n",
      "2023-07-07 14:58:49,794 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3472\n",
      "2023-07-07 14:59:02,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3492\n",
      "2023-07-07 14:59:14,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3512\n",
      "2023-07-07 14:59:26,797 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3532\n",
      "2023-07-07 14:59:39,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3552\n",
      "2023-07-07 14:59:51,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3572\n",
      "2023-07-07 15:00:03,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3592\n",
      "2023-07-07 15:00:16,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3612\n",
      "2023-07-07 15:00:28,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3632\n",
      "2023-07-07 15:00:40,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3652\n",
      "2023-07-07 15:00:41,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3166 failed with Exception \n",
      "2023-07-07 15:00:53,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3671\n",
      "2023-07-07 15:01:05,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3691\n",
      "2023-07-07 15:01:17,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3711\n",
      "2023-07-07 15:01:30,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3731\n",
      "2023-07-07 15:01:42,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3751\n",
      "2023-07-07 15:01:54,772 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3771\n",
      "2023-07-07 15:02:07,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3791\n",
      "2023-07-07 15:02:19,439 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3811\n",
      "2023-07-07 15:02:31,760 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3831\n",
      "2023-07-07 15:02:44,087 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3851\n",
      "2023-07-07 15:02:45,336 - \u001b[1;33mWARNING\u001b[1;0m - Request 3804 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 300be356da827c654aa95ace7e1dfd7c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:02:56,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3870\n",
      "2023-07-07 15:03:04,977 - \u001b[1;33mWARNING\u001b[1;0m - Request 3834 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3638504a316a29324fe9eea05a7d8649 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:03:08,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3889\n",
      "2023-07-07 15:03:21,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3909\n",
      "2023-07-07 15:03:33,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3929\n",
      "2023-07-07 15:03:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3461 failed with Exception \n",
      "2023-07-07 15:03:45,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3948\n",
      "2023-07-07 15:03:58,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3968\n",
      "2023-07-07 15:04:10,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3988\n",
      "2023-07-07 15:04:22,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4008\n",
      "2023-07-07 15:04:35,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4028\n",
      "2023-07-07 15:04:45,583 - \u001b[1;33mWARNING\u001b[1;0m - Request 3996 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75f0af83c78436254910703d90738704 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:04:47,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4047\n",
      "2023-07-07 15:04:59,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4067\n",
      "2023-07-07 15:05:12,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4087\n",
      "2023-07-07 15:05:24,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4107\n",
      "2023-07-07 15:05:36,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4127\n",
      "2023-07-07 15:05:49,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4147\n",
      "2023-07-07 15:06:01,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4167\n",
      "2023-07-07 15:06:13,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4187\n",
      "2023-07-07 15:06:26,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:06:38,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4227\n",
      "2023-07-07 15:06:50,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4247\n",
      "2023-07-07 15:06:53,169 - \u001b[1;33mWARNING\u001b[1;0m - Request 4202 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6afd3152218eaf2f0e41dd49030e395 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:07:03,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4266\n",
      "2023-07-07 15:07:15,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4286\n",
      "2023-07-07 15:07:15,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3803 failed with Exception \n",
      "2023-07-07 15:07:27,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4305\n",
      "2023-07-07 15:07:40,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4325\n",
      "2023-07-07 15:07:52,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4345\n",
      "2023-07-07 15:08:00,406 - \u001b[1;33mWARNING\u001b[1;0m - Request 4309 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f7b6efc24ef2336fab12c49983160251 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:08:04,715 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4364\n",
      "2023-07-07 15:08:17,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4384\n",
      "2023-07-07 15:08:29,383 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4404\n",
      "2023-07-07 15:08:41,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4424\n",
      "2023-07-07 15:08:54,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4444\n",
      "2023-07-07 15:09:06,365 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4464\n",
      "2023-07-07 15:09:18,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4484\n",
      "2023-07-07 15:09:23,106 - \u001b[1;33mWARNING\u001b[1;0m - Request 4442 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d5b2ca41305ab0759f4dd74c4e9fd697 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:09:28,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4016 failed with Exception \n",
      "2023-07-07 15:09:31,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4502\n",
      "2023-07-07 15:09:43,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4522\n",
      "2023-07-07 15:09:51,031 - \u001b[1;33mWARNING\u001b[1;0m - Request 4487 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7139b4e1202ac6e8d43222e3bc10e7e5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:09:55,677 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4541\n",
      "2023-07-07 15:10:08,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4561\n",
      "2023-07-07 15:10:20,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4581\n",
      "2023-07-07 15:10:32,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4601\n",
      "2023-07-07 15:10:45,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4621\n",
      "2023-07-07 15:10:57,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4641\n",
      "2023-07-07 15:11:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4175 failed with Exception \n",
      "2023-07-07 15:11:09,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4660\n",
      "2023-07-07 15:11:22,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4680\n",
      "2023-07-07 15:11:34,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4700\n",
      "2023-07-07 15:11:46,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4720\n",
      "2023-07-07 15:11:58,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4740\n",
      "2023-07-07 15:12:11,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4760\n",
      "2023-07-07 15:12:23,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4780\n",
      "2023-07-07 15:12:35,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4800\n",
      "2023-07-07 15:12:48,317 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4820\n",
      "2023-07-07 15:13:00,638 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4840\n",
      "2023-07-07 15:13:12,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4860\n",
      "2023-07-07 15:13:25,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4880\n",
      "2023-07-07 15:13:37,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4900\n",
      "2023-07-07 15:13:49,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4920\n",
      "2023-07-07 15:14:02,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4940\n",
      "2023-07-07 15:14:09,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4469 failed with Exception \n",
      "2023-07-07 15:14:14,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4959\n",
      "2023-07-07 15:14:27,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4979\n",
      "2023-07-07 15:14:39,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4999\n",
      "2023-07-07 15:14:51,663 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5019\n",
      "2023-07-07 15:15:03,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4553 failed with Exception \n",
      "2023-07-07 15:15:03,995 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5039\n",
      "2023-07-07 15:15:16,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5058\n",
      "2023-07-07 15:15:16,422 - \u001b[1;33mWARNING\u001b[1;0m - Request 5010 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 29a7570e7a30974da86e6d09591d8cb6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:15:17,777 - \u001b[1;33mWARNING\u001b[1;0m - Request 5012 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 30a00ec67698d8855f74b26b8b050f16 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:15:28,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5076\n",
      "2023-07-07 15:15:37,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4608 failed with Exception \n",
      "2023-07-07 15:15:41,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5095\n",
      "2023-07-07 15:15:53,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5115\n",
      "2023-07-07 15:16:05,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5135\n",
      "2023-07-07 15:16:18,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5155\n",
      "2023-07-07 15:16:30,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5175\n",
      "2023-07-07 15:16:42,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5195\n",
      "2023-07-07 15:16:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4723 failed with Exception \n",
      "2023-07-07 15:16:55,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5214\n",
      "2023-07-07 15:17:07,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5234\n",
      "2023-07-07 15:17:19,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5254\n",
      "2023-07-07 15:17:32,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5274\n",
      "2023-07-07 15:17:44,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5294\n",
      "2023-07-07 15:17:56,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5314\n",
      "2023-07-07 15:18:09,083 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5334\n",
      "2023-07-07 15:18:21,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5354\n",
      "2023-07-07 15:18:33,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5374\n",
      "2023-07-07 15:18:46,091 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5394\n",
      "2023-07-07 15:18:58,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5414\n",
      "2023-07-07 15:19:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4942 failed with Exception \n",
      "2023-07-07 15:19:10,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5433\n",
      "2023-07-07 15:19:23,111 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5453\n",
      "2023-07-07 15:19:35,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5473\n",
      "2023-07-07 15:19:47,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5493\n",
      "2023-07-07 15:20:00,088 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5513\n",
      "2023-07-07 15:20:11,939 - \u001b[1;33mWARNING\u001b[1;0m - Request 5483 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a444f5959688b3e31f34d2183330b6a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:20:12,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5533\n",
      "2023-07-07 15:20:24,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5552\n",
      "2023-07-07 15:20:37,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:20:49,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5592\n",
      "2023-07-07 15:21:01,745 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5612\n",
      "2023-07-07 15:21:14,086 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5632\n",
      "2023-07-07 15:21:24,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5164 failed with Exception \n",
      "2023-07-07 15:21:26,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5651\n",
      "2023-07-07 15:21:38,755 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5671\n",
      "2023-07-07 15:21:43,148 - \u001b[1;33mWARNING\u001b[1;0m - Request 5630 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ba47e9ac4ff7cf9327a5d05fa173d624 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:21:51,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5690\n",
      "2023-07-07 15:22:03,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5710\n",
      "2023-07-07 15:22:15,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5730\n",
      "2023-07-07 15:22:20,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5255 failed with Exception \n",
      "2023-07-07 15:22:28,088 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5749\n",
      "2023-07-07 15:22:40,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5769\n",
      "2023-07-07 15:22:51,629 - \u001b[1;33mWARNING\u001b[1;0m - Request 5255 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fa82b5e03c768b203df06a2f31b1b74b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:22:52,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5255\n",
      "2023-07-07 15:23:05,068 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5808\n",
      "2023-07-07 15:23:17,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5828\n",
      "2023-07-07 15:23:24,269 - \u001b[1;33mWARNING\u001b[1;0m - Request 5790 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9cdb80270ca85020f42f4e9256a6f3f3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:23:29,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5847\n",
      "2023-07-07 15:23:42,066 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5867\n",
      "2023-07-07 15:23:54,415 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5887\n",
      "2023-07-07 15:24:06,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5907\n",
      "2023-07-07 15:24:19,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5927\n",
      "2023-07-07 15:24:31,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5947\n",
      "2023-07-07 15:24:43,776 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5967\n",
      "2023-07-07 15:24:55,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5505 failed with Exception \n",
      "2023-07-07 15:24:56,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5987\n",
      "2023-07-07 15:25:08,417 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6006\n",
      "2023-07-07 15:25:20,751 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6026\n",
      "2023-07-07 15:25:33,072 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6046\n",
      "2023-07-07 15:25:45,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6066\n",
      "2023-07-07 15:25:57,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6086\n",
      "2023-07-07 15:26:10,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6106\n",
      "2023-07-07 15:26:22,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6126\n",
      "2023-07-07 15:26:34,689 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6146\n",
      "2023-07-07 15:26:40,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 6107 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 284115266926d2be7a0ef02b39338f4e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:26:47,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6165\n",
      "2023-07-07 15:26:59,365 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6185\n",
      "2023-07-07 15:27:11,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6205\n",
      "2023-07-07 15:27:24,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6225\n",
      "2023-07-07 15:27:36,343 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6245\n",
      "2023-07-07 15:27:48,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6265\n",
      "2023-07-07 15:27:52,396 - \u001b[1;33mWARNING\u001b[1;0m - Request 6222 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fecda5c137c3cfdba79f1d57790b71f6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:28:01,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6284\n",
      "2023-07-07 15:28:13,339 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6304\n",
      "2023-07-07 15:28:14,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 6258 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd9960fcda7c3171beb150ea78d77b7f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:28:25,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6323\n",
      "2023-07-07 15:28:37,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 6294 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4cbd8ccac6f95ba6c5e3d60280963359 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:28:37,990 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6343\n",
      "2023-07-07 15:28:45,699 - \u001b[1;33mWARNING\u001b[1;0m - Request 6306 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c966a3f528037d568712ffcf07580f4a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:28:50,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6361\n",
      "2023-07-07 15:29:02,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6381\n",
      "2023-07-07 15:29:15,004 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6401\n",
      "2023-07-07 15:29:27,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6421\n",
      "2023-07-07 15:29:39,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6441\n",
      "2023-07-07 15:29:51,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6461\n",
      "2023-07-07 15:30:04,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6481\n",
      "2023-07-07 15:30:16,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6501\n",
      "2023-07-07 15:30:28,987 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6521\n",
      "2023-07-07 15:30:41,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6541\n",
      "2023-07-07 15:30:53,641 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6561\n",
      "2023-07-07 15:31:05,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6581\n",
      "2023-07-07 15:31:18,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6601\n",
      "2023-07-07 15:31:30,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6621\n",
      "2023-07-07 15:31:42,996 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6641\n",
      "2023-07-07 15:31:55,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6661\n",
      "2023-07-07 15:32:07,668 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6681\n",
      "2023-07-07 15:32:19,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6701\n",
      "2023-07-07 15:32:32,322 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6721\n",
      "2023-07-07 15:32:44,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6741\n",
      "2023-07-07 15:32:57,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6761\n",
      "2023-07-07 15:33:09,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6781\n",
      "2023-07-07 15:33:21,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6801\n",
      "2023-07-07 15:33:34,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6821\n",
      "2023-07-07 15:33:46,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6841\n",
      "2023-07-07 15:33:58,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6861\n",
      "2023-07-07 15:34:11,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6881\n",
      "2023-07-07 15:34:23,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6901\n",
      "2023-07-07 15:34:35,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6921\n",
      "2023-07-07 15:34:48,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6941\n",
      "2023-07-07 15:35:00,349 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:35:12,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6981\n",
      "2023-07-07 15:35:24,992 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7001\n",
      "2023-07-07 15:35:37,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7021\n",
      "2023-07-07 15:35:49,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7041\n",
      "2023-07-07 15:36:01,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7061\n",
      "2023-07-07 15:36:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6579 failed with Exception \n",
      "2023-07-07 15:36:14,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7080\n",
      "2023-07-07 15:36:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6603 failed with Exception \n",
      "2023-07-07 15:36:26,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7099\n",
      "2023-07-07 15:36:38,963 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7119\n",
      "2023-07-07 15:36:51,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7139\n",
      "2023-07-07 15:37:03,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7159\n",
      "2023-07-07 15:37:15,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7179\n",
      "2023-07-07 15:37:28,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7199\n",
      "2023-07-07 15:37:40,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7219\n",
      "2023-07-07 15:37:52,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7239\n",
      "2023-07-07 15:38:05,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7259\n",
      "2023-07-07 15:38:09,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6780 failed with Exception \n",
      "2023-07-07 15:38:17,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7278\n",
      "2023-07-07 15:38:29,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7298\n",
      "2023-07-07 15:38:39,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6829 failed with Exception \n",
      "2023-07-07 15:38:42,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7317\n",
      "2023-07-07 15:38:52,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6850 failed with Exception \n",
      "2023-07-07 15:38:54,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7336\n",
      "2023-07-07 15:39:06,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7356\n",
      "2023-07-07 15:39:19,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7376\n",
      "2023-07-07 15:39:31,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7396\n",
      "2023-07-07 15:39:43,940 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7416\n",
      "2023-07-07 15:39:56,289 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7436\n",
      "2023-07-07 15:40:08,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7456\n",
      "2023-07-07 15:40:20,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7476\n",
      "2023-07-07 15:40:33,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7496\n",
      "2023-07-07 15:40:45,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7516\n",
      "2023-07-07 15:40:57,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7536\n",
      "2023-07-07 15:40:59,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7056 failed with Exception \n",
      "2023-07-07 15:41:07,906 - \u001b[1;33mWARNING\u001b[1;0m - Request 7503 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 49905c71c4ffd7c1b2d4dfb619fbeae0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:41:10,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7554\n",
      "2023-07-07 15:41:22,647 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7574\n",
      "2023-07-07 15:41:34,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7594\n",
      "2023-07-07 15:41:47,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7614\n",
      "2023-07-07 15:41:59,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7634\n",
      "2023-07-07 15:42:11,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7654\n",
      "2023-07-07 15:42:24,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7674\n",
      "2023-07-07 15:42:36,622 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7694\n",
      "2023-07-07 15:42:48,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7714\n",
      "2023-07-07 15:43:01,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7734\n",
      "2023-07-07 15:43:01,310 - \u001b[1;33mWARNING\u001b[1;0m - Request 7685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 73c9653c56da4c49fb1eda6c5c4d099c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:43:07,447 - \u001b[1;33mWARNING\u001b[1;0m - Request 7695 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ce64e73ce71d7ce581cc307ddeab2ba1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:43:13,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7752\n",
      "2023-07-07 15:43:25,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7772\n",
      "2023-07-07 15:43:38,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7792\n",
      "2023-07-07 15:43:50,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7812\n",
      "2023-07-07 15:44:02,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7832\n",
      "2023-07-07 15:44:15,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7852\n",
      "2023-07-07 15:44:27,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7872\n",
      "2023-07-07 15:44:31,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7395 failed with Exception \n",
      "2023-07-07 15:44:39,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7891\n",
      "2023-07-07 15:44:52,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7911\n",
      "2023-07-07 15:45:04,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7931\n",
      "2023-07-07 15:45:15,780 - \u001b[1;33mWARNING\u001b[1;0m - Request 7897 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4d3f8c02e4133c644a3033ef3fca41c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:45:16,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7897\n",
      "2023-07-07 15:45:29,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7970\n",
      "2023-07-07 15:45:41,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7990\n",
      "2023-07-07 15:45:53,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8010\n",
      "2023-07-07 15:46:06,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8030\n",
      "2023-07-07 15:46:18,638 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8050\n",
      "2023-07-07 15:46:30,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8070\n",
      "2023-07-07 15:46:43,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8090\n",
      "2023-07-07 15:46:55,638 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8110\n",
      "2023-07-07 15:47:07,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8130\n",
      "2023-07-07 15:47:20,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8150\n",
      "2023-07-07 15:47:32,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8170\n",
      "2023-07-07 15:47:44,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8190\n",
      "2023-07-07 15:47:57,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8210\n",
      "2023-07-07 15:48:09,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8230\n",
      "2023-07-07 15:48:21,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8250\n",
      "2023-07-07 15:48:32,220 - \u001b[1;33mWARNING\u001b[1;0m - Request 8216 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 159179f8af725a74a3a07caea792b838 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:48:34,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8269\n",
      "2023-07-07 15:48:46,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8289\n",
      "2023-07-07 15:48:58,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8309\n",
      "2023-07-07 15:49:11,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8329\n",
      "2023-07-07 15:49:23,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8349\n",
      "2023-07-07 15:49:35,943 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8369\n",
      "2023-07-07 15:49:48,280 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8389\n",
      "2023-07-07 15:50:00,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8409\n",
      "2023-07-07 15:50:12,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8429\n",
      "2023-07-07 15:50:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7953 failed with Exception \n",
      "2023-07-07 15:50:25,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8448\n",
      "2023-07-07 15:50:37,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8468\n",
      "2023-07-07 15:50:49,963 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8488\n",
      "2023-07-07 15:51:02,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8508\n",
      "2023-07-07 15:51:14,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8528\n",
      "2023-07-07 15:51:26,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8548\n",
      "2023-07-07 15:51:27,577 - \u001b[1;33mWARNING\u001b[1;0m - Request 8500 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b594752d7886a170a195641300f5338 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:51:39,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8567\n",
      "2023-07-07 15:51:51,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8587\n",
      "2023-07-07 15:52:03,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8607\n",
      "2023-07-07 15:52:16,275 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8627\n",
      "2023-07-07 15:52:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8161 failed with Exception \n",
      "2023-07-07 15:52:28,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8161\n",
      "2023-07-07 15:52:40,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8666\n",
      "2023-07-07 15:52:53,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8686\n",
      "2023-07-07 15:53:05,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8706\n",
      "2023-07-07 15:53:17,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8726\n",
      "2023-07-07 15:53:30,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8746\n",
      "2023-07-07 15:53:42,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8766\n",
      "2023-07-07 15:53:54,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8786\n",
      "2023-07-07 15:54:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8319 failed with Exception \n",
      "2023-07-07 15:54:07,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8805\n",
      "2023-07-07 15:54:19,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8825\n",
      "2023-07-07 15:54:31,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8845\n",
      "2023-07-07 15:54:44,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8865\n",
      "2023-07-07 15:54:56,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8885\n",
      "2023-07-07 15:55:08,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8905\n",
      "2023-07-07 15:55:21,232 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8925\n",
      "2023-07-07 15:55:21,890 - \u001b[1;33mWARNING\u001b[1;0m - Request 8877 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1cdddb7283580a37028c2607bf03d50d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:55:33,541 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8944\n",
      "2023-07-07 15:55:45,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8964\n",
      "2023-07-07 15:55:58,207 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8984\n",
      "2023-07-07 15:56:00,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8505 failed with Exception \n",
      "2023-07-07 15:56:10,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9003\n",
      "2023-07-07 15:56:22,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9023\n",
      "2023-07-07 15:56:35,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9043\n",
      "2023-07-07 15:56:47,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9063\n",
      "2023-07-07 15:56:59,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9083\n",
      "2023-07-07 15:57:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8607 failed with Exception \n",
      "2023-07-07 15:57:12,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9102\n",
      "2023-07-07 15:57:24,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9122\n",
      "2023-07-07 15:57:36,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9142\n",
      "2023-07-07 15:57:38,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8661 failed with Exception \n",
      "2023-07-07 15:57:49,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9161\n",
      "2023-07-07 15:58:01,521 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9181\n",
      "2023-07-07 15:58:13,855 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9201\n",
      "2023-07-07 15:58:26,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9221\n",
      "2023-07-07 15:58:38,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9241\n",
      "2023-07-07 15:58:50,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9261\n",
      "2023-07-07 15:59:03,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9281\n",
      "2023-07-07 15:59:06,167 - \u001b[1;33mWARNING\u001b[1;0m - Request 9236 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ab905a93f768855094074c1733bf7db1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:59:15,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9300\n",
      "2023-07-07 15:59:16,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 9254 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5a5900be7cf6f19fc48619401a7fd839 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 15:59:27,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9319\n",
      "2023-07-07 15:59:40,160 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9339\n",
      "2023-07-07 15:59:52,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9359\n",
      "2023-07-07 16:00:01,216 - \u001b[1;33mWARNING\u001b[1;0m - Request 9324 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 551b101c5d48b66c797b2d6a13aa304d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:00:04,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9378\n",
      "2023-07-07 16:00:17,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9398\n",
      "2023-07-07 16:00:29,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9418\n",
      "2023-07-07 16:00:29,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 9370 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6abcc5ee446b52703a6e6152b4107ed6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:00:29,768 - \u001b[1;33mWARNING\u001b[1;0m - Request 9367 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a8b468f365a38a0fa23c3049c36b4ea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:00:41,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9436\n",
      "2023-07-07 16:00:54,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9456\n",
      "2023-07-07 16:01:06,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9476\n",
      "2023-07-07 16:01:18,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9496\n",
      "2023-07-07 16:01:31,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9516\n",
      "2023-07-07 16:01:43,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9536\n",
      "2023-07-07 16:01:55,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9556\n",
      "2023-07-07 16:02:08,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9576\n",
      "2023-07-07 16:02:20,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9596\n",
      "2023-07-07 16:02:32,813 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9616\n",
      "2023-07-07 16:02:45,150 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9636\n",
      "2023-07-07 16:02:57,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9656\n",
      "2023-07-07 16:03:09,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9676\n",
      "2023-07-07 16:03:22,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9696\n",
      "2023-07-07 16:03:34,486 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9716\n",
      "2023-07-07 16:03:46,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9736\n",
      "2023-07-07 16:03:53,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9265 failed with Exception \n",
      "2023-07-07 16:03:59,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9755\n",
      "2023-07-07 16:04:11,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9775\n",
      "2023-07-07 16:04:23,857 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9795\n",
      "2023-07-07 16:04:36,192 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9815\n",
      "2023-07-07 16:04:48,545 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9835\n",
      "2023-07-07 16:05:00,892 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9855\n",
      "2023-07-07 16:05:13,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9875\n",
      "2023-07-07 16:05:25,535 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9895\n",
      "2023-07-07 16:05:37,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9915\n",
      "2023-07-07 16:05:39,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9431 failed with Exception \n",
      "2023-07-07 16:05:50,210 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9934\n",
      "2023-07-07 16:06:02,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9954\n",
      "2023-07-07 16:06:10,608 - \u001b[1;33mWARNING\u001b[1;0m - Request 9431 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bccbc29f5af3b358e7a7dfd85dd5916f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 16:06:14,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9973\n",
      "2023-07-07 16:06:27,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9993\n",
      "2023-07-07 16:06:39,535 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10013\n",
      "2023-07-07 16:06:51,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10033\n",
      "2023-07-07 16:07:04,180 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10053\n",
      "2023-07-07 16:07:06,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9573 failed with Exception \n",
      "2023-07-07 16:07:16,499 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10072\n",
      "2023-07-07 16:07:28,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10092\n",
      "2023-07-07 16:07:41,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10112\n",
      "2023-07-07 16:07:46,732 - \u001b[1;33mWARNING\u001b[1;0m - Request 10072 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f35f29dbe0e0ca127397a1f4d2fb755d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:07:53,492 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10131\n",
      "2023-07-07 16:08:05,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10151\n",
      "2023-07-07 16:08:18,155 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10171\n",
      "2023-07-07 16:08:30,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10191\n",
      "2023-07-07 16:08:42,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10211\n",
      "2023-07-07 16:08:55,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10231\n",
      "2023-07-07 16:09:07,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10251\n",
      "2023-07-07 16:09:19,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10271\n",
      "2023-07-07 16:09:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9790 failed with Exception \n",
      "2023-07-07 16:09:32,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10290\n",
      "2023-07-07 16:09:44,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10310\n",
      "2023-07-07 16:09:56,797 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10330\n",
      "2023-07-07 16:09:57,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9849 failed with Exception \n",
      "2023-07-07 16:10:09,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10349\n",
      "2023-07-07 16:10:21,452 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10369\n",
      "2023-07-07 16:10:33,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10389\n",
      "2023-07-07 16:10:46,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10409\n",
      "2023-07-07 16:10:58,460 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10429\n",
      "2023-07-07 16:11:10,806 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10449\n",
      "2023-07-07 16:11:23,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10469\n",
      "2023-07-07 16:11:28,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9994 failed with Exception \n",
      "2023-07-07 16:11:35,489 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10488\n",
      "2023-07-07 16:11:47,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10508\n",
      "2023-07-07 16:12:00,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10528\n",
      "2023-07-07 16:12:12,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10548\n",
      "2023-07-07 16:12:24,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10568\n",
      "2023-07-07 16:12:37,178 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10588\n",
      "2023-07-07 16:12:44,563 - \u001b[1;33mWARNING\u001b[1;0m - Request 10551 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5a8b391d57b4af52b23691f790a4f59f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:12:49,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10607\n",
      "2023-07-07 16:13:01,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10627\n",
      "2023-07-07 16:13:14,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10647\n",
      "2023-07-07 16:13:26,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10667\n",
      "2023-07-07 16:13:38,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10687\n",
      "2023-07-07 16:13:51,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10707\n",
      "2023-07-07 16:14:03,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10727\n",
      "2023-07-07 16:14:15,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10747\n",
      "2023-07-07 16:14:28,157 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10767\n",
      "2023-07-07 16:14:40,489 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10787\n",
      "2023-07-07 16:14:52,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10807\n",
      "2023-07-07 16:15:05,168 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10827\n",
      "2023-07-07 16:15:17,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10847\n",
      "2023-07-07 16:15:29,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10867\n",
      "2023-07-07 16:15:33,012 - \u001b[1;33mWARNING\u001b[1;0m - Request 10823 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 187658c47a585a018780dd87390e7a7e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:15:42,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10886\n",
      "2023-07-07 16:15:54,503 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10906\n",
      "2023-07-07 16:16:06,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10926\n",
      "2023-07-07 16:16:19,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10946\n",
      "2023-07-07 16:16:31,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10966\n",
      "2023-07-07 16:16:43,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10986\n",
      "2023-07-07 16:16:56,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11006\n",
      "2023-07-07 16:17:08,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11026\n",
      "2023-07-07 16:17:20,801 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11046\n",
      "2023-07-07 16:17:33,113 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11066\n",
      "2023-07-07 16:17:39,320 - \u001b[1;33mWARNING\u001b[1;0m - Request 11027 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ee12f093211db070476e8a29b7370251 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:17:45,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11085\n",
      "2023-07-07 16:17:57,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11105\n",
      "2023-07-07 16:18:10,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11125\n",
      "2023-07-07 16:18:22,444 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11145\n",
      "2023-07-07 16:18:34,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11165\n",
      "2023-07-07 16:18:47,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11185\n",
      "2023-07-07 16:18:59,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11205\n",
      "2023-07-07 16:19:11,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11225\n",
      "2023-07-07 16:19:24,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11245\n",
      "2023-07-07 16:19:36,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11265\n",
      "2023-07-07 16:19:48,744 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11285\n",
      "2023-07-07 16:19:55,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10811 failed with Exception \n",
      "2023-07-07 16:19:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10816 failed with Exception \n",
      "2023-07-07 16:20:01,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11303\n",
      "2023-07-07 16:20:13,401 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11323\n",
      "2023-07-07 16:20:25,742 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11343\n",
      "2023-07-07 16:20:38,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11363\n",
      "2023-07-07 16:20:48,568 - \u001b[1;33mWARNING\u001b[1;0m - Request 11331 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 12ba78b981e612eca8595b9ab392588d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:20:50,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11382\n",
      "2023-07-07 16:20:55,964 - \u001b[1;33mWARNING\u001b[1;0m - Request 11343 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f02b1c11398fb29cd8599617e6f53567 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:21:02,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11401\n",
      "2023-07-07 16:21:15,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11421\n",
      "2023-07-07 16:21:27,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11441\n",
      "2023-07-07 16:21:39,698 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 16:21:52,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11481\n",
      "2023-07-07 16:22:04,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11501\n",
      "2023-07-07 16:22:16,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11521\n",
      "2023-07-07 16:22:29,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11541\n",
      "2023-07-07 16:22:41,364 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11561\n",
      "2023-07-07 16:22:53,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11581\n",
      "2023-07-07 16:23:06,027 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11601\n",
      "2023-07-07 16:23:18,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11621\n",
      "2023-07-07 16:23:30,667 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11641\n",
      "2023-07-07 16:23:42,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11661\n",
      "2023-07-07 16:23:55,318 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11681\n",
      "2023-07-07 16:24:07,651 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11701\n",
      "2023-07-07 16:24:19,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11721\n",
      "2023-07-07 16:24:32,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11741\n",
      "2023-07-07 16:24:44,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11761\n",
      "2023-07-07 16:24:56,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11781\n",
      "2023-07-07 16:25:09,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11801\n",
      "2023-07-07 16:25:21,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11821\n",
      "2023-07-07 16:25:33,955 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11841\n",
      "2023-07-07 16:25:46,284 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11861\n",
      "2023-07-07 16:25:58,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11881\n",
      "2023-07-07 16:26:10,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11901\n",
      "2023-07-07 16:26:23,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11921\n",
      "2023-07-07 16:26:27,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11441 failed with Exception \n",
      "2023-07-07 16:26:35,609 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11940\n",
      "2023-07-07 16:26:47,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11960\n",
      "2023-07-07 16:27:00,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11980\n",
      "2023-07-07 16:27:12,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12000\n",
      "2023-07-07 16:27:17,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11521 failed with Exception \n",
      "2023-07-07 16:27:24,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12019\n",
      "2023-07-07 16:27:37,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12039\n",
      "2023-07-07 16:27:49,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12059\n",
      "2023-07-07 16:28:01,877 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12079\n",
      "2023-07-07 16:28:14,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12099\n",
      "2023-07-07 16:28:26,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12119\n",
      "2023-07-07 16:28:38,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12139\n",
      "2023-07-07 16:28:51,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12159\n",
      "2023-07-07 16:29:03,541 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12179\n",
      "2023-07-07 16:29:15,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12199\n",
      "2023-07-07 16:29:28,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12219\n",
      "2023-07-07 16:29:40,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12239\n",
      "2023-07-07 16:29:43,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 12195 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3bffd6c5a770e4cfafcec05b12ccb36e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:29:52,886 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12258\n",
      "2023-07-07 16:30:05,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12278\n",
      "2023-07-07 16:30:05,831 - \u001b[1;33mWARNING\u001b[1;0m - Request 12231 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0eb1d4a94b6020158744ff35f52ff62 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:30:17,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12297\n",
      "2023-07-07 16:30:29,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12317\n",
      "2023-07-07 16:30:42,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12337\n",
      "2023-07-07 16:30:54,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12357\n",
      "2023-07-07 16:31:06,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12377\n",
      "2023-07-07 16:31:19,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12397\n",
      "2023-07-07 16:31:31,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12417\n",
      "2023-07-07 16:31:43,884 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12437\n",
      "2023-07-07 16:31:56,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12457\n",
      "2023-07-07 16:32:08,535 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12477\n",
      "2023-07-07 16:32:20,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12497\n",
      "2023-07-07 16:32:33,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12517\n",
      "2023-07-07 16:32:45,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12537\n",
      "2023-07-07 16:32:57,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12557\n",
      "2023-07-07 16:33:10,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12577\n",
      "2023-07-07 16:33:22,550 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12597\n",
      "2023-07-07 16:33:34,880 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12617\n",
      "2023-07-07 16:33:47,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12637\n",
      "2023-07-07 16:33:53,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12162 failed with Exception \n",
      "2023-07-07 16:33:59,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12656\n",
      "2023-07-07 16:34:11,871 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12676\n",
      "2023-07-07 16:34:24,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12696\n",
      "2023-07-07 16:34:36,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12716\n",
      "2023-07-07 16:34:48,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12736\n",
      "2023-07-07 16:34:56,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 12697 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5914a4636a194b9c16a7c5ab8e10882d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:35:01,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12755\n",
      "2023-07-07 16:35:13,509 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12775\n",
      "2023-07-07 16:35:25,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12795\n",
      "2023-07-07 16:35:38,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12815\n",
      "2023-07-07 16:35:50,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12835\n",
      "2023-07-07 16:36:02,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12855\n",
      "2023-07-07 16:36:15,155 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12875\n",
      "2023-07-07 16:36:27,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12895\n",
      "2023-07-07 16:36:39,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12915\n",
      "2023-07-07 16:36:52,174 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12935\n",
      "2023-07-07 16:37:04,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12955\n",
      "2023-07-07 16:37:16,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12975\n",
      "2023-07-07 16:37:21,158 - \u001b[1;33mWARNING\u001b[1;0m - Request 12933 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7d06155309bdb11bd69d47bca49cc088 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:37:29,156 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12994\n",
      "2023-07-07 16:37:41,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13014\n",
      "2023-07-07 16:37:53,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13034\n",
      "2023-07-07 16:38:06,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13054\n",
      "2023-07-07 16:38:18,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13074\n",
      "2023-07-07 16:38:30,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13094\n",
      "2023-07-07 16:38:43,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13114\n",
      "2023-07-07 16:38:55,483 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13134\n",
      "2023-07-07 16:39:07,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13154\n",
      "2023-07-07 16:39:20,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13174\n",
      "2023-07-07 16:39:32,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13194\n",
      "2023-07-07 16:39:44,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13214\n",
      "2023-07-07 16:39:44,862 - \u001b[1;33mWARNING\u001b[1;0m - Request 13165 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42e2dedfe5bde0d6bf14fc4e399b47eb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 16:39:57,158 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13233\n",
      "2023-07-07 16:40:09,492 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13253\n",
      "2023-07-07 16:40:21,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13273\n",
      "2023-07-07 16:40:34,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13293\n",
      "2023-07-07 16:40:41,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12819 failed with Exception \n",
      "2023-07-07 16:40:46,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13312\n",
      "2023-07-07 16:40:58,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13332\n",
      "2023-07-07 16:41:05,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 13295 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 550da3c807680f5a0791166069f57404 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:41:11,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13351\n",
      "2023-07-07 16:41:23,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13371\n",
      "2023-07-07 16:41:35,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13391\n",
      "2023-07-07 16:41:48,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13411\n",
      "2023-07-07 16:42:00,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13431\n",
      "2023-07-07 16:42:12,793 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13451\n",
      "2023-07-07 16:42:25,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13471\n",
      "2023-07-07 16:42:37,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13491\n",
      "2023-07-07 16:42:49,796 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13511\n",
      "2023-07-07 16:43:02,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13531\n",
      "2023-07-07 16:43:14,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13551\n",
      "2023-07-07 16:43:26,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13571\n",
      "2023-07-07 16:43:39,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13591\n",
      "2023-07-07 16:43:51,448 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13611\n",
      "2023-07-07 16:44:03,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13631\n",
      "2023-07-07 16:44:16,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13651\n",
      "2023-07-07 16:44:28,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13671\n",
      "2023-07-07 16:44:40,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13691\n",
      "2023-07-07 16:44:53,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13711\n",
      "2023-07-07 16:45:05,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13731\n",
      "2023-07-07 16:45:17,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13751\n",
      "2023-07-07 16:45:30,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13771\n",
      "2023-07-07 16:45:42,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13791\n",
      "2023-07-07 16:45:54,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13811\n",
      "2023-07-07 16:46:07,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13831\n",
      "2023-07-07 16:46:19,448 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13851\n",
      "2023-07-07 16:46:29,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 13819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b75bd59a5787a0819b2269315c517369 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:46:31,793 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13870\n",
      "2023-07-07 16:46:44,128 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13890\n",
      "2023-07-07 16:46:50,278 - \u001b[1;33mWARNING\u001b[1;0m - Request 13852 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40d1bf09ba7ad56b3a20358c9e2fab5c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:46:56,479 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13909\n",
      "2023-07-07 16:47:08,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13929\n",
      "2023-07-07 16:47:21,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13949\n",
      "2023-07-07 16:47:33,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13969\n",
      "2023-07-07 16:47:45,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13989\n",
      "2023-07-07 16:47:58,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14009\n",
      "2023-07-07 16:48:10,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14029\n",
      "2023-07-07 16:48:22,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14049\n",
      "2023-07-07 16:48:35,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14069\n",
      "2023-07-07 16:48:47,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14089\n",
      "2023-07-07 16:48:59,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14109\n",
      "2023-07-07 16:49:12,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14129\n",
      "2023-07-07 16:49:17,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13653 failed with Exception \n",
      "2023-07-07 16:49:24,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14148\n",
      "2023-07-07 16:49:36,806 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14168\n",
      "2023-07-07 16:49:49,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14188\n",
      "2023-07-07 16:50:01,466 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14208\n",
      "2023-07-07 16:50:13,790 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14228\n",
      "2023-07-07 16:50:26,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14248\n",
      "2023-07-07 16:50:38,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14268\n",
      "2023-07-07 16:50:41,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13788 failed with Exception \n",
      "2023-07-07 16:50:50,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14287\n",
      "2023-07-07 16:51:03,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14307\n",
      "2023-07-07 16:51:15,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14327\n",
      "2023-07-07 16:51:27,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14347\n",
      "2023-07-07 16:51:40,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14367\n",
      "2023-07-07 16:51:52,402 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14387\n",
      "2023-07-07 16:52:04,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14407\n",
      "2023-07-07 16:52:17,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14427\n",
      "2023-07-07 16:52:29,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14447\n",
      "2023-07-07 16:52:41,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14467\n",
      "2023-07-07 16:52:48,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 14429 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3527bd79eb4a8e839d417ebcefcef543 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:52:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 13997 failed with Exception \n",
      "2023-07-07 16:52:54,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14485\n",
      "2023-07-07 16:53:06,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14505\n",
      "2023-07-07 16:53:18,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14525\n",
      "2023-07-07 16:53:22,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 14048 failed with Exception \n",
      "2023-07-07 16:53:31,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14544\n",
      "2023-07-07 16:53:43,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14564\n",
      "2023-07-07 16:53:55,734 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14584\n",
      "2023-07-07 16:54:08,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14604\n",
      "2023-07-07 16:54:20,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14624\n",
      "2023-07-07 16:54:32,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14644\n",
      "2023-07-07 16:54:45,048 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14664\n",
      "2023-07-07 16:54:57,365 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14684\n",
      "2023-07-07 16:55:09,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14704\n",
      "2023-07-07 16:55:22,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14724\n",
      "2023-07-07 16:55:34,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14744\n",
      "2023-07-07 16:55:46,669 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14764\n",
      "2023-07-07 16:55:59,019 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14784\n",
      "2023-07-07 16:56:11,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14804\n",
      "2023-07-07 16:56:17,002 - \u001b[1;33mWARNING\u001b[1;0m - Request 14764 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 051c93805eb24e0f4fbab01d491948fe in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:56:23,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14823\n",
      "2023-07-07 16:56:36,017 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14843\n",
      "2023-07-07 16:56:48,355 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 16:57:00,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14883\n",
      "2023-07-07 16:57:11,180 - \u001b[1;33mWARNING\u001b[1;0m - Request 14851 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8141cacd80db33d8ecabbb41089256f3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 16:57:13,009 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14902\n",
      "2023-07-07 16:57:25,339 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14922\n",
      "2023-07-07 16:57:37,672 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14942\n",
      "2023-07-07 16:57:45,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 14472 failed with Exception \n",
      "2023-07-07 16:57:49,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14961\n",
      "2023-07-07 16:58:02,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14981\n",
      "2023-07-07 16:58:14,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15001\n",
      "2023-07-07 16:58:26,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15021\n",
      "2023-07-07 16:58:39,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15041\n",
      "2023-07-07 16:58:51,663 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15061\n",
      "2023-07-07 16:58:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 14590 failed with Exception \n",
      "2023-07-07 16:59:04,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15080\n",
      "2023-07-07 16:59:16,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15100\n",
      "2023-07-07 16:59:28,673 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15120\n",
      "2023-07-07 16:59:40,995 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15140\n",
      "2023-07-07 16:59:53,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15160\n",
      "2023-07-07 17:00:05,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15180\n",
      "2023-07-07 17:00:18,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15200\n",
      "2023-07-07 17:00:30,352 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15220\n",
      "2023-07-07 17:00:42,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15240\n",
      "2023-07-07 17:00:55,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15260\n",
      "2023-07-07 17:01:07,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15280\n",
      "2023-07-07 17:01:19,682 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15300\n",
      "2023-07-07 17:01:32,014 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15320\n",
      "2023-07-07 17:01:44,343 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15340\n",
      "2023-07-07 17:01:56,678 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15360\n",
      "2023-07-07 17:02:09,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15380\n",
      "2023-07-07 17:02:21,332 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15400\n",
      "2023-07-07 17:02:33,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15420\n",
      "2023-07-07 17:02:46,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15440\n",
      "2023-07-07 17:02:58,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15460\n",
      "2023-07-07 17:03:10,667 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15480\n",
      "2023-07-07 17:03:22,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15500\n",
      "2023-07-07 17:03:35,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15520\n",
      "2023-07-07 17:03:47,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15540\n",
      "2023-07-07 17:03:49,581 - \u001b[1;33mWARNING\u001b[1;0m - Request 15494 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 013844ba708f96a7177b36c21958aed8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:03:59,981 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15559\n",
      "2023-07-07 17:04:12,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15579\n",
      "2023-07-07 17:04:24,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15599\n",
      "2023-07-07 17:04:36,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15619\n",
      "2023-07-07 17:04:49,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15639\n",
      "2023-07-07 17:05:01,648 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15659\n",
      "2023-07-07 17:05:13,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15679\n",
      "2023-07-07 17:05:26,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15699\n",
      "2023-07-07 17:05:38,621 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15719\n",
      "2023-07-07 17:05:50,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15739\n",
      "2023-07-07 17:05:58,361 - \u001b[1;33mWARNING\u001b[1;0m - Request 15702 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c0b6860ef2dbb1377e4c13f487158649 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:06:03,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15758\n",
      "2023-07-07 17:06:15,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15778\n",
      "2023-07-07 17:06:27,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15798\n",
      "2023-07-07 17:06:40,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15818\n",
      "2023-07-07 17:06:52,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15838\n",
      "2023-07-07 17:07:04,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15858\n",
      "2023-07-07 17:07:17,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15878\n",
      "2023-07-07 17:07:29,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15898\n",
      "2023-07-07 17:07:34,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 15420 failed with Exception \n",
      "2023-07-07 17:07:41,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15917\n",
      "2023-07-07 17:07:54,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15937\n",
      "2023-07-07 17:08:06,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15957\n",
      "2023-07-07 17:08:13,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 15484 failed with Exception \n",
      "2023-07-07 17:08:18,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15976\n",
      "2023-07-07 17:08:31,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15996\n",
      "2023-07-07 17:08:43,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16016\n",
      "2023-07-07 17:08:55,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16036\n",
      "2023-07-07 17:09:08,225 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16056\n",
      "2023-07-07 17:09:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 15590 failed with Exception \n",
      "2023-07-07 17:09:20,574 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15590\n",
      "2023-07-07 17:09:32,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16095\n",
      "2023-07-07 17:09:45,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16115\n",
      "2023-07-07 17:09:57,587 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16135\n",
      "2023-07-07 17:10:09,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16155\n",
      "2023-07-07 17:10:22,234 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16175\n",
      "2023-07-07 17:10:30,350 - \u001b[1;33mWARNING\u001b[1;0m - Request 16139 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97c7c9a5a985b9d6993b1759738904b8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:10:34,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16194\n",
      "2023-07-07 17:10:46,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16214\n",
      "2023-07-07 17:10:59,248 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16234\n",
      "2023-07-07 17:11:11,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16254\n",
      "2023-07-07 17:11:23,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16274\n",
      "2023-07-07 17:11:36,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16294\n",
      "2023-07-07 17:11:48,622 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16314\n",
      "2023-07-07 17:12:00,941 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16334\n",
      "2023-07-07 17:12:13,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16354\n",
      "2023-07-07 17:12:22,537 - \u001b[1;33mWARNING\u001b[1;0m - Request 16320 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bf3e0af6c79589be579ba31b19af888c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:12:25,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16373\n",
      "2023-07-07 17:12:37,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16393\n",
      "2023-07-07 17:12:50,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16413\n",
      "2023-07-07 17:13:02,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16433\n",
      "2023-07-07 17:13:14,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16453\n",
      "2023-07-07 17:13:27,322 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16473\n",
      "2023-07-07 17:13:39,645 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16493\n",
      "2023-07-07 17:13:45,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 16019 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:13:51,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16512\n",
      "2023-07-07 17:14:04,291 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16532\n",
      "2023-07-07 17:14:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 16049 failed with Exception \n",
      "2023-07-07 17:14:08,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 16055 failed with Exception \n",
      "2023-07-07 17:14:16,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16550\n",
      "2023-07-07 17:14:28,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16570\n",
      "2023-07-07 17:14:41,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16590\n",
      "2023-07-07 17:14:53,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16610\n",
      "2023-07-07 17:14:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 16134 failed with Exception \n",
      "2023-07-07 17:15:05,980 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16629\n",
      "2023-07-07 17:15:18,312 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16649\n",
      "2023-07-07 17:15:30,641 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16669\n",
      "2023-07-07 17:15:42,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16689\n",
      "2023-07-07 17:15:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 16215 failed with Exception \n",
      "2023-07-07 17:15:55,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16708\n",
      "2023-07-07 17:16:00,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 16236 failed with Exception \n",
      "2023-07-07 17:16:07,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16727\n",
      "2023-07-07 17:16:19,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16747\n",
      "2023-07-07 17:16:32,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16767\n",
      "2023-07-07 17:16:44,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16787\n",
      "2023-07-07 17:16:56,987 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16807\n",
      "2023-07-07 17:17:09,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16827\n",
      "2023-07-07 17:17:16,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 16359 failed with Exception \n",
      "2023-07-07 17:17:21,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16846\n",
      "2023-07-07 17:17:33,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16866\n",
      "2023-07-07 17:17:46,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16886\n",
      "2023-07-07 17:17:58,648 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16906\n",
      "2023-07-07 17:18:10,986 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16926\n",
      "2023-07-07 17:18:23,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16946\n",
      "2023-07-07 17:18:35,620 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16966\n",
      "2023-07-07 17:18:47,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16986\n",
      "2023-07-07 17:19:00,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17006\n",
      "2023-07-07 17:19:12,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17026\n",
      "2023-07-07 17:19:24,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17046\n",
      "2023-07-07 17:19:37,275 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17066\n",
      "2023-07-07 17:19:43,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 16592 failed with Exception \n",
      "2023-07-07 17:19:49,608 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17085\n",
      "2023-07-07 17:20:01,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17105\n",
      "2023-07-07 17:20:14,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17125\n",
      "2023-07-07 17:20:26,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17145\n",
      "2023-07-07 17:20:38,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17165\n",
      "2023-07-07 17:20:51,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17185\n",
      "2023-07-07 17:21:03,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17205\n",
      "2023-07-07 17:21:15,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17225\n",
      "2023-07-07 17:21:28,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17245\n",
      "2023-07-07 17:21:40,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17265\n",
      "2023-07-07 17:21:52,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17285\n",
      "2023-07-07 17:22:05,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17305\n",
      "2023-07-07 17:22:07,815 - \u001b[1;33mWARNING\u001b[1;0m - Request 17260 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47182a147993e5f8e7995a94ff2f268e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:22:17,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17324\n",
      "2023-07-07 17:22:29,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17344\n",
      "2023-07-07 17:22:42,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17364\n",
      "2023-07-07 17:22:54,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17384\n",
      "2023-07-07 17:23:06,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17404\n",
      "2023-07-07 17:23:19,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17424\n",
      "2023-07-07 17:23:31,622 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17444\n",
      "2023-07-07 17:23:43,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17464\n",
      "2023-07-07 17:23:56,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17484\n",
      "2023-07-07 17:24:08,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17504\n",
      "2023-07-07 17:24:20,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17524\n",
      "2023-07-07 17:24:33,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17544\n",
      "2023-07-07 17:24:45,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17564\n",
      "2023-07-07 17:24:57,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17584\n",
      "2023-07-07 17:25:10,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17604\n",
      "2023-07-07 17:25:22,613 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17624\n",
      "2023-07-07 17:25:34,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17644\n",
      "2023-07-07 17:25:47,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17664\n",
      "2023-07-07 17:25:59,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17684\n",
      "2023-07-07 17:26:11,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17704\n",
      "2023-07-07 17:26:24,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17724\n",
      "2023-07-07 17:26:36,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17744\n",
      "2023-07-07 17:26:48,928 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17764\n",
      "2023-07-07 17:27:01,247 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17784\n",
      "2023-07-07 17:27:11,748 - \u001b[1;33mWARNING\u001b[1;0m - Request 17752 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cab292c2ffbc40af7cc7a20c7a3b304d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:27:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 17315 failed with Exception \n",
      "2023-07-07 17:27:13,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17315\n",
      "2023-07-07 17:27:25,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17822\n",
      "2023-07-07 17:27:38,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17842\n",
      "2023-07-07 17:27:50,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17862\n",
      "2023-07-07 17:28:02,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17882\n",
      "2023-07-07 17:28:15,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17902\n",
      "2023-07-07 17:28:27,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17922\n",
      "2023-07-07 17:28:31,965 - \u001b[1;33mWARNING\u001b[1;0m - Request 17880 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID da696122bda5b224cc95f04e21fa58a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:28:39,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17941\n",
      "2023-07-07 17:28:52,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17961\n",
      "2023-07-07 17:29:04,582 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17981\n",
      "2023-07-07 17:29:16,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18001\n",
      "2023-07-07 17:29:29,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18021\n",
      "2023-07-07 17:29:41,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18041\n",
      "2023-07-07 17:29:44,142 - \u001b[1;33mWARNING\u001b[1;0m - Request 17996 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1383c6ae2c6488ab1b8b9b91d99ebf11 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:29:53,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18060\n",
      "2023-07-07 17:30:06,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18080\n",
      "2023-07-07 17:30:18,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18100\n",
      "2023-07-07 17:30:30,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18120\n",
      "2023-07-07 17:30:43,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18140\n",
      "2023-07-07 17:30:55,580 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18160\n",
      "2023-07-07 17:31:07,903 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:31:20,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18200\n",
      "2023-07-07 17:31:27,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 18163 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 41ee2b2ee04f8e0b7bd3df9601217012 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:31:32,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18219\n",
      "2023-07-07 17:31:44,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18239\n",
      "2023-07-07 17:31:57,219 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18259\n",
      "2023-07-07 17:32:09,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18279\n",
      "2023-07-07 17:32:21,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18299\n",
      "2023-07-07 17:32:34,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18319\n",
      "2023-07-07 17:32:38,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 17841 failed with Exception \n",
      "2023-07-07 17:32:46,574 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18338\n",
      "2023-07-07 17:32:58,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18358\n",
      "2023-07-07 17:33:11,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18378\n",
      "2023-07-07 17:33:18,011 - \u001b[1;33mWARNING\u001b[1;0m - Request 18340 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 576be125d94c96919a5abae4de9663f2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:33:23,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18397\n",
      "2023-07-07 17:33:35,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18417\n",
      "2023-07-07 17:33:48,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18437\n",
      "2023-07-07 17:33:49,470 - \u001b[1;33mWARNING\u001b[1;0m - Request 18390 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 44724062a47ac4a47d78ee3c1fde5262 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:34:00,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18456\n",
      "2023-07-07 17:34:12,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18476\n",
      "2023-07-07 17:34:25,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18496\n",
      "2023-07-07 17:34:31,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 18456 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5754d70d4d1ae715acb6d46df64d84aa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:34:33,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 18461 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1905ef257e7851dea7111f8c6b29fd75 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:34:37,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18514\n",
      "2023-07-07 17:34:49,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18534\n",
      "2023-07-07 17:35:02,171 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18554\n",
      "2023-07-07 17:35:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 18077 failed with Exception \n",
      "2023-07-07 17:35:14,516 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18573\n",
      "2023-07-07 17:35:26,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18593\n",
      "2023-07-07 17:35:39,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18613\n",
      "2023-07-07 17:35:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 18142 failed with Exception \n",
      "2023-07-07 17:35:51,515 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18632\n",
      "2023-07-07 17:36:03,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18652\n",
      "2023-07-07 17:36:16,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18672\n",
      "2023-07-07 17:36:28,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18692\n",
      "2023-07-07 17:36:40,857 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18712\n",
      "2023-07-07 17:36:53,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18732\n",
      "2023-07-07 17:37:05,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18752\n",
      "2023-07-07 17:37:17,871 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18772\n",
      "2023-07-07 17:37:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 18296 failed with Exception \n",
      "2023-07-07 17:37:30,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18791\n",
      "2023-07-07 17:37:42,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18811\n",
      "2023-07-07 17:37:54,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18831\n",
      "2023-07-07 17:38:07,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18851\n",
      "2023-07-07 17:38:19,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18871\n",
      "2023-07-07 17:38:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 18402 failed with Exception \n",
      "2023-07-07 17:38:31,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18890\n",
      "2023-07-07 17:38:44,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18910\n",
      "2023-07-07 17:38:56,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18930\n",
      "2023-07-07 17:39:08,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18950\n",
      "2023-07-07 17:39:21,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18970\n",
      "2023-07-07 17:39:33,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18990\n",
      "2023-07-07 17:39:45,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19010\n",
      "2023-07-07 17:39:58,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19030\n",
      "2023-07-07 17:40:10,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19050\n",
      "2023-07-07 17:40:22,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19070\n",
      "2023-07-07 17:40:35,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19090\n",
      "2023-07-07 17:40:47,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19110\n",
      "2023-07-07 17:40:58,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 19079 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d0619a637705a37e4aebf18a926efd9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:40:59,902 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19079\n",
      "2023-07-07 17:41:12,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19149\n",
      "2023-07-07 17:41:24,571 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19169\n",
      "2023-07-07 17:41:36,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19189\n",
      "2023-07-07 17:41:49,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19209\n",
      "2023-07-07 17:42:01,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19229\n",
      "2023-07-07 17:42:13,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19249\n",
      "2023-07-07 17:42:18,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 18772 failed with Exception \n",
      "2023-07-07 17:42:26,223 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19268\n",
      "2023-07-07 17:42:38,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19288\n",
      "2023-07-07 17:42:44,124 - \u001b[1;33mWARNING\u001b[1;0m - Request 19249 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56bb14c25f3410d0ebd2e1df59afc57b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:42:50,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19307\n",
      "2023-07-07 17:42:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 18825 failed with Exception \n",
      "2023-07-07 17:43:03,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19326\n",
      "2023-07-07 17:43:15,550 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19346\n",
      "2023-07-07 17:43:27,884 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19366\n",
      "2023-07-07 17:43:29,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 18886 failed with Exception \n",
      "2023-07-07 17:43:40,210 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19385\n",
      "2023-07-07 17:43:52,521 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19405\n",
      "2023-07-07 17:44:04,855 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19425\n",
      "2023-07-07 17:44:17,174 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19445\n",
      "2023-07-07 17:44:23,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 19406 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 55d2eba0f3d3c3f777e41bb9717391d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:44:29,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19464\n",
      "2023-07-07 17:44:41,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19484\n",
      "2023-07-07 17:44:54,174 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19504\n",
      "2023-07-07 17:45:06,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19524\n",
      "2023-07-07 17:45:18,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19544\n",
      "2023-07-07 17:45:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 19068 failed with Exception \n",
      "2023-07-07 17:45:31,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19563\n",
      "2023-07-07 17:45:43,483 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19583\n",
      "2023-07-07 17:45:55,812 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19603\n",
      "2023-07-07 17:46:01,383 - \u001b[1;33mWARNING\u001b[1;0m - Request 19563 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e1a756bd09214ee7c8dea416aece4deb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:46:08,150 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19622\n",
      "2023-07-07 17:46:20,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19642\n",
      "2023-07-07 17:46:32,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19662\n",
      "2023-07-07 17:46:33,437 - \u001b[1;33mWARNING\u001b[1;0m - Request 19614 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d45618fbfab14a45baf61f2b123c5813 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:46:45,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19681\n",
      "2023-07-07 17:46:57,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19701\n",
      "2023-07-07 17:47:09,806 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19721\n",
      "2023-07-07 17:47:22,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19741\n",
      "2023-07-07 17:47:34,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19761\n",
      "2023-07-07 17:47:46,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19781\n",
      "2023-07-07 17:47:56,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 19315 failed with Exception \n",
      "2023-07-07 17:47:59,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19800\n",
      "2023-07-07 17:48:11,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19820\n",
      "2023-07-07 17:48:23,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19840\n",
      "2023-07-07 17:48:36,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19860\n",
      "2023-07-07 17:48:48,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19880\n",
      "2023-07-07 17:49:00,782 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19900\n",
      "2023-07-07 17:49:07,038 - \u001b[1;33mWARNING\u001b[1;0m - Request 19861 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6201e7ab57a4dd9cdd81003a35e8d9be in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:49:09,446 - \u001b[1;33mWARNING\u001b[1;0m - Request 19865 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f3ebe4807ded6bbd17464947ad09b46 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:49:13,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19918\n",
      "2023-07-07 17:49:25,439 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19938\n",
      "2023-07-07 17:49:37,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19958\n",
      "2023-07-07 17:49:40,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 19865 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 305f9a4dbf742d074d91d5f4e9e717a8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-07 17:49:50,093 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19977\n",
      "2023-07-07 17:50:02,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19997\n",
      "2023-07-07 17:54:45,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 19969 failed with Exception \n",
      "2023-07-07 17:54:47,532 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230707_142350.jsonl\n",
      "2023-07-07 17:54:47,537 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230707_142350.jsonl\n",
      "2023-07-07 17:54:48,261 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...inish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 668, \"completion_tokens\": 33, \"total_tokens\": 701}}, {\"fact\": \"comparison with today's findings\"}] for fact \"comparison with today's findings\": GPT is acting weird: I'm sorry, but I need more information to provide a complete response. Could you please provide the medical fact that you would like to compare with today's findings?\n",
      "2023-07-07 17:54:48,265 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 667, \"completion_tokens\": 30, \"total_tokens\": 697}}, {\"fact\": \"suggestive of this\"}] for fact \"suggestive of this\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"suggestive of this\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,282 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...st?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 665, \"completion_tokens\": 28, \"total_tokens\": 693}}, {\"fact\": \"different configuration\"}] for fact \"different configuration\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"different configuration\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,283 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...quest?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 666, \"completion_tokens\": 29, \"total_tokens\": 695}}, {\"fact\": \"suggested resolution\"}] for fact \"suggested resolution\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"suggested resolution\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,302 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...quest?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 665, \"completion_tokens\": 28, \"total_tokens\": 693}}, {\"fact\": \"confirmation desired\"}] for fact \"confirmation desired\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"confirmation desired\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,309 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...our request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 665, \"completion_tokens\": 28, \"total_tokens\": 693}}, {\"fact\": \"volume related\"}] for fact \"volume related\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"volume related\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,334 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi... request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 665, \"completion_tokens\": 28, \"total_tokens\": 693}}, {\"fact\": \"third possibility\"}] for fact \"third possibility\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"third possibility\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,347 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...rther.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 667, \"completion_tokens\": 60, \"total_tokens\": 727}}, {\"fact\": \"determine chronicity\"}] for fact \"determine chronicity\": GPT is acting weird: I'm sorry, but the given medical fact \"determine chronicity\" does not provide enough information to determine the anatomical location, detailed observation, short observation, category, health status, prev_study_comparison?, and comparison status. Please provide more specific details or context for me to assist you further.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-07 17:54:48,374 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 667, \"completion_tokens\": 33, \"total_tokens\": 700}}, {\"fact\": \"comparison to old studies\"}] for fact \"comparison to old studies\": GPT is acting weird: I'm sorry, but I cannot generate the output you're looking for without a specific medical fact. Could you please provide a medical fact for me to work with?\n",
      "2023-07-07 17:54:48,376 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...arison?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 666, \"completion_tokens\": 71, \"total_tokens\": 737}}, {\"fact\": \"question dissection\"}] for fact \"question dissection\": GPT is acting weird: - What is the anatomical location?\n",
      "- What was observed in detail?\n",
      "- Can you provide a short summary of the observation?\n",
      "- What is the category of the observation?\n",
      "- What is the health status indicated by the observation?\n",
      "- Is there a comparison with a previous study?\n",
      "- If there is a comparison, what is the status of the comparison?\n",
      "2023-07-07 17:54:48,382 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...ur request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 666, \"completion_tokens\": 29, \"total_tokens\": 695}}, {\"fact\": \"further concern\"}] for fact \"further concern\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"further concern\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,385 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...est?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 667, \"completion_tokens\": 30, \"total_tokens\": 697}}, {\"fact\": \"marking focal findings\"}] for fact \"marking focal findings\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"marking focal findings\". Could you please provide more information or clarify your request?\n",
      "2023-07-07 17:54:48,428 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...e?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 666, \"completion_tokens\": 24, \"total_tokens\": 690}}, {\"fact\": \"more complete evaluation\"}] for fact \"more complete evaluation\": GPT is acting weird: I apologize for the confusion. Could you please provide more information or context about the medical fact you would like to evaluate?\n",
      "2023-07-07 17:54:48,438 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...\\\").\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 665, \"completion_tokens\": 51, \"total_tokens\": 716}}, {\"fact\": \"location clarification\"}] for fact \"location clarification\": Could not parse output: If the medical fact provides a specific anatomical location, it should be included in the \"anatomical location\" field. If the fact does not provide a specific anatomical location, the \"anatomical location\" field should be left empty (\"\").\n",
      "2023-07-07 17:54:48,495 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...rocess?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 666, \"completion_tokens\": 32, \"total_tokens\": 698}}, {\"fact\": \"similar abnormality\"}] for fact \"similar abnormality\": GPT is acting weird: I'm sorry, but I need more information to provide a response. Can you please provide the specific medical fact or observation that you would like me to process?\n",
      "2023-07-07 17:54:48,499 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...iew?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 667, \"completion_tokens\": 22, \"total_tokens\": 689}}, {\"fact\": \"review of the findings\"}] for fact \"review of the findings\": GPT is acting weird: I apologize for the confusion. Could you please provide the specific medical fact that you would like me to review?\n",
      "2023-07-07 17:54:48,519 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-07-07 17:54:48,533 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 19984 of 20000 API responses.\n",
      "                    16 of 20000 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_metadata_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\" \\\n",
    "    --offset 40000 \\\n",
    "    --num_facts 20000 \\\n",
    "    --sample_facts_uniformly \\\n",
    "    --max_requests_per_minute 3300 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__v2_offset=40000_uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15846a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-08 13:22:33,922 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19936 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\n",
      "2023-07-08 13:22:34,061 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19936 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\n",
      "2023-07-08 13:22:34,075 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 19936\n",
      "2023-07-08 13:22:34,296 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19948 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=20000.jsonl\n",
      "2023-07-08 13:22:34,308 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 39884\n",
      "2023-07-08 13:22:34,460 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19984 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl\n",
      "2023-07-08 13:22:34,472 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 59868\n",
      "2023-07-08 13:22:39,129 - \u001b[1;32mINFO\u001b[1;0m - Loaded 518822 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_metadata_Seq2Seq(t5-small)_200_1_20230708_120532.jsonl\n",
      "2023-07-08 13:22:39,425 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 578690\n",
      "2023-07-08 13:22:39,425 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\n",
      "2023-07-08 13:22:44,868 - \u001b[1;32mINFO\u001b[1;0m - Loaded 677694 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\n",
      "2023-07-08 13:22:45,560 - \u001b[1;32mINFO\u001b[1;0m - Found 578718 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\n",
      "2023-07-08 13:22:45,600 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 578718/578718 [01:20<00:00, 7176.75it/s]\n",
      "2023-07-08 13:24:06,239 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 578718/578718 [00:01<00:00, 335179.39it/s]\n",
      "2023-07-08 13:24:09,756 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-07-08 13:24:09,757 - \u001b[1;32mINFO\u001b[1;0m - First fact: A BENIGN CALCIFICATION IN LUNG OR RIB, OR VESSEL, EITHER ON END OR CROSSING in the right lower lung\n",
      "2023-07-08 13:24:09,757 - \u001b[1;32mINFO\u001b[1;0m - Last fact: right\n",
      "2023-07-08 13:24:09,980 - \u001b[1;33mWARNING\u001b[1;0m - Requested 1000000 facts but only 578718 are available. Using 578718 instead.\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 28\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 1. distal location of Swan Ganz catheter\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 4. continued opacification of the right hemidiaphragm\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 7. comparison with chest radiographs at :\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 10. infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection suggestive of infection\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 13. suggestion that only a short segment of the right pleural drain is intrathoracic\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 16. new pulmonary parenchymal infiltrate in the right upper lobe area has increased in size\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 19. repeat chest radiographs (PA and lateral),\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 22. costophrenic angles particularly on the right\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 25. favoring aspiration over infectious pneumonia\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - 28. unchanged sternal wires suggesting a sternal wires suggesting a sternal wires suggesting a sternal wires suggesting a sternal wires suggesting a sternal wires suggesting a sternal wires suggesting a sternal wires suggesting a sternal wires\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230708_132410.jsonl\n",
      "2023-07-08 13:24:10,966 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230708_132410.jsonl\n",
      "2023-07-08 13:24:11,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-08 13:24:11,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-07-08 13:24:14,699 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230708_132410.jsonl\n",
      "2023-07-08 13:24:14,704 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230708_132410.jsonl\n",
      "2023-07-08 13:24:14,708 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-07-08 13:24:14,709 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 28 of 28 API responses.\n",
      "                    0 of 28 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_metadata_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49843061).jsonl\" \\\n",
    "    --preprocessed_facts_to_skip_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=20000.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_metadata_Seq2Seq(t5-small)_200_1_20230708_120532.jsonl\" \\\n",
    "    --offset 0 \\\n",
    "    --num_facts 1000000 \\\n",
    "    --sample_facts_uniformly \\\n",
    "    --max_requests_per_minute 3300 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffcc706e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 13:02:13,292 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19964 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\n",
      "2023-07-12 13:02:13,445 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19964 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\n",
      "2023-07-12 13:02:13,461 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 19964\n",
      "2023-07-12 13:02:13,701 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19948 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=20000.jsonl\n",
      "2023-07-12 13:02:13,716 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 39912\n",
      "2023-07-12 13:02:13,883 - \u001b[1;32mINFO\u001b[1;0m - Loaded 19984 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl\n",
      "2023-07-12 13:02:13,898 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 59896\n",
      "2023-07-12 13:02:19,148 - \u001b[1;32mINFO\u001b[1;0m - Loaded 518822 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_metadata_Seq2Seq(t5-small)_200_1_20230708_120532.jsonl\n",
      "2023-07-12 13:02:19,488 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 578718\n",
      "2023-07-12 13:02:19,488 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49840759).jsonl\n",
      "2023-07-12 13:02:34,233 - \u001b[1;32mINFO\u001b[1;0m - Loaded 677694 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49840759).jsonl\n",
      "2023-07-12 13:02:35,065 - \u001b[1;32mINFO\u001b[1;0m - Found 578715 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49840759).jsonl\n",
      "2023-07-12 13:02:35,112 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 578715/578715 [01:32<00:00, 6237.88it/s]\n",
      "2023-07-12 13:04:07,888 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 578715/578715 [00:02<00:00, 274679.95it/s]\n",
      "2023-07-12 13:04:12,211 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-07-12 13:04:12,211 - \u001b[1;32mINFO\u001b[1;0m - First fact: A BENIGN CALCIFICATION IN LUNG OR RIB, OR VESSEL, EITHER ON END OR CROSSING in the right lower lung\n",
      "2023-07-12 13:04:12,211 - \u001b[1;32mINFO\u001b[1;0m - Last fact: right\n",
      "2023-07-12 13:04:12,452 - \u001b[1;33mWARNING\u001b[1;0m - Requested 1000000 facts but only 578715 are available. Using 578715 instead.\n",
      "2023-07-12 13:04:12,828 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 16\n",
      "2023-07-12 13:04:12,828 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-07-12 13:04:12,828 - \u001b[1;32mINFO\u001b[1;0m - 1. fluoro spot views obtained after radiographs\n",
      "2023-07-12 13:04:12,828 - \u001b[1;32mINFO\u001b[1;0m - 2. bibasal consolidations at a similar if not more pronounced for infectious process superimposed on traumatic injury\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 4. stomach containing most if not all\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 6. frontal view of the chest compared to CTA chest x-ray\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 7. lateral view of the chest compared to CTA x-ray\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 9. distal end of the diaphragm into the stomach\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 11. multifocal patchy ill-defined mid and lower lung opacities in the\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 12. slight interval improvement in the widespread parenchymal opacities right lower lung\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 14. increased degree of\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - 16. region of consolidation adjacent to\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230712_130412.jsonl\n",
      "2023-07-12 13:04:12,829 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230712_130412.jsonl\n",
      "2023-07-12 13:04:13,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-12 13:04:16,959 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230712_130412.jsonl\n",
      "2023-07-12 13:04:16,963 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230712_130412.jsonl\n",
      "2023-07-12 13:04:16,965 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 7 fields:\\n\\n1. \\\"anatomi...tioned?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 667, \"completion_tokens\": 32, \"total_tokens\": 699}}, {\"fact\": \"increased degree of\"}] for fact \"increased degree of\": GPT is acting weird: I'm sorry, but I need more information about the medical fact you provided. Could you please provide the complete sentence or context in which the observation is mentioned?\n",
      "2023-07-12 13:04:16,966 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-07-12 13:04:16,966 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 15 of 16 API responses.\n",
      "                    1 of 16 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_metadata_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(58655550,49840759).jsonl\" \\\n",
    "    --preprocessed_facts_to_skip_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=20000.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_metadata_Seq2Seq(t5-small)_200_1_20230708_120532.jsonl\" \\\n",
    "    --offset 0 \\\n",
    "    --num_facts 1000000 \\\n",
    "    --max_requests_per_minute 3300 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13de3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gpt-3.5-turbo-0301_parsed_sentences.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__v2.jsonl\r\n",
      "'gpt-3.5-turbo-0613_parsed_facts__v2_offset=20000.jsonl'\r\n",
      "'gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl'\r\n",
      " gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\r\n",
      "'gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl'\r\n",
      " gpt-3.5-turbo_parsed_backgrounds.jsonl\r\n",
      " gpt-3.5-turbo_parsed_reports__backup.jsonl\r\n",
      " gpt-3.5-turbo_parsed_reports.jsonl\r\n",
      "'gpt-3.5-turbo_parsed_reports(old).jsonl'\r\n",
      " gpt-3.5-turbo_parsed_sentences.jsonl\r\n",
      " gpt-4-0613_parsed_reports.jsonl\r\n",
      " gpt-4-0613_parsed_sentences.jsonl\r\n",
      " gpt-4-0613_parsed_sentences__v2.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f633648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdadc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2_offset=40000_uniform.jsonl')\n",
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__v2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5702acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0487aa13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'fact': 'lateral view of the chest compared to CTA x-ray'},\n",
       "  'parsed_response': {'anatomical location': '',\n",
       "   'detailed observation': 'lateral view of the chest compared to CTA x-ray',\n",
       "   'short observation': 'lateral view of the chest compared to CTA x-ray',\n",
       "   'category': 'technical assessment',\n",
       "   'health status': 'unknown',\n",
       "   'prev_study_comparison?': 'yes',\n",
       "   'comparison status': 'resolved'}},\n",
       " {'metadata': {'fact': 'slight interval improvement in the widespread parenchymal opacities right lower lung'},\n",
       "  'parsed_response': {'anatomical location': 'right lower lung',\n",
       "   'detailed observation': 'slight interval improvement in the widespread parenchymal opacities',\n",
       "   'short observation': 'improvement in parenchymal opacities',\n",
       "   'category': 'anatomical finding',\n",
       "   'health status': 'abnormal',\n",
       "   'prev_study_comparison?': 'yes',\n",
       "   'comparison status': 'improved'}},\n",
       " {'metadata': {'fact': 'frontal view of the chest compared to CTA chest x-ray'},\n",
       "  'parsed_response': {'anatomical location': '',\n",
       "   'detailed observation': 'frontal view of the chest compared to CTA chest x-ray',\n",
       "   'short observation': 'frontal view of the chest',\n",
       "   'category': 'technical assessment',\n",
       "   'health status': 'unknown',\n",
       "   'prev_study_comparison?': 'yes',\n",
       "   'comparison status': 'resolved'}},\n",
       " {'metadata': {'fact': 'bibasal consolidations at a similar if not more pronounced for infectious process superimposed on traumatic injury'},\n",
       "  'parsed_response': {'anatomical location': 'bibasal',\n",
       "   'detailed observation': 'consolidations at a similar if not more pronounced for infectious process superimposed on traumatic injury',\n",
       "   'short observation': 'consolidations',\n",
       "   'category': 'anatomical finding',\n",
       "   'health status': 'abnormal',\n",
       "   'prev_study_comparison?': 'no',\n",
       "   'comparison status': ''}},\n",
       " {'metadata': {'fact': 'indeterminate whether cardiomegaly is due to pericardial effusion'},\n",
       "  'parsed_response': {'anatomical location': '',\n",
       "   'detailed observation': 'indeterminate whether cardiomegaly is due to pericardial effusion',\n",
       "   'short observation': 'indeterminate cardiomegaly',\n",
       "   'category': 'anatomical finding',\n",
       "   'health status': 'ambiguous',\n",
       "   'prev_study_comparison?': 'no',\n",
       "   'comparison status': ''}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
