{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525b6006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:34:19,723 - \u001b[1;32mINFO\u001b[1;0m - Loaded 2 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\n",
      "2023-06-27 17:34:19,723 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 17:34:26,337 - \u001b[1;32mINFO\u001b[1;0m - Loaded 849523 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 17:34:27,483 - \u001b[1;32mINFO\u001b[1;0m - Found 414580 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 17:34:27,516 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 414580/414580 [00:50<00:00, 8252.33it/s]\n",
      "2023-06-27 17:35:17,755 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 414580/414580 [00:00<00:00, 433276.37it/s]\n",
      "2023-06-27 17:35:19,747 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-06-27 17:35:19,747 - \u001b[1;32mINFO\u001b[1;0m - First fact: Mediastinal bulgary bulgarian mediastinal bulgarian mediastinal bulgarian hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-27 17:35:19,747 - \u001b[1;32mINFO\u001b[1;0m - Last fact: Right\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 1. Tarda former of cleidocranial dysostosis\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 1667. Left pleural drain crossing left chest lateromedially to the apex\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 3333. Cardiac dextroposition\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 5000. Midclavicle fracture\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 6666. Crackles halfway up the right base\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 8332. Cyberknife therapy\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 9999. New radio-density in the left upper quadrant\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 11665. PICC in mid-to-proximal forearm\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 13331. Clearness of the left clavicle of shoulder imaging\n",
      "2023-06-27 17:35:19,887 - \u001b[1;32mINFO\u001b[1;0m - 14998. Acceptation in fluid\n",
      "2023-06-27 17:35:19,958 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230627_173519.jsonl\n",
      "2023-06-27 17:35:19,959 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_173519.jsonl\n",
      "2023-06-27 17:35:20,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-27 17:35:20,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-06-27 17:35:20,759 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-06-27 17:35:20,886 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-06-27 17:35:21,005 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-06-27 17:35:21,063 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-06-27 17:35:25,143 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-06-27 17:35:35,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #140\n",
      "2023-06-27 17:35:46,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #160\n",
      "2023-06-27 17:35:51,736 - \u001b[1;33mWARNING\u001b[1;0m - Request 29 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c53df6b339bab63bcf4e754d4cf978f2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:51,811 - \u001b[1;33mWARNING\u001b[1;0m - Request 54 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0e0fa532a2b560653b26bc5b29a2e3ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:51,820 - \u001b[1;33mWARNING\u001b[1;0m - Request 3 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2dc6ed3586ea620a30e954b0e2131de8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:51,887 - \u001b[1;33mWARNING\u001b[1;0m - Request 43 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99fa991ea6e1f2fbfba5bc31d8293533 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:51,906 - \u001b[1;33mWARNING\u001b[1;0m - Request 66 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf70f67e3a09c8caefa90abbb84ea57c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:51,951 - \u001b[1;33mWARNING\u001b[1;0m - Request 21 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5ed32467059329237b836475cd56d724 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:51,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 78 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 960f2cc2f5a0edf1cc663f69d5b70160 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:52,041 - \u001b[1;33mWARNING\u001b[1;0m - Request 64 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b11b35c12326b15f7f0ccabe2876b651 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:35:57,103 - \u001b[1;32mINFO\u001b[1;0m - Starting request #172\n",
      "2023-06-27 17:36:07,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #192\n",
      "2023-06-27 17:36:18,393 - \u001b[1;32mINFO\u001b[1;0m - Starting request #212\n",
      "2023-06-27 17:36:29,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #232\n",
      "2023-06-27 17:36:39,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #252\n",
      "2023-06-27 17:36:40,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 196 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d41cad7e9327f157040309c5d1b0ce24 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:36:50,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #271\n",
      "2023-06-27 17:36:58,820 - \u001b[1;33mWARNING\u001b[1;0m - Request 231 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c039298848a4823b2b7fd2dc689e7e9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:37:01,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #290\n",
      "2023-06-27 17:37:11,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #310\n",
      "2023-06-27 17:37:18,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 266 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 22308df43987af9f2aa87a758854f246 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:37:20,899 - \u001b[1;33mWARNING\u001b[1;0m - Request 271 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 55fb0cab7a55672c8614d8b997e8f8ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:37:22,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #328\n",
      "2023-06-27 17:37:22,775 - \u001b[1;33mWARNING\u001b[1;0m - Request 275 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2410cd8425b37677a954f406155c0955 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:37:32,992 - \u001b[1;32mINFO\u001b[1;0m - Starting request #347\n",
      "2023-06-27 17:37:43,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #367\n",
      "2023-06-27 17:37:53,738 - \u001b[1;33mWARNING\u001b[1;0m - Request 275 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c12f322745565743744113e892250676 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:37:54,318 - \u001b[1;32mINFO\u001b[1;0m - Starting request #275\n",
      "2023-06-27 17:38:04,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #406\n",
      "2023-06-27 17:38:13,970 - \u001b[1;33mWARNING\u001b[1;0m - Request 367 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2b3128fd2527be71867cd260f3785c6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:38:15,648 - \u001b[1;32mINFO\u001b[1;0m - Starting request #425\n",
      "2023-06-27 17:38:26,283 - \u001b[1;32mINFO\u001b[1;0m - Starting request #445\n",
      "2023-06-27 17:38:36,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #465\n",
      "2023-06-27 17:38:40,685 - \u001b[1;33mWARNING\u001b[1;0m - Request 416 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f63c2c2ef81c72deefd0222e3bb9a141 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:38:47,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #484\n",
      "2023-06-27 17:38:48,694 - \u001b[1;33mWARNING\u001b[1;0m - Request 430 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 288ae99760648a8041e1d83593cc3d25 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:38:58,268 - \u001b[1;32mINFO\u001b[1;0m - Starting request #503\n",
      "2023-06-27 17:39:08,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #523\n",
      "2023-06-27 17:39:19,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #543\n",
      "2023-06-27 17:39:30,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #563\n",
      "2023-06-27 17:39:31,764 - \u001b[1;33mWARNING\u001b[1;0m - Request 509 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42b18e055feeb6a0fb089bb9f0b37031 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:39:34,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 514 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 635bb970bdf41f2039e60fe5d7d7e4bb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:39:40,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #581\n",
      "2023-06-27 17:39:42,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 529 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 07613e28f5274b76ae077b9f15b0b8fb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:39:45,688 - \u001b[1;33mWARNING\u001b[1;0m - Request 535 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 17459f73819c0347f87ffc1e4b70b8bc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:39:46,179 - \u001b[1;33mWARNING\u001b[1;0m - Request 536 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 08d399178ec1d84bc2d1117895d7021d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:39:49,885 - \u001b[1;33mWARNING\u001b[1;0m - Request 543 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16924c8097e1122d2cabb0fb72fd49f9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:39:51,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #597\n",
      "2023-06-27 17:40:02,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #617\n",
      "2023-06-27 17:40:12,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #637\n",
      "2023-06-27 17:40:23,568 - \u001b[1;32mINFO\u001b[1;0m - Starting request #657\n",
      "2023-06-27 17:40:24,141 - \u001b[1;33mWARNING\u001b[1;0m - Request 601 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 30f9233ffefe8a0d986f658394c0296e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:40:34,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #676\n",
      "2023-06-27 17:40:34,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 137 failed with Exception \n",
      "2023-06-27 17:40:44,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #695\n",
      "2023-06-27 17:40:55,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #715\n",
      "2023-06-27 17:41:06,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #735\n",
      "2023-06-27 17:41:09,303 - \u001b[1;33mWARNING\u001b[1;0m - Request 684 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40478e54b279b73aa3c1d9697aca28cc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:41:16,851 - \u001b[1;32mINFO\u001b[1;0m - Starting request #754\n",
      "2023-06-27 17:41:20,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 705 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2d15ef3e6d6002c6feb5a3a7ed491484 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:41:25,308 - \u001b[1;33mWARNING\u001b[1;0m - Request 714 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cea0c2dc97b7f7eae6609294381f5ea6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:41:25,837 - \u001b[1;33mWARNING\u001b[1;0m - Request 715 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8bdd5f21a1762d7487b9471f14f60de6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:41:27,522 - \u001b[1;32mINFO\u001b[1;0m - Starting request #771\n",
      "2023-06-27 17:41:29,590 - \u001b[1;33mWARNING\u001b[1;0m - Request 722 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b502dbc072660693c9b418920f1bfea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:41:38,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #790\n",
      "2023-06-27 17:41:44,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 748 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03962770188fe8fa31517cb181a47ea7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:41:48,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #809\n",
      "2023-06-27 17:41:59,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #829\n",
      "2023-06-27 17:42:03,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 781 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f38497990b1354f07f4238d8bcc27dc0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:09,625 - \u001b[1;33mWARNING\u001b[1;0m - Request 792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6141c8342b6553ead2f2c50ca669db8e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:10,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #848\n",
      "2023-06-27 17:42:15,453 - \u001b[1;33mWARNING\u001b[1;0m - Request 802 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0e3b5403ad619430ec49cd8ff3ae8b7b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:20,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 812 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 163fbd044f09130fb4a3337058edf163 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:20,796 - \u001b[1;32mINFO\u001b[1;0m - Starting request #866\n",
      "2023-06-27 17:42:25,056 - \u001b[1;33mWARNING\u001b[1;0m - Request 820 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05eb319824d17895268ec765e64d262c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:31,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #884\n",
      "2023-06-27 17:42:32,488 - \u001b[1;33mWARNING\u001b[1;0m - Request 834 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8aa2d94df47984e24012d3843dff4fa9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:33,145 - \u001b[1;33mWARNING\u001b[1;0m - Request 833 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3429f7d2ac8782df8152d63c7cc84011 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:35,167 - \u001b[1;33mWARNING\u001b[1;0m - Request 781 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7bf938787688ba9696e3f0f246bef073 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:42:42,083 - \u001b[1;32mINFO\u001b[1;0m - Starting request #901\n",
      "2023-06-27 17:42:52,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #921\n",
      "2023-06-27 17:43:03,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #941\n",
      "2023-06-27 17:43:14,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #961\n",
      "2023-06-27 17:43:18,713 - \u001b[1;33mWARNING\u001b[1;0m - Request 912 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 93d42a4f06de970cd9e266ab0356d571 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:43:24,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #980\n",
      "2023-06-27 17:43:34,770 - \u001b[1;33mWARNING\u001b[1;0m - Request 943 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b63f68e441d25d53e05e879871a485d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:43:35,363 - \u001b[1;32mINFO\u001b[1;0m - Starting request #943\n",
      "2023-06-27 17:43:46,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1019\n",
      "2023-06-27 17:43:52,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 491 failed with Exception \n",
      "2023-06-27 17:43:56,689 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1038\n",
      "2023-06-27 17:43:59,286 - \u001b[1;33mWARNING\u001b[1;0m - Request 988 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5411f26c32e13446bcb5cc5d9f13aed in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:44:03,007 - \u001b[1;33mWARNING\u001b[1;0m - Request 995 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2024e53b3e780f727c643a99eea7adf0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:44:05,669 - \u001b[1;33mWARNING\u001b[1;0m - Request 943 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f33fbf117fd9a66c2f0983178c36b1f7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:44:07,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1055\n",
      "2023-06-27 17:44:17,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1075\n",
      "2023-06-27 17:44:28,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1095\n",
      "2023-06-27 17:44:30,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 988 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 64dd6da19d8c4c5aec634193f40003a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:44:39,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1114\n",
      "2023-06-27 17:44:49,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1134\n",
      "2023-06-27 17:44:54,147 - \u001b[1;33mWARNING\u001b[1;0m - Request 1086 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b76c908af7bd88926873a9937d40a636 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:45:00,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1153\n",
      "2023-06-27 17:45:08,586 - \u001b[1;33mWARNING\u001b[1;0m - Request 1112 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 543fcdf7a178033d1a04235b6ff0b50f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:45:11,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:45:16,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 1126 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7611d7f8a53ba306ad84145488312e99 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:45:21,908 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1191\n",
      "2023-06-27 17:45:32,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1211\n",
      "2023-06-27 17:45:43,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1231\n",
      "2023-06-27 17:45:53,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1251\n",
      "2023-06-27 17:46:02,868 - \u001b[1;33mWARNING\u001b[1;0m - Request 1211 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ed600c15fb5ca942a161e5492aa22140 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:46:04,609 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1270\n",
      "2023-06-27 17:46:15,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1290\n",
      "2023-06-27 17:46:25,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1310\n",
      "2023-06-27 17:46:36,588 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1330\n",
      "2023-06-27 17:46:43,535 - \u001b[1;33mWARNING\u001b[1;0m - Request 1286 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f157cb7ac98851d6d81845f48d84174d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:46:47,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1349\n",
      "2023-06-27 17:46:54,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 1307 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 156390451cde551e45f8bfc3f0b994fe in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:46:57,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1368\n",
      "2023-06-27 17:47:08,566 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1388\n",
      "2023-06-27 17:47:19,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1408\n",
      "2023-06-27 17:47:29,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 1366 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ec34bb84ee50040f9700075c663b6c83 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:47:29,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1366\n",
      "2023-06-27 17:47:40,584 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1447\n",
      "2023-06-27 17:47:47,946 - \u001b[1;33mWARNING\u001b[1;0m - Request 1405 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1184ad02f91f6a216fe9b485ca6077f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:47:51,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1466\n",
      "2023-06-27 17:47:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 928 failed with Exception \n",
      "2023-06-27 17:48:01,930 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1485\n",
      "2023-06-27 17:48:10,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 954 failed with Exception \n",
      "2023-06-27 17:48:12,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1504\n",
      "2023-06-27 17:48:16,203 - \u001b[1;33mWARNING\u001b[1;0m - Request 1457 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d5575b389a4f72436c0f12811a27c313 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:48:21,529 - \u001b[1;33mWARNING\u001b[1;0m - Request 1466 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2567664cf8208e37cb605117c03d7d66 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:48:21,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 1463 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a91638135e97f28da41bf008f4bf734 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:48:23,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1521\n",
      "2023-06-27 17:48:25,807 - \u001b[1;33mWARNING\u001b[1;0m - Request 1474 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d45e58d2e21a28a74d200f10de3bb4af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:48:32,751 - \u001b[1;33mWARNING\u001b[1;0m - Request 1486 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1c5fea14d71bc3aa38096e732198667 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:48:33,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1539\n",
      "2023-06-27 17:48:44,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1559\n",
      "2023-06-27 17:48:55,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1579\n",
      "2023-06-27 17:49:05,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1599\n",
      "2023-06-27 17:49:08,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1057 failed with Exception \n",
      "2023-06-27 17:49:12,189 - \u001b[1;33mWARNING\u001b[1;0m - Request 1554 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a281df7ad05271124cd04aca3543f6ed in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:49:16,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1617\n",
      "2023-06-27 17:49:27,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1637\n",
      "2023-06-27 17:49:28,194 - \u001b[1;33mWARNING\u001b[1;0m - Request 1584 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 38dcdf5ccfe7fb17b386a0dc36027849 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:49:37,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1656\n",
      "2023-06-27 17:49:48,550 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1676\n",
      "2023-06-27 17:49:59,221 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1696\n",
      "2023-06-27 17:49:59,650 - \u001b[1;33mWARNING\u001b[1;0m - Request 1640 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ab1a2810841741e5d2992a9fe22044e7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:50:09,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1715\n",
      "2023-06-27 17:50:20,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1735\n",
      "2023-06-27 17:50:22,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1191 failed with Exception \n",
      "2023-06-27 17:50:26,400 - \u001b[1;33mWARNING\u001b[1;0m - Request 1690 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b6fa3073c8eaadec41ac05d7d4951da in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:50:31,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1753\n",
      "2023-06-27 17:50:41,886 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1773\n",
      "2023-06-27 17:50:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1230 failed with Exception \n",
      "2023-06-27 17:50:52,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1792\n",
      "2023-06-27 17:51:00,977 - \u001b[1;33mWARNING\u001b[1;0m - Request 1752 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b344c8f08c7887e3051330c5ab53e603 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:01,585 - \u001b[1;33mWARNING\u001b[1;0m - Request 1753 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1a462df45a565b99e75ea2eb8fdee55 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:03,200 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1810\n",
      "2023-06-27 17:51:13,846 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1830\n",
      "2023-06-27 17:51:17,535 - \u001b[1;33mWARNING\u001b[1;0m - Request 1782 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 118561ff74295d74cc7f759756ff4b00 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:22,867 - \u001b[1;33mWARNING\u001b[1;0m - Request 1792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8478eafdabe2fa7490530bee19a06015 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:24,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1848\n",
      "2023-06-27 17:51:28,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 1801 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 426b6f22559cc37f5c017af9313b908b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:31,403 - \u001b[1;33mWARNING\u001b[1;0m - Request 1808 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50105f374353048d11495066cb4035d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:35,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1866\n",
      "2023-06-27 17:51:37,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 1729 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4f1d2bb23218da3aaca5ced42cb6efce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:37,978 - \u001b[1;33mWARNING\u001b[1;0m - Request 1711 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c00c6d1532bbc306dbe70b85b935844 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:42,563 - \u001b[1;33mWARNING\u001b[1;0m - Request 1827 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03bf14f8b025a38b15acdeeaef1a2443 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:44,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 1831 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 67bbcd10d674a9585dd345cc6482e46b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:45,806 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1882\n",
      "2023-06-27 17:51:55,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 1849 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0981adec4dcf4fee7b1e54a81da6adc8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:56,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1901\n",
      "2023-06-27 17:51:56,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 1852 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 58c73e3d6ba20b5ac82758bb161885c5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:07,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1920\n",
      "2023-06-27 17:52:17,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1940\n",
      "2023-06-27 17:52:28,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1960\n",
      "2023-06-27 17:52:34,833 - \u001b[1;33mWARNING\u001b[1;0m - Request 1915 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 51b13c08ca0ec5e1bfb7765a0d2cf510 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:39,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1979\n",
      "2023-06-27 17:52:41,199 - \u001b[1;33mWARNING\u001b[1;0m - Request 1921 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 891399ea58e7ec62471c0c8d57944973 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:43,314 - \u001b[1;33mWARNING\u001b[1;0m - Request 1931 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e0591090d7c32f583345d30fc3c3dfba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:49,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1997\n",
      "2023-06-27 17:53:00,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2017\n",
      "2023-06-27 17:53:11,093 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2037\n",
      "2023-06-27 17:53:15,973 - \u001b[1;33mWARNING\u001b[1;0m - Request 1988 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0dd26f0eab2584efd82169de3dcef49c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:53:21,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2056\n",
      "2023-06-27 17:53:32,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2076\n",
      "2023-06-27 17:53:36,646 - \u001b[1;33mWARNING\u001b[1;0m - Request 2028 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1d353f6ecefba6ab6f6a4b2d25fd6b1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:53:43,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2095\n",
      "2023-06-27 17:53:53,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2115\n",
      "2023-06-27 17:54:04,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:54:15,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2155\n",
      "2023-06-27 17:54:16,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 2112 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 17:54:25,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2174\n",
      "2023-06-27 17:54:36,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2194\n",
      "2023-06-27 17:54:39,999 - \u001b[1;33mWARNING\u001b[1;0m - Request 2145 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4cb202af5c2b2c61f4969598d3fc4b0f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:54:46,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2213\n",
      "2023-06-27 17:54:51,838 - \u001b[1;33mWARNING\u001b[1;0m - Request 2166 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2b1822e831418ae4edcd1a3db66df792 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:54:57,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2232\n",
      "2023-06-27 17:55:08,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2252\n",
      "2023-06-27 17:55:17,825 - \u001b[1;33mWARNING\u001b[1;0m - Request 2214 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1368bc2a4828d092d95440bd8d384f2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:18,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2271\n",
      "2023-06-27 17:55:22,086 - \u001b[1;33mWARNING\u001b[1;0m - Request 2222 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b1839f2e7038db910ae912a4322f0a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:29,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2290\n",
      "2023-06-27 17:55:33,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 2242 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b9f83649caf73fa3f265265835e0ed65 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:33,814 - \u001b[1;33mWARNING\u001b[1;0m - Request 2243 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8eb30b4a8f4d42f7c23fd0dd9fd8cf05 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:40,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2308\n",
      "2023-06-27 17:55:45,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 2265 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 86350b5103b4f90f97646a02f81f9774 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:50,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2327\n",
      "2023-06-27 17:55:58,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 2288 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13d70b2d616b43cc928c8df96dc683a3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:59,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 2290 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4893be0a2f68cea10b1dee6472761f48 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:01,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2345\n",
      "2023-06-27 17:56:05,803 - \u001b[1;33mWARNING\u001b[1;0m - Request 2299 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 190a627dcf59887543d34eda5aca73ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:12,262 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2364\n",
      "2023-06-27 17:56:14,313 - \u001b[1;33mWARNING\u001b[1;0m - Request 2315 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c157a63ca947d8eb63931f0673ee173e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:20,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1840 failed with Exception \n",
      "2023-06-27 17:56:22,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2382\n",
      "2023-06-27 17:56:25,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 2335 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6334cab89e04a7fa2434cb029405ccad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:27,102 - \u001b[1;33mWARNING\u001b[1;0m - Request 2338 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1cfb7fd468b9abaf50d5668c3860dc2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:33,609 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2400\n",
      "2023-06-27 17:56:43,153 - \u001b[1;33mWARNING\u001b[1;0m - Request 2365 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bbc65355750dc1703ef3363b4c1029ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:44,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2419\n",
      "2023-06-27 17:56:49,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 2376 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2419e23eb9ce3238b3cfc0efbeacf2c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:50,562 - \u001b[1;33mWARNING\u001b[1;0m - Request 2378 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5ef3e7f703f07b3584f70feea07d0ef3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:54,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2437\n",
      "2023-06-27 17:57:05,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2457\n",
      "2023-06-27 17:57:10,824 - \u001b[1;33mWARNING\u001b[1;0m - Request 2413 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f93263af2b125078afcd3cdc9b6f436 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:16,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:57:21,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 2378 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a6cce9e39d49b56b5241507fb29e461 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:26,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2495\n",
      "2023-06-27 17:57:37,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2515\n",
      "2023-06-27 17:57:48,167 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2535\n",
      "2023-06-27 17:57:58,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2555\n",
      "2023-06-27 17:58:09,471 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2575\n",
      "2023-06-27 17:58:14,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 2527 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd798d70453b53efc97bc456a7bda807 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:19,580 - \u001b[1;33mWARNING\u001b[1;0m - Request 2537 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 87006b267d9e0bd5d265fe06fc404b68 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:20,118 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2537\n",
      "2023-06-27 17:58:30,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2613\n",
      "2023-06-27 17:58:41,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2633\n",
      "2023-06-27 17:58:52,103 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2653\n",
      "2023-06-27 17:58:54,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 2601 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 890607f7a9daba026985de1bd8ec71e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:02,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2672\n",
      "2023-06-27 17:59:07,539 - \u001b[1;33mWARNING\u001b[1;0m - Request 2625 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2609f56305e4587af704e180c44b4fab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:13,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2691\n",
      "2023-06-27 17:59:15,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2640 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db335e8c9164ead531d789ab19ea03c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:16,613 - \u001b[1;33mWARNING\u001b[1;0m - Request 2641 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7b134db485013dad98f07924d1cdcdd6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:23,469 - \u001b[1;33mWARNING\u001b[1;0m - Request 2655 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f5fb5570a3a62159fd6bcf8a7b06b65 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:24,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2655\n",
      "2023-06-27 17:59:34,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2728\n",
      "2023-06-27 17:59:45,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2748\n",
      "2023-06-27 17:59:56,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2768\n",
      "2023-06-27 18:00:01,917 - \u001b[1;33mWARNING\u001b[1;0m - Request 2722 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7d408ee59dfb837565fcc259a7898ecc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:05,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 2728 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f68da0008fb91497d93a2875040b2839 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:06,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2786\n",
      "2023-06-27 18:00:11,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 2257 failed with Exception \n",
      "2023-06-27 18:00:17,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2805\n",
      "2023-06-27 18:00:25,480 - \u001b[1;33mWARNING\u001b[1;0m - Request 2766 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1251120c72fe14c1deb90cdda60a049 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:27,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2824\n",
      "2023-06-27 18:00:28,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2287 failed with Exception \n",
      "2023-06-27 18:00:38,655 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2843\n",
      "2023-06-27 18:00:49,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2863\n",
      "2023-06-27 18:00:59,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2883\n",
      "2023-06-27 18:01:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2345 failed with Exception \n",
      "2023-06-27 18:01:09,007 - \u001b[1;33mWARNING\u001b[1;0m - Request 2843 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b37bf64ca02d2e9768a34e33c5628d3f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:10,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2901\n",
      "2023-06-27 18:01:18,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 2861 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID da401a3ad9e844122010b06dbca3294f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:21,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2920\n",
      "2023-06-27 18:01:29,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 2881 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7de444342159abc37deae4c80ab55d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:31,972 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2939\n",
      "2023-06-27 18:01:37,228 - \u001b[1;33mWARNING\u001b[1;0m - Request 2895 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 32542aa9dfaf62cd380ebfffc9dddf4b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:42,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2958\n",
      "2023-06-27 18:01:53,288 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2978\n",
      "2023-06-27 18:02:03,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2998\n",
      "2023-06-27 18:02:10,467 - \u001b[1;33mWARNING\u001b[1;0m - Request 2920 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aba8507122e240266e80da16179b0d69 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:02:14,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3017\n",
      "2023-06-27 18:02:25,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3037\n",
      "2023-06-27 18:02:26,803 - \u001b[1;33mWARNING\u001b[1;0m - Request 2984 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8006c84a589e5cf359524739dc91b6d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:02:28,376 - \u001b[1;33mWARNING\u001b[1;0m - Request 2987 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3e7ac492a0a8a940f6c508f683d6b3a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:02:35,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3055\n",
      "2023-06-27 18:02:44,103 - \u001b[1;33mWARNING\u001b[1;0m - Request 3015 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f66a84180779056a9951844b06113aa5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:02:46,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3074\n",
      "2023-06-27 18:02:47,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 3021 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ece84830f4b37e74b38c74042f074af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:02:57,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3093\n",
      "2023-06-27 18:02:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2553 failed with Exception \n",
      "2023-06-27 18:03:00,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 3044 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c49481e53d238de9a7067ee56b1ece09 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:07,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3111\n",
      "2023-06-27 18:03:18,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3131\n",
      "2023-06-27 18:03:29,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3151\n",
      "2023-06-27 18:03:32,279 - \u001b[1;33mWARNING\u001b[1;0m - Request 3100 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de184b5c1793ff6941ea83ab9ecf24f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:39,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3170\n",
      "2023-06-27 18:03:42,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 3119 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4f9842e9d0735ad79a01425941e47b47 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:50,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3189\n",
      "2023-06-27 18:03:51,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2650 failed with Exception \n",
      "2023-06-27 18:03:56,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 3145 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a58912e67736ce9a66cd3591d5345bd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:01,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3207\n",
      "2023-06-27 18:04:11,756 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3227\n",
      "2023-06-27 18:04:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2689 failed with Exception \n",
      "2023-06-27 18:04:20,218 - \u001b[1;33mWARNING\u001b[1;0m - Request 3188 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b9330a8c97e047e4ec1ebbc628aa9987 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:22,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3245\n",
      "2023-06-27 18:04:33,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3265\n",
      "2023-06-27 18:04:33,565 - \u001b[1;33mWARNING\u001b[1;0m - Request 3211 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f71f9653fcec76deeac8db54ebba501 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:36,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 3217 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75c0f1aca065eef00ebc2948ce6a8030 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:43,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3283\n",
      "2023-06-27 18:04:54,375 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3303\n",
      "2023-06-27 18:04:56,420 - \u001b[1;33mWARNING\u001b[1;0m - Request 3252 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9423262bd117c0e60405b91034dde7f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2773 failed with Exception \n",
      "2023-06-27 18:05:05,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3321\n",
      "2023-06-27 18:05:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2786 failed with Exception \n",
      "2023-06-27 18:05:10,876 - \u001b[1;33mWARNING\u001b[1;0m - Request 3277 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b14bb28d0b3b3e4ca74b04bf62c1efff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:14,536 - \u001b[1;33mWARNING\u001b[1;0m - Request 3284 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13825f0695d4b95f11d310b29e439b11 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:15,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3338\n",
      "2023-06-27 18:05:16,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 3288 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 536533515628f206e156fde35a86f78f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:17,236 - \u001b[1;33mWARNING\u001b[1;0m - Request 3289 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f9774add24c64ca0361ec1c5502a84a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:24,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2817 failed with Exception \n",
      "2023-06-27 18:05:26,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3355\n",
      "2023-06-27 18:05:31,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2829 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:05:35,327 - \u001b[1;33mWARNING\u001b[1;0m - Request 3321 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ccdb116b0babe5a788756337c4662aff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:36,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 3323 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4e91ac227259d96fb23f8f5528c3fe34 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:37,017 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3323\n",
      "2023-06-27 18:05:41,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 3277 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7fff5ba5dc2579e2ed0fe04d006ab02f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:43,852 - \u001b[1;33mWARNING\u001b[1;0m - Request 3335 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8072ba57a2fd4709a53316bd1d9204bd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:47,672 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3390\n",
      "2023-06-27 18:05:48,653 - \u001b[1;33mWARNING\u001b[1;0m - Request 3341 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3787ed36554f9452a90d16566ad524ac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:50,860 - \u001b[1;33mWARNING\u001b[1;0m - Request 3345 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e6e8b5b48c0d6b278b479fe0915daea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2866 failed with Exception \n",
      "2023-06-27 18:05:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2872 failed with Exception \n",
      "2023-06-27 18:05:58,333 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3406\n",
      "2023-06-27 18:06:08,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3426\n",
      "2023-06-27 18:06:13,703 - \u001b[1;33mWARNING\u001b[1;0m - Request 3383 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3d554ec99e0ed7bee1da0d7efdadbe6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:19,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3445\n",
      "2023-06-27 18:06:30,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3465\n",
      "2023-06-27 18:06:30,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 3410 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e62f91398bdc9370b9249678e75c2c6e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:31,455 - \u001b[1;33mWARNING\u001b[1;0m - Request 3411 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 548e9adb0b488c6ca1ed682f241bf037 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:39,808 - \u001b[1;33mWARNING\u001b[1;0m - Request 3427 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 93adf57ad33ff61148037872539e87bb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:40,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3482\n",
      "2023-06-27 18:06:48,883 - \u001b[1;33mWARNING\u001b[1;0m - Request 3443 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1e4f4f140c4de1c749e2661e0ebc1079 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:51,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3501\n",
      "2023-06-27 18:06:58,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 3460 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 730e623f266bfdb17926524b7cb5a25e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:02,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3520\n",
      "2023-06-27 18:07:08,079 - \u001b[1;33mWARNING\u001b[1;0m - Request 3477 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6d53e01078c5f4279dd1fa8020d41bc0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:12,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3539\n",
      "2023-06-27 18:07:18,717 - \u001b[1;33mWARNING\u001b[1;0m - Request 3496 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID afc9c6096b21003dd675b272bda03a3a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:23,586 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3558\n",
      "2023-06-27 18:07:29,387 - \u001b[1;33mWARNING\u001b[1;0m - Request 3460 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bfd7b141d01c6badb3abcaa968967ee7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:32,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3048 failed with Exception \n",
      "2023-06-27 18:07:34,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3576\n",
      "2023-06-27 18:07:35,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 3526 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1f1ddcfea4aa114405d8c79b9101ea3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:38,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 3531 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 12e065c4b48f511135ea76be70fd1665 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:44,910 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3594\n",
      "2023-06-27 18:07:55,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3614\n",
      "2023-06-27 18:08:06,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3634\n",
      "2023-06-27 18:08:16,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3654\n",
      "2023-06-27 18:08:17,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3129 failed with Exception \n",
      "2023-06-27 18:08:27,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:08:29,052 - \u001b[1;33mWARNING\u001b[1;0m - Request 3620 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e92925be33f36716d4ad39447cb6c2c2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:34,889 - \u001b[1;33mWARNING\u001b[1;0m - Request 3631 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c8da551e95935a5b6c8f966b6aba5ae9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:38,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3691\n",
      "2023-06-27 18:08:46,596 - \u001b[1;33mWARNING\u001b[1;0m - Request 3653 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8776e109274b5550f1c2eb1cc558ec6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:48,814 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3710\n",
      "2023-06-27 18:08:55,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 3669 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47755bf12abfaa45a6b2c685fdc0874c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:59,472 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3729\n",
      "2023-06-27 18:09:07,912 - \u001b[1;33mWARNING\u001b[1;0m - Request 3690 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5e337ea4081fd97435b95db33a723bd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:09:10,136 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3748\n",
      "2023-06-27 18:09:19,225 - \u001b[1;33mWARNING\u001b[1;0m - Request 3710 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a3c17fb94cca6a20a6ef838cb07e839b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:09:20,791 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3767\n",
      "2023-06-27 18:09:31,442 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3787\n",
      "2023-06-27 18:09:42,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3807\n",
      "2023-06-27 18:09:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3294 failed with Exception \n",
      "2023-06-27 18:09:52,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3826\n",
      "2023-06-27 18:09:53,817 - \u001b[1;33mWARNING\u001b[1;0m - Request 3772 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fe4001ef7f9ef1dafd9dc58bd6b360be in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:03,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3845\n",
      "2023-06-27 18:10:08,773 - \u001b[1;33mWARNING\u001b[1;0m - Request 3800 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 80e65afebd8633816c6365180affe5ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:14,005 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3864\n",
      "2023-06-27 18:10:16,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 3815 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 527708dcb9c4f0e47b19c35e5e3ca3e9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:18,913 - \u001b[1;33mWARNING\u001b[1;0m - Request 3819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13148f35e83797ff3a0b2603b47f3992 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:24,089 - \u001b[1;33mWARNING\u001b[1;0m - Request 3828 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 958cf296a307396095e6e6eb27aa8d6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:24,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3828\n",
      "2023-06-27 18:10:26,806 - \u001b[1;33mWARNING\u001b[1;0m - Request 3832 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ca80d56ff6d93a214f724020c71b05d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:28,373 - \u001b[1;33mWARNING\u001b[1;0m - Request 3835 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b7d4069115fb60c08305e388cc83ab01 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:35,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3899\n",
      "2023-06-27 18:10:40,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3378 failed with Exception \n",
      "2023-06-27 18:10:45,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3918\n",
      "2023-06-27 18:10:50,709 - \u001b[1;33mWARNING\u001b[1;0m - Request 3874 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 34c54024230658ffce69d9dd3effa677 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:56,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3937\n",
      "2023-06-27 18:11:07,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3957\n",
      "2023-06-27 18:11:13,227 - \u001b[1;33mWARNING\u001b[1;0m - Request 3912 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bf284abdec6055b214031ba2c914f94b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:14,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3383 failed with Exception \n",
      "2023-06-27 18:11:17,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3975\n",
      "2023-06-27 18:11:18,900 - \u001b[1;33mWARNING\u001b[1;0m - Request 3923 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0c067f12bfc624636a91df6f30e8238 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:23,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 3931 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1fbc5b3598cc8317e00a603f15e56e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:28,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3993\n",
      "2023-06-27 18:11:39,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:11:39,311 - \u001b[1;33mWARNING\u001b[1;0m - Request 3957 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d26ecb6a197578c66ff9fd877587eba0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:49,835 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4032\n",
      "2023-06-27 18:11:54,621 - \u001b[1;33mWARNING\u001b[1;0m - Request 3931 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eba950a6110a5d5ad847d458c22eb192 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:55,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3508 failed with Exception \n",
      "2023-06-27 18:11:57,353 - \u001b[1;33mWARNING\u001b[1;0m - Request 3990 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 43c56e26fe057778771c0373dc8278ac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:00,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4049\n",
      "2023-06-27 18:12:05,237 - \u001b[1;33mWARNING\u001b[1;0m - Request 4005 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50280bf72ec92de8d0f2b710ab1dab86 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:08,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 4012 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 94818f54b65f84decdc5222425563115 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:11,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4067\n",
      "2023-06-27 18:12:19,094 - \u001b[1;33mWARNING\u001b[1;0m - Request 4030 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 034a8df3235784c1e6ce5ac7445bb058 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:19,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3550 failed with Exception \n",
      "2023-06-27 18:12:20,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 4031 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0f718b402ccc98a603139e7870b10f1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:21,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4084\n",
      "2023-06-27 18:12:32,435 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4104\n",
      "2023-06-27 18:12:43,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4124\n",
      "2023-06-27 18:12:49,418 - \u001b[1;33mWARNING\u001b[1;0m - Request 4082 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 387b4d0da1e8984f9bf2ced0552ca526 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:53,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4143\n",
      "2023-06-27 18:12:55,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3613 failed with Exception \n",
      "2023-06-27 18:13:04,375 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4162\n",
      "2023-06-27 18:13:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3645 failed with Exception \n",
      "2023-06-27 18:13:15,019 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4181\n",
      "2023-06-27 18:13:25,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4201\n",
      "2023-06-27 18:13:32,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 4157 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ad1f7b0b11eba473b79abfd26157b081 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:36,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4220\n",
      "2023-06-27 18:13:36,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3687 failed with Exception \n",
      "2023-06-27 18:13:42,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3698 failed with Exception \n",
      "2023-06-27 18:13:46,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4238\n",
      "2023-06-27 18:13:51,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 4193 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 277c716eb3718c7432623b7361944264 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:54,353 - \u001b[1;33mWARNING\u001b[1;0m - Request 4198 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ef71be755dbb1d5ea860274ea595b632 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:55,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 4201 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62965bad082b33b72ed1a061e66eddfb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:57,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4255\n",
      "2023-06-27 18:14:03,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3735 failed with Exception \n",
      "2023-06-27 18:14:03,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 4215 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6729c43e27dff6af870d127b545db076 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:14:08,246 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4273\n",
      "2023-06-27 18:14:08,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 4223 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 00ade29e030525d36098ecc66d0646cb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:14:18,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4292\n",
      "2023-06-27 18:14:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3765 failed with Exception \n",
      "2023-06-27 18:14:26,311 - \u001b[1;33mWARNING\u001b[1;0m - Request 4253 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d35eeb8d94e0caee6f3b81d9b8c1423a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:14:27,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 4255 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 51d5386686e5a05cb3c433afe61c290a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:14:29,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4309\n",
      "2023-06-27 18:14:40,180 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4329\n",
      "2023-06-27 18:14:43,855 - \u001b[1;33mWARNING\u001b[1;0m - Request 4282 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5a451ef8424c38a0c41b2facc70905a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:14:50,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4348\n",
      "2023-06-27 18:15:01,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4368\n",
      "2023-06-27 18:15:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3847 failed with Exception \n",
      "2023-06-27 18:15:12,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4387\n",
      "2023-06-27 18:15:22,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4407\n",
      "2023-06-27 18:15:33,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4427\n",
      "2023-06-27 18:15:44,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4447\n",
      "2023-06-27 18:15:54,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4467\n",
      "2023-06-27 18:16:05,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4487\n",
      "2023-06-27 18:16:15,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4507\n",
      "2023-06-27 18:16:17,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 4453 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2a1f1f69e39efc2214d1f6b524e02258 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:16:26,584 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4526\n",
      "2023-06-27 18:16:37,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4546\n",
      "2023-06-27 18:16:47,860 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4566\n",
      "2023-06-27 18:16:53,169 - \u001b[1;33mWARNING\u001b[1;0m - Request 4519 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ea5c0a220bca11dfa4f06d7f13d0b0b2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:16:54,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 4522 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8679643d0d30611a31900fdd86bca8f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:16:57,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 4528 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a19780eb015b0d5329f40027b6f56b7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:16:58,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4528\n",
      "2023-06-27 18:16:59,521 - \u001b[1;33mWARNING\u001b[1;0m - Request 4531 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e68ba381299a2edfdfdf277100219c33 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:08,192 - \u001b[1;33mWARNING\u001b[1;0m - Request 4545 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID faebdaac3523d3617d42344e2fa408cb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:09,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4545\n",
      "2023-06-27 18:17:19,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4621\n",
      "2023-06-27 18:17:30,406 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4641\n",
      "2023-06-27 18:17:39,433 - \u001b[1;33mWARNING\u001b[1;0m - Request 4545 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 63314050aaee3fe9ac80be14eb522afb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:41,043 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4660\n",
      "2023-06-27 18:17:42,714 - \u001b[1;33mWARNING\u001b[1;0m - Request 4607 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b4f5b7f82ce4b62773bd5bbb04c4d1b2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:46,867 - \u001b[1;33mWARNING\u001b[1;0m - Request 4615 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0bacc6f81d06065d14b64093bb93a95e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:48,461 - \u001b[1;33mWARNING\u001b[1;0m - Request 4618 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de3cd8e13968c9b7a8eca62819ce449d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:51,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4677\n",
      "2023-06-27 18:17:58,818 - \u001b[1;33mWARNING\u001b[1;0m - Request 4637 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb23c9f622d2c774d6ab3afff2e3214d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:02,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4696\n",
      "2023-06-27 18:18:13,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4716\n",
      "2023-06-27 18:18:13,466 - \u001b[1;33mWARNING\u001b[1;0m - Request 4664 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1532e898dfd5a167a77469d0f9ce5459 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:13,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 4607 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d688e70fd12ffdab84985df9d8eb7456 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:19,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4188 failed with Exception \n",
      "2023-06-27 18:18:20,377 - \u001b[1;33mWARNING\u001b[1;0m - Request 4674 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f505043c21283ca63754731419e1f76e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:23,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4732\n",
      "2023-06-27 18:18:32,226 - \u001b[1;33mWARNING\u001b[1;0m - Request 4695 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0f5b40bdf3bdd3a9027ae5db94dc03a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:34,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4751\n",
      "2023-06-27 18:18:41,173 - \u001b[1;33mWARNING\u001b[1;0m - Request 4712 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2d99212c0149b39e34487508cac794b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:44,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4770\n",
      "2023-06-27 18:18:47,035 - \u001b[1;33mWARNING\u001b[1;0m - Request 4721 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 27a2790bd519234b853cd5d3d8ce467c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:18:55,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4789\n",
      "2023-06-27 18:19:02,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 4748 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff6982fb6671392db061bcabe611066a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:06,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4808\n",
      "2023-06-27 18:19:13,626 - \u001b[1;33mWARNING\u001b[1;0m - Request 4767 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6410a5804c7fdc2ee214d24e2658e5a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:15,958 - \u001b[1;33mWARNING\u001b[1;0m - Request 4771 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7635fba368abdc3fe5c0db1a5d913ac1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:16,611 - \u001b[1;33mWARNING\u001b[1;0m - Request 4772 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 08e5fd2250a5b4f9f43a4acfecf6c437 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:16,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4771\n",
      "2023-06-27 18:19:27,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4845\n",
      "2023-06-27 18:19:33,818 - \u001b[1;33mWARNING\u001b[1;0m - Request 4803 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a3b8bc78533214d75943b33d8d97ef10 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:38,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4864\n",
      "2023-06-27 18:19:41,782 - \u001b[1;33mWARNING\u001b[1;0m - Request 4818 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ffb5eebeebe0e8072a9087f5a12d4ad3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:42,316 - \u001b[1;33mWARNING\u001b[1;0m - Request 4819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e667e761e8a2d17ba8170109dd55ac04 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:48,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4882\n",
      "2023-06-27 18:19:49,274 - \u001b[1;33mWARNING\u001b[1;0m - Request 4829 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0381c7cc9583f56dfc9ffea89ca0a4ad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:59,349 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4901\n",
      "2023-06-27 18:20:06,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 4860 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a5f25e1ea2ec1eb5da97345ae0f19b38 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:09,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4920\n",
      "2023-06-27 18:20:20,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4940\n",
      "2023-06-27 18:20:25,997 - \u001b[1;33mWARNING\u001b[1;0m - Request 4894 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4f68208228187e342b582001644eb2b2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:29,143 - \u001b[1;33mWARNING\u001b[1;0m - Request 4900 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 81b44703cf21b7c3ddb8d48a7ab47502 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:31,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4958\n",
      "2023-06-27 18:20:41,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4978\n",
      "2023-06-27 18:20:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4457 failed with Exception \n",
      "2023-06-27 18:20:50,882 - \u001b[1;33mWARNING\u001b[1;0m - Request 4940 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 685c113440354e3975e9c78c3da0f79b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:52,476 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4996\n",
      "2023-06-27 18:21:03,103 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5016\n",
      "2023-06-27 18:21:07,872 - \u001b[1;33mWARNING\u001b[1;0m - Request 4970 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4a01f62084034816c5450c011181da1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:13,748 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5035\n",
      "2023-06-27 18:21:16,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 4986 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 143edb5bab62c5dcd6b287a4a3acfd4e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:21,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 4940 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e97df07f69ff2c89b8c271639d307489 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:24,377 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5053\n",
      "2023-06-27 18:21:28,145 - \u001b[1;33mWARNING\u001b[1;0m - Request 5006 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 214e79e8ecbfe6a49df9c90d9013c8e5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:33,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 5016 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 435de70d35e03a95aabdf1eea31d0d94 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:35,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5071\n",
      "2023-06-27 18:21:44,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 5035 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c785081109caaff2a80da02a8ca78e4c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:21:45,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5090\n",
      "2023-06-27 18:21:54,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 5053 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9acc572a8c4493d84ea89b3d060583a8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:56,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5109\n",
      "2023-06-27 18:21:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4580 failed with Exception \n",
      "2023-06-27 18:22:02,163 - \u001b[1;33mWARNING\u001b[1;0m - Request 5066 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f36d0a43574df527cb05302b89911b09 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:06,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5127\n",
      "2023-06-27 18:22:17,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5147\n",
      "2023-06-27 18:22:19,662 - \u001b[1;33mWARNING\u001b[1;0m - Request 5097 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3fd6e34359aa0bab8df6d7736bf09302 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:20,733 - \u001b[1;33mWARNING\u001b[1;0m - Request 5099 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f50a282f5672491dd73f01cfb34752b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:28,200 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5165\n",
      "2023-06-27 18:22:30,289 - \u001b[1;33mWARNING\u001b[1;0m - Request 5115 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8d17995244d86f33b86c87021b8c624c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:31,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 5118 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d9245e7b26e21b3729a60ef2a34b8d7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:38,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4656 failed with Exception \n",
      "2023-06-27 18:22:38,860 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5183\n",
      "2023-06-27 18:22:42,023 - \u001b[1;33mWARNING\u001b[1;0m - Request 5136 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dc8e52371883957ed3ea925dd932eba9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:49,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5201\n",
      "2023-06-27 18:22:56,145 - \u001b[1;33mWARNING\u001b[1;0m - Request 5156 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c484b2e523098bf0990337cab616957 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:00,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5220\n",
      "2023-06-27 18:23:10,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5240\n",
      "2023-06-27 18:23:19,837 - \u001b[1;33mWARNING\u001b[1;0m - Request 5201 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 88a61de6421c695533e54fa1b980255a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:21,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5259\n",
      "2023-06-27 18:23:32,066 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5279\n",
      "2023-06-27 18:23:42,702 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5299\n",
      "2023-06-27 18:23:44,828 - \u001b[1;33mWARNING\u001b[1;0m - Request 5247 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aeb0b4ba14123babca6e1e0c7e57a5fb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:47,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 5252 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f556fa1308b9446cfd38771b34d5b0b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:53,334 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5317\n",
      "2023-06-27 18:23:57,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 5269 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 17cd89b70aa5e23ff9d14d5d8c24031a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:03,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4748 failed with Exception \n",
      "2023-06-27 18:24:03,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5336\n",
      "2023-06-27 18:24:14,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5355\n",
      "2023-06-27 18:24:16,263 - \u001b[1;33mWARNING\u001b[1;0m - Request 5304 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1fc776b723be83141849bf7f8cd4aa4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:25,243 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5374\n",
      "2023-06-27 18:24:31,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 5331 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 741216788b5c542f7f63a9237b4b19b6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:35,869 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5393\n",
      "2023-06-27 18:24:38,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 5342 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7705198b5b46655670f114d5878b71b8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:46,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5412\n",
      "2023-06-27 18:24:49,162 - \u001b[1;33mWARNING\u001b[1;0m - Request 5362 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 461bea51f2323114a5baf058db66138b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:55,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 5373 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9a8e94e5e4c2bacc11ace8b74de02ba4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:24:57,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5430\n",
      "2023-06-27 18:25:00,852 - \u001b[1;33mWARNING\u001b[1;0m - Request 5384 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a9453e41a4f66589c2027cdba6d24c6a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:07,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5449\n",
      "2023-06-27 18:25:12,016 - \u001b[1;33mWARNING\u001b[1;0m - Request 5403 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2b5c34f30e1f74cf88053fa00106301e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:18,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5468\n",
      "2023-06-27 18:25:27,410 - \u001b[1;33mWARNING\u001b[1;0m - Request 5401 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 18:25:27,972 - \u001b[1;33mWARNING\u001b[1;0m - Request 5431 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b356f8a89644bcbc41a84e93137c5ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:29,027 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5431\n",
      "2023-06-27 18:25:35,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 5444 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b73907f6278855f97b56ed8c22ef4fe1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:39,123 - \u001b[1;33mWARNING\u001b[1;0m - Request 5451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a44650dbd1bc4f5e32f94325794f8d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:39,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5451\n",
      "2023-06-27 18:25:50,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5524\n",
      "2023-06-27 18:26:00,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5544\n",
      "2023-06-27 18:26:06,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 5444 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7632a44818e9e7e3144f04df09bf7f56 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:09,954 - \u001b[1;33mWARNING\u001b[1;0m - Request 5451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7b9cefd474bc03c1f9f8366b0ed36ee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:11,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5562\n",
      "2023-06-27 18:26:22,230 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5582\n",
      "2023-06-27 18:26:22,692 - \u001b[1;33mWARNING\u001b[1;0m - Request 5528 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID caaa66c5c18a928e1720352671ade604 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:32,851 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5601\n",
      "2023-06-27 18:26:35,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 5552 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c82d9d241aa840fc3647a760d8b7b775 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:41,898 - \u001b[1;33mWARNING\u001b[1;0m - Request 5562 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3eb786b789e867e321fb5e75d43803a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:43,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5619\n",
      "2023-06-27 18:26:49,348 - \u001b[1;33mWARNING\u001b[1;0m - Request 5576 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1b54aaefe081083fb1218a346d466115 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:54,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5638\n",
      "2023-06-27 18:26:57,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 5589 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6670f02f2d507143ac22c4cd9dc1b021 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:58,361 - \u001b[1;33mWARNING\u001b[1;0m - Request 5592 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5dbebe93b35e9f9095040cf7f6eff2d5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:01,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 5597 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f5421e3b15ad4f97c75dee074cc2664 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:04,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5655\n",
      "2023-06-27 18:27:11,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 5615 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 141fd97c2bdf9e89ce3873c9ac58ee26 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:11,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5134 failed with Exception \n",
      "2023-06-27 18:27:14,305 - \u001b[1;33mWARNING\u001b[1;0m - Request 5620 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a3a090ee2b4195e5b2459805d5302494 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:15,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5620\n",
      "2023-06-27 18:27:22,025 - \u001b[1;33mWARNING\u001b[1;0m - Request 5632 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 88409252f775a47c0e7f3609350da9c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:25,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5691\n",
      "2023-06-27 18:27:35,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5175 failed with Exception \n",
      "2023-06-27 18:27:36,526 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5175\n",
      "2023-06-27 18:27:47,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:27:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5198 failed with Exception \n",
      "2023-06-27 18:27:48,783 - \u001b[1;33mWARNING\u001b[1;0m - Request 5678 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 881b19982f2ca7c0857486fd77dd3ee4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:50,380 - \u001b[1;33mWARNING\u001b[1;0m - Request 5681 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c3fab7c8395d6ee462a2b1a6b1fb04d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:57,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5747\n",
      "2023-06-27 18:28:08,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5767\n",
      "2023-06-27 18:28:18,948 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5787\n",
      "2023-06-27 18:28:19,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 5198 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ca5322fbcd1d209caf0fe51c97262a4a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:20,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 5678 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c2ab6a0adff681197716cc93a2d730fc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:26,438 - \u001b[1;33mWARNING\u001b[1;0m - Request 5744 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6cf88bed17eb37ac03d52317884c51e6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:29,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5804\n",
      "2023-06-27 18:28:30,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5275 failed with Exception \n",
      "2023-06-27 18:28:40,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5823\n",
      "2023-06-27 18:28:50,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5843\n",
      "2023-06-27 18:29:01,381 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5863\n",
      "2023-06-27 18:29:01,416 - \u001b[1;33mWARNING\u001b[1;0m - Request 5800 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f010528734278c55b29bf5e09a03d28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:08,338 - \u001b[1;33mWARNING\u001b[1;0m - Request 5819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5989b68a0c3461b5c7532d7276aafd92 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:11,987 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5881\n",
      "2023-06-27 18:29:13,636 - \u001b[1;33mWARNING\u001b[1;0m - Request 5829 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 45f9d7ad4d13cc371756ed5417c1b9a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:22,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5900\n",
      "2023-06-27 18:29:29,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5381 failed with Exception \n",
      "2023-06-27 18:29:33,200 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5919\n",
      "2023-06-27 18:29:43,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5939\n",
      "2023-06-27 18:29:44,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 5885 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 356919d556a375317545b3f8c748def0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:47,081 - \u001b[1;33mWARNING\u001b[1;0m - Request 5889 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a0f6ed9ae8a53421f983c4ba343ea9f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:51,819 - \u001b[1;33mWARNING\u001b[1;0m - Request 5898 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03afc9d11d7f0a05aa40eea264a848e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:54,410 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5956\n",
      "2023-06-27 18:29:59,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 5912 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f98f30629f36b572cfcea6969c93dd88 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:00,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 5914 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d65bbf92464e83a9492efc34effad4c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:00,833 - \u001b[1;33mWARNING\u001b[1;0m - Request 5381 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 885996a9be916eafa2cda242cf064907 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:01,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 5915 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 14e4147c9762bf3bbeab6b11a2c69e4e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:03,553 - \u001b[1;33mWARNING\u001b[1;0m - Request 5919 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8ff999e87a6b4f0645958f957f852dab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:05,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5971\n",
      "2023-06-27 18:30:06,162 - \u001b[1;33mWARNING\u001b[1;0m - Request 5924 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c239a93a6b84b2153b2c52db0cbceb71 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:15,621 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5990\n",
      "2023-06-27 18:30:26,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6010\n",
      "2023-06-27 18:30:27,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 5962 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e32d7d2917ed7154d6e039421b8ab7de in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:30:31,651 - \u001b[1;33mWARNING\u001b[1;0m - Request 5914 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ee34f8e2433684a318e46094011bbba9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:36,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6028\n",
      "2023-06-27 18:30:47,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6048\n",
      "2023-06-27 18:30:52,809 - \u001b[1;33mWARNING\u001b[1;0m - Request 6003 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b0bec4f857dbe4523c8c64c762946cd1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:58,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6067\n",
      "2023-06-27 18:31:02,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 5914 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03e94d91f7c6dd0043ffff80eaaf0191 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5551 failed with Exception \n",
      "2023-06-27 18:31:08,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6085\n",
      "2023-06-27 18:31:19,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6105\n",
      "2023-06-27 18:31:22,511 - \u001b[1;33mWARNING\u001b[1;0m - Request 6057 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fbaf370dc0e932d1553145d89b8e4e7b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:26,258 - \u001b[1;33mWARNING\u001b[1;0m - Request 6063 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID afd87b66468f4e8a05ff41f620a8e1d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:26,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5588 failed with Exception \n",
      "2023-06-27 18:31:28,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 6068 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a9d97088f2bf0afd15108030f89164d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:29,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6068\n",
      "2023-06-27 18:31:40,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6141\n",
      "2023-06-27 18:31:44,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 6095 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3625ff142e5bee8b3ef696ce28eb961f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:51,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6160\n",
      "2023-06-27 18:31:53,304 - \u001b[1;33mWARNING\u001b[1;0m - Request 6112 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dcd22007fbdc2cdc08387dbc9d2326a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:54,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5638 failed with Exception \n",
      "2023-06-27 18:31:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5643 failed with Exception \n",
      "2023-06-27 18:32:00,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 6121 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6d328370a0a78a67e330f3ef2490753 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:01,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6176\n",
      "2023-06-27 18:32:12,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6196\n",
      "2023-06-27 18:32:18,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 6154 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a20ce86af0b42baef9533a392f0a5039 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:21,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 6160 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e6b97d2e91c07507cd48100701623ff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:22,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6214\n",
      "2023-06-27 18:32:26,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 6167 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 217f1d888eca46ef4a1460d5634da14d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:33,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6233\n",
      "2023-06-27 18:32:36,215 - \u001b[1;33mWARNING\u001b[1;0m - Request 6184 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 34dd43f90785e2a679a9c837848580c3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:44,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6252\n",
      "2023-06-27 18:32:54,710 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6272\n",
      "2023-06-27 18:33:02,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5755 failed with Exception \n",
      "2023-06-27 18:33:05,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6291\n",
      "2023-06-27 18:33:11,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 6246 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ce3da419dbea3f5269759ef370eb07a1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:12,814 - \u001b[1;33mWARNING\u001b[1;0m - Request 6249 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 198d9e29d2a78376f6ec5697d338a3fc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:15,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6309\n",
      "2023-06-27 18:33:17,888 - \u001b[1;33mWARNING\u001b[1;0m - Request 6258 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5f871561817a06db199ea1c24d08252 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:18,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5786 failed with Exception \n",
      "2023-06-27 18:33:26,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6327\n",
      "2023-06-27 18:33:37,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6347\n",
      "2023-06-27 18:33:39,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5820 failed with Exception \n",
      "2023-06-27 18:33:47,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:33:58,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6386\n",
      "2023-06-27 18:33:59,999 - \u001b[1;33mWARNING\u001b[1;0m - Request 6333 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c92e2387977832de5a5f25c37c416889 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:00,531 - \u001b[1;33mWARNING\u001b[1;0m - Request 6334 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a6c44cec5c888c91c33a7cf6fff3c6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:05,299 - \u001b[1;33mWARNING\u001b[1;0m - Request 6343 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b7c3118b48cd21df0dc55b214522a23e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:08,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6403\n",
      "2023-06-27 18:34:13,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 6358 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7b1c7a22a2d72baab8b8ca484242539a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:16,978 - \u001b[1;33mWARNING\u001b[1;0m - Request 6364 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e2e01087756ca4c9745ce2d9926355ac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:19,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6421\n",
      "2023-06-27 18:34:19,623 - \u001b[1;33mWARNING\u001b[1;0m - Request 6369 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e40fd16529451a19d687ee2a7048143 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:28,653 - \u001b[1;33mWARNING\u001b[1;0m - Request 6386 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2531a89eedd8384c58a68de6bf7d6891 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:30,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6439\n",
      "2023-06-27 18:34:30,921 - \u001b[1;33mWARNING\u001b[1;0m - Request 6390 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a85b9fbbf43477d34c3e16b16d9df2c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:32,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 6391 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 06a1a82655eff0aa709c5c5a6a466dad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:40,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6457\n",
      "2023-06-27 18:34:51,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6477\n",
      "2023-06-27 18:35:02,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6497\n",
      "2023-06-27 18:35:04,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 6444 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b533224cb42b18ae2fbfec5e22fe089f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:07,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 6451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7776c67b3612a1fc2fcdda0be451a7c4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:12,609 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6515\n",
      "2023-06-27 18:35:20,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5998 failed with Exception \n",
      "2023-06-27 18:35:23,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6534\n",
      "2023-06-27 18:35:29,641 - \u001b[1;33mWARNING\u001b[1;0m - Request 6492 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3f5d9f6b0d6a20ecdcbc6ad260e68a79 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:33,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6553\n",
      "2023-06-27 18:35:34,957 - \u001b[1;33mWARNING\u001b[1;0m - Request 6502 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b7bdd5bac70bf5fab84dbbee94f56ec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:37,072 - \u001b[1;33mWARNING\u001b[1;0m - Request 6505 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a40608a4e93caf427125ca2bf353733 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:40,559 - \u001b[1;33mWARNING\u001b[1;0m - Request 6451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3fbd20aab611814fd711a84ea86c7b89 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:44,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 6517 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e06f8c48c989a53e19621e44b41565f6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:44,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6570\n",
      "2023-06-27 18:35:45,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 6520 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 83c3178d574e51d436101d3719ea0296 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:55,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6588\n",
      "2023-06-27 18:36:05,173 - \u001b[1;33mWARNING\u001b[1;0m - Request 6555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bfbf70c116c340512f07c453becd5fee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:05,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6608\n",
      "2023-06-27 18:36:06,250 - \u001b[1;33mWARNING\u001b[1;0m - Request 6502 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e79fcacbcab7ba5e5a2f60cc2bb7d2ae in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:36:16,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6626\n",
      "2023-06-27 18:36:16,333 - \u001b[1;33mWARNING\u001b[1;0m - Request 6572 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ab3563cac0a50bfc59c499b742fb64f2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:26,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6645\n",
      "2023-06-27 18:36:31,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 6599 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 90d1da54e5e316b29f1c98159b1cef6d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:37,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6664\n",
      "2023-06-27 18:36:48,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6684\n",
      "2023-06-27 18:36:58,377 - \u001b[1;33mWARNING\u001b[1;0m - Request 6647 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53ef9e8c15989f8752369da577e701cc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:58,810 - \u001b[1;33mWARNING\u001b[1;0m - Request 6648 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6a29ce109e0b6c5d6c4f09c14c76ceab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:58,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6704\n",
      "2023-06-27 18:37:09,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6722\n",
      "2023-06-27 18:37:16,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 6680 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4ff019c719fb91305ffe7859938a1138 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:37:20,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6741\n",
      "2023-06-27 18:37:26,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6219 failed with Exception \n",
      "2023-06-27 18:37:29,765 - \u001b[1;33mWARNING\u001b[1;0m - Request 6647 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 503bbda5c886c65830bb6ea284caa685 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:37:30,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6759\n",
      "2023-06-27 18:37:41,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6779\n",
      "2023-06-27 18:37:52,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6799\n",
      "2023-06-27 18:38:02,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6819\n",
      "2023-06-27 18:38:05,447 - \u001b[1;33mWARNING\u001b[1;0m - Request 6767 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 64eacb5b1dc550f80b0eebef9b5ba0b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:38:13,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6838\n",
      "2023-06-27 18:38:17,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 6788 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e9644ac9a0865a47a8aef675d5b58c21 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:38:20,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6315 failed with Exception \n",
      "2023-06-27 18:38:24,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6856\n",
      "2023-06-27 18:38:34,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6876\n",
      "2023-06-27 18:38:41,178 - \u001b[1;33mWARNING\u001b[1;0m - Request 6833 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c40885efe7193e2f56eedaf20e0485a5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:38:45,513 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6895\n",
      "2023-06-27 18:38:47,638 - \u001b[1;33mWARNING\u001b[1;0m - Request 6845 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dfa9a025da20bc0c09b664f5d1f88e81 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:38:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6367 failed with Exception \n",
      "2023-06-27 18:38:54,490 - \u001b[1;33mWARNING\u001b[1;0m - Request 6856 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 517f6ed58ce5a37b16a6db957b6549ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:38:56,159 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6912\n",
      "2023-06-27 18:39:05,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 6877 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9a86debfb865f34b43b8d4f302aaed74 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:06,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6931\n",
      "2023-06-27 18:39:17,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6951\n",
      "2023-06-27 18:39:20,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 6902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76cf1ef06b6e76c25ab67102dadd8f51 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:26,525 - \u001b[1;33mWARNING\u001b[1;0m - Request 6912 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1d17bef28b2248cd300477eb146041c4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:28,178 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6969\n",
      "2023-06-27 18:39:30,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 6920 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 723e5a98974bac757e6ea0ee4dad035c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:38,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6988\n",
      "2023-06-27 18:39:45,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 6464 failed with Exception \n",
      "2023-06-27 18:39:45,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 6465 failed with Exception \n",
      "2023-06-27 18:39:49,499 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7006\n",
      "2023-06-27 18:40:00,169 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7026\n",
      "2023-06-27 18:40:03,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 6977 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ad8ed4f829fb91fdf9b6c06191a9b1d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:40:10,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7045\n",
      "2023-06-27 18:40:11,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 6993 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d614e853b8672cea767832531ed974ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:40:19,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 7005 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID be68ecd78b84818700bd83e9d8b8bf25 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:40:21,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7063\n",
      "2023-06-27 18:40:32,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7083\n",
      "2023-06-27 18:40:32,255 - \u001b[1;33mWARNING\u001b[1;0m - Request 7029 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0007090a8fce328bd899055b6f904a49 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:40:42,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7102\n",
      "2023-06-27 18:40:53,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7122\n",
      "2023-06-27 18:41:04,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7142\n",
      "2023-06-27 18:41:09,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6613 failed with Exception \n",
      "2023-06-27 18:41:14,757 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7161\n",
      "2023-06-27 18:41:20,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 7115 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f848ba9c7ade4bda5974cde0844280a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:41:22,149 - \u001b[1;33mWARNING\u001b[1;0m - Request 7119 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ad653ebccea6515be1bb26f100a4ed0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:41:25,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7179\n",
      "2023-06-27 18:41:31,761 - \u001b[1;33mWARNING\u001b[1;0m - Request 7137 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a06be3c3e543735a99eabd552bd0259e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:41:36,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7198\n",
      "2023-06-27 18:41:41,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6671 failed with Exception \n",
      "2023-06-27 18:41:46,742 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7217\n",
      "2023-06-27 18:41:47,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6682 failed with Exception \n",
      "2023-06-27 18:41:54,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 7176 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 982b352d7907ad966be977667de96998 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:41:57,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7235\n",
      "2023-06-27 18:42:01,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 7189 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a73f1bb369e14d77d088fc548a6380a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:08,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7254\n",
      "2023-06-27 18:42:09,550 - \u001b[1;33mWARNING\u001b[1;0m - Request 7204 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6cf6611f8c8dffacbecc01afe8d3119e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:18,737 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7273\n",
      "2023-06-27 18:42:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6739 failed with Exception \n",
      "2023-06-27 18:42:29,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7292\n",
      "2023-06-27 18:42:31,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6759 failed with Exception \n",
      "2023-06-27 18:42:33,632 - \u001b[1;33mWARNING\u001b[1;0m - Request 7245 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40772230ecd902c8786640846fabddc7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:40,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7310\n",
      "2023-06-27 18:42:45,198 - \u001b[1;33mWARNING\u001b[1;0m - Request 7265 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dadbbecf4b65ac940bbf7117a170b428 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:50,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7329\n",
      "2023-06-27 18:42:52,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 7278 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 79909a12069224ccbb66802294ccdb52 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6812 failed with Exception \n",
      "2023-06-27 18:43:00,239 - \u001b[1;33mWARNING\u001b[1;0m - Request 7293 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 07204c409db729430aca75d911b07865 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:01,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7346\n",
      "2023-06-27 18:43:10,483 - \u001b[1;33mWARNING\u001b[1;0m - Request 7310 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8422e4ba927e27fc181036a18c1abe99 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:12,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7365\n",
      "2023-06-27 18:43:18,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 7324 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 51da29a5105a5e31f8717c6863e1a8c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:21,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 7330 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 834151600a6cdfdd545f556058c787fc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:22,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7383\n",
      "2023-06-27 18:43:33,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:43:38,125 - \u001b[1;33mWARNING\u001b[1;0m - Request 7358 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c20195f8adda0f1fb8dce514feca3a27 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:44,073 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7422\n",
      "2023-06-27 18:43:50,930 - \u001b[1;33mWARNING\u001b[1;0m - Request 7380 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7aa006e12df0c0f9c294a12787f7e259 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:54,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7441\n",
      "2023-06-27 18:44:05,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7461\n",
      "2023-06-27 18:44:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6932 failed with Exception \n",
      "2023-06-27 18:44:10,139 - \u001b[1;33mWARNING\u001b[1;0m - Request 7414 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d0f6039b07eadcb1e7db2c5fbe553152 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:12,765 - \u001b[1;33mWARNING\u001b[1;0m - Request 7419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 72f9bf127b94600bfe953ac5ea062df2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:16,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7478\n",
      "2023-06-27 18:44:18,085 - \u001b[1;33mWARNING\u001b[1;0m - Request 7429 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c94fccf7e7c016198da659c2500e3c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:18,704 - \u001b[1;33mWARNING\u001b[1;0m - Request 7430 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 64c6973ee2db27ac2700d285f9994cba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:26,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7496\n",
      "2023-06-27 18:44:32,058 - \u001b[1;33mWARNING\u001b[1;0m - Request 7454 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2a8e1126377d9c7b84727d138b834c84 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:37,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7515\n",
      "2023-06-27 18:44:47,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7002 failed with Exception \n",
      "2023-06-27 18:44:48,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7002\n",
      "2023-06-27 18:44:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7006 failed with Exception \n",
      "2023-06-27 18:44:58,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7553\n",
      "2023-06-27 18:45:09,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7573\n",
      "2023-06-27 18:45:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7047 failed with Exception \n",
      "2023-06-27 18:45:13,582 - \u001b[1;33mWARNING\u001b[1;0m - Request 7526 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 29c8a41bbc7001b9494aefb55743d90a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:45:17,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7056 failed with Exception \n",
      "2023-06-27 18:45:20,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7590\n",
      "2023-06-27 18:45:25,275 - \u001b[1;33mWARNING\u001b[1;0m - Request 7546 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7efdfd7ecdcd34a3919302ff0014b15e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:45:30,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7609\n",
      "2023-06-27 18:45:41,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7629\n",
      "2023-06-27 18:45:44,255 - \u001b[1;33mWARNING\u001b[1;0m - Request 7047 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e206332f847a1636acc2cffe58ffe02e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:45:52,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7648\n",
      "2023-06-27 18:45:56,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7126 failed with Exception \n",
      "2023-06-27 18:45:56,805 - \u001b[1;33mWARNING\u001b[1;0m - Request 7601 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6c76a6e152276bc070954c49ab40e1b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:45:57,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 7603 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3051f9666c6c15a09212a97779e5fa12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:01,513 - \u001b[1;33mWARNING\u001b[1;0m - Request 7610 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ab7372442ff400940045d3ee5f03596 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:02,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 7611 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae85db87ac27708ce509e6800070ef92 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:02,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7611\n",
      "2023-06-27 18:46:05,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 7617 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dddfff943c0a3dcd354896615a4b1557 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:13,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7682\n",
      "2023-06-27 18:46:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7173 failed with Exception \n",
      "2023-06-27 18:46:22,864 - \u001b[1;33mWARNING\u001b[1;0m - Request 7649 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d79e6d3c6a21bce34ec20df367c65344 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:23,996 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7649\n",
      "2023-06-27 18:46:34,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7720\n",
      "2023-06-27 18:46:39,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 7674 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0fb1a8a4cb77356d58e087ed10ffe6da in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:46:45,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7739\n",
      "2023-06-27 18:46:45,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 7686 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0fd9cbb01a5b053602b539f9bf76d3fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:47,882 - \u001b[1;33mWARNING\u001b[1;0m - Request 7690 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4ecd40facbad67ee7475fe84affda3c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:55,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7757\n",
      "2023-06-27 18:46:56,956 - \u001b[1;33mWARNING\u001b[1;0m - Request 7705 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8b7ab67687fb4f62082830d5c99a810b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:06,613 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7776\n",
      "2023-06-27 18:47:07,082 - \u001b[1;33mWARNING\u001b[1;0m - Request 7724 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8903f2f13913f2b77658018b997fa32c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:12,930 - \u001b[1;33mWARNING\u001b[1;0m - Request 7734 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 577edf6cef4683f2b0f7a3c58034f880 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:17,277 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7794\n",
      "2023-06-27 18:47:25,242 - \u001b[1;33mWARNING\u001b[1;0m - Request 7755 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af8dc3b2384cfb2423ebc0ebf3d242cf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:27,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7813\n",
      "2023-06-27 18:47:37,432 - \u001b[1;33mWARNING\u001b[1;0m - Request 7777 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 497cf94748c80b5b318142012c3db159 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:38,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7832\n",
      "2023-06-27 18:47:49,268 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7852\n",
      "2023-06-27 18:47:58,874 - \u001b[1;33mWARNING\u001b[1;0m - Request 7814 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd1f2576948593f6e4e8094183d9e821 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:59,326 - \u001b[1;33mWARNING\u001b[1;0m - Request 7815 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d588e5c03d053842d3501603da2bdece in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:59,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7814\n",
      "2023-06-27 18:48:04,094 - \u001b[1;33mWARNING\u001b[1;0m - Request 7824 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 30a1d98c27ed4bc0c40fe3bba065a784 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:10,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7889\n",
      "2023-06-27 18:48:14,774 - \u001b[1;33mWARNING\u001b[1;0m - Request 7843 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9feda0eb27807adbb533835e4b71b147 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:21,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7908\n",
      "2023-06-27 18:48:22,854 - \u001b[1;33mWARNING\u001b[1;0m - Request 7858 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9c06c8175713a7bd3088a3d01f1cd130 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:27,878 - \u001b[1;33mWARNING\u001b[1;0m - Request 7867 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd64a35b71279cc376e3348e77d95f1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:31,906 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7926\n",
      "2023-06-27 18:48:42,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7946\n",
      "2023-06-27 18:48:44,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 7895 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0a46755643610b4f2022d0cd104ff80 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:53,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7965\n",
      "2023-06-27 18:49:00,458 - \u001b[1;33mWARNING\u001b[1;0m - Request 7922 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f684673f15c9f5bf9425b73ac6f9b40a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:03,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7984\n",
      "2023-06-27 18:49:14,571 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8004\n",
      "2023-06-27 18:49:25,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8024\n",
      "2023-06-27 18:49:28,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7499 failed with Exception \n",
      "2023-06-27 18:49:28,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 7975 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6df56dfd730bf0986988dd919b302b1c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:35,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8042\n",
      "2023-06-27 18:49:37,938 - \u001b[1;33mWARNING\u001b[1;0m - Request 7991 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b85727a5c57fb633c6bb8a6f5ecf2c4c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:43,297 - \u001b[1;33mWARNING\u001b[1;0m - Request 8001 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 755f8c167a64dc9be2bdb745c2e1d1f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:49:46,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8060\n",
      "2023-06-27 18:49:57,234 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8080\n",
      "2023-06-27 18:50:02,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 8035 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c55a0f12df64636770bb0e5852b8e37 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:04,037 - \u001b[1;33mWARNING\u001b[1;0m - Request 8038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7a6b46508046dbeff413c5237ac384c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:07,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8098\n",
      "2023-06-27 18:50:15,791 - \u001b[1;33mWARNING\u001b[1;0m - Request 8058 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f4846b759837d7f7321ccf4463d1057f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:18,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8117\n",
      "2023-06-27 18:50:29,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8137\n",
      "2023-06-27 18:50:32,890 - \u001b[1;33mWARNING\u001b[1;0m - Request 8090 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 086cb0f2ecfc1a0e5b4c422e2189432c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:37,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 8096 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f861ec3cbec70a69eb6169b6e47e2f0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:39,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8155\n",
      "2023-06-27 18:50:40,907 - \u001b[1;33mWARNING\u001b[1;0m - Request 8103 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dea908679b2dc8693b69a0822716f4df in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:43,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7632 failed with Exception \n",
      "2023-06-27 18:50:48,850 - \u001b[1;33mWARNING\u001b[1;0m - Request 8117 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7cbaba0464c7cb802c81883175e7e5f0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:50,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8172\n",
      "2023-06-27 18:51:01,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8192\n",
      "2023-06-27 18:51:04,305 - \u001b[1;33mWARNING\u001b[1;0m - Request 8145 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 64060562d96cbc40380da3803a765c41 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:11,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8211\n",
      "2023-06-27 18:51:16,022 - \u001b[1;33mWARNING\u001b[1;0m - Request 8161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 46dc1e1a45b1ca8f60d28056ecd1bb1c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:21,047 - \u001b[1;33mWARNING\u001b[1;0m - Request 8172 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40d808e70747a60b99869827c642f67d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:22,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8229\n",
      "2023-06-27 18:51:24,023 - \u001b[1;33mWARNING\u001b[1;0m - Request 8178 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f86ee1873e1741c7fb00534ece5c49d4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:28,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7707 failed with Exception \n",
      "2023-06-27 18:51:33,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8247\n",
      "2023-06-27 18:51:43,802 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8267\n",
      "2023-06-27 18:51:54,472 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8287\n",
      "2023-06-27 18:52:03,432 - \u001b[1;33mWARNING\u001b[1;0m - Request 8247 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e6f5d66ef5cc0424afccf21b87a1c8c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:05,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8306\n",
      "2023-06-27 18:52:06,638 - \u001b[1;33mWARNING\u001b[1;0m - Request 8253 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b80ef838f753c3389455f186f5abb17 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:07,713 - \u001b[1;33mWARNING\u001b[1;0m - Request 8255 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de5ea53bbd02faa175544471639c0cf8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:15,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 8270 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 33b54e8e52bb16dffbe552971527a664 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:15,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8324\n",
      "2023-06-27 18:52:23,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 8285 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 28f3daab19ac20d57d7c5f258f2de44a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:26,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8342\n",
      "2023-06-27 18:52:37,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8362\n",
      "2023-06-27 18:52:38,636 - \u001b[1;33mWARNING\u001b[1;0m - Request 8255 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c26a1d1f2c4bd199a908d11b050612d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:47,755 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8381\n",
      "2023-06-27 18:52:49,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 8329 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6ed6889907c59c2cac4823dc9876ba3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:52:58,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8400\n",
      "2023-06-27 18:52:59,037 - \u001b[1;33mWARNING\u001b[1;0m - Request 8346 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8690b5eac4415dd57e7687e3f9756e07 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:07,408 - \u001b[1;33mWARNING\u001b[1;0m - Request 8362 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 837fe82fafe7a4d10db4bf2c48245857 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:07,925 - \u001b[1;33mWARNING\u001b[1;0m - Request 8363 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 85c2c7e4341e27bad3f8be502a2529b0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:09,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8417\n",
      "2023-06-27 18:53:15,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 8376 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e879af4ee1862103118b3a3c2b7c16b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:19,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8436\n",
      "2023-06-27 18:53:30,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8456\n",
      "2023-06-27 18:53:41,002 - \u001b[1;33mWARNING\u001b[1;0m - Request 8420 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d4f1323cfde231f40fc4c1969b8dce4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:41,059 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8476\n",
      "2023-06-27 18:53:48,940 - \u001b[1;33mWARNING\u001b[1;0m - Request 8434 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dc302ef2a93e86e28a9e1d22389ad593 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:49,483 - \u001b[1;33mWARNING\u001b[1;0m - Request 8435 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5abe10b858cae910fd2609d85157578d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:51,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8493\n",
      "2023-06-27 18:54:02,368 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8513\n",
      "2023-06-27 18:54:13,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8533\n",
      "2023-06-27 18:54:14,010 - \u001b[1;33mWARNING\u001b[1;0m - Request 8480 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 238edfc3e7bba3ef6ed7fbad2b14323a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:54:23,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8552\n",
      "2023-06-27 18:54:34,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8572\n",
      "2023-06-27 18:54:35,858 - \u001b[1;33mWARNING\u001b[1;0m - Request 8519 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9dfb6aaed1090b788c704d3b5a1356be in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:54:42,795 - \u001b[1;33mWARNING\u001b[1;0m - Request 8532 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0adb0c22b94e6ff420bc1d7f1e16d50c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:54:45,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8590\n",
      "2023-06-27 18:54:49,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8065 failed with Exception \n",
      "2023-06-27 18:54:55,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8609\n",
      "2023-06-27 18:54:58,132 - \u001b[1;33mWARNING\u001b[1;0m - Request 8557 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db4aa758a4f62c814bdcc00de40fc8c3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:00,388 - \u001b[1;33mWARNING\u001b[1;0m - Request 8564 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e56ab92cb5f7d48b229ee110c30e0f5b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:04,835 - \u001b[1;33mWARNING\u001b[1;0m - Request 8572 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b2d3b9a569457a123876b2fc7c35b5d7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:06,367 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8626\n",
      "2023-06-27 18:55:17,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8646\n",
      "2023-06-27 18:55:27,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8666\n",
      "2023-06-27 18:55:38,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8686\n",
      "2023-06-27 18:55:49,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8706\n",
      "2023-06-27 18:55:55,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 8661 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7bd7660004cf8946b57701e8433e9e2f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:59,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8725\n",
      "2023-06-27 18:56:03,923 - \u001b[1;33mWARNING\u001b[1;0m - Request 8677 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c7963526f43d25c5181722d95ad2a067 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:10,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8744\n",
      "2023-06-27 18:56:15,654 - \u001b[1;33mWARNING\u001b[1;0m - Request 8699 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 23745a9dd0d05be2321041ff661baf3f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:17,775 - \u001b[1;33mWARNING\u001b[1;0m - Request 8703 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05176f1ef4a8436a651b91240e97ad5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:21,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8762\n",
      "2023-06-27 18:56:22,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8172 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:56:23,160 - \u001b[1;33mWARNING\u001b[1;0m - Request 8713 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1e0b6ab97254f383cc2f9887b2c74d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:25,240 - \u001b[1;33mWARNING\u001b[1;0m - Request 8717 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 535491c4fe256d157418f4444b85d3a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:31,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8779\n",
      "2023-06-27 18:56:34,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 8733 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f055d9a0f919efe64c2ae2dde5eec72f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:35,364 - \u001b[1;33mWARNING\u001b[1;0m - Request 8734 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 345dfb26774da870d50685e30dc443b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:42,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8797\n",
      "2023-06-27 18:56:51,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8281 failed with Exception \n",
      "2023-06-27 18:56:52,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 8764 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1b61ffcbc05b0c22a8b6abafe85f8405 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:53,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8764\n",
      "2023-06-27 18:56:58,287 - \u001b[1;33mWARNING\u001b[1;0m - Request 8772 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19df028a0f63e9b7a04bfd0395e6d226 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:03,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8834\n",
      "2023-06-27 18:57:14,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 8799 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a023ef48fd8154f6547390462e1f49b5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:14,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8854\n",
      "2023-06-27 18:57:25,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8873\n",
      "2023-06-27 18:57:35,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8893\n",
      "2023-06-27 18:57:43,593 - \u001b[1;33mWARNING\u001b[1;0m - Request 8852 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0959fcdbf7f77087ddbff42c7d327c7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:46,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8912\n",
      "2023-06-27 18:57:46,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 8857 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1e73861a1afe63f53fe4c9a1c9a736fc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:51,068 - \u001b[1;33mWARNING\u001b[1;0m - Request 8865 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ddeafc9230585c15c1eead2eb6c4431 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:56,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8930\n",
      "2023-06-27 18:57:58,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 8878 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4e7e6058d341aa9d2b6d33cb317d52d1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:59,848 - \u001b[1;33mWARNING\u001b[1;0m - Request 8881 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 211ec93abb2b2ef074ac6e2663d90a52 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:58:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8412 failed with Exception \n",
      "2023-06-27 18:58:06,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 8894 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 26ece67c5cfe91efb1140740f580b9ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:58:07,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8946\n",
      "2023-06-27 18:58:13,423 - \u001b[1;33mWARNING\u001b[1;0m - Request 8907 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 378dc000268c14a4d98e0732577aa351 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:58:18,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8965\n",
      "2023-06-27 18:58:21,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 8920 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e63b5fc4f9328de0e7d0c833c364bde8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:58:28,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8984\n",
      "2023-06-27 18:58:33,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8460 failed with Exception \n",
      "2023-06-27 18:58:39,649 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9003\n",
      "2023-06-27 18:58:47,015 - \u001b[1;33mWARNING\u001b[1;0m - Request 8962 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a7454dd26630dabf97a2d53ba5f774b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:58:50,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9022\n",
      "2023-06-27 18:58:55,025 - \u001b[1;33mWARNING\u001b[1;0m - Request 8976 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d6ef42dd27cdf1d54745b3b808ee429 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:00,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9041\n",
      "2023-06-27 18:59:01,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 8989 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6667effd39eecf214c82d4b957e023cc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:59:06,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 8997 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f173fe22dbcafa44e5dd82b1601807c3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:11,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9059\n",
      "2023-06-27 18:59:15,389 - \u001b[1;33mWARNING\u001b[1;0m - Request 9013 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fbffad9834831362ccd9e7b0e465c7d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:22,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9078\n",
      "2023-06-27 18:59:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8558 failed with Exception \n",
      "2023-06-27 18:59:32,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9097\n",
      "2023-06-27 18:59:43,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9117\n",
      "2023-06-27 18:59:48,846 - \u001b[1;33mWARNING\u001b[1;0m - Request 9071 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0001ef8dea851bde401a4407665ddbaf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:52,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 9078 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 117bc678ee202f5c83ae9e4f7e8333f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:54,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9135\n",
      "2023-06-27 18:59:58,418 - \u001b[1;33mWARNING\u001b[1;0m - Request 8558 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c36e75ff2e806914ecc99e0a38134ae0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:04,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9154\n",
      "2023-06-27 19:00:12,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 9115 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3cc38bc73116d80db199b84ac7a8f4a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:15,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9173\n",
      "2023-06-27 19:00:16,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 9121 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 95512ec0b294c706a1a26a71e8f98d78 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:17,605 - \u001b[1;33mWARNING\u001b[1;0m - Request 9124 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a14f8e0258c808dd0cf4b529c9f866f6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:26,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9191\n",
      "2023-06-27 19:00:36,861 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9211\n",
      "2023-06-27 19:00:43,712 - \u001b[1;33mWARNING\u001b[1;0m - Request 9115 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 48d9c6016f19aeefdec0ff2be6ef47d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:45,853 - \u001b[1;33mWARNING\u001b[1;0m - Request 9173 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d76eaf8c01f6eba04ea20da1f1b8811 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:47,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9229\n",
      "2023-06-27 19:00:56,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 9191 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 908da9c57ec923da086ec717b2a55eec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:58,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9248\n",
      "2023-06-27 19:01:03,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 9204 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 945a7c5cb3f8092cdd6749a9592766d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:05,589 - \u001b[1;33mWARNING\u001b[1;0m - Request 9208 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e4c8e0c95af675d8372de5259410ca61 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:08,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9266\n",
      "2023-06-27 19:01:18,985 - \u001b[1;33mWARNING\u001b[1;0m - Request 9231 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03bcc8d94a0020de8b493d2837dea367 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:19,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9286\n",
      "2023-06-27 19:01:30,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9305\n",
      "2023-06-27 19:01:40,812 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9325\n",
      "2023-06-27 19:01:44,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8801 failed with Exception \n",
      "2023-06-27 19:01:45,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8802 failed with Exception \n",
      "2023-06-27 19:01:51,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9343\n",
      "2023-06-27 19:01:52,444 - \u001b[1;33mWARNING\u001b[1;0m - Request 9290 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 63662b3b3e30647e42d408387bc94c5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:54,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 9293 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7af94e389365a348136d5acd0f8dbdee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:55,668 - \u001b[1;33mWARNING\u001b[1;0m - Request 9296 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ec6a0f33c31d301fc5b7cbea7e76cd0e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:02,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9360\n",
      "2023-06-27 19:02:03,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 9311 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 547edadfabe2d3376d613f2086ae7154 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:02:04,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 9312 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6be2cab4c75cf480f4f750c26a72f6dd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:08,439 - \u001b[1;33mWARNING\u001b[1;0m - Request 9320 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d331631f326ec6f148e886bc831b001 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:10,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8846 failed with Exception \n",
      "2023-06-27 19:02:12,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9376\n",
      "2023-06-27 19:02:20,741 - \u001b[1;33mWARNING\u001b[1;0m - Request 9341 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bacddfce95b13b5133a8332b7dbde8c3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:22,305 - \u001b[1;33mWARNING\u001b[1;0m - Request 9344 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1103312226dae01f020e47b0dec89113 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:23,472 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9394\n",
      "2023-06-27 19:02:34,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9414\n",
      "2023-06-27 19:02:36,701 - \u001b[1;33mWARNING\u001b[1;0m - Request 9366 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c7f75d2214a83e81424ff41277ab0df in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:44,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9433\n",
      "2023-06-27 19:02:55,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9453\n",
      "2023-06-27 19:03:02,329 - \u001b[1;33mWARNING\u001b[1;0m - Request 9410 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 96124c6b4b1097b275c8b8d4d3759909 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:03,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8939 failed with Exception \n",
      "2023-06-27 19:03:06,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9471\n",
      "2023-06-27 19:03:07,113 - \u001b[1;33mWARNING\u001b[1;0m - Request 9419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f8ca357da937a37a867a8cd5929f7f03 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:16,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9490\n",
      "2023-06-27 19:03:24,208 - \u001b[1;33mWARNING\u001b[1;0m - Request 9450 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cfff749edef40ed27942b058afb46532 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:27,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9509\n",
      "2023-06-27 19:03:34,324 - \u001b[1;33mWARNING\u001b[1;0m - Request 9468 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e074419b8e36efd342f897facf9bca8c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:37,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 9473 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9bc804fd2f94692aaf6467c0f80627bf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:38,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9473\n",
      "2023-06-27 19:03:42,461 - \u001b[1;33mWARNING\u001b[1;0m - Request 9481 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0580fc17e261d0b9b3fe95f9d1784ad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:47,723 - \u001b[1;33mWARNING\u001b[1;0m - Request 9491 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b73ea276bf638b36dbe37c53e5e488a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:48,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9491\n",
      "2023-06-27 19:03:49,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 9495 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 497c334d717d3ec6a66b0f8ec27205cf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:50,309 - \u001b[1;33mWARNING\u001b[1;0m - Request 9496 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c2010f7edecc9b157e2044ad72dc5e1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:52,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 9499 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dc408325f5ee0527b84a9a60b9c941d1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9032 failed with Exception \n",
      "2023-06-27 19:03:59,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9561\n",
      "2023-06-27 19:04:06,826 - \u001b[1;33mWARNING\u001b[1;0m - Request 9525 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 088ad9c29b8ff5f3413dedd7b2efab28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:04:10,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9580\n",
      "2023-06-27 19:04:11,991 - \u001b[1;33mWARNING\u001b[1;0m - Request 9533 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d80fe7d1523e4fa1199a3ff8e703eb75 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:04:12,032 - \u001b[1;33mWARNING\u001b[1;0m - Request 9483 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 19:04:20,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9598\n",
      "2023-06-27 19:04:31,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9618\n",
      "2023-06-27 19:04:39,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9109 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:04:42,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9637\n",
      "2023-06-27 19:04:52,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9657\n",
      "2023-06-27 19:05:03,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9677\n",
      "2023-06-27 19:05:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9154 failed with Exception \n",
      "2023-06-27 19:05:07,618 - \u001b[1;33mWARNING\u001b[1;0m - Request 9629 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ceb6519907c1a42c45a3f6177a72a222 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:14,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9695\n",
      "2023-06-27 19:05:14,524 - \u001b[1;33mWARNING\u001b[1;0m - Request 9641 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7bc7460989106b497056adc10f609adc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:24,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9714\n",
      "2023-06-27 19:05:35,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9734\n",
      "2023-06-27 19:05:46,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9754\n",
      "2023-06-27 19:05:56,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9774\n",
      "2023-06-27 19:06:07,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9794\n",
      "2023-06-27 19:06:18,031 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9814\n",
      "2023-06-27 19:06:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9288 failed with Exception \n",
      "2023-06-27 19:06:28,011 - \u001b[1;33mWARNING\u001b[1;0m - Request 9776 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7cca2589e7b1b08f64c46585b7f57661 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:28,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9776\n",
      "2023-06-27 19:06:29,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 9778 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 116ee5ced2a3f12f73f5fe1b5ca76149 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:37,064 - \u001b[1;33mWARNING\u001b[1;0m - Request 9792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3315b12dd183543bb624b1bf4f025ead in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:39,388 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9850\n",
      "2023-06-27 19:06:50,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9870\n",
      "2023-06-27 19:06:55,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 9827 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d508578b10d8f3af27b6ece74b8de510 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:57,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 9830 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 55cbb76fa829bedabe0d2734321e5def in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:00,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9888\n",
      "2023-06-27 19:07:01,152 - \u001b[1;33mWARNING\u001b[1;0m - Request 9835 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID afdd01aae59b38ece6013060416d3863 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:04,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 9842 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 95871c497c104f3d5d10ed1ba3fcda1c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:11,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9906\n",
      "2023-06-27 19:07:19,259 - \u001b[1;33mWARNING\u001b[1;0m - Request 9868 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4680b6697eb6bad230d78dc3d56ff605 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:22,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9925\n",
      "2023-06-27 19:07:25,138 - \u001b[1;33mWARNING\u001b[1;0m - Request 9879 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d36b626c2b2fccd5ad1212ef1a39f46d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:30,981 - \u001b[1;33mWARNING\u001b[1;0m - Request 9888 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 33d9d0f1886a30f9c89305c3f8e498c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:32,685 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9943\n",
      "2023-06-27 19:07:43,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9963\n",
      "2023-06-27 19:07:54,004 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9983\n",
      "2023-06-27 19:07:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9456 failed with Exception \n",
      "2023-06-27 19:07:57,648 - \u001b[1;33mWARNING\u001b[1;0m - Request 9934 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af6a53090fbf2962e0f852c9e422c683 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:04,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10001\n",
      "2023-06-27 19:08:15,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10021\n",
      "2023-06-27 19:08:18,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 9972 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b675ffcd620beb4ba24a20dd5cf3eb54 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:25,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10040\n",
      "2023-06-27 19:08:36,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10060\n",
      "2023-06-27 19:08:38,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9473 failed with Exception \n",
      "2023-06-27 19:08:41,393 - \u001b[1;33mWARNING\u001b[1;0m - Request 10013 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56f544cdcba80a452e822032ebf5473e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:45,628 - \u001b[1;33mWARNING\u001b[1;0m - Request 10021 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2187fd3721e00e978a8217c383ae3c1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:08:47,258 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10077\n",
      "2023-06-27 19:08:47,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 10025 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5ff49df3cdebc64e8de929aeb3c0693d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:50,136 - \u001b[1;33mWARNING\u001b[1;0m - Request 10028 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a628aa98348a7e572380f8768a337c51 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:51,452 - \u001b[1;33mWARNING\u001b[1;0m - Request 10031 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ca7eb26489ef49f022835a2abaab4ae in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:52,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 10032 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53a03a35612bec970b4b97f33e62492e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:54,108 - \u001b[1;33mWARNING\u001b[1;0m - Request 10036 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c53a280d7cd2231897d48501bdc972d1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:57,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10092\n",
      "2023-06-27 19:08:58,921 - \u001b[1;33mWARNING\u001b[1;0m - Request 10045 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 762cf41b059196f22494a7953e919799 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:08,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10111\n",
      "2023-06-27 19:09:10,101 - \u001b[1;33mWARNING\u001b[1;0m - Request 10065 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb69084de08003f7af09a38811b06d53 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:19,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10130\n",
      "2023-06-27 19:09:20,223 - \u001b[1;33mWARNING\u001b[1;0m - Request 10081 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 289afad4fe947d9a822a98f8cdaaef2c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:26,609 - \u001b[1;33mWARNING\u001b[1;0m - Request 10089 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e0bbe55f0e16fea62b4b60ae455ca68e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:28,776 - \u001b[1;33mWARNING\u001b[1;0m - Request 10093 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 83ca4ed14a18178a9c0cc2fa8de143df in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:29,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10147\n",
      "2023-06-27 19:09:32,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 10099 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de0d582d38a40a5f391093b436cff3ab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:33,560 - \u001b[1;33mWARNING\u001b[1;0m - Request 10101 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 572fa747bc3014e17276b00427d0d69c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:37,821 - \u001b[1;33mWARNING\u001b[1;0m - Request 10109 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ae0be5a83624277047db285fb452f8d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:40,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10164\n",
      "2023-06-27 19:09:48,991 - \u001b[1;33mWARNING\u001b[1;0m - Request 10129 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b34dba2af3f736531120203cae69683b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:51,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10183\n",
      "2023-06-27 19:10:01,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10203\n",
      "2023-06-27 19:10:05,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 10155 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cdd12e87fc74d987797237291ad839f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:10:12,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10222\n",
      "2023-06-27 19:10:23,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10242\n",
      "2023-06-27 19:10:26,783 - \u001b[1;33mWARNING\u001b[1;0m - Request 10193 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3edbe885afc19c2abff9618d9a283958 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:10:33,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10261\n",
      "2023-06-27 19:10:35,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9733 failed with Exception \n",
      "2023-06-27 19:10:44,416 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10280\n",
      "2023-06-27 19:10:47,016 - \u001b[1;33mWARNING\u001b[1;0m - Request 10230 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ed593e82b265e122c47cfaf6120f97c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:10:53,453 - \u001b[1;33mWARNING\u001b[1;0m - Request 10242 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 27387eecdc4c1fc58231fa95966ac66e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:10:55,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10298\n",
      "2023-06-27 19:11:05,168 - \u001b[1;33mWARNING\u001b[1;0m - Request 10263 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 49032b27696912b6178373b32886b035 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:11:05,684 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10318\n",
      "2023-06-27 19:11:14,188 - \u001b[1;33mWARNING\u001b[1;0m - Request 10279 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 84553eb2d0e2ad6b34936fe991a0588b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:16,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10336\n",
      "2023-06-27 19:11:20,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9818 failed with Exception \n",
      "2023-06-27 19:11:26,990 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10355\n",
      "2023-06-27 19:11:30,144 - \u001b[1;33mWARNING\u001b[1;0m - Request 10307 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1650c6a471db3fc79ddf074aea303ba8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:37,649 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10374\n",
      "2023-06-27 19:11:47,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9864 failed with Exception \n",
      "2023-06-27 19:11:48,237 - \u001b[1;33mWARNING\u001b[1;0m - Request 10339 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e499b50c73ebc24b28f87c3f0cbcd515 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:48,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9864\n",
      "2023-06-27 19:11:56,747 - \u001b[1;33mWARNING\u001b[1;0m - Request 10354 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c1b25015348f85d8a1d9e5bd9035f53 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:58,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10411\n",
      "2023-06-27 19:12:03,714 - \u001b[1;33mWARNING\u001b[1;0m - Request 10366 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b9446ce693aa25129034aee9115c27cf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:09,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10430\n",
      "2023-06-27 19:12:12,316 - \u001b[1;33mWARNING\u001b[1;0m - Request 10382 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 10f1a9de4776f885cd8cae637c2cb4b8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:20,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10449\n",
      "2023-06-27 19:12:29,234 - \u001b[1;33mWARNING\u001b[1;0m - Request 10411 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7abcf315b5be514f2fea671633182b68 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:29,754 - \u001b[1;33mWARNING\u001b[1;0m - Request 10412 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2fcfe371377781e17a3afde3661f013e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:30,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10467\n",
      "2023-06-27 19:12:41,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10487\n",
      "2023-06-27 19:12:52,167 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10507\n",
      "2023-06-27 19:12:57,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9989 failed with Exception \n",
      "2023-06-27 19:13:02,793 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10526\n",
      "2023-06-27 19:13:13,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10546\n",
      "2023-06-27 19:13:14,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10019 failed with Exception \n",
      "2023-06-27 19:13:24,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10565\n",
      "2023-06-27 19:13:25,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10039 failed with Exception \n",
      "2023-06-27 19:13:26,746 - \u001b[1;33mWARNING\u001b[1;0m - Request 10515 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e41fe4d547eed44fb67bec0ecc4ae0c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:30,982 - \u001b[1;33mWARNING\u001b[1;0m - Request 10522 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 71bc5e00b1fd49a7644d39b219952a75 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:34,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10582\n",
      "2023-06-27 19:13:35,745 - \u001b[1;33mWARNING\u001b[1;0m - Request 10531 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 981f8fc409419a249021db5e5455e633 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:45,362 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10601\n",
      "2023-06-27 19:13:49,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 10555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97cfc60976acf13eebf4f7c59a19f491 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:56,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10620\n",
      "2023-06-27 19:14:01,794 - \u001b[1;33mWARNING\u001b[1;0m - Request 10577 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b9d1a9a064715a7deda9cba46d415a79 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:14:06,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10639\n",
      "2023-06-27 19:14:13,017 - \u001b[1;33mWARNING\u001b[1;0m - Request 10596 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d85413cafd8974276e04f4625d894acf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:14:17,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10658\n",
      "2023-06-27 19:14:27,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10678\n",
      "2023-06-27 19:14:34,289 - \u001b[1;33mWARNING\u001b[1;0m - Request 10634 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ab2ad6f91a2bf08887cc0f2b26badb70 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:14:38,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10697\n",
      "2023-06-27 19:14:43,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 10596 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d06988bfcf67c2da4dd455e08250a481 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:14:49,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10716\n",
      "2023-06-27 19:14:59,305 - \u001b[1;33mWARNING\u001b[1;0m - Request 10680 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b1eb1c84edafb2f6f3457d5ba591003 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:14:59,851 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10680\n",
      "2023-06-27 19:15:04,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 10655 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b46ba91458798af96f302cedebc830b2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:10,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10754\n",
      "2023-06-27 19:15:21,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10774\n",
      "2023-06-27 19:15:31,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10794\n",
      "2023-06-27 19:15:42,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10814\n",
      "2023-06-27 19:15:53,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10834\n",
      "2023-06-27 19:15:59,408 - \u001b[1;33mWARNING\u001b[1;0m - Request 10789 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9279ea850f943f2f79605f3e8991b138 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:03,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10853\n",
      "2023-06-27 19:16:13,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10330 failed with Exception \n",
      "2023-06-27 19:16:14,344 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10330\n",
      "2023-06-27 19:16:24,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10350 failed with Exception \n",
      "2023-06-27 19:16:24,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10892\n",
      "2023-06-27 19:16:35,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10911\n",
      "2023-06-27 19:16:38,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 10861 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 80497a6f8159c0bfbdbdf5eecf649043 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:46,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10930\n",
      "2023-06-27 19:16:49,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 10882 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8e4887ab6cfa9220d191bc511866171c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:52,086 - \u001b[1;33mWARNING\u001b[1;0m - Request 10886 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b1d84711e3f3bd252b7f8366c65cf50b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:56,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10948\n",
      "2023-06-27 19:17:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10414 failed with Exception \n",
      "2023-06-27 19:17:07,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10967\n",
      "2023-06-27 19:17:12,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 10923 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c2fd72a3dc22b8b0dd6871d4457b2c69 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:18,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10986\n",
      "2023-06-27 19:17:19,302 - \u001b[1;33mWARNING\u001b[1;0m - Request 10935 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c0b19f764112c259f288eea61c800a7b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:19,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 10936 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d8e569a5c677647f381dd21ffb25e26 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:21,363 - \u001b[1;33mWARNING\u001b[1;0m - Request 10938 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53fd2a7b8a61438aa48b13afa3ccb559 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:28,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11003\n",
      "2023-06-27 19:17:29,865 - \u001b[1;33mWARNING\u001b[1;0m - Request 10953 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2098f9f4a5fbbcfbd5ec15ffec1604b8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:34,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10473 failed with Exception \n",
      "2023-06-27 19:17:39,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11021\n",
      "2023-06-27 19:17:40,065 - \u001b[1;33mWARNING\u001b[1;0m - Request 10971 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f8569a3b87675de2cfdff1a84c5b623 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:49,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10501 failed with Exception \n",
      "2023-06-27 19:17:50,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10501\n",
      "2023-06-27 19:18:00,744 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11059\n",
      "2023-06-27 19:18:11,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11079\n",
      "2023-06-27 19:18:21,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 11040 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 31edcdc098a58fe8871aaa72f109d8ff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:22,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11040\n",
      "2023-06-27 19:18:22,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 11043 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3c93eb234cc1819f26157b9cfca4de8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:27,939 - \u001b[1;33mWARNING\u001b[1;0m - Request 11053 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 856c9a2e61439f9f0a8dd67f3b1a7fd5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:32,649 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11116\n",
      "2023-06-27 19:18:39,565 - \u001b[1;33mWARNING\u001b[1;0m - Request 11075 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6b2c4c3b4dface6796afc056ce46705 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:18:40,609 - \u001b[1;33mWARNING\u001b[1;0m - Request 11077 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4d356031c9bd116f9b4497c5dc67cd1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:43,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11134\n",
      "2023-06-27 19:18:51,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 11098 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2241151df9b0c082ab3ba2eff4fa5584 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:53,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11153\n",
      "2023-06-27 19:19:04,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11173\n",
      "2023-06-27 19:19:15,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11193\n",
      "2023-06-27 19:19:15,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 11136 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 22808df11d14c1ed518123098338c3dc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:25,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11212\n",
      "2023-06-27 19:19:36,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11232\n",
      "2023-06-27 19:19:39,176 - \u001b[1;33mWARNING\u001b[1;0m - Request 11181 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f52d177f37a1befc8824d5806523ebc6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:39,633 - \u001b[1;33mWARNING\u001b[1;0m - Request 11182 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e47ff784171f0cbdd5909805caaa3e85 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:47,013 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11250\n",
      "2023-06-27 19:19:52,370 - \u001b[1;33mWARNING\u001b[1;0m - Request 11205 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 48349288abffb4f4385cf84830b3b9a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:54,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 11209 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 38cf495d7c55a0a1201aa2eb358f4009 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:56,084 - \u001b[1;33mWARNING\u001b[1;0m - Request 11212 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9a0ce57e728eea2f0f5878162bb40047 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:57,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11267\n",
      "2023-06-27 19:19:58,485 - \u001b[1;33mWARNING\u001b[1;0m - Request 11216 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c81726c2931dcd48b519e56df45cb66 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10743 failed with Exception \n",
      "2023-06-27 19:20:04,630 - \u001b[1;33mWARNING\u001b[1;0m - Request 11228 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fdfd1d26b8d4e94e55f04d1d9b2bca46 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:08,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11284\n",
      "2023-06-27 19:20:18,825 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11304\n",
      "2023-06-27 19:20:23,123 - \u001b[1;33mWARNING\u001b[1;0m - Request 11261 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9ee9562bbb8da1830f124433e0e02f77 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:24,771 - \u001b[1;33mWARNING\u001b[1;0m - Request 11218 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1506486553d1ab2d2aa7963e93699bf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:29,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11322\n",
      "2023-06-27 19:20:36,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 11281 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a9ac0b20ef6d094e2c56a47e76df5103 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:39,588 - \u001b[1;33mWARNING\u001b[1;0m - Request 11286 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 904896b5865a8ef2fa24a3f379c85af2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:40,027 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11341\n",
      "2023-06-27 19:20:40,632 - \u001b[1;33mWARNING\u001b[1;0m - Request 11288 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff05df4787d535d2bbd509224dcffa75 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:49,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 11302 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d24b95300004c117c09c7d043325d901 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:50,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11302\n",
      "2023-06-27 19:20:58,139 - \u001b[1;33mWARNING\u001b[1;0m - Request 11319 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d895199b7adc780ee85ee70de771aa39 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:01,234 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11377\n",
      "2023-06-27 19:21:05,555 - \u001b[1;33mWARNING\u001b[1;0m - Request 11333 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a508a9987bc9d0c664fe6b686bb75692 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:11,828 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:21:22,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11416\n",
      "2023-06-27 19:21:33,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11436\n",
      "2023-06-27 19:21:38,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 11390 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c35266a553aec34e863afec2793dd95d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:39,469 - \u001b[1;33mWARNING\u001b[1;0m - Request 11391 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ca20879a6cd72b3dadbc96c9e6f984b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:43,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11454\n",
      "2023-06-27 19:21:54,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11474\n",
      "2023-06-27 19:22:04,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11494\n",
      "2023-06-27 19:22:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10966 failed with Exception \n",
      "2023-06-27 19:22:15,213 - \u001b[1;33mWARNING\u001b[1;0m - Request 11456 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f6a9b11b7c7c0de6ee9e81bbbc4bd80d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:15,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11513\n",
      "2023-06-27 19:22:26,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11532\n",
      "2023-06-27 19:22:30,883 - \u001b[1;33mWARNING\u001b[1;0m - Request 11486 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4871ae3f62b555c3afa9f142fcac715e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:34,099 - \u001b[1;33mWARNING\u001b[1;0m - Request 11492 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5299585d5fa26117c32fedbc8a6d69bd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:36,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11550\n",
      "2023-06-27 19:22:37,782 - \u001b[1;33mWARNING\u001b[1;0m - Request 11499 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 878882345eee2388fff713cc4e939ddf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:42,594 - \u001b[1;33mWARNING\u001b[1;0m - Request 11507 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a2f40984361bc0b2e19e88e7a1d99242 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:47,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11568\n",
      "2023-06-27 19:22:48,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 11518 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0964f7fc998e3d4accbaea727ae5df2d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:57,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11587\n",
      "2023-06-27 19:23:07,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 11551 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 544056df68f2bd164628f95756bc11e0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:08,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11551\n",
      "2023-06-27 19:23:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11080 failed with Exception \n",
      "2023-06-27 19:23:19,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11625\n",
      "2023-06-27 19:23:29,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11645\n",
      "2023-06-27 19:23:40,349 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11665\n",
      "2023-06-27 19:23:44,590 - \u001b[1;33mWARNING\u001b[1;0m - Request 11616 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ec08b80f6e03856a5a3f7df055d6d72 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:47,218 - \u001b[1;33mWARNING\u001b[1;0m - Request 11621 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 88d6031534c64921c79a0db84802a9c5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:50,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11683\n",
      "2023-06-27 19:24:01,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11703\n",
      "2023-06-27 19:24:12,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11723\n",
      "2023-06-27 19:24:14,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 11673 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b93208f3065c8eae5464a0dcb0c485ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:19,292 - \u001b[1;33mWARNING\u001b[1;0m - Request 11679 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 43f56fa821b1747ab2687a44669a15b5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:22,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11741\n",
      "2023-06-27 19:24:29,787 - \u001b[1;33mWARNING\u001b[1;0m - Request 11699 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4a830cfc7e9c960e7bd311c80cf301ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:33,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11760\n",
      "2023-06-27 19:24:36,186 - \u001b[1;33mWARNING\u001b[1;0m - Request 11711 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eff36b1f06f5bb452bc061871a9c0892 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:38,864 - \u001b[1;33mWARNING\u001b[1;0m - Request 11716 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40338bdf2ba15bf584eab191efdf8a31 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:44,246 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11778\n",
      "2023-06-27 19:24:53,382 - \u001b[1;33mWARNING\u001b[1;0m - Request 11741 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9dd05e3ce392ddef5556c308196a572 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:24:54,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11797\n",
      "2023-06-27 19:24:56,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11265 failed with Exception \n",
      "2023-06-27 19:25:05,587 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11816\n",
      "2023-06-27 19:25:16,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11836\n",
      "2023-06-27 19:25:19,322 - \u001b[1;33mWARNING\u001b[1;0m - Request 11787 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1029ef566d6aa750576b1ad0a3da1c17 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:26,900 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11855\n",
      "2023-06-27 19:25:37,574 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11875\n",
      "2023-06-27 19:25:48,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11895\n",
      "2023-06-27 19:25:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11364 failed with Exception \n",
      "2023-06-27 19:25:58,795 - \u001b[1;33mWARNING\u001b[1;0m - Request 11858 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b966c87c1bc6be4835eeee446e053542 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:58,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11914\n",
      "2023-06-27 19:26:09,483 - \u001b[1;33mWARNING\u001b[1;0m - Request 11878 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8bdb15f581fa2a8530d83a755b92f43c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:09,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11933\n",
      "2023-06-27 19:26:12,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 11883 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c2c03a7d93a5755da07dfc2a2d606a07 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:17,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 11892 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID faa75faec60b61b4889382e56f2ff2e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:20,214 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11950\n",
      "2023-06-27 19:26:30,861 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11970\n",
      "2023-06-27 19:26:31,320 - \u001b[1;33mWARNING\u001b[1;0m - Request 11917 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 86dd91ef9e4ff0ec742224385ab3629c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:41,552 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11989\n",
      "2023-06-27 19:26:52,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12009\n",
      "2023-06-27 19:27:02,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12029\n",
      "2023-06-27 19:27:13,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12049\n",
      "2023-06-27 19:27:19,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 12003 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd426b28c91dfb5e2ac82c6a820417ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:27:24,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12068\n",
      "2023-06-27 19:27:25,948 - \u001b[1;33mWARNING\u001b[1;0m - Request 12015 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56559d01fae587e7f2671165f4e55882 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:27:34,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12087\n",
      "2023-06-27 19:27:38,015 - \u001b[1;33mWARNING\u001b[1;0m - Request 12038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 405aec2cfaa780551d7e1cdb491bcd42 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:27:45,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12106\n",
      "2023-06-27 19:27:56,189 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12126\n",
      "2023-06-27 19:28:06,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12146\n",
      "2023-06-27 19:28:08,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 12038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a8a675dfd88c80b3073f2bae2b825b28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:17,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12165\n",
      "2023-06-27 19:28:21,672 - \u001b[1;33mWARNING\u001b[1;0m - Request 12117 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a85a572ea09c90015c6246daf27f77df in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:28,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12184\n",
      "2023-06-27 19:28:31,998 - \u001b[1;33mWARNING\u001b[1;0m - Request 12136 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 464b7a9d964abbed97b2a4809b96e2de in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:38,835 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12203\n",
      "2023-06-27 19:28:49,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12223\n",
      "2023-06-27 19:29:00,189 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12243\n",
      "2023-06-27 19:29:04,342 - \u001b[1;33mWARNING\u001b[1;0m - Request 12194 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13146280cb4bc4a8dd702b5ca458a8d7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:07,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 12200 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f35ab6b4f90460ae31d53f98760695e6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:10,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12261\n",
      "2023-06-27 19:29:18,274 - \u001b[1;33mWARNING\u001b[1;0m - Request 12220 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 820dbe51cf8ba52589750db815b107c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:21,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12280\n",
      "2023-06-27 19:29:31,533 - \u001b[1;33mWARNING\u001b[1;0m - Request 12245 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69a0a9c5708fc86ec849fb09521874d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:29:32,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12245\n",
      "2023-06-27 19:29:38,083 - \u001b[1;33mWARNING\u001b[1;0m - Request 12256 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9678cdcd20ac37cf94c3a0b04491b9ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:40,641 - \u001b[1;33mWARNING\u001b[1;0m - Request 12260 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99e8d9dfd8ef52f6ecffa66e4f02bd9e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:41,155 - \u001b[1;33mWARNING\u001b[1;0m - Request 12261 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a79ac20917e8dd0942089a418718116 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:42,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12316\n",
      "2023-06-27 19:29:50,734 - \u001b[1;33mWARNING\u001b[1;0m - Request 12278 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6c2ea582ac4989d2ded1d67d1df9a1e2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:53,472 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12335\n",
      "2023-06-27 19:30:04,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12355\n",
      "2023-06-27 19:30:12,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 12315 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d552379bbefd25e4c5a9c526a1765696 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:13,673 - \u001b[1;33mWARNING\u001b[1;0m - Request 12317 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 91488633c3ef53f4fd536f8a365c90f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:14,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 12319 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e037ff01dae15304bf39180cdd09ba12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:14,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12373\n",
      "2023-06-27 19:30:25,391 - \u001b[1;33mWARNING\u001b[1;0m - Request 12338 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d15318fb03efba31046afba1bf43d6c4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:25,476 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12392\n",
      "2023-06-27 19:30:32,901 - \u001b[1;33mWARNING\u001b[1;0m - Request 12352 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6928682b8a851a4d1621e5642c1277f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:36,052 - \u001b[1;33mWARNING\u001b[1;0m - Request 12358 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4d08ae90ae730a6003101f2f0795ab14 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:36,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12410\n",
      "2023-06-27 19:30:46,796 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12429\n",
      "2023-06-27 19:30:57,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12449\n",
      "2023-06-27 19:31:08,122 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12469\n",
      "2023-06-27 19:31:13,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11938 failed with Exception \n",
      "2023-06-27 19:31:18,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12488\n",
      "2023-06-27 19:31:29,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12508\n",
      "2023-06-27 19:31:39,101 - \u001b[1;33mWARNING\u001b[1;0m - Request 12470 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40c894587c3c6a0af44d85f189a96d87 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:31:40,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12470\n",
      "2023-06-27 19:31:50,778 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12547\n",
      "2023-06-27 19:31:51,265 - \u001b[1;33mWARNING\u001b[1;0m - Request 12492 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cc2e03d9274c11d14ebb95d6a5521a00 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:01,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12566\n",
      "2023-06-27 19:32:12,108 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12586\n",
      "2023-06-27 19:32:15,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 12537 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d86650ff874beeef34e63f3f2f78abb5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:22,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12605\n",
      "2023-06-27 19:32:30,125 - \u001b[1;33mWARNING\u001b[1;0m - Request 12563 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4da8d61f098f4ec3fc8de259d61426b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:33,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12624\n",
      "2023-06-27 19:32:44,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12644\n",
      "2023-06-27 19:32:47,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 12595 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 73b88bee22bb5f3f8177ae25baad88e7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:48,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 12597 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae9605caf682c71514624f30bb0a3349 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:54,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12662\n",
      "2023-06-27 19:33:02,700 - \u001b[1;33mWARNING\u001b[1;0m - Request 12622 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cde28afb419a1421e087afbfac61213b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:33:05,448 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12681\n",
      "2023-06-27 19:33:16,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12701\n",
      "2023-06-27 19:33:23,520 - \u001b[1;33mWARNING\u001b[1;0m - Request 12659 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42cd9c1799ffedd252fd6b1fe16e8a00 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:26,792 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12720\n",
      "2023-06-27 19:33:37,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12740\n",
      "2023-06-27 19:33:37,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 12685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 086f5fef7d19217e0ebd9544698550aa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:42,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 12694 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19b7c4efa27db2fb8c47117dc0479eba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:48,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12758\n",
      "2023-06-27 19:33:58,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12778\n",
      "2023-06-27 19:33:59,219 - \u001b[1;33mWARNING\u001b[1;0m - Request 12724 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0f247be1a4eea102495c502d18aeb81 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:00,912 - \u001b[1;33mWARNING\u001b[1;0m - Request 12727 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3ba2900fcb83a3fb37cd77f225652613 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:05,088 - \u001b[1;33mWARNING\u001b[1;0m - Request 12735 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2e538a2275f00b509c3434ed602dddcf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:06,153 - \u001b[1;33mWARNING\u001b[1;0m - Request 12737 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd980bde5652ad0af2bd3116405afbfc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:06,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 12738 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47f2a893c58f1e4afa20ebe276248118 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:08,840 - \u001b[1;33mWARNING\u001b[1;0m - Request 12685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 914f794f1320bae2698aff9851c5091f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:09,470 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12685\n",
      "2023-06-27 19:34:20,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12812\n",
      "2023-06-27 19:34:30,801 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12832\n",
      "2023-06-27 19:34:41,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12852\n",
      "2023-06-27 19:34:41,571 - \u001b[1;33mWARNING\u001b[1;0m - Request 12685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d47373914ab4b420b5e35e3185528009 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12278 failed with Exception \n",
      "2023-06-27 19:34:52,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12278\n",
      "2023-06-27 19:34:57,892 - \u001b[1;33mWARNING\u001b[1;0m - Request 12826 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd4284451a9210db3b42f67d1e413aa2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:35:02,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12889\n",
      "2023-06-27 19:35:13,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12909\n",
      "2023-06-27 19:35:18,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 12864 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7698e63bcb48950b5ea17218a09d954 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:35:24,097 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12928\n",
      "2023-06-27 19:35:34,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12948\n",
      "2023-06-27 19:35:37,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 12897 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 00d449d28083b0ce3348907246091246 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:35:45,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12967\n",
      "2023-06-27 19:35:56,103 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12987\n",
      "2023-06-27 19:35:59,673 - \u001b[1;33mWARNING\u001b[1;0m - Request 12902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e8ff1ce5abe873fcfb189c8fea5bf3e6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:06,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13006\n",
      "2023-06-27 19:36:17,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13026\n",
      "2023-06-27 19:36:23,738 - \u001b[1;33mWARNING\u001b[1;0m - Request 12982 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 83baa1316346f48baa41dd754458a189 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:28,088 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13045\n",
      "2023-06-27 19:36:30,657 - \u001b[1;33mWARNING\u001b[1;0m - Request 12902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 675dc75d5b474de59936901dfc785661 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:34,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 13001 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 36df8bf6d1505d6ee454e2f28b119d23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:36:38,736 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13063\n",
      "2023-06-27 19:36:48,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 13028 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5c25601891e6ee76481fd1b9184cdd0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:49,401 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13028\n",
      "2023-06-27 19:37:00,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13102\n",
      "2023-06-27 19:37:02,093 - \u001b[1;33mWARNING\u001b[1;0m - Request 13051 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b6d4a00c216424f404b4a2505889d0a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:10,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13121\n",
      "2023-06-27 19:37:21,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13141\n",
      "2023-06-27 19:37:22,349 - \u001b[1;33mWARNING\u001b[1;0m - Request 13087 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f751cf91b35716fc025a202bc02a6d6b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:32,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13160\n",
      "2023-06-27 19:37:42,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13180\n",
      "2023-06-27 19:37:51,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 13141 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 420fbdcb8e2902886f353bd03ef418e3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:53,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13199\n",
      "2023-06-27 19:37:56,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 13149 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8bc806f0be3f68c8487cd7fa2bbbc474 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:02,957 - \u001b[1;33mWARNING\u001b[1;0m - Request 13161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0b58c8a1345761215ed0b23e475331e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:04,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13217\n",
      "2023-06-27 19:38:14,312 - \u001b[1;33mWARNING\u001b[1;0m - Request 13182 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0e2ee4133a86cc7fc01c07e236c887b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:14,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13237\n",
      "2023-06-27 19:38:16,775 - \u001b[1;33mWARNING\u001b[1;0m - Request 13187 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 23bfc8472b771872043ab72b1a0d9d32 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:25,362 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13255\n",
      "2023-06-27 19:38:33,808 - \u001b[1;33mWARNING\u001b[1;0m - Request 13161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c6222a13298ae88c6c0795738db5732 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:36,024 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13274\n",
      "2023-06-27 19:38:46,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13294\n",
      "2023-06-27 19:38:55,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 13255 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db2ffd1499a63d28856f927e9762ccfc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:57,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 13258 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b00b6c643c418994b0472de2f77fd19 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:57,318 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13313\n",
      "2023-06-27 19:39:07,981 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13332\n",
      "2023-06-27 19:39:18,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13352\n",
      "2023-06-27 19:39:29,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13372\n",
      "2023-06-27 19:39:39,968 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13392\n",
      "2023-06-27 19:39:50,610 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13412\n",
      "2023-06-27 19:40:01,266 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13432\n",
      "2023-06-27 19:40:11,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13452\n",
      "2023-06-27 19:40:22,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13472\n",
      "2023-06-27 19:40:33,204 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13492\n",
      "2023-06-27 19:40:43,880 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13512\n",
      "2023-06-27 19:40:54,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13532\n",
      "2023-06-27 19:41:05,189 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13552\n",
      "2023-06-27 19:41:15,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13572\n",
      "2023-06-27 19:41:26,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13592\n",
      "2023-06-27 19:41:37,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13612\n",
      "2023-06-27 19:41:47,866 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13632\n",
      "2023-06-27 19:41:58,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13652\n",
      "2023-06-27 19:42:09,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13672\n",
      "2023-06-27 19:42:19,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13692\n",
      "2023-06-27 19:42:30,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13712\n",
      "2023-06-27 19:42:41,169 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13732\n",
      "2023-06-27 19:42:51,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13752\n",
      "2023-06-27 19:43:02,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13772\n",
      "2023-06-27 19:43:13,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13792\n",
      "2023-06-27 19:43:23,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13812\n",
      "2023-06-27 19:43:34,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13832\n",
      "2023-06-27 19:43:45,143 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13852\n",
      "2023-06-27 19:43:55,796 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13872\n",
      "2023-06-27 19:44:06,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13892\n",
      "2023-06-27 19:44:17,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13912\n",
      "2023-06-27 19:44:27,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13932\n",
      "2023-06-27 19:44:38,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13952\n",
      "2023-06-27 19:44:49,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13972\n",
      "2023-06-27 19:44:59,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13992\n",
      "2023-06-27 19:45:10,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14012\n",
      "2023-06-27 19:45:21,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14032\n",
      "2023-06-27 19:45:31,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14052\n",
      "2023-06-27 19:45:42,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14072\n",
      "2023-06-27 19:45:53,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14092\n",
      "2023-06-27 19:46:03,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14112\n",
      "2023-06-27 19:46:14,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:46:25,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14152\n",
      "2023-06-27 19:46:35,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14172\n",
      "2023-06-27 19:46:46,399 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14192\n",
      "2023-06-27 19:46:57,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14212\n",
      "2023-06-27 19:47:07,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14232\n",
      "2023-06-27 19:47:18,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14252\n",
      "2023-06-27 19:47:29,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14272\n",
      "2023-06-27 19:47:39,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14292\n",
      "2023-06-27 19:47:50,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14312\n",
      "2023-06-27 19:48:00,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14332\n",
      "2023-06-27 19:48:11,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14352\n",
      "2023-06-27 19:48:22,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14372\n",
      "2023-06-27 19:48:32,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14392\n",
      "2023-06-27 19:48:43,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14412\n",
      "2023-06-27 19:48:54,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14432\n",
      "2023-06-27 19:49:04,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14452\n",
      "2023-06-27 19:49:15,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14472\n",
      "2023-06-27 19:49:26,214 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14492\n",
      "2023-06-27 19:49:36,862 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14512\n",
      "2023-06-27 19:49:47,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14532\n",
      "2023-06-27 19:49:58,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14552\n",
      "2023-06-27 19:50:08,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14572\n",
      "2023-06-27 19:50:19,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14592\n",
      "2023-06-27 19:50:30,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14612\n",
      "2023-06-27 19:50:40,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14632\n",
      "2023-06-27 19:50:51,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14652\n",
      "2023-06-27 19:51:02,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14672\n",
      "2023-06-27 19:51:12,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14692\n",
      "2023-06-27 19:51:23,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14712\n",
      "2023-06-27 19:51:33,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14732\n",
      "2023-06-27 19:51:44,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14752\n",
      "2023-06-27 19:51:55,214 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14772\n",
      "2023-06-27 19:52:05,841 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14792\n",
      "2023-06-27 19:52:16,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14812\n",
      "2023-06-27 19:52:27,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14832\n",
      "2023-06-27 19:52:37,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14852\n",
      "2023-06-27 19:52:48,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14872\n",
      "2023-06-27 19:52:59,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14892\n",
      "2023-06-27 19:53:09,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14912\n",
      "2023-06-27 19:53:20,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14932\n",
      "2023-06-27 19:53:30,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14952\n",
      "2023-06-27 19:53:41,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14972\n",
      "2023-06-27 19:53:52,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14992\n",
      "2023-06-27 19:53:55,464 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_173519.jsonl\n",
      "2023-06-27 19:53:55,468 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_173519.jsonl\n",
      "2023-06-27 19:53:55,937 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Dikting machine cut off\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,937 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the inconvenience. Could you please provide the medical fact again?, returning default object\n",
      "2023-06-27 19:53:55,938 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not familiar with the term \"PIF VERSION\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,939 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"IVA PHONE\". Can you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,939 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...\"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 555, \"completion_tokens\": 41, \"total_tokens\": 596}}, {\"fact\": \"Tip of what? (missing context)\"}] for fact \"Tip of what? (missing context)\": Could not parse output: I apologize for the confusion. The given medical fact refers to observations or findings in medical imaging, such as X-rays or CT scans. The output JSON object should describe the location and nature of the observation.\n",
      "2023-06-27 19:53:55,940 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... to assist.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 10, \"total_tokens\": 559}}, {\"fact\": \"Late submission\"}] for fact \"Late submission\": Could not parse output: I apologize, but I'm unable to assist.\n",
      "2023-06-27 19:53:55,940 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"correlation with specifics of clinical scenario requested\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,940 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: To ensure resolution, please provide the medical fact or observation for which you would like the JSON object to be generated., returning default object\n",
      "2023-06-27 19:53:55,941 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am an AI language model and I cannot make phone calls. However, I can assist you with any questions or information you need. How can I help you?, returning default object\n",
      "2023-06-27 19:53:55,941 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the error. Could you please provide the correct medical fact?, returning default object\n",
      "2023-06-27 19:53:55,943 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I cannot generate the JSON object without the original report. Please provide the medical fact or the original report so that I can assist you further., returning default object\n",
      "2023-06-27 19:53:55,943 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're asking for. Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,943 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... are\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 200, \"total_tokens\": 751}}, {\"fact\": \"Loss to explain why\"}] for fact \"Loss to explain why\": Could not parse output: I apologize for the confusion. Here is the explanation:\n",
      "\n",
      "The task is to generate a JSON object with three fields: \"location\", \"specific\", and \"general\" based on a given medical fact. The \"location\" field should contain the anatomical location of the observation if provided, otherwise it should be empty. The \"specific\" field refers to the specific observation, and the \"general\" field refers to a more general term for the observation.\n",
      "\n",
      "In the examples provided, the JSON objects are generated based on the given medical facts. The \"location\" field contains the anatomical location of the observation if provided, such as \"left base\", \"left lower lung\", \"retrocardiac position\", etc. If the anatomical location is not provided, the \"location\" field is empty.\n",
      "\n",
      "The \"specific\" field contains the specific observation, such as \"linear opacity\", \"linear bands of atelectasis\", \"triangular-shaped density\", etc. If additional attributes are provided, they are\n",
      "2023-06-27 19:53:55,944 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information in order to generate the JSON object. Could you please provide the medical fact or observation that you discussed with Dr.?, returning default object\n",
      "2023-06-27 19:53:55,946 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Shoule consideration\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,946 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information to provide a response. Could you please provide a specific medical fact or observation related to radiology?, returning default object\n",
      "2023-06-27 19:53:55,946 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"line that defines it\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,949 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to understand your request. Could you please provide more information or clarify your question?, returning default object\n",
      "2023-06-27 19:53:55,950 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Cn advance\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,950 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Unable to decipher\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,951 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Thank you! I'm glad you think so. If you have any specific medical facts or examples you'd like me to generate JSON objects for, please let me know., returning default object\n",
      "2023-06-27 19:53:55,954 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 200, \"total_tokens\": 752}}, {\"fact\": \"Region needs to be clarified\"}] for fact \"Region needs to be clarified\": Could not parse output: If the region needs to be clarified, you can include it as a separate field in the JSON object called \"region\". The \"location\" field should still contain the anatomical location, if provided. Here are some examples:\n",
      "\n",
      "Linear opacity at left base in the lower lobe\n",
      "{\n",
      "\"region\": \"lower lobe\",\n",
      "\"location\": \"left base\",\n",
      "\"specific\": \"linear opacity\",\n",
      "\"general\": \"opacity\"\n",
      "}\n",
      "\n",
      "Triangular-shaped density in retrocardiac position in the upper lobe\n",
      "{\n",
      "\"region\": \"upper lobe\",\n",
      "\"location\": \"retrocardiac position\",\n",
      "\"specific\": \"triangular-shaped density\",\n",
      "\"general\": \"density\"\n",
      "}\n",
      "\n",
      "Parenchymal densities in the posterior portion of the left lower lobe in the middle lobe\n",
      "{\n",
      "\"region\": \"middle lobe\",\n",
      "\"location\": \"posterior portion of the left lower lobe\",\n",
      "\"specific\": \"parenchymal densities\",\n",
      "\"general\": \"densities\"\n",
      "}\n",
      "\n",
      "Peripheral band\n",
      "2023-06-27 19:53:55,954 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...iven.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 120, \"total_tokens\": 670}}, {\"fact\": \"Expectable locations\"}] for fact \"Expectable locations\": Could not parse output: The possible values for the \"location\" field can vary depending on the medical fact provided. Here are some examples of expectable locations:\n",
      "\n",
      "- Left base\n",
      "- Left lower lung\n",
      "- Left lower lobe\n",
      "- Retrocardiac position\n",
      "- Adjacent to the left heart border\n",
      "- Posterior portion of the left lower lobe\n",
      "- Left mid and lower lung\n",
      "- Lingular segment of the left lobe\n",
      "- Left fourth rib\n",
      "- Aorta\n",
      "\n",
      "These are just a few examples, and the actual value of the \"location\" field will depend on the specific medical fact given.\n",
      "2023-06-27 19:53:55,956 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\..._reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 197, \"total_tokens\": 749}}, {\"fact\": \"Repeat with more optimized technique\"}] for fact \"Repeat with more optimized technique\": Could not parse output: def parse_medical_fact(fact):\n",
      "    location = \"\"\n",
      "    specific = \"\"\n",
      "    general = \"\"\n",
      "    \n",
      "    # Split the fact into words\n",
      "    words = fact.split()\n",
      "    \n",
      "    # Check if the fact contains an anatomical location\n",
      "    if \"in\" in words:\n",
      "        location_start = words.index(\"in\") + 1\n",
      "        location_end = len(words)\n",
      "        location = \" \".join(words[location_start:location_end])\n",
      "    \n",
      "    # Check if the fact contains a specific observation\n",
      "    if \"of\" in words:\n",
      "        specific_start = words.index(\"of\") + 1\n",
      "        specific_end = len(words)\n",
      "        specific = \" \".join(words[specific_start:specific_end])\n",
      "    \n",
      "    # Check if the fact contains a general observation\n",
      "    if specific == \"\":\n",
      "        general = fact\n",
      "    else:\n",
      "        general = specific\n",
      "    \n",
      "    return {\n",
      "        \"location\": location,\n",
      "        \"specific\": specific,\n",
      "        \"general\": general\n",
      "    }\n",
      "2023-06-27 19:53:55,959 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"follow-sided diagnosis\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 19:53:55,959 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... empty.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 117, \"total_tokens\": 666}}, {\"fact\": \"Requirement needed\"}] for fact \"Requirement needed\": Could not parse output: The requirement is to create a JSON object with 3 fields: \"location\", \"specific\", and \"general\" based on a given medical fact. The \"location\" field should contain the anatomical location of the observation if provided, otherwise it should be empty. The \"specific\" and \"general\" fields both refer to the observation. The \"general\" field should be very short, while the \"specific\" field should contain additional attributes if provided. If only an anatomical location is provided but the observation is missing, both \"specific\" and \"general\" should be empty.\n",
      "2023-06-27 19:53:55,959 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...n(\\\"left mid\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"View needed\"}] for fact \"View needed\": Could not parse output: I apologize for the confusion. Here is the code that will generate the JSON object based on the given medical fact:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def generate_json(location, specific, general):\n",
      "    data = {\n",
      "        \"location\": location,\n",
      "        \"specific\": specific,\n",
      "        \"general\": general\n",
      "    }\n",
      "    return json.dumps(data)\n",
      "\n",
      "# Examples\n",
      "print(generate_json(\"left base\", \"linear opacity\", \"opacity\"))\n",
      "print(generate_json(\"left lower lung\", \"linear bands of atelectasis\", \"atelectasis\"))\n",
      "print(generate_json(\"left lower lobe\", \"linear densities\", \"densities\"))\n",
      "print(generate_json(\"retrocardiac position\", \"triangular-shaped density\", \"density\"))\n",
      "print(generate_json(\"adjacent to the left heart border\", \"aortic mass\", \"mass\"))\n",
      "print(generate_json(\"posterior portion of the left lower lobe\", \"parenchymal densities\", \"densities\"))\n",
      "print(generate_json(\"left mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:53:55,965 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"irregular entries\". Could you please provide more information or examples?, returning default object\r\n",
      "2023-06-27 19:53:55,966 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"second incident\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,966 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...uired JSON\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"Plan approach\"}] for fact \"Plan approach\": Could not parse output: To solve this problem, we can follow these steps:\r\n",
      "\r\n",
      "1. Split the input medical fact into individual words.\r\n",
      "2. Identify the anatomical location by searching for specific keywords such as \"left\", \"right\", \"upper\", \"lower\", \"lobe\", \"segment\", \"base\", \"border\", etc.\r\n",
      "3. Identify the observation by searching for specific keywords such as \"opacity\", \"density\", \"mass\", \"atelectasis\", \"effusion\", etc.\r\n",
      "4. If an anatomical location is found, assign it to the \"location\" field in the JSON object. Otherwise, leave it empty.\r\n",
      "5. If an observation is found, assign it to both the \"specific\" and \"general\" fields in the JSON object. Otherwise, leave both fields empty.\r\n",
      "6. If additional attributes are found for the observation, append them to the \"specific\" field in the JSON object.\r\n",
      "\r\n",
      "By following these steps, we can extract the relevant information from the medical fact and generate the required JSON\r\n",
      "2023-06-27 19:53:55,967 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"informative views\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,970 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"dynamic changes\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,970 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"larger contributor\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,971 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Kunse resolution\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,971 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize if there was any confusion. Could you please provide me with the medical fact or observation that you would like me to generate the JSON object for?, returning default object\r\n",
      "2023-06-27 19:53:55,973 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Hilfful evaluation\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,974 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...nts.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 55, \"total_tokens\": 606}}, {\"fact\": \"Feasibility evaluation\"}] for fact \"Feasibility evaluation\": Could not parse output: The task of generating a JSON object with the given fields based on a medical fact is feasible. It involves parsing the medical fact to extract the relevant information such as anatomical location, specific observation, and general observation. The logic can be implemented using string manipulation and conditional statements.\r\n",
      "2023-06-27 19:53:55,978 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Similar to 9:42am\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,980 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...m\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Generalization process\"}] for fact \"Generalization process\": Could not parse output: To generalize the medical fact, we need to identify the main observation or finding and categorize it into a more general term. This involves understanding the specific attributes or characteristics of the observation and determining a broader term that encompasses those attributes.\r\n",
      "\r\n",
      "Here is a step-by-step process to generalize the medical fact:\r\n",
      "\r\n",
      "1. Identify the main observation or finding: Read the medical fact and identify the key observation or finding mentioned. This could be a specific abnormality, condition, or characteristic.\r\n",
      "\r\n",
      "2. Determine the specific attributes: Look for any additional attributes or details provided in the medical fact that describe the observation. These attributes could include the shape, location, size, or any other specific characteristic.\r\n",
      "\r\n",
      "3. Categorize into a general term: Based on the specific attributes, categorize the observation into a more general term that encompasses those attributes. This general term should be a broader category or concept that the specific observation falls under.\r\n",
      "\r\n",
      "4. Assign the general term to the \"general\" field: Assign the determined general term\r\n",
      "2023-06-27 19:53:55,982 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...sion\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 129, \"total_tokens\": 681}}, {\"fact\": \"Possible possiblities\"}] for fact \"Possible possiblities\": Could not parse output: 1. Linear opacity at left base\r\n",
      "2. Linear bands of atelectasis in the left lower lung\r\n",
      "3. Left lower lobe linear densities\r\n",
      "4. Triangular-shaped density in retrocardiac position\r\n",
      "5. Aortic mass adjacent to the left heart border\r\n",
      "6. Parenchymal densities in the posterior portion of the left lower lobe\r\n",
      "7. Peripheral band-like opacities in left mid and lower lung\r\n",
      "8. Atelectasis in the lingular segment of the left lobe\r\n",
      "9. Mass involving left fourth rib\r\n",
      "10. Left base\r\n",
      "11. Aorta\r\n",
      "12. Pleural effusion\r\n",
      "2023-06-27 19:53:55,982 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"multiple prioritization\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,982 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"multiple priorities\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,983 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Improved eppars\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,989 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"TECHnical changes\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,993 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize if my previous response was unclear. Could you please provide me with a medical fact or observation that you would like me to generate a JSON object for?, returning default object\r\n",
      "2023-06-27 19:53:55,994 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ur vous aider.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 38, \"total_tokens\": 588}}, {\"fact\": \"Enqu\\u00eate\"}] for fact \"Enquête\": Could not parse output: Je suis désolé, je ne comprends pas votre demande. Pouvez-vous fournir plus de détails ou poser une question spécifique ? Je suis là pour vous aider.\r\n",
      "2023-06-27 19:53:55,994 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information in order to provide the correct output. Could you please provide the medical fact that you would like me to process?, returning default object\r\n",
      "2023-06-27 19:53:55,994 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information in order to provide a response. Could you please provide the medical fact or observation that you would like me to process?, returning default object\r\n",
      "2023-06-27 19:53:55,994 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... a given medical fact.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 548, \"completion_tokens\": 28, \"total_tokens\": 576}}, {\"fact\": \"Goal\"}] for fact \"Goal\": Could not parse output: The goal is to create a JSON object with the fields \"location\", \"specific\", and \"general\" based on a given medical fact.\r\n",
      "2023-06-27 19:53:55,994 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're asking for. Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,995 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Repeatment\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,995 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"expolations\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,996 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"replacements\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,997 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Processing\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,998 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"SUB\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,998 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"embolded bullets\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,999 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"persist\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,999 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Reformats\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,999 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Spezification\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,999 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Tuschale\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:55,999 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"configurations\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,000 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate an interview for you. I can only assist with providing information or answering questions. Is there anything specific you would like to know or discuss?, returning default object\r\n",
      "2023-06-27 19:53:56,000 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...d are correct.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 9, \"total_tokens\": 558}}, {\"fact\": \"Confirmations\"}] for fact \"Confirmations\": Could not parse output: I confirm that the examples provided are correct.\r\n",
      "2023-06-27 19:53:56,000 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Ornalization\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,001 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ld be empty.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 127, \"total_tokens\": 676}}, {\"fact\": \"Justification\"}] for fact \"Justification\": Could not parse output: The task requires parsing a medical fact and extracting relevant information such as anatomical location, specific observation, and a general description. This information can be used for further analysis or categorization of medical observations. The output format is a JSON object with three fields: \"location\", \"specific\", and \"general\". The \"location\" field contains the anatomical location if provided, otherwise it is empty. The \"specific\" field contains the specific observation, and the \"general\" field contains a more general description. If only an anatomical location is provided without an observation, both the \"specific\" and \"general\" fields should be empty.\r\n",
      "2023-06-27 19:53:56,001 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"ENGrainment\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,001 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Coding\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,001 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide a medical fact or observation?, returning default object\r\n",
      "2023-06-27 19:53:56,002 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"manipulations\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,002 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Could you please provide me with a medical fact so that I can generate the JSON object for you?, returning default object\r\n",
      "2023-06-27 19:53:56,002 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Dodoff\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,004 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to refer to a radiologist. I can only provide information based on the medical facts given to me. If you have any specific medical questions or concerns, I recommend consulting with a qualified healthcare professional or radiologist., returning default object\r\n",
      "2023-06-27 19:53:56,004 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"cross table view\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,005 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Tentative to consolidate\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,007 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I cannot process voice messages. Please provide the medical fact as text so that I can assist you., returning default object\r\n",
      "2023-06-27 19:53:56,008 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"modification of interpretation\". Could you please provide more details or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,010 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to resolve etiologies. My purpose is to generate JSON objects based on medical facts. If you have any medical facts that you would like me to process, please provide them and I'll be happy to assist you., returning default object\r\n",
      "2023-06-27 19:53:56,011 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Refer to use\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,011 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm here to help! Please go ahead and ask your serious questions., returning default object\r\n",
      "2023-06-27 19:53:56,011 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for any confusion. Could you please provide the medical fact that you would like me to process?, returning default object\r\n",
      "2023-06-27 19:53:56,012 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"diagnostic alternatives\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,015 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ns\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"Technical perspective\"}] for fact \"Technical perspective\": Could not parse output: To solve this problem, we can use regular expressions to extract the relevant information from the medical fact. We can define patterns for anatomical locations, specific observations, and general observations. \r\n",
      "\r\n",
      "First, we can check if the medical fact contains an anatomical location by searching for specific keywords such as \"base\", \"lobe\", \"segment\", \"position\", \"border\", etc. If a match is found, we can extract the location and remove it from the medical fact.\r\n",
      "\r\n",
      "Next, we can search for specific observations by looking for keywords such as \"opacity\", \"density\", \"mass\", \"effusion\", etc. If a match is found, we can extract the specific observation and remove it from the medical fact.\r\n",
      "\r\n",
      "Finally, if there are no specific observations remaining in the medical fact, we can assume that the general observation is the same as the specific observation. Otherwise, the general observation can be a more general term for the specific observation.\r\n",
      "\r\n",
      "Once we have extracted the location, specific, and general observations\r\n",
      "2023-06-27 19:53:56,016 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ist you?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 8, \"total_tokens\": 558}}, {\"fact\": \"Assistance required\"}] for fact \"Assistance required\": Could not parse output: Sure! How can I assist you?\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:53:56,021 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ssist you?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 9, \"total_tokens\": 559}}, {\"fact\": \"Assistance needed\"}] for fact \"Assistance needed\": Could not parse output: Of course! How can I assist you?\r\n",
      "2023-06-27 19:53:56,022 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"different orientations\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,032 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 200, \"total_tokens\": 752}}, {\"fact\": \"Better charachterization\"}] for fact \"Better charachterization\": Could not parse output: I apologize for any confusion. Here is a revised explanation:\r\n",
      "\r\n",
      "Given a medical fact, the task is to generate a JSON object with three fields: \"location\", \"specific\", and \"general\". The \"location\" field should contain the anatomical location of the observation if provided, otherwise it should be empty. The \"specific\" field refers to the specific observation and should be as detailed as possible. The \"general\" field should provide a more general description of the observation.\r\n",
      "\r\n",
      "If both the anatomical location and the specific observation are provided, the \"location\" field should contain the anatomical location, the \"specific\" field should contain the specific observation, and the \"general\" field should provide a more general description of the observation.\r\n",
      "\r\n",
      "If only the anatomical location is provided and the specific observation is missing, the \"location\" field should contain the anatomical location, and both the \"specific\" and \"general\" fields should be empty.\r\n",
      "\r\n",
      "If only the specific observation is provided and the anatomical\r\n",
      "2023-06-27 19:53:56,033 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Could you please provide me with the medical fact that you would like to process?, returning default object\r\n",
      "2023-06-27 19:53:56,037 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...while\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 200, \"total_tokens\": 751}}, {\"fact\": \"Emphasis on extent\"}] for fact \"Emphasis on extent\": Could not parse output: To add emphasis on the extent of the observation, you can include an additional field called \"extent\" in the JSON object. The \"extent\" field should describe the size or severity of the observation. Here's an example:\r\n",
      "\r\n",
      "Linear opacity at left base, extensive\r\n",
      "{\r\n",
      "\"location\": \"left base\",\r\n",
      "\"specific\": \"linear opacity\",\r\n",
      "\"general\": \"opacity\",\r\n",
      "\"extent\": \"extensive\"\r\n",
      "}\r\n",
      "\r\n",
      "Triangular-shaped density in retrocardiac position, small\r\n",
      "{\r\n",
      "\"location\": \"retrocardiac position\",\r\n",
      "\"specific\": \"triangular-shaped density\",\r\n",
      "\"general\": \"density\",\r\n",
      "\"extent\": \"small\"\r\n",
      "}\r\n",
      "\r\n",
      "Parenchymal densities in the posterior portion of the left lower lobe, moderate\r\n",
      "{\r\n",
      "\"location\": \"posterior portion of the left lower lobe\",\r\n",
      "\"specific\": \"parenchymal densities\",\r\n",
      "\"general\": \"densities\",\r\n",
      "\"extent\": \"moderate\"\r\n",
      "}\r\n",
      "\r\n",
      "This way, you can provide additional information about the extent of the observation while\r\n",
      "2023-06-27 19:53:56,039 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...lds, and\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"Resolve process\"}] for fact \"Resolve process\": Could not parse output: To resolve the given task, we can follow these steps:\r\n",
      "\r\n",
      "1. Parse the input to extract the relevant information, such as the anatomical location and the observation.\r\n",
      "2. Check if both the anatomical location and the observation are provided. If not, set the \"specific\" and \"general\" fields to empty strings.\r\n",
      "3. If both the anatomical location and the observation are provided, set the \"location\" field to the anatomical location, and set the \"specific\" and \"general\" fields to the observation.\r\n",
      "4. If only the anatomical location is provided, set the \"location\" field to the anatomical location, and set the \"specific\" and \"general\" fields to empty strings.\r\n",
      "5. If only the observation is provided, set the \"location\" field to an empty string, and set the \"specific\" and \"general\" fields to the observation.\r\n",
      "6. Create a JSON object with the \"location\", \"specific\", and \"general\" fields, and\r\n",
      "2023-06-27 19:53:56,047 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"construct\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,047 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Situation\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,048 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Pings\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,048 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...or inflammation.\\\"\\n}\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 548, \"completion_tokens\": 72, \"total_tokens\": 620}}, {\"fact\": \"Bonus\"}] for fact \"Bonus\": Could not parse output: Sure! Here's an example with all the fields, including a bonus field called \"notes\" which can contain any additional information related to the observation:\r\n",
      "\r\n",
      "Linear opacity at left base\r\n",
      "{\r\n",
      "\"location\": \"left base\",\r\n",
      "\"specific\": \"linear opacity\",\r\n",
      "\"general\": \"opacity\",\r\n",
      "\"notes\": \"Opacity may indicate a possible lung infection or inflammation.\"\r\n",
      "}\r\n",
      "2023-06-27 19:53:56,048 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Re-inserted\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,048 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Disses\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,049 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ntent\": \"import json\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 548, \"completion_tokens\": 2, \"total_tokens\": 550}}, {\"fact\": \"Package\"}] for fact \"Package\": Could not parse output: import json\r\n",
      "2023-06-27 19:53:56,049 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're asking. Could you please provide more information or clarify your question?, returning default object\r\n",
      "2023-06-27 19:53:56,050 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Addition\". Could you please provide more context or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,050 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to perform the extraction for you. My purpose is to provide information and answer questions based on the given medical fact., returning default object\r\n",
      "2023-06-27 19:53:56,050 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Clier\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,051 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're asking for. Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,051 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Could you please provide me with the medical fact again so that I can generate the JSON object correctly?, returning default object\r\n",
      "2023-06-27 19:53:56,052 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate a response based on the input you provided. Can you please provide a medical fact or observation for me to work with?, returning default object\r\n",
      "2023-06-27 19:53:56,053 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I need a medical fact in order to provide the requested output. Could you please provide a medical fact?, returning default object\r\n",
      "2023-06-27 19:53:56,053 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 72, \"total_tokens\": 623}}, {\"fact\": \"Radiology communications dashboard\"}] for fact \"Radiology communications dashboard\": Could not parse output: {\r\n",
      "  \"dashboard\": \"radiology communications\",\r\n",
      "  \"fields\": [\r\n",
      "    {\r\n",
      "      \"name\": \"location\",\r\n",
      "      \"type\": \"string\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "      \"name\": \"specific\",\r\n",
      "      \"type\": \"string\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "      \"name\": \"general\",\r\n",
      "      \"type\": \"string\"\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\r\n",
      "2023-06-27 19:53:56,053 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"differentiation between possibilities\". Could you please provide more information or clarify your question?, returning default object\r\n",
      "2023-06-27 19:53:56,055 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Incorrectly entered\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,056 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the inconvenience. Could you please provide the medical fact again?, returning default object\r\n",
      "2023-06-27 19:53:56,060 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...usage\": {\"prompt_tokens\": 553, \"completion_tokens\": 84, \"total_tokens\": 637}}, {\"fact\": \"Additional considerations in appropriate clinical settings\"}] for fact \"Additional considerations in appropriate clinical settings\": Could not parse output: In appropriate clinical settings, there are additional considerations to take into account when providing the medical fact. These considerations may include the patient's medical history, symptoms, physical examination findings, and any relevant diagnostic test results. These factors can help in determining the significance and appropriate management of the observation. It is important to consult with a healthcare professional for a comprehensive evaluation and interpretation of the medical fact in the context of the individual patient.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:53:56,073 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Two EXAMS\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,073 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information in order to provide a response. Could you please clarify what you mean by \"two keys\"?, returning default object\r\n",
      "2023-06-27 19:53:56,075 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Function assessment\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,076 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the inconvenience. Could you please provide me with the medical fact so that I can generate the JSON object for you?, returning default object\r\n",
      "2023-06-27 19:53:56,079 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Stromper improvement\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,082 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"SEMI view\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 19:53:56,083 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\r\n",
      "2023-06-27 19:53:56,094 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 14972 of 14998 API responses.\r\n",
      "                    26 of 14998 API responses could not be processed.\r\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_fine_grained_details_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\" \\\n",
    "    --offset 0 \\\n",
    "    --num_facts 15000 \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7e65fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:25:43,735 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14977 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\n",
      "2023-06-27 21:25:43,813 - \u001b[1;32mINFO\u001b[1;0m - Loaded 15094 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n",
      "2023-06-27 21:25:43,821 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 30071\n",
      "2023-06-27 21:25:43,821 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 21:25:50,691 - \u001b[1;32mINFO\u001b[1;0m - Loaded 849523 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 21:25:51,834 - \u001b[1;32mINFO\u001b[1;0m - Found 414580 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 21:25:51,867 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 414580/414580 [00:49<00:00, 8320.57it/s]\n",
      "2023-06-27 21:26:41,694 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 414580/414580 [00:00<00:00, 440226.42it/s]\n",
      "2023-06-27 21:26:43,671 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-06-27 21:26:43,671 - \u001b[1;32mINFO\u001b[1;0m - First fact: Mediastinal bulgary bulgarian mediastinal bulgarian mediastinal bulgarian hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-27 21:26:43,671 - \u001b[1;32mINFO\u001b[1;0m - Last fact: Right\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 14463\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 1. Tip of what? (missing context)\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 1607. Plack band in appropriate position\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 3214. Supraaortic lung mass\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 4821. Likely from prior ligamentous injury\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 6428. Ventriculostomy catheter\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 8035. Well-delineated diaphragmatic contours\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 9642. Parenchymal umbrella filter\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 11249. Lymphoma consolidation\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 12856. Regressive left-sided basal pleural densities\n",
      "2023-06-27 21:26:43,821 - \u001b[1;32mINFO\u001b[1;0m - 14463. Inability to raise arms\n",
      "2023-06-27 21:26:43,891 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230627_212643.jsonl\n",
      "2023-06-27 21:26:43,891 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_212643.jsonl\n",
      "2023-06-27 21:26:44,523 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-27 21:26:44,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-06-27 21:26:44,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-06-27 21:26:44,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-06-27 21:26:44,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-06-27 21:26:44,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-06-27 21:26:48,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-06-27 21:26:59,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #140\n",
      "2023-06-27 21:27:10,142 - \u001b[1;32mINFO\u001b[1;0m - Starting request #160\n",
      "2023-06-27 21:27:20,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #180\n",
      "2023-06-27 21:27:31,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #200\n",
      "2023-06-27 21:27:42,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #220\n",
      "2023-06-27 21:27:52,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #240\n",
      "2023-06-27 21:28:03,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #260\n",
      "2023-06-27 21:28:13,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #280\n",
      "2023-06-27 21:28:24,580 - \u001b[1;32mINFO\u001b[1;0m - Starting request #300\n",
      "2023-06-27 21:28:35,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #320\n",
      "2023-06-27 21:28:45,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #340\n",
      "2023-06-27 21:28:56,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #360\n",
      "2023-06-27 21:29:07,027 - \u001b[1;32mINFO\u001b[1;0m - Starting request #380\n",
      "2023-06-27 21:29:17,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #400\n",
      "2023-06-27 21:29:28,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #420\n",
      "2023-06-27 21:29:38,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #440\n",
      "2023-06-27 21:29:49,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #460\n",
      "2023-06-27 21:30:00,027 - \u001b[1;32mINFO\u001b[1;0m - Starting request #480\n",
      "2023-06-27 21:30:10,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #500\n",
      "2023-06-27 21:30:21,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #520\n",
      "2023-06-27 21:30:31,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #540\n",
      "2023-06-27 21:30:42,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #560\n",
      "2023-06-27 21:30:53,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #580\n",
      "2023-06-27 21:31:03,714 - \u001b[1;32mINFO\u001b[1;0m - Starting request #600\n",
      "2023-06-27 21:31:14,381 - \u001b[1;32mINFO\u001b[1;0m - Starting request #620\n",
      "2023-06-27 21:31:25,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #640\n",
      "2023-06-27 21:31:35,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #660\n",
      "2023-06-27 21:31:46,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #680\n",
      "2023-06-27 21:31:57,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #700\n",
      "2023-06-27 21:32:07,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #720\n",
      "2023-06-27 21:32:18,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #740\n",
      "2023-06-27 21:32:29,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #760\n",
      "2023-06-27 21:32:39,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #780\n",
      "2023-06-27 21:32:50,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #800\n",
      "2023-06-27 21:33:01,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #820\n",
      "2023-06-27 21:33:11,685 - \u001b[1;32mINFO\u001b[1;0m - Starting request #840\n",
      "2023-06-27 21:33:22,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #860\n",
      "2023-06-27 21:33:33,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #880\n",
      "2023-06-27 21:33:43,696 - \u001b[1;32mINFO\u001b[1;0m - Starting request #900\n",
      "2023-06-27 21:33:54,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #920\n",
      "2023-06-27 21:34:05,028 - \u001b[1;32mINFO\u001b[1;0m - Starting request #940\n",
      "2023-06-27 21:34:15,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #960\n",
      "2023-06-27 21:34:26,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #980\n",
      "2023-06-27 21:34:37,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1000\n",
      "2023-06-27 21:34:47,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1020\n",
      "2023-06-27 21:34:58,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1040\n",
      "2023-06-27 21:35:09,083 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1060\n",
      "2023-06-27 21:35:19,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1080\n",
      "2023-06-27 21:35:30,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1100\n",
      "2023-06-27 21:35:41,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1120\n",
      "2023-06-27 21:35:51,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1140\n",
      "2023-06-27 21:36:02,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1160\n",
      "2023-06-27 21:36:13,086 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1180\n",
      "2023-06-27 21:36:23,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1200\n",
      "2023-06-27 21:36:34,417 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1220\n",
      "2023-06-27 21:36:45,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1240\n",
      "2023-06-27 21:36:55,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1260\n",
      "2023-06-27 21:37:06,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1280\n",
      "2023-06-27 21:37:17,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1300\n",
      "2023-06-27 21:37:27,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1320\n",
      "2023-06-27 21:37:38,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1340\n",
      "2023-06-27 21:37:49,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1360\n",
      "2023-06-27 21:37:59,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1380\n",
      "2023-06-27 21:38:10,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1400\n",
      "2023-06-27 21:38:21,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1420\n",
      "2023-06-27 21:38:31,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1440\n",
      "2023-06-27 21:38:42,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1460\n",
      "2023-06-27 21:38:53,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1480\n",
      "2023-06-27 21:39:03,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1500\n",
      "2023-06-27 21:39:14,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1520\n",
      "2023-06-27 21:39:16,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 960 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:39:25,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1539\n",
      "2023-06-27 21:39:35,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1559\n",
      "2023-06-27 21:39:46,397 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1579\n",
      "2023-06-27 21:39:57,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1599\n",
      "2023-06-27 21:40:07,742 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1619\n",
      "2023-06-27 21:40:18,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1639\n",
      "2023-06-27 21:40:29,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1659\n",
      "2023-06-27 21:40:38,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1115 failed with Exception \n",
      "2023-06-27 21:40:39,737 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1678\n",
      "2023-06-27 21:40:50,422 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1698\n",
      "2023-06-27 21:41:01,086 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1718\n",
      "2023-06-27 21:41:11,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1738\n",
      "2023-06-27 21:41:22,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1758\n",
      "2023-06-27 21:41:33,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1778\n",
      "2023-06-27 21:41:43,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1798\n",
      "2023-06-27 21:41:54,375 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1818\n",
      "2023-06-27 21:42:05,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1838\n",
      "2023-06-27 21:42:15,712 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1858\n",
      "2023-06-27 21:42:26,375 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1878\n",
      "2023-06-27 21:42:37,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1898\n",
      "2023-06-27 21:42:47,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1918\n",
      "2023-06-27 21:42:58,322 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1938\n",
      "2023-06-27 21:43:08,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1396 failed with Exception \n",
      "2023-06-27 21:43:08,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1958\n",
      "2023-06-27 21:43:19,645 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1977\n",
      "2023-06-27 21:43:30,331 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1997\n",
      "2023-06-27 21:43:33,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1443 failed with Exception \n",
      "2023-06-27 21:43:40,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2016\n",
      "2023-06-27 21:43:51,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2036\n",
      "2023-06-27 21:44:02,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2056\n",
      "2023-06-27 21:44:12,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2076\n",
      "2023-06-27 21:44:23,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2096\n",
      "2023-06-27 21:44:34,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2116\n",
      "2023-06-27 21:44:44,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2136\n",
      "2023-06-27 21:44:55,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2156\n",
      "2023-06-27 21:45:06,282 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2176\n",
      "2023-06-27 21:45:16,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2196\n",
      "2023-06-27 21:45:23,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1647 failed with Exception \n",
      "2023-06-27 21:45:27,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2215\n",
      "2023-06-27 21:45:38,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2235\n",
      "2023-06-27 21:45:48,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2255\n",
      "2023-06-27 21:45:59,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2275\n",
      "2023-06-27 21:46:10,271 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2295\n",
      "2023-06-27 21:46:20,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2315\n",
      "2023-06-27 21:46:31,598 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2335\n",
      "2023-06-27 21:46:42,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2355\n",
      "2023-06-27 21:46:52,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2375\n",
      "2023-06-27 21:47:02,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1833 failed with Exception \n",
      "2023-06-27 21:47:03,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2394\n",
      "2023-06-27 21:47:14,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2414\n",
      "2023-06-27 21:47:24,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2434\n",
      "2023-06-27 21:47:35,615 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2454\n",
      "2023-06-27 21:47:46,284 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2474\n",
      "2023-06-27 21:47:56,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2494\n",
      "2023-06-27 21:47:58,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1938 failed with Exception \n",
      "2023-06-27 21:48:07,622 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2513\n",
      "2023-06-27 21:48:18,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2533\n",
      "2023-06-27 21:48:28,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2553\n",
      "2023-06-27 21:48:39,587 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2573\n",
      "2023-06-27 21:48:42,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2017 failed with Exception \n",
      "2023-06-27 21:48:50,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2592\n",
      "2023-06-27 21:49:00,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2612\n",
      "2023-06-27 21:49:11,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2632\n",
      "2023-06-27 21:49:22,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2652\n",
      "2023-06-27 21:49:32,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2672\n",
      "2023-06-27 21:49:43,505 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2692\n",
      "2023-06-27 21:49:54,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2712\n",
      "2023-06-27 21:50:04,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2732\n",
      "2023-06-27 21:50:15,492 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2752\n",
      "2023-06-27 21:50:26,158 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2772\n",
      "2023-06-27 21:50:36,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2792\n",
      "2023-06-27 21:50:47,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2812\n",
      "2023-06-27 21:50:58,111 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2832\n",
      "2023-06-27 21:51:08,760 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2852\n",
      "2023-06-27 21:51:19,415 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2872\n",
      "2023-06-27 21:51:30,088 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2892\n",
      "2023-06-27 21:51:30,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2332 failed with Exception \n",
      "2023-06-27 21:51:40,745 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2911\n",
      "2023-06-27 21:51:51,393 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2931\n",
      "2023-06-27 21:52:02,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2951\n",
      "2023-06-27 21:52:12,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2971\n",
      "2023-06-27 21:52:23,333 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2991\n",
      "2023-06-27 21:52:34,001 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3011\n",
      "2023-06-27 21:52:44,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3031\n",
      "2023-06-27 21:52:55,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3051\n",
      "2023-06-27 21:53:05,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3071\n",
      "2023-06-27 21:53:16,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3091\n",
      "2023-06-27 21:53:27,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3111\n",
      "2023-06-27 21:53:37,888 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3131\n",
      "2023-06-27 21:53:40,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2574 failed with Exception \n",
      "2023-06-27 21:53:48,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3150\n",
      "2023-06-27 21:53:59,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3170\n",
      "2023-06-27 21:54:06,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2622 failed with Exception \n",
      "2023-06-27 21:54:09,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3189\n",
      "2023-06-27 21:54:20,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3209\n",
      "2023-06-27 21:54:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2648 failed with Exception \n",
      "2023-06-27 21:54:31,112 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3228\n",
      "2023-06-27 21:54:41,748 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3248\n",
      "2023-06-27 21:54:47,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2698 failed with Exception \n",
      "2023-06-27 21:54:52,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3267\n",
      "2023-06-27 21:55:03,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3287\n",
      "2023-06-27 21:55:08,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2738 failed with Exception \n",
      "2023-06-27 21:55:13,668 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3306\n",
      "2023-06-27 21:55:24,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3326\n",
      "2023-06-27 21:55:34,942 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3346\n",
      "2023-06-27 21:55:45,590 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3366\n",
      "2023-06-27 21:55:56,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3386\n",
      "2023-06-27 21:56:06,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3406\n",
      "2023-06-27 21:56:17,503 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3426\n",
      "2023-06-27 21:56:28,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3446\n",
      "2023-06-27 21:56:38,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3466\n",
      "2023-06-27 21:56:49,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3486\n",
      "2023-06-27 21:57:00,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3506\n",
      "2023-06-27 21:57:10,666 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3526\n",
      "2023-06-27 21:57:21,291 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3546\n",
      "2023-06-27 21:57:31,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:57:42,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3586\n",
      "2023-06-27 21:57:53,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3606\n",
      "2023-06-27 21:58:03,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3626\n",
      "2023-06-27 21:58:14,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3646\n",
      "2023-06-27 21:58:24,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3666\n",
      "2023-06-27 21:58:35,541 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3686\n",
      "2023-06-27 21:58:39,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3133 failed with Exception \n",
      "2023-06-27 21:58:46,137 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3705\n",
      "2023-06-27 21:58:56,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3725\n",
      "2023-06-27 21:59:07,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3745\n",
      "2023-06-27 21:59:18,118 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3765\n",
      "2023-06-27 21:59:18,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3205 failed with Exception \n",
      "2023-06-27 21:59:28,772 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3784\n",
      "2023-06-27 21:59:39,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3804\n",
      "2023-06-27 21:59:50,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3824\n",
      "2023-06-27 22:00:00,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3844\n",
      "2023-06-27 22:00:01,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3284 failed with Exception \n",
      "2023-06-27 22:00:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3289 failed with Exception \n",
      "2023-06-27 22:00:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3292 failed with Exception \n",
      "2023-06-27 22:00:08,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3296 failed with Exception \n",
      "2023-06-27 22:00:11,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3860\n",
      "2023-06-27 22:00:22,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3880\n",
      "2023-06-27 22:00:32,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3900\n",
      "2023-06-27 22:00:43,404 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3920\n",
      "2023-06-27 22:00:54,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3940\n",
      "2023-06-27 22:01:04,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3960\n",
      "2023-06-27 22:01:15,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3980\n",
      "2023-06-27 22:01:26,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4000\n",
      "2023-06-27 22:01:36,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4020\n",
      "2023-06-27 22:01:47,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4040\n",
      "2023-06-27 22:01:58,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4060\n",
      "2023-06-27 22:01:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3503 failed with Exception \n",
      "2023-06-27 22:02:07,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3519 failed with Exception \n",
      "2023-06-27 22:02:08,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4078\n",
      "2023-06-27 22:02:19,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4098\n",
      "2023-06-27 22:02:30,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4118\n",
      "2023-06-27 22:02:40,702 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4138\n",
      "2023-06-27 22:02:51,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4158\n",
      "2023-06-27 22:03:02,103 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4178\n",
      "2023-06-27 22:03:12,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4198\n",
      "2023-06-27 22:03:21,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3658 failed with Exception \n",
      "2023-06-27 22:03:23,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4217\n",
      "2023-06-27 22:03:34,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4237\n",
      "2023-06-27 22:03:44,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4257\n",
      "2023-06-27 22:03:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3710 failed with Exception \n",
      "2023-06-27 22:03:53,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3717 failed with Exception \n",
      "2023-06-27 22:03:55,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4275\n",
      "2023-06-27 22:04:06,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4295\n",
      "2023-06-27 22:04:16,715 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4315\n",
      "2023-06-27 22:04:27,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4335\n",
      "2023-06-27 22:04:38,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4355\n",
      "2023-06-27 22:04:48,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4375\n",
      "2023-06-27 22:04:59,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4395\n",
      "2023-06-27 22:05:10,024 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4415\n",
      "2023-06-27 22:05:20,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4435\n",
      "2023-06-27 22:05:31,372 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4455\n",
      "2023-06-27 22:05:42,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4475\n",
      "2023-06-27 22:05:52,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4495\n",
      "2023-06-27 22:05:54,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3940 failed with Exception \n",
      "2023-06-27 22:06:03,355 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4514\n",
      "2023-06-27 22:06:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3974 failed with Exception \n",
      "2023-06-27 22:06:14,011 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4533\n",
      "2023-06-27 22:06:24,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4553\n",
      "2023-06-27 22:06:30,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4007 failed with Exception \n",
      "2023-06-27 22:06:35,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4572\n",
      "2023-06-27 22:06:35,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4017 failed with Exception \n",
      "2023-06-27 22:06:46,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4591\n",
      "2023-06-27 22:06:53,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4050 failed with Exception \n",
      "2023-06-27 22:06:56,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4610\n",
      "2023-06-27 22:07:07,347 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4630\n",
      "2023-06-27 22:07:17,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4650\n",
      "2023-06-27 22:07:28,654 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4670\n",
      "2023-06-27 22:07:39,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4690\n",
      "2023-06-27 22:07:49,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4710\n",
      "2023-06-27 22:08:00,648 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4730\n",
      "2023-06-27 22:08:11,317 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4750\n",
      "2023-06-27 22:08:21,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4770\n",
      "2023-06-27 22:08:32,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4790\n",
      "2023-06-27 22:08:43,277 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4810\n",
      "2023-06-27 22:08:53,928 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4830\n",
      "2023-06-27 22:09:04,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4850\n",
      "2023-06-27 22:09:15,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4870\n",
      "2023-06-27 22:09:25,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4890\n",
      "2023-06-27 22:09:27,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4335 failed with Exception \n",
      "2023-06-27 22:09:36,588 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4909\n",
      "2023-06-27 22:09:47,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4929\n",
      "2023-06-27 22:09:57,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4949\n",
      "2023-06-27 22:10:08,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4969\n",
      "2023-06-27 22:10:19,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4989\n",
      "2023-06-27 22:10:29,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5009\n",
      "2023-06-27 22:10:40,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5029\n",
      "2023-06-27 22:10:51,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5049\n",
      "2023-06-27 22:11:01,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5069\n",
      "2023-06-27 22:11:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4519 failed with Exception \n",
      "2023-06-27 22:11:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4530 failed with Exception \n",
      "2023-06-27 22:11:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4531 failed with Exception \n",
      "2023-06-27 22:11:12,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5088\n",
      "2023-06-27 22:11:23,209 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5106\n",
      "2023-06-27 22:11:33,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5126\n",
      "2023-06-27 22:11:44,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5146\n",
      "2023-06-27 22:11:55,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5166\n",
      "2023-06-27 22:12:05,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5186\n",
      "2023-06-27 22:12:16,539 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5206\n",
      "2023-06-27 22:12:27,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5226\n",
      "2023-06-27 22:12:37,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5246\n",
      "2023-06-27 22:12:48,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5266\n",
      "2023-06-27 22:12:59,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5286\n",
      "2023-06-27 22:13:09,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5306\n",
      "2023-06-27 22:13:20,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5326\n",
      "2023-06-27 22:13:24,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4773 failed with Exception \n",
      "2023-06-27 22:13:31,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5345\n",
      "2023-06-27 22:13:41,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5365\n",
      "2023-06-27 22:13:52,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5385\n",
      "2023-06-27 22:14:03,159 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:14:13,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5425\n",
      "2023-06-27 22:14:14,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4868 failed with Exception \n",
      "2023-06-27 22:14:24,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5444\n",
      "2023-06-27 22:14:35,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5464\n",
      "2023-06-27 22:14:45,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5484\n",
      "2023-06-27 22:14:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4935 failed with Exception \n",
      "2023-06-27 22:14:56,470 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5503\n",
      "2023-06-27 22:15:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4960 failed with Exception \n",
      "2023-06-27 22:15:07,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5522\n",
      "2023-06-27 22:15:17,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5542\n",
      "2023-06-27 22:15:28,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5562\n",
      "2023-06-27 22:15:39,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5582\n",
      "2023-06-27 22:15:49,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5602\n",
      "2023-06-27 22:16:00,417 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5622\n",
      "2023-06-27 22:16:11,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5642\n",
      "2023-06-27 22:16:21,723 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5662\n",
      "2023-06-27 22:16:32,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5682\n",
      "2023-06-27 22:16:43,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5702\n",
      "2023-06-27 22:16:53,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5722\n",
      "2023-06-27 22:17:04,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5742\n",
      "2023-06-27 22:17:14,981 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5762\n",
      "2023-06-27 22:17:25,622 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5782\n",
      "2023-06-27 22:17:36,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5802\n",
      "2023-06-27 22:17:46,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5822\n",
      "2023-06-27 22:17:57,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5842\n",
      "2023-06-27 22:18:08,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5862\n",
      "2023-06-27 22:18:18,902 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5882\n",
      "2023-06-27 22:18:29,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5902\n",
      "2023-06-27 22:18:40,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5922\n",
      "2023-06-27 22:18:50,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5942\n",
      "2023-06-27 22:19:01,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5962\n",
      "2023-06-27 22:19:12,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5982\n",
      "2023-06-27 22:19:22,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6002\n",
      "2023-06-27 22:19:33,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6022\n",
      "2023-06-27 22:19:44,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6042\n",
      "2023-06-27 22:19:54,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6062\n",
      "2023-06-27 22:20:05,363 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6082\n",
      "2023-06-27 22:20:16,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6102\n",
      "2023-06-27 22:20:26,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6122\n",
      "2023-06-27 22:20:37,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6142\n",
      "2023-06-27 22:20:47,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6162\n",
      "2023-06-27 22:20:58,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6182\n",
      "2023-06-27 22:21:09,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6202\n",
      "2023-06-27 22:21:19,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6222\n",
      "2023-06-27 22:21:30,489 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6242\n",
      "2023-06-27 22:21:41,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6262\n",
      "2023-06-27 22:21:51,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6282\n",
      "2023-06-27 22:22:02,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6302\n",
      "2023-06-27 22:22:13,028 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6322\n",
      "2023-06-27 22:22:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5774 failed with Exception \n",
      "2023-06-27 22:22:23,669 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6341\n",
      "2023-06-27 22:22:34,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6361\n",
      "2023-06-27 22:22:44,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6381\n",
      "2023-06-27 22:22:55,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6401\n",
      "2023-06-27 22:23:06,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6421\n",
      "2023-06-27 22:23:16,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6441\n",
      "2023-06-27 22:23:27,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6461\n",
      "2023-06-27 22:23:32,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5907 failed with Exception \n",
      "2023-06-27 22:23:38,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6480\n",
      "2023-06-27 22:23:48,736 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6500\n",
      "2023-06-27 22:23:59,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6520\n",
      "2023-06-27 22:24:09,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6540\n",
      "2023-06-27 22:24:20,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6560\n",
      "2023-06-27 22:24:31,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6580\n",
      "2023-06-27 22:24:41,730 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6600\n",
      "2023-06-27 22:24:52,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6620\n",
      "2023-06-27 22:24:52,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6057 failed with Exception \n",
      "2023-06-27 22:25:03,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6639\n",
      "2023-06-27 22:25:13,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6659\n",
      "2023-06-27 22:25:24,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6679\n",
      "2023-06-27 22:25:35,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6699\n",
      "2023-06-27 22:25:45,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6719\n",
      "2023-06-27 22:25:56,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6739\n",
      "2023-06-27 22:26:07,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6759\n",
      "2023-06-27 22:26:17,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6779\n",
      "2023-06-27 22:26:28,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6799\n",
      "2023-06-27 22:26:39,014 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6819\n",
      "2023-06-27 22:26:49,677 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6839\n",
      "2023-06-27 22:27:00,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6859\n",
      "2023-06-27 22:27:11,018 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6879\n",
      "2023-06-27 22:27:21,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6899\n",
      "2023-06-27 22:27:32,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6919\n",
      "2023-06-27 22:27:42,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6939\n",
      "2023-06-27 22:27:53,629 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6959\n",
      "2023-06-27 22:28:04,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6979\n",
      "2023-06-27 22:28:14,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6999\n",
      "2023-06-27 22:28:25,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7019\n",
      "2023-06-27 22:28:36,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7039\n",
      "2023-06-27 22:28:46,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6494 failed with Exception \n",
      "2023-06-27 22:28:46,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7059\n",
      "2023-06-27 22:28:57,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7078\n",
      "2023-06-27 22:29:08,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7098\n",
      "2023-06-27 22:29:18,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7118\n",
      "2023-06-27 22:29:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6559 failed with Exception \n",
      "2023-06-27 22:29:29,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7137\n",
      "2023-06-27 22:29:40,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7157\n",
      "2023-06-27 22:29:50,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7177\n",
      "2023-06-27 22:29:53,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6057 failed with Exception \n",
      "2023-06-27 22:30:01,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7196\n",
      "2023-06-27 22:30:12,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7216\n",
      "2023-06-27 22:30:22,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7236\n",
      "2023-06-27 22:30:30,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6690 failed with Exception \n",
      "2023-06-27 22:30:33,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7255\n",
      "2023-06-27 22:30:44,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7275\n",
      "2023-06-27 22:30:54,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7295\n",
      "2023-06-27 22:31:05,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7315\n",
      "2023-06-27 22:31:16,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7335\n",
      "2023-06-27 22:31:26,920 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7355\n",
      "2023-06-27 22:31:37,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7375\n",
      "2023-06-27 22:31:48,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7395\n",
      "2023-06-27 22:31:58,900 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7415\n",
      "2023-06-27 22:32:09,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7435\n",
      "2023-06-27 22:32:20,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7455\n",
      "2023-06-27 22:32:30,882 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7475\n",
      "2023-06-27 22:32:41,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7495\n",
      "2023-06-27 22:32:52,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7515\n",
      "2023-06-27 22:32:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6960 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:33:02,868 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7534\n",
      "2023-06-27 22:33:13,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7554\n",
      "2023-06-27 22:33:24,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7574\n",
      "2023-06-27 22:33:34,838 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7594\n",
      "2023-06-27 22:33:45,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7614\n",
      "2023-06-27 22:33:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7062 failed with Exception \n",
      "2023-06-27 22:33:56,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7633\n",
      "2023-06-27 22:34:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7085 failed with Exception \n",
      "2023-06-27 22:34:06,828 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7652\n",
      "2023-06-27 22:34:17,496 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7672\n",
      "2023-06-27 22:34:28,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7692\n",
      "2023-06-27 22:34:38,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7712\n",
      "2023-06-27 22:34:49,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7732\n",
      "2023-06-27 22:35:00,157 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7752\n",
      "2023-06-27 22:35:10,812 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7772\n",
      "2023-06-27 22:35:21,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7792\n",
      "2023-06-27 22:35:23,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7236 failed with Exception \n",
      "2023-06-27 22:35:32,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7811\n",
      "2023-06-27 22:35:42,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7831\n",
      "2023-06-27 22:35:53,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7851\n",
      "2023-06-27 22:36:04,124 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7871\n",
      "2023-06-27 22:36:14,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7891\n",
      "2023-06-27 22:36:25,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7911\n",
      "2023-06-27 22:36:36,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7931\n",
      "2023-06-27 22:36:46,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7951\n",
      "2023-06-27 22:36:57,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7971\n",
      "2023-06-27 22:37:08,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7991\n",
      "2023-06-27 22:37:18,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8011\n",
      "2023-06-27 22:37:29,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8031\n",
      "2023-06-27 22:37:40,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8051\n",
      "2023-06-27 22:37:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7510 failed with Exception \n",
      "2023-06-27 22:37:50,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8071\n",
      "2023-06-27 22:38:01,349 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8090\n",
      "2023-06-27 22:38:12,001 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8110\n",
      "2023-06-27 22:38:22,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8130\n",
      "2023-06-27 22:38:33,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8150\n",
      "2023-06-27 22:38:43,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8170\n",
      "2023-06-27 22:38:54,640 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8190\n",
      "2023-06-27 22:39:05,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8210\n",
      "2023-06-27 22:39:15,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8230\n",
      "2023-06-27 22:39:26,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8250\n",
      "2023-06-27 22:39:37,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8270\n",
      "2023-06-27 22:39:47,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8290\n",
      "2023-06-27 22:39:58,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8310\n",
      "2023-06-27 22:40:09,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8330\n",
      "2023-06-27 22:40:19,903 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8350\n",
      "2023-06-27 22:40:30,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8370\n",
      "2023-06-27 22:40:41,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8390\n",
      "2023-06-27 22:40:51,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8410\n",
      "2023-06-27 22:41:02,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8430\n",
      "2023-06-27 22:41:13,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8450\n",
      "2023-06-27 22:41:23,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8470\n",
      "2023-06-27 22:41:34,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8490\n",
      "2023-06-27 22:41:45,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8510\n",
      "2023-06-27 22:41:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7964 failed with Exception \n",
      "2023-06-27 22:41:55,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8529\n",
      "2023-06-27 22:42:06,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8549\n",
      "2023-06-27 22:42:17,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8569\n",
      "2023-06-27 22:42:27,756 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8589\n",
      "2023-06-27 22:42:38,406 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8609\n",
      "2023-06-27 22:42:49,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8629\n",
      "2023-06-27 22:42:49,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8068 failed with Exception \n",
      "2023-06-27 22:42:59,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8648\n",
      "2023-06-27 22:43:10,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8668\n",
      "2023-06-27 22:43:20,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8688\n",
      "2023-06-27 22:43:31,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8708\n",
      "2023-06-27 22:43:42,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8728\n",
      "2023-06-27 22:43:52,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8748\n",
      "2023-06-27 22:44:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8204 failed with Exception \n",
      "2023-06-27 22:44:03,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8767\n",
      "2023-06-27 22:44:14,220 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8787\n",
      "2023-06-27 22:44:24,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8807\n",
      "2023-06-27 22:44:35,505 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8827\n",
      "2023-06-27 22:44:46,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8847\n",
      "2023-06-27 22:44:56,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8867\n",
      "2023-06-27 22:45:06,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8323 failed with Exception \n",
      "2023-06-27 22:45:07,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8323\n",
      "2023-06-27 22:45:18,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8906\n",
      "2023-06-27 22:45:28,678 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8926\n",
      "2023-06-27 22:45:39,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8946\n",
      "2023-06-27 22:45:49,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8966\n",
      "2023-06-27 22:46:00,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8986\n",
      "2023-06-27 22:46:11,248 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9006\n",
      "2023-06-27 22:46:21,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9026\n",
      "2023-06-27 22:46:32,505 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9046\n",
      "2023-06-27 22:46:43,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9066\n",
      "2023-06-27 22:46:53,718 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9086\n",
      "2023-06-27 22:47:04,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9106\n",
      "2023-06-27 22:47:14,910 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9126\n",
      "2023-06-27 22:47:25,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9146\n",
      "2023-06-27 22:47:36,192 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9166\n",
      "2023-06-27 22:47:46,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9186\n",
      "2023-06-27 22:47:54,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8638 failed with Exception \n",
      "2023-06-27 22:47:57,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9205\n",
      "2023-06-27 22:48:01,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8650 failed with Exception \n",
      "2023-06-27 22:48:08,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9224\n",
      "2023-06-27 22:48:18,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9244\n",
      "2023-06-27 22:48:29,539 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9264\n",
      "2023-06-27 22:48:40,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9284\n",
      "2023-06-27 22:48:47,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 9240 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11245923a64118c601a4b770d5afc4a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 22:48:50,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9303\n",
      "2023-06-27 22:49:01,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9323\n",
      "2023-06-27 22:49:12,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9343\n",
      "2023-06-27 22:49:22,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9363\n",
      "2023-06-27 22:49:33,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9383\n",
      "2023-06-27 22:49:44,209 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9403\n",
      "2023-06-27 22:49:54,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9423\n",
      "2023-06-27 22:50:05,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9443\n",
      "2023-06-27 22:50:16,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9463\n",
      "2023-06-27 22:50:26,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9483\n",
      "2023-06-27 22:50:37,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9503\n",
      "2023-06-27 22:50:40,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8948 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:50:48,160 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9522\n",
      "2023-06-27 22:50:58,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9542\n",
      "2023-06-27 22:51:09,496 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9562\n",
      "2023-06-27 22:51:11,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9005 failed with Exception \n",
      "2023-06-27 22:51:20,169 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9581\n",
      "2023-06-27 22:51:30,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9601\n",
      "2023-06-27 22:51:41,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9621\n",
      "2023-06-27 22:51:52,156 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9641\n",
      "2023-06-27 22:52:02,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9661\n",
      "2023-06-27 22:52:13,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9681\n",
      "2023-06-27 22:52:24,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9701\n",
      "2023-06-27 22:52:34,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9721\n",
      "2023-06-27 22:52:38,651 - \u001b[1;33mWARNING\u001b[1;0m - Request 9539 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 22:52:45,471 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9740\n",
      "2023-06-27 22:52:48,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9188 failed with Exception \n",
      "2023-06-27 22:52:56,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9759\n",
      "2023-06-27 22:53:06,801 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9779\n",
      "2023-06-27 22:53:17,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9799\n",
      "2023-06-27 22:53:28,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9819\n",
      "2023-06-27 22:53:38,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9839\n",
      "2023-06-27 22:53:49,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9859\n",
      "2023-06-27 22:54:00,093 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9879\n",
      "2023-06-27 22:54:10,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9899\n",
      "2023-06-27 22:54:21,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9919\n",
      "2023-06-27 22:54:32,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9939\n",
      "2023-06-27 22:54:42,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9959\n",
      "2023-06-27 22:54:53,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9979\n",
      "2023-06-27 22:55:04,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9999\n",
      "2023-06-27 22:55:14,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10019\n",
      "2023-06-27 22:55:25,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10039\n",
      "2023-06-27 22:55:36,111 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10059\n",
      "2023-06-27 22:55:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9512 failed with Exception \n",
      "2023-06-27 22:55:46,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10078\n",
      "2023-06-27 22:55:57,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10098\n",
      "2023-06-27 22:56:08,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10118\n",
      "2023-06-27 22:56:18,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10138\n",
      "2023-06-27 22:56:29,424 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10158\n",
      "2023-06-27 22:56:40,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10178\n",
      "2023-06-27 22:56:50,725 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10198\n",
      "2023-06-27 22:57:01,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10218\n",
      "2023-06-27 22:57:12,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10238\n",
      "2023-06-27 22:57:22,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10258\n",
      "2023-06-27 22:57:33,335 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10278\n",
      "2023-06-27 22:57:43,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10298\n",
      "2023-06-27 22:57:54,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10318\n",
      "2023-06-27 22:58:05,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10338\n",
      "2023-06-27 22:58:15,963 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10358\n",
      "2023-06-27 22:58:26,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10378\n",
      "2023-06-27 22:58:37,288 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10398\n",
      "2023-06-27 22:58:47,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10418\n",
      "2023-06-27 22:58:58,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10438\n",
      "2023-06-27 22:59:03,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9885 failed with Exception \n",
      "2023-06-27 22:59:09,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10457\n",
      "2023-06-27 22:59:19,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10477\n",
      "2023-06-27 22:59:26,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9927 failed with Exception \n",
      "2023-06-27 22:59:30,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10496\n",
      "2023-06-27 22:59:41,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10516\n",
      "2023-06-27 22:59:47,870 - \u001b[1;33mWARNING\u001b[1;0m - Request 10460 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 22:59:51,908 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10535\n",
      "2023-06-27 23:00:02,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10555\n",
      "2023-06-27 23:00:13,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10575\n",
      "2023-06-27 23:00:23,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10595\n",
      "2023-06-27 23:00:29,299 - \u001b[1;33mWARNING\u001b[1;0m - Request 10548 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 810517e761e620324be21c0786759432 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 23:00:34,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10614\n",
      "2023-06-27 23:00:45,204 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10634\n",
      "2023-06-27 23:00:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10083 failed with Exception \n",
      "2023-06-27 23:00:55,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10653\n",
      "2023-06-27 23:01:06,516 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10673\n",
      "2023-06-27 23:01:13,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10128 failed with Exception \n",
      "2023-06-27 23:01:17,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10692\n",
      "2023-06-27 23:01:18,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10137 failed with Exception \n",
      "2023-06-27 23:01:27,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10711\n",
      "2023-06-27 23:01:38,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10731\n",
      "2023-06-27 23:01:49,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10751\n",
      "2023-06-27 23:01:59,806 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10771\n",
      "2023-06-27 23:02:10,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10791\n",
      "2023-06-27 23:02:21,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10811\n",
      "2023-06-27 23:02:31,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10831\n",
      "2023-06-27 23:02:42,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10851\n",
      "2023-06-27 23:02:53,060 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10871\n",
      "2023-06-27 23:03:03,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10891\n",
      "2023-06-27 23:03:14,339 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10911\n",
      "2023-06-27 23:03:24,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10931\n",
      "2023-06-27 23:03:35,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10951\n",
      "2023-06-27 23:03:46,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10971\n",
      "2023-06-27 23:03:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10434 failed with Exception \n",
      "2023-06-27 23:03:56,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10991\n",
      "2023-06-27 23:04:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10450 failed with Exception \n",
      "2023-06-27 23:04:07,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11009\n",
      "2023-06-27 23:04:18,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11029\n",
      "2023-06-27 23:04:28,841 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11049\n",
      "2023-06-27 23:04:37,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10508 failed with Exception \n",
      "2023-06-27 23:04:39,496 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11068\n",
      "2023-06-27 23:04:42,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10518 failed with Exception \n",
      "2023-06-27 23:04:50,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11087\n",
      "2023-06-27 23:05:00,801 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11107\n",
      "2023-06-27 23:05:11,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11127\n",
      "2023-06-27 23:05:15,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10578 failed with Exception \n",
      "2023-06-27 23:05:22,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11146\n",
      "2023-06-27 23:05:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10591 failed with Exception \n",
      "2023-06-27 23:05:32,715 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11165\n",
      "2023-06-27 23:05:38,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 10621 failed with Exception \n",
      "2023-06-27 23:05:43,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11184\n",
      "2023-06-27 23:05:52,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10646 failed with Exception \n",
      "2023-06-27 23:05:53,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11203\n",
      "2023-06-27 23:06:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10662 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 23:06:04,645 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11222\n",
      "2023-06-27 23:06:15,290 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11242\n",
      "2023-06-27 23:06:25,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11262\n",
      "2023-06-27 23:06:31,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10717 failed with Exception \n",
      "2023-06-27 23:06:36,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11281\n",
      "2023-06-27 23:06:47,214 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11301\n",
      "2023-06-27 23:06:49,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10751 failed with Exception \n",
      "2023-06-27 23:06:57,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11320\n",
      "2023-06-27 23:07:08,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11340\n",
      "2023-06-27 23:07:19,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11360\n",
      "2023-06-27 23:07:29,677 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11380\n",
      "2023-06-27 23:07:40,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11400\n",
      "2023-06-27 23:07:50,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11420\n",
      "2023-06-27 23:07:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10881 failed with Exception \n",
      "2023-06-27 23:08:01,638 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11439\n",
      "2023-06-27 23:08:12,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11459\n",
      "2023-06-27 23:08:22,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11479\n",
      "2023-06-27 23:08:33,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11499\n",
      "2023-06-27 23:08:34,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10947 failed with Exception \n",
      "2023-06-27 23:08:44,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11518\n",
      "2023-06-27 23:08:50,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10978 failed with Exception \n",
      "2023-06-27 23:08:51,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10979 failed with Exception \n",
      "2023-06-27 23:08:54,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11536\n",
      "2023-06-27 23:09:05,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11556\n",
      "2023-06-27 23:09:16,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11576\n",
      "2023-06-27 23:09:26,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11596\n",
      "2023-06-27 23:09:28,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11048 failed with Exception \n",
      "2023-06-27 23:09:37,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11615\n",
      "2023-06-27 23:09:48,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11635\n",
      "2023-06-27 23:09:49,092 - \u001b[1;33mWARNING\u001b[1;0m - Request 11168 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 23:09:58,906 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11654\n",
      "2023-06-27 23:10:09,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11674\n",
      "2023-06-27 23:10:20,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11694\n",
      "2023-06-27 23:10:30,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11714\n",
      "2023-06-27 23:10:41,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11734\n",
      "2023-06-27 23:10:52,251 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11754\n",
      "2023-06-27 23:10:57,922 - \u001b[1;33mWARNING\u001b[1;0m - Request 11755 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 23:11:02,906 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11773\n",
      "2023-06-27 23:11:13,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11793\n",
      "2023-06-27 23:11:24,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11813\n",
      "2023-06-27 23:11:34,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11833\n",
      "2023-06-27 23:11:45,580 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11853\n",
      "2023-06-27 23:11:56,230 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11873\n",
      "2023-06-27 23:11:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11323 failed with Exception \n",
      "2023-06-27 23:12:06,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11892\n",
      "2023-06-27 23:12:17,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11912\n",
      "2023-06-27 23:12:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11374 failed with Exception \n",
      "2023-06-27 23:12:28,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11374\n",
      "2023-06-27 23:12:29,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11379 failed with Exception \n",
      "2023-06-27 23:12:33,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11387 failed with Exception \n",
      "2023-06-27 23:12:38,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11949\n",
      "2023-06-27 23:12:49,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11969\n",
      "2023-06-27 23:13:00,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11989\n",
      "2023-06-27 23:13:10,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12009\n",
      "2023-06-27 23:13:21,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12029\n",
      "2023-06-27 23:13:32,218 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12049\n",
      "2023-06-27 23:13:42,868 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12069\n",
      "2023-06-27 23:13:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11525 failed with Exception \n",
      "2023-06-27 23:13:53,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12088\n",
      "2023-06-27 23:14:04,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12108\n",
      "2023-06-27 23:14:14,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12128\n",
      "2023-06-27 23:14:25,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12148\n",
      "2023-06-27 23:14:36,223 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12168\n",
      "2023-06-27 23:14:46,895 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12188\n",
      "2023-06-27 23:14:57,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12208\n",
      "2023-06-27 23:14:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11654 failed with Exception \n",
      "2023-06-27 23:15:02,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11660 failed with Exception \n",
      "2023-06-27 23:15:08,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12226\n",
      "2023-06-27 23:15:18,915 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12246\n",
      "2023-06-27 23:15:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11692 failed with Exception \n",
      "2023-06-27 23:15:29,571 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12265\n",
      "2023-06-27 23:15:40,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12285\n",
      "2023-06-27 23:15:50,904 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12305\n",
      "2023-06-27 23:16:01,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12325\n",
      "2023-06-27 23:16:12,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12345\n",
      "2023-06-27 23:16:22,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12365\n",
      "2023-06-27 23:16:33,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12385\n",
      "2023-06-27 23:16:44,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12405\n",
      "2023-06-27 23:16:54,828 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12425\n",
      "2023-06-27 23:17:05,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12445\n",
      "2023-06-27 23:17:16,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12465\n",
      "2023-06-27 23:17:26,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12485\n",
      "2023-06-27 23:17:37,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12505\n",
      "2023-06-27 23:17:48,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12525\n",
      "2023-06-27 23:17:58,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12545\n",
      "2023-06-27 23:18:02,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11992 failed with Exception \n",
      "2023-06-27 23:18:09,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12564\n",
      "2023-06-27 23:18:20,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12584\n",
      "2023-06-27 23:18:30,796 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12604\n",
      "2023-06-27 23:18:41,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12624\n",
      "2023-06-27 23:18:45,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12073 failed with Exception \n",
      "2023-06-27 23:18:52,097 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12643\n",
      "2023-06-27 23:19:02,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12663\n",
      "2023-06-27 23:19:13,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12683\n",
      "2023-06-27 23:19:24,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12703\n",
      "2023-06-27 23:19:34,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12723\n",
      "2023-06-27 23:19:45,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12743\n",
      "2023-06-27 23:19:46,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12186 failed with Exception \n",
      "2023-06-27 23:19:56,068 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12762\n",
      "2023-06-27 23:20:06,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12782\n",
      "2023-06-27 23:20:17,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12802\n",
      "2023-06-27 23:20:28,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12822\n",
      "2023-06-27 23:20:38,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12842\n",
      "2023-06-27 23:20:49,364 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12862\n",
      "2023-06-27 23:21:00,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12882\n",
      "2023-06-27 23:21:10,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12902\n",
      "2023-06-27 23:21:21,349 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12922\n",
      "2023-06-27 23:21:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12363 failed with Exception \n",
      "2023-06-27 23:21:32,024 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 23:21:42,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12961\n",
      "2023-06-27 23:21:53,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12981\n",
      "2023-06-27 23:22:03,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13001\n",
      "2023-06-27 23:22:14,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13021\n",
      "2023-06-27 23:22:25,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13041\n",
      "2023-06-27 23:22:35,981 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13061\n",
      "2023-06-27 23:22:46,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13081\n",
      "2023-06-27 23:22:57,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13101\n",
      "2023-06-27 23:23:07,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13121\n",
      "2023-06-27 23:23:18,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13141\n",
      "2023-06-27 23:23:29,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13161\n",
      "2023-06-27 23:23:38,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 12876 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9fe182731ac573fd82c6066c8de771f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 23:23:39,892 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13180\n",
      "2023-06-27 23:23:50,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13200\n",
      "2023-06-27 23:24:01,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13220\n",
      "2023-06-27 23:24:11,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13240\n",
      "2023-06-27 23:24:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12680 failed with Exception \n",
      "2023-06-27 23:24:22,471 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13259\n",
      "2023-06-27 23:24:33,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13279\n",
      "2023-06-27 23:24:43,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13299\n",
      "2023-06-27 23:24:54,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13319\n",
      "2023-06-27 23:25:05,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13339\n",
      "2023-06-27 23:25:15,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13359\n",
      "2023-06-27 23:25:26,365 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13379\n",
      "2023-06-27 23:25:37,019 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13399\n",
      "2023-06-27 23:25:47,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12858 failed with Exception \n",
      "2023-06-27 23:25:47,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13419\n",
      "2023-06-27 23:25:58,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13438\n",
      "2023-06-27 23:26:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12884 failed with Exception \n",
      "2023-06-27 23:26:08,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13457\n",
      "2023-06-27 23:26:19,584 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13477\n",
      "2023-06-27 23:26:30,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13497\n",
      "2023-06-27 23:26:40,873 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13517\n",
      "2023-06-27 23:26:51,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13537\n",
      "2023-06-27 23:27:02,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13557\n",
      "2023-06-27 23:27:12,776 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13577\n",
      "2023-06-27 23:27:23,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13597\n",
      "2023-06-27 23:27:34,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13617\n",
      "2023-06-27 23:27:44,679 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13637\n",
      "2023-06-27 23:27:55,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13657\n",
      "2023-06-27 23:28:05,900 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13677\n",
      "2023-06-27 23:28:16,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13697\n",
      "2023-06-27 23:28:27,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13717\n",
      "2023-06-27 23:28:37,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13737\n",
      "2023-06-27 23:28:48,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13757\n",
      "2023-06-27 23:28:53,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13204 failed with Exception \n",
      "2023-06-27 23:28:59,204 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13776\n",
      "2023-06-27 23:29:09,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13796\n",
      "2023-06-27 23:29:18,716 - \u001b[1;33mWARNING\u001b[1;0m - Request 13757 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d9d1445bf9cd41582d71815a794c4eab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 23:29:20,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13815\n",
      "2023-06-27 23:29:31,171 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13835\n",
      "2023-06-27 23:29:41,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13855\n",
      "2023-06-27 23:29:52,503 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13875\n",
      "2023-06-27 23:30:03,159 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13895\n",
      "2023-06-27 23:30:13,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13915\n",
      "2023-06-27 23:30:24,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13935\n",
      "2023-06-27 23:30:31,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 13388 failed with Exception \n",
      "2023-06-27 23:30:35,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13954\n",
      "2023-06-27 23:30:45,802 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13974\n",
      "2023-06-27 23:30:56,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13994\n",
      "2023-06-27 23:31:07,156 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14014\n",
      "2023-06-27 23:31:17,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14034\n",
      "2023-06-27 23:31:28,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14054\n",
      "2023-06-27 23:31:39,150 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14074\n",
      "2023-06-27 23:31:49,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14094\n",
      "2023-06-27 23:32:00,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14114\n",
      "2023-06-27 23:32:11,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14134\n",
      "2023-06-27 23:32:21,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14154\n",
      "2023-06-27 23:32:32,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14174\n",
      "2023-06-27 23:32:43,180 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14194\n",
      "2023-06-27 23:32:53,840 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14214\n",
      "2023-06-27 23:33:04,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14234\n",
      "2023-06-27 23:33:15,157 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14254\n",
      "2023-06-27 23:33:25,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14274\n",
      "2023-06-27 23:33:36,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14294\n",
      "2023-06-27 23:33:37,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13735 failed with Exception \n",
      "2023-06-27 23:33:47,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14313\n",
      "2023-06-27 23:33:57,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14333\n",
      "2023-06-27 23:34:03,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13784 failed with Exception \n",
      "2023-06-27 23:34:08,466 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14352\n",
      "2023-06-27 23:34:19,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14372\n",
      "2023-06-27 23:34:29,794 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14392\n",
      "2023-06-27 23:34:40,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14412\n",
      "2023-06-27 23:34:51,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14432\n",
      "2023-06-27 23:35:01,776 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14452\n",
      "2023-06-27 23:39:07,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 14350 failed with Exception \n",
      "2023-06-27 23:39:09,005 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_212643.jsonl\n",
      "2023-06-27 23:39:09,009 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_212643.jsonl\n",
      "2023-06-27 23:39:09,462 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sure! How can I assist you?, returning default object\n",
      "2023-06-27 23:39:09,462 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...d are correct.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 9, \"total_tokens\": 558}}, {\"fact\": \"Confirmations\"}] for fact \"Confirmations\": Could not parse output: I confirm that the examples provided are correct.\n",
      "2023-06-27 23:39:09,462 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize, but I'm unable to assist., returning default object\n",
      "2023-06-27 23:39:09,462 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sure, I'd be happy to help. What do you need assistance with?, returning default object\n",
      "2023-06-27 23:39:09,463 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... provided information.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 548, \"completion_tokens\": 38, \"total_tokens\": 586}}, {\"fact\": \"Goal\"}] for fact \"Goal\": Could not parse output: The goal is to create a function that takes a medical fact as input and returns a JSON object with the fields \"location\", \"specific\", and \"general\" based on the provided information.\n",
      "2023-06-27 23:39:09,463 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. The given medical fact refers to observations or findings in medical imaging, such as X-rays or CT scans. The output JSON object should describe the location and nature of the observation., returning default object\n",
      "2023-06-27 23:39:09,463 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... information.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 48, \"total_tokens\": 597}}, {\"fact\": \"Justification\"}] for fact \"Justification\": Could not parse output: The task requires parsing a medical fact and extracting relevant information such as anatomical location and observation details. The output should be in the form of a JSON object with specific fields. This will allow for easy retrieval and manipulation of the extracted information.\n",
      "2023-06-27 23:39:09,463 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...apacit\\u00e9s.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 56, \"total_tokens\": 606}}, {\"fact\": \"Enqu\\u00eate\"}] for fact \"Enquête\": Could not parse output: Je suis désolé, je ne comprends pas ce que vous voulez dire par \"enquête\". Pouvez-vous fournir plus de détails ou poser une question spécifique ? Je serai heureux de vous aider dans la mesure de mes capacités.\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...usage\": {\"prompt_tokens\": 553, \"completion_tokens\": 84, \"total_tokens\": 637}}, {\"fact\": \"Additional considerations in appropriate clinical settings\"}] for fact \"Additional considerations in appropriate clinical settings\": Could not parse output: In appropriate clinical settings, there are additional considerations to take into account when providing the medical fact. These considerations may include the patient's medical history, symptoms, physical examination findings, and any relevant diagnostic test results. These factors can help in determining the significance and appropriate management of the observation. It is important to consult with a healthcare professional for a comprehensive evaluation and interpretation of the medical fact in the context of the individual patient.\n",
      "2023-06-27 23:39:09,464 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sure! Here's an example with all the fields, including a bonus field called \"notes\" which can contain any additional information related to the observation:\n",
      "\n",
      "Linear opacity at left base\n",
      "{\n",
      "\"location\": \"left base\",\n",
      "\"specific\": \"linear opacity\",\n",
      "\"general\": \"opacity\",\n",
      "\"notes\": \"Opacity may indicate a possible infection or inflammation in the left base\"\n",
      "}, returning default object\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...iven.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 120, \"total_tokens\": 670}}, {\"fact\": \"Expectable locations\"}] for fact \"Expectable locations\": Could not parse output: The possible values for the \"location\" field can vary depending on the medical fact provided. Here are some examples of expectable locations:\n",
      "\n",
      "- Left base\n",
      "- Left lower lung\n",
      "- Left lower lobe\n",
      "- Retrocardiac position\n",
      "- Adjacent to the left heart border\n",
      "- Posterior portion of the left lower lobe\n",
      "- Left mid and lower lung\n",
      "- Lingular segment of the left lobe\n",
      "- Left fourth rib\n",
      "- Aorta\n",
      "\n",
      "These are just a few examples, and the actual value of the \"location\" field will depend on the specific medical fact given.\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... empty.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 117, \"total_tokens\": 666}}, {\"fact\": \"Requirement needed\"}] for fact \"Requirement needed\": Could not parse output: The requirement is to create a JSON object with 3 fields: \"location\", \"specific\", and \"general\" based on a given medical fact. The \"location\" field should contain the anatomical location of the observation if provided, otherwise it should be empty. The \"specific\" and \"general\" fields both refer to the observation. The \"general\" field should be very short, while the \"specific\" field should contain additional attributes if provided. If only an anatomical location is provided but the observation is missing, both \"specific\" and \"general\" should be empty.\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...sion\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 129, \"total_tokens\": 681}}, {\"fact\": \"Possible possiblities\"}] for fact \"Possible possiblities\": Could not parse output: 1. Linear opacity at left base\n",
      "2. Linear bands of atelectasis in the left lower lung\n",
      "3. Left lower lobe linear densities\n",
      "4. Triangular-shaped density in retrocardiac position\n",
      "5. Aortic mass adjacent to the left heart border\n",
      "6. Parenchymal densities in the posterior portion of the left lower lobe\n",
      "7. Peripheral band-like opacities in left mid and lower lung\n",
      "8. Atelectasis in the lingular segment of the left lobe\n",
      "9. Mass involving left fourth rib\n",
      "10. Left base\n",
      "11. Aorta\n",
      "12. Pleural effusion\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... the output.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 183, \"total_tokens\": 732}}, {\"fact\": \"Plan approach\"}] for fact \"Plan approach\": Could not parse output: To solve this problem, we can follow these steps:\n",
      "\n",
      "1. Split the input medical fact into individual words.\n",
      "2. Identify the anatomical location by searching for specific keywords such as \"left\", \"right\", \"upper\", \"lower\", \"lobe\", \"segment\", \"portion\", etc.\n",
      "3. Identify the observation by searching for specific keywords such as \"opacity\", \"density\", \"mass\", \"atelectasis\", \"effusion\", etc.\n",
      "4. If an anatomical location is found, remove it from the list of words.\n",
      "5. If an observation is found, remove it from the list of words.\n",
      "6. Join the remaining words to form the general observation.\n",
      "7. If an anatomical location is found, join the remaining words to form the specific observation.\n",
      "8. Create a JSON object with the \"location\", \"specific\", and \"general\" fields and return it as the output.\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...nts.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 55, \"total_tokens\": 606}}, {\"fact\": \"Feasibility evaluation\"}] for fact \"Feasibility evaluation\": Could not parse output: The task of generating a JSON object with the given fields based on a medical fact is feasible. It involves parsing the medical fact to extract the relevant information such as anatomical location, specific observation, and general observation. The logic can be implemented using string manipulation and conditional statements.\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 72, \"total_tokens\": 623}}, {\"fact\": \"Radiology communications dashboard\"}] for fact \"Radiology communications dashboard\": Could not parse output: {\n",
      "  \"dashboard\": \"radiology communications\",\n",
      "  \"fields\": [\n",
      "    {\n",
      "      \"name\": \"location\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"specific\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"general\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "2023-06-27 23:39:09,464 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 200, \"total_tokens\": 752}}, {\"fact\": \"Region needs to be clarified\"}] for fact \"Region needs to be clarified\": Could not parse output: If the region needs to be clarified, you can include it as a separate field in the JSON object called \"region\". The \"location\" field should still contain the anatomical location, if provided. Here are some examples:\n",
      "\n",
      "Linear opacity at left base in the lower lobe\n",
      "{\n",
      "\"region\": \"lower lobe\",\n",
      "\"location\": \"left base\",\n",
      "\"specific\": \"linear opacity\",\n",
      "\"general\": \"opacity\"\n",
      "}\n",
      "\n",
      "Triangular-shaped density in retrocardiac position in the upper lobe\n",
      "{\n",
      "\"region\": \"upper lobe\",\n",
      "\"location\": \"retrocardiac position\",\n",
      "\"specific\": \"triangular-shaped density\",\n",
      "\"general\": \"density\"\n",
      "}\n",
      "\n",
      "Parenchymal densities in the posterior portion of the left lower lobe in the middle lobe\n",
      "{\n",
      "\"region\": \"middle lobe\",\n",
      "\"location\": \"posterior portion of the left lower lobe\",\n",
      "\"specific\": \"parenchymal densities\",\n",
      "\"general\": \"densities\"\n",
      "}\n",
      "\n",
      "Peripheral band\n",
      "2023-06-27 23:39:09,464 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Here is the explanation for the given examples:\n",
      "\n",
      "1. Linear opacity at left base:\n",
      "   - Location: \"left base\"\n",
      "   - Specific: \"linear opacity\"\n",
      "   - General: \"opacity\"\n",
      "\n",
      "2. Linear bands of atelectasis in the left lower lung:\n",
      "   - Location: \"left lower lung\"\n",
      "   - Specific: \"linear bands of atelectasis\"\n",
      "   - General: \"atelectasis\"\n",
      "\n",
      "3. Left lower lobe linear densities:\n",
      "   - Location: \"left lower lobe\"\n",
      "   - Specific: \"linear densities\"\n",
      "   - General: \"densities\"\n",
      "\n",
      "4. Triangular-shaped density in retrocardiac position:\n",
      "   - Location: \"retrocardiac position\"\n",
      "   - Specific: \"triangular-shaped density\"\n",
      "   - General: \"density\"\n",
      "\n",
      "5. Aortic mass adjacent to the left heart border:\n",
      "   - Location: \"adjacent to the left heart border\"\n",
      "   - Specific: \"aortic mass\"\n",
      "  , returning default object\n",
      "2023-06-27 23:39:09,464 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for any confusion. Here is a revised explanation:\n",
      "\n",
      "Given a medical fact, the task is to generate a JSON object with three fields: \"location\", \"specific\", and \"general\". The \"location\" field should contain the anatomical location of the observation if provided, otherwise it should be empty. The \"specific\" field refers to the specific observation and should be as detailed as possible. The \"general\" field should provide a more general description of the observation.\n",
      "\n",
      "If both the anatomical location and the specific observation are provided, the \"location\" field should contain the anatomical location, the \"specific\" field should contain the specific observation, and the \"general\" field should provide a more general description of the observation.\n",
      "\n",
      "If only the anatomical location is provided and the specific observation is missing, the \"location\" field should contain the anatomical location, and both the \"specific\" and \"general\" fields should be empty.\n",
      "\n",
      "If only the specific observation is provided and the anatomical, returning default object\n",
      "2023-06-27 23:39:09,465 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...n\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Generalization process\"}] for fact \"Generalization process\": Could not parse output: To generalize the medical fact, we need to identify the main observation or finding and categorize it into a more general term. This involves understanding the specific attributes or characteristics of the observation and determining a broader term that encompasses those attributes.\n",
      "\n",
      "Here is a step-by-step process to generalize the medical fact:\n",
      "\n",
      "1. Identify the main observation or finding: Read the medical fact and identify the key observation or finding mentioned. This could be a specific abnormality, condition, or characteristic.\n",
      "\n",
      "2. Determine the specific attributes: Look for any additional attributes or details provided in the medical fact that describe the observation. These attributes could include the shape, location, size, or appearance of the observation.\n",
      "\n",
      "3. Categorize into a general term: Based on the specific attributes, categorize the observation into a more general term that encompasses those attributes. This general term should be a broader category or classification of the specific observation.\n",
      "\n",
      "4. Assign the general and specific terms: Assign the general term to the \"general\" field in\n",
      "2023-06-27 23:39:09,465 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...an\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"Technical perspective\"}] for fact \"Technical perspective\": Could not parse output: To solve this problem, we can use regular expressions to extract the relevant information from the medical fact. We can define patterns for anatomical locations, specific observations, and general observations. \n",
      "\n",
      "First, we can check if the medical fact contains an anatomical location by searching for specific keywords such as \"base\", \"lobe\", \"segment\", \"position\", \"border\", etc. If a match is found, we extract the location and remove it from the medical fact.\n",
      "\n",
      "Next, we can search for specific observations using keywords such as \"opacity\", \"density\", \"mass\", \"effusion\", etc. If a match is found, we extract the specific observation and remove it from the medical fact.\n",
      "\n",
      "Finally, if there are no specific observations remaining in the medical fact, we can assume that the general observation is the same as the specific observation. Otherwise, the general observation can be a more general term for the specific observation.\n",
      "\n",
      "Once we have extracted the location, specific observation, and general observation, we can\n",
      "2023-06-27 23:39:09,465 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...eason\": \"length\"}], \"usage\": {\"prompt_tokens\": 552, \"completion_tokens\": 200, \"total_tokens\": 752}}, {\"fact\": \"Repeat with more optimized technique\"}] for fact \"Repeat with more optimized technique\": Could not parse output: def parse_medical_fact(fact):\n",
      "    observation = \"\"\n",
      "    location = \"\"\n",
      "    \n",
      "    # Check for specific observations\n",
      "    if \"opacity\" in fact:\n",
      "        observation = \"opacity\"\n",
      "    elif \"atelectasis\" in fact:\n",
      "        observation = \"atelectasis\"\n",
      "    elif \"densities\" in fact:\n",
      "        observation = \"densities\"\n",
      "    elif \"mass\" in fact:\n",
      "        observation = \"mass\"\n",
      "    elif \"opacities\" in fact:\n",
      "        observation = \"opacities\"\n",
      "    elif \"effusion\" in fact:\n",
      "        observation = \"pleural effusion\"\n",
      "    \n",
      "    # Check for anatomical location\n",
      "    if \"left base\" in fact:\n",
      "        location = \"left base\"\n",
      "    elif \"left lower lung\" in fact:\n",
      "        location = \"left lower lung\"\n",
      "    elif \"left lower lobe\" in fact:\n",
      "        location = \"left lower lobe\"\n",
      "    elif \"retrocardiac position\" in fact:\n",
      "        location =\n",
      "2023-06-27 23:39:09,467 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I don't understand what you mean by \"Cour\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,467 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"conversion\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,468 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for any confusion caused. Could you please provide more details or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,468 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I couldn't understand your input. Could you please provide a valid medical fact?, returning default object\n",
      "2023-06-27 23:39:09,468 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...on\\\"\\n    }\\n]\\n}\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 548, \"completion_tokens\": 135, \"total_tokens\": 683}}, {\"fact\": \"Entities\"}] for fact \"Entities\": Could not parse output: {\n",
      "\"entities\": [\n",
      "    {\n",
      "        \"start\": 0,\n",
      "        \"end\": 9,\n",
      "        \"value\": \"Linear\",\n",
      "        \"entity\": \"observation\"\n",
      "    },\n",
      "    {\n",
      "        \"start\": 10,\n",
      "        \"end\": 16,\n",
      "        \"value\": \"opacity\",\n",
      "        \"entity\": \"observation\"\n",
      "    },\n",
      "    {\n",
      "        \"start\": 20,\n",
      "        \"end\": 24,\n",
      "        \"value\": \"left\",\n",
      "        \"entity\": \"location\"\n",
      "    },\n",
      "    {\n",
      "        \"start\": 25,\n",
      "        \"end\": 29,\n",
      "        \"value\": \"base\",\n",
      "        \"entity\": \"location\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "2023-06-27 23:39:09,469 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I don't understand what you mean by \"Standarding\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,469 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I need more information or a specific medical fact in order to provide the desired output. Could you please provide a medical fact or a specific observation?, returning default object\n",
      "2023-06-27 23:39:09,470 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Radiologist check\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,470 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"discrimination between possibilities\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,471 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sorry, but I can't generate medical records., returning default object\n",
      "2023-06-27 23:39:09,471 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"technique limitations not allowed\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,479 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Suggestions of extension\"}] for fact \"Suggestions of extension\": Could not parse output: Here are some suggestions for extending the functionality of the program:\n",
      "\n",
      "1. Handle multiple observations: Modify the program to handle cases where there are multiple observations in the input. For example, \"Linear opacity at left base and pleural effusion\" should output two separate JSON objects for each observation.\n",
      "\n",
      "2. Handle modifiers: Some medical facts may include modifiers that provide additional information about the observation. For example, \"Large mass involving left fourth rib\" or \"Small pleural effusion\". Modify the program to include a \"modifier\" field in the JSON object to capture these modifiers.\n",
      "\n",
      "3. Handle uncertainty: In some cases, the medical fact may include uncertainty or ambiguity. For example, \"Possible linear opacity at left base\" or \"Probable pleural effusion\". Modify the program to include an \"uncertainty\" field in the JSON object to capture these uncertainties.\n",
      "\n",
      "4. Handle laterality: In cases where the observation is specific to one side of the body, such as \"Opacity in the right\n",
      "2023-06-27 23:39:09,480 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide the medical fact again?, returning default object\n",
      "2023-06-27 23:39:09,481 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide the medical fact again?, returning default object\n",
      "2023-06-27 23:39:09,481 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Different ages\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,481 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"different reason\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,482 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"terminates in appropriate fashion\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 23:39:09,488 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to export the recommended JSON object for you. My purpose is to assist with generating the JSON object based on the provided medical fact. If you have a specific medical fact that you would like me to process, please provide it and I'll be happy to help you generate the JSON object., returning default object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 23:39:09,496 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"She changes\". Could you please provide more context or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,498 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Here are some suggestions for medical facts:\r\n",
      "\r\n",
      "1. Consolidation in the right middle lobe\r\n",
      "2. Ground-glass opacities in bilateral lung fields\r\n",
      "3. Nodule in the upper lobe of the right lung\r\n",
      "4. Pleural thickening in the left hemithorax\r\n",
      "5. Cavitary lesion in the right lower lobe\r\n",
      "6. Enlarged lymph nodes in the mediastinum\r\n",
      "7. Pneumothorax in the right lung\r\n",
      "8. Pulmonary edema in the bilateral lung fields\r\n",
      "9. Atelectasis in the right lower lobe\r\n",
      "10. Mass in the liver\r\n",
      "\r\n",
      "Please let me know if you need more examples or if you have any specific requirements., returning default object\r\n",
      "2023-06-27 23:39:09,498 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you're asking. Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,498 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"re-adjustment\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,499 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...curate and complete.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 548, \"completion_tokens\": 64, \"total_tokens\": 612}}, {\"fact\": \"Review\"}] for fact \"Review\": Could not parse output: The solution provided correctly handles the different cases and generates the expected output. It correctly identifies the anatomical location, specific observation, and general observation based on the given medical fact. The solution also handles cases where the observation or anatomical location is missing and generates the appropriate output. Overall, the solution is accurate and complete.\r\n",
      "2023-06-27 23:39:09,499 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to generate the JSON object you're looking for., returning default object\r\n",
      "2023-06-27 23:39:09,499 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Addendum\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,499 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"intention\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,500 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for any confusion. Could you please provide me with the medical fact you would like to convert into a JSON object?, returning default object\r\n",
      "2023-06-27 23:39:09,502 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to provide recommendations based on the given medical fact. My purpose is to generate JSON objects based on medical facts. If you have any other medical facts that you would like me to process, please let me know., returning default object\r\n",
      "2023-06-27 23:39:09,503 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I don't understand what you mean by \"If desired\". Could you please clarify or provide more information?, returning default object\r\n",
      "2023-06-27 23:39:09,504 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to generate the JSON object without a medical fact. Could you please provide a medical fact for me to work with?, returning default object\r\n",
      "2023-06-27 23:39:09,504 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Other option\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,507 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...e\": {\"prompt_tokens\": 558, \"completion_tokens\": 30, \"total_tokens\": 588}}, {\"fact\": \"Right posteromedial opacity should have attention on follow-up\"}] for fact \"Right posteromedial opacity should have attention on follow-up\": Could not parse output: {\r\n",
      "\"location\": \"right posteromedial\",\r\n",
      "\"specific\": \"opacity\",\r\n",
      "\"general\": \"opacity\",\r\n",
      "\"follow_up\": \"attention\"\r\n",
      "}\r\n",
      "2023-06-27 23:39:09,510 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sure! Here's a more detailed explanation of the fields in the JSON object:\r\n",
      "\r\n",
      "1. \"location\": This field represents the anatomical location of the observation. It should contain the specific location mentioned in the medical fact. For example, if the fact mentions \"linear opacity at left base\", the \"location\" field should be \"left base\". If no anatomical location is provided, this field should be empty.\r\n",
      "\r\n",
      "2. \"specific\": This field represents the specific observation mentioned in the medical fact. It should provide a more detailed description of the observation. For example, if the fact mentions \"linear opacity at left base\", the \"specific\" field should be \"linear opacity\". If no specific observation is provided, this field should be empty.\r\n",
      "\r\n",
      "3. \"general\": This field represents a general term or category that the specific observation falls under. It should provide a broader description of the observation. For example, if the fact mentions \"linear opacity at left base\", the \"general\" field should be, returning default object\r\n",
      "2023-06-27 23:39:09,511 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\... \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 180, \"total_tokens\": 731}}, {\"fact\": \"Potential option for process\"}] for fact \"Potential option for process\": Could not parse output: To solve this problem, you can follow these steps:\r\n",
      "\r\n",
      "1. Parse the input medical fact to extract the anatomical location and observation.\r\n",
      "2. Check if the anatomical location is provided. If it is, assign it to the \"location\" field in the JSON object. Otherwise, leave it empty.\r\n",
      "3. Check if the observation is provided. If it is, assign it to both the \"specific\" and \"general\" fields in the JSON object. Otherwise, leave both fields empty.\r\n",
      "4. If the observation is provided, check if there are any additional attributes or qualifiers. If there are, append them to the \"specific\" field in the JSON object.\r\n",
      "5. Return the JSON object with the \"location\", \"specific\", and \"general\" fields.\r\n",
      "\r\n",
      "By following these steps, you can accurately extract the anatomical location and observation from the medical fact and generate the required JSON object.\r\n",
      "2023-06-27 23:39:09,512 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for any confusion. Here is a clearer explanation:\r\n",
      "\r\n",
      "Given a medical fact, you need to create a JSON object with 3 fields: \"location\", \"specific\", and \"general\".\r\n",
      "\r\n",
      "1. \"Location\" should contain the anatomical location of the observation if provided. If no anatomical location is provided, it should be empty.\r\n",
      "\r\n",
      "2. \"Specific\" refers to the specific observation mentioned in the medical fact. It should be a more detailed description of the observation. If no specific observation is provided, it should be empty.\r\n",
      "\r\n",
      "3. \"General\" refers to a general term or category that the specific observation falls under. It should be a shorter and more general description. If no specific observation is provided, \"general\" should be empty as well.\r\n",
      "\r\n",
      "Here are some examples to help clarify:\r\n",
      "\r\n",
      "Example 1:\r\n",
      "Medical Fact: \"Linear opacity at left base\"\r\n",
      "JSON Object:\r\n",
      "{\r\n",
      "  \"location\": \"left base\",\r\n",
      "  \"specific\": \"linear opacity\",\r\n",
      "  \"general\": \", returning default object\r\n",
      "2023-06-27 23:39:09,512 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sure, I can provide further clarification. Please let me know what specific information you need clarification on., returning default object\r\n",
      "2023-06-27 23:39:09,514 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for any confusion. Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,515 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but as an AI text-based model, I cannot directly process or analyze images. However, if you can provide a description or text-based information about the medical fact or observation, I would be happy to assist you in generating the JSON object., returning default object\r\n",
      "2023-06-27 23:39:09,517 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...pty.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 60, \"total_tokens\": 609}}, {\"fact\": \"Position clarification\"}] for fact \"Position clarification\": Could not parse output: The \"location\" field refers to the anatomical location of the observation. For example, if the observation is \"Linear opacity at left base\", the \"location\" field would be \"left base\". If the observation does not specify an anatomical location, the \"location\" field should be empty.\r\n",
      "2023-06-27 23:39:09,520 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to understand your request. Could you please provide more information or clarify your question?, returning default object\r\n",
      "2023-06-27 23:39:09,523 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"duplicated view\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,525 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I am unable to process images. I can only work with text inputs. If you have any medical facts or observations that you would like me to process, please provide them in text format., returning default object\r\n",
      "2023-06-27 23:39:09,526 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I don't understand what you mean by \"Sufragment\". Can you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,526 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Sorry, but I'm not sure what you mean by \"Interfaces\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,526 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...el free to ask.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 16, \"total_tokens\": 566}}, {\"fact\": \"Appreciated\"}] for fact \"Appreciated\": Could not parse output: You're welcome! If you have any more questions, feel free to ask.\r\n",
      "2023-06-27 23:39:09,529 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Dr phone\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,531 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you're asking. Could you please provide more information or clarify your question?, returning default object\r\n",
      "2023-06-27 23:39:09,531 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the technical error. Could you please provide the medical fact again?, returning default object\r\n",
      "2023-06-27 23:39:09,532 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: Could you please provide more information or clarify your question?, returning default object\r\n",
      "2023-06-27 23:39:09,534 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...o ask.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 551, \"completion_tokens\": 27, \"total_tokens\": 578}}, {\"fact\": \"Satisfactory results\"}] for fact \"Satisfactory results\": Could not parse output: I'm glad to hear that the results are satisfactory! If you have any more questions or need further assistance, feel free to ask.\r\n",
      "2023-06-27 23:39:09,535 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to generate a response without a specific medical fact. Could you please provide a medical fact for me to work with?, returning default object\r\n",
      "2023-06-27 23:39:09,536 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"variations in lung finding\". Could you please provide more specific information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,536 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"ascending order\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,536 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the inconvenience. Could you please provide a medical fact or observation for me to generate the JSON object?, returning default object\r\n",
      "2023-06-27 23:39:09,539 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I need more information in order to provide a response. Could you please provide a medical fact or observation?, returning default object\r\n",
      "2023-06-27 23:39:09,540 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Here's the updated code to handle the given medical facts and generate the JSON object:\r\n",
      "\r\n",
      "```python\r\n",
      "import json\r\n",
      "\r\n",
      "def generate_json(location, specific, general):\r\n",
      "    data = {\r\n",
      "        \"location\": location,\r\n",
      "        \"specific\": specific,\r\n",
      "        \"general\": general\r\n",
      "    }\r\n",
      "    return json.dumps(data)\r\n",
      "\r\n",
      "# Examples with all the fields\r\n",
      "json_data = generate_json(\"left base\", \"linear opacity\", \"opacity\")\r\n",
      "print(json_data)\r\n",
      "\r\n",
      "json_data = generate_json(\"left lower lung\", \"linear bands of atelectasis\", \"atelectasis\")\r\n",
      "print(json_data)\r\n",
      "\r\n",
      "json_data = generate_json(\"left lower lobe\", \"linear densities\", \"densities\")\r\n",
      "print(json_data)\r\n",
      "\r\n",
      "json_data = generate_json(\"retrocardiac position\", \"triangular-shaped density\", \"density\")\r\n",
      "print(json_data)\r\n",
      "\r\n",
      "json_data = generate_json(\"adjacent to the left heart border\", \"aortic mass\", \"mass\")\r\n",
      "print(json_data)\r\n",
      "\r\n",
      "json_data = generate, returning default object\r\n",
      "2023-06-27 23:39:09,540 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"unclear contributions\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,540 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"renewed visualization\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,541 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"lead using expected positions\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,542 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"placement of box\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,544 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the error. Could you please provide the correct medical fact so that I can generate the JSON object accurately?, returning default object\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 23:39:09,551 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to generate recommendations based on the given medical fact. My purpose is to provide information and assist with generating JSON objects based on medical facts. If you have any specific medical facts you would like me to process, please provide them and I'll be happy to assist you., returning default object\r\n",
      "2023-06-27 23:39:09,551 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I can't generate that JSON object for you., returning default object\r\n",
      "2023-06-27 23:39:09,552 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion, but I'm not sure what you mean by \"document resolution\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,559 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Further evaluation step\"}] for fact \"Further evaluation step\": Could not parse output: To further evaluate the medical fact, you can consider the following steps:\r\n",
      "\r\n",
      "1. Review the patient's medical history: Look for any relevant information about the patient's past medical conditions, surgeries, or treatments that may be related to the observation.\r\n",
      "\r\n",
      "2. Conduct a physical examination: Perform a thorough physical examination of the patient, focusing on the area mentioned in the observation. Look for any signs or symptoms that may support or contradict the observation.\r\n",
      "\r\n",
      "3. Order diagnostic tests: Depending on the nature of the observation, you may need to order specific diagnostic tests such as imaging studies (X-ray, CT scan, MRI), laboratory tests, or biopsies to gather more information and confirm the observation.\r\n",
      "\r\n",
      "4. Consult with specialists: If the observation is complex or requires specialized knowledge, consider consulting with relevant specialists such as radiologists, pathologists, or surgeons to get their expert opinion and guidance.\r\n",
      "\r\n",
      "5. Analyze the results: Once you have the results of the diagnostic tests, carefully analyze them in conjunction with\r\n",
      "2023-06-27 23:39:09,562 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"partial reverse section\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,564 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide more details or clarify what you mean by \"better quantification\"?, returning default object\r\n",
      "2023-06-27 23:39:09,571 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"re-demonstration\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,572 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...h_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 119, \"total_tokens\": 669}}, {\"fact\": \"Further definitive characterization\"}] for fact \"Further definitive characterization\": Could not parse output: To further characterize the observation, you can add additional fields to the JSON object. Here's an example:\r\n",
      "\r\n",
      "Linear opacity at left base\r\n",
      "{\r\n",
      "\"location\": \"left base\",\r\n",
      "\"specific\": \"linear opacity\",\r\n",
      "\"general\": \"opacity\",\r\n",
      "\"shape\": \"linear\",\r\n",
      "\"size\": \"\",\r\n",
      "\"border\": \"\",\r\n",
      "\"composition\": \"\"\r\n",
      "}\r\n",
      "\r\n",
      "In this example, \"shape\", \"size\", \"border\", and \"composition\" are additional attributes that can be used to provide more specific information about the observation. You can add these fields as needed, depending on the available information and the specific medical context.\r\n",
      "2023-06-27 23:39:09,573 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to provide a radiology review. I can only assist with generating JSON objects based on medical facts. If you have any medical facts that you would like me to generate a JSON object for, please let me know., returning default object\r\n",
      "2023-06-27 23:39:09,574 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I cannot provide detail views for the given medical facts. My purpose is to generate JSON objects based on the provided information., returning default object\r\n",
      "2023-06-27 23:39:09,574 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"other alternative consideration\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,574 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to provide a differential diagnosis based on the given medical fact. My purpose is to generate JSON objects based on medical facts. If you have any specific medical facts that you would like me to generate JSON objects for, please let me know and I'll be happy to assist you., returning default object\r\n",
      "2023-06-27 23:39:09,574 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to provide the specific JSON object you're looking for., returning default object\r\n",
      "2023-06-27 23:39:09,577 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"changing pattern\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,579 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide me with the medical fact that you would like to convert into a JSON object?, returning default object\r\n",
      "2023-06-27 23:39:09,582 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I need more information in order to provide a more precise evaluation. Can you please provide me with the specific medical fact or observation that you would like me to evaluate?, returning default object\r\n",
      "2023-06-27 23:39:09,584 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not able to assist with that request., returning default object\r\n",
      "2023-06-27 23:39:09,590 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Question of integrity\". Could you please provide more information or clarify your question?, returning default object\r\n",
      "2023-06-27 23:39:09,594 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide the medical fact that you would like me to process?, returning default object\r\n",
      "2023-06-27 23:39:09,594 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide me with the medical fact that you would like to convert into a JSON object?, returning default object\r\n",
      "2023-06-27 23:39:09,595 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"supporting between possibilities\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,598 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"components in their respective positions\". Could you please provide more information or clarify your request?, returning default object\r\n",
      "2023-06-27 23:39:09,599 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide a specific medical fact or observation for me to generate the JSON object?, returning default object\r\n",
      "2023-06-27 23:39:09,599 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide the medical fact that you would like me to process?, returning default object\r\n",
      "2023-06-27 23:39:09,599 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I apologize for the confusion. Could you please provide me with the medical fact that you would like to convert into a JSON object?, returning default object\r\n",
      "2023-06-27 23:39:09,600 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 23:39:09,610 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 14438 of 14463 API responses.\r\n",
      "                    25 of 14463 API responses could not be processed.\r\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_fine_grained_details_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\" \\\n",
    "    --preprocessed_facts_to_skip_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\" \\\n",
    "    --offset 0 \\\n",
    "    --num_facts 30000 \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "388753b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-28 08:57:33,655 - \u001b[1;32mINFO\u001b[1;0m - Loaded 29415 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\n",
      "2023-06-28 08:57:33,855 - \u001b[1;32mINFO\u001b[1;0m - Loaded 24741 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n",
      "2023-06-28 08:57:33,871 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 54156\n",
      "2023-06-28 08:57:36,454 - \u001b[1;32mINFO\u001b[1;0m - Loaded 360415 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_details_Seq2Seq(t5-small)_256_1_20230628_082217.jsonl\n",
      "2023-06-28 08:57:36,675 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 414571\n",
      "2023-06-28 08:57:36,675 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-28 08:57:44,025 - \u001b[1;32mINFO\u001b[1;0m - Loaded 849523 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-28 08:57:45,181 - \u001b[1;32mINFO\u001b[1;0m - Found 414580 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-28 08:57:45,213 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 414580/414580 [00:51<00:00, 8079.85it/s]\n",
      "2023-06-28 08:58:36,525 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 414580/414580 [00:00<00:00, 434166.38it/s]\n",
      "2023-06-28 08:58:38,527 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-06-28 08:58:38,527 - \u001b[1;32mINFO\u001b[1;0m - First fact: Mediastinal bulgary bulgarian mediastinal bulgarian mediastinal bulgarian hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-28 08:58:38,527 - \u001b[1;32mINFO\u001b[1;0m - Last fact: Right\n",
      "2023-06-28 08:58:38,670 - \u001b[1;33mWARNING\u001b[1;0m - Requested 500000 facts but only 414580 are available. Using 414580 instead.\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 9\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 1. Right lower lateral rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage rib cage opacity\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 2. Screws at level T4,\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 3. Generally appropriate configuration\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 4. Generally directed chest tube\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 5. Generally stable diffuse abnormality\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 6. Fixation screws at level T4,\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 7. Soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue soft tissue\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 8. Metastases in T8,\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - 9. General findings\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230628_085838.jsonl\n",
      "2023-06-28 08:58:38,882 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230628_085838.jsonl\n",
      "2023-06-28 08:58:39,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-28 08:58:42,455 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230628_085838.jsonl\n",
      "2023-06-28 08:58:42,458 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230628_085838.jsonl\n",
      "2023-06-28 08:58:42,459 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-06-28 08:58:42,459 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 9 of 9 API responses.\n",
      "                    0 of 9 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_fine_grained_details_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\" \\\n",
    "    --preprocessed_facts_to_skip_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_details_Seq2Seq(t5-small)_256_1_20230628_082217.jsonl\" \\\n",
    "    --offset 0 \\\n",
    "    --num_facts 500000 \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b54d59c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-28 10:00:00,011 - \u001b[1;32mINFO\u001b[1;0m - Loaded 29424 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\n",
      "2023-06-28 10:00:00,206 - \u001b[1;32mINFO\u001b[1;0m - Loaded 24741 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n",
      "2023-06-28 10:00:00,222 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 54165\n",
      "2023-06-28 10:00:02,761 - \u001b[1;32mINFO\u001b[1;0m - Loaded 360415 facts to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_details_Seq2Seq(t5-small)_256_1_20230628_082217.jsonl\n",
      "2023-06-28 10:00:02,987 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to skip: 414580\n",
      "2023-06-28 10:00:02,987 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63882717).jsonl\n",
      "2023-06-28 10:00:10,259 - \u001b[1;32mINFO\u001b[1;0m - Loaded 849523 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63882717).jsonl\n",
      "2023-06-28 10:00:11,397 - \u001b[1;32mINFO\u001b[1;0m - Found 414563 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63882717).jsonl\n",
      "2023-06-28 10:00:11,429 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 414563/414563 [00:51<00:00, 8116.45it/s]\n",
      "2023-06-28 10:01:02,508 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 414563/414563 [00:00<00:00, 433250.61it/s]\n",
      "2023-06-28 10:01:04,511 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-06-28 10:01:04,511 - \u001b[1;32mINFO\u001b[1;0m - First fact: Mediastinal bulgary bulgarian mediastinal hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-28 10:01:04,512 - \u001b[1;32mINFO\u001b[1;0m - Last fact: Right\n",
      "2023-06-28 10:01:04,651 - \u001b[1;33mWARNING\u001b[1;0m - Requested 500000 facts but only 414563 are available. Using 414563 instead.\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 27\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 1. Mediastinal bulgary bulgarian mediastinal hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 3. Poor quality of radiograph hyperdense definitive evaluation\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 6. Air outlining airless lung\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 9. Looped proximal malposition\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 12. Radiodense left lateral view\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 15. Partially imaged proximal right humeral prosthesis\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 18. Right lower lateral rib cage opacity\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 21. Posterior pleural sinus enlargement\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 24. Mediastinal midline volume\n",
      "2023-06-28 10:01:04,859 - \u001b[1;32mINFO\u001b[1;0m - 27. Moderate to bilateral pleural effusions\n",
      "2023-06-28 10:01:04,860 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230628_100104.jsonl\n",
      "2023-06-28 10:01:04,860 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230628_100104.jsonl\n",
      "2023-06-28 10:01:05,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-28 10:01:05,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-06-28 10:01:35,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 4 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 07032c23ed043f85ce6b7d565459e879 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-28 10:01:37,152 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230628_100104.jsonl\n",
      "2023-06-28 10:01:37,156 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230628_100104.jsonl\n",
      "2023-06-28 10:01:37,160 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-06-28 10:01:37,160 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 27 of 27 API responses.\n",
      "                    0 of 27 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_fine_grained_details_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63882717).jsonl\" \\\n",
    "    --preprocessed_facts_to_skip_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/huggingface/extracted_details_Seq2Seq(t5-small)_256_1_20230628_082217.jsonl\" \\\n",
    "    --offset 0 \\\n",
    "    --num_facts 500000 \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f633648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdadc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__hard.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3496c10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29451"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ee740ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'fact': 'Small amount of posterior pleural sinus atelectasis in the left base'},\n",
       "  'parsed_response': {'location': 'left base',\n",
       "   'specific': 'small amount of posterior pleural sinus atelectasis',\n",
       "   'general': 'atelectasis'}},\n",
       " {'metadata': {'fact': 'Looped proximal malposition'},\n",
       "  'parsed_response': {'location': 'proximal',\n",
       "   'specific': 'looped malposition',\n",
       "   'general': 'malposition'}},\n",
       " {'metadata': {'fact': 'Radiodense left lateral view'},\n",
       "  'parsed_response': {'location': 'left lateral view',\n",
       "   'specific': 'radiodense',\n",
       "   'general': 'radiodense'}},\n",
       " {'metadata': {'fact': 'Emphysematous pulmonary'},\n",
       "  'parsed_response': {'location': '',\n",
       "   'specific': 'emphysematous pulmonary',\n",
       "   'general': 'emphysematous pulmonary'}},\n",
       " {'metadata': {'fact': 'Posterior pleural sinus enlargement'},\n",
       "  'parsed_response': {'location': 'posterior pleural sinus',\n",
       "   'specific': 'enlargement',\n",
       "   'general': 'enlargement'}},\n",
       " {'metadata': {'fact': 'Apex lateral'},\n",
       "  'parsed_response': {'location': 'apex lateral',\n",
       "   'specific': '',\n",
       "   'general': ''}},\n",
       " {'metadata': {'fact': 'Moderate to bilateral pleural effusions'},\n",
       "  'parsed_response': {'location': '',\n",
       "   'specific': 'moderate to bilateral pleural effusions',\n",
       "   'general': 'pleural effusions'}},\n",
       " {'metadata': {'fact': 'Poor quality of radiograph hyperdense definitive evaluation'},\n",
       "  'parsed_response': {'location': '',\n",
       "   'specific': 'poor quality of radiograph',\n",
       "   'general': 'poor quality'}},\n",
       " {'metadata': {'fact': 'Partially imaged proximal right humeral prosthesis'},\n",
       "  'parsed_response': {'location': 'proximal right humerus',\n",
       "   'specific': 'partially imaged proximal humeral prosthesis',\n",
       "   'general': 'prosthesis'}},\n",
       " {'metadata': {'fact': 'Air apical laterally apical and laterally air apical and laterally air apical and laterally air apical and laterally air apical and laterally air apical and laterally air apical and laterally air apical and laterally air apical and laterally air apical and likely due to positional differences'},\n",
       "  'parsed_response': {'location': 'apical and laterally',\n",
       "   'specific': 'air',\n",
       "   'general': 'air'}}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
