{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b6006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:10:40,314 - \u001b[1;32mINFO\u001b[1;0m - Loaded 101 already parsed sentences from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\n",
      "2023-07-03 16:10:40,314 - \u001b[1;32mINFO\u001b[1;0m - Loading preprocessed reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "100%|█████████████████████████████████| 227835/227835 [00:45<00:00, 5024.41it/s]\n",
      "2023-07-03 16:11:26,352 - \u001b[1;32mINFO\u001b[1;0m - Loaded 227835 reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "2023-07-03 16:11:26,352 - \u001b[1;32mINFO\u001b[1;0m - Found 677694 unique sentences to parse\n",
      "2023-07-03 16:11:26,408 - \u001b[1;32mINFO\u001b[1;0m - Sorting sentences by difficulty...\n",
      "100%|█████████████████████████████████| 677694/677694 [02:13<00:00, 5080.49it/s]\n",
      "2023-07-03 16:13:39,800 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 677694/677694 [00:03<00:00, 185946.39it/s]\n",
      "2023-07-03 16:13:46,694 - \u001b[1;32mINFO\u001b[1;0m - Done sorting sentences.\n",
      "2023-07-03 16:13:46,694 - \u001b[1;32mINFO\u001b[1;0m - First sentence: M recently stopped coumadin(afib) p/w L>R pain,abd pain, s/p 's, cold foot s/p L pop cutdown embolectomy L fasciotomy s/p LLE angio embolectomy s/p L guillotine + L BKA // Dobhoff placement - require assistance and sequential imaging.\n",
      "2023-07-03 16:13:46,694 - \u001b[1;32mINFO\u001b[1;0m - Last sentence: .\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to parse: 9899\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to parse:\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 1. WET READ VERSION #1 WET READ VERSION #2 8:46 PM RIGHT MAINSTEM INTUBATION WITH LEFT LUNG WHITE OUT.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 1100. SUCH RAPID IMPROVEMENT IS MORE TYPICAL OF ASPIRATION OR ATELECTASIS THAN INFECTIOUS PNEUMONIA.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 2200. Per OMR note, patient with known steak impaction in esophagus; however, if needed to evaluate for foreign body by xray, a lateral view of the neck and chest could be obtained.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 3300. Small right pleural effusion may layer posteriorly depending on the degree of incline in the patient's position.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 4400. Thoracoabdominal aortic ectasia is again noted.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 5499. Increase in minimal pleural thickening, effusion or hemothorax is due to multiple right-sided rib fractures from the lateral fifth through ninht ribs.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 6599. No pleural effusion or pneumothorax is seen.Flattening of the diaphragm may be secondary to emphysema or small airway obstruction.\n",
      "2023-07-03 16:13:47,091 - \u001b[1;32mINFO\u001b[1;0m - 7699. Single portable semi-erect chest film at 503 is submitted.\n",
      "2023-07-03 16:13:47,092 - \u001b[1;32mINFO\u001b[1;0m - 8799. Streaky bibasilar opacities which could represent aspiration versus bibasilar atelectasis=.\n",
      "2023-07-03 16:13:47,092 - \u001b[1;32mINFO\u001b[1;0m - 9899. Lung volumes are overall imrpoved.\n",
      "2023-07-03 16:13:47,177 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230703_161347.jsonl\n",
      "2023-07-03 16:13:47,177 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_161347.jsonl\n",
      "2023-07-03 16:13:47,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-03 16:13:47,904 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-07-03 16:13:48,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-07-03 16:13:48,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 56 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:13:48,514 - \u001b[1;33mWARNING\u001b[1;0m - Request 57 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:13:48,515 - \u001b[1;33mWARNING\u001b[1;0m - Request 51 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:13:48,523 - \u001b[1;33mWARNING\u001b[1;0m - Request 52 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:14:03,515 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:14:03 2023\n",
      "2023-07-03 16:14:03,523 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:14:03 2023\n",
      "2023-07-03 16:14:03,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #57\n",
      "2023-07-03 16:14:03,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 63 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:14:18,761 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:14:18 2023\n",
      "2023-07-03 16:14:18,792 - \u001b[1;32mINFO\u001b[1;0m - Starting request #75\n",
      "2023-07-03 16:14:18,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 80 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:14:33,997 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:14:33 2023\n",
      "2023-07-03 16:14:34,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #94\n",
      "2023-07-03 16:14:34,446 - \u001b[1;33mWARNING\u001b[1;0m - Request 93 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:14:49,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:14:49 2023\n",
      "2023-07-03 16:14:49,768 - \u001b[1;33mWARNING\u001b[1;0m - Request 110 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:15:04,782 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:15:04 2023\n",
      "2023-07-03 16:15:04,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #112\n",
      "2023-07-03 16:15:05,010 - \u001b[1;33mWARNING\u001b[1;0m - Request 112 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:15:20,019 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:15:20 2023\n",
      "2023-07-03 16:15:20,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #131\n",
      "2023-07-03 16:15:20,433 - \u001b[1;33mWARNING\u001b[1;0m - Request 127 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:15:35,444 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:15:35 2023\n",
      "2023-07-03 16:15:35,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #150\n",
      "2023-07-03 16:15:35,898 - \u001b[1;33mWARNING\u001b[1;0m - Request 151 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:15:50,910 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:15:50 2023\n",
      "2023-07-03 16:15:51,258 - \u001b[1;33mWARNING\u001b[1;0m - Request 162 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:16:06,268 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:16:06 2023\n",
      "2023-07-03 16:16:06,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #168\n",
      "2023-07-03 16:16:06,736 - \u001b[1;33mWARNING\u001b[1;0m - Request 180 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:16:21,747 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:16:21 2023\n",
      "2023-07-03 16:16:21,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #187\n",
      "2023-07-03 16:16:21,988 - \u001b[1;33mWARNING\u001b[1;0m - Request 194 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:16:36,997 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:16:36 2023\n",
      "2023-07-03 16:16:37,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #206\n",
      "2023-07-03 16:16:37,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 206 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:16:37,468 - \u001b[1;33mWARNING\u001b[1;0m - Request 207 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:16:52,295 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:16:52 2023\n",
      "2023-07-03 16:16:52,470 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:16:52 2023\n",
      "2023-07-03 16:16:53,592 - \u001b[1;33mWARNING\u001b[1;0m - Request 222 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:17:08,602 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:17:08 2023\n",
      "2023-07-03 16:17:08,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #222\n",
      "2023-07-03 16:17:08,905 - \u001b[1;33mWARNING\u001b[1;0m - Request 236 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:17:23,918 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:17:23 2023\n",
      "2023-07-03 16:17:23,941 - \u001b[1;32mINFO\u001b[1;0m - Starting request #242\n",
      "2023-07-03 16:17:24,372 - \u001b[1;33mWARNING\u001b[1;0m - Request 248 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:17:39,383 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:17:39 2023\n",
      "2023-07-03 16:17:39,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #261\n",
      "2023-07-03 16:17:39,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 251 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:17:54,946 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:17:54 2023\n",
      "2023-07-03 16:17:55,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 265 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:18:10,506 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:18:10 2023\n",
      "2023-07-03 16:18:10,508 - \u001b[1;32mINFO\u001b[1;0m - Starting request #265\n",
      "2023-07-03 16:18:10,759 - \u001b[1;33mWARNING\u001b[1;0m - Request 289 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:18:25,769 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:18:25 2023\n",
      "2023-07-03 16:18:25,792 - \u001b[1;32mINFO\u001b[1;0m - Starting request #298\n",
      "2023-07-03 16:18:25,999 - \u001b[1;33mWARNING\u001b[1;0m - Request 300 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:18:41,013 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:18:40 2023\n",
      "2023-07-03 16:18:41,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #317\n",
      "2023-07-03 16:18:41,334 - \u001b[1;33mWARNING\u001b[1;0m - Request 319 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:18:56,347 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:18:56 2023\n",
      "2023-07-03 16:18:56,721 - \u001b[1;33mWARNING\u001b[1;0m - Request 335 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:19:11,732 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:19:11 2023\n",
      "2023-07-03 16:19:11,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #336\n",
      "2023-07-03 16:19:12,168 - \u001b[1;33mWARNING\u001b[1;0m - Request 345 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:19:12,173 - \u001b[1;33mWARNING\u001b[1;0m - Request 341 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:19:27,180 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:19:27 2023\n",
      "2023-07-03 16:19:27,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #353\n",
      "2023-07-03 16:19:28,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 363 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:19:43,463 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:19:43 2023\n",
      "2023-07-03 16:19:43,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #372\n",
      "2023-07-03 16:19:43,685 - \u001b[1;33mWARNING\u001b[1;0m - Request 372 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:19:58,694 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:19:58 2023\n",
      "2023-07-03 16:19:58,741 - \u001b[1;32mINFO\u001b[1;0m - Starting request #391\n",
      "2023-07-03 16:19:59,019 - \u001b[1;33mWARNING\u001b[1;0m - Request 384 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:20:14,029 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:20:14 2023\n",
      "2023-07-03 16:20:14,469 - \u001b[1;33mWARNING\u001b[1;0m - Request 401 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:20:29,479 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:20:29 2023\n",
      "2023-07-03 16:20:29,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #409\n",
      "2023-07-03 16:20:29,932 - \u001b[1;33mWARNING\u001b[1;0m - Request 416 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:20:44,943 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:20:44 2023\n",
      "2023-07-03 16:20:44,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #428\n",
      "2023-07-03 16:20:45,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 430 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:21:00,410 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:21:00 2023\n",
      "2023-07-03 16:21:00,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #447\n",
      "2023-07-03 16:21:00,957 - \u001b[1;33mWARNING\u001b[1;0m - Request 436 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:21:15,967 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:21:15 2023\n",
      "2023-07-03 16:21:16,190 - \u001b[1;33mWARNING\u001b[1;0m - Request 451 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:21:16,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 462 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:21:31,202 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:21:31 2023\n",
      "2023-07-03 16:21:31,452 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:21:31 2023\n",
      "2023-07-03 16:21:31,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #464\n",
      "2023-07-03 16:21:31,685 - \u001b[1;33mWARNING\u001b[1;0m - Request 469 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:21:46,697 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:21:46 2023\n",
      "2023-07-03 16:21:46,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #483\n",
      "2023-07-03 16:21:46,921 - \u001b[1;33mWARNING\u001b[1;0m - Request 484 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:22:01,934 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:22:01 2023\n",
      "2023-07-03 16:22:01,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #502\n",
      "2023-07-03 16:22:02,227 - \u001b[1;33mWARNING\u001b[1;0m - Request 495 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:22:17,229 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:22:17 2023\n",
      "2023-07-03 16:22:17,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 515 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:22:32,446 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:22:32 2023\n",
      "2023-07-03 16:22:32,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #520\n",
      "2023-07-03 16:22:32,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 527 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:22:47,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:22:47 2023\n",
      "2023-07-03 16:22:47,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #539\n",
      "2023-07-03 16:22:47,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 542 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:22:48,047 - \u001b[1;33mWARNING\u001b[1;0m - Request 546 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:23:02,918 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:23:03 2023\n",
      "2023-07-03 16:23:03,048 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:23:03 2023\n",
      "2023-07-03 16:23:03,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #557\n",
      "2023-07-03 16:23:04,075 - \u001b[1;33mWARNING\u001b[1;0m - Request 560 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:23:19,090 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:23:19 2023\n",
      "2023-07-03 16:23:20,252 - \u001b[1;33mWARNING\u001b[1;0m - Request 575 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:23:35,264 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:23:35 2023\n",
      "2023-07-03 16:23:35,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #576\n",
      "2023-07-03 16:23:35,488 - \u001b[1;33mWARNING\u001b[1;0m - Request 588 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:23:50,502 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:23:50 2023\n",
      "2023-07-03 16:23:50,522 - \u001b[1;32mINFO\u001b[1;0m - Starting request #594\n",
      "2023-07-03 16:23:50,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 603 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:24:05,986 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:24:05 2023\n",
      "2023-07-03 16:24:06,019 - \u001b[1;32mINFO\u001b[1;0m - Starting request #613\n",
      "2023-07-03 16:24:06,895 - \u001b[1;33mWARNING\u001b[1;0m - Request 618 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:24:21,909 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:24:21 2023\n",
      "2023-07-03 16:24:22,143 - \u001b[1;32mINFO\u001b[1;0m - Starting request #632\n",
      "2023-07-03 16:24:22,376 - \u001b[1;33mWARNING\u001b[1;0m - Request 625 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:24:37,385 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:24:37 2023\n",
      "2023-07-03 16:24:37,824 - \u001b[1;33mWARNING\u001b[1;0m - Request 641 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:24:52,835 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:24:52 2023\n",
      "2023-07-03 16:24:52,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #650\n",
      "2023-07-03 16:24:53,303 - \u001b[1;33mWARNING\u001b[1;0m - Request 658 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:25:08,316 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:25:08 2023\n",
      "2023-07-03 16:25:08,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #669\n",
      "2023-07-03 16:25:08,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 658 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:25:23,814 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:25:23 2023\n",
      "2023-07-03 16:25:23,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #688\n",
      "2023-07-03 16:25:24,063 - \u001b[1;33mWARNING\u001b[1;0m - Request 688 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:25:39,075 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:25:39 2023\n",
      "2023-07-03 16:25:39,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 702 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:25:54,313 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:25:54 2023\n",
      "2023-07-03 16:25:54,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #706\n",
      "2023-07-03 16:25:54,638 - \u001b[1;33mWARNING\u001b[1;0m - Request 705 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:26:09,650 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:26:09 2023\n",
      "2023-07-03 16:26:09,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #725\n",
      "2023-07-03 16:26:09,973 - \u001b[1;33mWARNING\u001b[1;0m - Request 725 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:26:24,984 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:26:24 2023\n",
      "2023-07-03 16:26:25,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #744\n",
      "2023-07-03 16:26:25,225 - \u001b[1;33mWARNING\u001b[1;0m - Request 742 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:26:40,237 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:26:40 2023\n",
      "2023-07-03 16:26:40,571 - \u001b[1;33mWARNING\u001b[1;0m - Request 758 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:26:55,582 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:26:55 2023\n",
      "2023-07-03 16:26:55,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #762\n",
      "2023-07-03 16:26:55,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 772 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:27:10,896 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:27:10 2023\n",
      "2023-07-03 16:27:10,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #781\n",
      "2023-07-03 16:27:11,193 - \u001b[1;33mWARNING\u001b[1;0m - Request 786 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:27:26,205 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:27:26 2023\n",
      "2023-07-03 16:27:26,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #800\n",
      "2023-07-03 16:27:26,510 - \u001b[1;33mWARNING\u001b[1;0m - Request 800 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:27:41,521 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:27:41 2023\n",
      "2023-07-03 16:27:41,965 - \u001b[1;33mWARNING\u001b[1;0m - Request 812 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:27:56,976 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:27:56 2023\n",
      "2023-07-03 16:27:56,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #818\n",
      "2023-07-03 16:27:57,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 823 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:27:57,257 - \u001b[1;33mWARNING\u001b[1;0m - Request 828 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:28:12,190 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:28:12 2023\n",
      "2023-07-03 16:28:12,258 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:28:12 2023\n",
      "2023-07-03 16:28:12,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #836\n",
      "2023-07-03 16:28:12,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 830 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:28:27,687 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:28:27 2023\n",
      "2023-07-03 16:28:27,741 - \u001b[1;32mINFO\u001b[1;0m - Starting request #855\n",
      "2023-07-03 16:28:28,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 851 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:28:43,139 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:28:43 2023\n",
      "2023-07-03 16:28:43,410 - \u001b[1;33mWARNING\u001b[1;0m - Request 863 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:28:58,423 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:28:58 2023\n",
      "2023-07-03 16:28:58,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #873\n",
      "2023-07-03 16:28:58,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 877 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:29:13,779 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:29:13 2023\n",
      "2023-07-03 16:29:13,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #892\n",
      "2023-07-03 16:29:14,318 - \u001b[1;33mWARNING\u001b[1;0m - Request 897 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:29:29,329 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:29:29 2023\n",
      "2023-07-03 16:29:29,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #911\n",
      "2023-07-03 16:29:29,561 - \u001b[1;33mWARNING\u001b[1;0m - Request 907 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:29:29,695 - \u001b[1;33mWARNING\u001b[1;0m - Request 912 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:29:44,574 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:29:44 2023\n",
      "2023-07-03 16:29:44,696 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:29:44 2023\n",
      "2023-07-03 16:29:47,115 - \u001b[1;33mWARNING\u001b[1;0m - Request 927 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:30:02,129 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:30:02 2023\n",
      "2023-07-03 16:30:02,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #927\n",
      "2023-07-03 16:30:02,479 - \u001b[1;33mWARNING\u001b[1;0m - Request 934 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:30:17,491 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:30:17 2023\n",
      "2023-07-03 16:30:17,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #947\n",
      "2023-07-03 16:30:18,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 934 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:30:33,020 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:30:33 2023\n",
      "2023-07-03 16:30:33,063 - \u001b[1;32mINFO\u001b[1;0m - Starting request #966\n",
      "2023-07-03 16:30:33,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 967 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:30:48,265 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:30:48 2023\n",
      "2023-07-03 16:30:48,509 - \u001b[1;33mWARNING\u001b[1;0m - Request 981 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:03,522 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:31:03 2023\n",
      "2023-07-03 16:31:03,524 - \u001b[1;32mINFO\u001b[1;0m - Starting request #981\n",
      "2023-07-03 16:31:03,738 - \u001b[1;33mWARNING\u001b[1;0m - Request 997 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:03,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 998 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:18,751 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:31:18 2023\n",
      "2023-07-03 16:31:18,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:31:18 2023\n",
      "2023-07-03 16:31:18,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1002\n",
      "2023-07-03 16:31:19,912 - \u001b[1;33mWARNING\u001b[1;0m - Request 1012 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:34,924 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:31:34 2023\n",
      "2023-07-03 16:31:34,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1021\n",
      "2023-07-03 16:31:35,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 1025 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,213 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:31:50 2023\n",
      "2023-07-03 16:31:50,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1040\n",
      "2023-07-03 16:31:50,635 - \u001b[1;33mWARNING\u001b[1;0m - Request 1027 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:03,240 - \u001b[1;33mWARNING\u001b[1;0m - Request 956 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47888ffa295bc557d3db4f0e689beff7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:05,637 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:05 2023\n",
      "2023-07-03 16:32:05,857 - \u001b[1;33mWARNING\u001b[1;0m - Request 1053 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:20,858 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:20 2023\n",
      "2023-07-03 16:32:20,872 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1057\n",
      "2023-07-03 16:32:21,125 - \u001b[1;33mWARNING\u001b[1;0m - Request 1066 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:36,127 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:36 2023\n",
      "2023-07-03 16:32:36,163 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1076\n",
      "2023-07-03 16:32:36,343 - \u001b[1;33mWARNING\u001b[1;0m - Request 1081 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:51,353 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:51 2023\n",
      "2023-07-03 16:32:51,544 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1095\n",
      "2023-07-03 16:32:51,738 - \u001b[1;33mWARNING\u001b[1;0m - Request 1095 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:06,749 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:06 2023\n",
      "2023-07-03 16:33:08,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 1110 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:23,120 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:23 2023\n",
      "2023-07-03 16:33:23,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1113\n",
      "2023-07-03 16:33:23,447 - \u001b[1;33mWARNING\u001b[1;0m - Request 1124 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:38,458 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:38 2023\n",
      "2023-07-03 16:33:38,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1132\n",
      "2023-07-03 16:33:38,978 - \u001b[1;33mWARNING\u001b[1;0m - Request 1136 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:53,991 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:53 2023\n",
      "2023-07-03 16:33:54,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1151\n",
      "2023-07-03 16:33:54,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 1145 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:09,275 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:09 2023\n",
      "2023-07-03 16:34:09,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 1162 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:34:24,511 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:24 2023\n",
      "2023-07-03 16:34:24,521 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1169\n",
      "2023-07-03 16:34:24,798 - \u001b[1;33mWARNING\u001b[1;0m - Request 1168 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:24,831 - \u001b[1;33mWARNING\u001b[1;0m - Request 1180 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:39,810 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:39 2023\n",
      "2023-07-03 16:34:39,832 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:39 2023\n",
      "2023-07-03 16:34:39,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1187\n",
      "2023-07-03 16:34:41,082 - \u001b[1;33mWARNING\u001b[1;0m - Request 1194 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:56,094 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:56 2023\n",
      "2023-07-03 16:34:56,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1206\n",
      "2023-07-03 16:34:56,417 - \u001b[1;33mWARNING\u001b[1;0m - Request 1205 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:11,431 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:11 2023\n",
      "2023-07-03 16:35:11,841 - \u001b[1;33mWARNING\u001b[1;0m - Request 1205 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:26,853 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:26 2023\n",
      "2023-07-03 16:35:26,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1224\n",
      "2023-07-03 16:35:27,158 - \u001b[1;33mWARNING\u001b[1;0m - Request 1235 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:42,169 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:42 2023\n",
      "2023-07-03 16:35:42,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1243\n",
      "2023-07-03 16:35:42,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 1250 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:57,445 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:57 2023\n",
      "2023-07-03 16:35:57,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1262\n",
      "2023-07-03 16:35:57,702 - \u001b[1;33mWARNING\u001b[1;0m - Request 1262 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:12,714 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:12 2023\n",
      "2023-07-03 16:36:12,932 - \u001b[1;33mWARNING\u001b[1;0m - Request 1278 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:27,943 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:27 2023\n",
      "2023-07-03 16:36:27,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1280\n",
      "2023-07-03 16:36:28,672 - \u001b[1;33mWARNING\u001b[1;0m - Request 1279 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:43,677 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:43 2023\n",
      "2023-07-03 16:36:43,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1299\n",
      "2023-07-03 16:36:43,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 1302 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:58,909 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:58 2023\n",
      "2023-07-03 16:36:58,948 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1318\n",
      "2023-07-03 16:36:59,143 - \u001b[1;33mWARNING\u001b[1;0m - Request 1320 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:59,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 1321 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:14,155 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:14 2023\n",
      "2023-07-03 16:37:14,215 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:14 2023\n",
      "2023-07-03 16:37:14,421 - \u001b[1;33mWARNING\u001b[1;0m - Request 1334 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:27,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 1258 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2620c9b483749d5f0860aabf2e76e3dd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:29,425 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:29 2023\n",
      "2023-07-03 16:37:29,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1334\n",
      "2023-07-03 16:37:29,645 - \u001b[1;33mWARNING\u001b[1;0m - Request 1347 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:37:44,657 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:44 2023\n",
      "2023-07-03 16:37:44,682 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1353\n",
      "2023-07-03 16:37:44,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 1358 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:59,906 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:59 2023\n",
      "2023-07-03 16:37:59,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1372\n",
      "2023-07-03 16:38:00,160 - \u001b[1;33mWARNING\u001b[1;0m - Request 1375 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:15,172 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:15 2023\n",
      "2023-07-03 16:38:15,627 - \u001b[1;33mWARNING\u001b[1;0m - Request 1385 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:30,640 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:30 2023\n",
      "2023-07-03 16:38:30,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1385\n",
      "2023-07-03 16:38:31,261 - \u001b[1;33mWARNING\u001b[1;0m - Request 1391 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:46,272 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:46 2023\n",
      "2023-07-03 16:38:46,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1409\n",
      "2023-07-03 16:38:46,714 - \u001b[1;33mWARNING\u001b[1;0m - Request 1410 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:01,727 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:01 2023\n",
      "2023-07-03 16:39:01,772 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1428\n",
      "2023-07-03 16:39:01,984 - \u001b[1;33mWARNING\u001b[1;0m - Request 1427 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:16,997 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:16 2023\n",
      "2023-07-03 16:39:17,222 - \u001b[1;33mWARNING\u001b[1;0m - Request 1427 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:32,236 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:32 2023\n",
      "2023-07-03 16:39:32,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1427\n",
      "2023-07-03 16:39:32,621 - \u001b[1;33mWARNING\u001b[1;0m - Request 1454 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:32,707 - \u001b[1;33mWARNING\u001b[1;0m - Request 1460 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:47,632 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:47 2023\n",
      "2023-07-03 16:39:47,708 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:47 2023\n",
      "2023-07-03 16:39:47,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1464\n",
      "2023-07-03 16:39:48,088 - \u001b[1;33mWARNING\u001b[1;0m - Request 1473 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:03,102 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:03 2023\n",
      "2023-07-03 16:40:03,142 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1483\n",
      "2023-07-03 16:40:03,317 - \u001b[1;33mWARNING\u001b[1;0m - Request 1485 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:16,540 - \u001b[1;33mWARNING\u001b[1;0m - Request 1409 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b56e28c3d36b5daae80870acff804bae in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:18,321 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:18 2023\n",
      "2023-07-03 16:40:18,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 1500 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:33,557 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:33 2023\n",
      "2023-07-03 16:40:33,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1501\n",
      "2023-07-03 16:40:33,876 - \u001b[1;33mWARNING\u001b[1;0m - Request 1510 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:48,885 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:48 2023\n",
      "2023-07-03 16:40:48,906 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1519\n",
      "2023-07-03 16:40:49,100 - \u001b[1;33mWARNING\u001b[1;0m - Request 1527 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:04,109 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:04 2023\n",
      "2023-07-03 16:41:04,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1538\n",
      "2023-07-03 16:41:04,325 - \u001b[1;33mWARNING\u001b[1;0m - Request 1537 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:41:19,336 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:19 2023\n",
      "2023-07-03 16:41:19,543 - \u001b[1;33mWARNING\u001b[1;0m - Request 1556 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:34,556 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:34 2023\n",
      "2023-07-03 16:41:34,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1557\n",
      "2023-07-03 16:41:34,852 - \u001b[1;33mWARNING\u001b[1;0m - Request 1566 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:49,861 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:49 2023\n",
      "2023-07-03 16:41:49,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1575\n",
      "2023-07-03 16:41:50,063 - \u001b[1;33mWARNING\u001b[1;0m - Request 1584 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:05,073 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:05 2023\n",
      "2023-07-03 16:42:05,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1594\n",
      "2023-07-03 16:42:05,298 - \u001b[1;33mWARNING\u001b[1;0m - Request 1596 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:20,309 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:20 2023\n",
      "2023-07-03 16:42:20,533 - \u001b[1;33mWARNING\u001b[1;0m - Request 1612 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:20,557 - \u001b[1;33mWARNING\u001b[1;0m - Request 1599 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:35,546 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:35 2023\n",
      "2023-07-03 16:42:35,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1613\n",
      "2023-07-03 16:42:35,559 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:35 2023\n",
      "2023-07-03 16:42:36,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 1626 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:51,769 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:51 2023\n",
      "2023-07-03 16:42:51,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1630\n",
      "2023-07-03 16:42:52,047 - \u001b[1;33mWARNING\u001b[1;0m - Request 1631 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:07,057 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:07 2023\n",
      "2023-07-03 16:43:07,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1649\n",
      "2023-07-03 16:43:07,289 - \u001b[1;33mWARNING\u001b[1;0m - Request 1648 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:22,292 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:22 2023\n",
      "2023-07-03 16:43:22,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1668\n",
      "2023-07-03 16:43:22,751 - \u001b[1;33mWARNING\u001b[1;0m - Request 1668 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:37,753 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:37 2023\n",
      "2023-07-03 16:43:38,005 - \u001b[1;33mWARNING\u001b[1;0m - Request 1669 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:53,017 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:53 2023\n",
      "2023-07-03 16:43:53,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1686\n",
      "2023-07-03 16:43:53,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 1696 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:08,261 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:08 2023\n",
      "2023-07-03 16:44:08,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1705\n",
      "2023-07-03 16:44:08,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 1710 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:23,543 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:23 2023\n",
      "2023-07-03 16:44:23,590 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1724\n",
      "2023-07-03 16:44:23,822 - \u001b[1;33mWARNING\u001b[1;0m - Request 1721 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:38,834 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:38 2023\n",
      "2023-07-03 16:44:39,148 - \u001b[1;33mWARNING\u001b[1;0m - Request 1726 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:54,158 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:54 2023\n",
      "2023-07-03 16:44:54,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1742\n",
      "2023-07-03 16:44:54,391 - \u001b[1;33mWARNING\u001b[1;0m - Request 1744 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:44:54,439 - \u001b[1;33mWARNING\u001b[1;0m - Request 1753 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:09,405 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:09 2023\n",
      "2023-07-03 16:45:09,440 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:09 2023\n",
      "2023-07-03 16:45:09,470 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1760\n",
      "2023-07-03 16:45:09,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 1763 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:24,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:24 2023\n",
      "2023-07-03 16:45:24,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1779\n",
      "2023-07-03 16:45:24,907 - \u001b[1;33mWARNING\u001b[1;0m - Request 1780 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:39,921 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:39 2023\n",
      "2023-07-03 16:45:40,227 - \u001b[1;33mWARNING\u001b[1;0m - Request 1785 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:55,238 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:55 2023\n",
      "2023-07-03 16:45:55,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1797\n",
      "2023-07-03 16:45:55,447 - \u001b[1;33mWARNING\u001b[1;0m - Request 1795 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:10,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:10 2023\n",
      "2023-07-03 16:46:10,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1816\n",
      "2023-07-03 16:46:10,664 - \u001b[1;33mWARNING\u001b[1;0m - Request 1820 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:25,677 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:25 2023\n",
      "2023-07-03 16:46:25,723 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1835\n",
      "2023-07-03 16:46:25,911 - \u001b[1;33mWARNING\u001b[1;0m - Request 1834 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:25,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 1833 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:40,917 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:40 2023\n",
      "2023-07-03 16:46:41,239 - \u001b[1;33mWARNING\u001b[1;0m - Request 1834 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:56,249 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:56 2023\n",
      "2023-07-03 16:46:56,260 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1852\n",
      "2023-07-03 16:46:56,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 1854 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:11,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:11 2023\n",
      "2023-07-03 16:47:11,508 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1871\n",
      "2023-07-03 16:47:11,748 - \u001b[1;33mWARNING\u001b[1;0m - Request 1867 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:26,760 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:26 2023\n",
      "2023-07-03 16:47:26,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1890\n",
      "2023-07-03 16:47:26,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 1891 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:41,977 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:41 2023\n",
      "2023-07-03 16:47:42,318 - \u001b[1;33mWARNING\u001b[1;0m - Request 1900 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:57,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:57 2023\n",
      "2023-07-03 16:47:57,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1908\n",
      "2023-07-03 16:47:57,576 - \u001b[1;33mWARNING\u001b[1;0m - Request 1917 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:12,589 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:12 2023\n",
      "2023-07-03 16:48:12,620 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1927\n",
      "2023-07-03 16:48:12,851 - \u001b[1;33mWARNING\u001b[1;0m - Request 1927 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:27,862 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:27 2023\n",
      "2023-07-03 16:48:27,910 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1946\n",
      "2023-07-03 16:48:28,197 - \u001b[1;33mWARNING\u001b[1;0m - Request 1943 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:48:43,208 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:43 2023\n",
      "2023-07-03 16:48:43,515 - \u001b[1;33mWARNING\u001b[1;0m - Request 1954 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:58,525 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:58 2023\n",
      "2023-07-03 16:48:58,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1964\n",
      "2023-07-03 16:48:58,748 - \u001b[1;33mWARNING\u001b[1;0m - Request 1974 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:12,324 - \u001b[1;33mWARNING\u001b[1;0m - Request 1896 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62e0cf14212b664964c8bbb65d35b3cb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:13,752 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:13 2023\n",
      "2023-07-03 16:49:13,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1982\n",
      "2023-07-03 16:49:13,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 1986 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:28,985 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:28 2023\n",
      "2023-07-03 16:49:29,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2001\n",
      "2023-07-03 16:49:29,198 - \u001b[1;33mWARNING\u001b[1;0m - Request 1995 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:29,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 1999 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:44,210 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:44 2023\n",
      "2023-07-03 16:49:44,219 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:44 2023\n",
      "2023-07-03 16:49:44,530 - \u001b[1;33mWARNING\u001b[1;0m - Request 1999 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:58,109 - \u001b[1;33mWARNING\u001b[1;0m - Request 1936 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 584bbd657549a96aa777871248f6a190 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:59,533 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:59 2023\n",
      "2023-07-03 16:49:59,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2017\n",
      "2023-07-03 16:49:59,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 2028 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:14,777 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:14 2023\n",
      "2023-07-03 16:50:14,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2036\n",
      "2023-07-03 16:50:14,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 2042 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:15,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 2043 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:29,985 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:30 2023\n",
      "2023-07-03 16:50:30,043 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:30 2023\n",
      "2023-07-03 16:50:30,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2054\n",
      "2023-07-03 16:50:30,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 2054 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:45,526 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:45 2023\n",
      "2023-07-03 16:50:45,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 2069 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:00,857 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:00 2023\n",
      "2023-07-03 16:51:00,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2072\n",
      "2023-07-03 16:51:01,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 2084 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:16,085 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:16 2023\n",
      "2023-07-03 16:51:16,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2091\n",
      "2023-07-03 16:51:16,307 - \u001b[1;33mWARNING\u001b[1;0m - Request 2092 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:31,318 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:31 2023\n",
      "2023-07-03 16:51:31,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2110\n",
      "2023-07-03 16:51:31,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 2112 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:46,761 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:46 2023\n",
      "2023-07-03 16:51:47,061 - \u001b[1;33mWARNING\u001b[1;0m - Request 2122 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:52:02,072 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:02 2023\n",
      "2023-07-03 16:52:02,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2128\n",
      "2023-07-03 16:52:02,280 - \u001b[1;33mWARNING\u001b[1;0m - Request 2137 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:17,286 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:17 2023\n",
      "2023-07-03 16:52:17,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2147\n",
      "2023-07-03 16:52:17,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 2154 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:32,517 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:32 2023\n",
      "2023-07-03 16:52:32,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2166\n",
      "2023-07-03 16:52:32,770 - \u001b[1;33mWARNING\u001b[1;0m - Request 2165 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:47,782 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:47 2023\n",
      "2023-07-03 16:52:48,128 - \u001b[1;33mWARNING\u001b[1;0m - Request 2165 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:48,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 2183 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:03,141 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:03 2023\n",
      "2023-07-03 16:53:03,165 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:03 2023\n",
      "2023-07-03 16:53:03,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2165\n",
      "2023-07-03 16:53:03,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 2196 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:18,437 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:18 2023\n",
      "2023-07-03 16:53:18,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2202\n",
      "2023-07-03 16:53:18,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 2210 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:18,723 - \u001b[1;33mWARNING\u001b[1;0m - Request 2200 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:33,732 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:33 2023\n",
      "2023-07-03 16:53:33,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2220\n",
      "2023-07-03 16:53:34,071 - \u001b[1;33mWARNING\u001b[1;0m - Request 2223 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:47,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 2151 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 596c9e919d6a081dda6b85dbbd0ae186 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:49,075 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:49 2023\n",
      "2023-07-03 16:53:49,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 2235 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:04,440 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:04 2023\n",
      "2023-07-03 16:54:04,442 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2235\n",
      "2023-07-03 16:54:04,653 - \u001b[1;33mWARNING\u001b[1;0m - Request 2246 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:19,665 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:19 2023\n",
      "2023-07-03 16:54:19,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2256\n",
      "2023-07-03 16:54:20,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 2263 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:35,020 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:35 2023\n",
      "2023-07-03 16:54:35,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2275\n",
      "2023-07-03 16:54:35,255 - \u001b[1;33mWARNING\u001b[1;0m - Request 2273 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:50,268 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:50 2023\n",
      "2023-07-03 16:54:50,610 - \u001b[1;33mWARNING\u001b[1;0m - Request 2292 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:05,621 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:05 2023\n",
      "2023-07-03 16:55:05,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2292\n",
      "2023-07-03 16:55:05,841 - \u001b[1;33mWARNING\u001b[1;0m - Request 2306 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:20,856 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:20 2023\n",
      "2023-07-03 16:55:20,880 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:55:21,079 - \u001b[1;33mWARNING\u001b[1;0m - Request 2309 failed with error {'message': 'Rate limit reached for default-gpt-4 in organization org-6MF1Te7RXD4IZ1S7ywx5pC7H on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_facts_from_report_sentences_with_openai.py \\\n",
    "    --preprocessed_reports_filename \"background_findings_and_impression_20230612_174143.json\" \\\n",
    "    --offset 0 \\\n",
    "    --num_sentences 10000 \\\n",
    "    --rank_sentences_by_difficulty \\\n",
    "    --max_requests_per_minute 200 \\\n",
    "    --max_tokens_per_minute 39000 \\\n",
    "    --max_tokens_per_request 256 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_3\" \\\n",
    "    --openai_model_name \"gpt-4-0613\" \\\n",
    "    --alias \"__v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f633648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdadc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5702acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0487aa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'sentence': 'Small left pneumothorax .volume loss at both bases.'},\n",
       " 'parsed_response': ['small left pneumothorax', 'volume loss at both bases']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
