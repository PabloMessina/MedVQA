{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19e7a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gpt-3.5-turbo-0301_parsed_sentences.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\r\n",
      " gpt-3.5-turbo_parsed_backgrounds.jsonl\r\n",
      " gpt-3.5-turbo_parsed_reports__backup.jsonl\r\n",
      " gpt-3.5-turbo_parsed_reports.jsonl\r\n",
      "'gpt-3.5-turbo_parsed_reports(old).jsonl'\r\n",
      " gpt-3.5-turbo_parsed_sentences.jsonl\r\n",
      " gpt-4-0613_parsed_reports.jsonl\r\n",
      " gpt-4-0613_parsed_sentences.jsonl\r\n",
      " gpt-4-0613_parsed_sentences__v2.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525b6006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:46:02,110 - \u001b[1;32mINFO\u001b[1;0m - Loading preprocessed reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "100%|█████████████████████████████████| 227835/227835 [00:45<00:00, 4995.89it/s]\n",
      "2023-07-03 16:46:48,410 - \u001b[1;32mINFO\u001b[1;0m - Loaded 227835 reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "2023-07-03 16:46:48,411 - \u001b[1;32mINFO\u001b[1;0m - Found 677694 unique sentences to parse\n",
      "2023-07-03 16:46:48,465 - \u001b[1;32mINFO\u001b[1;0m - Sorting sentences by difficulty...\n",
      "100%|█████████████████████████████████| 677694/677694 [02:13<00:00, 5076.09it/s]\n",
      "2023-07-03 16:49:01,973 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 677694/677694 [00:03<00:00, 182864.59it/s]\n",
      "2023-07-03 16:49:08,958 - \u001b[1;32mINFO\u001b[1;0m - Done sorting sentences.\n",
      "2023-07-03 16:49:08,959 - \u001b[1;32mINFO\u001b[1;0m - First sentence: M recently stopped coumadin(afib) p/w L>R pain,abd pain, s/p 's, cold foot s/p L pop cutdown embolectomy L fasciotomy s/p LLE angio embolectomy s/p L guillotine + L BKA // Dobhoff placement - require assistance and sequential imaging.\n",
      "2023-07-03 16:49:08,959 - \u001b[1;32mINFO\u001b[1;0m - Last sentence: .\n",
      "2023-07-03 16:49:09,405 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to parse: 20000\n",
      "2023-07-03 16:49:09,405 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to parse:\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 1. Evaluation of the sternum is limited, but the appearance in the lateral view is unchanged.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 2223. Left port-a-cath with tip in right atrium.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 4445. There is a new NG tube with tip in the stomach.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 6667. There is pulmonary and mediastinal vascular engorgement suggesting volume overload, without overt pulmonary edema.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 8889. While this may be due to tortuosity, a focal dilatation cannot be excluded.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 11111. Airspace opacity at the right base may reflect atelectasis.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 13333. Portable semi-erect chest radiograph at 8:48.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 15555. Midline and right pleural drainage catheters in place.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 17777. There is no evidence of pneumonia, masses, CHF, pneumothorax or pleural effusion.\n",
      "2023-07-03 16:49:09,406 - \u001b[1;32mINFO\u001b[1;0m - 20000. Nasogastric tube also high in position; repositioning recommended.\n",
      "2023-07-03 16:49:09,513 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230703_164909.jsonl\n",
      "2023-07-03 16:49:09,513 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_164909.jsonl\n",
      "2023-07-03 16:49:10,339 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-03 16:49:10,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-07-03 16:49:10,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-07-03 16:49:10,519 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-07-03 16:49:10,578 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-07-03 16:49:10,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-03 16:49:10,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-07-03 16:49:11,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 126 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89865 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:11,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 124 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89862 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:11,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89854 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:11,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 128 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89851 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:11,219 - \u001b[1;33mWARNING\u001b[1;0m - Request 129 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89844 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:11,277 - \u001b[1;33mWARNING\u001b[1;0m - Request 131 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89761 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:26,219 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:26 2023\n",
      "2023-07-03 16:49:26,278 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:26 2023\n",
      "2023-07-03 16:49:26,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #134\n",
      "2023-07-03 16:49:26,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #154\n",
      "2023-07-03 16:49:26,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 157 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89360 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:26,559 - \u001b[1;33mWARNING\u001b[1;0m - Request 155 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:41,554 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:41 2023\n",
      "2023-07-03 16:49:41,559 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:41 2023\n",
      "2023-07-03 16:49:41,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #172\n",
      "2023-07-03 16:49:42,298 - \u001b[1;33mWARNING\u001b[1;0m - Request 191 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:57,305 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:57 2023\n",
      "2023-07-03 16:49:57,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #192\n",
      "2023-07-03 16:49:57,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #211\n",
      "2023-07-03 16:49:57,600 - \u001b[1;33mWARNING\u001b[1;0m - Request 215 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89709 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:57,612 - \u001b[1;33mWARNING\u001b[1;0m - Request 217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89721 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:50:12,616 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:12 2023\n",
      "2023-07-03 16:50:12,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #229\n",
      "2023-07-03 16:50:12,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #249\n",
      "2023-07-03 16:50:12,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 253 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89843 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:13,003 - \u001b[1;33mWARNING\u001b[1;0m - Request 255 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89697 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:27,917 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:28 2023\n",
      "2023-07-03 16:50:28,004 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:28 2023\n",
      "2023-07-03 16:50:28,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #267\n",
      "2023-07-03 16:50:28,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #287\n",
      "2023-07-03 16:50:33,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 294 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89775 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:33,150 - \u001b[1;33mWARNING\u001b[1;0m - Request 297 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89702 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:48,112 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:48 2023\n",
      "2023-07-03 16:50:48,151 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:48 2023\n",
      "2023-07-03 16:50:48,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #305\n",
      "2023-07-03 16:50:48,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #325\n",
      "2023-07-03 16:50:48,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 325 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89747 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:03,477 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:03 2023\n",
      "2023-07-03 16:51:03,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #344\n",
      "2023-07-03 16:51:04,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 352 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89498 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:04,032 - \u001b[1;33mWARNING\u001b[1;0m - Request 361 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:19,009 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:19 2023\n",
      "2023-07-03 16:51:19,034 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:19 2023\n",
      "2023-07-03 16:51:19,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #361\n",
      "2023-07-03 16:51:19,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #382\n",
      "2023-07-03 16:51:19,390 - \u001b[1;33mWARNING\u001b[1;0m - Request 393 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89442 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:19,520 - \u001b[1;33mWARNING\u001b[1;0m - Request 390 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89248 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:34,405 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:34 2023\n",
      "2023-07-03 16:51:34,521 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:34 2023\n",
      "2023-07-03 16:51:34,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #400\n",
      "2023-07-03 16:51:34,608 - \u001b[1;32mINFO\u001b[1;0m - Starting request #420\n",
      "2023-07-03 16:51:35,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 408 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89850 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:50,035 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:50 2023\n",
      "2023-07-03 16:51:50,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #439\n",
      "2023-07-03 16:51:50,316 - \u001b[1;33mWARNING\u001b[1;0m - Request 453 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89948 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:05,326 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:05 2023\n",
      "2023-07-03 16:52:05,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #453\n",
      "2023-07-03 16:52:05,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #478\n",
      "2023-07-03 16:52:05,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 487 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89334 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:05,606 - \u001b[1;33mWARNING\u001b[1;0m - Request 486 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89305 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:05,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 490 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:20,611 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:20 2023\n",
      "2023-07-03 16:52:20,616 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:20 2023\n",
      "2023-07-03 16:52:20,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #495\n",
      "2023-07-03 16:52:20,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #515\n",
      "2023-07-03 16:52:21,195 - \u001b[1;33mWARNING\u001b[1;0m - Request 521 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:36,210 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:36 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:52:36,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #534\n",
      "2023-07-03 16:52:36,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 533 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89903 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:51,511 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:51 2023\n",
      "2023-07-03 16:52:51,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #554\n",
      "2023-07-03 16:52:51,582 - \u001b[1;32mINFO\u001b[1;0m - Starting request #573\n",
      "2023-07-03 16:52:52,613 - \u001b[1;33mWARNING\u001b[1;0m - Request 559 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89550 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:52,623 - \u001b[1;33mWARNING\u001b[1;0m - Request 557 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89545 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:07,627 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:07 2023\n",
      "2023-07-03 16:53:07,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #591\n",
      "2023-07-03 16:53:07,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #611\n",
      "2023-07-03 16:53:09,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 605 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:24,072 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:24 2023\n",
      "2023-07-03 16:53:24,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #630\n",
      "2023-07-03 16:53:24,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #650\n",
      "2023-07-03 16:53:24,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89480 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:24,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 649 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:24,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 654 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89366 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:39,372 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:39 2023\n",
      "2023-07-03 16:53:39,429 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:39 2023\n",
      "2023-07-03 16:53:39,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #667\n",
      "2023-07-03 16:53:40,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #687\n",
      "2023-07-03 16:53:41,054 - \u001b[1;33mWARNING\u001b[1;0m - Request 672 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89680 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:56,068 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:56 2023\n",
      "2023-07-03 16:53:56,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #706\n",
      "2023-07-03 16:53:56,556 - \u001b[1;33mWARNING\u001b[1;0m - Request 719 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89496 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:56,594 - \u001b[1;33mWARNING\u001b[1;0m - Request 711 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:10,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 45 failed with Exception \n",
      "2023-07-03 16:54:11,558 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:11 2023\n",
      "2023-07-03 16:54:11,594 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:11 2023\n",
      "2023-07-03 16:54:11,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #723\n",
      "2023-07-03 16:54:11,672 - \u001b[1;32mINFO\u001b[1;0m - Starting request #743\n",
      "2023-07-03 16:54:14,058 - \u001b[1;33mWARNING\u001b[1;0m - Request 738 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89869 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:29,059 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:29 2023\n",
      "2023-07-03 16:54:29,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #762\n",
      "2023-07-03 16:54:29,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #782\n",
      "2023-07-03 16:54:29,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 787 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89622 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:29,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 788 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:44,618 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:44 2023\n",
      "2023-07-03 16:54:44,733 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:44 2023\n",
      "2023-07-03 16:54:44,776 - \u001b[1;32mINFO\u001b[1;0m - Starting request #800\n",
      "2023-07-03 16:54:44,855 - \u001b[1;32mINFO\u001b[1;0m - Starting request #820\n",
      "2023-07-03 16:54:45,036 - \u001b[1;33mWARNING\u001b[1;0m - Request 817 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89488 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:00,045 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:00 2023\n",
      "2023-07-03 16:55:00,111 - \u001b[1;32mINFO\u001b[1;0m - Starting request #839\n",
      "2023-07-03 16:55:00,540 - \u001b[1;33mWARNING\u001b[1;0m - Request 844 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89319 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:00,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89919 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:55:15,543 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:15 2023\n",
      "2023-07-03 16:55:15,624 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:15 2023\n",
      "2023-07-03 16:55:15,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #857\n",
      "2023-07-03 16:55:15,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #877\n",
      "2023-07-03 16:55:16,143 - \u001b[1;33mWARNING\u001b[1;0m - Request 884 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89759 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:16,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 885 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89668 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:31,156 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:31 2023\n",
      "2023-07-03 16:55:31,210 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:31 2023\n",
      "2023-07-03 16:55:31,251 - \u001b[1;32mINFO\u001b[1;0m - Starting request #895\n",
      "2023-07-03 16:55:31,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #915\n",
      "2023-07-03 16:55:32,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 909 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89597 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:32,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 918 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:47,137 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:47 2023\n",
      "2023-07-03 16:55:47,274 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:47 2023\n",
      "2023-07-03 16:55:47,330 - \u001b[1;32mINFO\u001b[1;0m - Starting request #933\n",
      "2023-07-03 16:55:47,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 943 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:02,565 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:02 2023\n",
      "2023-07-03 16:56:02,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #952\n",
      "2023-07-03 16:56:02,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #972\n",
      "2023-07-03 16:56:02,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 982 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:02,993 - \u001b[1;33mWARNING\u001b[1;0m - Request 957 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89487 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:17,977 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:17 2023\n",
      "2023-07-03 16:56:17,994 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:17 2023\n",
      "2023-07-03 16:56:18,028 - \u001b[1;32mINFO\u001b[1;0m - Starting request #990\n",
      "2023-07-03 16:56:18,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1010\n",
      "2023-07-03 16:56:18,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 1006 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:33,341 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:33 2023\n",
      "2023-07-03 16:56:33,399 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1029\n",
      "2023-07-03 16:56:34,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1049\n",
      "2023-07-03 16:56:38,355 - \u001b[1;33mWARNING\u001b[1;0m - Request 1056 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89963 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:53,368 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:53 2023\n",
      "2023-07-03 16:56:53,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1068\n",
      "2023-07-03 16:56:53,471 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1088\n",
      "2023-07-03 16:56:53,620 - \u001b[1;33mWARNING\u001b[1;0m - Request 1087 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89369 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:53,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 1088 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89365 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:05,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 482 failed with Exception \n",
      "2023-07-03 16:57:08,624 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:08 2023\n",
      "2023-07-03 16:57:08,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1105\n",
      "2023-07-03 16:57:08,915 - \u001b[1;33mWARNING\u001b[1;0m - Request 1112 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89608 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:08,954 - \u001b[1;33mWARNING\u001b[1;0m - Request 1114 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:09,050 - \u001b[1;33mWARNING\u001b[1;0m - Request 1119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:23,924 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:24 2023\n",
      "2023-07-03 16:57:24,051 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:24 2023\n",
      "2023-07-03 16:57:24,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1122\n",
      "2023-07-03 16:57:24,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1142\n",
      "2023-07-03 16:57:27,106 - \u001b[1;33mWARNING\u001b[1;0m - Request 1145 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89707 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:57:42,121 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:42 2023\n",
      "2023-07-03 16:57:42,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1161\n",
      "2023-07-03 16:57:42,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1181\n",
      "2023-07-03 16:57:47,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 1198 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:47,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 1189 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:02,060 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:02 2023\n",
      "2023-07-03 16:58:02,268 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:02 2023\n",
      "2023-07-03 16:58:02,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1189\n",
      "2023-07-03 16:58:02,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1219\n",
      "2023-07-03 16:58:02,745 - \u001b[1;33mWARNING\u001b[1;0m - Request 1227 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89587 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:02,753 - \u001b[1;33mWARNING\u001b[1;0m - Request 1217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89574 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:08,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 615 failed with Exception \n",
      "2023-07-03 16:58:17,748 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:17 2023\n",
      "2023-07-03 16:58:17,754 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:17 2023\n",
      "2023-07-03 16:58:17,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1236\n",
      "2023-07-03 16:58:17,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1256\n",
      "2023-07-03 16:58:18,262 - \u001b[1;33mWARNING\u001b[1;0m - Request 1259 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89385 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:18,307 - \u001b[1;33mWARNING\u001b[1;0m - Request 1244 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:33,276 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:33 2023\n",
      "2023-07-03 16:58:33,308 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:33 2023\n",
      "2023-07-03 16:58:33,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1274\n",
      "2023-07-03 16:58:33,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 1269 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:48,909 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:48 2023\n",
      "2023-07-03 16:58:48,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1294\n",
      "2023-07-03 16:58:48,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1313\n",
      "2023-07-03 16:58:49,399 - \u001b[1;33mWARNING\u001b[1;0m - Request 1319 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89623 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:49,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 1325 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89589 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:04,413 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:04 2023\n",
      "2023-07-03 16:59:04,427 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:04 2023\n",
      "2023-07-03 16:59:04,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1331\n",
      "2023-07-03 16:59:04,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1351\n",
      "2023-07-03 16:59:09,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 1358 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89769 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:09,090 - \u001b[1;33mWARNING\u001b[1;0m - Request 1367 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89664 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:24,040 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:24 2023\n",
      "2023-07-03 16:59:24,092 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:24 2023\n",
      "2023-07-03 16:59:24,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1369\n",
      "2023-07-03 16:59:24,167 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1389\n",
      "2023-07-03 16:59:24,694 - \u001b[1;33mWARNING\u001b[1;0m - Request 1399 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:29,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 766 failed with Exception \n",
      "2023-07-03 16:59:39,705 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:39 2023\n",
      "2023-07-03 16:59:39,734 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1407\n",
      "2023-07-03 16:59:39,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1427\n",
      "2023-07-03 16:59:39,992 - \u001b[1;33mWARNING\u001b[1;0m - Request 1427 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:39,994 - \u001b[1;33mWARNING\u001b[1;0m - Request 1428 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:45,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 799 failed with Exception \n",
      "2023-07-03 16:59:55,002 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:54 2023\n",
      "2023-07-03 16:59:55,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1444\n",
      "2023-07-03 16:59:55,382 - \u001b[1;33mWARNING\u001b[1;0m - Request 1461 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89472 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:55,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 1456 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89411 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:00:10,396 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:10 2023\n",
      "2023-07-03 17:00:10,427 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:10 2023\n",
      "2023-07-03 17:00:10,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1456\n",
      "2023-07-03 17:00:10,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1482\n",
      "2023-07-03 17:00:10,889 - \u001b[1;33mWARNING\u001b[1;0m - Request 1474 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:25,905 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:25 2023\n",
      "2023-07-03 17:00:25,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1501\n",
      "2023-07-03 17:00:26,103 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1521\n",
      "2023-07-03 17:00:26,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 1523 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:26,308 - \u001b[1;33mWARNING\u001b[1;0m - Request 1501 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89308 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:41,311 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:41 2023\n",
      "2023-07-03 17:00:41,363 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1539\n",
      "2023-07-03 17:00:41,570 - \u001b[1;33mWARNING\u001b[1;0m - Request 1547 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89472 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:41,699 - \u001b[1;33mWARNING\u001b[1;0m - Request 1557 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89276 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:56,584 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:56 2023\n",
      "2023-07-03 17:00:56,700 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:56 2023\n",
      "2023-07-03 17:00:56,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1547\n",
      "2023-07-03 17:00:56,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1577\n",
      "2023-07-03 17:00:56,960 - \u001b[1;33mWARNING\u001b[1;0m - Request 1586 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89490 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:11,970 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:11 2023\n",
      "2023-07-03 17:01:12,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1596\n",
      "2023-07-03 17:01:12,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1616\n",
      "2023-07-03 17:01:12,444 - \u001b[1;33mWARNING\u001b[1;0m - Request 1599 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89463 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:12,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 1621 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89407 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:27,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:27 2023\n",
      "2023-07-03 17:01:27,464 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:27 2023\n",
      "2023-07-03 17:01:27,515 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1634\n",
      "2023-07-03 17:01:27,941 - \u001b[1;33mWARNING\u001b[1;0m - Request 1636 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:42,955 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:42 2023\n",
      "2023-07-03 17:01:42,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1654\n",
      "2023-07-03 17:01:43,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1673\n",
      "2023-07-03 17:01:43,484 - \u001b[1;33mWARNING\u001b[1;0m - Request 1672 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89828 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:58,499 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:58 2023\n",
      "2023-07-03 17:01:58,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1692\n",
      "2023-07-03 17:01:58,587 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1712\n",
      "2023-07-03 17:01:58,855 - \u001b[1;33mWARNING\u001b[1;0m - Request 1693 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89934 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:59,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 1690 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89647 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:13,870 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:14 2023\n",
      "2023-07-03 17:02:14,044 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:14 2023\n",
      "2023-07-03 17:02:14,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1730\n",
      "2023-07-03 17:02:14,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1750\n",
      "2023-07-03 17:02:14,928 - \u001b[1;33mWARNING\u001b[1;0m - Request 1751 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89658 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:15,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 1750 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89458 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:29,942 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:30 2023\n",
      "2023-07-03 17:02:30,068 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:30 2023\n",
      "2023-07-03 17:02:30,127 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1768\n",
      "2023-07-03 17:02:30,611 - \u001b[1;33mWARNING\u001b[1;0m - Request 1782 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89959 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:02:45,625 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:45 2023\n",
      "2023-07-03 17:02:45,640 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1787\n",
      "2023-07-03 17:02:45,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1807\n",
      "2023-07-03 17:02:46,557 - \u001b[1;33mWARNING\u001b[1;0m - Request 1806 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89784 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:46,753 - \u001b[1;33mWARNING\u001b[1;0m - Request 1817 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89481 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:01,573 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:01 2023\n",
      "2023-07-03 17:03:01,754 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:01 2023\n",
      "2023-07-03 17:03:01,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1825\n",
      "2023-07-03 17:03:01,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1845\n",
      "2023-07-03 17:03:02,569 - \u001b[1;33mWARNING\u001b[1;0m - Request 1850 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89570 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:02,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 1827 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89574 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:17,579 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:17 2023\n",
      "2023-07-03 17:03:17,631 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1863\n",
      "2023-07-03 17:03:18,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1883\n",
      "2023-07-03 17:03:20,877 - \u001b[1;33mWARNING\u001b[1;0m - Request 1884 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:20,925 - \u001b[1;33mWARNING\u001b[1;0m - Request 1888 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:35,881 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:35 2023\n",
      "2023-07-03 17:03:35,926 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:35 2023\n",
      "2023-07-03 17:03:35,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1901\n",
      "2023-07-03 17:03:36,188 - \u001b[1;33mWARNING\u001b[1;0m - Request 1917 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89661 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:51,202 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:51 2023\n",
      "2023-07-03 17:03:51,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1917\n",
      "2023-07-03 17:03:51,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1940\n",
      "2023-07-03 17:03:51,487 - \u001b[1;33mWARNING\u001b[1;0m - Request 1950 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89725 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:51,634 - \u001b[1;33mWARNING\u001b[1;0m - Request 1952 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:06,502 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:06 2023\n",
      "2023-07-03 17:04:06,635 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:06 2023\n",
      "2023-07-03 17:04:06,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1958\n",
      "2023-07-03 17:04:06,723 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1978\n",
      "2023-07-03 17:04:07,128 - \u001b[1;33mWARNING\u001b[1;0m - Request 1983 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:22,142 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:22 2023\n",
      "2023-07-03 17:04:22,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1997\n",
      "2023-07-03 17:04:22,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 2016 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89663 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:22,437 - \u001b[1;33mWARNING\u001b[1;0m - Request 2011 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89649 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:24,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 1376 failed with Exception \n",
      "2023-07-03 17:04:37,423 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:37 2023\n",
      "2023-07-03 17:04:37,424 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2017\n",
      "2023-07-03 17:04:37,438 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:37 2023\n",
      "2023-07-03 17:04:37,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2034\n",
      "2023-07-03 17:04:37,959 - \u001b[1;33mWARNING\u001b[1;0m - Request 2043 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89445 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:38,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 2047 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89371 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:52,974 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:53 2023\n",
      "2023-07-03 17:04:53,000 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:53 2023\n",
      "2023-07-03 17:04:53,019 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2052\n",
      "2023-07-03 17:04:53,083 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2072\n",
      "2023-07-03 17:04:53,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 2077 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89525 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:05:08,280 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:08 2023\n",
      "2023-07-03 17:05:08,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2091\n",
      "2023-07-03 17:05:08,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2111\n",
      "2023-07-03 17:05:08,776 - \u001b[1;33mWARNING\u001b[1;0m - Request 2106 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:23,790 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:23 2023\n",
      "2023-07-03 17:05:23,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2130\n",
      "2023-07-03 17:05:26,640 - \u001b[1;33mWARNING\u001b[1;0m - Request 2149 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:41,651 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:41 2023\n",
      "2023-07-03 17:05:41,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2150\n",
      "2023-07-03 17:05:41,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2169\n",
      "2023-07-03 17:05:43,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 2167 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89804 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:43,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 2162 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89782 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:43,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 2180 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:58,193 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:58 2023\n",
      "2023-07-03 17:05:58,210 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:58 2023\n",
      "2023-07-03 17:05:58,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2186\n",
      "2023-07-03 17:05:58,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2206\n",
      "2023-07-03 17:05:58,700 - \u001b[1;33mWARNING\u001b[1;0m - Request 2214 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89585 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:58,711 - \u001b[1;33mWARNING\u001b[1;0m - Request 2215 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89574 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:13,715 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:13 2023\n",
      "2023-07-03 17:06:13,754 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2224\n",
      "2023-07-03 17:06:13,813 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2244\n",
      "2023-07-03 17:06:14,002 - \u001b[1;33mWARNING\u001b[1;0m - Request 2233 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89728 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:29,015 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:29 2023\n",
      "2023-07-03 17:06:29,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2263\n",
      "2023-07-03 17:06:29,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 2279 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89686 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:29,488 - \u001b[1;33mWARNING\u001b[1;0m - Request 2272 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89564 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:44,434 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:44 2023\n",
      "2023-07-03 17:06:44,489 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:44 2023\n",
      "2023-07-03 17:06:44,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2281\n",
      "2023-07-03 17:06:44,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2301\n",
      "2023-07-03 17:06:45,854 - \u001b[1;33mWARNING\u001b[1;0m - Request 2284 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89480 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:45,862 - \u001b[1;33mWARNING\u001b[1;0m - Request 2313 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89444 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:00,857 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:00 2023\n",
      "2023-07-03 17:07:00,863 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:00 2023\n",
      "2023-07-03 17:07:00,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2319\n",
      "2023-07-03 17:07:00,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2339\n",
      "2023-07-03 17:07:01,351 - \u001b[1;33mWARNING\u001b[1;0m - Request 2336 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:14,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 1719 failed with Exception \n",
      "2023-07-03 17:07:16,354 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:16 2023\n",
      "2023-07-03 17:07:16,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2357\n",
      "2023-07-03 17:07:16,629 - \u001b[1;33mWARNING\u001b[1;0m - Request 2373 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89460 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:16,639 - \u001b[1;33mWARNING\u001b[1;0m - Request 2375 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89432 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:31,643 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:31 2023\n",
      "2023-07-03 17:07:31,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2377\n",
      "2023-07-03 17:07:31,711 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:07:35,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2415\n",
      "2023-07-03 17:07:36,517 - \u001b[1;33mWARNING\u001b[1;0m - Request 2390 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89905 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:46,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 1804 failed with Exception \n",
      "2023-07-03 17:07:51,524 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:51 2023\n",
      "2023-07-03 17:07:51,578 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2433\n",
      "2023-07-03 17:07:52,033 - \u001b[1;33mWARNING\u001b[1;0m - Request 2444 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89741 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:52,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 2425 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:07,044 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:07 2023\n",
      "2023-07-03 17:08:07,230 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:07 2023\n",
      "2023-07-03 17:08:07,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2451\n",
      "2023-07-03 17:08:07,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2471\n",
      "2023-07-03 17:08:08,355 - \u001b[1;33mWARNING\u001b[1;0m - Request 2480 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89894 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:08,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 2483 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89824 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:23,369 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:23 2023\n",
      "2023-07-03 17:08:23,407 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:23 2023\n",
      "2023-07-03 17:08:23,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2489\n",
      "2023-07-03 17:08:23,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2509\n",
      "2023-07-03 17:08:23,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 2491 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89841 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:38,737 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:38 2023\n",
      "2023-07-03 17:08:38,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2528\n",
      "2023-07-03 17:08:39,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 2547 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89895 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:39,193 - \u001b[1;33mWARNING\u001b[1;0m - Request 2527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89676 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:54,045 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:54 2023\n",
      "2023-07-03 17:08:54,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2548\n",
      "2023-07-03 17:08:54,194 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:54 2023\n",
      "2023-07-03 17:08:54,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2566\n",
      "2023-07-03 17:08:54,579 - \u001b[1;33mWARNING\u001b[1;0m - Request 2572 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89701 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:54,617 - \u001b[1;33mWARNING\u001b[1;0m - Request 2579 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89643 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:09,592 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:09 2023\n",
      "2023-07-03 17:09:09,618 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:09 2023\n",
      "2023-07-03 17:09:09,638 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2584\n",
      "2023-07-03 17:09:09,702 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2604\n",
      "2023-07-03 17:09:09,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 2609 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89836 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:24,875 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:24 2023\n",
      "2023-07-03 17:09:24,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2623\n",
      "2023-07-03 17:09:25,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2643\n",
      "2023-07-03 17:09:25,293 - \u001b[1;33mWARNING\u001b[1;0m - Request 2643 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89724 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:25,312 - \u001b[1;33mWARNING\u001b[1;0m - Request 2614 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89708 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:40,306 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:40 2023\n",
      "2023-07-03 17:09:40,313 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:40 2023\n",
      "2023-07-03 17:09:40,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2661\n",
      "2023-07-03 17:09:43,444 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2681\n",
      "2023-07-03 17:09:45,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 2682 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89569 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:45,243 - \u001b[1;33mWARNING\u001b[1;0m - Request 2683 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89322 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:00,089 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:00 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:10:00,244 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:00 2023\n",
      "2023-07-03 17:10:00,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2699\n",
      "2023-07-03 17:10:00,545 - \u001b[1;33mWARNING\u001b[1;0m - Request 2715 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89478 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:00,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 2716 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89435 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:08,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 2110 failed with Exception \n",
      "2023-07-03 17:10:10,609 - \u001b[1;33mWARNING\u001b[1;0m - Request 2614 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 889a07e16030e376989d82e967de9e6b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:15,551 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:15 2023\n",
      "2023-07-03 17:10:15,574 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:15 2023\n",
      "2023-07-03 17:10:15,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2716\n",
      "2023-07-03 17:10:15,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2735\n",
      "2023-07-03 17:10:15,831 - \u001b[1;33mWARNING\u001b[1;0m - Request 2743 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89628 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:30,844 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:30 2023\n",
      "2023-07-03 17:10:30,884 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2754\n",
      "2023-07-03 17:10:30,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2774\n",
      "2023-07-03 17:10:31,218 - \u001b[1;33mWARNING\u001b[1;0m - Request 2775 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89626 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:31,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 2778 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89526 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:46,227 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:46 2023\n",
      "2023-07-03 17:10:46,270 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:46 2023\n",
      "2023-07-03 17:10:46,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2792\n",
      "2023-07-03 17:10:46,526 - \u001b[1;33mWARNING\u001b[1;0m - Request 2794 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89612 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:01,540 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:01 2023\n",
      "2023-07-03 17:11:01,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2811\n",
      "2023-07-03 17:11:01,613 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2831\n",
      "2023-07-03 17:11:01,812 - \u001b[1;33mWARNING\u001b[1;0m - Request 2835 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89757 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:01,884 - \u001b[1;33mWARNING\u001b[1;0m - Request 2842 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89650 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:16,819 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:16 2023\n",
      "2023-07-03 17:11:16,886 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:16 2023\n",
      "2023-07-03 17:11:16,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2849\n",
      "2023-07-03 17:11:16,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2869\n",
      "2023-07-03 17:11:17,148 - \u001b[1;33mWARNING\u001b[1;0m - Request 2873 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89899 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:32,162 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:32 2023\n",
      "2023-07-03 17:11:32,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2888\n",
      "2023-07-03 17:11:32,648 - \u001b[1;33mWARNING\u001b[1;0m - Request 2904 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89725 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:47,663 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:47 2023\n",
      "2023-07-03 17:11:47,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2904\n",
      "2023-07-03 17:11:47,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2927\n",
      "2023-07-03 17:11:48,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 2914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:48,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 2931 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89449 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:03,221 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:03 2023\n",
      "2023-07-03 17:12:03,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2945\n",
      "2023-07-03 17:12:03,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2965\n",
      "2023-07-03 17:12:03,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 2969 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:03,535 - \u001b[1;33mWARNING\u001b[1;0m - Request 2966 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89540 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:18,546 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:18 2023\n",
      "2023-07-03 17:12:18,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:12:19,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 2997 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89374 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:19,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 3001 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:34,033 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:34 2023\n",
      "2023-07-03 17:12:34,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3003\n",
      "2023-07-03 17:12:34,046 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:34 2023\n",
      "2023-07-03 17:12:34,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3021\n",
      "2023-07-03 17:12:34,511 - \u001b[1;33mWARNING\u001b[1;0m - Request 3010 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:49,525 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:49 2023\n",
      "2023-07-03 17:12:49,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3040\n",
      "2023-07-03 17:12:49,610 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3060\n",
      "2023-07-03 17:12:50,013 - \u001b[1;33mWARNING\u001b[1;0m - Request 3060 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89818 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:50,360 - \u001b[1;33mWARNING\u001b[1;0m - Request 3067 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:05,028 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:05 2023\n",
      "2023-07-03 17:13:05,361 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:05 2023\n",
      "2023-07-03 17:13:05,405 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3078\n",
      "2023-07-03 17:13:05,460 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3098\n",
      "2023-07-03 17:13:05,697 - \u001b[1;33mWARNING\u001b[1;0m - Request 3099 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89371 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:20,712 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:20 2023\n",
      "2023-07-03 17:13:20,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3117\n",
      "2023-07-03 17:13:20,991 - \u001b[1;33mWARNING\u001b[1;0m - Request 3116 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:21,002 - \u001b[1;33mWARNING\u001b[1;0m - Request 3118 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89566 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:36,005 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:36 2023\n",
      "2023-07-03 17:13:36,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3135\n",
      "2023-07-03 17:13:36,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3155\n",
      "2023-07-03 17:13:38,334 - \u001b[1;33mWARNING\u001b[1;0m - Request 3147 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89395 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:38,360 - \u001b[1;33mWARNING\u001b[1;0m - Request 3158 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89360 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:53,349 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:53 2023\n",
      "2023-07-03 17:13:53,361 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:53 2023\n",
      "2023-07-03 17:13:53,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3173\n",
      "2023-07-03 17:13:53,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3193\n",
      "2023-07-03 17:13:53,762 - \u001b[1;33mWARNING\u001b[1;0m - Request 3199 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:08,776 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:08 2023\n",
      "2023-07-03 17:14:08,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3212\n",
      "2023-07-03 17:14:09,124 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3232\n",
      "2023-07-03 17:14:09,290 - \u001b[1;33mWARNING\u001b[1;0m - Request 3223 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89721 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:09,368 - \u001b[1;33mWARNING\u001b[1;0m - Request 3232 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89646 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:24,303 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:24 2023\n",
      "2023-07-03 17:14:24,369 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:24 2023\n",
      "2023-07-03 17:14:24,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3250\n",
      "2023-07-03 17:14:24,721 - \u001b[1;33mWARNING\u001b[1;0m - Request 3251 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89784 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:25,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2622 failed with Exception \n",
      "2023-07-03 17:14:39,727 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:39 2023\n",
      "2023-07-03 17:14:39,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3268\n",
      "2023-07-03 17:14:39,812 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3288\n",
      "2023-07-03 17:14:40,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 3295 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89816 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:55,047 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:55 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:14:55,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3307\n",
      "2023-07-03 17:14:55,149 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3327\n",
      "2023-07-03 17:14:55,318 - \u001b[1;33mWARNING\u001b[1;0m - Request 3304 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89947 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:55,516 - \u001b[1;33mWARNING\u001b[1;0m - Request 3317 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89649 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:10,332 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:10 2023\n",
      "2023-07-03 17:15:10,517 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:10 2023\n",
      "2023-07-03 17:15:10,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3345\n",
      "2023-07-03 17:15:11,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 3329 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89891 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:11,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 3353 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89880 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:26,697 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:26 2023\n",
      "2023-07-03 17:15:26,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3363\n",
      "2023-07-03 17:15:26,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3383\n",
      "2023-07-03 17:15:27,443 - \u001b[1;33mWARNING\u001b[1;0m - Request 3374 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:42,458 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:42 2023\n",
      "2023-07-03 17:15:42,496 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3402\n",
      "2023-07-03 17:15:42,555 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3422\n",
      "2023-07-03 17:15:42,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 3425 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89466 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:43,022 - \u001b[1;33mWARNING\u001b[1;0m - Request 3426 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89734 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:57,729 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:58 2023\n",
      "2023-07-03 17:15:58,023 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:58 2023\n",
      "2023-07-03 17:15:58,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3440\n",
      "2023-07-03 17:15:58,319 - \u001b[1;33mWARNING\u001b[1;0m - Request 3457 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89932 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:58,366 - \u001b[1;33mWARNING\u001b[1;0m - Request 3458 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89849 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:13,333 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:13 2023\n",
      "2023-07-03 17:16:13,367 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:13 2023\n",
      "2023-07-03 17:16:13,368 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3457\n",
      "2023-07-03 17:16:13,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3478\n",
      "2023-07-03 17:16:13,881 - \u001b[1;33mWARNING\u001b[1;0m - Request 3488 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89624 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:13,935 - \u001b[1;33mWARNING\u001b[1;0m - Request 3490 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89540 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:17,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 2858 failed with Exception \n",
      "2023-07-03 17:16:28,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:28 2023\n",
      "2023-07-03 17:16:28,936 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:28 2023\n",
      "2023-07-03 17:16:28,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3495\n",
      "2023-07-03 17:16:29,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3515\n",
      "2023-07-03 17:16:29,440 - \u001b[1;33mWARNING\u001b[1;0m - Request 3520 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89455 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:32,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 2877 failed with Exception \n",
      "2023-07-03 17:16:44,442 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:44 2023\n",
      "2023-07-03 17:16:44,489 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3533\n",
      "2023-07-03 17:16:44,913 - \u001b[1;33mWARNING\u001b[1;0m - Request 3541 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:44,956 - \u001b[1;33mWARNING\u001b[1;0m - Request 3551 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89266 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:59,927 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:59 2023\n",
      "2023-07-03 17:16:59,928 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3553\n",
      "2023-07-03 17:16:59,957 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:59 2023\n",
      "2023-07-03 17:17:00,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3571\n",
      "2023-07-03 17:17:00,220 - \u001b[1;33mWARNING\u001b[1;0m - Request 3583 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:00,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 3584 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:17:14,712 - \u001b[1;33mWARNING\u001b[1;0m - Request 3533 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 31b2c4865e5f2c5ae4fb74c504d1a581 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:15,221 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:15 2023\n",
      "2023-07-03 17:17:15,242 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:15 2023\n",
      "2023-07-03 17:17:15,258 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3588\n",
      "2023-07-03 17:17:15,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3608\n",
      "2023-07-03 17:17:18,539 - \u001b[1;33mWARNING\u001b[1;0m - Request 3621 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:33,552 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:33 2023\n",
      "2023-07-03 17:17:33,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3627\n",
      "2023-07-03 17:17:33,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3647\n",
      "2023-07-03 17:17:33,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 3653 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:33,847 - \u001b[1;33mWARNING\u001b[1;0m - Request 3650 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:48,859 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:48 2023\n",
      "2023-07-03 17:17:48,908 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3665\n",
      "2023-07-03 17:17:49,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3685\n",
      "2023-07-03 17:17:50,612 - \u001b[1;33mWARNING\u001b[1;0m - Request 3688 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:50,617 - \u001b[1;33mWARNING\u001b[1;0m - Request 3657 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89527 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:05,626 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:05 2023\n",
      "2023-07-03 17:18:05,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3703\n",
      "2023-07-03 17:18:06,117 - \u001b[1;33mWARNING\u001b[1;0m - Request 3712 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89289 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:21,129 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:21 2023\n",
      "2023-07-03 17:18:21,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3722\n",
      "2023-07-03 17:18:21,220 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3742\n",
      "2023-07-03 17:18:21,694 - \u001b[1;33mWARNING\u001b[1;0m - Request 3734 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89729 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:21,698 - \u001b[1;33mWARNING\u001b[1;0m - Request 3753 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89703 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:36,708 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:36 2023\n",
      "2023-07-03 17:18:36,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3760\n",
      "2023-07-03 17:18:36,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3780\n",
      "2023-07-03 17:18:37,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 3781 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89532 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:37,294 - \u001b[1;33mWARNING\u001b[1;0m - Request 3785 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89407 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:52,220 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:52 2023\n",
      "2023-07-03 17:18:52,295 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:52 2023\n",
      "2023-07-03 17:18:52,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3798\n",
      "2023-07-03 17:18:53,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3818\n",
      "2023-07-03 17:18:56,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 3820 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89980 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:09,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 3228 failed with Exception \n",
      "2023-07-03 17:19:11,188 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:11 2023\n",
      "2023-07-03 17:19:11,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3836\n",
      "2023-07-03 17:19:11,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 3854 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89404 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:11,473 - \u001b[1;33mWARNING\u001b[1;0m - Request 3853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89378 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:24,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 3223 failed with Exception \n",
      "2023-07-03 17:19:26,455 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:26 2023\n",
      "2023-07-03 17:19:26,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3856\n",
      "2023-07-03 17:19:26,474 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:26 2023\n",
      "2023-07-03 17:19:26,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3873\n",
      "2023-07-03 17:19:26,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 3879 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89888 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:40,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 3293 failed with Exception \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:19:41,953 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:41 2023\n",
      "2023-07-03 17:19:41,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3891\n",
      "2023-07-03 17:19:42,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3911\n",
      "2023-07-03 17:19:42,242 - \u001b[1;33mWARNING\u001b[1;0m - Request 3914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:42,276 - \u001b[1;33mWARNING\u001b[1;0m - Request 3910 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89353 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:57,249 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:57 2023\n",
      "2023-07-03 17:19:57,279 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:57 2023\n",
      "2023-07-03 17:19:57,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3929\n",
      "2023-07-03 17:19:57,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3949\n",
      "2023-07-03 17:19:57,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 3948 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89537 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:12,588 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:12 2023\n",
      "2023-07-03 17:20:12,655 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3968\n",
      "2023-07-03 17:20:12,851 - \u001b[1;33mWARNING\u001b[1;0m - Request 3979 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89666 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:12,858 - \u001b[1;33mWARNING\u001b[1;0m - Request 3977 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89669 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:27,865 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:27 2023\n",
      "2023-07-03 17:20:27,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3986\n",
      "2023-07-03 17:20:27,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4006\n",
      "2023-07-03 17:20:28,176 - \u001b[1;33mWARNING\u001b[1;0m - Request 4009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89727 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:28,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 4013 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89681 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:43,191 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:43 2023\n",
      "2023-07-03 17:20:43,202 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:43 2023\n",
      "2023-07-03 17:20:43,247 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4024\n",
      "2023-07-03 17:20:43,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4044\n",
      "2023-07-03 17:20:43,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 4043 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89703 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:58,501 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:58 2023\n",
      "2023-07-03 17:20:58,568 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4063\n",
      "2023-07-03 17:20:59,400 - \u001b[1;33mWARNING\u001b[1;0m - Request 4055 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89748 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:59,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 4048 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89745 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:14,407 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:14 2023\n",
      "2023-07-03 17:21:14,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4081\n",
      "2023-07-03 17:21:14,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4101\n",
      "2023-07-03 17:21:14,681 - \u001b[1;33mWARNING\u001b[1;0m - Request 4104 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89991 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:29,133 - \u001b[1;33mWARNING\u001b[1;0m - Request 4075 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a492e78ad2556e0480a1657277b1d075 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:29,683 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:29 2023\n",
      "2023-07-03 17:21:29,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4119\n",
      "2023-07-03 17:21:29,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4139\n",
      "2023-07-03 17:21:30,902 - \u001b[1;33mWARNING\u001b[1;0m - Request 4141 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89425 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:30,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 4115 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:30,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 4143 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89293 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:45,915 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:45 2023\n",
      "2023-07-03 17:21:45,991 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:45 2023\n",
      "2023-07-03 17:21:46,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4156\n",
      "2023-07-03 17:21:47,347 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4176\n",
      "2023-07-03 17:21:50,814 - \u001b[1;33mWARNING\u001b[1;0m - Request 4176 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89822 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:22:05,829 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:05 2023\n",
      "2023-07-03 17:22:05,877 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4195\n",
      "2023-07-03 17:22:05,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4215\n",
      "2023-07-03 17:22:06,325 - \u001b[1;33mWARNING\u001b[1;0m - Request 4215 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89669 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:06,534 - \u001b[1;33mWARNING\u001b[1;0m - Request 4216 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:15,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 3614 failed with Exception \n",
      "2023-07-03 17:22:21,333 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:21 2023\n",
      "2023-07-03 17:22:21,535 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:21 2023\n",
      "2023-07-03 17:22:21,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4232\n",
      "2023-07-03 17:22:21,800 - \u001b[1;33mWARNING\u001b[1;0m - Request 4244 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:21,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 4247 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:34,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 3625 failed with Exception \n",
      "2023-07-03 17:22:36,803 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:36 2023\n",
      "2023-07-03 17:22:36,881 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:36 2023\n",
      "2023-07-03 17:22:36,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4249\n",
      "2023-07-03 17:22:36,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4269\n",
      "2023-07-03 17:22:37,154 - \u001b[1;33mWARNING\u001b[1;0m - Request 4275 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:52,168 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:52 2023\n",
      "2023-07-03 17:22:52,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4288\n",
      "2023-07-03 17:22:52,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4308\n",
      "2023-07-03 17:22:56,787 - \u001b[1;33mWARNING\u001b[1;0m - Request 4314 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89700 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:56,954 - \u001b[1;33mWARNING\u001b[1;0m - Request 4319 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89436 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:11,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:11 2023\n",
      "2023-07-03 17:23:11,955 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:11 2023\n",
      "2023-07-03 17:23:11,986 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4326\n",
      "2023-07-03 17:23:12,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4346\n",
      "2023-07-03 17:23:12,455 - \u001b[1;33mWARNING\u001b[1;0m - Request 4343 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:12,457 - \u001b[1;33mWARNING\u001b[1;0m - Request 4348 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89322 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:27,469 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:27 2023\n",
      "2023-07-03 17:23:27,521 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4364\n",
      "2023-07-03 17:23:27,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 4382 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89585 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:42,730 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:42 2023\n",
      "2023-07-03 17:23:42,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4382\n",
      "2023-07-03 17:23:42,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4403\n",
      "2023-07-03 17:23:46,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4423\n",
      "2023-07-03 17:23:47,061 - \u001b[1;33mWARNING\u001b[1;0m - Request 4418 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89418 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:47,141 - \u001b[1;33mWARNING\u001b[1;0m - Request 4420 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89297 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:55,500 - \u001b[1;33mWARNING\u001b[1;0m - Request 3822 failed with Exception \n",
      "2023-07-03 17:24:02,069 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:02 2023\n",
      "2023-07-03 17:24:02,143 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:02 2023\n",
      "2023-07-03 17:24:02,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4440\n",
      "2023-07-03 17:24:02,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 4440 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89719 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:02,809 - \u001b[1;33mWARNING\u001b[1;0m - Request 4455 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:17,704 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:17 2023\n",
      "2023-07-03 17:24:17,810 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:17 2023\n",
      "2023-07-03 17:24:17,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4458\n",
      "2023-07-03 17:24:17,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4478\n",
      "2023-07-03 17:24:18,106 - \u001b[1;33mWARNING\u001b[1;0m - Request 4477 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89709 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:24:33,121 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:33 2023\n",
      "2023-07-03 17:24:33,163 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4497\n",
      "2023-07-03 17:24:33,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4517\n",
      "2023-07-03 17:24:33,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 4510 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89798 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:33,725 - \u001b[1;33mWARNING\u001b[1;0m - Request 4519 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89313 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:48,421 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:48 2023\n",
      "2023-07-03 17:24:48,726 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:48 2023\n",
      "2023-07-03 17:24:48,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4535\n",
      "2023-07-03 17:24:49,736 - \u001b[1;33mWARNING\u001b[1;0m - Request 4544 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89800 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:04,749 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:04 2023\n",
      "2023-07-03 17:25:04,755 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4554\n",
      "2023-07-03 17:25:04,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4574\n",
      "2023-07-03 17:25:05,134 - \u001b[1;33mWARNING\u001b[1;0m - Request 4585 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89852 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:05,235 - \u001b[1;33mWARNING\u001b[1;0m - Request 4582 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89697 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:20,150 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:20 2023\n",
      "2023-07-03 17:25:20,238 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:20 2023\n",
      "2023-07-03 17:25:20,268 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4592\n",
      "2023-07-03 17:25:20,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4612\n",
      "2023-07-03 17:25:20,711 - \u001b[1;33mWARNING\u001b[1;0m - Request 4617 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89594 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:35,725 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:35 2023\n",
      "2023-07-03 17:25:35,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4631\n",
      "2023-07-03 17:25:35,986 - \u001b[1;33mWARNING\u001b[1;0m - Request 4630 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89635 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:36,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 4639 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89560 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:50,996 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:51 2023\n",
      "2023-07-03 17:25:51,043 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:51 2023\n",
      "2023-07-03 17:25:51,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4630\n",
      "2023-07-03 17:25:51,113 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4669\n",
      "2023-07-03 17:25:51,310 - \u001b[1;33mWARNING\u001b[1;0m - Request 4681 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89667 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:51,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 4667 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89386 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:06,323 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:06 2023\n",
      "2023-07-03 17:26:06,496 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:06 2023\n",
      "2023-07-03 17:26:06,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4687\n",
      "2023-07-03 17:26:06,582 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4707\n",
      "2023-07-03 17:26:06,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 4711 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89497 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:06,872 - \u001b[1;33mWARNING\u001b[1;0m - Request 4713 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89384 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:21,817 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:21 2023\n",
      "2023-07-03 17:26:21,874 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:21 2023\n",
      "2023-07-03 17:26:21,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4725\n",
      "2023-07-03 17:26:22,210 - \u001b[1;33mWARNING\u001b[1;0m - Request 4726 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89540 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:37,216 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:37 2023\n",
      "2023-07-03 17:26:37,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4745\n",
      "2023-07-03 17:26:37,285 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4764\n",
      "2023-07-03 17:26:37,510 - \u001b[1;33mWARNING\u001b[1;0m - Request 4775 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89672 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:37,612 - \u001b[1;33mWARNING\u001b[1;0m - Request 4777 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:52,519 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:52 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:26:52,613 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:52 2023\n",
      "2023-07-03 17:26:52,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4782\n",
      "2023-07-03 17:26:52,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4802\n",
      "2023-07-03 17:26:54,360 - \u001b[1;33mWARNING\u001b[1;0m - Request 4799 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89669 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:06,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 4195 failed with Exception \n",
      "2023-07-03 17:27:09,365 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:09 2023\n",
      "2023-07-03 17:27:09,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4820\n",
      "2023-07-03 17:27:09,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4840\n",
      "2023-07-03 17:27:09,825 - \u001b[1;33mWARNING\u001b[1;0m - Request 4827 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89540 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:09,864 - \u001b[1;33mWARNING\u001b[1;0m - Request 4841 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89477 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:24,828 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:24 2023\n",
      "2023-07-03 17:27:24,865 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:24 2023\n",
      "2023-07-03 17:27:25,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4858\n",
      "2023-07-03 17:27:25,466 - \u001b[1;33mWARNING\u001b[1;0m - Request 4872 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89838 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:40,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:40 2023\n",
      "2023-07-03 17:27:40,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4877\n",
      "2023-07-03 17:27:40,566 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4897\n",
      "2023-07-03 17:27:41,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 4900 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89554 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:42,006 - \u001b[1;33mWARNING\u001b[1;0m - Request 4885 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89547 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:57,009 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:57 2023\n",
      "2023-07-03 17:27:57,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4915\n",
      "2023-07-03 17:27:57,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4935\n",
      "2023-07-03 17:27:58,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 4920 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89946 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:13,566 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:13 2023\n",
      "2023-07-03 17:28:13,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4954\n",
      "2023-07-03 17:28:13,696 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4974\n",
      "2023-07-03 17:28:14,098 - \u001b[1;33mWARNING\u001b[1;0m - Request 4970 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89713 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:29,112 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:29 2023\n",
      "2023-07-03 17:28:29,170 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4993\n",
      "2023-07-03 17:28:29,374 - \u001b[1;33mWARNING\u001b[1;0m - Request 5008 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89939 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:29,381 - \u001b[1;33mWARNING\u001b[1;0m - Request 5009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89934 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:29,458 - \u001b[1;33mWARNING\u001b[1;0m - Request 5010 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89819 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:44,389 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:44 2023\n",
      "2023-07-03 17:28:44,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:44 2023\n",
      "2023-07-03 17:28:44,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5009\n",
      "2023-07-03 17:28:44,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5030\n",
      "2023-07-03 17:28:44,760 - \u001b[1;33mWARNING\u001b[1;0m - Request 5037 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89932 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:59,775 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:59 2023\n",
      "2023-07-03 17:28:59,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5049\n",
      "2023-07-03 17:28:59,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5069\n",
      "2023-07-03 17:29:00,060 - \u001b[1;33mWARNING\u001b[1;0m - Request 5065 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89969 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:00,087 - \u001b[1;33mWARNING\u001b[1;0m - Request 5054 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89955 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:15,075 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:15 2023\n",
      "2023-07-03 17:29:15,091 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:15 2023\n",
      "2023-07-03 17:29:15,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5087\n",
      "2023-07-03 17:29:15,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 5092 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89773 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:29:15,627 - \u001b[1;33mWARNING\u001b[1;0m - Request 5105 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89655 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:30,564 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:30 2023\n",
      "2023-07-03 17:29:30,628 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:30 2023\n",
      "2023-07-03 17:29:30,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5092\n",
      "2023-07-03 17:29:30,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5125\n",
      "2023-07-03 17:29:31,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 5112 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89726 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:46,081 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:46 2023\n",
      "2023-07-03 17:29:46,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5144\n",
      "2023-07-03 17:29:46,188 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5164\n",
      "2023-07-03 17:29:46,370 - \u001b[1;33mWARNING\u001b[1;0m - Request 5169 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89797 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:46,630 - \u001b[1;33mWARNING\u001b[1;0m - Request 5168 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:01,384 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:01 2023\n",
      "2023-07-03 17:30:01,631 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:01 2023\n",
      "2023-07-03 17:30:01,679 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5182\n",
      "2023-07-03 17:30:01,924 - \u001b[1;33mWARNING\u001b[1;0m - Request 5179 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:01,976 - \u001b[1;33mWARNING\u001b[1;0m - Request 5201 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:16,938 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:16 2023\n",
      "2023-07-03 17:30:16,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5202\n",
      "2023-07-03 17:30:16,976 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:16 2023\n",
      "2023-07-03 17:30:17,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5220\n",
      "2023-07-03 17:30:17,409 - \u001b[1;33mWARNING\u001b[1;0m - Request 5204 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:32,423 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:32 2023\n",
      "2023-07-03 17:30:32,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5239\n",
      "2023-07-03 17:30:32,522 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5259\n",
      "2023-07-03 17:30:32,712 - \u001b[1;33mWARNING\u001b[1;0m - Request 5265 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:47,726 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:47 2023\n",
      "2023-07-03 17:30:47,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5278\n",
      "2023-07-03 17:30:47,984 - \u001b[1;33mWARNING\u001b[1;0m - Request 5287 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89638 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:48,002 - \u001b[1;33mWARNING\u001b[1;0m - Request 5295 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89624 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:02,998 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:03 2023\n",
      "2023-07-03 17:31:02,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5298\n",
      "2023-07-03 17:31:03,002 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:03 2023\n",
      "2023-07-03 17:31:03,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5316\n",
      "2023-07-03 17:31:03,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 5324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89776 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:03,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 5329 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89606 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:18,288 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:18 2023\n",
      "2023-07-03 17:31:18,386 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:18 2023\n",
      "2023-07-03 17:31:18,405 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5334\n",
      "2023-07-03 17:31:18,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5354\n",
      "2023-07-03 17:31:18,892 - \u001b[1;33mWARNING\u001b[1;0m - Request 5360 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89432 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:18,922 - \u001b[1;33mWARNING\u001b[1;0m - Request 5361 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:22,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 4727 failed with Exception \n",
      "2023-07-03 17:31:33,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:33 2023\n",
      "2023-07-03 17:31:33,922 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:33 2023\n",
      "2023-07-03 17:31:33,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5371\n",
      "2023-07-03 17:31:34,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5391\n",
      "2023-07-03 17:31:34,178 - \u001b[1;33mWARNING\u001b[1;0m - Request 5391 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89525 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:31:49,193 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:49 2023\n",
      "2023-07-03 17:31:49,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5410\n",
      "2023-07-03 17:31:49,489 - \u001b[1;33mWARNING\u001b[1;0m - Request 5422 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89566 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:49,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 5424 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89513 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:04,503 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:04 2023\n",
      "2023-07-03 17:32:04,519 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5428\n",
      "2023-07-03 17:32:04,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5448\n",
      "2023-07-03 17:32:04,978 - \u001b[1;33mWARNING\u001b[1;0m - Request 5452 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:19,992 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:19 2023\n",
      "2023-07-03 17:32:20,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5467\n",
      "2023-07-03 17:32:20,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5487\n",
      "2023-07-03 17:32:20,248 - \u001b[1;33mWARNING\u001b[1;0m - Request 5482 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89622 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:20,260 - \u001b[1;33mWARNING\u001b[1;0m - Request 5488 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89613 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:35,263 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:35 2023\n",
      "2023-07-03 17:32:35,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5505\n",
      "2023-07-03 17:32:37,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5525\n",
      "2023-07-03 17:32:39,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 5523 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89603 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:54,937 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:54 2023\n",
      "2023-07-03 17:32:54,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5544\n",
      "2023-07-03 17:32:55,536 - \u001b[1;33mWARNING\u001b[1;0m - Request 5554 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:56,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 5545 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:10,549 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:11 2023\n",
      "2023-07-03 17:33:11,032 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:11 2023\n",
      "2023-07-03 17:33:11,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5554\n",
      "2023-07-03 17:33:11,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5582\n",
      "2023-07-03 17:33:11,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 5594 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89588 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:11,302 - \u001b[1;33mWARNING\u001b[1;0m - Request 5585 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89587 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:14,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 4920 failed with Exception \n",
      "2023-07-03 17:33:26,298 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:26 2023\n",
      "2023-07-03 17:33:26,303 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:26 2023\n",
      "2023-07-03 17:33:26,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5599\n",
      "2023-07-03 17:33:26,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5619\n",
      "2023-07-03 17:33:28,427 - \u001b[1;33mWARNING\u001b[1;0m - Request 5627 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89873 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:28,566 - \u001b[1;33mWARNING\u001b[1;0m - Request 5629 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89696 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:43,431 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:43 2023\n",
      "2023-07-03 17:33:43,567 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:43 2023\n",
      "2023-07-03 17:33:43,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5637\n",
      "2023-07-03 17:33:43,651 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5657\n",
      "2023-07-03 17:33:44,023 - \u001b[1;33mWARNING\u001b[1;0m - Request 5649 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89525 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:44,095 - \u001b[1;33mWARNING\u001b[1;0m - Request 5661 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:59,030 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:59 2023\n",
      "2023-07-03 17:33:59,096 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:59 2023\n",
      "2023-07-03 17:33:59,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5675\n",
      "2023-07-03 17:33:59,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 5693 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89837 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:14,707 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:14 2023\n",
      "2023-07-03 17:34:14,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:34:14,793 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5714\n",
      "2023-07-03 17:34:15,238 - \u001b[1;33mWARNING\u001b[1;0m - Request 5721 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89682 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:15,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 5726 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89608 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:30,253 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:30 2023\n",
      "2023-07-03 17:34:30,284 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:30 2023\n",
      "2023-07-03 17:34:30,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5732\n",
      "2023-07-03 17:34:30,372 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5752\n",
      "2023-07-03 17:34:33,216 - \u001b[1;33mWARNING\u001b[1;0m - Request 5750 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89346 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:33,219 - \u001b[1;33mWARNING\u001b[1;0m - Request 5736 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89349 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:46,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 5145 failed with Exception \n",
      "2023-07-03 17:34:48,219 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:48 2023\n",
      "2023-07-03 17:34:48,246 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5769\n",
      "2023-07-03 17:34:48,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5789\n",
      "2023-07-03 17:34:48,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 5789 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89466 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:03,515 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:03 2023\n",
      "2023-07-03 17:35:03,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5808\n",
      "2023-07-03 17:35:04,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5828\n",
      "2023-07-03 17:35:07,645 - \u001b[1;33mWARNING\u001b[1;0m - Request 5821 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:07,685 - \u001b[1;33mWARNING\u001b[1;0m - Request 5798 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:22,657 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:22 2023\n",
      "2023-07-03 17:35:22,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:22 2023\n",
      "2023-07-03 17:35:22,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5846\n",
      "2023-07-03 17:35:22,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5866\n",
      "2023-07-03 17:35:23,067 - \u001b[1;33mWARNING\u001b[1;0m - Request 5866 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:38,077 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:38 2023\n",
      "2023-07-03 17:35:38,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5885\n",
      "2023-07-03 17:35:38,333 - \u001b[1;33mWARNING\u001b[1;0m - Request 5890 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:38,487 - \u001b[1;33mWARNING\u001b[1;0m - Request 5867 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89289 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:53,345 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:53 2023\n",
      "2023-07-03 17:35:53,489 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:53 2023\n",
      "2023-07-03 17:35:53,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5903\n",
      "2023-07-03 17:35:53,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5923\n",
      "2023-07-03 17:35:54,037 - \u001b[1;33mWARNING\u001b[1;0m - Request 5928 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89801 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:54,137 - \u001b[1;33mWARNING\u001b[1;0m - Request 5931 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89649 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:09,049 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:09 2023\n",
      "2023-07-03 17:36:09,138 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:09 2023\n",
      "2023-07-03 17:36:09,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5941\n",
      "2023-07-03 17:36:09,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5961\n",
      "2023-07-03 17:36:09,616 - \u001b[1;33mWARNING\u001b[1;0m - Request 5957 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89399 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:09,661 - \u001b[1;33mWARNING\u001b[1;0m - Request 5963 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89335 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:24,632 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:24 2023\n",
      "2023-07-03 17:36:24,662 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:24 2023\n",
      "2023-07-03 17:36:24,722 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5979\n",
      "2023-07-03 17:36:25,427 - \u001b[1;33mWARNING\u001b[1;0m - Request 5995 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89411 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:40,440 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:40 2023\n",
      "2023-07-03 17:36:40,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:36:40,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6018\n",
      "2023-07-03 17:36:40,770 - \u001b[1;33mWARNING\u001b[1;0m - Request 6028 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89441 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:40,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 6011 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:55,773 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:55 2023\n",
      "2023-07-03 17:36:55,846 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:55 2023\n",
      "2023-07-03 17:36:55,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6036\n",
      "2023-07-03 17:36:55,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6056\n",
      "2023-07-03 17:36:56,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 6060 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89578 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:11,511 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:11 2023\n",
      "2023-07-03 17:37:11,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6075\n",
      "2023-07-03 17:37:11,772 - \u001b[1;33mWARNING\u001b[1;0m - Request 6093 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:11,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 6087 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:26,775 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:26 2023\n",
      "2023-07-03 17:37:26,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:26 2023\n",
      "2023-07-03 17:37:26,801 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6093\n",
      "2023-07-03 17:37:26,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6113\n",
      "2023-07-03 17:37:27,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 6103 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89591 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:27,814 - \u001b[1;33mWARNING\u001b[1;0m - Request 6126 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89373 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:42,685 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:42 2023\n",
      "2023-07-03 17:37:42,815 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:42 2023\n",
      "2023-07-03 17:37:42,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6131\n",
      "2023-07-03 17:37:42,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6151\n",
      "2023-07-03 17:37:43,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 6158 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89843 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:58,398 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:58 2023\n",
      "2023-07-03 17:37:58,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6170\n",
      "2023-07-03 17:37:58,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6190\n",
      "2023-07-03 17:37:58,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 6182 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89597 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:58,954 - \u001b[1;33mWARNING\u001b[1;0m - Request 6191 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:13,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 6066 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-03 17:38:13,936 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:13 2023\n",
      "2023-07-03 17:38:13,956 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:13 2023\n",
      "2023-07-03 17:38:14,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6207\n",
      "2023-07-03 17:38:14,393 - \u001b[1;33mWARNING\u001b[1;0m - Request 6204 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89523 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:14,534 - \u001b[1;33mWARNING\u001b[1;0m - Request 6222 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89314 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:26,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 5602 failed with Exception \n",
      "2023-07-03 17:38:29,397 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:29 2023\n",
      "2023-07-03 17:38:29,535 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:29 2023\n",
      "2023-07-03 17:38:29,544 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6224\n",
      "2023-07-03 17:38:29,616 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6244\n",
      "2023-07-03 17:38:30,111 - \u001b[1;33mWARNING\u001b[1;0m - Request 6253 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89740 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:45,113 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:45 2023\n",
      "2023-07-03 17:38:45,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6263\n",
      "2023-07-03 17:38:45,207 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6283\n",
      "2023-07-03 17:38:45,619 - \u001b[1;33mWARNING\u001b[1;0m - Request 6281 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89584 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:45,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 6286 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89358 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:38:59,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 5682 failed with Exception \n",
      "2023-07-03 17:39:00,621 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:00 2023\n",
      "2023-07-03 17:39:00,767 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:00 2023\n",
      "2023-07-03 17:39:00,821 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6300\n",
      "2023-07-03 17:39:01,338 - \u001b[1;33mWARNING\u001b[1;0m - Request 6317 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89821 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:16,341 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:16 2023\n",
      "2023-07-03 17:39:16,347 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6319\n",
      "2023-07-03 17:39:16,415 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6339\n",
      "2023-07-03 17:39:16,826 - \u001b[1;33mWARNING\u001b[1;0m - Request 6346 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89777 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:16,943 - \u001b[1;33mWARNING\u001b[1;0m - Request 6350 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89604 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:31,829 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:31 2023\n",
      "2023-07-03 17:39:31,944 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:31 2023\n",
      "2023-07-03 17:39:31,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6357\n",
      "2023-07-03 17:39:32,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6377\n",
      "2023-07-03 17:39:33,155 - \u001b[1;33mWARNING\u001b[1;0m - Request 6383 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89747 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:48,169 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:48 2023\n",
      "2023-07-03 17:39:48,215 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6396\n",
      "2023-07-03 17:39:48,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6416\n",
      "2023-07-03 17:39:48,657 - \u001b[1;33mWARNING\u001b[1;0m - Request 6408 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:48,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 6405 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89497 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:03,661 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:03 2023\n",
      "2023-07-03 17:40:03,678 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:03 2023\n",
      "2023-07-03 17:40:03,754 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6434\n",
      "2023-07-03 17:40:04,067 - \u001b[1;33mWARNING\u001b[1;0m - Request 6448 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89513 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:04,120 - \u001b[1;33mWARNING\u001b[1;0m - Request 6419 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:19,082 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:19 2023\n",
      "2023-07-03 17:40:19,121 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:19 2023\n",
      "2023-07-03 17:40:19,136 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6452\n",
      "2023-07-03 17:40:19,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6472\n",
      "2023-07-03 17:40:23,771 - \u001b[1;33mWARNING\u001b[1;0m - Request 6489 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89496 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:38,774 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:38 2023\n",
      "2023-07-03 17:40:38,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6491\n",
      "2023-07-03 17:40:38,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6511\n",
      "2023-07-03 17:40:39,070 - \u001b[1;33mWARNING\u001b[1;0m - Request 6521 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89628 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:39,072 - \u001b[1;33mWARNING\u001b[1;0m - Request 6514 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89641 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:54,082 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:54 2023\n",
      "2023-07-03 17:40:54,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6529\n",
      "2023-07-03 17:40:54,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6549\n",
      "2023-07-03 17:40:54,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 6540 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89444 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:54,582 - \u001b[1;33mWARNING\u001b[1;0m - Request 6545 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:09,577 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:09 2023\n",
      "2023-07-03 17:41:09,583 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:09 2023\n",
      "2023-07-03 17:41:09,638 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6567\n",
      "2023-07-03 17:41:10,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 6585 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89353 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:10,049 - \u001b[1;33mWARNING\u001b[1;0m - Request 6572 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:41:25,058 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:25 2023\n",
      "2023-07-03 17:41:25,060 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6585\n",
      "2023-07-03 17:41:25,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6605\n",
      "2023-07-03 17:41:29,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6625\n",
      "2023-07-03 17:41:29,755 - \u001b[1;33mWARNING\u001b[1;0m - Request 6626 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89442 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:44,770 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:44 2023\n",
      "2023-07-03 17:41:44,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6644\n",
      "2023-07-03 17:41:45,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 6647 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:45,338 - \u001b[1;33mWARNING\u001b[1;0m - Request 6659 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89892 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:00,282 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:00 2023\n",
      "2023-07-03 17:42:00,339 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:00 2023\n",
      "2023-07-03 17:42:00,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6662\n",
      "2023-07-03 17:42:00,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6682\n",
      "2023-07-03 17:42:00,623 - \u001b[1;33mWARNING\u001b[1;0m - Request 6689 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:00,624 - \u001b[1;33mWARNING\u001b[1;0m - Request 6690 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:15,627 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:15 2023\n",
      "2023-07-03 17:42:15,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6700\n",
      "2023-07-03 17:42:15,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6720\n",
      "2023-07-03 17:42:15,911 - \u001b[1;33mWARNING\u001b[1;0m - Request 6714 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:30,926 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:30 2023\n",
      "2023-07-03 17:42:30,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6739\n",
      "2023-07-03 17:42:33,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6759\n",
      "2023-07-03 17:42:33,836 - \u001b[1;33mWARNING\u001b[1;0m - Request 6733 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:33,838 - \u001b[1;33mWARNING\u001b[1;0m - Request 6728 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89319 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:48,851 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:48 2023\n",
      "2023-07-03 17:42:48,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6777\n",
      "2023-07-03 17:42:49,170 - \u001b[1;33mWARNING\u001b[1;0m - Request 6786 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:49,270 - \u001b[1;33mWARNING\u001b[1;0m - Request 6764 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89277 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:04,181 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:04 2023\n",
      "2023-07-03 17:43:04,271 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:04 2023\n",
      "2023-07-03 17:43:04,284 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6795\n",
      "2023-07-03 17:43:04,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6815\n",
      "2023-07-03 17:43:04,540 - \u001b[1;33mWARNING\u001b[1;0m - Request 6822 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89508 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:04,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 6823 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:19,553 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:19 2023\n",
      "2023-07-03 17:43:19,690 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:19 2023\n",
      "2023-07-03 17:43:19,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6833\n",
      "2023-07-03 17:43:19,791 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6853\n",
      "2023-07-03 17:43:20,250 - \u001b[1;33mWARNING\u001b[1;0m - Request 6855 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89736 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:34,576 - \u001b[1;33mWARNING\u001b[1;0m - Request 6795 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f955f55dcb002e9161c6cbcd9e24ce60 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:35,253 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:35 2023\n",
      "2023-07-03 17:43:35,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6871\n",
      "2023-07-03 17:43:35,747 - \u001b[1;33mWARNING\u001b[1;0m - Request 6883 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89573 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:35,838 - \u001b[1;33mWARNING\u001b[1;0m - Request 6887 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89446 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:43:50,762 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:50 2023\n",
      "2023-07-03 17:43:50,839 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:50 2023\n",
      "2023-07-03 17:43:50,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6889\n",
      "2023-07-03 17:43:51,024 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6909\n",
      "2023-07-03 17:43:51,446 - \u001b[1;33mWARNING\u001b[1;0m - Request 6919 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89885 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:06,458 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:06 2023\n",
      "2023-07-03 17:44:06,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6928\n",
      "2023-07-03 17:44:06,552 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6948\n",
      "2023-07-03 17:44:06,711 - \u001b[1;33mWARNING\u001b[1;0m - Request 6949 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:06,713 - \u001b[1;33mWARNING\u001b[1;0m - Request 6944 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89366 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:16,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 6338 failed with Exception \n",
      "2023-07-03 17:44:21,718 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:21 2023\n",
      "2023-07-03 17:44:21,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6965\n",
      "2023-07-03 17:44:22,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 6981 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89805 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:37,252 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:37 2023\n",
      "2023-07-03 17:44:37,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6984\n",
      "2023-07-03 17:44:37,331 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7004\n",
      "2023-07-03 17:44:37,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 7007 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89579 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:37,752 - \u001b[1;33mWARNING\u001b[1;0m - Request 7011 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:52,753 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:52 2023\n",
      "2023-07-03 17:44:52,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7022\n",
      "2023-07-03 17:44:52,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7042\n",
      "2023-07-03 17:44:53,105 - \u001b[1;33mWARNING\u001b[1;0m - Request 7042 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89631 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:53,251 - \u001b[1;33mWARNING\u001b[1;0m - Request 7047 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89402 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:08,120 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:08 2023\n",
      "2023-07-03 17:45:08,254 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:08 2023\n",
      "2023-07-03 17:45:08,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7060\n",
      "2023-07-03 17:45:09,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7080\n",
      "2023-07-03 17:45:11,728 - \u001b[1;33mWARNING\u001b[1;0m - Request 7055 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89768 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:26,730 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:26 2023\n",
      "2023-07-03 17:45:26,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7099\n",
      "2023-07-03 17:45:27,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7119\n",
      "2023-07-03 17:45:30,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 7103 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:30,194 - \u001b[1;33mWARNING\u001b[1;0m - Request 7121 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89346 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:45,195 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:45 2023\n",
      "2023-07-03 17:45:45,243 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7137\n",
      "2023-07-03 17:45:45,790 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7157\n",
      "2023-07-03 17:45:46,197 - \u001b[1;33mWARNING\u001b[1;0m - Request 7129 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:01,211 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:01 2023\n",
      "2023-07-03 17:46:01,282 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7176\n",
      "2023-07-03 17:46:01,709 - \u001b[1;33mWARNING\u001b[1;0m - Request 7185 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89914 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:01,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 7188 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89893 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:16,721 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:16 2023\n",
      "2023-07-03 17:46:16,727 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:16 2023\n",
      "2023-07-03 17:46:16,745 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7194\n",
      "2023-07-03 17:46:16,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7214\n",
      "2023-07-03 17:46:21,661 - \u001b[1;33mWARNING\u001b[1;0m - Request 7232 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89454 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:46:22,163 - \u001b[1;33mWARNING\u001b[1;0m - Request 7228 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89419 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:36,676 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:37 2023\n",
      "2023-07-03 17:46:37,166 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:37 2023\n",
      "2023-07-03 17:46:37,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7232\n",
      "2023-07-03 17:46:37,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7252\n",
      "2023-07-03 17:46:37,423 - \u001b[1;33mWARNING\u001b[1;0m - Request 7257 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89604 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:37,424 - \u001b[1;33mWARNING\u001b[1;0m - Request 7261 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89607 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:52,432 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:52 2023\n",
      "2023-07-03 17:46:52,459 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7270\n",
      "2023-07-03 17:46:52,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7290\n",
      "2023-07-03 17:46:52,716 - \u001b[1;33mWARNING\u001b[1;0m - Request 7294 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89782 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:52,861 - \u001b[1;33mWARNING\u001b[1;0m - Request 7296 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:07,732 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:07 2023\n",
      "2023-07-03 17:47:07,862 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:07 2023\n",
      "2023-07-03 17:47:07,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7308\n",
      "2023-07-03 17:47:08,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7328\n",
      "2023-07-03 17:47:08,641 - \u001b[1;33mWARNING\u001b[1;0m - Request 7300 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89667 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:23,656 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:23 2023\n",
      "2023-07-03 17:47:23,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7347\n",
      "2023-07-03 17:47:23,992 - \u001b[1;33mWARNING\u001b[1;0m - Request 7361 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89692 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:24,023 - \u001b[1;33mWARNING\u001b[1;0m - Request 7359 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89658 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:39,007 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:39 2023\n",
      "2023-07-03 17:47:39,023 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:39 2023\n",
      "2023-07-03 17:47:39,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7365\n",
      "2023-07-03 17:47:39,104 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7385\n",
      "2023-07-03 17:47:39,279 - \u001b[1;33mWARNING\u001b[1;0m - Request 7375 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89794 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:49,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 6788 failed with Exception \n",
      "2023-07-03 17:47:54,285 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:54 2023\n",
      "2023-07-03 17:47:54,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7403\n",
      "2023-07-03 17:47:54,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7423\n",
      "2023-07-03 17:47:54,586 - \u001b[1;33mWARNING\u001b[1;0m - Request 7424 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89817 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:54,628 - \u001b[1;33mWARNING\u001b[1;0m - Request 7407 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:09,598 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:09 2023\n",
      "2023-07-03 17:48:09,629 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:09 2023\n",
      "2023-07-03 17:48:09,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7441\n",
      "2023-07-03 17:48:12,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7461\n",
      "2023-07-03 17:48:13,874 - \u001b[1;33mWARNING\u001b[1;0m - Request 7425 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89713 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:13,881 - \u001b[1;33mWARNING\u001b[1;0m - Request 7445 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89707 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:28,887 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:28 2023\n",
      "2023-07-03 17:48:28,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7479\n",
      "2023-07-03 17:48:29,197 - \u001b[1;33mWARNING\u001b[1;0m - Request 7495 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89886 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:44,211 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:44 2023\n",
      "2023-07-03 17:48:44,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7498\n",
      "2023-07-03 17:48:44,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7518\n",
      "2023-07-03 17:48:44,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 7527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89905 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:44,567 - \u001b[1;33mWARNING\u001b[1;0m - Request 7528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89856 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:48:59,553 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:59 2023\n",
      "2023-07-03 17:48:59,569 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:59 2023\n",
      "2023-07-03 17:48:59,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7536\n",
      "2023-07-03 17:48:59,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7556\n",
      "2023-07-03 17:48:59,824 - \u001b[1;33mWARNING\u001b[1;0m - Request 7557 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89329 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:59,832 - \u001b[1;33mWARNING\u001b[1;0m - Request 7558 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:14,838 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:14 2023\n",
      "2023-07-03 17:49:14,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7574\n",
      "2023-07-03 17:49:16,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7594\n",
      "2023-07-03 17:49:19,373 - \u001b[1;33mWARNING\u001b[1;0m - Request 7570 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89523 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:19,394 - \u001b[1;33mWARNING\u001b[1;0m - Request 7560 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:34,385 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:34 2023\n",
      "2023-07-03 17:49:34,395 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:34 2023\n",
      "2023-07-03 17:49:34,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7612\n",
      "2023-07-03 17:49:34,806 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7632\n",
      "2023-07-03 17:49:34,920 - \u001b[1;33mWARNING\u001b[1;0m - Request 7630 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:34,958 - \u001b[1;33mWARNING\u001b[1;0m - Request 7632 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89267 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:49,933 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:49 2023\n",
      "2023-07-03 17:49:49,959 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:49 2023\n",
      "2023-07-03 17:49:50,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7650\n",
      "2023-07-03 17:49:50,526 - \u001b[1;33mWARNING\u001b[1;0m - Request 7664 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89713 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:05,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:05 2023\n",
      "2023-07-03 17:50:05,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7669\n",
      "2023-07-03 17:50:05,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7689\n",
      "2023-07-03 17:50:05,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 7695 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89760 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:09,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 7080 failed with Exception \n",
      "2023-07-03 17:50:20,799 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:20 2023\n",
      "2023-07-03 17:50:20,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7707\n",
      "2023-07-03 17:50:20,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7727\n",
      "2023-07-03 17:50:21,343 - \u001b[1;33mWARNING\u001b[1;0m - Request 7725 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89521 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:36,357 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:36 2023\n",
      "2023-07-03 17:50:36,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7746\n",
      "2023-07-03 17:50:36,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 7761 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89459 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:36,848 - \u001b[1;33mWARNING\u001b[1;0m - Request 7754 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89985 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:51,715 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:51 2023\n",
      "2023-07-03 17:50:51,850 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:51 2023\n",
      "2023-07-03 17:50:51,861 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7764\n",
      "2023-07-03 17:50:51,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7784\n",
      "2023-07-03 17:50:52,116 - \u001b[1;33mWARNING\u001b[1;0m - Request 7784 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:52,153 - \u001b[1;33mWARNING\u001b[1;0m - Request 7789 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89484 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:01,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 7189 failed with Exception \n",
      "2023-07-03 17:51:07,123 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:07 2023\n",
      "2023-07-03 17:51:07,154 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:07 2023\n",
      "2023-07-03 17:51:07,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7801\n",
      "2023-07-03 17:51:07,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7821\n",
      "2023-07-03 17:51:07,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 7823 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89615 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:07,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 7819 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89318 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:51:17,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 7207 failed with Exception \n",
      "2023-07-03 17:51:22,451 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:22 2023\n",
      "2023-07-03 17:51:22,644 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:22 2023\n",
      "2023-07-03 17:51:22,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7838\n",
      "2023-07-03 17:51:22,921 - \u001b[1;33mWARNING\u001b[1;0m - Request 7853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89524 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:23,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 7854 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89325 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:37,933 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:38 2023\n",
      "2023-07-03 17:51:38,070 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:38 2023\n",
      "2023-07-03 17:51:38,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7856\n",
      "2023-07-03 17:51:38,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7876\n",
      "2023-07-03 17:51:38,351 - \u001b[1;33mWARNING\u001b[1;0m - Request 7877 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89594 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:53,363 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:53 2023\n",
      "2023-07-03 17:51:53,401 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7895\n",
      "2023-07-03 17:51:53,460 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7915\n",
      "2023-07-03 17:51:53,828 - \u001b[1;33mWARNING\u001b[1;0m - Request 7900 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89502 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:53,829 - \u001b[1;33mWARNING\u001b[1;0m - Request 7908 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89467 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:08,843 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:08 2023\n",
      "2023-07-03 17:52:08,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7933\n",
      "2023-07-03 17:52:09,295 - \u001b[1;33mWARNING\u001b[1;0m - Request 7935 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89356 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:24,309 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:24 2023\n",
      "2023-07-03 17:52:24,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7952\n",
      "2023-07-03 17:52:24,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7972\n",
      "2023-07-03 17:52:24,565 - \u001b[1;33mWARNING\u001b[1;0m - Request 7981 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:24,566 - \u001b[1;33mWARNING\u001b[1;0m - Request 7976 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:39,578 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:39 2023\n",
      "2023-07-03 17:52:39,615 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7990\n",
      "2023-07-03 17:52:39,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8010\n",
      "2023-07-03 17:52:40,079 - \u001b[1;33mWARNING\u001b[1;0m - Request 8006 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89420 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:40,164 - \u001b[1;33mWARNING\u001b[1;0m - Request 8014 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:55,081 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:55 2023\n",
      "2023-07-03 17:52:55,165 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:55 2023\n",
      "2023-07-03 17:52:55,218 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8028\n",
      "2023-07-03 17:52:56,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8048\n",
      "2023-07-03 17:52:57,789 - \u001b[1;33mWARNING\u001b[1;0m - Request 8024 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89403 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:12,804 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:12 2023\n",
      "2023-07-03 17:53:12,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8067\n",
      "2023-07-03 17:53:13,130 - \u001b[1;33mWARNING\u001b[1;0m - Request 8063 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89495 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:13,136 - \u001b[1;33mWARNING\u001b[1;0m - Request 8052 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89488 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:28,145 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:28 2023\n",
      "2023-07-03 17:53:28,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8085\n",
      "2023-07-03 17:53:28,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8105\n",
      "2023-07-03 17:53:28,545 - \u001b[1;33mWARNING\u001b[1;0m - Request 8111 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89492 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:43,560 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:43 2023\n",
      "2023-07-03 17:53:43,600 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8124\n",
      "2023-07-03 17:53:43,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8144\n",
      "2023-07-03 17:53:43,851 - \u001b[1;33mWARNING\u001b[1;0m - Request 8147 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89619 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:43,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 8140 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89605 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:53:58,866 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:58 2023\n",
      "2023-07-03 17:53:58,870 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:58 2023\n",
      "2023-07-03 17:53:58,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8162\n",
      "2023-07-03 17:54:00,566 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8182\n",
      "2023-07-03 17:54:04,114 - \u001b[1;33mWARNING\u001b[1;0m - Request 8189 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89477 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:19,130 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:19 2023\n",
      "2023-07-03 17:54:19,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8201\n",
      "2023-07-03 17:54:19,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8221\n",
      "2023-07-03 17:54:19,389 - \u001b[1;33mWARNING\u001b[1;0m - Request 8220 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89724 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:19,402 - \u001b[1;33mWARNING\u001b[1;0m - Request 8217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89701 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:34,400 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:34 2023\n",
      "2023-07-03 17:54:34,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8239\n",
      "2023-07-03 17:54:34,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 7629 failed with Exception \n",
      "2023-07-03 17:54:34,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 8238 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89937 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:34,748 - \u001b[1;33mWARNING\u001b[1;0m - Request 8252 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89811 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:49,679 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:49 2023\n",
      "2023-07-03 17:54:49,749 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:49 2023\n",
      "2023-07-03 17:54:49,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8256\n",
      "2023-07-03 17:54:49,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8276\n",
      "2023-07-03 17:54:49,993 - \u001b[1;33mWARNING\u001b[1;0m - Request 8282 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:49,994 - \u001b[1;33mWARNING\u001b[1;0m - Request 8276 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:04,997 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:04 2023\n",
      "2023-07-03 17:55:05,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8294\n",
      "2023-07-03 17:55:05,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8314\n",
      "2023-07-03 17:55:05,288 - \u001b[1;33mWARNING\u001b[1;0m - Request 8311 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89660 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:20,295 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:20 2023\n",
      "2023-07-03 17:55:20,364 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8333\n",
      "2023-07-03 17:55:20,780 - \u001b[1;33mWARNING\u001b[1;0m - Request 8339 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89592 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:20,784 - \u001b[1;33mWARNING\u001b[1;0m - Request 8344 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:35,796 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:35 2023\n",
      "2023-07-03 17:55:35,812 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8351\n",
      "2023-07-03 17:55:35,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8371\n",
      "2023-07-03 17:55:36,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 8375 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89674 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:36,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 8379 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89444 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:51,135 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:51 2023\n",
      "2023-07-03 17:55:51,264 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:51 2023\n",
      "2023-07-03 17:55:51,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8389\n",
      "2023-07-03 17:55:51,363 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8409\n",
      "2023-07-03 17:55:51,817 - \u001b[1;33mWARNING\u001b[1;0m - Request 8411 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89906 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:06,832 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:06 2023\n",
      "2023-07-03 17:56:06,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8428\n",
      "2023-07-03 17:56:09,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8448\n",
      "2023-07-03 17:56:10,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 8442 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89571 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:10,302 - \u001b[1;33mWARNING\u001b[1;0m - Request 8447 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89561 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:23,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 7845 failed with Exception \n",
      "2023-07-03 17:56:25,299 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:25 2023\n",
      "2023-07-03 17:56:25,302 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:25 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:56:25,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8465\n",
      "2023-07-03 17:56:25,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 8478 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89878 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:40,581 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:40 2023\n",
      "2023-07-03 17:56:40,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8484\n",
      "2023-07-03 17:56:40,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8504\n",
      "2023-07-03 17:56:40,833 - \u001b[1;33mWARNING\u001b[1;0m - Request 8512 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:40,889 - \u001b[1;33mWARNING\u001b[1;0m - Request 8513 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89261 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:55,847 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:55 2023\n",
      "2023-07-03 17:56:55,890 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:55 2023\n",
      "2023-07-03 17:56:55,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8522\n",
      "2023-07-03 17:56:55,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8542\n",
      "2023-07-03 17:56:56,403 - \u001b[1;33mWARNING\u001b[1;0m - Request 8544 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89783 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:56,482 - \u001b[1;33mWARNING\u001b[1;0m - Request 8545 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89683 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:11,417 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:11 2023\n",
      "2023-07-03 17:57:11,484 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:11 2023\n",
      "2023-07-03 17:57:11,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8560\n",
      "2023-07-03 17:57:11,740 - \u001b[1;33mWARNING\u001b[1;0m - Request 8569 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89912 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:26,754 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:26 2023\n",
      "2023-07-03 17:57:26,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8579\n",
      "2023-07-03 17:57:26,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8599\n",
      "2023-07-03 17:57:27,131 - \u001b[1;33mWARNING\u001b[1;0m - Request 8609 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89811 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:27,233 - \u001b[1;33mWARNING\u001b[1;0m - Request 8599 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89658 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:40,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 7992 failed with Exception \n",
      "2023-07-03 17:57:42,134 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:42 2023\n",
      "2023-07-03 17:57:42,235 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:42 2023\n",
      "2023-07-03 17:57:42,268 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8616\n",
      "2023-07-03 17:57:42,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8636\n",
      "2023-07-03 17:57:42,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 8640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89554 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:42,695 - \u001b[1;33mWARNING\u001b[1;0m - Request 8617 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:55,500 - \u001b[1;33mWARNING\u001b[1;0m - Request 8041 failed with Exception \n",
      "2023-07-03 17:57:57,600 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:57 2023\n",
      "2023-07-03 17:57:57,695 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:57 2023\n",
      "2023-07-03 17:57:57,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8653\n",
      "2023-07-03 17:57:58,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8673\n",
      "2023-07-03 17:58:00,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 8653 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:00,452 - \u001b[1;33mWARNING\u001b[1;0m - Request 8676 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:15,458 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:15 2023\n",
      "2023-07-03 17:58:15,513 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8691\n",
      "2023-07-03 17:58:15,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 8704 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89697 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:30,753 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:30 2023\n",
      "2023-07-03 17:58:30,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8710\n",
      "2023-07-03 17:58:30,832 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8730\n",
      "2023-07-03 17:58:32,297 - \u001b[1;33mWARNING\u001b[1;0m - Request 8721 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:32,313 - \u001b[1;33mWARNING\u001b[1;0m - Request 8714 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89351 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:47,312 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:47 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:58:47,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8748\n",
      "2023-07-03 17:58:47,399 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8768\n",
      "2023-07-03 17:58:47,657 - \u001b[1;33mWARNING\u001b[1;0m - Request 8763 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89376 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:47,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 8774 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:01,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 8719 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3021de57adf0c64f84c8e71cd9a4b47d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:02,660 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:02 2023\n",
      "2023-07-03 17:59:02,691 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:02 2023\n",
      "2023-07-03 17:59:02,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8785\n",
      "2023-07-03 17:59:02,991 - \u001b[1;33mWARNING\u001b[1;0m - Request 8804 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89503 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:18,006 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:17 2023\n",
      "2023-07-03 17:59:18,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8805\n",
      "2023-07-03 17:59:18,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8824\n",
      "2023-07-03 17:59:18,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 8822 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89638 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:18,406 - \u001b[1;33mWARNING\u001b[1;0m - Request 8837 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:33,360 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:33 2023\n",
      "2023-07-03 17:59:33,408 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:33 2023\n",
      "2023-07-03 17:59:33,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8842\n",
      "2023-07-03 17:59:33,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8862\n",
      "2023-07-03 17:59:33,872 - \u001b[1;33mWARNING\u001b[1;0m - Request 8862 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:48,885 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:48 2023\n",
      "2023-07-03 17:59:48,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8881\n",
      "2023-07-03 17:59:49,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8901\n",
      "2023-07-03 17:59:49,157 - \u001b[1;33mWARNING\u001b[1;0m - Request 8898 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:49,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 8901 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89604 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:04,170 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:04 2023\n",
      "2023-07-03 18:00:04,204 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:04 2023\n",
      "2023-07-03 18:00:04,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8919\n",
      "2023-07-03 18:00:04,470 - \u001b[1;33mWARNING\u001b[1;0m - Request 8926 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89803 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:19,484 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:19 2023\n",
      "2023-07-03 18:00:19,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8938\n",
      "2023-07-03 18:00:19,600 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8958\n",
      "2023-07-03 18:00:19,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 8943 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89779 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:19,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 8965 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:34,884 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:34 2023\n",
      "2023-07-03 18:00:34,911 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:34 2023\n",
      "2023-07-03 18:00:34,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8976\n",
      "2023-07-03 18:00:35,009 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8996\n",
      "2023-07-03 18:00:35,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 8997 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89473 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:49,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 8935 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6f387c0c758d52e40b57d86e2f529d9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:50,456 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:50 2023\n",
      "2023-07-03 18:00:50,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9014\n",
      "2023-07-03 18:00:50,771 - \u001b[1;33mWARNING\u001b[1;0m - Request 9019 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89667 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:50,785 - \u001b[1;33mWARNING\u001b[1;0m - Request 9018 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:01:05,785 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:05 2023\n",
      "2023-07-03 18:01:05,802 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9032\n",
      "2023-07-03 18:01:05,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9052\n",
      "2023-07-03 18:01:06,075 - \u001b[1;33mWARNING\u001b[1;0m - Request 9036 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89686 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:06,171 - \u001b[1;33mWARNING\u001b[1;0m - Request 9060 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89541 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:21,090 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:21 2023\n",
      "2023-07-03 18:01:21,172 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:21 2023\n",
      "2023-07-03 18:01:21,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9070\n",
      "2023-07-03 18:01:21,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9090\n",
      "2023-07-03 18:01:21,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 9091 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89295 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:36,673 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:36 2023\n",
      "2023-07-03 18:01:36,734 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9109\n",
      "2023-07-03 18:01:36,940 - \u001b[1;33mWARNING\u001b[1;0m - Request 9124 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89524 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:51,954 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:51 2023\n",
      "2023-07-03 18:01:51,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9128\n",
      "2023-07-03 18:01:52,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9148\n",
      "2023-07-03 18:01:53,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 9143 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89514 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:53,297 - \u001b[1;33mWARNING\u001b[1;0m - Request 9159 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:53,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 9144 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89509 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:08,220 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:08 2023\n",
      "2023-07-03 18:02:08,427 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:08 2023\n",
      "2023-07-03 18:02:08,452 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9165\n",
      "2023-07-03 18:02:08,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9185\n",
      "2023-07-03 18:02:09,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 9170 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:24,697 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:24 2023\n",
      "2023-07-03 18:02:24,858 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9204\n",
      "2023-07-03 18:02:24,908 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9224\n",
      "2023-07-03 18:02:26,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 9196 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89451 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:41,057 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:41 2023\n",
      "2023-07-03 18:02:41,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9243\n",
      "2023-07-03 18:02:43,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9263\n",
      "2023-07-03 18:02:46,246 - \u001b[1;33mWARNING\u001b[1;0m - Request 9261 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89474 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:46,779 - \u001b[1;33mWARNING\u001b[1;0m - Request 9266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89400 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:01,261 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:01 2023\n",
      "2023-07-03 18:03:01,781 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:01 2023\n",
      "2023-07-03 18:03:01,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9281\n",
      "2023-07-03 18:03:01,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9301\n",
      "2023-07-03 18:03:06,746 - \u001b[1;33mWARNING\u001b[1;0m - Request 9312 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89841 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:06,796 - \u001b[1;33mWARNING\u001b[1;0m - Request 9306 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89760 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:07,111 - \u001b[1;33mWARNING\u001b[1;0m - Request 9311 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:16,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 8707 failed with Exception \n",
      "2023-07-03 18:03:21,752 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:22 2023\n",
      "2023-07-03 18:03:22,112 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:22 2023\n",
      "2023-07-03 18:03:22,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9317\n",
      "2023-07-03 18:03:22,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9337\n",
      "2023-07-03 18:03:22,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 9328 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89853 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:03:22,772 - \u001b[1;33mWARNING\u001b[1;0m - Request 9343 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89631 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:31,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 8722 failed with Exception \n",
      "2023-07-03 18:03:37,630 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:37 2023\n",
      "2023-07-03 18:03:37,773 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:37 2023\n",
      "2023-07-03 18:03:37,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9354\n",
      "2023-07-03 18:03:38,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9374\n",
      "2023-07-03 18:03:38,329 - \u001b[1;33mWARNING\u001b[1;0m - Request 9374 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89300 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:38,344 - \u001b[1;33mWARNING\u001b[1;0m - Request 9372 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89351 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:53,332 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:53 2023\n",
      "2023-07-03 18:03:53,345 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:53 2023\n",
      "2023-07-03 18:03:53,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9392\n",
      "2023-07-03 18:03:53,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 9406 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89720 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:03,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 8802 failed with Exception \n",
      "2023-07-03 18:04:08,953 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:08 2023\n",
      "2023-07-03 18:04:08,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9410\n",
      "2023-07-03 18:04:09,048 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9430\n",
      "2023-07-03 18:04:09,468 - \u001b[1;33mWARNING\u001b[1;0m - Request 9434 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:09,542 - \u001b[1;33mWARNING\u001b[1;0m - Request 9438 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89455 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:24,477 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:24 2023\n",
      "2023-07-03 18:04:24,543 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:24 2023\n",
      "2023-07-03 18:04:24,582 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9448\n",
      "2023-07-03 18:04:24,640 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9468\n",
      "2023-07-03 18:04:25,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 9469 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89580 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:40,911 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:40 2023\n",
      "2023-07-03 18:04:40,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9487\n",
      "2023-07-03 18:04:41,189 - \u001b[1;33mWARNING\u001b[1;0m - Request 9502 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89705 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:41,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 9504 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89693 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:56,192 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:56 2023\n",
      "2023-07-03 18:04:56,213 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:56 2023\n",
      "2023-07-03 18:04:56,215 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9504\n",
      "2023-07-03 18:04:56,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9525\n",
      "2023-07-03 18:04:58,602 - \u001b[1;33mWARNING\u001b[1;0m - Request 9534 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89499 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:58,617 - \u001b[1;33mWARNING\u001b[1;0m - Request 9535 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89486 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:13,618 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:13 2023\n",
      "2023-07-03 18:05:13,631 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9543\n",
      "2023-07-03 18:05:13,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9563\n",
      "2023-07-03 18:05:13,885 - \u001b[1;33mWARNING\u001b[1;0m - Request 9569 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89589 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:28,900 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:28 2023\n",
      "2023-07-03 18:05:28,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9582\n",
      "2023-07-03 18:05:29,001 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9602\n",
      "2023-07-03 18:05:29,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 9601 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89760 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:29,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 9604 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89644 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:35,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8988 failed with Exception \n",
      "2023-07-03 18:05:44,174 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:44 2023\n",
      "2023-07-03 18:05:44,250 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:44 2023\n",
      "2023-07-03 18:05:44,307 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9619\n",
      "2023-07-03 18:05:46,474 - \u001b[1;33mWARNING\u001b[1;0m - Request 9635 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89764 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:05:51,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 9010 failed with Exception \n",
      "2023-07-03 18:06:01,485 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:01 2023\n",
      "2023-07-03 18:06:01,486 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9639\n",
      "2023-07-03 18:06:01,552 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9657\n",
      "2023-07-03 18:06:01,883 - \u001b[1;33mWARNING\u001b[1;0m - Request 9662 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89716 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:16,897 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:16 2023\n",
      "2023-07-03 18:06:16,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9676\n",
      "2023-07-03 18:06:16,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9696\n",
      "2023-07-03 18:06:17,164 - \u001b[1;33mWARNING\u001b[1;0m - Request 9701 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89866 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:17,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 9699 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89836 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:32,177 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:32 2023\n",
      "2023-07-03 18:06:32,185 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:32 2023\n",
      "2023-07-03 18:06:32,232 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9714\n",
      "2023-07-03 18:06:32,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9734\n",
      "2023-07-03 18:06:32,462 - \u001b[1;33mWARNING\u001b[1;0m - Request 9734 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:47,475 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:47 2023\n",
      "2023-07-03 18:06:47,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9753\n",
      "2023-07-03 18:06:47,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 9759 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89435 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:47,761 - \u001b[1;33mWARNING\u001b[1;0m - Request 9762 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:52,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 9149 failed with Exception \n",
      "2023-07-03 18:07:02,762 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:02 2023\n",
      "2023-07-03 18:07:02,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9770\n",
      "2023-07-03 18:07:02,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9790\n",
      "2023-07-03 18:07:03,021 - \u001b[1;33mWARNING\u001b[1;0m - Request 9796 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89692 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:03,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 9793 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89695 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:18,035 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:18 2023\n",
      "2023-07-03 18:07:18,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9808\n",
      "2023-07-03 18:07:18,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9828\n",
      "2023-07-03 18:07:18,363 - \u001b[1;33mWARNING\u001b[1;0m - Request 9820 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89732 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:18,374 - \u001b[1;33mWARNING\u001b[1;0m - Request 9808 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89715 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:33,378 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:33 2023\n",
      "2023-07-03 18:07:33,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9846\n",
      "2023-07-03 18:07:33,657 - \u001b[1;33mWARNING\u001b[1;0m - Request 9842 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89901 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:48,667 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:48 2023\n",
      "2023-07-03 18:07:48,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9865\n",
      "2023-07-03 18:07:48,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9885\n",
      "2023-07-03 18:07:48,923 - \u001b[1;33mWARNING\u001b[1;0m - Request 9889 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:48,939 - \u001b[1;33mWARNING\u001b[1;0m - Request 9891 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:03,934 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:03 2023\n",
      "2023-07-03 18:08:03,940 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:03 2023\n",
      "2023-07-03 18:08:03,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9903\n",
      "2023-07-03 18:08:04,043 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9923\n",
      "2023-07-03 18:08:04,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 9921 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89554 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:04,254 - \u001b[1;33mWARNING\u001b[1;0m - Request 9914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89484 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:18,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 9870 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6040455e7193256040f69d3ad09af4a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:08:19,215 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:19 2023\n",
      "2023-07-03 18:08:19,254 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:19 2023\n",
      "2023-07-03 18:08:19,317 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9940\n",
      "2023-07-03 18:08:19,767 - \u001b[1;33mWARNING\u001b[1;0m - Request 9950 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89985 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:34,783 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:34 2023\n",
      "2023-07-03 18:08:34,804 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9959\n",
      "2023-07-03 18:08:34,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9979\n",
      "2023-07-03 18:08:38,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 9955 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89654 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:38,796 - \u001b[1;33mWARNING\u001b[1;0m - Request 9958 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89595 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:53,751 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:53 2023\n",
      "2023-07-03 18:08:53,797 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:53 2023\n",
      "2023-07-03 18:08:53,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9997\n",
      "2023-07-03 18:08:53,877 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10017\n",
      "2023-07-03 18:08:58,519 - \u001b[1;33mWARNING\u001b[1;0m - Request 10034 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89518 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:58,604 - \u001b[1;33mWARNING\u001b[1;0m - Request 10035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89390 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:58,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 10036 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89309 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:13,524 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:13 2023\n",
      "2023-07-03 18:09:13,524 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10037\n",
      "2023-07-03 18:09:13,659 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:13 2023\n",
      "2023-07-03 18:09:13,725 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10054\n",
      "2023-07-03 18:09:14,225 - \u001b[1;33mWARNING\u001b[1;0m - Request 10067 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89739 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:29,229 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:29 2023\n",
      "2023-07-03 18:09:29,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10073\n",
      "2023-07-03 18:09:29,307 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10093\n",
      "2023-07-03 18:09:32,537 - \u001b[1;33mWARNING\u001b[1;0m - Request 10101 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89611 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:32,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 10088 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89606 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:47,549 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:47 2023\n",
      "2023-07-03 18:09:47,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10111\n",
      "2023-07-03 18:09:47,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10131\n",
      "2023-07-03 18:09:53,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 10146 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89681 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:53,188 - \u001b[1;33mWARNING\u001b[1;0m - Request 10147 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89683 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:08,195 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:08 2023\n",
      "2023-07-03 18:10:08,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10146\n",
      "2023-07-03 18:10:08,271 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10169\n",
      "2023-07-03 18:10:08,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 10181 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:08,836 - \u001b[1;33mWARNING\u001b[1;0m - Request 10180 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89500 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:23,761 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:23 2023\n",
      "2023-07-03 18:10:23,837 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:23 2023\n",
      "2023-07-03 18:10:23,860 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10187\n",
      "2023-07-03 18:10:23,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10207\n",
      "2023-07-03 18:10:24,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 10212 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89507 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:39,093 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:39 2023\n",
      "2023-07-03 18:10:39,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10226\n",
      "2023-07-03 18:10:39,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10246\n",
      "2023-07-03 18:10:42,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 10217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89551 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:42,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 10238 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:10:57,797 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:57 2023\n",
      "2023-07-03 18:10:57,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10264\n",
      "2023-07-03 18:10:58,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10284\n",
      "2023-07-03 18:11:02,835 - \u001b[1;33mWARNING\u001b[1;0m - Request 10271 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89740 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:02,838 - \u001b[1;33mWARNING\u001b[1;0m - Request 10262 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89736 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:17,849 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:17 2023\n",
      "2023-07-03 18:11:17,884 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10302\n",
      "2023-07-03 18:11:17,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10322\n",
      "2023-07-03 18:11:18,119 - \u001b[1;33mWARNING\u001b[1;0m - Request 10324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:33,135 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:33 2023\n",
      "2023-07-03 18:11:33,192 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10341\n",
      "2023-07-03 18:11:33,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 10358 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89951 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:33,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10349 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89944 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:48,462 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:48 2023\n",
      "2023-07-03 18:11:48,495 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:48 2023\n",
      "2023-07-03 18:11:48,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10349\n",
      "2023-07-03 18:11:48,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10379\n",
      "2023-07-03 18:11:52,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10399\n",
      "2023-07-03 18:11:55,017 - \u001b[1;33mWARNING\u001b[1;0m - Request 10394 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:10,025 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:10 2023\n",
      "2023-07-03 18:12:10,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10418\n",
      "2023-07-03 18:12:10,280 - \u001b[1;33mWARNING\u001b[1;0m - Request 10431 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89527 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:10,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 10430 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:10,295 - \u001b[1;33mWARNING\u001b[1;0m - Request 10425 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89514 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:25,294 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:25 2023\n",
      "2023-07-03 18:12:25,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10430\n",
      "2023-07-03 18:12:25,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10455\n",
      "2023-07-03 18:12:25,738 - \u001b[1;33mWARNING\u001b[1;0m - Request 10466 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89549 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:25,792 - \u001b[1;33mWARNING\u001b[1;0m - Request 10465 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89463 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:33,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 9852 failed with Exception \n",
      "2023-07-03 18:12:33,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 9836 failed with Exception \n",
      "2023-07-03 18:12:40,739 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:40 2023\n",
      "2023-07-03 18:12:40,793 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:40 2023\n",
      "2023-07-03 18:12:40,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10471\n",
      "2023-07-03 18:12:40,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10491\n",
      "2023-07-03 18:12:41,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 10495 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:56,075 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:56 2023\n",
      "2023-07-03 18:12:56,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10510\n",
      "2023-07-03 18:12:56,413 - \u001b[1;33mWARNING\u001b[1;0m - Request 10528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89728 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:56,476 - \u001b[1;33mWARNING\u001b[1;0m - Request 10523 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89804 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:04,500 - \u001b[1;33mWARNING\u001b[1;0m - Request 9900 failed with Exception \n",
      "2023-07-03 18:13:11,421 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:11 2023\n",
      "2023-07-03 18:13:11,477 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:11 2023\n",
      "2023-07-03 18:13:11,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10528\n",
      "2023-07-03 18:13:11,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10547\n",
      "2023-07-03 18:13:11,747 - \u001b[1;33mWARNING\u001b[1;0m - Request 10544 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89834 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:13:26,757 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:26 2023\n",
      "2023-07-03 18:13:26,792 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10566\n",
      "2023-07-03 18:13:26,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10586\n",
      "2023-07-03 18:13:27,143 - \u001b[1;33mWARNING\u001b[1;0m - Request 10591 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89799 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:27,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 10573 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89703 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:35,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 9973 failed with Exception \n",
      "2023-07-03 18:13:35,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 9950 failed with Exception \n",
      "2023-07-03 18:13:42,151 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:42 2023\n",
      "2023-07-03 18:13:42,208 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:42 2023\n",
      "2023-07-03 18:13:42,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10602\n",
      "2023-07-03 18:13:42,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 10618 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89951 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:57,516 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:57 2023\n",
      "2023-07-03 18:13:57,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10618\n",
      "2023-07-03 18:13:57,590 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10641\n",
      "2023-07-03 18:13:57,845 - \u001b[1;33mWARNING\u001b[1;0m - Request 10650 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:57,883 - \u001b[1;33mWARNING\u001b[1;0m - Request 10640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89304 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:12,860 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:12 2023\n",
      "2023-07-03 18:14:12,885 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:12 2023\n",
      "2023-07-03 18:14:12,910 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10659\n",
      "2023-07-03 18:14:12,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10679\n",
      "2023-07-03 18:14:13,584 - \u001b[1;33mWARNING\u001b[1;0m - Request 10678 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:13,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 10675 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89478 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:28,591 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:28 2023\n",
      "2023-07-03 18:14:28,666 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:28 2023\n",
      "2023-07-03 18:14:28,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10697\n",
      "2023-07-03 18:14:28,858 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10717\n",
      "2023-07-03 18:14:29,437 - \u001b[1;33mWARNING\u001b[1;0m - Request 10692 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89535 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:29,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 10718 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:44,452 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:44 2023\n",
      "2023-07-03 18:14:44,466 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:44 2023\n",
      "2023-07-03 18:14:44,523 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10735\n",
      "2023-07-03 18:14:44,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 10748 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89635 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:59,741 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:59 2023\n",
      "2023-07-03 18:14:59,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10754\n",
      "2023-07-03 18:14:59,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10774\n",
      "2023-07-03 18:15:00,216 - \u001b[1;33mWARNING\u001b[1;0m - Request 10782 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89569 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:00,245 - \u001b[1;33mWARNING\u001b[1;0m - Request 10763 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89516 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:15,225 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:15 2023\n",
      "2023-07-03 18:15:15,246 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:15 2023\n",
      "2023-07-03 18:15:15,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10792\n",
      "2023-07-03 18:15:15,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10812\n",
      "2023-07-03 18:15:15,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 10812 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89377 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:15,772 - \u001b[1;33mWARNING\u001b[1;0m - Request 10814 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:24,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 10187 failed with Exception \n",
      "2023-07-03 18:15:30,758 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:30 2023\n",
      "2023-07-03 18:15:30,774 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:30 2023\n",
      "2023-07-03 18:15:30,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10829\n",
      "2023-07-03 18:15:31,361 - \u001b[1;33mWARNING\u001b[1;0m - Request 10845 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89780 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:15:39,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 10237 failed with Exception \n",
      "2023-07-03 18:15:39,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 10224 failed with Exception \n",
      "2023-07-03 18:15:46,369 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:46 2023\n",
      "2023-07-03 18:15:46,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10224\n",
      "2023-07-03 18:15:46,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10866\n",
      "2023-07-03 18:15:46,791 - \u001b[1;33mWARNING\u001b[1;0m - Request 10846 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:01,802 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:01 2023\n",
      "2023-07-03 18:16:01,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10885\n",
      "2023-07-03 18:16:01,902 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10905\n",
      "2023-07-03 18:16:02,225 - \u001b[1;33mWARNING\u001b[1;0m - Request 10900 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89575 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:02,231 - \u001b[1;33mWARNING\u001b[1;0m - Request 10882 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:17,240 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:17 2023\n",
      "2023-07-03 18:16:17,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10923\n",
      "2023-07-03 18:16:17,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 10935 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89632 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:17,594 - \u001b[1;33mWARNING\u001b[1;0m - Request 10940 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:32,555 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:32 2023\n",
      "2023-07-03 18:16:32,595 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:32 2023\n",
      "2023-07-03 18:16:32,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10940\n",
      "2023-07-03 18:16:32,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10961\n",
      "2023-07-03 18:16:32,863 - \u001b[1;33mWARNING\u001b[1;0m - Request 10968 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89838 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:47,877 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:47 2023\n",
      "2023-07-03 18:16:47,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10980\n",
      "2023-07-03 18:16:47,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11000\n",
      "2023-07-03 18:16:50,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 11008 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89799 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:02,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 10961 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 18a3b330a840df5277334fc68a5ee5e9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:05,227 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:05 2023\n",
      "2023-07-03 18:17:05,272 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11018\n",
      "2023-07-03 18:17:05,332 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11038\n",
      "2023-07-03 18:17:07,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 11021 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89937 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:07,436 - \u001b[1;33mWARNING\u001b[1;0m - Request 11018 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89894 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:22,406 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:22 2023\n",
      "2023-07-03 18:17:22,438 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:22 2023\n",
      "2023-07-03 18:17:22,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11056\n",
      "2023-07-03 18:17:23,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11076\n",
      "2023-07-03 18:17:28,106 - \u001b[1;33mWARNING\u001b[1;0m - Request 11078 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89913 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:28,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 11081 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89758 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:28,245 - \u001b[1;33mWARNING\u001b[1;0m - Request 11087 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89709 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:43,122 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:43 2023\n",
      "2023-07-03 18:17:43,247 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:43 2023\n",
      "2023-07-03 18:17:43,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11093\n",
      "2023-07-03 18:17:43,332 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11113\n",
      "2023-07-03 18:17:47,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 11089 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89295 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:56,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 10519 failed with Exception \n",
      "2023-07-03 18:18:02,712 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:02 2023\n",
      "2023-07-03 18:18:02,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11131\n",
      "2023-07-03 18:18:02,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11151\n",
      "2023-07-03 18:18:03,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 11157 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89735 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:03,230 - \u001b[1;33mWARNING\u001b[1;0m - Request 11158 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89727 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:18:18,231 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:18 2023\n",
      "2023-07-03 18:18:18,290 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11169\n",
      "2023-07-03 18:18:18,355 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11189\n",
      "2023-07-03 18:18:18,865 - \u001b[1;33mWARNING\u001b[1;0m - Request 11177 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89330 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:19,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 11162 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89763 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:33,881 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:34 2023\n",
      "2023-07-03 18:18:34,067 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:34 2023\n",
      "2023-07-03 18:18:34,124 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11207\n",
      "2023-07-03 18:18:34,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 11217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:34,580 - \u001b[1;33mWARNING\u001b[1;0m - Request 11222 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89550 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:42,500 - \u001b[1;33mWARNING\u001b[1;0m - Request 10592 failed with Exception \n",
      "2023-07-03 18:18:49,577 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:49 2023\n",
      "2023-07-03 18:18:49,581 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:49 2023\n",
      "2023-07-03 18:18:49,586 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10592\n",
      "2023-07-03 18:18:49,669 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11244\n",
      "2023-07-03 18:18:49,884 - \u001b[1;33mWARNING\u001b[1;0m - Request 11249 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:04,887 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:04 2023\n",
      "2023-07-03 18:19:04,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11263\n",
      "2023-07-03 18:19:04,996 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11283\n",
      "2023-07-03 18:19:05,164 - \u001b[1;33mWARNING\u001b[1;0m - Request 11282 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89812 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:05,238 - \u001b[1;33mWARNING\u001b[1;0m - Request 11286 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:20,166 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:20 2023\n",
      "2023-07-03 18:19:20,239 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:20 2023\n",
      "2023-07-03 18:19:20,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11301\n",
      "2023-07-03 18:19:20,691 - \u001b[1;33mWARNING\u001b[1;0m - Request 11296 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89560 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:20,764 - \u001b[1;33mWARNING\u001b[1;0m - Request 11318 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89449 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:35,701 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:35 2023\n",
      "2023-07-03 18:19:35,765 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:35 2023\n",
      "2023-07-03 18:19:35,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11318\n",
      "2023-07-03 18:19:35,948 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11339\n",
      "2023-07-03 18:19:36,364 - \u001b[1;33mWARNING\u001b[1;0m - Request 11341 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89847 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:44,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 10720 failed with Exception \n",
      "2023-07-03 18:19:51,373 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:51 2023\n",
      "2023-07-03 18:19:51,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11357\n",
      "2023-07-03 18:19:51,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11377\n",
      "2023-07-03 18:19:53,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 11377 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89353 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:53,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 11360 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:08,061 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:08 2023\n",
      "2023-07-03 18:20:08,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11395\n",
      "2023-07-03 18:20:08,163 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11415\n",
      "2023-07-03 18:20:08,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 11414 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89910 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:23,585 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:23 2023\n",
      "2023-07-03 18:20:23,647 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11434\n",
      "2023-07-03 18:20:23,903 - \u001b[1;33mWARNING\u001b[1;0m - Request 11445 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:38,907 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:38 2023\n",
      "2023-07-03 18:20:38,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11453\n",
      "2023-07-03 18:20:38,992 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11473\n",
      "2023-07-03 18:20:39,189 - \u001b[1;33mWARNING\u001b[1;0m - Request 11481 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89499 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:20:39,601 - \u001b[1;33mWARNING\u001b[1;0m - Request 11479 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89602 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:54,005 - \u001b[1;33mWARNING\u001b[1;0m - Request 11441 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ddc1db503d96f0ce545c6e28e0b5825c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:54,190 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:54 2023\n",
      "2023-07-03 18:20:54,603 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:54 2023\n",
      "2023-07-03 18:20:54,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11490\n",
      "2023-07-03 18:20:54,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11510\n",
      "2023-07-03 18:20:55,116 - \u001b[1;33mWARNING\u001b[1;0m - Request 11510 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89415 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:55,120 - \u001b[1;33mWARNING\u001b[1;0m - Request 11500 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89414 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:10,129 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:10 2023\n",
      "2023-07-03 18:21:10,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11528\n",
      "2023-07-03 18:21:11,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 11530 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89925 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:11,236 - \u001b[1;33mWARNING\u001b[1;0m - Request 11546 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89695 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:26,106 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:26 2023\n",
      "2023-07-03 18:21:26,238 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:26 2023\n",
      "2023-07-03 18:21:26,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11530\n",
      "2023-07-03 18:21:26,322 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11566\n",
      "2023-07-03 18:21:26,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 11577 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89878 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:42,001 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:41 2023\n",
      "2023-07-03 18:21:42,031 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11585\n",
      "2023-07-03 18:21:42,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11605\n",
      "2023-07-03 18:21:42,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 11608 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89990 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:42,371 - \u001b[1;33mWARNING\u001b[1;0m - Request 11611 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89849 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:57,281 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:57 2023\n",
      "2023-07-03 18:21:57,372 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:57 2023\n",
      "2023-07-03 18:21:57,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11623\n",
      "2023-07-03 18:21:57,795 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11643\n",
      "2023-07-03 18:21:57,852 - \u001b[1;33mWARNING\u001b[1;0m - Request 11637 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89678 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:57,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 11643 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89512 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:05,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 11020 failed with Exception \n",
      "2023-07-03 18:22:12,853 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:12 2023\n",
      "2023-07-03 18:22:12,963 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:12 2023\n",
      "2023-07-03 18:22:13,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11660\n",
      "2023-07-03 18:22:14,436 - \u001b[1;33mWARNING\u001b[1;0m - Request 11673 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:14,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 11676 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89312 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:29,438 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:29 2023\n",
      "2023-07-03 18:22:29,465 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:29 2023\n",
      "2023-07-03 18:22:29,471 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11678\n",
      "2023-07-03 18:22:29,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11698\n",
      "2023-07-03 18:22:33,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 11686 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89643 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:49,009 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:48 2023\n",
      "2023-07-03 18:22:49,011 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11686\n",
      "2023-07-03 18:22:49,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11737\n",
      "2023-07-03 18:22:49,359 - \u001b[1;33mWARNING\u001b[1;0m - Request 11748 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89665 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:49,391 - \u001b[1;33mWARNING\u001b[1;0m - Request 11749 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89632 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:23:03,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 11138 failed with Exception \n",
      "2023-07-03 18:23:04,360 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:04 2023\n",
      "2023-07-03 18:23:04,392 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:04 2023\n",
      "2023-07-03 18:23:04,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11754\n",
      "2023-07-03 18:23:04,476 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11774\n",
      "2023-07-03 18:23:05,883 - \u001b[1;33mWARNING\u001b[1;0m - Request 11782 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:20,891 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:20 2023\n",
      "2023-07-03 18:23:20,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11793\n",
      "2023-07-03 18:23:20,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11813\n",
      "2023-07-03 18:23:23,378 - \u001b[1;33mWARNING\u001b[1;0m - Request 11819 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:23,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 11797 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89851 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:38,392 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:38 2023\n",
      "2023-07-03 18:23:38,514 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:38 2023\n",
      "2023-07-03 18:23:38,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11831\n",
      "2023-07-03 18:23:38,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11851\n",
      "2023-07-03 18:23:43,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 11824 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:43,846 - \u001b[1;33mWARNING\u001b[1;0m - Request 11848 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89633 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:44,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 11862 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89410 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:51,386 - \u001b[1;33mWARNING\u001b[1;0m - Request 11784 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e286a1fc9f364746b65b6f92d7257535 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:58,854 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:59 2023\n",
      "2023-07-03 18:23:59,009 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:59 2023\n",
      "2023-07-03 18:23:59,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11867\n",
      "2023-07-03 18:23:59,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11887\n",
      "2023-07-03 18:23:59,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 11848 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:14,314 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:14 2023\n",
      "2023-07-03 18:24:14,367 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11906\n",
      "2023-07-03 18:24:15,307 - \u001b[1;33mWARNING\u001b[1;0m - Request 11914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89438 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:30,319 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:30 2023\n",
      "2023-07-03 18:24:30,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11926\n",
      "2023-07-03 18:24:30,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11945\n",
      "2023-07-03 18:24:33,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11965\n",
      "2023-07-03 18:24:35,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 11960 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89775 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:35,275 - \u001b[1;33mWARNING\u001b[1;0m - Request 11968 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89613 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:50,169 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:50 2023\n",
      "2023-07-03 18:24:50,276 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:50 2023\n",
      "2023-07-03 18:24:50,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11983\n",
      "2023-07-03 18:24:51,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12003\n",
      "2023-07-03 18:24:52,628 - \u001b[1;33mWARNING\u001b[1;0m - Request 12000 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:52,639 - \u001b[1;33mWARNING\u001b[1;0m - Request 11991 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89441 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:52,641 - \u001b[1;33mWARNING\u001b[1;0m - Request 11974 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89415 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:07,631 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:07 2023\n",
      "2023-07-03 18:25:07,641 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:07 2023\n",
      "2023-07-03 18:25:07,698 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12020\n",
      "2023-07-03 18:25:08,143 - \u001b[1;33mWARNING\u001b[1;0m - Request 12035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89898 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:23,157 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:23 2023\n",
      "2023-07-03 18:25:23,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:25:23,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12059\n",
      "2023-07-03 18:25:23,661 - \u001b[1;33mWARNING\u001b[1;0m - Request 12066 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89742 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:23,772 - \u001b[1;33mWARNING\u001b[1;0m - Request 12068 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89576 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:38,673 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:38 2023\n",
      "2023-07-03 18:25:38,773 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:38 2023\n",
      "2023-07-03 18:25:38,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12077\n",
      "2023-07-03 18:25:38,868 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12097\n",
      "2023-07-03 18:25:40,539 - \u001b[1;33mWARNING\u001b[1;0m - Request 12098 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89692 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:55,553 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:55 2023\n",
      "2023-07-03 18:25:55,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12116\n",
      "2023-07-03 18:25:56,072 - \u001b[1;33mWARNING\u001b[1;0m - Request 12134 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89500 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:56,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 12128 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89506 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:11,085 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:11 2023\n",
      "2023-07-03 18:26:11,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12136\n",
      "2023-07-03 18:26:11,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12154\n",
      "2023-07-03 18:26:11,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 12163 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89609 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:26,374 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:26 2023\n",
      "2023-07-03 18:26:26,397 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12173\n",
      "2023-07-03 18:26:26,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12193\n",
      "2023-07-03 18:26:26,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11576 failed with Exception \n",
      "2023-07-03 18:26:26,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11572 failed with Exception \n",
      "2023-07-03 18:26:26,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 12195 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89590 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:26,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 12194 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89584 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:41,657 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:41 2023\n",
      "2023-07-03 18:26:41,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12209\n",
      "2023-07-03 18:26:41,873 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12229\n",
      "2023-07-03 18:26:41,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 12219 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89734 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:42,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 12229 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89576 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:56,989 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:57 2023\n",
      "2023-07-03 18:26:57,044 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:57 2023\n",
      "2023-07-03 18:26:57,108 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12247\n",
      "2023-07-03 18:26:57,511 - \u001b[1;33mWARNING\u001b[1;0m - Request 12251 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:57,571 - \u001b[1;33mWARNING\u001b[1;0m - Request 12261 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89313 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:12,525 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:12 2023\n",
      "2023-07-03 18:27:12,572 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:12 2023\n",
      "2023-07-03 18:27:12,587 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12265\n",
      "2023-07-03 18:27:12,647 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12285\n",
      "2023-07-03 18:27:12,890 - \u001b[1;33mWARNING\u001b[1;0m - Request 12291 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89299 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:27,904 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:27 2023\n",
      "2023-07-03 18:27:27,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12304\n",
      "2023-07-03 18:27:28,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12324\n",
      "2023-07-03 18:27:28,272 - \u001b[1;33mWARNING\u001b[1;0m - Request 12325 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:28,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 12324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:43,277 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:43 2023\n",
      "2023-07-03 18:27:43,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:27:43,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 12355 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89764 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:58,814 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:58 2023\n",
      "2023-07-03 18:27:58,828 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12361\n",
      "2023-07-03 18:27:58,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12381\n",
      "2023-07-03 18:27:59,311 - \u001b[1;33mWARNING\u001b[1;0m - Request 12388 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89579 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:59,330 - \u001b[1;33mWARNING\u001b[1;0m - Request 12390 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89566 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:14,325 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:14 2023\n",
      "2023-07-03 18:28:14,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:14 2023\n",
      "2023-07-03 18:28:14,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12399\n",
      "2023-07-03 18:28:14,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12419\n",
      "2023-07-03 18:28:14,788 - \u001b[1;33mWARNING\u001b[1;0m - Request 12409 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89457 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:14,876 - \u001b[1;33mWARNING\u001b[1;0m - Request 12422 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:29,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:29 2023\n",
      "2023-07-03 18:28:29,877 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:29 2023\n",
      "2023-07-03 18:28:29,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12437\n",
      "2023-07-03 18:28:31,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12457\n",
      "2023-07-03 18:28:34,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 12463 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:49,612 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:49 2023\n",
      "2023-07-03 18:28:49,663 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12476\n",
      "2023-07-03 18:28:49,967 - \u001b[1;33mWARNING\u001b[1;0m - Request 12495 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:49,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 12491 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89358 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:04,981 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:04 2023\n",
      "2023-07-03 18:29:04,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12496\n",
      "2023-07-03 18:29:05,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12514\n",
      "2023-07-03 18:29:05,322 - \u001b[1;33mWARNING\u001b[1;0m - Request 12525 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89508 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:05,333 - \u001b[1;33mWARNING\u001b[1;0m - Request 12527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89454 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:20,337 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:20 2023\n",
      "2023-07-03 18:29:20,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12532\n",
      "2023-07-03 18:29:20,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12552\n",
      "2023-07-03 18:29:20,839 - \u001b[1;33mWARNING\u001b[1;0m - Request 12556 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89285 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:30,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 11949 failed with Exception \n",
      "2023-07-03 18:29:35,846 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:35 2023\n",
      "2023-07-03 18:29:35,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12570\n",
      "2023-07-03 18:29:35,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12590\n",
      "2023-07-03 18:29:36,133 - \u001b[1;33mWARNING\u001b[1;0m - Request 12589 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89407 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:36,139 - \u001b[1;33mWARNING\u001b[1;0m - Request 12590 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:51,145 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:51 2023\n",
      "2023-07-03 18:29:51,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12608\n",
      "2023-07-03 18:29:51,475 - \u001b[1;33mWARNING\u001b[1;0m - Request 12606 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:06,486 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:06 2023\n",
      "2023-07-03 18:30:06,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12627\n",
      "2023-07-03 18:30:06,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12647\n",
      "2023-07-03 18:30:07,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 12652 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89925 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:07,159 - \u001b[1;33mWARNING\u001b[1;0m - Request 12655 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89673 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:30:22,014 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:22 2023\n",
      "2023-07-03 18:30:22,160 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:22 2023\n",
      "2023-07-03 18:30:22,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12665\n",
      "2023-07-03 18:30:22,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12685\n",
      "2023-07-03 18:30:22,636 - \u001b[1;33mWARNING\u001b[1;0m - Request 12681 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89527 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:37,651 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:37 2023\n",
      "2023-07-03 18:30:37,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12704\n",
      "2023-07-03 18:30:37,979 - \u001b[1;33mWARNING\u001b[1;0m - Request 12709 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89604 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:38,103 - \u001b[1;33mWARNING\u001b[1;0m - Request 12681 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:52,992 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:53 2023\n",
      "2023-07-03 18:30:53,105 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:53 2023\n",
      "2023-07-03 18:30:53,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12722\n",
      "2023-07-03 18:30:53,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12742\n",
      "2023-07-03 18:30:53,461 - \u001b[1;33mWARNING\u001b[1;0m - Request 12751 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89529 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:53,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 12740 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:08,476 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:08 2023\n",
      "2023-07-03 18:31:08,573 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:08 2023\n",
      "2023-07-03 18:31:08,609 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12760\n",
      "2023-07-03 18:31:08,666 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12780\n",
      "2023-07-03 18:31:10,276 - \u001b[1;33mWARNING\u001b[1;0m - Request 12780 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89491 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:10,416 - \u001b[1;33mWARNING\u001b[1;0m - Request 12786 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:25,290 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:25 2023\n",
      "2023-07-03 18:31:25,417 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:25 2023\n",
      "2023-07-03 18:31:25,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12798\n",
      "2023-07-03 18:31:25,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12818\n",
      "2023-07-03 18:31:25,967 - \u001b[1;33mWARNING\u001b[1;0m - Request 12818 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89752 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:40,980 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:40 2023\n",
      "2023-07-03 18:31:41,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12837\n",
      "2023-07-03 18:31:41,479 - \u001b[1;33mWARNING\u001b[1;0m - Request 12839 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89625 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:41,547 - \u001b[1;33mWARNING\u001b[1;0m - Request 12851 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:56 2023\n",
      "2023-07-03 18:31:56,548 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:56 2023\n",
      "2023-07-03 18:31:56,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12855\n",
      "2023-07-03 18:31:56,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12875\n",
      "2023-07-03 18:31:57,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 12880 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:12,086 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:12 2023\n",
      "2023-07-03 18:32:12,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12894\n",
      "2023-07-03 18:32:12,187 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12914\n",
      "2023-07-03 18:32:13,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12285 failed with Exception \n",
      "2023-07-03 18:32:14,390 - \u001b[1;33mWARNING\u001b[1;0m - Request 12902 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89970 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:14,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 12285 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89762 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:29,398 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:29 2023\n",
      "2023-07-03 18:32:29,534 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:29 2023\n",
      "2023-07-03 18:32:29,578 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12931\n",
      "2023-07-03 18:32:29,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12951\n",
      "2023-07-03 18:32:32,086 - \u001b[1;33mWARNING\u001b[1;0m - Request 12936 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89411 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:32,100 - \u001b[1;33mWARNING\u001b[1;0m - Request 12285 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89435 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:32:47,100 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:47 2023\n",
      "2023-07-03 18:32:47,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12969\n",
      "2023-07-03 18:32:47,467 - \u001b[1;33mWARNING\u001b[1;0m - Request 12985 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:47,482 - \u001b[1;33mWARNING\u001b[1;0m - Request 12987 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89315 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:02,479 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:02 2023\n",
      "2023-07-03 18:33:02,482 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:02 2023\n",
      "2023-07-03 18:33:02,483 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12985\n",
      "2023-07-03 18:33:02,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13007\n",
      "2023-07-03 18:33:03,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 13019 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89706 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:18,058 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:18 2023\n",
      "2023-07-03 18:33:18,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13026\n",
      "2023-07-03 18:33:18,160 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13046\n",
      "2023-07-03 18:33:19,456 - \u001b[1;33mWARNING\u001b[1;0m - Request 13035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89710 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:34,470 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:34 2023\n",
      "2023-07-03 18:33:34,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13065\n",
      "2023-07-03 18:33:34,566 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13085\n",
      "2023-07-03 18:33:35,095 - \u001b[1;33mWARNING\u001b[1;0m - Request 13062 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:35,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 13075 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89335 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:50,110 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:50 2023\n",
      "2023-07-03 18:33:50,168 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:50 2023\n",
      "2023-07-03 18:33:50,223 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13103\n",
      "2023-07-03 18:33:50,885 - \u001b[1;33mWARNING\u001b[1;0m - Request 13117 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:50,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 13118 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89414 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:05,900 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:05 2023\n",
      "2023-07-03 18:34:05,967 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:05 2023\n",
      "2023-07-03 18:34:05,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13121\n",
      "2023-07-03 18:34:06,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13141\n",
      "2023-07-03 18:34:07,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 13142 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89664 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:07,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 13154 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89514 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:22,727 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:22 2023\n",
      "2023-07-03 18:34:22,798 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:22 2023\n",
      "2023-07-03 18:34:22,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13159\n",
      "2023-07-03 18:34:22,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13179\n",
      "2023-07-03 18:34:28,047 - \u001b[1;33mWARNING\u001b[1;0m - Request 13167 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89464 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:28,065 - \u001b[1;33mWARNING\u001b[1;0m - Request 13195 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89440 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:43,061 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:43 2023\n",
      "2023-07-03 18:34:43,066 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:43 2023\n",
      "2023-07-03 18:34:43,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13195\n",
      "2023-07-03 18:34:43,136 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13217\n",
      "2023-07-03 18:34:43,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 13228 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89268 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:58,543 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:58 2023\n",
      "2023-07-03 18:34:58,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13236\n",
      "2023-07-03 18:34:58,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13256\n",
      "2023-07-03 18:34:58,932 - \u001b[1;33mWARNING\u001b[1;0m - Request 13259 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89289 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:13,945 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:13 2023\n",
      "2023-07-03 18:35:13,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13275\n",
      "2023-07-03 18:35:14,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13295\n",
      "2023-07-03 18:35:18,849 - \u001b[1;33mWARNING\u001b[1;0m - Request 13296 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:35:33,861 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:33 2023\n",
      "2023-07-03 18:35:33,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13314\n",
      "2023-07-03 18:35:34,056 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13334\n",
      "2023-07-03 18:35:34,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 13333 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89902 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:34,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 13330 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89852 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:34,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 13335 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89806 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:49,629 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:49 2023\n",
      "2023-07-03 18:35:49,688 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:49 2023\n",
      "2023-07-03 18:35:49,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13351\n",
      "2023-07-03 18:35:50,160 - \u001b[1;33mWARNING\u001b[1;0m - Request 13364 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89680 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:50,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 13365 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:05,163 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:05 2023\n",
      "2023-07-03 18:36:05,184 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:05 2023\n",
      "2023-07-03 18:36:05,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13369\n",
      "2023-07-03 18:36:05,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13389\n",
      "2023-07-03 18:36:09,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 13381 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89498 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:09,524 - \u001b[1;33mWARNING\u001b[1;0m - Request 13383 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89499 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:24,500 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:24 2023\n",
      "2023-07-03 18:36:24,525 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:24 2023\n",
      "2023-07-03 18:36:24,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13381\n",
      "2023-07-03 18:36:24,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13427\n",
      "2023-07-03 18:36:25,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 13423 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89888 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:40,232 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:40 2023\n",
      "2023-07-03 18:36:40,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13446\n",
      "2023-07-03 18:36:40,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13466\n",
      "2023-07-03 18:36:40,915 - \u001b[1;33mWARNING\u001b[1;0m - Request 13461 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:40,954 - \u001b[1;33mWARNING\u001b[1;0m - Request 13469 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89426 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:40,976 - \u001b[1;33mWARNING\u001b[1;0m - Request 13473 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:41,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12844 failed with Exception \n",
      "2023-07-03 18:36:55,921 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:55 2023\n",
      "2023-07-03 18:36:55,977 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:55 2023\n",
      "2023-07-03 18:36:56,018 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13482\n",
      "2023-07-03 18:36:56,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13502\n",
      "2023-07-03 18:36:56,681 - \u001b[1;33mWARNING\u001b[1;0m - Request 13503 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89642 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12876 failed with Exception \n",
      "2023-07-03 18:37:11,683 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:11 2023\n",
      "2023-07-03 18:37:11,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13520\n",
      "2023-07-03 18:37:14,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13540\n",
      "2023-07-03 18:37:15,387 - \u001b[1;33mWARNING\u001b[1;0m - Request 13542 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89752 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:15,553 - \u001b[1;33mWARNING\u001b[1;0m - Request 13504 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89503 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:30,402 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:30 2023\n",
      "2023-07-03 18:37:30,553 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:30 2023\n",
      "2023-07-03 18:37:30,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13558\n",
      "2023-07-03 18:37:30,988 - \u001b[1;33mWARNING\u001b[1;0m - Request 13574 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:44,785 - \u001b[1;33mWARNING\u001b[1;0m - Request 13534 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a74b6b152d45fe5c5a503b51d37afd62 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:37:45,991 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:45 2023\n",
      "2023-07-03 18:37:45,998 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13576\n",
      "2023-07-03 18:37:46,063 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13596\n",
      "2023-07-03 18:37:46,341 - \u001b[1;33mWARNING\u001b[1;0m - Request 13600 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89606 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:46,365 - \u001b[1;33mWARNING\u001b[1;0m - Request 13605 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89588 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:01,356 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:01 2023\n",
      "2023-07-03 18:38:01,365 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:01 2023\n",
      "2023-07-03 18:38:01,401 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13614\n",
      "2023-07-03 18:38:01,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13634\n",
      "2023-07-03 18:38:05,094 - \u001b[1;33mWARNING\u001b[1;0m - Request 13644 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89666 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:20,109 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:20 2023\n",
      "2023-07-03 18:38:20,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13653\n",
      "2023-07-03 18:38:20,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13673\n",
      "2023-07-03 18:38:21,041 - \u001b[1;33mWARNING\u001b[1;0m - Request 13678 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89517 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:36,045 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:36 2023\n",
      "2023-07-03 18:38:36,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13692\n",
      "2023-07-03 18:38:36,383 - \u001b[1;33mWARNING\u001b[1;0m - Request 13699 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89649 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:36,395 - \u001b[1;33mWARNING\u001b[1;0m - Request 13703 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89627 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:36,402 - \u001b[1;33mWARNING\u001b[1;0m - Request 13708 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89618 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:51,398 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:51 2023\n",
      "2023-07-03 18:38:51,403 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:51 2023\n",
      "2023-07-03 18:38:51,404 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13699\n",
      "2023-07-03 18:38:51,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13729\n",
      "2023-07-03 18:38:53,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 13714 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:54,055 - \u001b[1;33mWARNING\u001b[1;0m - Request 13746 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89859 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:08,977 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:09 2023\n",
      "2023-07-03 18:39:09,056 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:09 2023\n",
      "2023-07-03 18:39:09,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13746\n",
      "2023-07-03 18:39:09,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13767\n",
      "2023-07-03 18:39:09,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 13770 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89849 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:24,445 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:24 2023\n",
      "2023-07-03 18:39:24,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13786\n",
      "2023-07-03 18:39:24,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13806\n",
      "2023-07-03 18:39:24,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 13799 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89946 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:24,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 13795 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89793 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:39,809 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:39 2023\n",
      "2023-07-03 18:39:39,899 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:39 2023\n",
      "2023-07-03 18:39:39,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13824\n",
      "2023-07-03 18:39:40,313 - \u001b[1;33mWARNING\u001b[1;0m - Request 13842 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89672 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:40,353 - \u001b[1;33mWARNING\u001b[1;0m - Request 13819 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:55,321 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:55 2023\n",
      "2023-07-03 18:39:55,353 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:55 2023\n",
      "2023-07-03 18:39:55,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13842\n",
      "2023-07-03 18:39:55,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13862\n",
      "2023-07-03 18:39:55,829 - \u001b[1;33mWARNING\u001b[1;0m - Request 13860 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89594 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:40:10,844 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:10 2023\n",
      "2023-07-03 18:40:10,873 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13881\n",
      "2023-07-03 18:40:10,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13901\n",
      "2023-07-03 18:40:11,516 - \u001b[1;33mWARNING\u001b[1;0m - Request 13907 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89771 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:11,633 - \u001b[1;33mWARNING\u001b[1;0m - Request 13893 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89590 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:26,530 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:26 2023\n",
      "2023-07-03 18:40:26,634 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:26 2023\n",
      "2023-07-03 18:40:26,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13919\n",
      "2023-07-03 18:40:26,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13939\n",
      "2023-07-03 18:40:27,110 - \u001b[1;33mWARNING\u001b[1;0m - Request 13936 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:27,191 - \u001b[1;33mWARNING\u001b[1;0m - Request 13939 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89313 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:42,125 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:42 2023\n",
      "2023-07-03 18:40:42,192 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:42 2023\n",
      "2023-07-03 18:40:42,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13957\n",
      "2023-07-03 18:40:42,624 - \u001b[1;33mWARNING\u001b[1;0m - Request 13971 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89868 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:57,639 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:57 2023\n",
      "2023-07-03 18:40:57,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13976\n",
      "2023-07-03 18:40:57,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13996\n",
      "2023-07-03 18:40:58,015 - \u001b[1;33mWARNING\u001b[1;0m - Request 14002 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89935 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:13,030 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:13 2023\n",
      "2023-07-03 18:41:13,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14015\n",
      "2023-07-03 18:41:13,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14035\n",
      "2023-07-03 18:41:13,514 - \u001b[1;33mWARNING\u001b[1;0m - Request 14034 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89691 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:13,520 - \u001b[1;33mWARNING\u001b[1;0m - Request 14035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89685 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:28,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:28 2023\n",
      "2023-07-03 18:41:28,588 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14053\n",
      "2023-07-03 18:41:31,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14073\n",
      "2023-07-03 18:41:31,041 - \u001b[1;33mWARNING\u001b[1;0m - Request 14057 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:31,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 14038 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89385 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:46,053 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:46 2023\n",
      "2023-07-03 18:41:46,063 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:46 2023\n",
      "2023-07-03 18:41:46,124 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14091\n",
      "2023-07-03 18:41:47,226 - \u001b[1;33mWARNING\u001b[1;0m - Request 14106 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89644 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:02,241 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:02 2023\n",
      "2023-07-03 18:42:02,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14110\n",
      "2023-07-03 18:42:02,322 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14130\n",
      "2023-07-03 18:42:02,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 14130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89553 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:02,728 - \u001b[1;33mWARNING\u001b[1;0m - Request 14135 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89540 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:02,829 - \u001b[1;33mWARNING\u001b[1;0m - Request 14139 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:17,735 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:17 2023\n",
      "2023-07-03 18:42:17,830 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:17 2023\n",
      "2023-07-03 18:42:17,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14147\n",
      "2023-07-03 18:42:17,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14167\n",
      "2023-07-03 18:42:18,549 - \u001b[1;33mWARNING\u001b[1;0m - Request 14168 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89654 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:33,564 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:33 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:42:33,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14186\n",
      "2023-07-03 18:42:33,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 14199 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89652 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:34,007 - \u001b[1;33mWARNING\u001b[1;0m - Request 14203 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89496 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:48,944 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:49 2023\n",
      "2023-07-03 18:42:49,008 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:49 2023\n",
      "2023-07-03 18:42:49,010 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14203\n",
      "2023-07-03 18:42:49,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14224\n",
      "2023-07-03 18:42:49,698 - \u001b[1;33mWARNING\u001b[1;0m - Request 14223 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89750 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:04,712 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:04 2023\n",
      "2023-07-03 18:43:04,860 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14243\n",
      "2023-07-03 18:43:04,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14263\n",
      "2023-07-03 18:43:05,299 - \u001b[1;33mWARNING\u001b[1;0m - Request 14257 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89341 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:05,302 - \u001b[1;33mWARNING\u001b[1;0m - Request 14262 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:20,314 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:20 2023\n",
      "2023-07-03 18:43:20,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14281\n",
      "2023-07-03 18:43:20,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 14298 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89399 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:35,700 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:35 2023\n",
      "2023-07-03 18:43:35,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14301\n",
      "2023-07-03 18:43:35,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14320\n",
      "2023-07-03 18:43:36,341 - \u001b[1;33mWARNING\u001b[1;0m - Request 14312 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89638 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:36,391 - \u001b[1;33mWARNING\u001b[1;0m - Request 14330 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89562 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:51,356 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:51 2023\n",
      "2023-07-03 18:43:51,392 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:51 2023\n",
      "2023-07-03 18:43:51,410 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14338\n",
      "2023-07-03 18:43:51,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14358\n",
      "2023-07-03 18:43:51,782 - \u001b[1;33mWARNING\u001b[1;0m - Request 14354 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89674 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:51,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 14365 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:06,797 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:06 2023\n",
      "2023-07-03 18:44:06,973 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:06 2023\n",
      "2023-07-03 18:44:07,014 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14376\n",
      "2023-07-03 18:44:07,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14396\n",
      "2023-07-03 18:44:07,333 - \u001b[1;33mWARNING\u001b[1;0m - Request 14396 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:22,347 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:22 2023\n",
      "2023-07-03 18:44:22,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14415\n",
      "2023-07-03 18:44:22,683 - \u001b[1;33mWARNING\u001b[1;0m - Request 14417 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89578 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:22,698 - \u001b[1;33mWARNING\u001b[1;0m - Request 14422 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89551 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:24,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 13787 failed with Exception \n",
      "2023-07-03 18:44:37,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:37 2023\n",
      "2023-07-03 18:44:37,700 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:37 2023\n",
      "2023-07-03 18:44:37,714 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14432\n",
      "2023-07-03 18:44:37,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14452\n",
      "2023-07-03 18:44:39,584 - \u001b[1;33mWARNING\u001b[1;0m - Request 14446 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89353 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:54,599 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:54 2023\n",
      "2023-07-03 18:44:54,631 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14471\n",
      "2023-07-03 18:44:54,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14491\n",
      "2023-07-03 18:44:58,013 - \u001b[1;33mWARNING\u001b[1;0m - Request 14473 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89259 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:44:58,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 14502 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89949 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:11,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 13885 failed with Exception \n",
      "2023-07-03 18:45:13,016 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:13 2023\n",
      "2023-07-03 18:45:13,058 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:13 2023\n",
      "2023-07-03 18:45:13,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14508\n",
      "2023-07-03 18:45:13,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14528\n",
      "2023-07-03 18:45:13,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 14531 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89825 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:13,561 - \u001b[1;33mWARNING\u001b[1;0m - Request 14533 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89802 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:28,549 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:28 2023\n",
      "2023-07-03 18:45:28,562 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:28 2023\n",
      "2023-07-03 18:45:28,598 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14546\n",
      "2023-07-03 18:45:29,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14566\n",
      "2023-07-03 18:45:33,056 - \u001b[1;33mWARNING\u001b[1;0m - Request 14573 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:48,072 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:48 2023\n",
      "2023-07-03 18:45:48,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14585\n",
      "2023-07-03 18:45:48,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14605\n",
      "2023-07-03 18:45:48,347 - \u001b[1;33mWARNING\u001b[1;0m - Request 14600 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:48,427 - \u001b[1;33mWARNING\u001b[1;0m - Request 14601 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:48,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 14606 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89454 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:03,357 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:03 2023\n",
      "2023-07-03 18:46:03,443 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:03 2023\n",
      "2023-07-03 18:46:03,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14622\n",
      "2023-07-03 18:46:03,767 - \u001b[1;33mWARNING\u001b[1;0m - Request 14632 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89619 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:18,781 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:18 2023\n",
      "2023-07-03 18:46:18,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14641\n",
      "2023-07-03 18:46:18,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14661\n",
      "2023-07-03 18:46:23,096 - \u001b[1;33mWARNING\u001b[1;0m - Request 14668 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89506 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:23,204 - \u001b[1;33mWARNING\u001b[1;0m - Request 14669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89339 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:30,500 - \u001b[1;33mWARNING\u001b[1;0m - Request 14070 failed with Exception \n",
      "2023-07-03 18:46:38,105 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:38 2023\n",
      "2023-07-03 18:46:38,206 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:38 2023\n",
      "2023-07-03 18:46:38,209 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14070\n",
      "2023-07-03 18:46:38,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14698\n",
      "2023-07-03 18:46:38,633 - \u001b[1;33mWARNING\u001b[1;0m - Request 14684 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89301 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:38,635 - \u001b[1;33mWARNING\u001b[1;0m - Request 14693 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:53,647 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:53 2023\n",
      "2023-07-03 18:46:53,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14716\n",
      "2023-07-03 18:46:53,741 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14736\n",
      "2023-07-03 18:46:54,555 - \u001b[1;33mWARNING\u001b[1;0m - Request 14740 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89952 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:09,565 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:09 2023\n",
      "2023-07-03 18:47:09,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14755\n",
      "2023-07-03 18:47:10,020 - \u001b[1;33mWARNING\u001b[1;0m - Request 14752 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:10,033 - \u001b[1;33mWARNING\u001b[1;0m - Request 14774 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89768 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:18,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 14149 failed with Exception \n",
      "2023-07-03 18:47:25,025 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:25 2023\n",
      "2023-07-03 18:47:25,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:47:25,034 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:25 2023\n",
      "2023-07-03 18:47:25,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14792\n",
      "2023-07-03 18:47:28,696 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14812\n",
      "2023-07-03 18:47:30,236 - \u001b[1;33mWARNING\u001b[1;0m - Request 14815 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89834 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:30,388 - \u001b[1;33mWARNING\u001b[1;0m - Request 14812 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89610 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:40,103 - \u001b[1;33mWARNING\u001b[1;0m - Request 14745 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4a46a0f9af32eb1cc16e174f291c21b8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:45,243 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:45 2023\n",
      "2023-07-03 18:47:45,389 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:45 2023\n",
      "2023-07-03 18:47:45,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14829\n",
      "2023-07-03 18:47:45,816 - \u001b[1;33mWARNING\u001b[1;0m - Request 14821 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89531 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:45,870 - \u001b[1;33mWARNING\u001b[1;0m - Request 14844 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:00,830 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:00 2023\n",
      "2023-07-03 18:48:00,870 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:00 2023\n",
      "2023-07-03 18:48:00,872 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14844\n",
      "2023-07-03 18:48:00,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14867\n",
      "2023-07-03 18:48:01,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 14853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89425 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:16,314 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:16 2023\n",
      "2023-07-03 18:48:16,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14886\n",
      "2023-07-03 18:48:16,410 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14906\n",
      "2023-07-03 18:48:16,568 - \u001b[1;33mWARNING\u001b[1;0m - Request 14910 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89551 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:16,569 - \u001b[1;33mWARNING\u001b[1;0m - Request 14908 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89547 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:20,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 14293 failed with Exception \n",
      "2023-07-03 18:48:31,580 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:31 2023\n",
      "2023-07-03 18:48:31,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14923\n",
      "2023-07-03 18:48:32,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 14930 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89444 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:32,075 - \u001b[1;33mWARNING\u001b[1;0m - Request 14941 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:36,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 14311 failed with Exception \n",
      "2023-07-03 18:48:47,063 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:47 2023\n",
      "2023-07-03 18:48:47,078 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:47 2023\n",
      "2023-07-03 18:48:47,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14930\n",
      "2023-07-03 18:48:47,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14960\n",
      "2023-07-03 18:48:47,618 - \u001b[1;33mWARNING\u001b[1;0m - Request 14972 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89865 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:02,633 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:02 2023\n",
      "2023-07-03 18:49:02,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14979\n",
      "2023-07-03 18:49:02,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14999\n",
      "2023-07-03 18:49:03,130 - \u001b[1;33mWARNING\u001b[1;0m - Request 15001 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89708 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:03,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 15005 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89568 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:18,141 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:18 2023\n",
      "2023-07-03 18:49:18,213 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:18 2023\n",
      "2023-07-03 18:49:18,260 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15017\n",
      "2023-07-03 18:49:18,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 15032 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89810 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:33,513 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:33 2023\n",
      "2023-07-03 18:49:33,513 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15037\n",
      "2023-07-03 18:49:33,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15056\n",
      "2023-07-03 18:49:33,821 - \u001b[1;33mWARNING\u001b[1;0m - Request 15068 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89942 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:49:33,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 15069 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89722 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:48,833 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:48 2023\n",
      "2023-07-03 18:49:48,953 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:48 2023\n",
      "2023-07-03 18:49:48,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15074\n",
      "2023-07-03 18:49:49,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15094\n",
      "2023-07-03 18:49:49,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 15093 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89799 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:04,267 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:04 2023\n",
      "2023-07-03 18:50:04,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15113\n",
      "2023-07-03 18:50:04,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15133\n",
      "2023-07-03 18:50:04,773 - \u001b[1;33mWARNING\u001b[1;0m - Request 15130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89472 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:04,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 15131 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:19,775 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:19 2023\n",
      "2023-07-03 18:50:19,800 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:19 2023\n",
      "2023-07-03 18:50:19,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15151\n",
      "2023-07-03 18:50:22,714 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15171\n",
      "2023-07-03 18:50:22,871 - \u001b[1;33mWARNING\u001b[1;0m - Request 15171 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89750 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:22,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 15155 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89551 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:37,882 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:37 2023\n",
      "2023-07-03 18:50:37,998 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:37 2023\n",
      "2023-07-03 18:50:38,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15189\n",
      "2023-07-03 18:50:41,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15209\n",
      "2023-07-03 18:50:42,939 - \u001b[1;33mWARNING\u001b[1;0m - Request 15200 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:43,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 15213 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89822 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:48,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 14576 failed with Exception \n",
      "2023-07-03 18:50:57,949 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:58 2023\n",
      "2023-07-03 18:50:58,041 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:58 2023\n",
      "2023-07-03 18:50:58,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15226\n",
      "2023-07-03 18:50:58,293 - \u001b[1;33mWARNING\u001b[1;0m - Request 15243 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:58,305 - \u001b[1;33mWARNING\u001b[1;0m - Request 15241 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89373 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:13,305 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:13 2023\n",
      "2023-07-03 18:51:13,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15241\n",
      "2023-07-03 18:51:13,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15264\n",
      "2023-07-03 18:51:13,555 - \u001b[1;33mWARNING\u001b[1;0m - Request 15269 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89584 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:19,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 14654 failed with Exception \n",
      "2023-07-03 18:51:28,565 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:28 2023\n",
      "2023-07-03 18:51:28,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15282\n",
      "2023-07-03 18:51:28,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15302\n",
      "2023-07-03 18:51:28,944 - \u001b[1;33mWARNING\u001b[1;0m - Request 15306 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:38,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 14694 failed with Exception \n",
      "2023-07-03 18:51:43,950 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:43 2023\n",
      "2023-07-03 18:51:44,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15320\n",
      "2023-07-03 18:51:44,230 - \u001b[1;33mWARNING\u001b[1;0m - Request 15333 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89634 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:44,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 15328 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89604 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:44,375 - \u001b[1;33mWARNING\u001b[1;0m - Request 15338 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89410 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:59,244 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:59 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:51:59,377 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:59 2023\n",
      "2023-07-03 18:51:59,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15333\n",
      "2023-07-03 18:51:59,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15357\n",
      "2023-07-03 18:51:59,632 - \u001b[1;33mWARNING\u001b[1;0m - Request 15367 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89505 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:14,646 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:14 2023\n",
      "2023-07-03 18:52:14,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15376\n",
      "2023-07-03 18:52:14,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15396\n",
      "2023-07-03 18:52:17,247 - \u001b[1;33mWARNING\u001b[1;0m - Request 15405 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89728 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:17,291 - \u001b[1;33mWARNING\u001b[1;0m - Request 15406 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89667 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:32,253 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:32 2023\n",
      "2023-07-03 18:52:32,292 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:32 2023\n",
      "2023-07-03 18:52:32,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15414\n",
      "2023-07-03 18:52:32,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15434\n",
      "2023-07-03 18:52:32,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 15437 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89423 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:47,805 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:47 2023\n",
      "2023-07-03 18:52:47,862 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15453\n",
      "2023-07-03 18:52:48,313 - \u001b[1;33mWARNING\u001b[1;0m - Request 15466 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89877 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:48,364 - \u001b[1;33mWARNING\u001b[1;0m - Request 15471 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89807 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:03,325 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:03 2023\n",
      "2023-07-03 18:53:03,366 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:03 2023\n",
      "2023-07-03 18:53:03,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15466\n",
      "2023-07-03 18:53:03,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15491\n",
      "2023-07-03 18:53:03,641 - \u001b[1;33mWARNING\u001b[1;0m - Request 15493 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89278 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:18,655 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:18 2023\n",
      "2023-07-03 18:53:18,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15510\n",
      "2023-07-03 18:53:18,744 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15530\n",
      "2023-07-03 18:53:19,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 15493 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:19,190 - \u001b[1;33mWARNING\u001b[1;0m - Request 15532 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89686 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:34,181 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:34 2023\n",
      "2023-07-03 18:53:34,190 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:34 2023\n",
      "2023-07-03 18:53:34,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15548\n",
      "2023-07-03 18:53:34,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 15545 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89654 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:49,625 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:49 2023\n",
      "2023-07-03 18:53:49,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15568\n",
      "2023-07-03 18:53:49,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15587\n",
      "2023-07-03 18:53:49,878 - \u001b[1;33mWARNING\u001b[1;0m - Request 15595 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89765 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:49,889 - \u001b[1;33mWARNING\u001b[1;0m - Request 15598 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89750 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:04,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 15549 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d2adc02868c9f0c878479653669ea0ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:04,879 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:04 2023\n",
      "2023-07-03 18:54:04,889 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:04 2023\n",
      "2023-07-03 18:54:04,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15604\n",
      "2023-07-03 18:54:04,978 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15624\n",
      "2023-07-03 18:54:05,401 - \u001b[1;33mWARNING\u001b[1;0m - Request 15628 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89492 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:05,402 - \u001b[1;33mWARNING\u001b[1;0m - Request 15629 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89488 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:20,413 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:20 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:54:20,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15642\n",
      "2023-07-03 18:54:20,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15662\n",
      "2023-07-03 18:54:20,857 - \u001b[1;33mWARNING\u001b[1;0m - Request 15645 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89339 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:35,869 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:35 2023\n",
      "2023-07-03 18:54:35,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15681\n",
      "2023-07-03 18:54:36,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 15693 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:36,130 - \u001b[1;33mWARNING\u001b[1;0m - Request 15694 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:51,140 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:51 2023\n",
      "2023-07-03 18:54:51,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15699\n",
      "2023-07-03 18:54:51,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15719\n",
      "2023-07-03 18:54:51,412 - \u001b[1;33mWARNING\u001b[1;0m - Request 15724 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89603 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:51,558 - \u001b[1;33mWARNING\u001b[1;0m - Request 15726 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:04,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 15120 failed with Exception \n",
      "2023-07-03 18:55:06,416 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:06 2023\n",
      "2023-07-03 18:55:06,559 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:06 2023\n",
      "2023-07-03 18:55:06,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15736\n",
      "2023-07-03 18:55:06,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15756\n",
      "2023-07-03 18:55:06,840 - \u001b[1;33mWARNING\u001b[1;0m - Request 15752 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89635 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:21,848 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:21 2023\n",
      "2023-07-03 18:55:21,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15775\n",
      "2023-07-03 18:55:22,158 - \u001b[1;33mWARNING\u001b[1;0m - Request 15778 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89687 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:22,308 - \u001b[1;33mWARNING\u001b[1;0m - Request 15789 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89463 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:37,173 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:37 2023\n",
      "2023-07-03 18:55:37,310 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:37 2023\n",
      "2023-07-03 18:55:37,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15793\n",
      "2023-07-03 18:55:37,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15813\n",
      "2023-07-03 18:55:38,482 - \u001b[1;33mWARNING\u001b[1;0m - Request 15813 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89709 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:53,497 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:53 2023\n",
      "2023-07-03 18:55:53,539 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15832\n",
      "2023-07-03 18:55:53,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15852\n",
      "2023-07-03 18:55:53,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 15850 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89744 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:53,957 - \u001b[1;33mWARNING\u001b[1;0m - Request 15855 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89624 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:08,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:08 2023\n",
      "2023-07-03 18:56:08,958 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:08 2023\n",
      "2023-07-03 18:56:09,027 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15870\n",
      "2023-07-03 18:56:09,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 15880 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89491 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:09,592 - \u001b[1;33mWARNING\u001b[1;0m - Request 15887 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89284 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:24,467 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:24 2023\n",
      "2023-07-03 18:56:24,593 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:24 2023\n",
      "2023-07-03 18:56:24,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15887\n",
      "2023-07-03 18:56:24,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15908\n",
      "2023-07-03 18:56:24,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 15918 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89355 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:39,967 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:39 2023\n",
      "2023-07-03 18:56:40,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15927\n",
      "2023-07-03 18:56:40,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15947\n",
      "2023-07-03 18:56:40,247 - \u001b[1;33mWARNING\u001b[1;0m - Request 15947 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89499 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:56:40,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 15951 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89362 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 15311 failed with Exception \n",
      "2023-07-03 18:56:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 15316 failed with Exception \n",
      "2023-07-03 18:56:55,248 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:55 2023\n",
      "2023-07-03 18:56:55,347 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:55 2023\n",
      "2023-07-03 18:56:55,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15963\n",
      "2023-07-03 18:56:55,604 - \u001b[1;33mWARNING\u001b[1;0m - Request 15975 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89538 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:10,605 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:10 2023\n",
      "2023-07-03 18:57:10,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15982\n",
      "2023-07-03 18:57:10,679 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16002\n",
      "2023-07-03 18:57:13,755 - \u001b[1;33mWARNING\u001b[1;0m - Request 16016 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89745 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:13,824 - \u001b[1;33mWARNING\u001b[1;0m - Request 16019 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89639 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:25,678 - \u001b[1;33mWARNING\u001b[1;0m - Request 15960 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 939d19ad6035e4582dba7fc655cc0bb6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:28,759 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:28 2023\n",
      "2023-07-03 18:57:28,825 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:28 2023\n",
      "2023-07-03 18:57:28,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16019\n",
      "2023-07-03 18:57:28,882 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16039\n",
      "2023-07-03 18:57:29,304 - \u001b[1;33mWARNING\u001b[1;0m - Request 16046 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89573 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:29,439 - \u001b[1;33mWARNING\u001b[1;0m - Request 16050 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:32,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 15410 failed with Exception \n",
      "2023-07-03 18:57:44,306 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:44 2023\n",
      "2023-07-03 18:57:44,441 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:44 2023\n",
      "2023-07-03 18:57:44,472 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16056\n",
      "2023-07-03 18:57:44,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16076\n",
      "2023-07-03 18:57:45,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 16081 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89810 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:00,042 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:00 2023\n",
      "2023-07-03 18:58:00,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16095\n",
      "2023-07-03 18:58:00,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16115\n",
      "2023-07-03 18:58:02,550 - \u001b[1;33mWARNING\u001b[1;0m - Request 16098 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89518 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:02,554 - \u001b[1;33mWARNING\u001b[1;0m - Request 16092 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89508 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:17,560 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:17 2023\n",
      "2023-07-03 18:58:17,620 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16133\n",
      "2023-07-03 18:58:19,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16153\n",
      "2023-07-03 18:58:19,847 - \u001b[1;33mWARNING\u001b[1;0m - Request 16154 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89474 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:34,858 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:34 2023\n",
      "2023-07-03 18:58:34,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16172\n",
      "2023-07-03 18:58:35,134 - \u001b[1;33mWARNING\u001b[1;0m - Request 16185 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89566 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:35,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 16186 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:50,137 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:50 2023\n",
      "2023-07-03 18:58:50,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16190\n",
      "2023-07-03 18:58:50,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16210\n",
      "2023-07-03 18:58:50,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 16202 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89454 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:50,633 - \u001b[1;33mWARNING\u001b[1;0m - Request 16212 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:05,609 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:05 2023\n",
      "2023-07-03 18:59:05,633 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:05 2023\n",
      "2023-07-03 18:59:05,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:59:05,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16248\n",
      "2023-07-03 18:59:05,920 - \u001b[1;33mWARNING\u001b[1;0m - Request 16245 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89536 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:06,082 - \u001b[1;33mWARNING\u001b[1;0m - Request 16250 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89297 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:20,934 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:21 2023\n",
      "2023-07-03 18:59:21,085 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:21 2023\n",
      "2023-07-03 18:59:21,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16266\n",
      "2023-07-03 18:59:23,377 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16286\n",
      "2023-07-03 18:59:24,822 - \u001b[1;33mWARNING\u001b[1;0m - Request 16270 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:39,837 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:39 2023\n",
      "2023-07-03 18:59:39,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16305\n",
      "2023-07-03 18:59:40,104 - \u001b[1;33mWARNING\u001b[1;0m - Request 16316 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89547 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:40,125 - \u001b[1;33mWARNING\u001b[1;0m - Request 16297 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:51,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 15717 failed with Exception \n",
      "2023-07-03 18:59:51,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 15704 failed with Exception \n",
      "2023-07-03 18:59:55,109 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:55 2023\n",
      "2023-07-03 18:59:55,126 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:55 2023\n",
      "2023-07-03 18:59:55,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15717\n",
      "2023-07-03 18:59:55,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16341\n",
      "2023-07-03 18:59:55,609 - \u001b[1;33mWARNING\u001b[1;0m - Request 16349 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89405 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:55,612 - \u001b[1;33mWARNING\u001b[1;0m - Request 16350 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:10,617 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:10 2023\n",
      "2023-07-03 19:00:10,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16359\n",
      "2023-07-03 19:00:10,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16379\n",
      "2023-07-03 19:00:10,943 - \u001b[1;33mWARNING\u001b[1;0m - Request 16379 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89482 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:25,957 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:25 2023\n",
      "2023-07-03 19:00:26,011 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16398\n",
      "2023-07-03 19:00:26,480 - \u001b[1;33mWARNING\u001b[1;0m - Request 16414 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:41,493 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:41 2023\n",
      "2023-07-03 19:00:41,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16417\n",
      "2023-07-03 19:00:41,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16437\n",
      "2023-07-03 19:00:42,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 16449 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89781 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:42,468 - \u001b[1;33mWARNING\u001b[1;0m - Request 16446 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89750 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:57,453 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:57 2023\n",
      "2023-07-03 19:00:57,469 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:57 2023\n",
      "2023-07-03 19:00:57,492 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16455\n",
      "2023-07-03 19:00:57,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16475\n",
      "2023-07-03 19:00:58,399 - \u001b[1;33mWARNING\u001b[1;0m - Request 16482 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:13,413 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:13 2023\n",
      "2023-07-03 19:01:13,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16494\n",
      "2023-07-03 19:01:13,521 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16514\n",
      "2023-07-03 19:01:13,903 - \u001b[1;33mWARNING\u001b[1;0m - Request 16509 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89510 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:13,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 16510 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89478 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:13,944 - \u001b[1;33mWARNING\u001b[1;0m - Request 16515 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89451 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:28,917 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:28 2023\n",
      "2023-07-03 19:01:28,946 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:28 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:01:29,004 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16531\n",
      "2023-07-03 19:01:29,263 - \u001b[1;33mWARNING\u001b[1;0m - Request 16531 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89621 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:44,277 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:44 2023\n",
      "2023-07-03 19:01:44,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16550\n",
      "2023-07-03 19:01:44,362 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16570\n",
      "2023-07-03 19:01:44,555 - \u001b[1;33mWARNING\u001b[1;0m - Request 16566 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:44,695 - \u001b[1;33mWARNING\u001b[1;0m - Request 16578 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89537 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:59,569 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:59 2023\n",
      "2023-07-03 19:01:59,696 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:59 2023\n",
      "2023-07-03 19:01:59,736 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16588\n",
      "2023-07-03 19:01:59,792 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16608\n",
      "2023-07-03 19:02:00,188 - \u001b[1;33mWARNING\u001b[1;0m - Request 16592 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:15,201 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:15 2023\n",
      "2023-07-03 19:02:15,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16627\n",
      "2023-07-03 19:02:15,718 - \u001b[1;33mWARNING\u001b[1;0m - Request 16636 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89925 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:15,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 16643 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89689 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:30,732 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:30 2023\n",
      "2023-07-03 19:02:30,874 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:30 2023\n",
      "2023-07-03 19:02:30,880 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16645\n",
      "2023-07-03 19:02:30,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16665\n",
      "2023-07-03 19:02:31,179 - \u001b[1;33mWARNING\u001b[1;0m - Request 16669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89744 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:46,193 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:46 2023\n",
      "2023-07-03 19:02:46,234 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16684\n",
      "2023-07-03 19:02:46,312 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16704\n",
      "2023-07-03 19:02:46,474 - \u001b[1;33mWARNING\u001b[1;0m - Request 16706 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89938 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:46,536 - \u001b[1;33mWARNING\u001b[1;0m - Request 16707 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89848 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:01,488 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:01 2023\n",
      "2023-07-03 19:03:01,538 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:01 2023\n",
      "2023-07-03 19:03:01,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16722\n",
      "2023-07-03 19:03:01,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 16727 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89400 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:01,810 - \u001b[1;33mWARNING\u001b[1;0m - Request 16731 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89381 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:16,809 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:16 2023\n",
      "2023-07-03 19:03:16,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16740\n",
      "2023-07-03 19:03:16,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16760\n",
      "2023-07-03 19:03:17,279 - \u001b[1;33mWARNING\u001b[1;0m - Request 16759 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89979 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:32,293 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:32 2023\n",
      "2023-07-03 19:03:32,333 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16779\n",
      "2023-07-03 19:03:32,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16799\n",
      "2023-07-03 19:03:32,804 - \u001b[1;33mWARNING\u001b[1;0m - Request 16797 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89833 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:32,875 - \u001b[1;33mWARNING\u001b[1;0m - Request 16803 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:47,818 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:47 2023\n",
      "2023-07-03 19:03:47,876 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:47 2023\n",
      "2023-07-03 19:03:47,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16817\n",
      "2023-07-03 19:03:48,386 - \u001b[1;33mWARNING\u001b[1;0m - Request 16834 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:48,429 - \u001b[1;33mWARNING\u001b[1;0m - Request 16835 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:04:03,397 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:03 2023\n",
      "2023-07-03 19:04:03,430 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:03 2023\n",
      "2023-07-03 19:04:03,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16834\n",
      "2023-07-03 19:04:03,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16855\n",
      "2023-07-03 19:04:03,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 16862 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89572 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:18,722 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:18 2023\n",
      "2023-07-03 19:04:18,756 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16874\n",
      "2023-07-03 19:04:18,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16894\n",
      "2023-07-03 19:04:21,081 - \u001b[1;33mWARNING\u001b[1;0m - Request 16894 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:21,092 - \u001b[1;33mWARNING\u001b[1;0m - Request 16874 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:36,093 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:36 2023\n",
      "2023-07-03 19:04:36,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16912\n",
      "2023-07-03 19:04:36,187 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16932\n",
      "2023-07-03 19:04:37,274 - \u001b[1;33mWARNING\u001b[1;0m - Request 16936 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89699 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:37,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 16937 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89494 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:52,288 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:52 2023\n",
      "2023-07-03 19:04:52,420 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:52 2023\n",
      "2023-07-03 19:04:52,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16950\n",
      "2023-07-03 19:04:53,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16970\n",
      "2023-07-03 19:04:57,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 16974 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89334 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:57,737 - \u001b[1;33mWARNING\u001b[1;0m - Request 16968 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:12,721 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:12 2023\n",
      "2023-07-03 19:05:12,738 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:12 2023\n",
      "2023-07-03 19:05:12,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16988\n",
      "2023-07-03 19:05:12,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17008\n",
      "2023-07-03 19:05:13,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 16998 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89542 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:28,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:28 2023\n",
      "2023-07-03 19:05:28,516 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17027\n",
      "2023-07-03 19:05:28,725 - \u001b[1;33mWARNING\u001b[1;0m - Request 17044 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89617 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:28,923 - \u001b[1;33mWARNING\u001b[1;0m - Request 17027 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:43,739 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:43 2023\n",
      "2023-07-03 19:05:43,924 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:43 2023\n",
      "2023-07-03 19:05:43,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17027\n",
      "2023-07-03 19:05:43,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17065\n",
      "2023-07-03 19:05:44,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 17068 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89537 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:59,231 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:59 2023\n",
      "2023-07-03 19:05:59,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17084\n",
      "2023-07-03 19:05:59,322 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17104\n",
      "2023-07-03 19:06:00,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 17091 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:00,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 17096 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89371 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:15,703 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:15 2023\n",
      "2023-07-03 19:06:15,728 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:15 2023\n",
      "2023-07-03 19:06:15,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17122\n",
      "2023-07-03 19:06:15,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17142\n",
      "2023-07-03 19:06:16,517 - \u001b[1;33mWARNING\u001b[1;0m - Request 17124 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89515 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:16,527 - \u001b[1;33mWARNING\u001b[1;0m - Request 17129 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89496 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:06:29,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 16530 failed with Exception \n",
      "2023-07-03 19:06:31,519 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:31 2023\n",
      "2023-07-03 19:06:31,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:31 2023\n",
      "2023-07-03 19:06:31,590 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17159\n",
      "2023-07-03 19:06:32,017 - \u001b[1;33mWARNING\u001b[1;0m - Request 17169 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89312 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:32,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 17171 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:47,023 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:47 2023\n",
      "2023-07-03 19:06:47,035 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:47 2023\n",
      "2023-07-03 19:06:47,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17177\n",
      "2023-07-03 19:06:47,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17197\n",
      "2023-07-03 19:06:47,549 - \u001b[1;33mWARNING\u001b[1;0m - Request 17205 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89812 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:02,561 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:02 2023\n",
      "2023-07-03 19:07:02,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17216\n",
      "2023-07-03 19:07:02,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17236\n",
      "2023-07-03 19:07:06,758 - \u001b[1;33mWARNING\u001b[1;0m - Request 17241 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89796 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:06,824 - \u001b[1;33mWARNING\u001b[1;0m - Request 17247 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89707 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:21,771 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:21 2023\n",
      "2023-07-03 19:07:21,826 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:21 2023\n",
      "2023-07-03 19:07:21,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17254\n",
      "2023-07-03 19:07:21,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17274\n",
      "2023-07-03 19:07:22,117 - \u001b[1;33mWARNING\u001b[1;0m - Request 17277 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89895 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:37,122 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:37 2023\n",
      "2023-07-03 19:07:37,174 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17293\n",
      "2023-07-03 19:07:38,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17313\n",
      "2023-07-03 19:07:39,331 - \u001b[1;33mWARNING\u001b[1;0m - Request 17315 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89297 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:54,345 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:54 2023\n",
      "2023-07-03 19:07:54,405 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17332\n",
      "2023-07-03 19:07:54,594 - \u001b[1;33mWARNING\u001b[1;0m - Request 17346 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89506 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:54,635 - \u001b[1;33mWARNING\u001b[1;0m - Request 17342 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89484 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:54,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 17345 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89409 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:09,608 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:09 2023\n",
      "2023-07-03 19:08:09,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:09 2023\n",
      "2023-07-03 19:08:09,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17349\n",
      "2023-07-03 19:08:09,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17369\n",
      "2023-07-03 19:08:10,071 - \u001b[1;33mWARNING\u001b[1;0m - Request 17378 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89408 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:25,085 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:25 2023\n",
      "2023-07-03 19:08:25,128 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17388\n",
      "2023-07-03 19:08:25,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17408\n",
      "2023-07-03 19:08:25,347 - \u001b[1;33mWARNING\u001b[1;0m - Request 17408 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:25,365 - \u001b[1;33mWARNING\u001b[1;0m - Request 17410 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:40,359 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:40 2023\n",
      "2023-07-03 19:08:40,366 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:40 2023\n",
      "2023-07-03 19:08:40,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17426\n",
      "2023-07-03 19:08:40,819 - \u001b[1;33mWARNING\u001b[1;0m - Request 17442 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:40,849 - \u001b[1;33mWARNING\u001b[1;0m - Request 17436 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89486 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:08:55,387 - \u001b[1;33mWARNING\u001b[1;0m - Request 17379 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b4c833c3e115c831ee9d5c94a1ea03c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:55,821 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:55 2023\n",
      "2023-07-03 19:08:55,850 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:55 2023\n",
      "2023-07-03 19:08:55,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17379\n",
      "2023-07-03 19:08:55,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17463\n",
      "2023-07-03 19:08:56,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 17467 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89314 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:11,357 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:11 2023\n",
      "2023-07-03 19:09:11,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17482\n",
      "2023-07-03 19:09:11,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17502\n",
      "2023-07-03 19:09:11,953 - \u001b[1;33mWARNING\u001b[1;0m - Request 17504 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89737 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:12,020 - \u001b[1;33mWARNING\u001b[1;0m - Request 17506 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:26,967 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:27 2023\n",
      "2023-07-03 19:09:27,021 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:27 2023\n",
      "2023-07-03 19:09:27,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17520\n",
      "2023-07-03 19:09:27,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 17525 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89698 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:42,350 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:42 2023\n",
      "2023-07-03 19:09:42,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17539\n",
      "2023-07-03 19:09:42,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17559\n",
      "2023-07-03 19:09:42,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 17560 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89756 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:42,676 - \u001b[1;33mWARNING\u001b[1;0m - Request 17570 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89730 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:57,677 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:57 2023\n",
      "2023-07-03 19:09:57,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17577\n",
      "2023-07-03 19:09:57,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17597\n",
      "2023-07-03 19:10:00,270 - \u001b[1;33mWARNING\u001b[1;0m - Request 17590 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89312 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:00,274 - \u001b[1;33mWARNING\u001b[1;0m - Request 17575 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:15,286 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:15 2023\n",
      "2023-07-03 19:10:15,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17615\n",
      "2023-07-03 19:10:15,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17635\n",
      "2023-07-03 19:10:15,601 - \u001b[1;33mWARNING\u001b[1;0m - Request 17630 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89388 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:15,669 - \u001b[1;33mWARNING\u001b[1;0m - Request 17638 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89308 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:30,611 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:30 2023\n",
      "2023-07-03 19:10:30,670 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:30 2023\n",
      "2023-07-03 19:10:30,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17653\n",
      "2023-07-03 19:10:30,937 - \u001b[1;33mWARNING\u001b[1;0m - Request 17669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89582 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:45,951 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:45 2023\n",
      "2023-07-03 19:10:45,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17672\n",
      "2023-07-03 19:10:46,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17692\n",
      "2023-07-03 19:10:46,216 - \u001b[1;33mWARNING\u001b[1;0m - Request 17701 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89631 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:46,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 17702 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89377 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:01,218 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:01 2023\n",
      "2023-07-03 19:11:01,385 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:01 2023\n",
      "2023-07-03 19:11:01,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17710\n",
      "2023-07-03 19:11:01,479 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17730\n",
      "2023-07-03 19:11:01,948 - \u001b[1;33mWARNING\u001b[1;0m - Request 17707 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89737 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:16,961 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:16 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:11:17,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17749\n",
      "2023-07-03 19:11:17,246 - \u001b[1;33mWARNING\u001b[1;0m - Request 17764 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89900 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:32,257 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:32 2023\n",
      "2023-07-03 19:11:32,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17768\n",
      "2023-07-03 19:11:32,332 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17788\n",
      "2023-07-03 19:11:32,751 - \u001b[1;33mWARNING\u001b[1;0m - Request 17796 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89726 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:32,808 - \u001b[1;33mWARNING\u001b[1;0m - Request 17785 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89645 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:47,765 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:47 2023\n",
      "2023-07-03 19:11:47,809 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:47 2023\n",
      "2023-07-03 19:11:47,841 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17806\n",
      "2023-07-03 19:11:47,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17826\n",
      "2023-07-03 19:11:48,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 17830 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89883 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:03,081 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:03 2023\n",
      "2023-07-03 19:12:03,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17845\n",
      "2023-07-03 19:12:03,344 - \u001b[1;33mWARNING\u001b[1;0m - Request 17860 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89295 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:03,350 - \u001b[1;33mWARNING\u001b[1;0m - Request 17861 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89284 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:18,358 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:18 2023\n",
      "2023-07-03 19:12:18,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17860\n",
      "2023-07-03 19:12:18,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17883\n",
      "2023-07-03 19:12:18,638 - \u001b[1;33mWARNING\u001b[1;0m - Request 17893 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:18,664 - \u001b[1;33mWARNING\u001b[1;0m - Request 17892 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:22,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 17271 failed with Exception \n",
      "2023-07-03 19:12:33,639 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:33 2023\n",
      "2023-07-03 19:12:33,665 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:33 2023\n",
      "2023-07-03 19:12:33,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17900\n",
      "2023-07-03 19:12:33,754 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17920\n",
      "2023-07-03 19:12:33,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 17922 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89487 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:33,989 - \u001b[1;33mWARNING\u001b[1;0m - Request 17925 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89440 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:48,967 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:48 2023\n",
      "2023-07-03 19:12:48,989 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:48 2023\n",
      "2023-07-03 19:12:49,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17938\n",
      "2023-07-03 19:12:49,240 - \u001b[1;33mWARNING\u001b[1;0m - Request 17955 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89700 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:13:04,255 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:13:04 2023\n",
      "2023-07-03 19:13:04,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17955\n",
      "2023-07-03 19:13:04,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17977\n",
      "2023-07-03 19:13:04,525 - \u001b[1;33mWARNING\u001b[1;0m - Request 17985 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89788 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:13:10,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 17358 failed with Exception \n",
      "2023-07-03 19:13:19,535 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:13:19 2023\n",
      "2023-07-03 19:13:19,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17995\n",
      "2023-07-03 19:13:19,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18015\n",
      "2023-07-03 19:13:19,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 18002 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89772 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:13:20,039 - \u001b[1;33mWARNING\u001b[1;0m - Request 18019 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:13:34,918 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:13:35 2023\n",
      "2023-07-03 19:13:35,041 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:13:35 2023\n",
      "2023-07-03 19:13:35,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18033\n",
      "2023-07-03 19:13:35,380 - \u001b[1;33mWARNING\u001b[1;0m - Request 18052 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89622 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:13:35,527 - \u001b[1;33mWARNING\u001b[1;0m - Request 18048 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89410 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:13:50,396 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:13:50 2023\n",
      "2023-07-03 19:13:50,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18053\n",
      "2023-07-03 19:13:50,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:13:50 2023\n",
      "2023-07-03 19:13:50,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18071\n",
      "2023-07-03 19:13:54,018 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18091\n",
      "2023-07-03 19:13:54,176 - \u001b[1;33mWARNING\u001b[1;0m - Request 18091 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89587 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:13:54,319 - \u001b[1;33mWARNING\u001b[1;0m - Request 18053 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:14:09,178 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:14:09 2023\n",
      "2023-07-03 19:14:09,321 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:14:09 2023\n",
      "2023-07-03 19:14:09,383 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18109\n",
      "2023-07-03 19:14:09,810 - \u001b[1;33mWARNING\u001b[1;0m - Request 18119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89979 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:14:24,825 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:14:24 2023\n",
      "2023-07-03 19:14:24,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18128\n",
      "2023-07-03 19:14:24,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18148\n",
      "2023-07-03 19:14:25,316 - \u001b[1;33mWARNING\u001b[1;0m - Request 18143 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89667 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:14:25,386 - \u001b[1;33mWARNING\u001b[1;0m - Request 18155 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:14:40,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:14:40 2023\n",
      "2023-07-03 19:14:40,388 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:14:40 2023\n",
      "2023-07-03 19:14:40,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18166\n",
      "2023-07-03 19:14:40,505 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18186\n",
      "2023-07-03 19:14:42,351 - \u001b[1;33mWARNING\u001b[1;0m - Request 18178 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89470 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:14:42,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 18186 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:14:57,367 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:14:57 2023\n",
      "2023-07-03 19:14:57,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18204\n",
      "2023-07-03 19:14:57,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 18213 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89301 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:15:12,887 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:15:12 2023\n",
      "2023-07-03 19:15:12,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18224\n",
      "2023-07-03 19:15:12,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18243\n",
      "2023-07-03 19:15:13,149 - \u001b[1;33mWARNING\u001b[1;0m - Request 18253 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89409 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:15:13,160 - \u001b[1;33mWARNING\u001b[1;0m - Request 18252 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:15:28,165 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:15:28 2023\n",
      "2023-07-03 19:15:28,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18261\n",
      "2023-07-03 19:15:28,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18281\n",
      "2023-07-03 19:15:32,288 - \u001b[1;33mWARNING\u001b[1;0m - Request 18273 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89512 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:15:32,289 - \u001b[1;33mWARNING\u001b[1;0m - Request 18289 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89512 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:15:43,239 - \u001b[1;33mWARNING\u001b[1;0m - Request 18242 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 677f36f94a97fde88f7b6527918ba2a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 19:15:47,293 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:15:47 2023\n",
      "2023-07-03 19:15:47,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18298\n",
      "2023-07-03 19:15:47,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18318\n",
      "2023-07-03 19:15:48,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 18328 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89309 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:16:03,736 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:16:03 2023\n",
      "2023-07-03 19:16:03,772 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18337\n",
      "2023-07-03 19:16:03,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18357\n",
      "2023-07-03 19:16:04,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 18361 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:16:04,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 18354 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89723 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:16:19,246 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:16:19 2023\n",
      "2023-07-03 19:16:19,255 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:16:19 2023\n",
      "2023-07-03 19:16:19,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18375\n",
      "2023-07-03 19:16:19,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 18381 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89588 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:16:19,862 - \u001b[1;33mWARNING\u001b[1;0m - Request 18393 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89488 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:16:34,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:16:34 2023\n",
      "2023-07-03 19:16:34,864 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:16:34 2023\n",
      "2023-07-03 19:16:34,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18381\n",
      "2023-07-03 19:16:34,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18413\n",
      "2023-07-03 19:16:37,858 - \u001b[1;33mWARNING\u001b[1;0m - Request 18415 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89793 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:16:48,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 17817 failed with Exception \n",
      "2023-07-03 19:16:52,864 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:16:52 2023\n",
      "2023-07-03 19:16:52,868 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17817\n",
      "2023-07-03 19:16:52,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18451\n",
      "2023-07-03 19:16:53,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 18451 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89840 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:16:53,280 - \u001b[1;33mWARNING\u001b[1;0m - Request 18462 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89783 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:03,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 17850 failed with Exception \n",
      "2023-07-03 19:17:08,213 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:17:08 2023\n",
      "2023-07-03 19:17:08,283 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:17:08 2023\n",
      "2023-07-03 19:17:08,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18468\n",
      "2023-07-03 19:17:08,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18488\n",
      "2023-07-03 19:17:08,775 - \u001b[1;33mWARNING\u001b[1;0m - Request 18492 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89695 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:08,871 - \u001b[1;33mWARNING\u001b[1;0m - Request 18493 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:23,790 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:17:23 2023\n",
      "2023-07-03 19:17:23,873 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:17:23 2023\n",
      "2023-07-03 19:17:23,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18506\n",
      "2023-07-03 19:17:24,745 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18526\n",
      "2023-07-03 19:17:27,252 - \u001b[1;33mWARNING\u001b[1;0m - Request 18527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:42,267 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:17:42 2023\n",
      "2023-07-03 19:17:42,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18545\n",
      "2023-07-03 19:17:42,817 - \u001b[1;33mWARNING\u001b[1;0m - Request 18564 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89877 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:49,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 17925 failed with Exception \n",
      "2023-07-03 19:17:57,827 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:17:57 2023\n",
      "2023-07-03 19:17:57,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18565\n",
      "2023-07-03 19:17:58,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18583\n",
      "2023-07-03 19:17:58,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 18593 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89542 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:58,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 18591 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89548 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:17:58,461 - \u001b[1;33mWARNING\u001b[1;0m - Request 18590 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:18:13,444 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:18:13 2023\n",
      "2023-07-03 19:18:13,462 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:18:13 2023\n",
      "2023-07-03 19:18:13,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18600\n",
      "2023-07-03 19:18:13,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18620\n",
      "2023-07-03 19:18:15,773 - \u001b[1;33mWARNING\u001b[1;0m - Request 18628 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89493 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:18:15,790 - \u001b[1;33mWARNING\u001b[1;0m - Request 18606 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89468 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:18:28,220 - \u001b[1;33mWARNING\u001b[1;0m - Request 18578 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eee8bf4dce1e7f88ae83fcc999e2c50d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:18:30,777 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:18:30 2023\n",
      "2023-07-03 19:18:30,791 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:18:30 2023\n",
      "2023-07-03 19:18:30,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18637\n",
      "2023-07-03 19:18:30,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18657\n",
      "2023-07-03 19:18:35,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 18036 failed with Exception \n",
      "2023-07-03 19:18:35,544 - \u001b[1;33mWARNING\u001b[1;0m - Request 18663 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:18:35,644 - \u001b[1;33mWARNING\u001b[1;0m - Request 18669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:18:50,546 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:18:50 2023\n",
      "2023-07-03 19:18:50,645 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:18:50 2023\n",
      "2023-07-03 19:18:50,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18674\n",
      "2023-07-03 19:18:50,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18694\n",
      "2023-07-03 19:18:51,134 - \u001b[1;33mWARNING\u001b[1;0m - Request 18698 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89787 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:19:06,144 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:19:06 2023\n",
      "2023-07-03 19:19:06,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18713\n",
      "2023-07-03 19:19:06,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18733\n",
      "2023-07-03 19:19:06,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 18734 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:19:06,696 - \u001b[1;33mWARNING\u001b[1;0m - Request 18710 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:19:21,701 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:19:21 2023\n",
      "2023-07-03 19:19:21,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18751\n",
      "2023-07-03 19:19:22,220 - \u001b[1;33mWARNING\u001b[1;0m - Request 18766 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89922 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:19:37,234 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:19:37 2023\n",
      "2023-07-03 19:19:37,246 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18770\n",
      "2023-07-03 19:19:37,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18790\n",
      "2023-07-03 19:19:39,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 18776 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89885 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:19:54,617 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:19:54 2023\n",
      "2023-07-03 19:19:54,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18809\n",
      "2023-07-03 19:19:54,702 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18829\n",
      "2023-07-03 19:19:55,103 - \u001b[1;33mWARNING\u001b[1;0m - Request 18836 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89606 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:19:55,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 18833 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89613 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:10,118 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:20:10 2023\n",
      "2023-07-03 19:20:10,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18847\n",
      "2023-07-03 19:20:10,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18867\n",
      "2023-07-03 19:20:10,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 18836 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:10,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 18866 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:25,689 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:20:25 2023\n",
      "2023-07-03 19:20:25,751 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18885\n",
      "2023-07-03 19:20:26,172 - \u001b[1;33mWARNING\u001b[1;0m - Request 18893 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89847 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:26,208 - \u001b[1;33mWARNING\u001b[1;0m - Request 18901 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89776 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:41,187 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:20:41 2023\n",
      "2023-07-03 19:20:41,210 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:20:41 2023\n",
      "2023-07-03 19:20:41,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18903\n",
      "2023-07-03 19:20:41,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18923\n",
      "2023-07-03 19:20:41,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 18924 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:47,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 18325 failed with Exception \n",
      "2023-07-03 19:20:56,735 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:20:56 2023\n",
      "2023-07-03 19:20:56,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18941\n",
      "2023-07-03 19:20:56,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18961\n",
      "2023-07-03 19:20:57,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 18960 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89440 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:20:57,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 18950 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89446 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:21:12,232 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:21:12 2023\n",
      "2023-07-03 19:21:12,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18979\n",
      "2023-07-03 19:21:12,898 - \u001b[1;33mWARNING\u001b[1;0m - Request 18979 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:21:12,956 - \u001b[1;33mWARNING\u001b[1;0m - Request 18997 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:21:27,911 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:21:27 2023\n",
      "2023-07-03 19:21:27,957 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:21:27 2023\n",
      "2023-07-03 19:21:27,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18979\n",
      "2023-07-03 19:21:28,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19017\n",
      "2023-07-03 19:21:28,533 - \u001b[1;33mWARNING\u001b[1;0m - Request 19028 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89404 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:21:28,564 - \u001b[1;33mWARNING\u001b[1;0m - Request 19029 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:21:43,546 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:21:43 2023\n",
      "2023-07-03 19:21:43,566 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:21:43 2023\n",
      "2023-07-03 19:21:43,590 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19035\n",
      "2023-07-03 19:21:43,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19055\n",
      "2023-07-03 19:21:44,383 - \u001b[1;33mWARNING\u001b[1;0m - Request 19052 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:21:59,398 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:21:59 2023\n",
      "2023-07-03 19:21:59,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19074\n",
      "2023-07-03 19:21:59,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19094\n",
      "2023-07-03 19:21:59,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 19092 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89944 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:22:14,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:22:14 2023\n",
      "2023-07-03 19:22:14,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19113\n",
      "2023-07-03 19:22:15,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 19119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:22:15,331 - \u001b[1;33mWARNING\u001b[1;0m - Request 19127 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89896 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:22:30,238 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:22:30 2023\n",
      "2023-07-03 19:22:30,332 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:22:30 2023\n",
      "2023-07-03 19:22:30,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19131\n",
      "2023-07-03 19:22:30,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19151\n",
      "2023-07-03 19:22:30,598 - \u001b[1;33mWARNING\u001b[1;0m - Request 19127 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:22:30,610 - \u001b[1;33mWARNING\u001b[1;0m - Request 19154 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:22:45,612 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:22:45 2023\n",
      "2023-07-03 19:22:45,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19169\n",
      "2023-07-03 19:22:45,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19189\n",
      "2023-07-03 19:22:46,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 19162 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89579 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:22:46,545 - \u001b[1;33mWARNING\u001b[1;0m - Request 19191 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89329 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:23:01,411 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:23:01 2023\n",
      "2023-07-03 19:23:01,547 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:23:01 2023\n",
      "2023-07-03 19:23:01,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19207\n",
      "2023-07-03 19:23:02,157 - \u001b[1;33mWARNING\u001b[1;0m - Request 19216 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89767 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:23:17,172 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:23:17 2023\n",
      "2023-07-03 19:23:17,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19226\n",
      "2023-07-03 19:23:17,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19246\n",
      "2023-07-03 19:23:19,271 - \u001b[1;33mWARNING\u001b[1;0m - Request 19237 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:23:19,365 - \u001b[1;33mWARNING\u001b[1;0m - Request 19251 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:23:34,286 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:23:34 2023\n",
      "2023-07-03 19:23:34,366 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:23:34 2023\n",
      "2023-07-03 19:23:34,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:23:34,466 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19284\n",
      "2023-07-03 19:23:39,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 19301 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89684 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:23:54,299 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:23:54 2023\n",
      "2023-07-03 19:23:54,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19303\n",
      "2023-07-03 19:23:54,377 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19323\n",
      "2023-07-03 19:23:54,556 - \u001b[1;33mWARNING\u001b[1;0m - Request 19333 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89754 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:23:54,584 - \u001b[1;33mWARNING\u001b[1;0m - Request 19332 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89743 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:09,570 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:24:09 2023\n",
      "2023-07-03 19:24:09,585 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:24:09 2023\n",
      "2023-07-03 19:24:09,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19341\n",
      "2023-07-03 19:24:09,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19361\n",
      "2023-07-03 19:24:09,972 - \u001b[1;33mWARNING\u001b[1;0m - Request 19365 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89786 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:09,975 - \u001b[1;33mWARNING\u001b[1;0m - Request 19340 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89827 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:24,986 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:24:24 2023\n",
      "2023-07-03 19:24:25,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19379\n",
      "2023-07-03 19:24:25,813 - \u001b[1;33mWARNING\u001b[1;0m - Request 19384 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89816 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:40,828 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:24:40 2023\n",
      "2023-07-03 19:24:40,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19384\n",
      "2023-07-03 19:24:40,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19418\n",
      "2023-07-03 19:24:41,183 - \u001b[1;33mWARNING\u001b[1;0m - Request 19405 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89829 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:41,186 - \u001b[1;33mWARNING\u001b[1;0m - Request 19402 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89819 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:56,197 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:24:56 2023\n",
      "2023-07-03 19:24:56,223 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19436\n",
      "2023-07-03 19:24:56,284 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19456\n",
      "2023-07-03 19:24:58,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 19431 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89844 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:24:58,922 - \u001b[1;33mWARNING\u001b[1;0m - Request 19467 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89840 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:25:13,934 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:25:13 2023\n",
      "2023-07-03 19:25:13,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19474\n",
      "2023-07-03 19:25:14,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19494\n",
      "2023-07-03 19:25:15,516 - \u001b[1;33mWARNING\u001b[1;0m - Request 19487 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:25:15,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 19490 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:25:30,531 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:25:30 2023\n",
      "2023-07-03 19:25:30,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19512\n",
      "2023-07-03 19:25:30,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19532\n",
      "2023-07-03 19:25:31,193 - \u001b[1;33mWARNING\u001b[1;0m - Request 19528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89646 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:25:46,208 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:25:46 2023\n",
      "2023-07-03 19:25:46,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19551\n",
      "2023-07-03 19:25:47,037 - \u001b[1;33mWARNING\u001b[1;0m - Request 19551 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89578 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:25:47,128 - \u001b[1;33mWARNING\u001b[1;0m - Request 19567 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89395 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:26:02,052 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:02 2023\n",
      "2023-07-03 19:26:02,129 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:02 2023\n",
      "2023-07-03 19:26:02,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19569\n",
      "2023-07-03 19:26:02,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19589\n",
      "2023-07-03 19:26:02,387 - \u001b[1;33mWARNING\u001b[1;0m - Request 19598 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89579 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:26:02,431 - \u001b[1;33mWARNING\u001b[1;0m - Request 19599 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89513 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:26:17,402 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:17 2023\n",
      "2023-07-03 19:26:17,432 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:17 2023\n",
      "2023-07-03 19:26:17,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19607\n",
      "2023-07-03 19:26:17,523 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19627\n",
      "2023-07-03 19:26:17,916 - \u001b[1;33mWARNING\u001b[1;0m - Request 19622 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89418 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:26:28,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 19007 failed with Exception \n",
      "2023-07-03 19:26:32,922 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:32 2023\n",
      "2023-07-03 19:26:32,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19645\n",
      "2023-07-03 19:26:33,510 - \u001b[1;33mWARNING\u001b[1;0m - Request 19645 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89747 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:26:33,627 - \u001b[1;33mWARNING\u001b[1;0m - Request 19663 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89576 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:26:48,520 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:48 2023\n",
      "2023-07-03 19:26:48,628 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:26:48 2023\n",
      "2023-07-03 19:26:48,629 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19645\n",
      "2023-07-03 19:26:48,696 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19683\n",
      "2023-07-03 19:26:48,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 19667 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89711 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:27:00,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 19090 failed with Exception \n",
      "2023-07-03 19:27:03,899 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:27:03 2023\n",
      "2023-07-03 19:27:03,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19701\n",
      "2023-07-03 19:27:04,097 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19721\n",
      "2023-07-03 19:27:04,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 19723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89634 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:27:04,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 19724 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89340 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:27:19,342 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:27:19 2023\n",
      "2023-07-03 19:27:19,513 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:27:19 2023\n",
      "2023-07-03 19:27:19,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19739\n",
      "2023-07-03 19:27:20,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19759\n",
      "2023-07-03 19:27:23,746 - \u001b[1;33mWARNING\u001b[1;0m - Request 19747 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:27:23,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 19741 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89288 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:27:38,757 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:27:38 2023\n",
      "2023-07-03 19:27:38,798 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:27:38 2023\n",
      "2023-07-03 19:27:38,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19777\n",
      "2023-07-03 19:27:38,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19797\n",
      "2023-07-03 19:27:39,790 - \u001b[1;33mWARNING\u001b[1;0m - Request 19741 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89792 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:27:54,805 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:27:54 2023\n",
      "2023-07-03 19:27:54,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19816\n",
      "2023-07-03 19:27:55,440 - \u001b[1;33mWARNING\u001b[1;0m - Request 19800 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:10,453 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:28:10 2023\n",
      "2023-07-03 19:28:10,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19835\n",
      "2023-07-03 19:28:10,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19855\n",
      "2023-07-03 19:28:10,748 - \u001b[1;33mWARNING\u001b[1;0m - Request 19838 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:10,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 19861 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89541 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:25,752 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:28:25 2023\n",
      "2023-07-03 19:28:25,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19873\n",
      "2023-07-03 19:28:25,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19893\n",
      "2023-07-03 19:28:26,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 19894 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:26,233 - \u001b[1;33mWARNING\u001b[1;0m - Request 19893 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89366 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:28:28,449 - \u001b[1;33mWARNING\u001b[1;0m - Request 19832 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a22fa3bf097cb459935c50481c42d336 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:41,248 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:28:41 2023\n",
      "2023-07-03 19:28:41,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19910\n",
      "2023-07-03 19:28:41,583 - \u001b[1;33mWARNING\u001b[1;0m - Request 19927 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89409 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:41,608 - \u001b[1;33mWARNING\u001b[1;0m - Request 19904 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:56,053 - \u001b[1;33mWARNING\u001b[1;0m - Request 19867 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 12758ca30174cd4bf7592f5712f120da in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 19:28:56,586 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:28:56 2023\n",
      "2023-07-03 19:28:56,608 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:28:56 2023\n",
      "2023-07-03 19:28:56,610 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19904\n",
      "2023-07-03 19:28:56,682 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19947\n",
      "2023-07-03 19:28:57,101 - \u001b[1;33mWARNING\u001b[1;0m - Request 19952 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89896 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:29:12,116 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:29:12 2023\n",
      "2023-07-03 19:29:12,150 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19966\n",
      "2023-07-03 19:29:12,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19986\n",
      "2023-07-03 19:29:12,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 19988 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89693 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:29:12,816 - \u001b[1;33mWARNING\u001b[1;0m - Request 19991 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-15ICma9D9qvo4LYZvf2AA40R on tokens per min. Limit: 90000 / min. Current: 89449 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:29:27,624 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:29:27 2023\n",
      "2023-07-03 19:29:27,818 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:29:27 2023\n",
      "2023-07-03 19:29:29,611 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_164909.jsonl\n",
      "2023-07-03 19:29:29,612 - \u001b[1;33mWARNING\u001b[1;0m - 993 rate limit errors received. Consider running at a lower rate.\n",
      "2023-07-03 19:29:29,616 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_164909.jsonl\n",
      "2023-07-03 19:29:30,343 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Comparison 2.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,344 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide the sentence from the chest x-ray report?, returning []\n",
      "2023-07-03 19:29:30,344 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...nish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 388, \"completion_tokens\": 9, \"total_tokens\": 397}}, {\"sentence\": \"WET READ VERSION #2 1:28 AM 1.\"}] for sentence \"WET READ VERSION #2 1:28 AM 1.\": Could not parse output: No acute cardiopulmonary abnormality.\n",
      "2023-07-03 19:29:30,345 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't have access to previous reports or notifications. I can only generate relevant facts based on the given sentence. If you provide me with a sentence from the previous report, I can generate the relevant facts for that sentence., returning []\n",
      "2023-07-03 19:29:30,345 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"6:07 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,348 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"10:12 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,351 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"9:24 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,354 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"6:55 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,358 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can't assist with that request., returning []\n",
      "2023-07-03 19:29:30,361 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"11:43 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,365 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ge\": {\"prompt_tokens\": 387, \"completion_tokens\": 26, \"total_tokens\": 413}}, {\"sentence\": \"Mild to moderate decrease in left-sided pleural effusion.\"}] for sentence \"Mild to moderate decrease in left-sided pleural effusion.\": Expecting ',' delimiter: line 3 column 1 (char 49)\n",
      "2023-07-03 19:29:30,368 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"8:40 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,371 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"9:57 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,375 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to access or analyze specific reports. My function is to generate relevant facts based on the given sentence. If you have any specific sentences or questions about a report, I would be happy to help., returning []\n",
      "2023-07-03 19:29:30,377 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"14:30.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,378 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"4:10 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,379 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...tokens\": 389, \"completion_tokens\": 5, \"total_tokens\": 394}}, {\"sentence\": \"Correlation with prior radiographs, if available, could also be helpful.\"}] for sentence \"Correlation with prior radiographs, if available, could also be helpful.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:29:30,380 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...\"}], \"usage\": {\"prompt_tokens\": 393, \"completion_tokens\": 5, \"total_tokens\": 398}}, {\"sentence\": \"PROVISIONAL FINDINGS IMPRESSION (PFI): 5:21 PM 1.\"}] for sentence \"PROVISIONAL FINDINGS IMPRESSION (PFI): 5:21 PM 1.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:29:30,381 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,381 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"7:48 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,383 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"1:37 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,385 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"7:42 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,390 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, but I'm not sure what you're asking. Could you please provide more context or clarify your question?, returning []\n",
      "2023-07-03 19:29:30,391 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 388, \"completion_tokens\": 5, \"total_tokens\": 393}}, {\"sentence\": \"WET READ VERSION #1 12:13 AM 1.\"}] for sentence \"WET READ VERSION #1 12:13 AM 1.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:29:30,394 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but it seems like your input is incomplete. Could you please provide the complete sentence or information from the chest CT report?, returning []\n",
      "2023-07-03 19:29:30,402 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"2:50 AM 1.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,408 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"11:22 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,411 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...stop\"}], \"usage\": {\"prompt_tokens\": 383, \"completion_tokens\": 9, \"total_tokens\": 392}}, {\"sentence\": \"Left lower lobe collapse has improved since .\"}] for sentence \"Left lower lobe collapse has improved since .\": Could not parse output: \"improved left lower lobe collapse\"\n",
      "2023-07-03 19:29:30,411 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...prompt_tokens\": 386, \"completion_tokens\": 26, \"total_tokens\": 412}}, {\"sentence\": \"Patchy regions of consolidation in the right lung are unchanged.\"}] for sentence \"Patchy regions of consolidation in the right lung are unchanged.\": Expecting ',' delimiter: line 3 column 1 (char 54)\n",
      "2023-07-03 19:29:30,412 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Is chronic.\" Could you please provide more context or clarify your statement?, returning []\n",
      "2023-07-03 19:29:30,418 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"10:59 PM.\" Could you please provide more context or clarify your request?, returning []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:29:30,424 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"T7.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,425 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to correlate the given sentence with a CT scan. My task is to generate a JSON list of relevant facts based on the sentence provided. If you have any specific questions or need further assistance, please let me know., returning []\n",
      "2023-07-03 19:29:30,426 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I'm not able to generate a response without any input. Could you please provide a sentence from a chest x-ray report?, returning []\n",
      "2023-07-03 19:29:30,427 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide the sentence from the chest x-ray report?, returning []\n",
      "2023-07-03 19:29:30,428 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"12:33 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,433 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Is images.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,437 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...op\"}], \"usage\": {\"prompt_tokens\": 385, \"completion_tokens\": 18, \"total_tokens\": 403}}, {\"sentence\": \"Mild to moderate cardiomegaly is demonstrated.\"}] for sentence \"Mild to moderate cardiomegaly is demonstrated.\": Expecting ',' delimiter: line 3 column 1 (char 22)\n",
      "2023-07-03 19:29:30,437 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ist you today?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 379, \"completion_tokens\": 10, \"total_tokens\": 389}}, {\"sentence\": \"6:49 AM.\"}] for sentence \"6:49 AM.\": Could not parse output: Good morning! How can I assist you today?\n",
      "2023-07-03 19:29:30,443 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... 391, \"completion_tokens\": 11, \"total_tokens\": 402}}, {\"sentence\": \"As before, there is similar mild relative elevation of the right hemidiaphragm.\"}] for sentence \"As before, there is similar mild relative elevation of the right hemidiaphragm.\": Could not parse output: mild relative elevation of the right hemidiaphragm\n",
      "2023-07-03 19:29:30,444 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"4:25 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,445 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ist you today?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 379, \"completion_tokens\": 10, \"total_tokens\": 389}}, {\"sentence\": \"6:51 AM.\"}] for sentence \"6:51 AM.\": Could not parse output: Good morning! How can I assist you today?\n",
      "2023-07-03 19:29:30,445 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"5:21 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,448 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sure, please let me know what correction you would like to make., returning []\n",
      "2023-07-03 19:29:30,455 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...nish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 388, \"completion_tokens\": 5, \"total_tokens\": 393}}, {\"sentence\": \"WET READ VERSION #1 4:31 PM 1.\"}] for sentence \"WET READ VERSION #1 4:31 PM 1.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:29:30,458 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"4:32 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,459 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...tal_tokens\": 408}}, {\"sentence\": \"PA and lateral images of the chest demonstrate improvement in the diffuse bilateral opacities from prior imaging.\"}] for sentence \"PA and lateral images of the chest demonstrate improvement in the diffuse bilateral opacities from prior imaging.\": Expecting value: line 3 column 1 (char 52)\n",
      "2023-07-03 19:29:30,466 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"12:44 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,466 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Let me provide you with some examples that include comparisons to previous studies:\n",
      "\n",
      "1. Comparison to a previous study:\n",
      "   \"The opacity in the right lobe has increased compared to the previous study.\"\n",
      "   Fact: \"increased opacity in the right lobe\"\n",
      "\n",
      "2. Comparison to a previous study:\n",
      "   \"The lungs are well inflated without evidence of pneumonia, similar to the previous study.\"\n",
      "   Fact: \"well inflated lungs without evidence of pneumonia\"\n",
      "\n",
      "3. Comparison to a previous study:\n",
      "   \"No significant changes were observed in the pleural effusions compared to the previous study.\"\n",
      "   Fact: \"no significant changes in pleural effusions\"\n",
      "\n",
      "Please let me know if you need further assistance., returning []\n",
      "2023-07-03 19:29:30,468 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"7:24 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,474 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"2:10 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,477 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to understand your input. Could you please rephrase or provide more information?, returning []\n",
      "2023-07-03 19:29:30,478 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"1:14 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,480 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"was contacted by.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,493 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your response. Could you please provide the sentence from the chest x-ray report?, returning []\n",
      "2023-07-03 19:29:30,495 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, I didn't understand your input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,502 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"5:30 AM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,506 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"7:08 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,511 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, I am not able to correlate with prior imaging studies and clinical history. My task is to generate a JSON list of relevant facts based on the given sentence from a chest x-ray report., returning []\n",
      "2023-07-03 19:29:30,522 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"10:13 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,526 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 386, \"completion_tokens\": 5, \"total_tokens\": 391}}, {\"sentence\": \"D/w Dr. at pm by phone by Dr. .\"}] for sentence \"D/w Dr. at pm by phone by Dr. .\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:29:30,531 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I'm not able to generate a response based on the time you provided. Could you please provide the sentence from the chest x-ray report that you would like me to analyze?, returning []\n",
      "2023-07-03 19:29:30,534 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can't assist with that., returning []\n",
      "2023-07-03 19:29:30,542 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"5:00 PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:29:30,545 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...\"}], \"usage\": {\"prompt_tokens\": 393, \"completion_tokens\": 5, \"total_tokens\": 398}}, {\"sentence\": \"PROVISIONAL FINDINGS IMPRESSION (PFI): 5:04 PM 1.\"}] for sentence \"PROVISIONAL FINDINGS IMPRESSION (PFI): 5:04 PM 1.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:29:30,550 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...mpt_tokens\": 387, \"completion_tokens\": 11, \"total_tokens\": 398}}, {\"sentence\": \"Moderate pulmonary edema is improved on current study compared to .\"}] for sentence \"Moderate pulmonary edema is improved on current study compared to .\": Could not parse output: \"moderate pulmonary edema improved on current study\"\n",
      "2023-07-03 19:29:30,553 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-07-03 19:29:30,564 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 19984 of 20000 API responses.\n",
      "                    16 of 20000 API responses could not be processed.\n",
      "                    Saving parsed sentences to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_facts_from_report_sentences_with_openai.py \\\n",
    "    --preprocessed_reports_filename \"background_findings_and_impression_20230612_174143.json\" \\\n",
    "    --offset 30000 \\\n",
    "    --num_sentences 20000 \\\n",
    "    --rank_sentences_by_difficulty \\\n",
    "    --sample_sentences_uniformly \\\n",
    "    --max_requests_per_minute 3200 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 256 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__v2(uniform)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3f1949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 pamessina pamessina 4.2M Jul  3 19:29 '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl'\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f633648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdadc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5702acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0826062d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'sentence': 'The lungs are clear but hyperinflated.The cardiac, hilar and mediastinal contours are normal.No pleural abnormality is seen.'},\n",
       " 'parsed_response': ['clear lungs',\n",
       "  'hyperinflated lungs',\n",
       "  'normal cardiac contours',\n",
       "  'normal hilar contours',\n",
       "  'normal mediastinal contours',\n",
       "  'no pleural abnormality']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
