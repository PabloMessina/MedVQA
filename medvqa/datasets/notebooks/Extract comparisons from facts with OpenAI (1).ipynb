{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ab94131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16 23:46:19,454 - \u001b[1;32mINFO\u001b[1;0m - Loaded 195 already processed sentences from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_comparisons__part1.jsonl\n",
      "2023-07-16 23:46:19,454 - \u001b[1;32mINFO\u001b[1;0m - Loading facts metadata from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\n",
      "2023-07-16 23:46:24,893 - \u001b[1;32mINFO\u001b[1;0m - Extraction methods: Counter({'t5-small-finetuned': 518822, 'gpt-3.5-turbo-0613': 59911})\n",
      "100%|███████████████████████████████| 578733/578733 [00:01<00:00, 462856.80it/s]\n",
      "2023-07-16 23:46:26,148 - \u001b[1;33mWARNING\u001b[1;0m - Found 48 inconsistent comparison statuses\n",
      "2023-07-16 23:46:26,148 - \u001b[1;32mINFO\u001b[1;0m - Found 224 unique GPT comparison statuses that need relabeling\n",
      "2023-07-16 23:46:26,149 - \u001b[1;32mINFO\u001b[1;0m - Found a total of 2613 GPT comparison statuses that need relabeling\n",
      "2023-07-16 23:46:26,149 - \u001b[1;32mINFO\u001b[1;0m - Found 347 unique T5 comparison statuses that need relabeling\n",
      "2023-07-16 23:46:26,149 - \u001b[1;32mINFO\u001b[1;0m - Found a total of 518822 T5 comparison statuses that need relabeling\n",
      "2023-07-16 23:46:26,151 - \u001b[1;32mINFO\u001b[1;0m - Total number GPT's comparison groups above threshold: 0\n",
      "2023-07-16 23:46:26,151 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"\" has 393404 facts above threshold\n",
      "2023-07-16 23:46:27,310 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"resolved\" has 44817 facts above threshold\n",
      "2023-07-16 23:46:27,414 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"stable\" has 2606 facts above threshold\n",
      "2023-07-16 23:46:27,420 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"larger\" has 6008 facts above threshold\n",
      "2023-07-16 23:46:27,435 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"worsened\" has 11118 facts above threshold\n",
      "2023-07-16 23:46:27,465 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"unchanged\" has 20968 facts above threshold\n",
      "2023-07-16 23:46:27,521 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"improved\" has 27937 facts above threshold\n",
      "2023-07-16 23:46:27,593 - \u001b[1;32mINFO\u001b[1;0m - T5's comparison group \"new\" has 3968 facts above threshold\n",
      "2023-07-16 23:46:27,612 - \u001b[1;32mINFO\u001b[1;0m - Total number T5's comparison groups above threshold: 8\n",
      "2023-07-16 23:46:27,612 - \u001b[1;32mINFO\u001b[1;0m - Total number of unique facts to process: 26609\n",
      "2023-07-16 23:46:27,660 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to process: 13805\n",
      "2023-07-16 23:46:27,660 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to process:\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 1. AC\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 727. stable left lower collapse\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 1454. segmental atelectasis remains\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 2180. stable small right pneumothorax\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 2907. pneumomediastinum is much smaller\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 3633. adjacent atelectases have increased\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 4360. minimal fibrotic streaks bilaterally\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 5086. progression of opacity in right lower\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 5813. smaller degree of effusion on the left\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 6539. stable left mid lung linear atelectasis\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 7266. splenic calcified lesion on the prior CT\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 7992. stable bibasilar subsegmental atelectasis\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 8719. small right pleural effusion has increased\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 9445. rounded opacity within the right upper lobe\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 10172. progression of volume loss at the right apex\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 10898. new regions of consolidation in the left lung\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 11625. mild cardiac enlargement has further increased\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 12351. interval removal of left-sided dual-chamber ICD\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 13078. interval all development of mild pulmonary edema\n",
      "2023-07-16 23:46:27,661 - \u001b[1;32mINFO\u001b[1;0m - 13805. increasing parenchymal opacifications bilaterally\n",
      "2023-07-16 23:46:27,696 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230716_234627.jsonl\n",
      "2023-07-16 23:46:27,696 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230716_234627.jsonl\n",
      "2023-07-16 23:46:28,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-16 23:46:28,904 - \u001b[1;32mINFO\u001b[1;0m - Starting request #50\n",
      "2023-07-16 23:46:29,045 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-16 23:46:29,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #150\n",
      "2023-07-16 23:46:29,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #200\n",
      "2023-07-16 23:46:29,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #250\n",
      "2023-07-16 23:46:29,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #300\n",
      "2023-07-16 23:46:29,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #350\n",
      "2023-07-16 23:46:36,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #400\n",
      "2023-07-16 23:46:44,782 - \u001b[1;32mINFO\u001b[1;0m - Starting request #450\n",
      "2023-07-16 23:46:53,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #500\n",
      "2023-07-16 23:46:59,240 - \u001b[1;33mWARNING\u001b[1;0m - Request 26 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c6804f1517a010d6e3e5c26137a7ae87 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:46:59,586 - \u001b[1;33mWARNING\u001b[1;0m - Request 208 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d5ca088dc1ce0b22fd0355e46bdd3a6b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:46:59,938 - \u001b[1;33mWARNING\u001b[1;0m - Request 315 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d990465f4bf03da32bf99dafb266a1f9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:01,679 - \u001b[1;32mINFO\u001b[1;0m - Starting request #547\n",
      "2023-07-16 23:47:03,052 - \u001b[1;33mWARNING\u001b[1;0m - Request 191 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ed3873d60d12dd2cc6e5cdf221848a4b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:04,926 - \u001b[1;33mWARNING\u001b[1;0m - Request 82 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2cd645955ff286be4186a3afacca6af8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:08,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 414 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6818a2717a02a831a36187b9943d966 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:10,143 - \u001b[1;32mINFO\u001b[1;0m - Starting request #594\n",
      "2023-07-16 23:47:18,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #644\n",
      "2023-07-16 23:47:22,088 - \u001b[1;33mWARNING\u001b[1;0m - Request 492 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 89814c21b3bbb0e46531a84b2d31073a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16 23:47:24,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 507 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1354ef6d3b93edd797dc56ef573be044 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:27,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #692\n",
      "2023-07-16 23:47:30,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 208 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1772ca9209e62c468ec369b2b773a0f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:32,164 - \u001b[1;33mWARNING\u001b[1;0m - Request 547 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 10d29a53cf5679455f3e33ad0063b573 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:47:35,513 - \u001b[1;32mINFO\u001b[1;0m - Starting request #740\n",
      "2023-07-16 23:47:43,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #790\n",
      "2023-07-16 23:47:52,435 - \u001b[1;32mINFO\u001b[1;0m - Starting request #840\n",
      "2023-07-16 23:48:00,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #890\n",
      "2023-07-16 23:48:03,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 727 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b3ce58cc01ec39e9926b1296c0603c31 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:09,364 - \u001b[1;32mINFO\u001b[1;0m - Starting request #939\n",
      "2023-07-16 23:48:09,797 - \u001b[1;33mWARNING\u001b[1;0m - Request 764 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7b962701e0d1d8a0cfd812f3b286811 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:16,121 - \u001b[1;33mWARNING\u001b[1;0m - Request 801 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5f1e4213ae640d5db3227822a148f1c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:17,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #987\n",
      "2023-07-16 23:48:26,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1037\n",
      "2023-07-16 23:48:34,772 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1087\n",
      "2023-07-16 23:48:37,377 - \u001b[1;33mWARNING\u001b[1;0m - Request 926 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a5e3503fc5a0695dbbc2db2587dac6ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:43,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1136\n",
      "2023-07-16 23:48:44,975 - \u001b[1;33mWARNING\u001b[1;0m - Request 970 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 23541fd9ea797af0037fd2a49bc41ef7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:49,818 - \u001b[1;33mWARNING\u001b[1;0m - Request 997 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0175d4ce99a27a20e0775e6d9d95f83a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:50,423 - \u001b[1;33mWARNING\u001b[1;0m - Request 1001 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ddf912b276ab78f700b13418045e3bba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:48:51,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1183\n",
      "2023-07-16 23:49:00,180 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1233\n",
      "2023-07-16 23:49:06,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 1096 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bb1c36a17e56d3521a9f7ca33a9676f7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:49:07,179 - \u001b[1;33mWARNING\u001b[1;0m - Request 1100 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9597b2b55e4db0d11401e104757a7485 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:49:08,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1281\n",
      "2023-07-16 23:49:17,143 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1331\n",
      "2023-07-16 23:49:25,615 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1381\n",
      "2023-07-16 23:49:34,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1431\n",
      "2023-07-16 23:49:42,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1481\n",
      "2023-07-16 23:49:51,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1531\n",
      "2023-07-16 23:49:59,559 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1581\n",
      "2023-07-16 23:50:03,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 1427 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f461d082b5a8b8abc8dcb58d06876e6e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:50:06,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 1442 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1363a9a538578408f8020c43a1c3c3b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:50:08,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1629\n",
      "2023-07-16 23:50:16,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1679\n",
      "2023-07-16 23:50:25,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1729\n",
      "2023-07-16 23:50:29,376 - \u001b[1;33mWARNING\u001b[1;0m - Request 1577 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cbc20092ff4447a8683490a1ac62edf6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:50:33,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1778\n",
      "2023-07-16 23:50:37,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 1624 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c7fe5d661d9eeafa2b71636020c60bb3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:50:41,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1827\n",
      "2023-07-16 23:50:50,340 - \u001b[1;33mWARNING\u001b[1;0m - Request 1676 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f33d82edbc717ac4a9eb2f2920cb6eb4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16 23:50:50,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1877\n",
      "2023-07-16 23:50:51,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 1667 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eafcd1d75a441cf45790550fe0044fa3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:50:54,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 1727 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0c0acfd396619b9a7df41834ce3e63e3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:50:58,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1924\n",
      "2023-07-16 23:51:02,394 - \u001b[1;33mWARNING\u001b[1;0m - Request 1770 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 00426eefe0537c26dc83bfa5661a2bc1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:51:04,980 - \u001b[1;33mWARNING\u001b[1;0m - Request 1785 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4d9960970efdee7d0e65a94102b187b9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:51:07,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1972\n",
      "2023-07-16 23:51:09,160 - \u001b[1;33mWARNING\u001b[1;0m - Request 1809 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ceb33ee7794c884d0b4c2dce3c871b58 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:51:15,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2021\n",
      "2023-07-16 23:51:24,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2071\n",
      "2023-07-16 23:51:27,486 - \u001b[1;33mWARNING\u001b[1;0m - Request 1914 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de0e6784d841065e27ffa723bde94c8d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:51:29,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 210 failed with Exception \n",
      "2023-07-16 23:51:29,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 215 failed with Exception \n",
      "2023-07-16 23:51:30,714 - \u001b[1;33mWARNING\u001b[1;0m - Request 1933 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6cf7a591a3112e26960e7576c46b53e5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:51:32,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2117\n",
      "2023-07-16 23:51:41,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2167\n",
      "2023-07-16 23:51:44,965 - \u001b[1;33mWARNING\u001b[1;0m - Request 2014 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1bce328e84c43b146d0346db38f78a29 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:51:49,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2216\n",
      "2023-07-16 23:51:58,442 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2266\n",
      "2023-07-16 23:52:01,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 2110 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e9b292c8b85778e90ec9bf951b20c23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:52:06,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2315\n",
      "2023-07-16 23:52:15,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2365\n",
      "2023-07-16 23:52:23,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2415\n",
      "2023-07-16 23:52:32,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2465\n",
      "2023-07-16 23:52:40,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2515\n",
      "2023-07-16 23:52:49,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2565\n",
      "2023-07-16 23:52:57,915 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2615\n",
      "2023-07-16 23:52:58,116 - \u001b[1;33mWARNING\u001b[1;0m - Request 2437 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0be2ae89ec8d1f086dd448e69e4716fb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:53:06,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2664\n",
      "2023-07-16 23:53:14,132 - \u001b[1;33mWARNING\u001b[1;0m - Request 2294 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dc2d96b2521dff5c63da19201a6fea97 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:53:14,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2713\n",
      "2023-07-16 23:53:19,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 2209 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4db41b37d3a2d6b658620c9160011f90 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:53:23,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2762\n",
      "2023-07-16 23:53:31,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2812\n",
      "2023-07-16 23:53:32,230 - \u001b[1;33mWARNING\u001b[1;0m - Request 2638 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 808c3f022318eb91838128bf42c0e4e7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:53:40,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2861\n",
      "2023-07-16 23:53:46,155 - \u001b[1;33mWARNING\u001b[1;0m - Request 2719 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 347f1ec359cf9dd67ff97c0075678951 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:53:48,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2910\n",
      "2023-07-16 23:53:54,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 2767 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 969c1846c5c77d4a54ad3ddfd61ba361 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:53:57,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2959\n",
      "2023-07-16 23:54:05,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3009\n",
      "2023-07-16 23:54:12,071 - \u001b[1;33mWARNING\u001b[1;0m - Request 2869 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c398806aae17600f674a320cfa03f3d1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:54:14,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16 23:54:22,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3108\n",
      "2023-07-16 23:54:31,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3158\n",
      "2023-07-16 23:54:31,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 2982 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a2af9207732d1e27ab7634b6ce081a27 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:54:39,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3207\n",
      "2023-07-16 23:54:48,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3257\n",
      "2023-07-16 23:54:56,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 3130 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 71167490d783dfb7ab0c915740708011 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:54:57,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3307\n",
      "2023-07-16 23:54:57,871 - \u001b[1;33mWARNING\u001b[1;0m - Request 3135 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bcc2ab389fa6629bc12399735a73e552 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:54:58,461 - \u001b[1;33mWARNING\u001b[1;0m - Request 3139 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b1bf19b2118e65194a78230ed1d993f6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:55:05,432 - \u001b[1;33mWARNING\u001b[1;0m - Request 3179 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5a8cb04536a1cef4d0639dd59c4aade8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:55:05,526 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3354\n",
      "2023-07-16 23:55:06,466 - \u001b[1;33mWARNING\u001b[1;0m - Request 3185 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1e8dbcd232424067e10b4be8f9b1a67 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:55:12,067 - \u001b[1;33mWARNING\u001b[1;0m - Request 3218 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 68878b1e43465beab8c5c6496e669026 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:55:14,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3401\n",
      "2023-07-16 23:55:22,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3451\n",
      "2023-07-16 23:55:31,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3501\n",
      "2023-07-16 23:55:39,559 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3551\n",
      "2023-07-16 23:55:48,086 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3601\n",
      "2023-07-16 23:55:51,631 - \u001b[1;33mWARNING\u001b[1;0m - Request 3444 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ccc11afdef0e3b2f8ad57d6c860d223 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:55:56,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3650\n",
      "2023-07-16 23:56:05,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 3523 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2393a1a5358ee30ea68b79d32f866700 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:56:05,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3700\n",
      "2023-07-16 23:56:13,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3749\n",
      "2023-07-16 23:56:22,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3799\n",
      "2023-07-16 23:56:30,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3849\n",
      "2023-07-16 23:56:36,620 - \u001b[1;33mWARNING\u001b[1;0m - Request 3706 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b80be593dfc2754b5e0ac43980339cc1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:56:39,209 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3898\n",
      "2023-07-16 23:56:45,570 - \u001b[1;33mWARNING\u001b[1;0m - Request 3759 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b7ee4442e456644bb6532b3efcc9ad38 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:56:46,251 - \u001b[1;33mWARNING\u001b[1;0m - Request 3763 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c1e3874c61aff4c23e3bcaac77c8878a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:56:47,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3946\n",
      "2023-07-16 23:56:48,297 - \u001b[1;33mWARNING\u001b[1;0m - Request 3775 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11c8f441bc54ae0211929233c9aed8fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:56:55,272 - \u001b[1;33mWARNING\u001b[1;0m - Request 3816 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e1e6ef032f55089bdf9c9d4b5e8c6d37 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:56:56,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3994\n",
      "2023-07-16 23:57:00,752 - \u001b[1;33mWARNING\u001b[1;0m - Request 3848 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6e225f0da63f8deaab53026fa79781a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:57:04,756 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4043\n",
      "2023-07-16 23:57:08,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 3893 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f5d41fb4855714c8604441b232f00d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:57:13,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4092\n",
      "2023-07-16 23:57:21,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4142\n",
      "2023-07-16 23:57:23,390 - \u001b[1;33mWARNING\u001b[1;0m - Request 3977 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b13289c19ce87958a99b1e37f1d30122 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16 23:57:30,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4191\n",
      "2023-07-16 23:57:38,862 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4241\n",
      "2023-07-16 23:57:47,379 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4291\n",
      "2023-07-16 23:57:54,407 - \u001b[1;33mWARNING\u001b[1;0m - Request 4155 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cc1abeb6d21bc48dc9c47e5eb1f756af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:57:55,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4340\n",
      "2023-07-16 23:58:04,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4390\n",
      "2023-07-16 23:58:06,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 4225 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8192adb0430ec98d1484c5a2cc3a976b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:58:12,653 - \u001b[1;33mWARNING\u001b[1;0m - Request 4262 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2dd04743ecd35e4c768140fba4b4ab92 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:58:12,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4262\n",
      "2023-07-16 23:58:21,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4488\n",
      "2023-07-16 23:58:23,560 - \u001b[1;33mWARNING\u001b[1;0m - Request 4326 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a07bc4e74edbf35849df62dd7796d893 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:58:30,005 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4537\n",
      "2023-07-16 23:58:38,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4587\n",
      "2023-07-16 23:58:47,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4637\n",
      "2023-07-16 23:58:55,629 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4687\n",
      "2023-07-16 23:59:02,432 - \u001b[1;33mWARNING\u001b[1;0m - Request 4550 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c03f25e819c9a3d773e4ad904e3c1257 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:59:04,163 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4736\n",
      "2023-07-16 23:59:12,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4786\n",
      "2023-07-16 23:59:20,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 4654 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6a3201d72f8b07b9bc8cf941430c1f26 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:59:20,392 - \u001b[1;33mWARNING\u001b[1;0m - Request 4655 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fc11236eeb20d2bf35f24b8e04f526a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:59:21,234 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4834\n",
      "2023-07-16 23:59:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3097 failed with Exception \n",
      "2023-07-16 23:59:28,053 - \u001b[1;33mWARNING\u001b[1;0m - Request 4700 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 54f35fc17809cc4176ac5d1e149378d2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:59:29,778 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4882\n",
      "2023-07-16 23:59:30,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3151 failed with Exception \n",
      "2023-07-16 23:59:35,593 - \u001b[1;33mWARNING\u001b[1;0m - Request 4743 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 612d5cc69f936c04a77761c81624f783 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-16 23:59:38,297 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4930\n",
      "2023-07-16 23:59:46,839 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4980\n",
      "2023-07-16 23:59:55,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5030\n",
      "2023-07-17 00:00:03,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5080\n",
      "2023-07-17 00:00:07,903 - \u001b[1;33mWARNING\u001b[1;0m - Request 4925 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7acc7b4c0a8bebc7367ab791dc053ca0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:00:12,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5129\n",
      "2023-07-17 00:00:20,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5179\n",
      "2023-07-17 00:00:24,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 5024 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cbe64a8463e941648e6940679720748e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:00:25,760 - \u001b[1;33mWARNING\u001b[1;0m - Request 5031 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3cdfd9256bfd2d28abc63699efd5804 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:00:29,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5227\n",
      "2023-07-17 00:00:38,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5277\n",
      "2023-07-17 00:00:46,608 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5327\n",
      "2023-07-17 00:00:55,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5377\n",
      "2023-07-17 00:00:58,518 - \u001b[1;33mWARNING\u001b[1;0m - Request 5220 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1610d20c64c2ae76fe21462122ecdf80 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:00:59,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 5228 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d9c47b786161e2d00f712637ec01f403 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:01:03,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5425\n",
      "2023-07-17 00:01:04,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 5256 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e14f0c7f3d01eba081591569b5c0fa62 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:01:12,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5474\n",
      "2023-07-17 00:01:18,562 - \u001b[1;33mWARNING\u001b[1;0m - Request 5337 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b722d9e2c059735800da68bd1876cc58 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:01:20,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5523\n",
      "2023-07-17 00:01:29,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5573\n",
      "2023-07-17 00:01:34,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 5428 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d8dc6686a671f0dff4b0403a66e1cd8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:01:37,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5622\n",
      "2023-07-17 00:01:41,611 - \u001b[1;33mWARNING\u001b[1;0m - Request 5469 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d0e5c59782b4ff1094c542d909928b24 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:01:44,353 - \u001b[1;33mWARNING\u001b[1;0m - Request 5485 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b762c7187b66e19b93a0cf5e3cd48586 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:01:46,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5670\n",
      "2023-07-17 00:01:54,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5720\n",
      "2023-07-17 00:01:59,518 - \u001b[1;33mWARNING\u001b[1;0m - Request 5573 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a3e107bdf0ec64da68317e25c33cd44e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:02:03,459 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5769\n",
      "2023-07-17 00:02:07,244 - \u001b[1;33mWARNING\u001b[1;0m - Request 5616 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a703ca0064d6e1b3d7d6d35811afce13 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:02:11,996 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5818\n",
      "2023-07-17 00:02:20,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5868\n",
      "2023-07-17 00:02:29,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5918\n",
      "2023-07-17 00:02:29,473 - \u001b[1;33mWARNING\u001b[1;0m - Request 5745 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e08cbab752987389a80a29e900fc7722 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:02:35,223 - \u001b[1;33mWARNING\u001b[1;0m - Request 5778 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3336b68e0d3506732b59f7164e9f7df6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:02:37,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5966\n",
      "2023-07-17 00:02:46,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6016\n",
      "2023-07-17 00:02:48,715 - \u001b[1;33mWARNING\u001b[1;0m - Request 5856 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9729f2bffe891215984d968e077df0c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:02:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4306 failed with Exception \n",
      "2023-07-17 00:02:54,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6064\n",
      "2023-07-17 00:03:03,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6114\n",
      "2023-07-17 00:03:11,871 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6164\n",
      "2023-07-17 00:03:20,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6214\n",
      "2023-07-17 00:03:28,941 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6264\n",
      "2023-07-17 00:03:37,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6314\n",
      "2023-07-17 00:03:40,389 - \u001b[1;33mWARNING\u001b[1;0m - Request 6154 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40f4d2e4207bd297cdec248d5b398275 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:03:46,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6363\n",
      "2023-07-17 00:03:54,442 - \u001b[1;33mWARNING\u001b[1;0m - Request 6236 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 07dffc397968ce1e0d30e86c99ca7dac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:03:54,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6413\n",
      "2023-07-17 00:04:03,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6462\n",
      "2023-07-17 00:04:04,997 - \u001b[1;33mWARNING\u001b[1;0m - Request 6298 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2df8c3aa1a4f849e34b25f81b87b1f0b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:04:10,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 6332 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3f0ccbe65ae43bc2e81c2af3d488babe in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:04:11,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6510\n",
      "2023-07-17 00:04:20,215 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6560\n",
      "2023-07-17 00:04:28,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6610\n",
      "2023-07-17 00:04:37,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6660\n",
      "2023-07-17 00:04:37,965 - \u001b[1;33mWARNING\u001b[1;0m - Request 6488 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53fd6451eec504436ea44841aafb1906 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:04:38,978 - \u001b[1;33mWARNING\u001b[1;0m - Request 6494 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e961efb8037aa57c690ef36c4b52093f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:04:45,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6708\n",
      "2023-07-17 00:04:47,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 6540 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0972a847615923417a48ff143a4912f1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:04:47,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 6542 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8342acaf4d0700969659f1444f473e57 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:04:51,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 6563 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c1e5ed281e4b04f75563ccf781df3129 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:04:54,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6755\n",
      "2023-07-17 00:05:03,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6805\n",
      "2023-07-17 00:05:09,937 - \u001b[1;33mWARNING\u001b[1;0m - Request 6672 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13634f9c41a0b8d61640f45b91064bf8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:05:11,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6854\n",
      "2023-07-17 00:05:12,244 - \u001b[1;33mWARNING\u001b[1;0m - Request 6685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f16e0641f954ba44fe17f7a4d09d0187 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:05:14,938 - \u001b[1;33mWARNING\u001b[1;0m - Request 6701 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6cbe5e7cca1872df50b10408577ce3bf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:05:20,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6902\n",
      "2023-07-17 00:05:28,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6952\n",
      "2023-07-17 00:05:29,446 - \u001b[1;33mWARNING\u001b[1;0m - Request 6783 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b930030f9b070943b2471c3e050342a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:05:37,223 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7001\n",
      "2023-07-17 00:05:37,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5271 failed with Exception \n",
      "2023-07-17 00:05:45,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7050\n",
      "2023-07-17 00:05:50,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 6904 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5f37abd988ad80b00aa872d523b55ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:05:54,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7099\n",
      "2023-07-17 00:05:58,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 6947 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b62fb35ea3db0c206151a633901e880c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:06:02,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7148\n",
      "2023-07-17 00:06:11,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7198\n",
      "2023-07-17 00:06:19,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7248\n",
      "2023-07-17 00:06:28,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7298\n",
      "2023-07-17 00:06:37,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7348\n",
      "2023-07-17 00:06:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5655 failed with Exception \n",
      "2023-07-17 00:06:45,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7397\n",
      "2023-07-17 00:06:54,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7447\n",
      "2023-07-17 00:06:59,606 - \u001b[1;33mWARNING\u001b[1;0m - Request 7303 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4137443e47584cb714887c8afe381c9d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:07:02,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7496\n",
      "2023-07-17 00:07:09,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5801 failed with Exception \n",
      "2023-07-17 00:07:11,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7545\n",
      "2023-07-17 00:07:19,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7595\n",
      "2023-07-17 00:07:28,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7645\n",
      "2023-07-17 00:07:31,808 - \u001b[1;33mWARNING\u001b[1;0m - Request 7489 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 70864fe58391884719b260164a2b8902 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:07:35,086 - \u001b[1;33mWARNING\u001b[1;0m - Request 7508 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5be9a5f7992a37a09e6ea661137114a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:07:37,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7693\n",
      "2023-07-17 00:07:45,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7743\n",
      "2023-07-17 00:07:54,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7793\n",
      "2023-07-17 00:07:57,719 - \u001b[1;33mWARNING\u001b[1;0m - Request 7638 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8498df33cf070c93b9a204f2f9f0a571 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:08:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6104 failed with Exception \n",
      "2023-07-17 00:08:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6106 failed with Exception \n",
      "2023-07-17 00:08:02,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6104\n",
      "2023-07-17 00:08:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6116 failed with Exception \n",
      "2023-07-17 00:08:11,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7889\n",
      "2023-07-17 00:08:19,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7939\n",
      "2023-07-17 00:08:28,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7989\n",
      "2023-07-17 00:08:33,354 - \u001b[1;33mWARNING\u001b[1;0m - Request 7842 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f7c5afba60f230ec2b17d1354591b02f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:08:36,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8038\n",
      "2023-07-17 00:08:39,015 - \u001b[1;33mWARNING\u001b[1;0m - Request 7874 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0deef538761fda6eb626736da5bfb54 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:08:45,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8087\n",
      "2023-07-17 00:08:54,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8137\n",
      "2023-07-17 00:09:02,111 - \u001b[1;33mWARNING\u001b[1;0m - Request 8009 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d71e90aab75ed36cfcc3abe8f644a20c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:09:02,711 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8186\n",
      "2023-07-17 00:09:05,651 - \u001b[1;33mWARNING\u001b[1;0m - Request 8029 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 108ce9e6a8dddb285181ffad1db48c3e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:09:11,268 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8235\n",
      "2023-07-17 00:09:19,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:09:20,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 8117 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d8edeae79d046756aab0999ec35beb3a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:09:24,219 - \u001b[1;33mWARNING\u001b[1;0m - Request 8136 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 711c89c1a957949018ee887568061a3d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:09:28,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8333\n",
      "2023-07-17 00:09:36,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8383\n",
      "2023-07-17 00:09:45,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8433\n",
      "2023-07-17 00:09:54,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8483\n",
      "2023-07-17 00:10:00,179 - \u001b[1;33mWARNING\u001b[1;0m - Request 8342 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 85d7d25ec45ebfc68f396762e2f31e9b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:10:02,064 - \u001b[1;33mWARNING\u001b[1;0m - Request 8353 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d9828edf777f70cb60438dde5471b207 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:10:02,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8531\n",
      "2023-07-17 00:10:11,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8581\n",
      "2023-07-17 00:10:19,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8631\n",
      "2023-07-17 00:10:27,754 - \u001b[1;33mWARNING\u001b[1;0m - Request 8503 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8bc158cdf612c303805b96271aedc6d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:10:28,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8680\n",
      "2023-07-17 00:10:36,152 - \u001b[1;33mWARNING\u001b[1;0m - Request 8550 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 517f867279f9e661f98c947bffe903cb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:10:36,940 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8729\n",
      "2023-07-17 00:10:45,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8779\n",
      "2023-07-17 00:10:54,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8829\n",
      "2023-07-17 00:10:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7095 failed with Exception \n",
      "2023-07-17 00:11:02,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8878\n",
      "2023-07-17 00:11:05,259 - \u001b[1;33mWARNING\u001b[1;0m - Request 8719 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 57ed310f768808008b6580097c90f9c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:11:11,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8927\n",
      "2023-07-17 00:11:19,855 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8977\n",
      "2023-07-17 00:11:28,442 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9027\n",
      "2023-07-17 00:11:37,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9077\n",
      "2023-07-17 00:11:45,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9127\n",
      "2023-07-17 00:11:54,163 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9177\n",
      "2023-07-17 00:11:54,703 - \u001b[1;33mWARNING\u001b[1;0m - Request 9004 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 85bbafdd5ff24dd09f81b4cc0348a63c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:02,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9226\n",
      "2023-07-17 00:12:03,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 9053 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d260e1673a7a799ec362443fc9e646fe in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:10,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 9098 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 84227fa9b5e0863fd73440cd00ec4fc6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:11,312 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9274\n",
      "2023-07-17 00:12:17,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 9138 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dda3b55bf4ac5582601d5a83a8f2bf13 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:19,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9323\n",
      "2023-07-17 00:12:25,154 - \u001b[1;33mWARNING\u001b[1;0m - Request 9181 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID adccb29a440bcc123832f9eaf0efd72c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:28,448 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9372\n",
      "2023-07-17 00:12:30,537 - \u001b[1;33mWARNING\u001b[1;0m - Request 9212 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d0982237b2fe8dbfc35ead5d751047ea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:37,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9421\n",
      "2023-07-17 00:12:45,307 - \u001b[1;33mWARNING\u001b[1;0m - Request 9296 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 261b6ad493406bb25f1f42a69fcc3626 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:12:45,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9296\n",
      "2023-07-17 00:12:54,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9520\n",
      "2023-07-17 00:13:02,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9570\n",
      "2023-07-17 00:13:11,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9620\n",
      "2023-07-17 00:13:19,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9670\n",
      "2023-07-17 00:13:28,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9720\n",
      "2023-07-17 00:13:30,398 - \u001b[1;33mWARNING\u001b[1;0m - Request 9555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c089e1699b152a6048cc3b9829a469ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:13:31,424 - \u001b[1;33mWARNING\u001b[1;0m - Request 9561 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 24b748bb679a907632b674f75a815869 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:13:37,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9768\n",
      "2023-07-17 00:13:45,344 - \u001b[1;33mWARNING\u001b[1;0m - Request 9642 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 424ecfe65d818e3c6af39ceef59a2a3c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:13:45,417 - \u001b[1;33mWARNING\u001b[1;0m - Request 9541 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d49cf677812fa37af0763fb314bc020d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:13:45,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 9644 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd181cc9368011e187da2bcf0f64eb50 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:13:45,725 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9541\n",
      "2023-07-17 00:13:54,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9865\n",
      "2023-07-17 00:14:02,861 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9915\n",
      "2023-07-17 00:14:05,819 - \u001b[1;33mWARNING\u001b[1;0m - Request 9759 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e835a84741e6c9a5d6cf5889e6e7cb67 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:14:07,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8210 failed with Exception \n",
      "2023-07-17 00:14:11,435 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9963\n",
      "2023-07-17 00:14:16,357 - \u001b[1;33mWARNING\u001b[1;0m - Request 9817 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2591f8a22aaca4dcac23a98222491234 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:14:20,013 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10012\n",
      "2023-07-17 00:14:24,756 - \u001b[1;33mWARNING\u001b[1;0m - Request 9865 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4cf1a3b045ded0c58f5bdab37406c236 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:14:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8324 failed with Exception \n",
      "2023-07-17 00:14:28,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10060\n",
      "2023-07-17 00:14:37,160 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10110\n",
      "2023-07-17 00:14:38,925 - \u001b[1;33mWARNING\u001b[1;0m - Request 9947 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2cabd3d97730b2c29af7d4081b6e3a4a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:14:45,569 - \u001b[1;33mWARNING\u001b[1;0m - Request 9980 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 835649dbd46969f475b76088d9649663 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:14:45,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10159\n",
      "2023-07-17 00:14:50,645 - \u001b[1;33mWARNING\u001b[1;0m - Request 10014 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff1252eafb81c213543c1f25ad8f1a29 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:14:54,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10207\n",
      "2023-07-17 00:15:00,383 - \u001b[1;33mWARNING\u001b[1;0m - Request 10068 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9ed4c3aa78aea5b6765ab07b38a4d3c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:15:02,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10256\n",
      "2023-07-17 00:15:07,539 - \u001b[1;33mWARNING\u001b[1;0m - Request 10111 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 14bb01ba38b569e242cb87bf3bf92de1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:15:11,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10305\n",
      "2023-07-17 00:15:20,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10355\n",
      "2023-07-17 00:15:28,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10405\n",
      "2023-07-17 00:15:37,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10455\n",
      "2023-07-17 00:15:45,816 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10505\n",
      "2023-07-17 00:15:47,230 - \u001b[1;33mWARNING\u001b[1;0m - Request 10331 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1143c064b8337e7fbc41b72f2192df86 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:15:54,399 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10554\n",
      "2023-07-17 00:16:03,005 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10604\n",
      "2023-07-17 00:16:11,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10654\n",
      "2023-07-17 00:16:17,753 - \u001b[1;33mWARNING\u001b[1;0m - Request 10331 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bfa107456935d92429977ba1fe47d1c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:16:20,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10703\n",
      "2023-07-17 00:16:28,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10753\n",
      "2023-07-17 00:16:31,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 10592 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f78a716f41b4095f0bcad9e03c89bcb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:16:35,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 10617 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50483f655d3e8f7dc9a12dcc019006e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:16:35,608 - \u001b[1;33mWARNING\u001b[1;0m - Request 10618 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5065db25d61cde611c3dba4e61117c45 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:16:37,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10800\n",
      "2023-07-17 00:16:40,488 - \u001b[1;33mWARNING\u001b[1;0m - Request 10646 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 388e3c835cbeb128621563c3b6e1e7c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:16:41,648 - \u001b[1;33mWARNING\u001b[1;0m - Request 10653 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bc474fdad09c70b8e1d459956324b02e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:16:45,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10848\n",
      "2023-07-17 00:16:54,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10898\n",
      "2023-07-17 00:16:56,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9188 failed with Exception \n",
      "2023-07-17 00:17:03,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10947\n",
      "2023-07-17 00:17:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9240 failed with Exception \n",
      "2023-07-17 00:17:11,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10996\n",
      "2023-07-17 00:17:13,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 10834 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eb6c973e66d2608ce709f783d34b9254 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:17:20,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11045\n",
      "2023-07-17 00:17:28,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 10920 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 68ffb7c0879877cf1f5a2ce0eb4525be in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:17:28,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11095\n",
      "2023-07-17 00:17:37,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11144\n",
      "2023-07-17 00:17:38,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 10975 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8599810c3a36a7bfe643d6a1ffc6618c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:17:43,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 11003 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c897937817188145266f05a3eadd8174 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:17:46,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11192\n",
      "2023-07-17 00:17:47,782 - \u001b[1;33mWARNING\u001b[1;0m - Request 11029 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f34a600c91799d6e9a31a454ce4d73d2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:17:54,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11241\n",
      "2023-07-17 00:17:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9539 failed with Exception \n",
      "2023-07-17 00:18:03,290 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11290\n",
      "2023-07-17 00:18:11,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11340\n",
      "2023-07-17 00:18:15,618 - \u001b[1;33mWARNING\u001b[1;0m - Request 11188 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID afd949c3eb8185f58c588c04d6bde7c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:18:20,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11389\n",
      "2023-07-17 00:18:25,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 11244 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 723e02b0d1ba37e34a9dd526b9ff4567 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:18:29,097 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11438\n",
      "2023-07-17 00:18:37,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11488\n",
      "2023-07-17 00:18:46,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11538\n",
      "2023-07-17 00:18:54,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11588\n",
      "2023-07-17 00:19:03,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11638\n",
      "2023-07-17 00:19:07,583 - \u001b[1;33mWARNING\u001b[1;0m - Request 11486 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7fafdfbdadd5c2a7ef325827b2643d67 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:19:08,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 11489 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ef98fc33acaf5a55ef50bd6f941f020 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:19:12,031 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11686\n",
      "2023-07-17 00:19:20,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11736\n",
      "2023-07-17 00:19:29,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11786\n",
      "2023-07-17 00:19:37,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11836\n",
      "2023-07-17 00:19:46,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11886\n",
      "2023-07-17 00:19:55,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11936\n",
      "2023-07-17 00:19:55,992 - \u001b[1;33mWARNING\u001b[1;0m - Request 11677 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09ceabc50f2f6cae80819e196ba4ab03 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:19:58,119 - \u001b[1;33mWARNING\u001b[1;0m - Request 11185 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b83722364277f7fab4b5e46db16b842a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:19:58,754 - \u001b[1;33mWARNING\u001b[1;0m - Request 11782 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7d9d4ab3b3bc9bc4a44eb7384bed3663 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:20:03,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11983\n",
      "2023-07-17 00:20:12,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12033\n",
      "2023-07-17 00:20:15,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 11880 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7f6636a25551899f9096c811cbed88c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:20:16,432 - \u001b[1;33mWARNING\u001b[1;0m - Request 11568 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-17 00:20:20,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12081\n",
      "2023-07-17 00:20:29,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12131\n",
      "2023-07-17 00:20:38,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12181\n",
      "2023-07-17 00:20:44,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 11792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 084b499e4b00086875b861b22884617f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:20:45,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 11839 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6b9f88b2e5df19bfa95843e1408391a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:20:46,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12229\n",
      "2023-07-17 00:20:47,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 12060 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a57c1de34cd57b830ba95bfd0e81d91 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:20:55,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12278\n",
      "2023-07-17 00:20:57,238 - \u001b[1;33mWARNING\u001b[1;0m - Request 11678 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 208b3bb19ba1ad9d75614a697171078a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:21:03,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12327\n",
      "2023-07-17 00:21:10,851 - \u001b[1;33mWARNING\u001b[1;0m - Request 12196 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID faa4d2ed3564986444eafe45c3627577 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:21:12,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12376\n",
      "2023-07-17 00:21:14,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 12215 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4d7c0ce60d41a72a9b75093df7413ddb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:21:21,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12425\n",
      "2023-07-17 00:21:29,648 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12475\n",
      "2023-07-17 00:21:30,898 - \u001b[1;33mWARNING\u001b[1;0m - Request 12308 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6db9341a95747bdb41ddfe7b923a6675 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:21:38,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12524\n",
      "2023-07-17 00:21:46,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12574\n",
      "2023-07-17 00:21:55,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12624\n",
      "2023-07-17 00:21:59,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 12470 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 047e375a67377a473d2cf82d37f3ab1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:22:04,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12673\n",
      "2023-07-17 00:22:05,356 - \u001b[1;33mWARNING\u001b[1;0m - Request 12506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5fb0a50d2dff9aaf27eb516a7858207 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:22:12,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12722\n",
      "2023-07-17 00:22:21,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12772\n",
      "2023-07-17 00:22:29,858 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12822\n",
      "2023-07-17 00:22:37,509 - \u001b[1;33mWARNING\u001b[1;0m - Request 11317 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-17 00:22:37,683 - \u001b[1;33mWARNING\u001b[1;0m - Request 12692 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f1ff8d3859a3674bedad763853ddd06 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:22:38,499 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12870\n",
      "2023-07-17 00:22:38,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 12697 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 638117fbcd166b366a4d70834ddeb223 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:22:47,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12919\n",
      "2023-07-17 00:22:55,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12969\n",
      "2023-07-17 00:23:04,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13019\n",
      "2023-07-17 00:23:12,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13069\n",
      "2023-07-17 00:23:18,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 12928 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2bb5a669b7d26b697352cb6a31d49fbc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:23:21,519 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13118\n",
      "2023-07-17 00:23:30,112 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13168\n",
      "2023-07-17 00:23:33,695 - \u001b[1;33mWARNING\u001b[1;0m - Request 13014 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d5511d4679bc287141a6969e6512d20 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:23:35,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 13025 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6955efd6c3f2ac663d881e082a613553 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:23:38,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13216\n",
      "2023-07-17 00:23:47,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13266\n",
      "2023-07-17 00:23:47,628 - \u001b[1;33mWARNING\u001b[1;0m - Request 13095 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID febe726af6de924d4fb3775258dd6739 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:23:55,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13315\n",
      "2023-07-17 00:23:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11596 failed with Exception \n",
      "2023-07-17 00:24:03,561 - \u001b[1;33mWARNING\u001b[1;0m - Request 13186 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 24850d51ddf517919980e045dae65b50 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:24:04,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13363\n",
      "2023-07-17 00:24:13,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13413\n",
      "2023-07-17 00:24:21,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13463\n",
      "2023-07-17 00:24:30,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13513\n",
      "2023-07-17 00:24:38,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13563\n",
      "2023-07-17 00:24:47,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-17 00:24:56,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13663\n",
      "2023-07-17 00:25:04,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13713\n",
      "2023-07-17 00:25:08,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 13559 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 949a7657ed45d8ae5e7a4d1c111253a1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:25:13,508 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13762\n",
      "2023-07-17 00:25:13,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 13588 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25efa53f1ce0adeec5d84404ad8956db in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:25:15,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 13597 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a3592c730f6244e6f7e8fdadada4bad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:25:18,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12062 failed with Exception \n",
      "2023-07-17 00:25:34,413 - \u001b[1;33mWARNING\u001b[1;0m - Request 13709 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eb65eb7823c8d0433aa176c8ae59b72d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-17 00:26:03,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12320 failed with Exception \n",
      "2023-07-17 00:26:36,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12509 failed with Exception \n",
      "2023-07-17 00:26:36,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12512 failed with Exception \n",
      "2023-07-17 00:27:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12670 failed with Exception \n",
      "2023-07-17 00:27:04,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12670\n",
      "2023-07-17 00:28:11,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 13060 failed with Exception \n",
      "2023-07-17 00:28:51,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13287 failed with Exception \n",
      "2023-07-17 00:28:52,066 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230716_234627.jsonl\n",
      "2023-07-17 00:28:52,069 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230716_234627.jsonl\n",
      "2023-07-17 00:28:52,340 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...arger\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 2, \"total_tokens\": 206}}, {\"sentence\": \"heart similar to 7\"}] for sentence \"heart similar to 7\": Could not parse output: larger\n",
      "2023-07-17 00:28:52,340 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...you please provide\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 200, \"completion_tokens\": 20, \"total_tokens\": 220}}, {\"sentence\": \"AC\"}] for sentence \"AC\": GPT is acting weird: I'm sorry, but I'm not sure what \"AC\" refers to. Could you please provide\n",
      "2023-07-17 00:28:52,340 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...port\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 202, \"completion_tokens\": 20, \"total_tokens\": 222}}, {\"sentence\": \"CT with contrast\"}] for sentence \"CT with contrast\": GPT is acting weird: I'm sorry, but I'm unable to generate a response without a specific statement from the CT report\n",
      "2023-07-17 00:28:52,341 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 203, \"completion_tokens\": 3, \"total_tokens\": 206}}, {\"sentence\": \"comparison to prior exam\"}] for sentence \"comparison to prior exam\": Could not parse output: unclear comparison\n",
      "2023-07-17 00:28:52,341 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...need\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 201, \"completion_tokens\": 20, \"total_tokens\": 221}}, {\"sentence\": \"good inspiration\"}] for sentence \"good inspiration\": Could not parse output: Thank you! I'm glad I could provide some inspiration. If you have any specific questions or need\n",
      "2023-07-17 00:28:52,341 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso... \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 205, \"completion_tokens\": 20, \"total_tokens\": 225}}, {\"sentence\": \"findings of sarcoidosis\"}] for sentence \"findings of sarcoidosis\": GPT is acting weird: I'm sorry, but I cannot generate a comparison category for the given statement \"findings of sarc\n",
      "2023-07-17 00:28:52,341 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...please provide\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 200, \"completion_tokens\": 20, \"total_tokens\": 220}}, {\"sentence\": \"change\"}] for sentence \"change\": GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"change\". Could you please provide\n",
      "2023-07-17 00:28:52,341 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 15, \"total_tokens\": 219}}, {\"sentence\": \"removal of other lines\"}] for sentence \"removal of other lines\": Could not parse output: right pleural effusion similar in size\n",
      "12. stable/unchanged\n",
      "2023-07-17 00:28:52,342 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...\"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 203, \"completion_tokens\": 20, \"total_tokens\": 223}}, {\"sentence\": \"combination of all three\"}] for sentence \"combination of all three\": GPT is acting weird: I'm sorry, but I can only provide one category at a time. Could you please provide a\n",
      "2023-07-17 00:28:52,343 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...inish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"lordotic views if possible\"}] for sentence \"lordotic views if possible\": GPT is acting weird: I apologize, but I am unable to provide lordotic views as I am a text-based AI model\n",
      "2023-07-17 00:28:52,344 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...nish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"need to advance any further\"}] for sentence \"need to advance any further\": GPT is acting weird: I'm sorry, but I'm not able to generate the desired output without additional information. Could you\n",
      "2023-07-17 00:28:52,346 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...inish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 7, \"total_tokens\": 211}}, {\"sentence\": \"opacity more apparent than on\"}] for sentence \"opacity more apparent than on\": Could not parse output: previous study\n",
      "4. worsened\n",
      "2023-07-17 00:28:52,348 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso..._reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"comparison with old radiographs\"}] for sentence \"comparison with old radiographs\": GPT is acting weird: Please provide the statement from the chest X-ray report for which you would like to determine the comparison category\n",
      "2023-07-17 00:28:52,351 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...eason\": \"length\"}], \"usage\": {\"prompt_tokens\": 206, \"completion_tokens\": 20, \"total_tokens\": 226}}, {\"sentence\": \"pneumonia into approved otherwise\"}] for sentence \"pneumonia into approved otherwise\": GPT is acting weird: I'm sorry, but I'm not sure I understand the statement \"pneumonia into approved\n",
      "2023-07-17 00:28:52,351 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...eason\": \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"possible components of hemorrhage\"}] for sentence \"possible components of hemorrhage\": Unexpected category: Hemoglobin\n",
      "2023-07-17 00:28:52,351 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso..._reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 205, \"completion_tokens\": 14, \"total_tokens\": 219}}, {\"sentence\": \"request to include the upper neck\"}] for sentence \"request to include the upper neck\": GPT is acting weird: I apologize, but I'm not able to assist with that request.\n",
      "2023-07-17 00:28:52,352 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...ason\": \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"comparison to previous radiographs\"}] for sentence \"comparison to previous radiographs\": GPT is acting weird: I apologize for the confusion. Thank you for providing the clarification. Here is the revised response:\n",
      "\n",
      "right\n",
      "2023-07-17 00:28:52,356 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...n\": \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"assuming it is clinically significant\"}] for sentence \"assuming it is clinically significant\": Could not parse output: If the statement is assumed to be clinically significant, the category would remain the same. However, if\n",
      "2023-07-17 00:28:52,363 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso... \"length\"}], \"usage\": {\"prompt_tokens\": 206, \"completion_tokens\": 20, \"total_tokens\": 226}}, {\"sentence\": \"characterization of this new abnormality\"}] for sentence \"characterization of this new abnormality\": Could not parse output: To provide a characterization of the new abnormality, I would need more information about the specific abnormality\n",
      "2023-07-17 00:28:52,363 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso... \"length\"}], \"usage\": {\"prompt_tokens\": 204, \"completion_tokens\": 20, \"total_tokens\": 224}}, {\"sentence\": \"comparison extended to chest examination\"}] for sentence \"comparison extended to chest examination\": GPT is acting weird: I apologize for the confusion. Here are some examples of statements related to the chest examination:\n",
      "\n",
      "1.\n",
      "2023-07-17 00:28:52,367 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...length\"}], \"usage\": {\"prompt_tokens\": 205, \"completion_tokens\": 20, \"total_tokens\": 225}}, {\"sentence\": \"comparison extended to a chest examination\"}] for sentence \"comparison extended to a chest examination\": GPT is acting weird: I'm sorry, but I can only provide a comparison category for a statement extracted from a chest X\n",
      "2023-07-17 00:28:52,373 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...ngth\"}], \"usage\": {\"prompt_tokens\": 207, \"completion_tokens\": 20, \"total_tokens\": 227}}, {\"sentence\": \"consideration of patient's age and condition\"}] for sentence \"consideration of patient's age and condition\": Could not parse output: Based on the given statement, it is not possible to determine a specific comparison category. The statement does\n",
      "2023-07-17 00:28:52,375 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a statement extracted from a chest X-ray report, output a compariso...gth\"}], \"usage\": {\"prompt_tokens\": 206, \"completion_tokens\": 20, \"total_tokens\": 226}}, {\"sentence\": \"comparison extended to a chest CT examination\"}] for sentence \"comparison extended to a chest CT examination\": Could not parse output: Since the statement mentions a chest CT examination, the comparison category would be \"no comparison\" (0\n",
      "2023-07-17 00:28:52,385 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-07-17 00:28:52,390 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 13782 of 13805 API responses.\n",
      "                    23 of 13805 API responses could not be processed.\n",
      "                    Saving processed sentences to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_comparisons__part1.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_comparisons_from_facts_with_openai.py \\\n",
    "    --integrated_fact_metadata_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\" \\\n",
    "    --sampling_threshold 2000 \\\n",
    "    --offset 0 \\\n",
    "    --num_sentences 14000 \\\n",
    "    --max_requests_per_minute 3000 \\\n",
    "    --max_tokens_per_minute 80000 \\\n",
    "    --max_tokens_per_request 20 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_1\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__part1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6f9962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_comparisons__part1.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f0adaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13977"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0cb3f5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'sentence': 'improvement of atelectasis in the left lower lobe'},\n",
       "  'parsed_response': 'improved'},\n",
       " {'metadata': {'sentence': 'improvement of severe distention of the esophagus'},\n",
       "  'parsed_response': 'improved'},\n",
       " {'metadata': {'sentence': 'improvement to the bilateral lower lobe opacities'},\n",
       "  'parsed_response': 'improved'},\n",
       " {'metadata': {'sentence': 'increase in bilateral mid to lower lung opacities'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'improving pulmonary edema in the right hemithorax'},\n",
       "  'parsed_response': 'improved'},\n",
       " {'metadata': {'sentence': 'increase in extent of the right basal atelectasis'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increase in number of bilateral pulmonary nodules'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increase in the extent of left pleural thickening'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'unlikely to represent asymmetric pulmonary edema'},\n",
       "  'parsed_response': 'no comparison'},\n",
       " {'metadata': {'sentence': 'increase of loss of volume in the left lower lobe'},\n",
       "  'parsed_response': 'decrease'},\n",
       " {'metadata': {'sentence': 'increased bibasilar atelectasis since prior study'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increase small to moderate right pleural effusion'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased caliber of previously normal size heart'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increased extent of left retrocardiac atelectasis'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increased heart size compared to previous studies'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased compared to the study from 3 days prior'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increased left pleural effusion compared to study'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased left pleural effusion since prior study'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased opacity in the right lung base medially'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increased severity of interstitial fluid overload'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased size of moderate right pleural effusion'},\n",
       "  'parsed_response': 'larger'},\n",
       " {'metadata': {'sentence': 'increased pulmonary edema on the right from prior'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased size of small right apical pneumothorax'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increased small-to-moderate left pleural effusion'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increasing areas of atelectasis at left lung base'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing areas of atelectasis at the lung bases'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing amount of right-sided pleural effusion'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'worse airspace opacities in the left lung base'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing areas of left retrocardiac atelectasis'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing atelectases in the left mid hemithorax'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing atelectasis in the retrocardiac region'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing bands of atelectasis in the right lung'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing bibasilar atelectases on the left side'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing bilateral areas of basilar atelectasis'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing bilateral subsequent basal atelectases'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing consolidation in the right middle lung'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing consolidations in the right lower lobe'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing consolidations in the right upper lobe'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing extent of opacities at both lung bases'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing interstitial pattern in the right lung'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increasing left retrocardiac areas of atelectasis'},\n",
       "  'parsed_response': 'worsened'},\n",
       " {'metadata': {'sentence': 'increasing multifocal opacities in the right lung'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increasing parenchymal opacifications bilaterally'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'development of bibasilar atelectasis on the right'},\n",
       "  'parsed_response': 'new finding'},\n",
       " {'metadata': {'sentence': 'interval development of left base consolidation'},\n",
       "  'parsed_response': 'progressed'},\n",
       " {'metadata': {'sentence': 'no significant interval change since prior exam'},\n",
       "  'parsed_response': 'stable/unchanged'},\n",
       " {'metadata': {'sentence': 'no pleural effusions smaller than on prior exam'},\n",
       "  'parsed_response': 'smaller'},\n",
       " {'metadata': {'sentence': 'slight increase in the left basilar atelectasis'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'increasing opacifications in the left lower lobe'},\n",
       "  'parsed_response': 'increase'},\n",
       " {'metadata': {'sentence': 'no other relevant changes since the recent study'},\n",
       "  'parsed_response': 'stable/unchanged'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-50:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
