{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e28bbc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-27 16:23:16,332 - \u001b[1;32mINFO\u001b[1;0m - Loaded 10 already processed sentences from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_chest_imagenome_labels_from_sentences__top5000_most_difficult.jsonl\n",
      "2023-07-27 16:23:16,591 - \u001b[1;32mINFO\u001b[1;0m - Loaded 556111 sentences to skip from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\n",
      "2023-07-27 16:23:22,967 - \u001b[1;32mINFO\u001b[1;0m - Loaded 578733 facts metadata from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "100%|███████████████████████████████| 578733/578733 [00:03<00:00, 166537.83it/s]\n",
      "2023-07-27 16:23:27,089 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14993 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\n",
      "2023-07-27 16:23:27,469 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14971 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\n",
      "2023-07-27 16:23:27,849 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14972 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\n",
      "2023-07-27 16:23:28,232 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14965 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\n",
      "2023-07-27 16:23:28,630 - \u001b[1;32mINFO\u001b[1;0m - Loaded 10000 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\n",
      "2023-07-27 16:23:28,957 - \u001b[1;32mINFO\u001b[1;0m - Loaded 9999 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\n",
      "2023-07-27 16:23:29,285 - \u001b[1;32mINFO\u001b[1;0m - Loaded 9997 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\n",
      "2023-07-27 16:23:30,228 - \u001b[1;32mINFO\u001b[1;0m - Loaded 9994 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\n",
      "2023-07-27 16:23:30,562 - \u001b[1;32mINFO\u001b[1;0m - Loaded 9996 paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\n",
      "2023-07-27 16:23:30,800 - \u001b[1;32mINFO\u001b[1;0m - Found 1996379 unique sentences\n",
      "2023-07-27 16:23:31,421 - \u001b[1;32mINFO\u001b[1;0m - Loading cached sorted sentences from /mnt/workspace/pamessina/medvqa-workspace/cache/sorted_sentences(1996379,100909165).pkl...\n",
      "2023-07-27 16:23:31,678 - \u001b[1;32mINFO\u001b[1;0m - Done loading cached sorted sentences.\n",
      "2023-07-27 16:23:31,678 - \u001b[1;32mINFO\u001b[1;0m - First sentence: A BENIGN CALCIFICATION IN LUNG OR RIB, OR VESSEL, EITHER ON END OR CROSSING in the right lower lung\n",
      "2023-07-27 16:23:31,678 - \u001b[1;32mINFO\u001b[1;0m - Last sentence: right\n",
      "2023-07-27 16:23:31,768 - \u001b[1;32mINFO\u001b[1;0m - Selecting the top 5000 most difficult sentences\n",
      "2023-07-27 16:23:31,841 - \u001b[1;32mINFO\u001b[1;0m - Filtering sentences to the 0-th of every 1 sentences\n",
      "2023-07-27 16:23:31,842 - \u001b[1;32mINFO\u001b[1;0m - Found 5000 sentences that are the 0-th of every 1\n",
      "2023-07-27 16:23:31,842 - \u001b[1;33mWARNING\u001b[1;0m - Requested 10000 sentences but only 5000 are available. Using 5000 instead.\n",
      "2023-07-27 16:23:31,842 - \u001b[1;32mINFO\u001b[1;0m - Collecting the first 5000 sentences from the 0-th sentence\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to process: 4990\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to process:\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - 1. MILD FOCAL NARROWING OF THE UPPER TRACHEA\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - 555. Newer treatment modalities have been introduced for the management of liver cancer in recent times\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - 1109. not characteristic of sickle cell hemoglobinopathy\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - 1664. barium contrast agent becoming caked\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - 2218. The reason for the thickening is not well-understood\n",
      "2023-07-27 16:23:31,844 - \u001b[1;32mINFO\u001b[1;0m - 2772. slight increase in size of proximal descending aortic/aortic arch aneurysm\n",
      "2023-07-27 16:23:31,845 - \u001b[1;32mINFO\u001b[1;0m - 3327. diaphragmatic pick-up sign\n",
      "2023-07-27 16:23:31,845 - \u001b[1;32mINFO\u001b[1;0m - 3881. ETT projects.3 cm above the carina\n",
      "2023-07-27 16:23:31,845 - \u001b[1;32mINFO\u001b[1;0m - 4435. Exceptionally severe consolidation present in the lower lobes bilaterally\n",
      "2023-07-27 16:23:31,845 - \u001b[1;32mINFO\u001b[1;0m - 4990. integrating the lateral radiograph into the image\n",
      "2023-07-27 16:23:31,857 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230727_162331.jsonl\n",
      "2023-07-27 16:23:31,857 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230727_162331.jsonl\n",
      "2023-07-27 16:23:32,335 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-27 16:23:39,559 - \u001b[1;32mINFO\u001b[1;0m - Starting request #50\n",
      "2023-07-27 16:24:45,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-27 16:25:50,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #150\n",
      "2023-07-27 16:26:56,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #200\n",
      "2023-07-27 16:28:02,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #250\n",
      "2023-07-27 16:29:07,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #300\n",
      "2023-07-27 16:30:13,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #350\n",
      "2023-07-27 16:31:18,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #400\n",
      "2023-07-27 16:32:24,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #450\n",
      "2023-07-27 16:33:30,184 - \u001b[1;32mINFO\u001b[1;0m - Starting request #500\n",
      "2023-07-27 16:34:35,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #550\n",
      "2023-07-27 16:35:41,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #600\n",
      "2023-07-27 16:36:47,091 - \u001b[1;32mINFO\u001b[1;0m - Starting request #650\n",
      "2023-07-27 16:37:52,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #700\n",
      "2023-07-27 16:38:58,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #750\n",
      "2023-07-27 16:40:03,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #800\n",
      "2023-07-27 16:41:09,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #850\n",
      "2023-07-27 16:42:15,073 - \u001b[1;32mINFO\u001b[1;0m - Starting request #900\n",
      "2023-07-27 16:43:20,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #950\n",
      "2023-07-27 16:44:26,283 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1000\n",
      "2023-07-27 16:45:31,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1050\n",
      "2023-07-27 16:46:37,526 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1100\n",
      "2023-07-27 16:47:43,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1150\n",
      "2023-07-27 16:48:48,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1200\n",
      "2023-07-27 16:49:54,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1250\n",
      "2023-07-27 16:50:59,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1300\n",
      "2023-07-27 16:52:05,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1350\n",
      "2023-07-27 16:53:11,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1400\n",
      "2023-07-27 16:54:16,874 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1450\n",
      "2023-07-27 16:55:22,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1500\n",
      "2023-07-27 16:56:28,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1550\n",
      "2023-07-27 16:57:33,778 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1600\n",
      "2023-07-27 16:58:39,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1650\n",
      "2023-07-27 16:59:44,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1700\n",
      "2023-07-27 17:00:50,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1750\n",
      "2023-07-27 17:01:56,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1800\n",
      "2023-07-27 17:03:01,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1850\n",
      "2023-07-27 17:04:07,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1900\n",
      "2023-07-27 17:06:18,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2000\n",
      "2023-07-27 17:07:24,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2050\n",
      "2023-07-27 17:08:29,797 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2100\n",
      "2023-07-27 17:09:35,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:10:41,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2200\n",
      "2023-07-27 17:11:46,710 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2250\n",
      "2023-07-27 17:12:52,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2300\n",
      "2023-07-27 17:13:57,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2350\n",
      "2023-07-27 17:15:03,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2400\n",
      "2023-07-27 17:16:09,018 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2450\n",
      "2023-07-27 17:17:14,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2500\n",
      "2023-07-27 17:18:20,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2550\n",
      "2023-07-27 17:19:25,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2600\n",
      "2023-07-27 17:20:31,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2650\n",
      "2023-07-27 17:21:37,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2700\n",
      "2023-07-27 17:22:42,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2750\n",
      "2023-07-27 17:23:48,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2800\n",
      "2023-07-27 17:24:53,987 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2850\n",
      "2023-07-27 17:25:59,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2900\n",
      "2023-07-27 17:27:05,335 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2950\n",
      "2023-07-27 17:28:10,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3000\n",
      "2023-07-27 17:29:16,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3050\n",
      "2023-07-27 17:30:22,087 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3100\n",
      "2023-07-27 17:31:27,729 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3150\n",
      "2023-07-27 17:32:33,247 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3200\n",
      "2023-07-27 17:33:38,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3250\n",
      "2023-07-27 17:34:44,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3300\n",
      "2023-07-27 17:35:49,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3350\n",
      "2023-07-27 17:36:55,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3400\n",
      "2023-07-27 17:38:01,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3450\n",
      "2023-07-27 17:39:06,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3500\n",
      "2023-07-27 17:40:12,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3550\n",
      "2023-07-27 17:41:17,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3600\n",
      "2023-07-27 17:42:23,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3650\n",
      "2023-07-27 17:43:28,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3700\n",
      "2023-07-27 17:44:34,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3750\n",
      "2023-07-27 17:45:39,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3800\n",
      "2023-07-27 17:46:45,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3850\n",
      "2023-07-27 17:47:35,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 3819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75f0db3859103f173be8ddcbca8deb51 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:47:51,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3899\n",
      "2023-07-27 17:48:56,589 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3949\n",
      "2023-07-27 17:50:02,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3999\n",
      "2023-07-27 17:51:07,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4049\n",
      "2023-07-27 17:52:13,230 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4099\n",
      "2023-07-27 17:53:18,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4149\n",
      "2023-07-27 17:54:24,289 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4199\n",
      "2023-07-27 17:55:16,562 - \u001b[1;33mWARNING\u001b[1;0m - Request 4170 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03946055aea7b6829b202fcd0e097af6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:55:21,754 - \u001b[1;33mWARNING\u001b[1;0m - Request 4174 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ed675cc256f75227fc450de7ff8532eb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:55:29,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4247\n",
      "2023-07-27 17:55:37,510 - \u001b[1;33mWARNING\u001b[1;0m - Request 4186 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3d3f4d491f04d84606afa7025cc5a63f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:55:54,491 - \u001b[1;33mWARNING\u001b[1;0m - Request 4199 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fba3b9fb7262cd946fa3fde4797fd9b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:55:55,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 4200 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e4043b92767fd7fc91052d71166beedb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:56:02,383 - \u001b[1;33mWARNING\u001b[1;0m - Request 4205 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb29e20da65c0b8d182d8828bfa80c2e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:56:04,713 - \u001b[1;33mWARNING\u001b[1;0m - Request 4204 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d0f18ac3d0ec78d2e2aa2323b3c330a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-27 17:56:35,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4292\n",
      "2023-07-27 17:57:41,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4342\n",
      "2023-07-27 17:58:46,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4392\n",
      "2023-07-27 17:59:52,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4442\n",
      "2023-07-27 18:00:57,669 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4492\n",
      "2023-07-27 18:02:03,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4542\n",
      "2023-07-27 18:03:08,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4592\n",
      "2023-07-27 18:04:14,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4642\n",
      "2023-07-27 18:05:19,869 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4692\n",
      "2023-07-27 18:06:25,401 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4742\n",
      "2023-07-27 18:07:30,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4792\n",
      "2023-07-27 18:08:36,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4842\n",
      "2023-07-27 18:09:41,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4892\n",
      "2023-07-27 18:10:47,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4942\n",
      "2023-07-27 18:11:49,446 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230727_162331.jsonl\n",
      "2023-07-27 18:11:49,451 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230727_162331.jsonl\n",
      "2023-07-27 18:11:49,633 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 4990 of 4990 API responses.\n",
      "                    0 of 4990 API responses could not be processed.\n",
      "                    Saving processed texts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_chest_imagenome_labels_from_sentences__top5000_most_difficult.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_chest_imagenome_labels_from_sentences_with_openai.py \\\n",
    "--integrated_fact_metadata_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--preprocessed_sentences_to_skip_filepaths \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\" \\\n",
    "--top_k_most_difficult_sentences 5000 \\\n",
    "--offset 0 \\\n",
    "--num_sentences 10000 \\\n",
    "--process_kth_of_every_n_sentences 0 1 \\\n",
    "--openai_model_name \"gpt-4-0613\" \\\n",
    "--api_key_name \"OPENAI_API_KEY_3\" \\\n",
    "--max_requests_per_minute 190 \\\n",
    "--max_tokens_per_minute 35000 \\\n",
    "--max_tokens_per_request 200 \\\n",
    "--temperature 0 \\\n",
    "--alias \"__top5000_most_difficult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59456ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_pickle, load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "352e5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl(\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_chest_imagenome_labels_from_sentences__top5000_most_difficult.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35921cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16fc7b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'query': 'No signs of aggressiveness are observed in the lesion'},\n",
       "  'parsed_response': []},\n",
       " {'metadata': {'query': 'patchy infiltrates in the infrabasilar areas'},\n",
       "  'parsed_response': ['infiltration']},\n",
       " {'metadata': {'query': 'Semi-prostrate upper abdominal examination'},\n",
       "  'parsed_response': []},\n",
       " {'metadata': {'query': 'no comparison with previous study at 05:53'},\n",
       "  'parsed_response': []},\n",
       " {'metadata': {'query': 'puffed-up stomach with gas'}, 'parsed_response': []},\n",
       " {'metadata': {'query': 'right clavicle abbreviation'}, 'parsed_response': []},\n",
       " {'metadata': {'query': 'right clavicle abridgment'}, 'parsed_response': []},\n",
       " {'metadata': {'query': 'right clavicle curtailment'}, 'parsed_response': []},\n",
       " {'metadata': {'query': 'study performed at 18:14'}, 'parsed_response': []},\n",
       " {'metadata': {'query': 'improvement of pneumothorax in the right lung base compared with the radiograph from at 06:24'},\n",
       "  'parsed_response': ['pneumothorax']},\n",
       " {'metadata': {'query': 'NG tube positioned in the subcardial region of the stomach'},\n",
       "  'parsed_response': ['enteric tube']},\n",
       " {'metadata': {'query': 'dominent retrocardiac nodule in the posterior left lower lobe'},\n",
       "  'parsed_response': ['mass/nodule (not otherwise specified)']},\n",
       " {'metadata': {'query': 'The left pleural space shows a well-coiled pigtail catheter'},\n",
       "  'parsed_response': ['pigtail catheter']},\n",
       " {'metadata': {'query': 'Extracted from a more medial position'},\n",
       "  'parsed_response': []},\n",
       " {'metadata': {'query': 'unchanged preplanned position of left-sided Port-A-Cath'},\n",
       "  'parsed_response': ['chest port']},\n",
       " {'metadata': {'query': 'minimal change since the radiograph from 17:31'},\n",
       "  'parsed_response': []},\n",
       " {'metadata': {'query': 'twisty and calcified aorta in the chest region'},\n",
       "  'parsed_response': ['vascular calcification', 'tortuous aorta']},\n",
       " {'metadata': {'query': 'well-proportioned pulmonary blood vessels'},\n",
       "  'parsed_response': []},\n",
       " {'metadata': {'query': 'passively collapsed left base'},\n",
       "  'parsed_response': ['lobar/segmental collapse']},\n",
       " {'metadata': {'query': 'integrating the lateral radiograph into the image'},\n",
       "  'parsed_response': []}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-20:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
