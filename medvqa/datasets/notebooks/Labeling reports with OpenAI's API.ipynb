{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81949475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-14 13:57:32,250 - \u001b[1;32mINFO\u001b[1;0m - Loading preprocessed reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "2023-06-14 13:57:32,935 - \u001b[1;32mINFO\u001b[1;0m - Loading ranked report indices from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/ranked_report_indices_1.0_1.0_1.0.pkl\n",
      "2023-06-14 13:57:32,946 - \u001b[1;32mINFO\u001b[1;0m - Loading preprocessed reports to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_reports.jsonl\n",
      "2023-06-14 13:57:33,392 - \u001b[1;32mINFO\u001b[1;0m - Loaded 15322 reports to skip\n",
      "2023-06-14 13:57:33,402 - \u001b[1;32mINFO\u001b[1;0m - Total number of reports to skip: 15322\n",
      "2023-06-14 13:57:34,086 - \u001b[1;32mINFO\u001b[1;0m - 9678 of the top 25000 reports were not found in the cache. Parsing them now.\n",
      "2023-06-14 13:57:34,086 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230614_135734.jsonl\n",
      "2023-06-14 13:57:34,086 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230614_135734.jsonl\n",
      "2023-06-14 13:57:34,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-14 13:57:34,943 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-06-14 13:57:41,524 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-06-14 13:58:05,218 - \u001b[1;33mWARNING\u001b[1;0m - Request 7 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e651b4c37b9c001af506173877a95470 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 13:58:05,221 - \u001b[1;33mWARNING\u001b[1;0m - Request 15 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bdd000b70f844de257d0c973c9f92dec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 13:58:13,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #58\n",
      "2023-06-14 13:58:46,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #78\n",
      "2023-06-14 13:59:18,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #98\n",
      "2023-06-14 13:59:51,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #118\n",
      "2023-06-14 14:00:24,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #138\n",
      "2023-06-14 14:00:56,698 - \u001b[1;32mINFO\u001b[1;0m - Starting request #158\n",
      "2023-06-14 14:01:29,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #178\n",
      "2023-06-14 14:02:01,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #198\n",
      "2023-06-14 14:02:33,866 - \u001b[1;32mINFO\u001b[1;0m - Starting request #218\n",
      "2023-06-14 14:03:06,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #238\n",
      "2023-06-14 14:03:22,021 - \u001b[1;33mWARNING\u001b[1;0m - Request 229 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f3350a17f8665b1f0d0b1d3b2df6856b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:03:38,804 - \u001b[1;32mINFO\u001b[1;0m - Starting request #257\n",
      "2023-06-14 14:04:11,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #277\n",
      "2023-06-14 14:04:43,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #297\n",
      "2023-06-14 14:05:15,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #317\n",
      "2023-06-14 14:05:48,318 - \u001b[1;32mINFO\u001b[1;0m - Starting request #337\n",
      "2023-06-14 14:06:21,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #357\n",
      "2023-06-14 14:06:53,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #377\n",
      "2023-06-14 14:07:25,792 - \u001b[1;32mINFO\u001b[1;0m - Starting request #397\n",
      "2023-06-14 14:07:58,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #417\n",
      "2023-06-14 14:08:30,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #437\n",
      "2023-06-14 14:09:03,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #457\n",
      "2023-06-14 14:09:35,696 - \u001b[1;32mINFO\u001b[1;0m - Starting request #477\n",
      "2023-06-14 14:10:08,060 - \u001b[1;32mINFO\u001b[1;0m - Starting request #497\n",
      "2023-06-14 14:10:26,839 - \u001b[1;33mWARNING\u001b[1;0m - Request 490 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0bd7aeb5ec9b960132998cd8f26a5ea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:10:40,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #516\n",
      "2023-06-14 14:11:12,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #536\n",
      "2023-06-14 14:11:44,946 - \u001b[1;33mWARNING\u001b[1;0m - Request 537 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 85835052af36530efc28c4da22970187 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:11:45,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #556\n",
      "2023-06-14 14:12:18,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #575\n",
      "2023-06-14 14:12:50,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #595\n",
      "2023-06-14 14:13:23,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #615\n",
      "2023-06-14 14:13:55,711 - \u001b[1;32mINFO\u001b[1;0m - Starting request #635\n",
      "2023-06-14 14:14:27,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #655\n",
      "2023-06-14 14:15:00,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #675\n",
      "2023-06-14 14:15:32,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #695\n",
      "2023-06-14 14:16:05,258 - \u001b[1;32mINFO\u001b[1;0m - Starting request #715\n",
      "2023-06-14 14:16:37,790 - \u001b[1;32mINFO\u001b[1;0m - Starting request #735\n",
      "2023-06-14 14:17:10,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #755\n",
      "2023-06-14 14:17:42,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #775\n",
      "2023-06-14 14:18:14,625 - \u001b[1;33mWARNING\u001b[1;0m - Request 776 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e33e0d63b7dc3516f2052c671d34eb4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:18:15,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #795\n",
      "2023-06-14 14:18:47,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #814\n",
      "2023-06-14 14:19:20,207 - \u001b[1;32mINFO\u001b[1;0m - Starting request #834\n",
      "2023-06-14 14:19:44,050 - \u001b[1;33mWARNING\u001b[1;0m - Request 830 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9e3b9d50d8f73b8c06848aeb040e7a07 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:19:52,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #853\n",
      "2023-06-14 14:20:25,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #873\n",
      "2023-06-14 14:20:57,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #893\n",
      "2023-06-14 14:21:29,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #913\n",
      "2023-06-14 14:21:43,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 903 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 389f39e7474981e7a456026941dca323 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:22:02,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #932\n",
      "2023-06-14 14:22:35,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #952\n",
      "2023-06-14 14:23:07,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #972\n",
      "2023-06-14 14:23:32,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 804 failed with Exception \n",
      "2023-06-14 14:23:40,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #991\n",
      "2023-06-14 14:24:12,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1011\n",
      "2023-06-14 14:24:45,118 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1031\n",
      "2023-06-14 14:25:17,442 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1051\n",
      "2023-06-14 14:25:49,797 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1071\n",
      "2023-06-14 14:26:22,368 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1091\n",
      "2023-06-14 14:26:54,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-14 14:27:27,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1131\n",
      "2023-06-14 14:28:00,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1151\n",
      "2023-06-14 14:28:32,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1171\n",
      "2023-06-14 14:29:04,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1191\n",
      "2023-06-14 14:29:37,355 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1211\n",
      "2023-06-14 14:30:09,682 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1231\n",
      "2023-06-14 14:30:42,043 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1251\n",
      "2023-06-14 14:31:14,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1271\n",
      "2023-06-14 14:31:46,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1291\n",
      "2023-06-14 14:32:19,444 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1311\n",
      "2023-06-14 14:32:51,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1331\n",
      "2023-06-14 14:33:24,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1351\n",
      "2023-06-14 14:33:56,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1371\n",
      "2023-06-14 14:34:29,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1391\n",
      "2023-06-14 14:35:01,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1411\n",
      "2023-06-14 14:35:33,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1431\n",
      "2023-06-14 14:36:06,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1451\n",
      "2023-06-14 14:36:28,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 1446 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0cff5020f18d86c21b859f5d798e085e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:36:38,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1470\n",
      "2023-06-14 14:37:11,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1490\n",
      "2023-06-14 14:37:43,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1510\n",
      "2023-06-14 14:38:16,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1530\n",
      "2023-06-14 14:38:48,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1550\n",
      "2023-06-14 14:39:21,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1570\n",
      "2023-06-14 14:39:30,636 - \u001b[1;33mWARNING\u001b[1;0m - Request 1557 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fa371dcd09cb095f78cd6c98848f6f30 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:39:53,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1589\n",
      "2023-06-14 14:40:26,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1609\n",
      "2023-06-14 14:40:58,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1629\n",
      "2023-06-14 14:41:31,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1649\n",
      "2023-06-14 14:42:03,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1669\n",
      "2023-06-14 14:42:36,184 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1689\n",
      "2023-06-14 14:43:09,013 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1709\n",
      "2023-06-14 14:43:41,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1729\n",
      "2023-06-14 14:44:13,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1749\n",
      "2023-06-14 14:44:46,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1769\n",
      "2023-06-14 14:45:19,086 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1789\n",
      "2023-06-14 14:45:26,294 - \u001b[1;33mWARNING\u001b[1;0m - Request 1775 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 77d0df4b335c67af4206aa0449bf04ab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:45:51,470 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1808\n",
      "2023-06-14 14:46:24,101 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1828\n",
      "2023-06-14 14:46:56,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1848\n",
      "2023-06-14 14:47:29,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1868\n",
      "2023-06-14 14:48:01,401 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1888\n",
      "2023-06-14 14:48:34,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1908\n",
      "2023-06-14 14:49:06,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1928\n",
      "2023-06-14 14:49:25,315 - \u001b[1;33mWARNING\u001b[1;0m - Request 1921 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1bc4697fc713d712a27ef36dfe9c691 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:49:38,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1947\n",
      "2023-06-14 14:50:11,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1967\n",
      "2023-06-14 14:50:43,794 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1987\n",
      "2023-06-14 14:51:16,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2007\n",
      "2023-06-14 14:51:48,459 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2027\n",
      "2023-06-14 14:52:20,610 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2047\n",
      "2023-06-14 14:52:52,730 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2067\n",
      "2023-06-14 14:53:25,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2087\n",
      "2023-06-14 14:53:57,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2107\n",
      "2023-06-14 14:54:30,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2127\n",
      "2023-06-14 14:54:39,846 - \u001b[1;33mWARNING\u001b[1;0m - Request 2114 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e2792e9bc76c91f0a91e247bbcd58107 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:55:02,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2146\n",
      "2023-06-14 14:55:34,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2166\n",
      "2023-06-14 14:56:07,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2186\n",
      "2023-06-14 14:56:39,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2206\n",
      "2023-06-14 14:57:12,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2226\n",
      "2023-06-14 14:57:45,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2246\n",
      "2023-06-14 14:58:17,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2266\n",
      "2023-06-14 14:58:50,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2286\n",
      "2023-06-14 14:59:22,757 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2306\n",
      "2023-06-14 14:59:43,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 2300 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c14787da124ae76cae88283a9575d4f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 14:59:55,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2325\n",
      "2023-06-14 15:00:27,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2345\n",
      "2023-06-14 15:01:00,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2365\n",
      "2023-06-14 15:01:32,590 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2385\n",
      "2023-06-14 15:02:05,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2405\n",
      "2023-06-14 15:02:06,193 - \u001b[1;33mWARNING\u001b[1;0m - Request 2387 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 267142ad90da0d766fb82dd877aa8963 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:02:37,402 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2424\n",
      "2023-06-14 15:02:41,823 - \u001b[1;33mWARNING\u001b[1;0m - Request 2408 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a78cdadd1f88ad79549cabe3063a3e4e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:02:56,470 - \u001b[1;33mWARNING\u001b[1;0m - Request 2417 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cc04e6e2b5da04e7f156996cd4b9ae50 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:03:09,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2442\n",
      "2023-06-14 15:03:42,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:03:45,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 2445 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1026227b6c778b1375c808bf4d1da01f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:04:14,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2481\n",
      "2023-06-14 15:04:38,621 - \u001b[1;33mWARNING\u001b[1;0m - Request 2477 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09aaff70ad13179f822ce3a872585584 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:04:47,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2500\n",
      "2023-06-14 15:05:19,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2520\n",
      "2023-06-14 15:05:51,999 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2540\n",
      "2023-06-14 15:06:24,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2560\n",
      "2023-06-14 15:06:57,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2580\n",
      "2023-06-14 15:07:29,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2600\n",
      "2023-06-14 15:08:01,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2620\n",
      "2023-06-14 15:08:34,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2640\n",
      "2023-06-14 15:09:06,757 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2660\n",
      "2023-06-14 15:09:39,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2680\n",
      "2023-06-14 15:10:11,362 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2700\n",
      "2023-06-14 15:10:43,850 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2720\n",
      "2023-06-14 15:10:48,053 - \u001b[1;33mWARNING\u001b[1;0m - Request 2704 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7034915f52d7d34e0371a8749db5ac23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:11:16,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2739\n",
      "2023-06-14 15:11:48,747 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2759\n",
      "2023-06-14 15:12:07,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 2752 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b40d452cd6d75a4a1b84b580d4a2dbfa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:12:21,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2778\n",
      "2023-06-14 15:12:53,335 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2798\n",
      "2023-06-14 15:13:25,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2818\n",
      "2023-06-14 15:13:58,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2838\n",
      "2023-06-14 15:14:30,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2858\n",
      "2023-06-14 15:15:03,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2878\n",
      "2023-06-14 15:15:35,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2898\n",
      "2023-06-14 15:16:08,031 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2918\n",
      "2023-06-14 15:16:10,767 - \u001b[1;33mWARNING\u001b[1;0m - Request 2901 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 80289f96ebe66c161de860ef55fae93b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:16:40,509 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2937\n",
      "2023-06-14 15:17:12,942 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2957\n",
      "2023-06-14 15:17:45,654 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2977\n",
      "2023-06-14 15:18:18,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2997\n",
      "2023-06-14 15:18:36,928 - \u001b[1;33mWARNING\u001b[1;0m - Request 2990 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8ce29670ed3abb3c8f5b4fb8bd669b12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:18:49,846 - \u001b[1;33mWARNING\u001b[1;0m - Request 2998 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3fb15a48ea58578bcd5943de57eca6a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:18:50,282 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3016\n",
      "2023-06-14 15:19:22,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3035\n",
      "2023-06-14 15:19:55,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3055\n",
      "2023-06-14 15:20:27,886 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3075\n",
      "2023-06-14 15:21:00,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3095\n",
      "2023-06-14 15:21:32,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3115\n",
      "2023-06-14 15:22:05,178 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3135\n",
      "2023-06-14 15:22:37,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3155\n",
      "2023-06-14 15:23:10,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3175\n",
      "2023-06-14 15:23:15,742 - \u001b[1;33mWARNING\u001b[1;0m - Request 3160 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 32e556542c23800d1f6ef66de107c93b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:23:42,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3194\n",
      "2023-06-14 15:24:14,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3214\n",
      "2023-06-14 15:24:47,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3234\n",
      "2023-06-14 15:25:19,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3254\n",
      "2023-06-14 15:25:20,716 - \u001b[1;33mWARNING\u001b[1;0m - Request 3236 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 203eff84e4de82f059befbd1c29ba1ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:25:52,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3273\n",
      "2023-06-14 15:26:24,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3293\n",
      "2023-06-14 15:26:56,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3313\n",
      "2023-06-14 15:27:28,326 - \u001b[1;33mWARNING\u001b[1;0m - Request 3314 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b7e49f636989fe62c8acedc833e5e46 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:27:28,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3333\n",
      "2023-06-14 15:28:01,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3352\n",
      "2023-06-14 15:28:33,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3372\n",
      "2023-06-14 15:29:05,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3392\n",
      "2023-06-14 15:29:38,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3412\n",
      "2023-06-14 15:30:10,737 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3432\n",
      "2023-06-14 15:30:43,122 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3452\n",
      "2023-06-14 15:31:15,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3472\n",
      "2023-06-14 15:31:47,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3492\n",
      "2023-06-14 15:32:20,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3512\n",
      "2023-06-14 15:32:52,776 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3532\n",
      "2023-06-14 15:33:25,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3552\n",
      "2023-06-14 15:33:57,804 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3572\n",
      "2023-06-14 15:34:30,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3592\n",
      "2023-06-14 15:35:02,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3612\n",
      "2023-06-14 15:35:35,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3632\n",
      "2023-06-14 15:36:07,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3652\n",
      "2023-06-14 15:36:40,189 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3672\n",
      "2023-06-14 15:37:12,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:37:44,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3712\n",
      "2023-06-14 15:38:17,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3732\n",
      "2023-06-14 15:38:49,756 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3752\n",
      "2023-06-14 15:39:22,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3772\n",
      "2023-06-14 15:39:54,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3792\n",
      "2023-06-14 15:40:26,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3812\n",
      "2023-06-14 15:40:59,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3832\n",
      "2023-06-14 15:41:31,629 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3852\n",
      "2023-06-14 15:42:04,178 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3872\n",
      "2023-06-14 15:42:36,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3892\n",
      "2023-06-14 15:43:09,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3912\n",
      "2023-06-14 15:43:41,666 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3932\n",
      "2023-06-14 15:44:14,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3952\n",
      "2023-06-14 15:44:46,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3972\n",
      "2023-06-14 15:45:18,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3992\n",
      "2023-06-14 15:45:51,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4012\n",
      "2023-06-14 15:46:01,760 - \u001b[1;33mWARNING\u001b[1;0m - Request 3957 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c475be486a9f638f36c69aaae5b1e349 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:46:23,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4031\n",
      "2023-06-14 15:46:55,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4051\n",
      "2023-06-14 15:47:28,393 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4071\n",
      "2023-06-14 15:48:00,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4091\n",
      "2023-06-14 15:48:33,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4111\n",
      "2023-06-14 15:50:43,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4191\n",
      "2023-06-14 15:51:15,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4211\n",
      "2023-06-14 15:51:47,871 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4231\n",
      "2023-06-14 15:52:20,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4251\n",
      "2023-06-14 15:52:52,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4271\n",
      "2023-06-14 15:53:25,288 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4291\n",
      "2023-06-14 15:53:57,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4311\n",
      "2023-06-14 15:54:30,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4331\n",
      "2023-06-14 15:55:02,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4351\n",
      "2023-06-14 15:55:34,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4371\n",
      "2023-06-14 15:56:07,655 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4391\n",
      "2023-06-14 15:56:39,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4411\n",
      "2023-06-14 15:57:12,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4431\n",
      "2023-06-14 15:57:44,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4451\n",
      "2023-06-14 15:58:16,874 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4471\n",
      "2023-06-14 15:58:49,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4491\n",
      "2023-06-14 15:58:56,789 - \u001b[1;33mWARNING\u001b[1;0m - Request 4477 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 95cee0602e451f1b6cdc73c4646432e1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 15:59:21,734 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4510\n",
      "2023-06-14 15:59:53,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4530\n",
      "2023-06-14 16:00:26,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4550\n",
      "2023-06-14 16:00:59,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4570\n",
      "2023-06-14 16:01:31,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4590\n",
      "2023-06-14 16:01:34,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 4573 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 12f9718d8a5c7a8e76937b18a138029b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:01:46,347 - \u001b[1;33mWARNING\u001b[1;0m - Request 4596 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-14 16:01:56,823 - \u001b[1;33mWARNING\u001b[1;0m - Request 4587 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6518df2ce22e8fa69d6d263e84cb6e51 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:02:03,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4607\n",
      "2023-06-14 16:02:36,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4627\n",
      "2023-06-14 16:02:42,187 - \u001b[1;33mWARNING\u001b[1;0m - Request 4612 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ea248caee1232d54f4848fadf484ffc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:02:58,452 - \u001b[1;33mWARNING\u001b[1;0m - Request 4622 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f17b414267705abcd71f519a19b2e246 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:03:08,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4645\n",
      "2023-06-14 16:03:41,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4665\n",
      "2023-06-14 16:04:13,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4685\n",
      "2023-06-14 16:04:45,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4705\n",
      "2023-06-14 16:05:18,435 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4725\n",
      "2023-06-14 16:05:46,988 - \u001b[1;33mWARNING\u001b[1;0m - Request 4724 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62965c2ab70dbb87dcb91fe812eac1b5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:05:51,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4744\n",
      "2023-06-14 16:06:23,496 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4764\n",
      "2023-06-14 16:06:55,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4784\n",
      "2023-06-14 16:07:28,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4804\n",
      "2023-06-14 16:08:00,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4824\n",
      "2023-06-14 16:08:33,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4844\n",
      "2023-06-14 16:09:05,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4864\n",
      "2023-06-14 16:09:38,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4884\n",
      "2023-06-14 16:10:10,621 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4904\n",
      "2023-06-14 16:10:42,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4924\n",
      "2023-06-14 16:11:15,500 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4944\n",
      "2023-06-14 16:11:47,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4964\n",
      "2023-06-14 16:12:20,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4984\n",
      "2023-06-14 16:12:52,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5004\n",
      "2023-06-14 16:13:08,365 - \u001b[1;33mWARNING\u001b[1;0m - Request 4995 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ccf0685ed547c044f219e122ffa8d7e6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:13:25,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5023\n",
      "2023-06-14 16:13:57,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5043\n",
      "2023-06-14 16:14:29,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5063\n",
      "2023-06-14 16:15:02,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5083\n",
      "2023-06-14 16:15:34,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5103\n",
      "2023-06-14 16:16:07,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5123\n",
      "2023-06-14 16:16:39,754 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-14 16:17:11,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5163\n",
      "2023-06-14 16:17:14,753 - \u001b[1;33mWARNING\u001b[1;0m - Request 5146 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 901672c97bf1a0011dca327009566a99 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:17:44,745 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5182\n",
      "2023-06-14 16:18:17,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5202\n",
      "2023-06-14 16:18:49,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5222\n",
      "2023-06-14 16:19:22,019 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5242\n",
      "2023-06-14 16:19:54,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5262\n",
      "2023-06-14 16:20:26,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5282\n",
      "2023-06-14 16:20:58,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5302\n",
      "2023-06-14 16:21:04,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 5287 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb75ee5bda88d554652b951bda3931c5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:21:31,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5321\n",
      "2023-06-14 16:22:03,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5341\n",
      "2023-06-14 16:22:36,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5361\n",
      "2023-06-14 16:23:08,568 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5381\n",
      "2023-06-14 16:23:41,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5401\n",
      "2023-06-14 16:24:13,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5421\n",
      "2023-06-14 16:24:46,113 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5441\n",
      "2023-06-14 16:25:18,331 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5461\n",
      "2023-06-14 16:25:50,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5481\n",
      "2023-06-14 16:26:23,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5501\n",
      "2023-06-14 16:26:55,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5521\n",
      "2023-06-14 16:27:27,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5541\n",
      "2023-06-14 16:28:00,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5561\n",
      "2023-06-14 16:28:32,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5581\n",
      "2023-06-14 16:29:05,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5601\n",
      "2023-06-14 16:29:37,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5621\n",
      "2023-06-14 16:30:09,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5641\n",
      "2023-06-14 16:30:12,656 - \u001b[1;33mWARNING\u001b[1;0m - Request 5624 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0c8d55b8e7051aaff788892bc308d8c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:30:42,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5660\n",
      "2023-06-14 16:30:51,721 - \u001b[1;33mWARNING\u001b[1;0m - Request 5647 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 835af8992c85b61c711414b18d51d347 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:30:53,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 5648 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2b33a2ae6285dbef5d2c9134ab03a25a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:31:14,955 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5678\n",
      "2023-06-14 16:31:47,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5698\n",
      "2023-06-14 16:32:19,832 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5718\n",
      "2023-06-14 16:32:52,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5738\n",
      "2023-06-14 16:33:24,902 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5758\n",
      "2023-06-14 16:33:57,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5778\n",
      "2023-06-14 16:34:29,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5798\n",
      "2023-06-14 16:34:50,467 - \u001b[1;33mWARNING\u001b[1;0m - Request 5792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e34d84d3954a29b2d2d2b1e8762cb6a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:35:02,113 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5817\n",
      "2023-06-14 16:35:34,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5837\n",
      "2023-06-14 16:36:06,813 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5857\n",
      "2023-06-14 16:36:39,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5877\n",
      "2023-06-14 16:37:11,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5897\n",
      "2023-06-14 16:37:43,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5917\n",
      "2023-06-14 16:38:16,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5937\n",
      "2023-06-14 16:38:48,412 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5957\n",
      "2023-06-14 16:39:21,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5977\n",
      "2023-06-14 16:39:53,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5997\n",
      "2023-06-14 16:40:25,906 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6017\n",
      "2023-06-14 16:40:41,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 6008 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 55c66d9e831a18b3cb16ad2bf02904a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:40:58,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6036\n",
      "2023-06-14 16:41:30,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6056\n",
      "2023-06-14 16:42:03,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6076\n",
      "2023-06-14 16:42:35,766 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6096\n",
      "2023-06-14 16:43:08,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6116\n",
      "2023-06-14 16:43:40,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6136\n",
      "2023-06-14 16:44:12,755 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6156\n",
      "2023-06-14 16:44:44,992 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6176\n",
      "2023-06-14 16:45:17,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6196\n",
      "2023-06-14 16:45:49,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6216\n",
      "2023-06-14 16:46:22,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6236\n",
      "2023-06-14 16:46:54,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6256\n",
      "2023-06-14 16:47:27,068 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6276\n",
      "2023-06-14 16:47:59,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6296\n",
      "2023-06-14 16:48:31,888 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6316\n",
      "2023-06-14 16:49:04,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6336\n",
      "2023-06-14 16:49:36,857 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6356\n",
      "2023-06-14 16:50:08,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6376\n",
      "2023-06-14 16:50:41,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6396\n",
      "2023-06-14 16:51:13,647 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6416\n",
      "2023-06-14 16:51:46,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6436\n",
      "2023-06-14 16:52:18,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6456\n",
      "2023-06-14 16:52:50,616 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6476\n",
      "2023-06-14 16:53:22,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6496\n",
      "2023-06-14 16:53:55,066 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6516\n",
      "2023-06-14 16:54:10,818 - \u001b[1;33mWARNING\u001b[1;0m - Request 6507 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5fd9617657c73cc37728633cef720060 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 16:54:27,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6535\n",
      "2023-06-14 16:55:00,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6555\n",
      "2023-06-14 16:55:32,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6575\n",
      "2023-06-14 16:56:04,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6595\n",
      "2023-06-14 16:56:36,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-14 16:57:08,906 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6635\n",
      "2023-06-14 16:57:41,621 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6655\n",
      "2023-06-14 16:58:13,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6675\n",
      "2023-06-14 16:58:46,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6695\n",
      "2023-06-14 16:59:18,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6715\n",
      "2023-06-14 16:59:51,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6735\n",
      "2023-06-14 17:00:23,260 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6755\n",
      "2023-06-14 17:00:55,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6775\n",
      "2023-06-14 17:01:09,773 - \u001b[1;33mWARNING\u001b[1;0m - Request 6765 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 98b5ce3d33432ea42e4d0912d4f3bbf5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 17:01:27,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6794\n",
      "2023-06-14 17:01:30,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 6778 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ec1b83fb34889a99faef6811d7d17b05 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 17:02:00,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6813\n",
      "2023-06-14 17:02:32,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6833\n",
      "2023-06-14 17:03:04,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6853\n",
      "2023-06-14 17:03:07,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 6789 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f9153e1679760eaa65fcff09cf3c664 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 17:03:37,568 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6872\n",
      "2023-06-14 17:04:09,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6892\n",
      "2023-06-14 17:04:42,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6912\n",
      "2023-06-14 17:05:14,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6932\n",
      "2023-06-14 17:05:46,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6952\n",
      "2023-06-14 17:06:19,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6972\n",
      "2023-06-14 17:06:27,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 6958 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ca0f8ea33dbd823acb6eb3df84f92432 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 17:06:51,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6991\n",
      "2023-06-14 17:07:24,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7011\n",
      "2023-06-14 17:07:56,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7031\n",
      "2023-06-14 17:08:28,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7051\n",
      "2023-06-14 17:09:00,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7071\n",
      "2023-06-14 17:09:33,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7091\n",
      "2023-06-14 17:10:05,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7111\n",
      "2023-06-14 17:10:37,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7131\n",
      "2023-06-14 17:11:10,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7151\n",
      "2023-06-14 17:11:42,285 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7171\n",
      "2023-06-14 17:12:14,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7191\n",
      "2023-06-14 17:12:46,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7211\n",
      "2023-06-14 17:13:19,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7231\n",
      "2023-06-14 17:13:51,545 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7251\n",
      "2023-06-14 17:14:23,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7271\n",
      "2023-06-14 17:14:56,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7291\n",
      "2023-06-14 17:15:28,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7311\n",
      "2023-06-14 17:15:54,201 - \u001b[1;33mWARNING\u001b[1;0m - Request 7308 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0e9e885979997c8e982596231ed55522 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 17:16:01,037 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7330\n",
      "2023-06-14 17:16:33,205 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7350\n",
      "2023-06-14 17:17:05,535 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7370\n",
      "2023-06-14 17:17:37,778 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7390\n",
      "2023-06-14 17:18:10,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7410\n",
      "2023-06-14 17:18:42,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7430\n",
      "2023-06-14 17:19:14,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7450\n",
      "2023-06-14 17:19:17,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 7433 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b1dc5f210e27a62c8ff41ccebc1771a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-14 17:19:47,168 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7469\n",
      "2023-06-14 17:20:19,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7489\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_sentences_from_reports_with_openai.py \\\n",
    "    --preprocessed_reports_filename \"background_findings_and_impression_20230612_174143.json\" \\\n",
    "    --ranked_report_indices_filename \"ranked_report_indices_1.0_1.0_1.0.pkl\" \\\n",
    "    --preprocessed_reports_to_skip_filename \"gpt-4-0613_parsed_reports.jsonl\" \\\n",
    "    --num_reports 25000 \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 87000 \\\n",
    "    --max_tokens_per_request 2048 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c192284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f789fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_reports.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3a7663ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15322"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "175d3b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'report_index': 66146,\n",
       "  'part_id': 12,\n",
       "  'subject_id': 12240747,\n",
       "  'study_id': 52771640,\n",
       "  'report': {'background': 'indication: -year-old female patient with abdominal pain and pain with inspiration, evaluate for pulmonary process or distended gastric bubble indicative of ileus.',\n",
       "   'findings': 'PA and lateral chest views were obtained with patient in upright position. Relatively high positioned diaphragms indicate poor inspirational effort. There is evidence of free abdominal air accumulating under the diaphragms, most marked on the right side. In addition, moderately air-distended colonic loops are identified. The lateral view also discloses the presence of some densities in the posterior pleural sinuses, probably some fluid accumulation. No other evidence of pulmonary abnormalities and no pneumothorax is seen in the apical area. In comparison with the next preceding similar chest examination of , the subdiaphragmatic air is new. Dr. was paged at 1: m. Dr. the , but did not know the patient. He referred to Dr. , a surgical resident who had taken care of the patient on previous occasions. She was paged at 1: m. Finally the responsible person was identified and was who had issued the request. I was informed that the patient underwent an ileectomy last ( ) which explains the free subdiaphragmatic air. Small amount of pleural effusion in posterior pleural sinuses was conveyed but no major pulmonary abnormalities were seen.',\n",
       "   'impression': '',\n",
       "   'path': '/mnt/data/mimic-cxr/files/p12/p12240747/s52771640.txt'}},\n",
       " 'parsed_response': [['PA and lateral chest views were obtained with patient in upright position',\n",
       "   0],\n",
       "  ['Relatively high positioned diaphragms indicate poor inspirational effort',\n",
       "   1],\n",
       "  ['There is evidence of free abdominal air accumulating under the diaphragms, most marked on the right side',\n",
       "   1],\n",
       "  ['Moderately air-distended colonic loops are identified', 1],\n",
       "  ['Some densities in the posterior pleural sinuses indicate probable fluid accumulation',\n",
       "   1],\n",
       "  ['No other evidence of pulmonary abnormalities is seen', 0],\n",
       "  ['No pneumothorax is seen in the apical area', 0],\n",
       "  ['The subdiaphragmatic air is new compared to the preceding chest examination',\n",
       "   1],\n",
       "  ['The patient underwent an ileectomy last', 1],\n",
       "  ['Small amount of pleural effusion in posterior pleural sinuses was conveyed',\n",
       "   1],\n",
       "  ['No major pulmonary abnormalities were seen', 0]]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b67eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse the following radiological report into a list of short sentences, summarizing the essential information.\n",
      "For each sentence, append the hashtag #positive if the sentence refers to (1) an abnormal finding or disease\n",
      "(if it was observed in a previous exam, or if it has not changed, still output #positive), (2) the presence\n",
      "of a strange visual pattern (e.g., obscurity, lucency, rotation), or (3) the presence of a device, tube, wire,\n",
      "foreign body, etc. Otherwise, append the hashtag #negative.\n",
      "\n",
      "Compared to the prior chest x-ray, there has been some clearing of both bases. The position of the various support lines and tubes is unchanged. Extensive pleural calcification is again noted.\n",
      "Clearing of both bases.\n"
     ]
    }
   ],
   "source": [
    "print(tmp[0][0]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f365e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#negative\n",
      "\n",
      "Position of support lines and tubes unchanged. #negative\n",
      "\n",
      "Extensive pleural calcification noted again. #positive\n"
     ]
    }
   ],
   "source": [
    "print(tmp[0][1]['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e081fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "614ab681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('14', 'Heart is mildly dilated', 'pos')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = re.match(r\"^(\\d+)\\.\\s+(.+)\\s+#(pos|neg)$\", \"14. Heart is mildly dilated #pos\")\n",
    "tmp.groups()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
