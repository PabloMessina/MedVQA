{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19e7a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gpt-3.5-turbo-0301_parsed_sentences.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__hard.jsonl\r\n",
      " gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\r\n",
      " gpt-3.5-turbo_parsed_backgrounds.jsonl\r\n",
      " gpt-3.5-turbo_parsed_reports__backup.jsonl\r\n",
      " gpt-3.5-turbo_parsed_reports.jsonl\r\n",
      "'gpt-3.5-turbo_parsed_reports(old).jsonl'\r\n",
      " gpt-3.5-turbo_parsed_sentences.jsonl\r\n",
      " gpt-4-0613_parsed_reports.jsonl\r\n",
      " gpt-4-0613_parsed_sentences.jsonl\r\n",
      " gpt-4-0613_parsed_sentences__v2.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525b6006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:28:55,288 - \u001b[1;32mINFO\u001b[1;0m - Loading preprocessed reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "100%|█████████████████████████████████| 227835/227835 [00:31<00:00, 7328.39it/s]\n",
      "2023-07-03 16:29:27,051 - \u001b[1;32mINFO\u001b[1;0m - Loaded 227835 reports from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/background_findings_and_impression_20230612_174143.json\n",
      "2023-07-03 16:29:27,051 - \u001b[1;32mINFO\u001b[1;0m - Found 677694 unique sentences to parse\n",
      "2023-07-03 16:29:27,106 - \u001b[1;32mINFO\u001b[1;0m - Sorting sentences by difficulty...\n",
      "100%|█████████████████████████████████| 677694/677694 [02:13<00:00, 5061.74it/s]\n",
      "2023-07-03 16:31:40,992 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 677694/677694 [00:03<00:00, 187561.31it/s]\n",
      "2023-07-03 16:31:47,823 - \u001b[1;32mINFO\u001b[1;0m - Done sorting sentences.\n",
      "2023-07-03 16:31:47,823 - \u001b[1;32mINFO\u001b[1;0m - First sentence: M recently stopped coumadin(afib) p/w L>R pain,abd pain, s/p 's, cold foot s/p L pop cutdown embolectomy L fasciotomy s/p LLE angio embolectomy s/p L guillotine + L BKA // Dobhoff placement - require assistance and sequential imaging.\n",
      "2023-07-03 16:31:47,823 - \u001b[1;32mINFO\u001b[1;0m - Last sentence: .\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to parse: 20000\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to parse:\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 1. Right IJ line terminates at the superior-cavoatrial junction.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 2223. Right upper lobe nodule, unchanged since and non-FDG avid as of .\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 4445. An aortic stent graft begins along the arch of the aorta as before.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 6667. Management alternatives include a short-term followup after treatment or consideration of chest CT to delineate the findings further if needed clinically.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 8889. It continues for about 3 cm in posterior direction before it curves finally with its tip laterally, so that it rests in a posterior lateral obtuse marginal vein of the coronary venous system.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 11111. The cardio-mediastinal silhouette is stable in appearance.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 13333. Diagnostic alternatives are drug report transfusion related edema, or diffuse pulmonary hemorrhage.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 15555. 8:14 PM Interval placement of right pigtail catheter with tip projecting over level of midthoracic spine eccentric to the right.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 17777. Persistent extensive right lung edema or hemorrhage may either be due to a continuation of the same process or new aspiration.\n",
      "2023-07-03 16:31:48,248 - \u001b[1;32mINFO\u001b[1;0m - 20000. Subpulmonic disposition of right effusion, likely unchanged in size.\n",
      "2023-07-03 16:31:48,356 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230703_163148.jsonl\n",
      "2023-07-03 16:31:48,356 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_163148.jsonl\n",
      "2023-07-03 16:31:49,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-03 16:31:49,266 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-07-03 16:31:49,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-07-03 16:31:49,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-07-03 16:31:49,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-07-03 16:31:49,508 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-03 16:31:49,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-07-03 16:31:50,078 - \u001b[1;33mWARNING\u001b[1;0m - Request 119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89758 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,089 - \u001b[1;33mWARNING\u001b[1;0m - Request 127 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89755 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 129 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89752 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89716 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,110 - \u001b[1;33mWARNING\u001b[1;0m - Request 134 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89713 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,111 - \u001b[1;33mWARNING\u001b[1;0m - Request 132 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89710 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,151 - \u001b[1;33mWARNING\u001b[1;0m - Request 122 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89675 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 135 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89397 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:31:50,371 - \u001b[1;33mWARNING\u001b[1;0m - Request 133 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89390 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:05,092 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:05 2023\n",
      "2023-07-03 16:32:05,372 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:05 2023\n",
      "2023-07-03 16:32:05,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #130\n",
      "2023-07-03 16:32:05,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #151\n",
      "2023-07-03 16:32:05,620 - \u001b[1;33mWARNING\u001b[1;0m - Request 161 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:05,624 - \u001b[1;33mWARNING\u001b[1;0m - Request 158 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89295 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:05,626 - \u001b[1;33mWARNING\u001b[1;0m - Request 157 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89304 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:32:19,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 79 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cdebde7638ba4069cc7c504b12a7a76a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:20,622 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:20 2023\n",
      "2023-07-03 16:32:20,627 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:20 2023\n",
      "2023-07-03 16:32:20,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #167\n",
      "2023-07-03 16:32:20,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #187\n",
      "2023-07-03 16:32:20,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 172 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89860 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:20,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 184 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89838 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:35,961 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:35 2023\n",
      "2023-07-03 16:32:35,971 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:35 2023\n",
      "2023-07-03 16:32:36,018 - \u001b[1;32mINFO\u001b[1;0m - Starting request #205\n",
      "2023-07-03 16:32:36,226 - \u001b[1;33mWARNING\u001b[1;0m - Request 223 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89782 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:36,227 - \u001b[1;33mWARNING\u001b[1;0m - Request 219 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:51,242 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:32:51 2023\n",
      "2023-07-03 16:32:51,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #225\n",
      "2023-07-03 16:32:51,312 - \u001b[1;32mINFO\u001b[1;0m - Starting request #243\n",
      "2023-07-03 16:32:51,515 - \u001b[1;33mWARNING\u001b[1;0m - Request 256 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89664 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:51,538 - \u001b[1;33mWARNING\u001b[1;0m - Request 257 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:32:51,698 - \u001b[1;33mWARNING\u001b[1;0m - Request 240 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:06,530 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:06 2023\n",
      "2023-07-03 16:33:06,699 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:06 2023\n",
      "2023-07-03 16:33:06,711 - \u001b[1;32mINFO\u001b[1;0m - Starting request #260\n",
      "2023-07-03 16:33:06,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #280\n",
      "2023-07-03 16:33:08,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 261 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89323 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:08,885 - \u001b[1;33mWARNING\u001b[1;0m - Request 277 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:08,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 293 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89341 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:23,893 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:23 2023\n",
      "2023-07-03 16:33:23,898 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:23 2023\n",
      "2023-07-03 16:33:23,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #297\n",
      "2023-07-03 16:33:23,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #317\n",
      "2023-07-03 16:33:24,183 - \u001b[1;33mWARNING\u001b[1;0m - Request 309 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89932 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:37,074 - \u001b[1;33mWARNING\u001b[1;0m - Request 276 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a84e3d1300e0610ae68f7268ada0ac9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:38,935 - \u001b[1;33mWARNING\u001b[1;0m - Request 267 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c1696ebad0bdf4c518bcb34b9c14877 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:39,184 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:39 2023\n",
      "2023-07-03 16:33:39,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #334\n",
      "2023-07-03 16:33:39,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #354\n",
      "2023-07-03 16:33:39,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 353 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89819 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:39,457 - \u001b[1;33mWARNING\u001b[1;0m - Request 356 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89800 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:39,469 - \u001b[1;33mWARNING\u001b[1;0m - Request 355 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89788 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:33:54,467 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:54 2023\n",
      "2023-07-03 16:33:54,471 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:33:54 2023\n",
      "2023-07-03 16:33:54,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #371\n",
      "2023-07-03 16:33:54,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 387 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89361 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:54,986 - \u001b[1;33mWARNING\u001b[1;0m - Request 377 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:33:55,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 388 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:09,977 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:10 2023\n",
      "2023-07-03 16:34:10,001 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:10 2023\n",
      "2023-07-03 16:34:10,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #377\n",
      "2023-07-03 16:34:10,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #408\n",
      "2023-07-03 16:34:10,261 - \u001b[1;33mWARNING\u001b[1;0m - Request 418 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89934 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:25,273 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:25 2023\n",
      "2023-07-03 16:34:25,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #427\n",
      "2023-07-03 16:34:25,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #447\n",
      "2023-07-03 16:34:30,961 - \u001b[1;33mWARNING\u001b[1;0m - Request 458 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89493 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:30,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 450 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89494 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:30,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 460 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89494 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:31,075 - \u001b[1;33mWARNING\u001b[1;0m - Request 461 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89323 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:45,978 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:46 2023\n",
      "2023-07-03 16:34:46,076 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:34:46 2023\n",
      "2023-07-03 16:34:46,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #458\n",
      "2023-07-03 16:34:46,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #483\n",
      "2023-07-03 16:34:46,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 472 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89792 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:34:46,457 - \u001b[1;33mWARNING\u001b[1;0m - Request 496 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89782 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:01,467 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:01 2023\n",
      "2023-07-03 16:35:01,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #501\n",
      "2023-07-03 16:35:01,550 - \u001b[1;32mINFO\u001b[1;0m - Starting request #521\n",
      "2023-07-03 16:35:01,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 525 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89615 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:16,740 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:16 2023\n",
      "2023-07-03 16:35:16,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #540\n",
      "2023-07-03 16:35:16,842 - \u001b[1;32mINFO\u001b[1;0m - Starting request #560\n",
      "2023-07-03 16:35:17,105 - \u001b[1;33mWARNING\u001b[1;0m - Request 555 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:32,119 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:32 2023\n",
      "2023-07-03 16:35:32,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #579\n",
      "2023-07-03 16:35:32,381 - \u001b[1;33mWARNING\u001b[1;0m - Request 592 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89797 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:32,381 - \u001b[1;33mWARNING\u001b[1;0m - Request 593 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89790 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:32,394 - \u001b[1;33mWARNING\u001b[1;0m - Request 595 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89769 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:32,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 594 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89765 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:32,467 - \u001b[1;33mWARNING\u001b[1;0m - Request 596 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89664 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:35:47,396 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:47 2023\n",
      "2023-07-03 16:35:47,468 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:35:47 2023\n",
      "2023-07-03 16:35:47,470 - \u001b[1;32mINFO\u001b[1;0m - Starting request #593\n",
      "2023-07-03 16:35:47,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #614\n",
      "2023-07-03 16:35:47,717 - \u001b[1;33mWARNING\u001b[1;0m - Request 615 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:35:47,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 625 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89521 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:02,731 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:02 2023\n",
      "2023-07-03 16:36:02,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #632\n",
      "2023-07-03 16:36:02,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #652\n",
      "2023-07-03 16:36:03,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 648 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89334 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:03,269 - \u001b[1;33mWARNING\u001b[1;0m - Request 658 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89633 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:18,015 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:18 2023\n",
      "2023-07-03 16:36:18,272 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:18 2023\n",
      "2023-07-03 16:36:18,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #670\n",
      "2023-07-03 16:36:18,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #690\n",
      "2023-07-03 16:36:18,762 - \u001b[1;33mWARNING\u001b[1;0m - Request 690 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89788 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:18,788 - \u001b[1;33mWARNING\u001b[1;0m - Request 683 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89759 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:18,899 - \u001b[1;33mWARNING\u001b[1;0m - Request 692 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89588 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:33,778 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:33 2023\n",
      "2023-07-03 16:36:33,900 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:33 2023\n",
      "2023-07-03 16:36:33,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #707\n",
      "2023-07-03 16:36:34,324 - \u001b[1;33mWARNING\u001b[1;0m - Request 723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89861 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:34,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 724 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89767 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:49,334 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:49 2023\n",
      "2023-07-03 16:36:49,385 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:36:49 2023\n",
      "2023-07-03 16:36:49,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #724\n",
      "2023-07-03 16:36:49,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #745\n",
      "2023-07-03 16:36:49,656 - \u001b[1;33mWARNING\u001b[1;0m - Request 748 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:36:49,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 747 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89558 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:04,671 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:04 2023\n",
      "2023-07-03 16:37:04,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #763\n",
      "2023-07-03 16:37:04,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #783\n",
      "2023-07-03 16:37:04,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 789 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89906 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:05,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 770 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89705 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:20,006 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:20 2023\n",
      "2023-07-03 16:37:20,127 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:20 2023\n",
      "2023-07-03 16:37:20,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #801\n",
      "2023-07-03 16:37:20,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #821\n",
      "2023-07-03 16:37:20,396 - \u001b[1;33mWARNING\u001b[1;0m - Request 817 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89390 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:20,433 - \u001b[1;33mWARNING\u001b[1;0m - Request 822 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89334 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:35,409 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:35 2023\n",
      "2023-07-03 16:37:35,434 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:35 2023\n",
      "2023-07-03 16:37:35,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #839\n",
      "2023-07-03 16:37:35,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 855 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89594 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:35,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 854 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89583 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:37:50,717 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:50 2023\n",
      "2023-07-03 16:37:50,727 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:37:50 2023\n",
      "2023-07-03 16:37:50,737 - \u001b[1;32mINFO\u001b[1;0m - Starting request #857\n",
      "2023-07-03 16:37:50,802 - \u001b[1;32mINFO\u001b[1;0m - Starting request #877\n",
      "2023-07-03 16:37:51,189 - \u001b[1;33mWARNING\u001b[1;0m - Request 869 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:51,191 - \u001b[1;33mWARNING\u001b[1;0m - Request 876 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89420 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:37:51,197 - \u001b[1;33mWARNING\u001b[1;0m - Request 879 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89404 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:06,201 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:06 2023\n",
      "2023-07-03 16:38:06,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #894\n",
      "2023-07-03 16:38:06,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #914\n",
      "2023-07-03 16:38:06,490 - \u001b[1;33mWARNING\u001b[1;0m - Request 918 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89883 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:06,617 - \u001b[1;33mWARNING\u001b[1;0m - Request 889 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89682 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:21,497 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:21 2023\n",
      "2023-07-03 16:38:21,618 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:21 2023\n",
      "2023-07-03 16:38:21,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #932\n",
      "2023-07-03 16:38:21,882 - \u001b[1;33mWARNING\u001b[1;0m - Request 937 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:21,889 - \u001b[1;33mWARNING\u001b[1;0m - Request 949 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89415 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:36,895 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:36 2023\n",
      "2023-07-03 16:38:36,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #949\n",
      "2023-07-03 16:38:36,972 - \u001b[1;32mINFO\u001b[1;0m - Starting request #970\n",
      "2023-07-03 16:38:37,317 - \u001b[1;33mWARNING\u001b[1;0m - Request 955 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89632 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:37,343 - \u001b[1;33mWARNING\u001b[1;0m - Request 965 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89592 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:52,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:52 2023\n",
      "2023-07-03 16:38:52,345 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:38:52 2023\n",
      "2023-07-03 16:38:52,377 - \u001b[1;32mINFO\u001b[1;0m - Starting request #988\n",
      "2023-07-03 16:38:52,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1008\n",
      "2023-07-03 16:38:52,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 1010 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:38:52,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 986 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89812 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:07,618 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:07 2023\n",
      "2023-07-03 16:39:07,758 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:07 2023\n",
      "2023-07-03 16:39:07,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1026\n",
      "2023-07-03 16:39:08,019 - \u001b[1;33mWARNING\u001b[1;0m - Request 1034 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89688 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:08,144 - \u001b[1;33mWARNING\u001b[1;0m - Request 1045 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89498 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:08,211 - \u001b[1;33mWARNING\u001b[1;0m - Request 1024 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89408 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:23,033 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:23 2023\n",
      "2023-07-03 16:39:23,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1046\n",
      "2023-07-03 16:39:23,213 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:23 2023\n",
      "2023-07-03 16:39:23,282 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1063\n",
      "2023-07-03 16:39:25,056 - \u001b[1;33mWARNING\u001b[1;0m - Request 1077 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89553 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:40,064 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:39:40 2023\n",
      "2023-07-03 16:39:40,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1082\n",
      "2023-07-03 16:39:40,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1102\n",
      "2023-07-03 16:39:44,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1122\n",
      "2023-07-03 16:39:45,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 1119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:45,078 - \u001b[1;33mWARNING\u001b[1;0m - Request 1115 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89619 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:39:45,133 - \u001b[1;33mWARNING\u001b[1;0m - Request 1120 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89531 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:39:45,151 - \u001b[1;33mWARNING\u001b[1;0m - Request 1122 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:00,089 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:00 2023\n",
      "2023-07-03 16:40:00,151 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:00 2023\n",
      "2023-07-03 16:40:00,215 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1138\n",
      "2023-07-03 16:40:01,380 - \u001b[1;33mWARNING\u001b[1;0m - Request 1152 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:01,396 - \u001b[1;33mWARNING\u001b[1;0m - Request 1153 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89399 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:16,395 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:16 2023\n",
      "2023-07-03 16:40:16,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1156\n",
      "2023-07-03 16:40:16,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1176\n",
      "2023-07-03 16:40:16,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 1178 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89984 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:16,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 1185 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:31,672 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:31 2023\n",
      "2023-07-03 16:40:31,794 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:31 2023\n",
      "2023-07-03 16:40:31,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1194\n",
      "2023-07-03 16:40:31,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1214\n",
      "2023-07-03 16:40:32,290 - \u001b[1;33mWARNING\u001b[1;0m - Request 1215 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89866 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:32,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 563 failed with Exception \n",
      "2023-07-03 16:40:47,297 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:40:47 2023\n",
      "2023-07-03 16:40:47,352 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1232\n",
      "2023-07-03 16:40:47,549 - \u001b[1;33mWARNING\u001b[1;0m - Request 1247 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89598 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:47,562 - \u001b[1;33mWARNING\u001b[1;0m - Request 1248 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89594 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:40:47,563 - \u001b[1;33mWARNING\u001b[1;0m - Request 1244 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:02,348 - \u001b[1;33mWARNING\u001b[1;0m - Request 1191 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c7ab15ffafe99d3e330e214947801c1b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:02,550 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:02 2023\n",
      "2023-07-03 16:41:02,565 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:02 2023\n",
      "2023-07-03 16:41:02,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1248\n",
      "2023-07-03 16:41:02,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1268\n",
      "2023-07-03 16:41:02,834 - \u001b[1;33mWARNING\u001b[1;0m - Request 1268 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:02,836 - \u001b[1;33mWARNING\u001b[1;0m - Request 1251 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89366 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:17,848 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:17 2023\n",
      "2023-07-03 16:41:17,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1286\n",
      "2023-07-03 16:41:17,946 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1306\n",
      "2023-07-03 16:41:18,159 - \u001b[1;33mWARNING\u001b[1;0m - Request 1309 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89887 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:18,161 - \u001b[1;33mWARNING\u001b[1;0m - Request 1307 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89838 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:18,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 1310 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89659 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:33,172 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:33 2023\n",
      "2023-07-03 16:41:33,286 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:33 2023\n",
      "2023-07-03 16:41:33,334 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1323\n",
      "2023-07-03 16:41:33,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 1340 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89840 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:41:33,825 - \u001b[1;33mWARNING\u001b[1;0m - Request 1341 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89771 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:48,815 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:48 2023\n",
      "2023-07-03 16:41:48,826 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:41:48 2023\n",
      "2023-07-03 16:41:48,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1340\n",
      "2023-07-03 16:41:48,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1361\n",
      "2023-07-03 16:41:49,277 - \u001b[1;33mWARNING\u001b[1;0m - Request 1349 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89289 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:49,316 - \u001b[1;33mWARNING\u001b[1;0m - Request 1373 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89980 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:41:49,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 725 failed with Exception \n",
      "2023-07-03 16:42:04,283 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:04 2023\n",
      "2023-07-03 16:42:04,317 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:04 2023\n",
      "2023-07-03 16:42:04,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1378\n",
      "2023-07-03 16:42:04,404 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1398\n",
      "2023-07-03 16:42:04,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 1403 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:04,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 1381 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89690 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:19,600 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:19 2023\n",
      "2023-07-03 16:42:19,644 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:19 2023\n",
      "2023-07-03 16:42:19,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1416\n",
      "2023-07-03 16:42:20,128 - \u001b[1;33mWARNING\u001b[1;0m - Request 1429 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89878 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:20,134 - \u001b[1;33mWARNING\u001b[1;0m - Request 1427 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89875 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:35,141 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:35 2023\n",
      "2023-07-03 16:42:35,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1436\n",
      "2023-07-03 16:42:35,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1454\n",
      "2023-07-03 16:42:35,480 - \u001b[1;33mWARNING\u001b[1;0m - Request 1465 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89530 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:35,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 1453 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89518 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:35,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 1450 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:50,494 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:50 2023\n",
      "2023-07-03 16:42:50,511 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:42:50 2023\n",
      "2023-07-03 16:42:50,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1471\n",
      "2023-07-03 16:42:50,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1491\n",
      "2023-07-03 16:42:51,106 - \u001b[1;33mWARNING\u001b[1;0m - Request 1491 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89449 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:51,119 - \u001b[1;33mWARNING\u001b[1;0m - Request 1498 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:42:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 887 failed with Exception \n",
      "2023-07-03 16:43:06,111 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:06 2023\n",
      "2023-07-03 16:43:06,120 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:06 2023\n",
      "2023-07-03 16:43:06,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1508\n",
      "2023-07-03 16:43:06,220 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1528\n",
      "2023-07-03 16:43:06,610 - \u001b[1;33mWARNING\u001b[1;0m - Request 1491 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89616 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:06,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 1525 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89618 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:21,623 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:21 2023\n",
      "2023-07-03 16:43:21,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1546\n",
      "2023-07-03 16:43:22,407 - \u001b[1;33mWARNING\u001b[1;0m - Request 1531 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:22,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 1538 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:43:37,420 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:37 2023\n",
      "2023-07-03 16:43:37,436 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:37 2023\n",
      "2023-07-03 16:43:37,442 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1564\n",
      "2023-07-03 16:43:37,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1584\n",
      "2023-07-03 16:43:41,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 1603 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:42,018 - \u001b[1;33mWARNING\u001b[1;0m - Request 1595 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89319 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:42,211 - \u001b[1;33mWARNING\u001b[1;0m - Request 1600 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89744 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:56,969 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:57 2023\n",
      "2023-07-03 16:43:56,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1604\n",
      "2023-07-03 16:43:57,212 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:43:57 2023\n",
      "2023-07-03 16:43:57,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1621\n",
      "2023-07-03 16:43:57,575 - \u001b[1;33mWARNING\u001b[1;0m - Request 1632 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89351 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:57,578 - \u001b[1;33mWARNING\u001b[1;0m - Request 1630 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89351 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:43:57,579 - \u001b[1;33mWARNING\u001b[1;0m - Request 1634 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:12,588 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:12 2023\n",
      "2023-07-03 16:44:12,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1638\n",
      "2023-07-03 16:44:12,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1658\n",
      "2023-07-03 16:44:14,788 - \u001b[1;33mWARNING\u001b[1;0m - Request 1654 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89885 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:14,892 - \u001b[1;33mWARNING\u001b[1;0m - Request 1665 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:29,795 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:29 2023\n",
      "2023-07-03 16:44:29,893 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:29 2023\n",
      "2023-07-03 16:44:29,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1676\n",
      "2023-07-03 16:44:29,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1696\n",
      "2023-07-03 16:44:30,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 1696 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:30,231 - \u001b[1;33mWARNING\u001b[1;0m - Request 1692 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89429 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:30,313 - \u001b[1;33mWARNING\u001b[1;0m - Request 1691 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89371 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:45,196 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:45 2023\n",
      "2023-07-03 16:44:45,314 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:44:45 2023\n",
      "2023-07-03 16:44:45,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1713\n",
      "2023-07-03 16:44:45,581 - \u001b[1;33mWARNING\u001b[1;0m - Request 1729 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89919 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:44:45,937 - \u001b[1;33mWARNING\u001b[1;0m - Request 1732 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:00,594 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:00 2023\n",
      "2023-07-03 16:45:00,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1733\n",
      "2023-07-03 16:45:00,939 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:00 2023\n",
      "2023-07-03 16:45:01,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1751\n",
      "2023-07-03 16:45:01,226 - \u001b[1;33mWARNING\u001b[1;0m - Request 1761 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89864 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:01,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 1748 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89561 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:16,240 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:16 2023\n",
      "2023-07-03 16:45:16,407 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:16 2023\n",
      "2023-07-03 16:45:16,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1769\n",
      "2023-07-03 16:45:16,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1789\n",
      "2023-07-03 16:45:16,679 - \u001b[1;33mWARNING\u001b[1;0m - Request 1794 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89278 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:45:16,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 1788 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:31,693 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:31 2023\n",
      "2023-07-03 16:45:31,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1807\n",
      "2023-07-03 16:45:31,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1827\n",
      "2023-07-03 16:45:32,370 - \u001b[1;33mWARNING\u001b[1;0m - Request 1805 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89797 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:32,373 - \u001b[1;33mWARNING\u001b[1;0m - Request 1818 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89793 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:32,435 - \u001b[1;33mWARNING\u001b[1;0m - Request 1829 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89683 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:45:47,382 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:47 2023\n",
      "2023-07-03 16:45:47,436 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:45:47 2023\n",
      "2023-07-03 16:45:47,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1844\n",
      "2023-07-03 16:45:47,937 - \u001b[1;33mWARNING\u001b[1;0m - Request 1849 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89790 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:02,951 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:02 2023\n",
      "2023-07-03 16:46:02,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1863\n",
      "2023-07-03 16:46:03,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1883\n",
      "2023-07-03 16:46:03,233 - \u001b[1;33mWARNING\u001b[1;0m - Request 1886 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:03,272 - \u001b[1;33mWARNING\u001b[1;0m - Request 1878 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:03,662 - \u001b[1;33mWARNING\u001b[1;0m - Request 1865 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89580 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:18,247 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:18 2023\n",
      "2023-07-03 16:46:18,663 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:18 2023\n",
      "2023-07-03 16:46:18,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1900\n",
      "2023-07-03 16:46:18,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1920\n",
      "2023-07-03 16:46:19,279 - \u001b[1;33mWARNING\u001b[1;0m - Request 1919 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89655 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:19,279 - \u001b[1;33mWARNING\u001b[1;0m - Request 1925 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89656 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:19,280 - \u001b[1;33mWARNING\u001b[1;0m - Request 1921 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89674 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:34,293 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:34 2023\n",
      "2023-07-03 16:46:34,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1937\n",
      "2023-07-03 16:46:34,604 - \u001b[1;33mWARNING\u001b[1;0m - Request 1956 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:49,617 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:46:49 2023\n",
      "2023-07-03 16:46:49,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1957\n",
      "2023-07-03 16:46:49,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1976\n",
      "2023-07-03 16:46:49,876 - \u001b[1;33mWARNING\u001b[1;0m - Request 1985 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89768 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:49,877 - \u001b[1;33mWARNING\u001b[1;0m - Request 1968 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89765 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:46:50,093 - \u001b[1;33mWARNING\u001b[1;0m - Request 1982 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:04,890 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:05 2023\n",
      "2023-07-03 16:47:05,094 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:05 2023\n",
      "2023-07-03 16:47:05,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1993\n",
      "2023-07-03 16:47:05,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2013\n",
      "2023-07-03 16:47:05,619 - \u001b[1;33mWARNING\u001b[1;0m - Request 2019 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89549 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:05,717 - \u001b[1;33mWARNING\u001b[1;0m - Request 2020 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:47:05,810 - \u001b[1;33mWARNING\u001b[1;0m - Request 2010 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89286 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:20,630 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:20 2023\n",
      "2023-07-03 16:47:20,811 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:20 2023\n",
      "2023-07-03 16:47:20,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2030\n",
      "2023-07-03 16:47:20,904 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2050\n",
      "2023-07-03 16:47:21,210 - \u001b[1;33mWARNING\u001b[1;0m - Request 2032 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:21,211 - \u001b[1;33mWARNING\u001b[1;0m - Request 2040 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89471 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:21,326 - \u001b[1;33mWARNING\u001b[1;0m - Request 2052 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89293 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:36,224 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:36 2023\n",
      "2023-07-03 16:47:36,327 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:36 2023\n",
      "2023-07-03 16:47:36,383 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2067\n",
      "2023-07-03 16:47:38,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2087\n",
      "2023-07-03 16:47:38,902 - \u001b[1;33mWARNING\u001b[1;0m - Request 2067 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89971 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:39,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 2088 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89783 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:51,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 1488 failed with Exception \n",
      "2023-07-03 16:47:53,906 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:54 2023\n",
      "2023-07-03 16:47:54,030 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:47:54 2023\n",
      "2023-07-03 16:47:54,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2104\n",
      "2023-07-03 16:47:54,456 - \u001b[1;33mWARNING\u001b[1;0m - Request 2119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89305 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:54,462 - \u001b[1;33mWARNING\u001b[1;0m - Request 2096 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89304 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:47:54,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 2104 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89274 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:09,465 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:09 2023\n",
      "2023-07-03 16:48:09,505 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:09 2023\n",
      "2023-07-03 16:48:09,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2121\n",
      "2023-07-03 16:48:09,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2141\n",
      "2023-07-03 16:48:09,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 2149 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89284 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:24,993 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:24 2023\n",
      "2023-07-03 16:48:25,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2160\n",
      "2023-07-03 16:48:25,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2180\n",
      "2023-07-03 16:48:25,257 - \u001b[1;33mWARNING\u001b[1;0m - Request 2179 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89707 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:25,258 - \u001b[1;33mWARNING\u001b[1;0m - Request 2175 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89708 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:25,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 2181 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89687 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:40,270 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:40 2023\n",
      "2023-07-03 16:48:40,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2197\n",
      "2023-07-03 16:48:40,828 - \u001b[1;33mWARNING\u001b[1;0m - Request 2204 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89756 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:40,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 2214 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89531 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:48:55,837 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:55 2023\n",
      "2023-07-03 16:48:55,975 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:48:55 2023\n",
      "2023-07-03 16:48:55,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2214\n",
      "2023-07-03 16:48:56,045 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2235\n",
      "2023-07-03 16:49:00,087 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2255\n",
      "2023-07-03 16:49:00,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 2228 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89674 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:00,912 - \u001b[1;33mWARNING\u001b[1;0m - Request 2238 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89660 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:00,925 - \u001b[1;33mWARNING\u001b[1;0m - Request 2254 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:49:15,925 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:15 2023\n",
      "2023-07-03 16:49:15,986 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2272\n",
      "2023-07-03 16:49:16,194 - \u001b[1;33mWARNING\u001b[1;0m - Request 2285 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89499 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:16,235 - \u001b[1;33mWARNING\u001b[1;0m - Request 2287 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:16,244 - \u001b[1;33mWARNING\u001b[1;0m - Request 2280 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89467 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:31,207 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:31 2023\n",
      "2023-07-03 16:49:31,244 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:31 2023\n",
      "2023-07-03 16:49:31,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2289\n",
      "2023-07-03 16:49:31,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2309\n",
      "2023-07-03 16:49:34,842 - \u001b[1;33mWARNING\u001b[1;0m - Request 2312 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:34,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 2307 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89275 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:49,855 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:49 2023\n",
      "2023-07-03 16:49:49,881 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:49:49 2023\n",
      "2023-07-03 16:49:49,887 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2327\n",
      "2023-07-03 16:49:49,978 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2347\n",
      "2023-07-03 16:49:50,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 2351 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89597 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:50,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 2357 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89594 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:49:50,363 - \u001b[1;33mWARNING\u001b[1;0m - Request 2330 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89315 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:05,189 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:05 2023\n",
      "2023-07-03 16:50:05,364 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:05 2023\n",
      "2023-07-03 16:50:05,508 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2364\n",
      "2023-07-03 16:50:05,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2384\n",
      "2023-07-03 16:50:05,815 - \u001b[1;33mWARNING\u001b[1;0m - Request 2367 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89539 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:20,829 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:20 2023\n",
      "2023-07-03 16:50:20,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2403\n",
      "2023-07-03 16:50:21,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 2421 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89858 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:21,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 2419 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89846 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:21,112 - \u001b[1;33mWARNING\u001b[1;0m - Request 2420 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89828 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:36,105 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:36 2023\n",
      "2023-07-03 16:50:36,113 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:36 2023\n",
      "2023-07-03 16:50:36,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2421\n",
      "2023-07-03 16:50:36,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2440\n",
      "2023-07-03 16:50:36,401 - \u001b[1;33mWARNING\u001b[1;0m - Request 2445 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:36,406 - \u001b[1;33mWARNING\u001b[1;0m - Request 2452 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89484 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:36,413 - \u001b[1;33mWARNING\u001b[1;0m - Request 2447 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89502 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:51,416 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:50:51 2023\n",
      "2023-07-03 16:50:51,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2457\n",
      "2023-07-03 16:50:51,505 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2477\n",
      "2023-07-03 16:50:51,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 2479 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:50:51,993 - \u001b[1;33mWARNING\u001b[1;0m - Request 2483 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89313 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:51:06,930 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:06 2023\n",
      "2023-07-03 16:51:06,995 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:06 2023\n",
      "2023-07-03 16:51:07,043 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2495\n",
      "2023-07-03 16:51:07,101 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2515\n",
      "2023-07-03 16:51:07,278 - \u001b[1;33mWARNING\u001b[1;0m - Request 2515 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89769 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:07,509 - \u001b[1;33mWARNING\u001b[1;0m - Request 2509 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89450 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:22,291 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:22 2023\n",
      "2023-07-03 16:51:22,511 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:22 2023\n",
      "2023-07-03 16:51:22,575 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2533\n",
      "2023-07-03 16:51:22,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 2541 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89925 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:22,830 - \u001b[1;33mWARNING\u001b[1;0m - Request 2537 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89864 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:37,808 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:37 2023\n",
      "2023-07-03 16:51:37,831 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:37 2023\n",
      "2023-07-03 16:51:37,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2551\n",
      "2023-07-03 16:51:37,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2571\n",
      "2023-07-03 16:51:38,113 - \u001b[1;33mWARNING\u001b[1;0m - Request 2573 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89639 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:38,114 - \u001b[1;33mWARNING\u001b[1;0m - Request 2577 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89639 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:38,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 2548 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89495 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:52,779 - \u001b[1;33mWARNING\u001b[1;0m - Request 2528 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 935b062ddfa9d2a0e849227bc9962898 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:53,114 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:53 2023\n",
      "2023-07-03 16:51:53,207 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:51:53 2023\n",
      "2023-07-03 16:51:53,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2587\n",
      "2023-07-03 16:51:53,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2607\n",
      "2023-07-03 16:51:53,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 2609 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89873 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:51:53,466 - \u001b[1;33mWARNING\u001b[1;0m - Request 2608 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89881 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:08,473 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:08 2023\n",
      "2023-07-03 16:52:08,531 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2625\n",
      "2023-07-03 16:52:08,733 - \u001b[1;33mWARNING\u001b[1;0m - Request 2640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89552 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:08,734 - \u001b[1;33mWARNING\u001b[1;0m - Request 2637 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:23,745 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:23 2023\n",
      "2023-07-03 16:52:23,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2643\n",
      "2023-07-03 16:52:23,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2663\n",
      "2023-07-03 16:52:23,994 - \u001b[1;33mWARNING\u001b[1;0m - Request 2672 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89402 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:24,007 - \u001b[1;33mWARNING\u001b[1;0m - Request 2661 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89405 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:39,008 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:39 2023\n",
      "2023-07-03 16:52:39,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2681\n",
      "2023-07-03 16:52:39,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2701\n",
      "2023-07-03 16:52:39,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 2699 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89884 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:39,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 2701 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89843 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:39,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 2704 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89669 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:52:54,315 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:54 2023\n",
      "2023-07-03 16:52:54,442 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:52:54 2023\n",
      "2023-07-03 16:52:54,499 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2718\n",
      "2023-07-03 16:52:54,702 - \u001b[1;33mWARNING\u001b[1;0m - Request 2734 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89592 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:52:54,707 - \u001b[1;33mWARNING\u001b[1;0m - Request 2722 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89586 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:09,704 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:09 2023\n",
      "2023-07-03 16:53:09,708 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:09 2023\n",
      "2023-07-03 16:53:09,715 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2736\n",
      "2023-07-03 16:53:09,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2756\n",
      "2023-07-03 16:53:10,367 - \u001b[1;33mWARNING\u001b[1;0m - Request 2767 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89374 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:10,386 - \u001b[1;33mWARNING\u001b[1;0m - Request 2761 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:10,399 - \u001b[1;33mWARNING\u001b[1;0m - Request 2754 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:25,380 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:25 2023\n",
      "2023-07-03 16:53:25,400 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:25 2023\n",
      "2023-07-03 16:53:25,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2773\n",
      "2023-07-03 16:53:25,489 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2793\n",
      "2023-07-03 16:53:25,761 - \u001b[1;33mWARNING\u001b[1;0m - Request 2798 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89629 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:25,887 - \u001b[1;33mWARNING\u001b[1;0m - Request 2792 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89446 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:40,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 2203 failed with Exception \n",
      "2023-07-03 16:53:40,763 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:40 2023\n",
      "2023-07-03 16:53:40,888 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:40 2023\n",
      "2023-07-03 16:53:40,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2810\n",
      "2023-07-03 16:53:41,172 - \u001b[1;33mWARNING\u001b[1;0m - Request 2829 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89914 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:41,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 2827 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89591 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:56,185 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:56 2023\n",
      "2023-07-03 16:53:56,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2830\n",
      "2023-07-03 16:53:56,398 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:53:56 2023\n",
      "2023-07-03 16:53:56,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2848\n",
      "2023-07-03 16:53:56,902 - \u001b[1;33mWARNING\u001b[1;0m - Request 2859 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89755 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:53:56,924 - \u001b[1;33mWARNING\u001b[1;0m - Request 2861 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:11,904 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:11 2023\n",
      "2023-07-03 16:54:11,925 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:11 2023\n",
      "2023-07-03 16:54:11,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2866\n",
      "2023-07-03 16:54:12,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2886\n",
      "2023-07-03 16:54:14,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 2870 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89564 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:14,169 - \u001b[1;33mWARNING\u001b[1;0m - Request 2864 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:14,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 2872 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:29,060 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:29 2023\n",
      "2023-07-03 16:54:29,186 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:29 2023\n",
      "2023-07-03 16:54:29,204 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2903\n",
      "2023-07-03 16:54:29,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2923\n",
      "2023-07-03 16:54:29,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 2927 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89469 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:29,738 - \u001b[1;33mWARNING\u001b[1;0m - Request 2929 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89376 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:54:44,692 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:44 2023\n",
      "2023-07-03 16:54:44,739 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:54:44 2023\n",
      "2023-07-03 16:54:44,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2941\n",
      "2023-07-03 16:54:44,991 - \u001b[1;33mWARNING\u001b[1;0m - Request 2956 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:45,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 2936 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89966 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:54:59,999 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:00 2023\n",
      "2023-07-03 16:55:00,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2961\n",
      "2023-07-03 16:55:00,010 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:00 2023\n",
      "2023-07-03 16:55:00,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2979\n",
      "2023-07-03 16:55:00,277 - \u001b[1;33mWARNING\u001b[1;0m - Request 2967 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89637 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:00,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 2991 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:00,351 - \u001b[1;33mWARNING\u001b[1;0m - Request 2965 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89539 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:15,292 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:15 2023\n",
      "2023-07-03 16:55:15,351 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:15 2023\n",
      "2023-07-03 16:55:15,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2996\n",
      "2023-07-03 16:55:15,435 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3016\n",
      "2023-07-03 16:55:15,613 - \u001b[1;33mWARNING\u001b[1;0m - Request 3020 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:15,626 - \u001b[1;33mWARNING\u001b[1;0m - Request 3005 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:30,627 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:30 2023\n",
      "2023-07-03 16:55:30,672 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3034\n",
      "2023-07-03 16:55:30,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3054\n",
      "2023-07-03 16:55:31,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 3055 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89532 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:46,014 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:55:46 2023\n",
      "2023-07-03 16:55:46,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3073\n",
      "2023-07-03 16:55:46,295 - \u001b[1;33mWARNING\u001b[1;0m - Request 3087 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89360 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:46,301 - \u001b[1;33mWARNING\u001b[1;0m - Request 3084 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:55:46,318 - \u001b[1;33mWARNING\u001b[1;0m - Request 3073 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:01,305 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:01 2023\n",
      "2023-07-03 16:56:01,319 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:01 2023\n",
      "2023-07-03 16:56:01,335 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3090\n",
      "2023-07-03 16:56:01,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3110\n",
      "2023-07-03 16:56:01,589 - \u001b[1;33mWARNING\u001b[1;0m - Request 3107 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:01,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 3110 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89770 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:01,725 - \u001b[1;33mWARNING\u001b[1;0m - Request 3094 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89575 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:16,604 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:16 2023\n",
      "2023-07-03 16:56:16,726 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:16 2023\n",
      "2023-07-03 16:56:16,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3127\n",
      "2023-07-03 16:56:16,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3147\n",
      "2023-07-03 16:56:16,993 - \u001b[1;33mWARNING\u001b[1;0m - Request 3148 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89293 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:17,037 - \u001b[1;33mWARNING\u001b[1;0m - Request 3143 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89959 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:32,006 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:32 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:56:32,039 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:32 2023\n",
      "2023-07-03 16:56:32,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3165\n",
      "2023-07-03 16:56:32,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 3179 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89673 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:32,297 - \u001b[1;33mWARNING\u001b[1;0m - Request 3181 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:32,309 - \u001b[1;33mWARNING\u001b[1;0m - Request 3180 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:47,310 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:56:47 2023\n",
      "2023-07-03 16:56:47,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3180\n",
      "2023-07-03 16:56:47,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3202\n",
      "2023-07-03 16:56:47,590 - \u001b[1;33mWARNING\u001b[1;0m - Request 3202 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:47,610 - \u001b[1;33mWARNING\u001b[1;0m - Request 3187 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89303 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:56:47,617 - \u001b[1;33mWARNING\u001b[1;0m - Request 3182 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89297 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:02,604 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:02 2023\n",
      "2023-07-03 16:57:02,618 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:02 2023\n",
      "2023-07-03 16:57:02,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3219\n",
      "2023-07-03 16:57:02,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3239\n",
      "2023-07-03 16:57:02,995 - \u001b[1;33mWARNING\u001b[1;0m - Request 3238 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:03,006 - \u001b[1;33mWARNING\u001b[1;0m - Request 3243 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89558 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:18,009 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:18 2023\n",
      "2023-07-03 16:57:18,064 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3257\n",
      "2023-07-03 16:57:18,298 - \u001b[1;33mWARNING\u001b[1;0m - Request 3273 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89952 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:18,385 - \u001b[1;33mWARNING\u001b[1;0m - Request 3275 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89825 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:32,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 3225 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 125d73ec0502af1baffaac4280003745 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:33,300 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:33 2023\n",
      "2023-07-03 16:57:33,386 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:33 2023\n",
      "2023-07-03 16:57:33,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3273\n",
      "2023-07-03 16:57:33,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3294\n",
      "2023-07-03 16:57:33,662 - \u001b[1;33mWARNING\u001b[1;0m - Request 3300 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89530 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:33,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 3303 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89535 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:33,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 3306 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:48,677 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:48 2023\n",
      "2023-07-03 16:57:48,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:57:48 2023\n",
      "2023-07-03 16:57:48,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3311\n",
      "2023-07-03 16:57:48,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3331\n",
      "2023-07-03 16:57:49,109 - \u001b[1;33mWARNING\u001b[1;0m - Request 3335 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89766 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:57:49,220 - \u001b[1;33mWARNING\u001b[1;0m - Request 3337 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89592 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:04,122 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:04 2023\n",
      "2023-07-03 16:58:04,221 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:04 2023\n",
      "2023-07-03 16:58:04,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3349\n",
      "2023-07-03 16:58:04,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3369\n",
      "2023-07-03 16:58:04,567 - \u001b[1;33mWARNING\u001b[1;0m - Request 3354 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89748 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:04,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 3364 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89735 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 16:58:19,580 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:19 2023\n",
      "2023-07-03 16:58:19,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3387\n",
      "2023-07-03 16:58:19,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 3401 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:19,888 - \u001b[1;33mWARNING\u001b[1;0m - Request 3397 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89291 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:34,892 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:34 2023\n",
      "2023-07-03 16:58:34,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3405\n",
      "2023-07-03 16:58:34,978 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3425\n",
      "2023-07-03 16:58:35,171 - \u001b[1;33mWARNING\u001b[1;0m - Request 3408 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89645 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:35,186 - \u001b[1;33mWARNING\u001b[1;0m - Request 3407 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:35,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 3433 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:50,185 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:50 2023\n",
      "2023-07-03 16:58:50,206 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:58:50 2023\n",
      "2023-07-03 16:58:50,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3442\n",
      "2023-07-03 16:58:50,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3462\n",
      "2023-07-03 16:58:50,582 - \u001b[1;33mWARNING\u001b[1;0m - Request 3464 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89859 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:58:50,639 - \u001b[1;33mWARNING\u001b[1;0m - Request 3445 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89771 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:05,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 3422 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3f8cf6eb5aab45aeff7335b5d1ac9b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:05,584 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:05 2023\n",
      "2023-07-03 16:59:05,640 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:05 2023\n",
      "2023-07-03 16:59:05,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3479\n",
      "2023-07-03 16:59:07,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3499\n",
      "2023-07-03 16:59:09,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 3497 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89530 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:09,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 3471 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:09,368 - \u001b[1;33mWARNING\u001b[1;0m - Request 3466 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89343 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:24,243 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:24 2023\n",
      "2023-07-03 16:59:24,369 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:24 2023\n",
      "2023-07-03 16:59:24,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3516\n",
      "2023-07-03 16:59:25,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3536\n",
      "2023-07-03 16:59:28,382 - \u001b[1;33mWARNING\u001b[1;0m - Request 3524 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89898 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:43,397 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 16:59:43 2023\n",
      "2023-07-03 16:59:43,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3555\n",
      "2023-07-03 16:59:43,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3575\n",
      "2023-07-03 16:59:45,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2933 failed with Exception \n",
      "2023-07-03 16:59:46,789 - \u001b[1;33mWARNING\u001b[1;0m - Request 3568 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89279 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:46,791 - \u001b[1;33mWARNING\u001b[1;0m - Request 3565 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89281 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:46,820 - \u001b[1;33mWARNING\u001b[1;0m - Request 3558 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89958 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 16:59:46,826 - \u001b[1;33mWARNING\u001b[1;0m - Request 3544 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89955 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:01,794 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:01 2023\n",
      "2023-07-03 17:00:01,828 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:01 2023\n",
      "2023-07-03 17:00:01,877 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3590\n",
      "2023-07-03 17:00:01,948 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3610\n",
      "2023-07-03 17:00:02,521 - \u001b[1;33mWARNING\u001b[1;0m - Request 3604 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89868 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:00:02,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 3608 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:17,534 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:17 2023\n",
      "2023-07-03 17:00:17,874 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:17 2023\n",
      "2023-07-03 17:00:17,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3628\n",
      "2023-07-03 17:00:18,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 3642 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89842 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:18,162 - \u001b[1;33mWARNING\u001b[1;0m - Request 3641 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89820 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:18,169 - \u001b[1;33mWARNING\u001b[1;0m - Request 3640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89790 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:33,137 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:33 2023\n",
      "2023-07-03 17:00:33,170 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:33 2023\n",
      "2023-07-03 17:00:33,178 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3645\n",
      "2023-07-03 17:00:33,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3665\n",
      "2023-07-03 17:00:33,464 - \u001b[1;33mWARNING\u001b[1;0m - Request 3671 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:33,476 - \u001b[1;33mWARNING\u001b[1;0m - Request 3672 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89309 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:33,490 - \u001b[1;33mWARNING\u001b[1;0m - Request 3669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:48,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:48 2023\n",
      "2023-07-03 17:00:48,491 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:00:48 2023\n",
      "2023-07-03 17:00:48,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3682\n",
      "2023-07-03 17:00:48,584 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3702\n",
      "2023-07-03 17:00:48,756 - \u001b[1;33mWARNING\u001b[1;0m - Request 3704 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89782 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:00:48,765 - \u001b[1;33mWARNING\u001b[1;0m - Request 3705 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89787 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:03,768 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:03 2023\n",
      "2023-07-03 17:01:03,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3720\n",
      "2023-07-03 17:01:04,044 - \u001b[1;33mWARNING\u001b[1;0m - Request 3736 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89595 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:04,144 - \u001b[1;33mWARNING\u001b[1;0m - Request 3737 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:17,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 3146 failed with Exception \n",
      "2023-07-03 17:01:19,047 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:19 2023\n",
      "2023-07-03 17:01:19,145 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:19 2023\n",
      "2023-07-03 17:01:19,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3737\n",
      "2023-07-03 17:01:19,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3757\n",
      "2023-07-03 17:01:19,400 - \u001b[1;33mWARNING\u001b[1;0m - Request 3767 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89843 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:19,409 - \u001b[1;33mWARNING\u001b[1;0m - Request 3749 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89829 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:19,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 3768 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89677 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:32,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 3172 failed with Exception \n",
      "2023-07-03 17:01:34,405 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:34 2023\n",
      "2023-07-03 17:01:34,509 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:34 2023\n",
      "2023-07-03 17:01:34,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3773\n",
      "2023-07-03 17:01:34,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3793\n",
      "2023-07-03 17:01:34,803 - \u001b[1;33mWARNING\u001b[1;0m - Request 3789 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:34,979 - \u001b[1;33mWARNING\u001b[1;0m - Request 3781 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89820 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:49,809 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:49 2023\n",
      "2023-07-03 17:01:49,980 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:01:49 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:01:50,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3811\n",
      "2023-07-03 17:01:50,244 - \u001b[1;33mWARNING\u001b[1;0m - Request 3815 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:50,248 - \u001b[1;33mWARNING\u001b[1;0m - Request 3819 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89407 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:01:50,263 - \u001b[1;33mWARNING\u001b[1;0m - Request 3829 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:05,258 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:05 2023\n",
      "2023-07-03 17:02:05,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3831\n",
      "2023-07-03 17:02:05,264 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:05 2023\n",
      "2023-07-03 17:02:05,331 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3848\n",
      "2023-07-03 17:02:05,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 3859 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89742 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:05,638 - \u001b[1;33mWARNING\u001b[1;0m - Request 3861 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89673 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:20,605 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:20 2023\n",
      "2023-07-03 17:02:20,640 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:20 2023\n",
      "2023-07-03 17:02:20,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3866\n",
      "2023-07-03 17:02:20,725 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3886\n",
      "2023-07-03 17:02:20,891 - \u001b[1;33mWARNING\u001b[1;0m - Request 3891 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:20,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 3889 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89384 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:35,638 - \u001b[1;33mWARNING\u001b[1;0m - Request 3846 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ee342f62e0cca98964478a8bc424491f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:35,893 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:35 2023\n",
      "2023-07-03 17:02:35,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3903\n",
      "2023-07-03 17:02:35,995 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3923\n",
      "2023-07-03 17:02:36,156 - \u001b[1;33mWARNING\u001b[1;0m - Request 3917 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89911 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:36,159 - \u001b[1;33mWARNING\u001b[1;0m - Request 3923 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89918 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:51,168 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:02:51 2023\n",
      "2023-07-03 17:02:51,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3941\n",
      "2023-07-03 17:02:51,471 - \u001b[1;33mWARNING\u001b[1;0m - Request 3954 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:02:51,576 - \u001b[1;33mWARNING\u001b[1;0m - Request 3923 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:06,484 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:06 2023\n",
      "2023-07-03 17:03:06,577 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:06 2023\n",
      "2023-07-03 17:03:06,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3959\n",
      "2023-07-03 17:03:06,655 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3979\n",
      "2023-07-03 17:03:06,839 - \u001b[1;33mWARNING\u001b[1;0m - Request 3972 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89692 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:06,842 - \u001b[1;33mWARNING\u001b[1;0m - Request 3981 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89689 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:06,843 - \u001b[1;33mWARNING\u001b[1;0m - Request 3979 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89686 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:21,854 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:21 2023\n",
      "2023-07-03 17:03:21,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3996\n",
      "2023-07-03 17:03:21,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4016\n",
      "2023-07-03 17:03:22,110 - \u001b[1;33mWARNING\u001b[1;0m - Request 4017 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89313 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:22,120 - \u001b[1;33mWARNING\u001b[1;0m - Request 4005 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89304 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:03:22,131 - \u001b[1;33mWARNING\u001b[1;0m - Request 4015 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89288 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:37,121 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:37 2023\n",
      "2023-07-03 17:03:37,133 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:37 2023\n",
      "2023-07-03 17:03:37,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4033\n",
      "2023-07-03 17:03:37,645 - \u001b[1;33mWARNING\u001b[1;0m - Request 4049 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89947 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:37,785 - \u001b[1;33mWARNING\u001b[1;0m - Request 4050 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89737 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:50,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 3446 failed with Exception \n",
      "2023-07-03 17:03:52,648 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:52 2023\n",
      "2023-07-03 17:03:52,787 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:03:52 2023\n",
      "2023-07-03 17:03:52,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4050\n",
      "2023-07-03 17:03:52,857 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4070\n",
      "2023-07-03 17:03:53,982 - \u001b[1;33mWARNING\u001b[1;0m - Request 4075 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89418 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:53,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 3446 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89402 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:03:54,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 4083 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:08,991 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:09 2023\n",
      "2023-07-03 17:04:09,028 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:09 2023\n",
      "2023-07-03 17:04:09,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4087\n",
      "2023-07-03 17:04:09,127 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4107\n",
      "2023-07-03 17:04:09,884 - \u001b[1;33mWARNING\u001b[1;0m - Request 4098 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89515 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:09,900 - \u001b[1;33mWARNING\u001b[1;0m - Request 4103 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89495 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:24,899 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:24 2023\n",
      "2023-07-03 17:04:24,902 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:24 2023\n",
      "2023-07-03 17:04:24,943 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4125\n",
      "2023-07-03 17:04:25,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4145\n",
      "2023-07-03 17:04:25,344 - \u001b[1;33mWARNING\u001b[1;0m - Request 4137 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89586 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:25,436 - \u001b[1;33mWARNING\u001b[1;0m - Request 4139 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89442 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:40,357 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:40 2023\n",
      "2023-07-03 17:04:40,437 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:40 2023\n",
      "2023-07-03 17:04:40,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4163\n",
      "2023-07-03 17:04:40,691 - \u001b[1;33mWARNING\u001b[1;0m - Request 4179 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89831 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:40,696 - \u001b[1;33mWARNING\u001b[1;0m - Request 4178 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89822 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:55,704 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:04:55 2023\n",
      "2023-07-03 17:04:55,712 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4181\n",
      "2023-07-03 17:04:55,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4201\n",
      "2023-07-03 17:04:55,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 4209 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:04:55,968 - \u001b[1;33mWARNING\u001b[1;0m - Request 4211 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89450 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:10,981 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:10 2023\n",
      "2023-07-03 17:05:11,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4219\n",
      "2023-07-03 17:05:11,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4239\n",
      "2023-07-03 17:05:11,619 - \u001b[1;33mWARNING\u001b[1;0m - Request 4243 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89428 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:11,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 4223 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:11,653 - \u001b[1;33mWARNING\u001b[1;0m - Request 4234 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:05:26,629 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:26 2023\n",
      "2023-07-03 17:05:26,653 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:26 2023\n",
      "2023-07-03 17:05:26,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4256\n",
      "2023-07-03 17:05:27,142 - \u001b[1;33mWARNING\u001b[1;0m - Request 4267 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89985 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:27,449 - \u001b[1;33mWARNING\u001b[1;0m - Request 4266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89523 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:42,144 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:42 2023\n",
      "2023-07-03 17:05:42,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4276\n",
      "2023-07-03 17:05:42,451 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:42 2023\n",
      "2023-07-03 17:05:42,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4294\n",
      "2023-07-03 17:05:43,186 - \u001b[1;33mWARNING\u001b[1;0m - Request 4308 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89875 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:43,192 - \u001b[1;33mWARNING\u001b[1;0m - Request 4276 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:43,230 - \u001b[1;33mWARNING\u001b[1;0m - Request 4309 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89814 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:49,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 3698 failed with Exception \n",
      "2023-07-03 17:05:58,193 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:58 2023\n",
      "2023-07-03 17:05:58,231 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:05:58 2023\n",
      "2023-07-03 17:05:58,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3698\n",
      "2023-07-03 17:05:58,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4330\n",
      "2023-07-03 17:05:58,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 4336 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89729 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:05:58,741 - \u001b[1;33mWARNING\u001b[1;0m - Request 4339 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:04,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 3709 failed with Exception \n",
      "2023-07-03 17:06:13,745 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:13 2023\n",
      "2023-07-03 17:06:13,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4347\n",
      "2023-07-03 17:06:13,838 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4367\n",
      "2023-07-03 17:06:14,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 4367 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89993 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:14,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 4370 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89284 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:29,015 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:29 2023\n",
      "2023-07-03 17:06:29,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4385\n",
      "2023-07-03 17:06:29,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 4395 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89958 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:29,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 4402 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89950 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:29,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 4403 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89512 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:35,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 3172 failed with Exception \n",
      "2023-07-03 17:06:44,505 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:44 2023\n",
      "2023-07-03 17:06:44,794 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:06:44 2023\n",
      "2023-07-03 17:06:44,795 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4395\n",
      "2023-07-03 17:06:44,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4421\n",
      "2023-07-03 17:06:45,787 - \u001b[1;33mWARNING\u001b[1;0m - Request 4431 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89408 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:45,790 - \u001b[1;33mWARNING\u001b[1;0m - Request 4432 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:06:45,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 4405 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89315 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:00,793 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:00 2023\n",
      "2023-07-03 17:07:00,845 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:00 2023\n",
      "2023-07-03 17:07:00,858 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4438\n",
      "2023-07-03 17:07:00,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4458\n",
      "2023-07-03 17:07:01,112 - \u001b[1;33mWARNING\u001b[1;0m - Request 4466 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89710 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:07:01,387 - \u001b[1;33mWARNING\u001b[1;0m - Request 4464 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:05,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 3836 failed with Exception \n",
      "2023-07-03 17:07:16,116 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:16 2023\n",
      "2023-07-03 17:07:16,388 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:16 2023\n",
      "2023-07-03 17:07:16,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4475\n",
      "2023-07-03 17:07:16,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4495\n",
      "2023-07-03 17:07:16,855 - \u001b[1;33mWARNING\u001b[1;0m - Request 4498 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:16,858 - \u001b[1;33mWARNING\u001b[1;0m - Request 4489 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:16,872 - \u001b[1;33mWARNING\u001b[1;0m - Request 4484 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:31,858 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:31 2023\n",
      "2023-07-03 17:07:31,872 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:31 2023\n",
      "2023-07-03 17:07:31,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4512\n",
      "2023-07-03 17:07:33,393 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4532\n",
      "2023-07-03 17:07:36,491 - \u001b[1;33mWARNING\u001b[1;0m - Request 4527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89689 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:36,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 4512 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89663 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:51,505 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:51 2023\n",
      "2023-07-03 17:07:51,508 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:07:51 2023\n",
      "2023-07-03 17:07:51,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4550\n",
      "2023-07-03 17:07:51,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4570\n",
      "2023-07-03 17:07:52,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 4555 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:52,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 4551 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89312 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:07:52,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 4566 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:07,220 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:07 2023\n",
      "2023-07-03 17:08:07,225 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:07 2023\n",
      "2023-07-03 17:08:07,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4587\n",
      "2023-07-03 17:08:08,392 - \u001b[1;33mWARNING\u001b[1;0m - Request 4600 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89747 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:08,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 4598 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89655 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:23,405 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:23 2023\n",
      "2023-07-03 17:08:23,448 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:23 2023\n",
      "2023-07-03 17:08:23,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4598\n",
      "2023-07-03 17:08:23,519 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4625\n",
      "2023-07-03 17:08:23,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 4634 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89557 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:23,995 - \u001b[1;33mWARNING\u001b[1;0m - Request 4637 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89510 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:24,019 - \u001b[1;33mWARNING\u001b[1;0m - Request 4631 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:38,976 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:39 2023\n",
      "2023-07-03 17:08:39,020 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:39 2023\n",
      "2023-07-03 17:08:39,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4642\n",
      "2023-07-03 17:08:39,093 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4662\n",
      "2023-07-03 17:08:39,378 - \u001b[1;33mWARNING\u001b[1;0m - Request 4668 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89735 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:39,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 4640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89560 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:54,389 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:54 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:08:54,504 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:08:54 2023\n",
      "2023-07-03 17:08:54,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4680\n",
      "2023-07-03 17:08:54,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4700\n",
      "2023-07-03 17:08:54,776 - \u001b[1;33mWARNING\u001b[1;0m - Request 4694 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89848 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:08:54,779 - \u001b[1;33mWARNING\u001b[1;0m - Request 4700 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:09,778 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:09 2023\n",
      "2023-07-03 17:09:09,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4718\n",
      "2023-07-03 17:09:10,056 - \u001b[1;33mWARNING\u001b[1;0m - Request 4730 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89455 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:10,064 - \u001b[1;33mWARNING\u001b[1;0m - Request 4724 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89450 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:10,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 4702 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89262 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:25,059 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:25 2023\n",
      "2023-07-03 17:09:25,186 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:25 2023\n",
      "2023-07-03 17:09:25,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4735\n",
      "2023-07-03 17:09:25,285 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4755\n",
      "2023-07-03 17:09:25,685 - \u001b[1;33mWARNING\u001b[1;0m - Request 4756 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89274 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:25,824 - \u001b[1;33mWARNING\u001b[1;0m - Request 4764 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89779 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:40,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:40 2023\n",
      "2023-07-03 17:09:40,825 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:09:40 2023\n",
      "2023-07-03 17:09:40,860 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4773\n",
      "2023-07-03 17:09:40,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4793\n",
      "2023-07-03 17:09:45,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 4785 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:09:45,697 - \u001b[1;33mWARNING\u001b[1;0m - Request 4769 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89660 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:00,707 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:00 2023\n",
      "2023-07-03 17:10:00,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4811\n",
      "2023-07-03 17:10:00,791 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4831\n",
      "2023-07-03 17:10:00,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 4837 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89858 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:01,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 4825 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:01,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 4832 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89532 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:14,600 - \u001b[1;33mWARNING\u001b[1;0m - Request 4787 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1ea73b40f472d603723530b6987b1423 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:15,990 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:16 2023\n",
      "2023-07-03 17:10:16,203 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:16 2023\n",
      "2023-07-03 17:10:16,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4847\n",
      "2023-07-03 17:10:16,407 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4867\n",
      "2023-07-03 17:10:16,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 4869 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:16,900 - \u001b[1;33mWARNING\u001b[1;0m - Request 4868 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89808 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:31,586 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:31 2023\n",
      "2023-07-03 17:10:31,901 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:31 2023\n",
      "2023-07-03 17:10:31,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4885\n",
      "2023-07-03 17:10:33,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4905\n",
      "2023-07-03 17:10:37,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 4897 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89355 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:37,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 4904 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89346 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:37,061 - \u001b[1;33mWARNING\u001b[1;0m - Request 4875 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:10:37,075 - \u001b[1;33mWARNING\u001b[1;0m - Request 4874 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:52,067 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:52 2023\n",
      "2023-07-03 17:10:52,076 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:10:52 2023\n",
      "2023-07-03 17:10:52,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4921\n",
      "2023-07-03 17:10:52,178 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4941\n",
      "2023-07-03 17:10:52,331 - \u001b[1;33mWARNING\u001b[1;0m - Request 4941 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89508 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:10:52,363 - \u001b[1;33mWARNING\u001b[1;0m - Request 4942 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89462 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:07,345 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:07 2023\n",
      "2023-07-03 17:11:07,364 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:07 2023\n",
      "2023-07-03 17:11:07,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4959\n",
      "2023-07-03 17:11:07,647 - \u001b[1;33mWARNING\u001b[1;0m - Request 4970 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89715 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:07,668 - \u001b[1;33mWARNING\u001b[1;0m - Request 4971 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89743 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:22,661 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:22 2023\n",
      "2023-07-03 17:11:22,669 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:22 2023\n",
      "2023-07-03 17:11:22,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4977\n",
      "2023-07-03 17:11:22,748 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4997\n",
      "2023-07-03 17:11:22,931 - \u001b[1;33mWARNING\u001b[1;0m - Request 5005 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:22,946 - \u001b[1;33mWARNING\u001b[1;0m - Request 5006 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89853 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:23,083 - \u001b[1;33mWARNING\u001b[1;0m - Request 5007 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89648 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:37,937 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:38 2023\n",
      "2023-07-03 17:11:38,083 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:38 2023\n",
      "2023-07-03 17:11:38,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5014\n",
      "2023-07-03 17:11:38,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5034\n",
      "2023-07-03 17:11:38,344 - \u001b[1;33mWARNING\u001b[1;0m - Request 5037 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89332 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:38,347 - \u001b[1;33mWARNING\u001b[1;0m - Request 5035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89323 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:53,359 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:11:53 2023\n",
      "2023-07-03 17:11:53,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5052\n",
      "2023-07-03 17:11:53,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 5070 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:11:53,903 - \u001b[1;33mWARNING\u001b[1;0m - Request 5068 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89809 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:08,714 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:08 2023\n",
      "2023-07-03 17:12:08,905 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:08 2023\n",
      "2023-07-03 17:12:08,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5070\n",
      "2023-07-03 17:12:08,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5090\n",
      "2023-07-03 17:12:09,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 5098 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89285 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:09,186 - \u001b[1;33mWARNING\u001b[1;0m - Request 5101 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89976 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:24,190 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:24 2023\n",
      "2023-07-03 17:12:24,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5108\n",
      "2023-07-03 17:12:24,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5128\n",
      "2023-07-03 17:12:25,098 - \u001b[1;33mWARNING\u001b[1;0m - Request 5129 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89894 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:25,106 - \u001b[1;33mWARNING\u001b[1;0m - Request 5136 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89884 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:25,383 - \u001b[1;33mWARNING\u001b[1;0m - Request 5128 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89472 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:12:40,105 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:40 2023\n",
      "2023-07-03 17:12:40,384 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:40 2023\n",
      "2023-07-03 17:12:40,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5145\n",
      "2023-07-03 17:12:40,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5165\n",
      "2023-07-03 17:12:41,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 5151 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89539 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:41,259 - \u001b[1;33mWARNING\u001b[1;0m - Request 5136 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89476 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:41,263 - \u001b[1;33mWARNING\u001b[1;0m - Request 5169 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89457 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:56,218 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:56 2023\n",
      "2023-07-03 17:12:56,264 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:12:56 2023\n",
      "2023-07-03 17:12:56,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5182\n",
      "2023-07-03 17:12:56,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 5185 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89782 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:12:56,966 - \u001b[1;33mWARNING\u001b[1;0m - Request 5201 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89713 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:11,932 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:11 2023\n",
      "2023-07-03 17:13:11,932 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5202\n",
      "2023-07-03 17:13:11,967 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:11 2023\n",
      "2023-07-03 17:13:12,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5220\n",
      "2023-07-03 17:13:13,090 - \u001b[1;33mWARNING\u001b[1;0m - Request 5217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89971 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:13,171 - \u001b[1;33mWARNING\u001b[1;0m - Request 5235 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89853 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:28,104 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:28 2023\n",
      "2023-07-03 17:13:28,172 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:28 2023\n",
      "2023-07-03 17:13:28,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5238\n",
      "2023-07-03 17:13:28,251 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5258\n",
      "2023-07-03 17:13:28,462 - \u001b[1;33mWARNING\u001b[1;0m - Request 5258 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89883 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:28,488 - \u001b[1;33mWARNING\u001b[1;0m - Request 5246 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89844 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:43,187 - \u001b[1;33mWARNING\u001b[1;0m - Request 5225 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1a28d1ab1d2d7fbecd91c58ecbeb640 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:43,464 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:43 2023\n",
      "2023-07-03 17:13:43,489 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:43 2023\n",
      "2023-07-03 17:13:43,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5275\n",
      "2023-07-03 17:13:43,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5295\n",
      "2023-07-03 17:13:43,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 5289 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89938 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:43,798 - \u001b[1;33mWARNING\u001b[1;0m - Request 5281 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89940 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:13:58,778 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:58 2023\n",
      "2023-07-03 17:13:58,799 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:13:58 2023\n",
      "2023-07-03 17:13:58,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5313\n",
      "2023-07-03 17:13:59,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5333\n",
      "2023-07-03 17:14:00,571 - \u001b[1;33mWARNING\u001b[1;0m - Request 5334 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:00,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 5323 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89597 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:00,880 - \u001b[1;33mWARNING\u001b[1;0m - Request 5318 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89586 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:15,586 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:15 2023\n",
      "2023-07-03 17:14:15,880 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:15 2023\n",
      "2023-07-03 17:14:15,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5350\n",
      "2023-07-03 17:14:16,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 5347 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89596 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:14:16,701 - \u001b[1;33mWARNING\u001b[1;0m - Request 5367 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89559 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:31,691 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:31 2023\n",
      "2023-07-03 17:14:31,702 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:31 2023\n",
      "2023-07-03 17:14:31,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5367\n",
      "2023-07-03 17:14:31,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5388\n",
      "2023-07-03 17:14:32,863 - \u001b[1;33mWARNING\u001b[1;0m - Request 5401 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89767 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:32,899 - \u001b[1;33mWARNING\u001b[1;0m - Request 5388 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89718 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:47,877 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:47 2023\n",
      "2023-07-03 17:14:47,901 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:14:47 2023\n",
      "2023-07-03 17:14:47,920 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5406\n",
      "2023-07-03 17:14:47,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5426\n",
      "2023-07-03 17:14:52,065 - \u001b[1;33mWARNING\u001b[1;0m - Request 5436 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89899 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:52,068 - \u001b[1;33mWARNING\u001b[1;0m - Request 5440 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89881 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:52,088 - \u001b[1;33mWARNING\u001b[1;0m - Request 5442 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89855 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:14:52,146 - \u001b[1;33mWARNING\u001b[1;0m - Request 5428 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89773 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:07,074 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:07 2023\n",
      "2023-07-03 17:15:07,147 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:07 2023\n",
      "2023-07-03 17:15:07,150 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5442\n",
      "2023-07-03 17:15:07,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5462\n",
      "2023-07-03 17:15:07,773 - \u001b[1;33mWARNING\u001b[1;0m - Request 5473 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89390 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:16,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 4787 failed with Exception \n",
      "2023-07-03 17:15:16,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 4865 failed with Exception \n",
      "2023-07-03 17:15:22,781 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:22 2023\n",
      "2023-07-03 17:15:22,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5479\n",
      "2023-07-03 17:15:22,874 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5499\n",
      "2023-07-03 17:15:23,044 - \u001b[1;33mWARNING\u001b[1;0m - Request 5502 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89470 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:23,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 5504 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89468 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:23,060 - \u001b[1;33mWARNING\u001b[1;0m - Request 5497 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89446 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:32,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 4887 failed with Exception \n",
      "2023-07-03 17:15:32,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 4885 failed with Exception \n",
      "2023-07-03 17:15:38,046 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:38 2023\n",
      "2023-07-03 17:15:38,061 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:38 2023\n",
      "2023-07-03 17:15:38,104 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5514\n",
      "2023-07-03 17:15:38,319 - \u001b[1;33mWARNING\u001b[1;0m - Request 5528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89534 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:38,323 - \u001b[1;33mWARNING\u001b[1;0m - Request 5533 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:38,333 - \u001b[1;33mWARNING\u001b[1;0m - Request 5532 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89514 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:53,327 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:53 2023\n",
      "2023-07-03 17:15:53,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5534\n",
      "2023-07-03 17:15:53,334 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:15:53 2023\n",
      "2023-07-03 17:15:53,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5551\n",
      "2023-07-03 17:15:53,822 - \u001b[1;33mWARNING\u001b[1;0m - Request 5556 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89386 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:53,829 - \u001b[1;33mWARNING\u001b[1;0m - Request 5558 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89385 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:15:53,830 - \u001b[1;33mWARNING\u001b[1;0m - Request 5565 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:16:08,825 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:08 2023\n",
      "2023-07-03 17:16:08,832 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:08 2023\n",
      "2023-07-03 17:16:08,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5568\n",
      "2023-07-03 17:16:09,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5588\n",
      "2023-07-03 17:16:09,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 5596 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89277 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:24,222 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:24 2023\n",
      "2023-07-03 17:16:24,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5607\n",
      "2023-07-03 17:16:24,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5627\n",
      "2023-07-03 17:16:24,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 5629 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89366 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:24,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 5627 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89362 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:24,525 - \u001b[1;33mWARNING\u001b[1;0m - Request 5622 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:39,509 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:39 2023\n",
      "2023-07-03 17:16:39,526 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:39 2023\n",
      "2023-07-03 17:16:39,582 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5644\n",
      "2023-07-03 17:16:39,788 - \u001b[1;33mWARNING\u001b[1;0m - Request 5660 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:39,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 5654 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89476 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:39,882 - \u001b[1;33mWARNING\u001b[1;0m - Request 5661 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:16:54,789 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:54 2023\n",
      "2023-07-03 17:16:54,884 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:16:54 2023\n",
      "2023-07-03 17:16:54,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5654\n",
      "2023-07-03 17:16:54,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5681\n",
      "2023-07-03 17:16:55,373 - \u001b[1;33mWARNING\u001b[1;0m - Request 5671 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89860 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:09,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 5100 failed with Exception \n",
      "2023-07-03 17:17:10,375 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:10 2023\n",
      "2023-07-03 17:17:10,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5699\n",
      "2023-07-03 17:17:10,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5719\n",
      "2023-07-03 17:17:10,861 - \u001b[1;33mWARNING\u001b[1;0m - Request 5723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89533 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:10,862 - \u001b[1;33mWARNING\u001b[1;0m - Request 5720 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89533 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:25,868 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:25 2023\n",
      "2023-07-03 17:17:25,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5737\n",
      "2023-07-03 17:17:25,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5757\n",
      "2023-07-03 17:17:26,145 - \u001b[1;33mWARNING\u001b[1;0m - Request 5752 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89681 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:26,154 - \u001b[1;33mWARNING\u001b[1;0m - Request 5757 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89684 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:26,245 - \u001b[1;33mWARNING\u001b[1;0m - Request 5743 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89530 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:40,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 5145 failed with Exception \n",
      "2023-07-03 17:17:41,147 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:41 2023\n",
      "2023-07-03 17:17:41,245 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:41 2023\n",
      "2023-07-03 17:17:41,290 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5773\n",
      "2023-07-03 17:17:41,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 5786 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89597 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:41,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 5788 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89541 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:56,497 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:56 2023\n",
      "2023-07-03 17:17:56,529 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:17:56 2023\n",
      "2023-07-03 17:17:56,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5791\n",
      "2023-07-03 17:17:56,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5811\n",
      "2023-07-03 17:17:56,798 - \u001b[1;33mWARNING\u001b[1;0m - Request 5816 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89653 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:56,800 - \u001b[1;33mWARNING\u001b[1;0m - Request 5818 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:17:56,804 - \u001b[1;33mWARNING\u001b[1;0m - Request 5820 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89633 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:18:11,805 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:11 2023\n",
      "2023-07-03 17:18:11,841 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5828\n",
      "2023-07-03 17:18:11,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5848\n",
      "2023-07-03 17:18:15,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 5859 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89629 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:16,063 - \u001b[1;33mWARNING\u001b[1;0m - Request 5848 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89503 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:30,509 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:31 2023\n",
      "2023-07-03 17:18:31,065 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:31 2023\n",
      "2023-07-03 17:18:31,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5866\n",
      "2023-07-03 17:18:31,147 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5886\n",
      "2023-07-03 17:18:31,364 - \u001b[1;33mWARNING\u001b[1;0m - Request 5892 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89529 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:31,368 - \u001b[1;33mWARNING\u001b[1;0m - Request 5891 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:46,378 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:18:46 2023\n",
      "2023-07-03 17:18:46,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5904\n",
      "2023-07-03 17:18:46,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5924\n",
      "2023-07-03 17:18:46,632 - \u001b[1;33mWARNING\u001b[1;0m - Request 5924 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89652 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:46,830 - \u001b[1;33mWARNING\u001b[1;0m - Request 5911 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89358 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:46,863 - \u001b[1;33mWARNING\u001b[1;0m - Request 5922 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:18:59,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 5331 failed with Exception \n",
      "2023-07-03 17:19:01,636 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:01 2023\n",
      "2023-07-03 17:19:01,865 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:01 2023\n",
      "2023-07-03 17:19:01,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5940\n",
      "2023-07-03 17:19:02,147 - \u001b[1;33mWARNING\u001b[1;0m - Request 5940 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:02,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 5948 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89894 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:17,155 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:17 2023\n",
      "2023-07-03 17:19:17,347 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:17 2023\n",
      "2023-07-03 17:19:17,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5958\n",
      "2023-07-03 17:19:17,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5978\n",
      "2023-07-03 17:19:18,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 5986 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89541 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:18,348 - \u001b[1;33mWARNING\u001b[1;0m - Request 5963 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89545 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:18,356 - \u001b[1;33mWARNING\u001b[1;0m - Request 5984 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:33,361 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:33 2023\n",
      "2023-07-03 17:19:33,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5995\n",
      "2023-07-03 17:19:33,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6015\n",
      "2023-07-03 17:19:33,637 - \u001b[1;33mWARNING\u001b[1;0m - Request 6018 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89482 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:33,641 - \u001b[1;33mWARNING\u001b[1;0m - Request 6007 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:33,662 - \u001b[1;33mWARNING\u001b[1;0m - Request 6021 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89444 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:48,649 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:48 2023\n",
      "2023-07-03 17:19:48,664 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:19:48 2023\n",
      "2023-07-03 17:19:48,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6032\n",
      "2023-07-03 17:19:48,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6052\n",
      "2023-07-03 17:19:48,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 6051 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89428 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:19:48,999 - \u001b[1;33mWARNING\u001b[1;0m - Request 6052 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:20:03,958 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:03 2023\n",
      "2023-07-03 17:20:04,000 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:03 2023\n",
      "2023-07-03 17:20:04,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6070\n",
      "2023-07-03 17:20:04,281 - \u001b[1;33mWARNING\u001b[1;0m - Request 6082 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:04,301 - \u001b[1;33mWARNING\u001b[1;0m - Request 6079 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89402 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:07,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 5449 failed with Exception \n",
      "2023-07-03 17:20:19,295 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:19 2023\n",
      "2023-07-03 17:20:19,302 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:19 2023\n",
      "2023-07-03 17:20:19,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6087\n",
      "2023-07-03 17:20:19,379 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6107\n",
      "2023-07-03 17:20:19,575 - \u001b[1;33mWARNING\u001b[1;0m - Request 6114 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89426 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:19,577 - \u001b[1;33mWARNING\u001b[1;0m - Request 6111 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:19,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 6108 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:34,590 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:34 2023\n",
      "2023-07-03 17:20:34,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6124\n",
      "2023-07-03 17:20:34,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6144\n",
      "2023-07-03 17:20:35,102 - \u001b[1;33mWARNING\u001b[1;0m - Request 6144 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:35,116 - \u001b[1;33mWARNING\u001b[1;0m - Request 6145 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89517 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:50,117 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:20:50 2023\n",
      "2023-07-03 17:20:50,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6162\n",
      "2023-07-03 17:20:50,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 6180 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89888 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:20:50,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 6181 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89847 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:05,630 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:05 2023\n",
      "2023-07-03 17:21:05,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6182\n",
      "2023-07-03 17:21:05,643 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:05 2023\n",
      "2023-07-03 17:21:05,710 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6200\n",
      "2023-07-03 17:21:05,909 - \u001b[1;33mWARNING\u001b[1;0m - Request 6210 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89840 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:06,137 - \u001b[1;33mWARNING\u001b[1;0m - Request 6212 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89499 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:20,924 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:21 2023\n",
      "2023-07-03 17:21:21,139 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:21 2023\n",
      "2023-07-03 17:21:21,159 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6218\n",
      "2023-07-03 17:21:21,225 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6238\n",
      "2023-07-03 17:21:21,395 - \u001b[1;33mWARNING\u001b[1;0m - Request 6246 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:21,414 - \u001b[1;33mWARNING\u001b[1;0m - Request 6244 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89463 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:36,410 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:36 2023\n",
      "2023-07-03 17:21:36,414 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:36 2023\n",
      "2023-07-03 17:21:36,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6256\n",
      "2023-07-03 17:21:36,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6276\n",
      "2023-07-03 17:21:36,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 6277 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89501 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:36,695 - \u001b[1;33mWARNING\u001b[1;0m - Request 6278 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:36,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 6266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89450 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:51,707 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:51 2023\n",
      "2023-07-03 17:21:51,732 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:21:51 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:21:51,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6293\n",
      "2023-07-03 17:21:52,004 - \u001b[1;33mWARNING\u001b[1;0m - Request 6303 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89414 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:52,033 - \u001b[1;33mWARNING\u001b[1;0m - Request 6310 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:21:52,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 6289 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89344 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:07,013 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:07 2023\n",
      "2023-07-03 17:22:07,052 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:07 2023\n",
      "2023-07-03 17:22:07,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6310\n",
      "2023-07-03 17:22:07,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6330\n",
      "2023-07-03 17:22:07,535 - \u001b[1;33mWARNING\u001b[1;0m - Request 6338 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89750 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:07,637 - \u001b[1;33mWARNING\u001b[1;0m - Request 6342 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89590 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:22,540 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:22 2023\n",
      "2023-07-03 17:22:22,638 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:22 2023\n",
      "2023-07-03 17:22:22,662 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6348\n",
      "2023-07-03 17:22:22,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6368\n",
      "2023-07-03 17:22:23,150 - \u001b[1;33mWARNING\u001b[1;0m - Request 6371 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89889 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:23,211 - \u001b[1;33mWARNING\u001b[1;0m - Request 6375 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89795 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:38,165 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:38 2023\n",
      "2023-07-03 17:22:38,212 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:38 2023\n",
      "2023-07-03 17:22:38,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6386\n",
      "2023-07-03 17:22:38,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6406\n",
      "2023-07-03 17:22:38,474 - \u001b[1;33mWARNING\u001b[1;0m - Request 6406 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89738 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:38,482 - \u001b[1;33mWARNING\u001b[1;0m - Request 6387 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89729 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:53,476 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:53 2023\n",
      "2023-07-03 17:22:53,483 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:22:53 2023\n",
      "2023-07-03 17:22:53,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6424\n",
      "2023-07-03 17:22:55,417 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6444\n",
      "2023-07-03 17:22:56,646 - \u001b[1;33mWARNING\u001b[1;0m - Request 6413 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89558 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:22:56,778 - \u001b[1;33mWARNING\u001b[1;0m - Request 6439 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:11,661 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:11 2023\n",
      "2023-07-03 17:23:11,780 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:11 2023\n",
      "2023-07-03 17:23:11,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6462\n",
      "2023-07-03 17:23:12,047 - \u001b[1;33mWARNING\u001b[1;0m - Request 6477 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89955 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:12,048 - \u001b[1;33mWARNING\u001b[1;0m - Request 6478 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89959 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:12,255 - \u001b[1;33mWARNING\u001b[1;0m - Request 6470 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89644 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:27,054 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:27 2023\n",
      "2023-07-03 17:23:27,255 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:27 2023\n",
      "2023-07-03 17:23:27,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6478\n",
      "2023-07-03 17:23:27,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6499\n",
      "2023-07-03 17:23:27,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 6509 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89536 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:27,585 - \u001b[1;33mWARNING\u001b[1;0m - Request 6485 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89421 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:42,526 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:42 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:23:42,586 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:23:42 2023\n",
      "2023-07-03 17:23:42,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6517\n",
      "2023-07-03 17:23:42,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6537\n",
      "2023-07-03 17:23:46,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 6551 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:47,038 - \u001b[1;33mWARNING\u001b[1;0m - Request 6546 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:47,053 - \u001b[1;33mWARNING\u001b[1;0m - Request 6549 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89377 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:23:47,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 6544 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:02,011 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:02 2023\n",
      "2023-07-03 17:24:02,127 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:02 2023\n",
      "2023-07-03 17:24:02,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6549\n",
      "2023-07-03 17:24:02,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6573\n",
      "2023-07-03 17:24:02,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 6546 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89331 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:02,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 6577 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89325 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:17,721 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:17 2023\n",
      "2023-07-03 17:24:17,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6591\n",
      "2023-07-03 17:24:17,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6611\n",
      "2023-07-03 17:24:18,029 - \u001b[1;33mWARNING\u001b[1;0m - Request 6613 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89730 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:18,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 6616 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89732 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:33,045 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:33 2023\n",
      "2023-07-03 17:24:33,207 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6629\n",
      "2023-07-03 17:24:33,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6649\n",
      "2023-07-03 17:24:33,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 6646 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89460 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:33,691 - \u001b[1;33mWARNING\u001b[1;0m - Request 6648 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89461 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:33,763 - \u001b[1;33mWARNING\u001b[1;0m - Request 6651 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:48,700 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:48 2023\n",
      "2023-07-03 17:24:48,763 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:24:48 2023\n",
      "2023-07-03 17:24:48,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6666\n",
      "2023-07-03 17:24:49,745 - \u001b[1;33mWARNING\u001b[1;0m - Request 6652 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:24:49,845 - \u001b[1;33mWARNING\u001b[1;0m - Request 6674 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:04,760 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:04 2023\n",
      "2023-07-03 17:25:04,845 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:04 2023\n",
      "2023-07-03 17:25:04,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6674\n",
      "2023-07-03 17:25:04,928 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6704\n",
      "2023-07-03 17:25:05,357 - \u001b[1;33mWARNING\u001b[1;0m - Request 6711 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89581 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:05,408 - \u001b[1;33mWARNING\u001b[1;0m - Request 6715 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:20,369 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:20 2023\n",
      "2023-07-03 17:25:20,409 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:20 2023\n",
      "2023-07-03 17:25:20,439 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6722\n",
      "2023-07-03 17:25:20,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6742\n",
      "2023-07-03 17:25:20,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 6739 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89642 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:20,986 - \u001b[1;33mWARNING\u001b[1;0m - Request 6716 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89476 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:25:35,890 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:35 2023\n",
      "2023-07-03 17:25:35,987 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:35 2023\n",
      "2023-07-03 17:25:36,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6760\n",
      "2023-07-03 17:25:36,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6780\n",
      "2023-07-03 17:25:36,467 - \u001b[1;33mWARNING\u001b[1;0m - Request 6780 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89584 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:36,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 6771 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89545 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:36,518 - \u001b[1;33mWARNING\u001b[1;0m - Request 6775 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89521 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:51,481 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:51 2023\n",
      "2023-07-03 17:25:51,519 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:25:51 2023\n",
      "2023-07-03 17:25:51,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6797\n",
      "2023-07-03 17:25:51,847 - \u001b[1;33mWARNING\u001b[1;0m - Request 6807 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89925 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:25:51,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 6811 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89750 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:06,861 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:06 2023\n",
      "2023-07-03 17:26:06,963 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:06 2023\n",
      "2023-07-03 17:26:06,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6815\n",
      "2023-07-03 17:26:07,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6835\n",
      "2023-07-03 17:26:07,237 - \u001b[1;33mWARNING\u001b[1;0m - Request 6842 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89470 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:07,303 - \u001b[1;33mWARNING\u001b[1;0m - Request 6837 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:22,249 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:22 2023\n",
      "2023-07-03 17:26:22,305 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:22 2023\n",
      "2023-07-03 17:26:22,347 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6853\n",
      "2023-07-03 17:26:22,405 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6873\n",
      "2023-07-03 17:26:22,588 - \u001b[1;33mWARNING\u001b[1;0m - Request 6872 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:22,737 - \u001b[1;33mWARNING\u001b[1;0m - Request 6853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89486 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:37,602 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:37 2023\n",
      "2023-07-03 17:26:37,738 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:37 2023\n",
      "2023-07-03 17:26:37,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6891\n",
      "2023-07-03 17:26:38,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 6903 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89679 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:38,255 - \u001b[1;33mWARNING\u001b[1;0m - Request 6905 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89650 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:38,298 - \u001b[1;33mWARNING\u001b[1;0m - Request 6907 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89570 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:52,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 6859 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c1a0629b0fda58bd761546cd1efa4284 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:53,231 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:53 2023\n",
      "2023-07-03 17:26:53,298 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:26:53 2023\n",
      "2023-07-03 17:26:53,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6907\n",
      "2023-07-03 17:26:53,368 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6927\n",
      "2023-07-03 17:26:54,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 6924 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89682 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:26:54,355 - \u001b[1;33mWARNING\u001b[1;0m - Request 6916 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89674 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:09,360 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:09 2023\n",
      "2023-07-03 17:27:09,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6945\n",
      "2023-07-03 17:27:09,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6965\n",
      "2023-07-03 17:27:09,616 - \u001b[1;33mWARNING\u001b[1;0m - Request 6969 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89355 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:09,629 - \u001b[1;33mWARNING\u001b[1;0m - Request 6970 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89334 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:09,631 - \u001b[1;33mWARNING\u001b[1;0m - Request 6964 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89339 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:27:24,629 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:24 2023\n",
      "2023-07-03 17:27:24,632 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:24 2023\n",
      "2023-07-03 17:27:24,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6982\n",
      "2023-07-03 17:27:24,901 - \u001b[1;33mWARNING\u001b[1;0m - Request 7000 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89791 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:39,915 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:39 2023\n",
      "2023-07-03 17:27:39,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7000\n",
      "2023-07-03 17:27:39,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7021\n",
      "2023-07-03 17:27:41,924 - \u001b[1;33mWARNING\u001b[1;0m - Request 7027 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:41,948 - \u001b[1;33mWARNING\u001b[1;0m - Request 7013 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89638 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:41,975 - \u001b[1;33mWARNING\u001b[1;0m - Request 7010 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89599 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:56,939 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:56 2023\n",
      "2023-07-03 17:27:56,976 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:27:56 2023\n",
      "2023-07-03 17:27:56,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7010\n",
      "2023-07-03 17:27:57,068 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7058\n",
      "2023-07-03 17:27:58,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 7053 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:58,550 - \u001b[1;33mWARNING\u001b[1;0m - Request 7044 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89626 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:27:58,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 7071 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:13,563 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:13 2023\n",
      "2023-07-03 17:28:13,672 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:13 2023\n",
      "2023-07-03 17:28:13,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7075\n",
      "2023-07-03 17:28:13,762 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7095\n",
      "2023-07-03 17:28:14,174 - \u001b[1;33mWARNING\u001b[1;0m - Request 7098 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89554 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:29,185 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:29 2023\n",
      "2023-07-03 17:28:29,227 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7114\n",
      "2023-07-03 17:28:29,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7134\n",
      "2023-07-03 17:28:29,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 7135 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89825 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:29,670 - \u001b[1;33mWARNING\u001b[1;0m - Request 7134 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89635 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:29,674 - \u001b[1;33mWARNING\u001b[1;0m - Request 7123 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89632 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:44,554 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:44 2023\n",
      "2023-07-03 17:28:44,675 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:28:44 2023\n",
      "2023-07-03 17:28:44,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7151\n",
      "2023-07-03 17:28:45,221 - \u001b[1;33mWARNING\u001b[1;0m - Request 7164 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89647 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:28:45,259 - \u001b[1;33mWARNING\u001b[1;0m - Request 7165 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89570 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:00,234 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:00 2023\n",
      "2023-07-03 17:29:00,259 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:00 2023\n",
      "2023-07-03 17:29:00,271 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7169\n",
      "2023-07-03 17:29:00,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7189\n",
      "2023-07-03 17:29:00,538 - \u001b[1;33mWARNING\u001b[1;0m - Request 7194 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:15,540 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:15 2023\n",
      "2023-07-03 17:29:15,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7208\n",
      "2023-07-03 17:29:15,654 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7228\n",
      "2023-07-03 17:29:16,017 - \u001b[1;33mWARNING\u001b[1;0m - Request 7217 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89498 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:16,032 - \u001b[1;33mWARNING\u001b[1;0m - Request 7218 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89476 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:16,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 7225 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:29:16,082 - \u001b[1;33mWARNING\u001b[1;0m - Request 7228 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:31,018 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:31 2023\n",
      "2023-07-03 17:29:31,084 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:31 2023\n",
      "2023-07-03 17:29:31,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7244\n",
      "2023-07-03 17:29:31,343 - \u001b[1;33mWARNING\u001b[1;0m - Request 7258 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:31,464 - \u001b[1;33mWARNING\u001b[1;0m - Request 7261 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89917 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:46,356 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:46 2023\n",
      "2023-07-03 17:29:46,466 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:29:46 2023\n",
      "2023-07-03 17:29:46,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7261\n",
      "2023-07-03 17:29:46,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7282\n",
      "2023-07-03 17:29:46,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 7285 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89343 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:46,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 7284 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89332 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:29:46,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 7290 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89337 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:01,969 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:01 2023\n",
      "2023-07-03 17:30:01,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7299\n",
      "2023-07-03 17:30:02,060 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7319\n",
      "2023-07-03 17:30:02,450 - \u001b[1;33mWARNING\u001b[1;0m - Request 7311 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89493 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:02,455 - \u001b[1;33mWARNING\u001b[1;0m - Request 7319 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89490 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:17,464 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:17 2023\n",
      "2023-07-03 17:30:17,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7337\n",
      "2023-07-03 17:30:17,948 - \u001b[1;33mWARNING\u001b[1;0m - Request 7350 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89729 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:17,982 - \u001b[1;33mWARNING\u001b[1;0m - Request 7355 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89673 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6728 failed with Exception \n",
      "2023-07-03 17:30:32,952 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:32 2023\n",
      "2023-07-03 17:30:32,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7357\n",
      "2023-07-03 17:30:32,982 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:32 2023\n",
      "2023-07-03 17:30:33,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7374\n",
      "2023-07-03 17:30:33,237 - \u001b[1;33mWARNING\u001b[1;0m - Request 7386 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89337 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:33,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 7384 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89340 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:33,255 - \u001b[1;33mWARNING\u001b[1;0m - Request 7387 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:48,250 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:48 2023\n",
      "2023-07-03 17:30:48,256 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:30:48 2023\n",
      "2023-07-03 17:30:48,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7391\n",
      "2023-07-03 17:30:48,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7411\n",
      "2023-07-03 17:30:48,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 7407 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89676 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:30:48,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 7418 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89550 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:03,546 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:03 2023\n",
      "2023-07-03 17:31:03,616 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:03 2023\n",
      "2023-07-03 17:31:03,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7429\n",
      "2023-07-03 17:31:03,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7449\n",
      "2023-07-03 17:31:04,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 7449 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89658 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:04,109 - \u001b[1;33mWARNING\u001b[1;0m - Request 7447 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89659 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:31:19,117 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:19 2023\n",
      "2023-07-03 17:31:19,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7467\n",
      "2023-07-03 17:31:19,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 7476 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89909 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:19,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 7477 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89810 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:34,625 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:34 2023\n",
      "2023-07-03 17:31:34,688 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:34 2023\n",
      "2023-07-03 17:31:34,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7485\n",
      "2023-07-03 17:31:34,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7505\n",
      "2023-07-03 17:31:35,188 - \u001b[1;33mWARNING\u001b[1;0m - Request 7513 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89841 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:35,192 - \u001b[1;33mWARNING\u001b[1;0m - Request 7514 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:35,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 7515 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89619 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:50,203 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:50 2023\n",
      "2023-07-03 17:31:50,338 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:31:50 2023\n",
      "2023-07-03 17:31:50,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7522\n",
      "2023-07-03 17:31:50,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7542\n",
      "2023-07-03 17:31:50,593 - \u001b[1;33mWARNING\u001b[1;0m - Request 7543 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:31:50,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 7538 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89420 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:05,607 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:05 2023\n",
      "2023-07-03 17:32:05,616 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:05 2023\n",
      "2023-07-03 17:32:05,672 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7560\n",
      "2023-07-03 17:32:05,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 7576 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89805 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:06,070 - \u001b[1;33mWARNING\u001b[1;0m - Request 7563 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89541 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:09,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6952 failed with Exception \n",
      "2023-07-03 17:32:20,906 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:21 2023\n",
      "2023-07-03 17:32:21,071 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:21 2023\n",
      "2023-07-03 17:32:21,073 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7563\n",
      "2023-07-03 17:32:21,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7597\n",
      "2023-07-03 17:32:21,681 - \u001b[1;33mWARNING\u001b[1;0m - Request 7607 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89513 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:21,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 7609 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89505 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:21,711 - \u001b[1;33mWARNING\u001b[1;0m - Request 7604 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89492 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:36,684 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:36 2023\n",
      "2023-07-03 17:32:36,713 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:36 2023\n",
      "2023-07-03 17:32:36,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7614\n",
      "2023-07-03 17:32:36,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7634\n",
      "2023-07-03 17:32:40,019 - \u001b[1;33mWARNING\u001b[1;0m - Request 7615 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89688 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:55,029 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:32:55 2023\n",
      "2023-07-03 17:32:55,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7653\n",
      "2023-07-03 17:32:55,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7673\n",
      "2023-07-03 17:32:55,554 - \u001b[1;33mWARNING\u001b[1;0m - Request 7675 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89819 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:32:55,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 7668 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89700 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:10,565 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:10 2023\n",
      "2023-07-03 17:33:10,645 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:10 2023\n",
      "2023-07-03 17:33:10,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7691\n",
      "2023-07-03 17:33:10,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7711\n",
      "2023-07-03 17:33:10,906 - \u001b[1;33mWARNING\u001b[1;0m - Request 7706 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89561 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:10,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 7708 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89569 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:10,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 7709 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89558 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:10,914 - \u001b[1;33mWARNING\u001b[1;0m - Request 7711 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:33:25,910 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:25 2023\n",
      "2023-07-03 17:33:25,915 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:25 2023\n",
      "2023-07-03 17:33:25,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7727\n",
      "2023-07-03 17:33:28,416 - \u001b[1;33mWARNING\u001b[1;0m - Request 7732 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89423 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:28,427 - \u001b[1;33mWARNING\u001b[1;0m - Request 7723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:28,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 7746 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89280 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:43,431 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:43 2023\n",
      "2023-07-03 17:33:43,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7747\n",
      "2023-07-03 17:33:43,535 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:43 2023\n",
      "2023-07-03 17:33:43,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7764\n",
      "2023-07-03 17:33:43,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 7776 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89837 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:43,887 - \u001b[1;33mWARNING\u001b[1;0m - Request 7777 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89696 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:58,806 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:58 2023\n",
      "2023-07-03 17:33:58,889 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:33:58 2023\n",
      "2023-07-03 17:33:58,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7782\n",
      "2023-07-03 17:33:58,974 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7802\n",
      "2023-07-03 17:33:59,161 - \u001b[1;33mWARNING\u001b[1;0m - Request 7807 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89355 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:33:59,162 - \u001b[1;33mWARNING\u001b[1;0m - Request 7797 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89355 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:14,164 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:14 2023\n",
      "2023-07-03 17:34:14,209 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7820\n",
      "2023-07-03 17:34:14,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7840\n",
      "2023-07-03 17:34:14,672 - \u001b[1;33mWARNING\u001b[1;0m - Request 7818 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:14,673 - \u001b[1;33mWARNING\u001b[1;0m - Request 7836 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:14,712 - \u001b[1;33mWARNING\u001b[1;0m - Request 7841 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89464 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:29,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:29 2023\n",
      "2023-07-03 17:34:29,713 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:29 2023\n",
      "2023-07-03 17:34:29,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7857\n",
      "2023-07-03 17:34:32,170 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7877\n",
      "2023-07-03 17:34:33,192 - \u001b[1;33mWARNING\u001b[1;0m - Request 7848 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:33,198 - \u001b[1;33mWARNING\u001b[1;0m - Request 7850 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:33,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 7879 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89329 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:48,197 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:48 2023\n",
      "2023-07-03 17:34:48,234 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:34:48 2023\n",
      "2023-07-03 17:34:48,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7894\n",
      "2023-07-03 17:34:48,510 - \u001b[1;33mWARNING\u001b[1;0m - Request 7907 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89623 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:34:48,561 - \u001b[1;33mWARNING\u001b[1;0m - Request 7910 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89536 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:03,515 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:03 2023\n",
      "2023-07-03 17:35:03,561 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:03 2023\n",
      "2023-07-03 17:35:03,568 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7912\n",
      "2023-07-03 17:35:03,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7932\n",
      "2023-07-03 17:35:07,629 - \u001b[1;33mWARNING\u001b[1;0m - Request 7925 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89453 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:07,645 - \u001b[1;33mWARNING\u001b[1;0m - Request 7907 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:07,646 - \u001b[1;33mWARNING\u001b[1;0m - Request 7950 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:35:18,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 7352 failed with Exception \n",
      "2023-07-03 17:35:22,634 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:22 2023\n",
      "2023-07-03 17:35:22,649 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:22 2023\n",
      "2023-07-03 17:35:22,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7925\n",
      "2023-07-03 17:35:22,715 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7968\n",
      "2023-07-03 17:35:22,911 - \u001b[1;33mWARNING\u001b[1;0m - Request 7976 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:23,054 - \u001b[1;33mWARNING\u001b[1;0m - Request 7980 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89646 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:37,921 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:38 2023\n",
      "2023-07-03 17:35:38,056 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:38 2023\n",
      "2023-07-03 17:35:38,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7986\n",
      "2023-07-03 17:35:38,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8006\n",
      "2023-07-03 17:35:38,321 - \u001b[1;33mWARNING\u001b[1;0m - Request 8009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89332 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:38,458 - \u001b[1;33mWARNING\u001b[1;0m - Request 8012 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:53,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:53 2023\n",
      "2023-07-03 17:35:53,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:35:53 2023\n",
      "2023-07-03 17:35:53,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8024\n",
      "2023-07-03 17:35:53,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 8042 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89777 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:35:53,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 8043 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89780 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:08,747 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:08 2023\n",
      "2023-07-03 17:36:08,747 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8044\n",
      "2023-07-03 17:36:08,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8062\n",
      "2023-07-03 17:36:09,010 - \u001b[1;33mWARNING\u001b[1;0m - Request 8069 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89400 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:09,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 8071 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:09,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 8070 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89373 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:24,025 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:24 2023\n",
      "2023-07-03 17:36:24,041 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:24 2023\n",
      "2023-07-03 17:36:24,056 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8079\n",
      "2023-07-03 17:36:24,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8099\n",
      "2023-07-03 17:36:24,344 - \u001b[1;33mWARNING\u001b[1;0m - Request 8106 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89842 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:24,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 8079 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89681 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:39,357 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:39 2023\n",
      "2023-07-03 17:36:39,455 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:39 2023\n",
      "2023-07-03 17:36:39,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8117\n",
      "2023-07-03 17:36:39,559 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8137\n",
      "2023-07-03 17:36:39,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 8119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89587 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:39,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 8136 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89581 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:39,833 - \u001b[1;33mWARNING\u001b[1;0m - Request 8138 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89425 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:54,741 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:54 2023\n",
      "2023-07-03 17:36:54,834 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:36:54 2023\n",
      "2023-07-03 17:36:54,894 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8154\n",
      "2023-07-03 17:36:55,110 - \u001b[1;33mWARNING\u001b[1;0m - Request 8167 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:36:55,152 - \u001b[1;33mWARNING\u001b[1;0m - Request 8162 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89303 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:37:06,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 7555 failed with Exception \n",
      "2023-07-03 17:37:10,115 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:10 2023\n",
      "2023-07-03 17:37:10,155 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:10 2023\n",
      "2023-07-03 17:37:10,168 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8171\n",
      "2023-07-03 17:37:10,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8191\n",
      "2023-07-03 17:37:10,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 8197 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89710 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:10,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 8199 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89706 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:25,445 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:25 2023\n",
      "2023-07-03 17:37:25,488 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8209\n",
      "2023-07-03 17:37:25,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8229\n",
      "2023-07-03 17:37:27,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 8233 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89563 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:27,655 - \u001b[1;33mWARNING\u001b[1;0m - Request 8201 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89564 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:27,720 - \u001b[1;33mWARNING\u001b[1;0m - Request 8202 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89465 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:42,666 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:42 2023\n",
      "2023-07-03 17:37:42,721 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:42 2023\n",
      "2023-07-03 17:37:42,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8246\n",
      "2023-07-03 17:37:42,835 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8266\n",
      "2023-07-03 17:37:42,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 8262 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89924 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:43,236 - \u001b[1;33mWARNING\u001b[1;0m - Request 8266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89536 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:57,987 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:58 2023\n",
      "2023-07-03 17:37:58,237 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:37:58 2023\n",
      "2023-07-03 17:37:58,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8284\n",
      "2023-07-03 17:37:58,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 8297 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89865 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:37:58,526 - \u001b[1;33mWARNING\u001b[1;0m - Request 8298 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:11,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 7686 failed with Exception \n",
      "2023-07-03 17:38:13,511 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:13 2023\n",
      "2023-07-03 17:38:13,526 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:13 2023\n",
      "2023-07-03 17:38:13,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8301\n",
      "2023-07-03 17:38:13,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8321\n",
      "2023-07-03 17:38:14,281 - \u001b[1;33mWARNING\u001b[1;0m - Request 8311 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89535 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:14,443 - \u001b[1;33mWARNING\u001b[1;0m - Request 8329 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89283 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:14,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 8324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89285 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:29,290 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:29 2023\n",
      "2023-07-03 17:38:29,447 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:29 2023\n",
      "2023-07-03 17:38:29,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8338\n",
      "2023-07-03 17:38:29,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8358\n",
      "2023-07-03 17:38:29,830 - \u001b[1;33mWARNING\u001b[1;0m - Request 8347 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89572 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:29,936 - \u001b[1;33mWARNING\u001b[1;0m - Request 8362 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89376 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:44,504 - \u001b[1;33mWARNING\u001b[1;0m - Request 7749 failed with Exception \n",
      "2023-07-03 17:38:44,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 7756 failed with Exception \n",
      "2023-07-03 17:38:44,832 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:44 2023\n",
      "2023-07-03 17:38:44,938 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:38:44 2023\n",
      "2023-07-03 17:38:44,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8374\n",
      "2023-07-03 17:38:45,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 8391 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89860 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:38:45,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 8390 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89840 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:39:00,205 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:00 2023\n",
      "2023-07-03 17:39:00,209 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:00 2023\n",
      "2023-07-03 17:39:00,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8390\n",
      "2023-07-03 17:39:00,284 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8412\n",
      "2023-07-03 17:39:00,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 8419 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89507 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:00,477 - \u001b[1;33mWARNING\u001b[1;0m - Request 8423 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89482 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:00,481 - \u001b[1;33mWARNING\u001b[1;0m - Request 8422 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:15,476 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:15 2023\n",
      "2023-07-03 17:39:15,481 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:15 2023\n",
      "2023-07-03 17:39:15,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8429\n",
      "2023-07-03 17:39:15,588 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8449\n",
      "2023-07-03 17:39:15,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 8453 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89848 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:15,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 8454 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89823 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:30,781 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:30 2023\n",
      "2023-07-03 17:39:30,795 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:30 2023\n",
      "2023-07-03 17:39:30,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8467\n",
      "2023-07-03 17:39:31,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8487\n",
      "2023-07-03 17:39:33,129 - \u001b[1;33mWARNING\u001b[1;0m - Request 8485 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:33,130 - \u001b[1;33mWARNING\u001b[1;0m - Request 8487 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:33,143 - \u001b[1;33mWARNING\u001b[1;0m - Request 8463 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89310 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:48,144 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:39:48 2023\n",
      "2023-07-03 17:39:48,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8504\n",
      "2023-07-03 17:39:48,654 - \u001b[1;33mWARNING\u001b[1;0m - Request 8518 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:48,660 - \u001b[1;33mWARNING\u001b[1;0m - Request 8515 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:39:48,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 8522 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89286 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:03,661 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:03 2023\n",
      "2023-07-03 17:40:03,688 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:03 2023\n",
      "2023-07-03 17:40:03,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8518\n",
      "2023-07-03 17:40:03,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8541\n",
      "2023-07-03 17:40:04,105 - \u001b[1;33mWARNING\u001b[1;0m - Request 8553 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89516 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:04,238 - \u001b[1;33mWARNING\u001b[1;0m - Request 8552 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:04,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7921 failed with Exception \n",
      "2023-07-03 17:40:19,110 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:19 2023\n",
      "2023-07-03 17:40:19,239 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:19 2023\n",
      "2023-07-03 17:40:19,262 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8558\n",
      "2023-07-03 17:40:19,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8578\n",
      "2023-07-03 17:40:23,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 8565 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89533 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:23,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 8593 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:38,542 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:38 2023\n",
      "2023-07-03 17:40:38,547 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:38 2023\n",
      "2023-07-03 17:40:38,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8596\n",
      "2023-07-03 17:40:38,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8616\n",
      "2023-07-03 17:40:38,840 - \u001b[1;33mWARNING\u001b[1;0m - Request 8618 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89852 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:40:38,850 - \u001b[1;33mWARNING\u001b[1;0m - Request 8617 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89851 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:38,892 - \u001b[1;33mWARNING\u001b[1;0m - Request 8625 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:53,852 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:53 2023\n",
      "2023-07-03 17:40:53,893 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:40:53 2023\n",
      "2023-07-03 17:40:53,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8633\n",
      "2023-07-03 17:40:53,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8653\n",
      "2023-07-03 17:40:54,160 - \u001b[1;33mWARNING\u001b[1;0m - Request 8652 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:54,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 8654 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89419 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:54,233 - \u001b[1;33mWARNING\u001b[1;0m - Request 8656 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:40:54,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8021 failed with Exception \n",
      "2023-07-03 17:41:09,166 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:09 2023\n",
      "2023-07-03 17:41:09,233 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:09 2023\n",
      "2023-07-03 17:41:09,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8669\n",
      "2023-07-03 17:41:10,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8689\n",
      "2023-07-03 17:41:12,509 - \u001b[1;33mWARNING\u001b[1;0m - Request 8652 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89620 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:12,515 - \u001b[1;33mWARNING\u001b[1;0m - Request 8662 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89610 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:27,521 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:27 2023\n",
      "2023-07-03 17:41:27,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8707\n",
      "2023-07-03 17:41:28,839 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8727\n",
      "2023-07-03 17:41:29,951 - \u001b[1;33mWARNING\u001b[1;0m - Request 8727 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89515 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:29,954 - \u001b[1;33mWARNING\u001b[1;0m - Request 8662 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89501 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:30,068 - \u001b[1;33mWARNING\u001b[1;0m - Request 8712 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:44,952 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:45 2023\n",
      "2023-07-03 17:41:45,070 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:41:45 2023\n",
      "2023-07-03 17:41:45,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8744\n",
      "2023-07-03 17:41:45,542 - \u001b[1;33mWARNING\u001b[1;0m - Request 8741 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:41:45,559 - \u001b[1;33mWARNING\u001b[1;0m - Request 8756 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89341 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:00,544 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:00 2023\n",
      "2023-07-03 17:42:00,560 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:00 2023\n",
      "2023-07-03 17:42:00,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8756\n",
      "2023-07-03 17:42:00,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8782\n",
      "2023-07-03 17:42:01,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 8772 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89459 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:01,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 8793 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:16,049 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:16 2023\n",
      "2023-07-03 17:42:16,071 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:16 2023\n",
      "2023-07-03 17:42:16,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8800\n",
      "2023-07-03 17:42:16,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8820\n",
      "2023-07-03 17:42:16,560 - \u001b[1;33mWARNING\u001b[1;0m - Request 8811 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89480 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:16,588 - \u001b[1;33mWARNING\u001b[1;0m - Request 8823 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:16,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 8795 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:42:31,561 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:31 2023\n",
      "2023-07-03 17:42:31,592 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:31 2023\n",
      "2023-07-03 17:42:31,641 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8837\n",
      "2023-07-03 17:42:32,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8857\n",
      "2023-07-03 17:42:33,841 - \u001b[1;33mWARNING\u001b[1;0m - Request 8838 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89676 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:48,851 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:42:48 2023\n",
      "2023-07-03 17:42:48,909 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8876\n",
      "2023-07-03 17:42:49,114 - \u001b[1;33mWARNING\u001b[1;0m - Request 8892 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:49,123 - \u001b[1;33mWARNING\u001b[1;0m - Request 8889 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89314 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:42:49,140 - \u001b[1;33mWARNING\u001b[1;0m - Request 8878 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:04,121 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:04 2023\n",
      "2023-07-03 17:43:04,142 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:04 2023\n",
      "2023-07-03 17:43:04,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8889\n",
      "2023-07-03 17:43:04,210 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8913\n",
      "2023-07-03 17:43:04,402 - \u001b[1;33mWARNING\u001b[1;0m - Request 8924 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89532 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:04,405 - \u001b[1;33mWARNING\u001b[1;0m - Request 8913 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89529 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:04,418 - \u001b[1;33mWARNING\u001b[1;0m - Request 8923 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:19,417 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:19 2023\n",
      "2023-07-03 17:43:19,444 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8930\n",
      "2023-07-03 17:43:19,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8950\n",
      "2023-07-03 17:43:19,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 8954 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89249 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:19,678 - \u001b[1;33mWARNING\u001b[1;0m - Request 8953 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89965 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:34,691 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:34 2023\n",
      "2023-07-03 17:43:34,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8968\n",
      "2023-07-03 17:43:34,943 - \u001b[1;33mWARNING\u001b[1;0m - Request 8982 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89767 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:34,956 - \u001b[1;33mWARNING\u001b[1;0m - Request 8986 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:35,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 8987 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89682 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:49,956 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:50 2023\n",
      "2023-07-03 17:43:49,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8988\n",
      "2023-07-03 17:43:50,002 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:43:50 2023\n",
      "2023-07-03 17:43:50,068 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9005\n",
      "2023-07-03 17:43:50,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 9008 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89398 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:43:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9005 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89788 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:05,278 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:05 2023\n",
      "2023-07-03 17:44:05,494 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:05 2023\n",
      "2023-07-03 17:44:05,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9023\n",
      "2023-07-03 17:44:05,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9043\n",
      "2023-07-03 17:44:05,991 - \u001b[1;33mWARNING\u001b[1;0m - Request 9049 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89796 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:05,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 9046 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89783 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:21,005 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:20 2023\n",
      "2023-07-03 17:44:21,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9061\n",
      "2023-07-03 17:44:21,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:44:21,258 - \u001b[1;33mWARNING\u001b[1;0m - Request 9081 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89573 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:21,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 9080 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:21,291 - \u001b[1;33mWARNING\u001b[1;0m - Request 9070 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:36,270 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:36 2023\n",
      "2023-07-03 17:44:36,292 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:36 2023\n",
      "2023-07-03 17:44:36,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9098\n",
      "2023-07-03 17:44:36,565 - \u001b[1;33mWARNING\u001b[1;0m - Request 9108 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89798 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:36,583 - \u001b[1;33mWARNING\u001b[1;0m - Request 9105 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89761 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:51,579 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:51 2023\n",
      "2023-07-03 17:44:51,584 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:44:51 2023\n",
      "2023-07-03 17:44:51,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9116\n",
      "2023-07-03 17:44:51,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9136\n",
      "2023-07-03 17:44:51,957 - \u001b[1;33mWARNING\u001b[1;0m - Request 9138 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89323 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:44:51,981 - \u001b[1;33mWARNING\u001b[1;0m - Request 9118 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89993 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:06,969 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:06 2023\n",
      "2023-07-03 17:45:06,982 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:06 2023\n",
      "2023-07-03 17:45:07,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9154\n",
      "2023-07-03 17:45:07,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9174\n",
      "2023-07-03 17:45:11,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 9155 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89469 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:11,213 - \u001b[1;33mWARNING\u001b[1;0m - Request 9186 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89457 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:11,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 9162 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89254 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:21,942 - \u001b[1;33mWARNING\u001b[1;0m - Request 9134 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3d567c9861bbd9c39ae3ba75bfb62484 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:26,212 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:26 2023\n",
      "2023-07-03 17:45:26,354 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:26 2023\n",
      "2023-07-03 17:45:26,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9190\n",
      "2023-07-03 17:45:26,439 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9210\n",
      "2023-07-03 17:45:30,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 9212 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89440 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:30,183 - \u001b[1;33mWARNING\u001b[1;0m - Request 9194 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:30,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 9224 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:30,221 - \u001b[1;33mWARNING\u001b[1;0m - Request 9205 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:45,195 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:45 2023\n",
      "2023-07-03 17:45:45,222 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:45:45 2023\n",
      "2023-07-03 17:45:45,232 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9226\n",
      "2023-07-03 17:45:45,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9246\n",
      "2023-07-03 17:45:46,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 9242 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:45:46,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 9230 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:01,211 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:01 2023\n",
      "2023-07-03 17:46:01,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:46:01,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9284\n",
      "2023-07-03 17:46:01,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 9280 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89591 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:16,701 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:16 2023\n",
      "2023-07-03 17:46:16,759 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9303\n",
      "2023-07-03 17:46:17,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9323\n",
      "2023-07-03 17:46:21,491 - \u001b[1;33mWARNING\u001b[1;0m - Request 9326 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89675 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:21,936 - \u001b[1;33mWARNING\u001b[1;0m - Request 9330 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89723 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:22,161 - \u001b[1;33mWARNING\u001b[1;0m - Request 9324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:28,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 8694 failed with Exception \n",
      "2023-07-03 17:46:36,500 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:37 2023\n",
      "2023-07-03 17:46:37,161 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:37 2023\n",
      "2023-07-03 17:46:37,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9339\n",
      "2023-07-03 17:46:37,262 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9359\n",
      "2023-07-03 17:46:37,420 - \u001b[1;33mWARNING\u001b[1;0m - Request 9355 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89725 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:37,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 9360 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89723 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:37,694 - \u001b[1;33mWARNING\u001b[1;0m - Request 9356 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:37,716 - \u001b[1;33mWARNING\u001b[1;0m - Request 9362 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:52,432 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:52 2023\n",
      "2023-07-03 17:46:52,717 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:46:52 2023\n",
      "2023-07-03 17:46:52,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9375\n",
      "2023-07-03 17:46:53,235 - \u001b[1;33mWARNING\u001b[1;0m - Request 9376 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89947 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:46:53,476 - \u001b[1;33mWARNING\u001b[1;0m - Request 9393 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89588 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:08,237 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:08 2023\n",
      "2023-07-03 17:47:08,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:08 2023\n",
      "2023-07-03 17:47:08,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9376\n",
      "2023-07-03 17:47:08,548 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9413\n",
      "2023-07-03 17:47:09,010 - \u001b[1;33mWARNING\u001b[1;0m - Request 9426 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89534 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:24,024 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:24 2023\n",
      "2023-07-03 17:47:24,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9432\n",
      "2023-07-03 17:47:24,112 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9452\n",
      "2023-07-03 17:47:24,521 - \u001b[1;33mWARNING\u001b[1;0m - Request 9455 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89388 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:24,544 - \u001b[1;33mWARNING\u001b[1;0m - Request 9452 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:24,550 - \u001b[1;33mWARNING\u001b[1;0m - Request 9450 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89358 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:24,560 - \u001b[1;33mWARNING\u001b[1;0m - Request 9458 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:39,535 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:39 2023\n",
      "2023-07-03 17:47:39,562 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:39 2023\n",
      "2023-07-03 17:47:39,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9468\n",
      "2023-07-03 17:47:39,662 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9488\n",
      "2023-07-03 17:47:40,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 9483 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:40,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 9490 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89338 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:47:40,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 9486 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89334 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:47:55,056 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:47:55 2023\n",
      "2023-07-03 17:47:55,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9505\n",
      "2023-07-03 17:47:55,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 9521 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:10,429 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:10 2023\n",
      "2023-07-03 17:48:10,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9524\n",
      "2023-07-03 17:48:10,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9544\n",
      "2023-07-03 17:48:13,890 - \u001b[1;33mWARNING\u001b[1;0m - Request 9529 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:13,891 - \u001b[1;33mWARNING\u001b[1;0m - Request 9533 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:13,928 - \u001b[1;33mWARNING\u001b[1;0m - Request 9528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:13,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 9558 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89340 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:28,905 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:28 2023\n",
      "2023-07-03 17:48:28,931 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:28 2023\n",
      "2023-07-03 17:48:28,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9533\n",
      "2023-07-03 17:48:28,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9580\n",
      "2023-07-03 17:48:29,219 - \u001b[1;33mWARNING\u001b[1;0m - Request 9581 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89482 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:29,226 - \u001b[1;33mWARNING\u001b[1;0m - Request 9565 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89487 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:44,229 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:44 2023\n",
      "2023-07-03 17:48:44,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9598\n",
      "2023-07-03 17:48:44,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9618\n",
      "2023-07-03 17:48:44,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 9592 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89619 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:59,653 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:48:59 2023\n",
      "2023-07-03 17:48:59,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9637\n",
      "2023-07-03 17:48:59,924 - \u001b[1;33mWARNING\u001b[1;0m - Request 9651 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89825 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:59,932 - \u001b[1;33mWARNING\u001b[1;0m - Request 9655 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89807 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:48:59,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 9656 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89785 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:14,937 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:14 2023\n",
      "2023-07-03 17:49:14,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9657\n",
      "2023-07-03 17:49:14,951 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:14 2023\n",
      "2023-07-03 17:49:15,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9674\n",
      "2023-07-03 17:49:18,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9694\n",
      "2023-07-03 17:49:19,333 - \u001b[1;33mWARNING\u001b[1;0m - Request 9651 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:19,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 9678 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89639 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:19,379 - \u001b[1;33mWARNING\u001b[1;0m - Request 9684 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89581 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:34,348 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:34 2023\n",
      "2023-07-03 17:49:34,379 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:34 2023\n",
      "2023-07-03 17:49:34,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9711\n",
      "2023-07-03 17:49:34,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 9724 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:34,881 - \u001b[1;33mWARNING\u001b[1;0m - Request 9727 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:34,883 - \u001b[1;33mWARNING\u001b[1;0m - Request 9723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:49:49,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:49:49 2023\n",
      "2023-07-03 17:49:49,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9727\n",
      "2023-07-03 17:49:49,966 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9748\n",
      "2023-07-03 17:49:50,157 - \u001b[1;33mWARNING\u001b[1;0m - Request 9750 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89721 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:49:50,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 9759 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89653 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:04,715 - \u001b[1;33mWARNING\u001b[1;0m - Request 9703 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c487166759ef41980699f48178d120b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:05,159 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:05 2023\n",
      "2023-07-03 17:50:05,219 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:05 2023\n",
      "2023-07-03 17:50:05,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9765\n",
      "2023-07-03 17:50:05,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9785\n",
      "2023-07-03 17:50:05,604 - \u001b[1;33mWARNING\u001b[1;0m - Request 9783 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89736 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:05,644 - \u001b[1;33mWARNING\u001b[1;0m - Request 9788 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:20,619 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:20 2023\n",
      "2023-07-03 17:50:20,645 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:20 2023\n",
      "2023-07-03 17:50:20,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9803\n",
      "2023-07-03 17:50:20,909 - \u001b[1;33mWARNING\u001b[1;0m - Request 9821 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89937 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:20,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 9822 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89937 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:35,914 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:35 2023\n",
      "2023-07-03 17:50:35,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9823\n",
      "2023-07-03 17:50:35,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9841\n",
      "2023-07-03 17:50:36,201 - \u001b[1;33mWARNING\u001b[1;0m - Request 9853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:36,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 9854 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89426 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:36,247 - \u001b[1;33mWARNING\u001b[1;0m - Request 9852 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:45,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 9253 failed with Exception \n",
      "2023-07-03 17:50:51,209 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:51 2023\n",
      "2023-07-03 17:50:51,248 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:50:51 2023\n",
      "2023-07-03 17:50:51,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9857\n",
      "2023-07-03 17:50:51,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9877\n",
      "2023-07-03 17:50:51,516 - \u001b[1;33mWARNING\u001b[1;0m - Request 9883 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89696 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:50:51,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 9882 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89676 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:06,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:06 2023\n",
      "2023-07-03 17:51:06,547 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:06 2023\n",
      "2023-07-03 17:51:06,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9895\n",
      "2023-07-03 17:51:06,648 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9915\n",
      "2023-07-03 17:51:06,873 - \u001b[1;33mWARNING\u001b[1;0m - Request 9892 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89793 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:06,887 - \u001b[1;33mWARNING\u001b[1;0m - Request 9915 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89774 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:07,001 - \u001b[1;33mWARNING\u001b[1;0m - Request 9917 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89622 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:21,887 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:22 2023\n",
      "2023-07-03 17:51:22,002 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:22 2023\n",
      "2023-07-03 17:51:22,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9932\n",
      "2023-07-03 17:51:22,282 - \u001b[1;33mWARNING\u001b[1;0m - Request 9942 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89880 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:22,293 - \u001b[1;33mWARNING\u001b[1;0m - Request 9948 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89858 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:51:37,295 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:37 2023\n",
      "2023-07-03 17:51:37,303 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9950\n",
      "2023-07-03 17:51:37,480 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9970\n",
      "2023-07-03 17:51:37,669 - \u001b[1;33mWARNING\u001b[1;0m - Request 9976 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89940 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:37,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 9970 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89938 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:52,683 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:51:52 2023\n",
      "2023-07-03 17:51:52,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9988\n",
      "2023-07-03 17:51:52,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10008\n",
      "2023-07-03 17:51:52,948 - \u001b[1;33mWARNING\u001b[1;0m - Request 10008 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89438 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:52,970 - \u001b[1;33mWARNING\u001b[1;0m - Request 10011 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:53,018 - \u001b[1;33mWARNING\u001b[1;0m - Request 10006 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:51:53,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9390 failed with Exception \n",
      "2023-07-03 17:52:07,963 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:08 2023\n",
      "2023-07-03 17:52:08,019 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:08 2023\n",
      "2023-07-03 17:52:08,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10024\n",
      "2023-07-03 17:52:08,278 - \u001b[1;33mWARNING\u001b[1;0m - Request 10040 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89576 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:08,280 - \u001b[1;33mWARNING\u001b[1;0m - Request 10037 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89579 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:23,284 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:23 2023\n",
      "2023-07-03 17:52:23,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10040\n",
      "2023-07-03 17:52:23,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10062\n",
      "2023-07-03 17:52:23,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 10055 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89677 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:23,783 - \u001b[1;33mWARNING\u001b[1;0m - Request 10068 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89338 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:38,567 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:38 2023\n",
      "2023-07-03 17:52:38,784 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:38 2023\n",
      "2023-07-03 17:52:38,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10080\n",
      "2023-07-03 17:52:38,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10100\n",
      "2023-07-03 17:52:39,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 10106 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:39,314 - \u001b[1;33mWARNING\u001b[1;0m - Request 10104 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89796 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:54,073 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:54 2023\n",
      "2023-07-03 17:52:54,315 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:52:54 2023\n",
      "2023-07-03 17:52:54,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10118\n",
      "2023-07-03 17:52:54,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10138\n",
      "2023-07-03 17:52:58,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 10130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89646 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:52:58,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 10145 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89715 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:13,133 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:13 2023\n",
      "2023-07-03 17:53:13,553 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:13 2023\n",
      "2023-07-03 17:53:13,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10156\n",
      "2023-07-03 17:53:13,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10176\n",
      "2023-07-03 17:53:18,901 - \u001b[1;33mWARNING\u001b[1;0m - Request 10157 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89356 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:18,909 - \u001b[1;33mWARNING\u001b[1;0m - Request 10165 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89345 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:18,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 10184 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:18,913 - \u001b[1;33mWARNING\u001b[1;0m - Request 10152 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:18,922 - \u001b[1;33mWARNING\u001b[1;0m - Request 10155 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89343 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:53:33,916 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:33 2023\n",
      "2023-07-03 17:53:33,923 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:33 2023\n",
      "2023-07-03 17:53:33,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10184\n",
      "2023-07-03 17:53:33,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10211\n",
      "2023-07-03 17:53:34,191 - \u001b[1;33mWARNING\u001b[1;0m - Request 10221 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:34,202 - \u001b[1;33mWARNING\u001b[1;0m - Request 10219 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89515 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:49,203 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:53:49 2023\n",
      "2023-07-03 17:53:49,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10229\n",
      "2023-07-03 17:53:49,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10249\n",
      "2023-07-03 17:53:49,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 10252 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89681 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:53:49,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 10253 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89682 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:04,477 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:04 2023\n",
      "2023-07-03 17:54:04,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10267\n",
      "2023-07-03 17:54:04,800 - \u001b[1;33mWARNING\u001b[1;0m - Request 10275 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89687 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:04,935 - \u001b[1;33mWARNING\u001b[1;0m - Request 10281 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89487 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:19,814 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:19 2023\n",
      "2023-07-03 17:54:19,937 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:19 2023\n",
      "2023-07-03 17:54:19,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10275\n",
      "2023-07-03 17:54:20,006 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10305\n",
      "2023-07-03 17:54:20,439 - \u001b[1;33mWARNING\u001b[1;0m - Request 10316 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89960 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:20,445 - \u001b[1;33mWARNING\u001b[1;0m - Request 10313 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89961 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:35,453 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:35 2023\n",
      "2023-07-03 17:54:35,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10323\n",
      "2023-07-03 17:54:35,539 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10343\n",
      "2023-07-03 17:54:39,346 - \u001b[1;33mWARNING\u001b[1;0m - Request 10354 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89663 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:39,476 - \u001b[1;33mWARNING\u001b[1;0m - Request 10359 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89463 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:39,850 - \u001b[1;33mWARNING\u001b[1;0m - Request 10330 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:54,360 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:54 2023\n",
      "2023-07-03 17:54:54,852 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:54:54 2023\n",
      "2023-07-03 17:54:54,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10330\n",
      "2023-07-03 17:54:54,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10380\n",
      "2023-07-03 17:54:58,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10400\n",
      "2023-07-03 17:54:59,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 10396 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:59,647 - \u001b[1;33mWARNING\u001b[1;0m - Request 10401 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89379 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:54:59,784 - \u001b[1;33mWARNING\u001b[1;0m - Request 10395 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89904 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:14,659 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:14 2023\n",
      "2023-07-03 17:55:14,785 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:14 2023\n",
      "2023-07-03 17:55:14,846 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10417\n",
      "2023-07-03 17:55:15,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 10425 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89320 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:15,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 10432 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89309 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:15,064 - \u001b[1;33mWARNING\u001b[1;0m - Request 10430 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:55:30,053 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:30 2023\n",
      "2023-07-03 17:55:30,064 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:30 2023\n",
      "2023-07-03 17:55:30,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10434\n",
      "2023-07-03 17:55:30,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10454\n",
      "2023-07-03 17:55:30,329 - \u001b[1;33mWARNING\u001b[1;0m - Request 10462 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89325 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:30,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 10438 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89283 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:45,343 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:45 2023\n",
      "2023-07-03 17:55:45,384 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:55:45 2023\n",
      "2023-07-03 17:55:45,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10472\n",
      "2023-07-03 17:55:45,475 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10492\n",
      "2023-07-03 17:55:45,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 10489 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:45,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 10496 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:45,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 10495 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89353 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:55:51,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9866 failed with Exception \n",
      "2023-07-03 17:56:00,652 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:00 2023\n",
      "2023-07-03 17:56:00,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10508\n",
      "2023-07-03 17:56:00,926 - \u001b[1;33mWARNING\u001b[1;0m - Request 10526 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89564 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:00,941 - \u001b[1;33mWARNING\u001b[1;0m - Request 10525 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:15,940 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:15 2023\n",
      "2023-07-03 17:56:15,942 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10526\n",
      "2023-07-03 17:56:16,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10546\n",
      "2023-07-03 17:56:16,427 - \u001b[1;33mWARNING\u001b[1;0m - Request 10554 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:16,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 10555 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:31,444 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:31 2023\n",
      "2023-07-03 17:56:31,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10564\n",
      "2023-07-03 17:56:31,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10584\n",
      "2023-07-03 17:56:31,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 10567 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:31,809 - \u001b[1;33mWARNING\u001b[1;0m - Request 10571 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89270 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:46,817 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:56:46 2023\n",
      "2023-07-03 17:56:46,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10602\n",
      "2023-07-03 17:56:46,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10622\n",
      "2023-07-03 17:56:47,320 - \u001b[1;33mWARNING\u001b[1;0m - Request 10615 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89711 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:47,327 - \u001b[1;33mWARNING\u001b[1;0m - Request 10618 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89711 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:56:47,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 10624 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:02,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:02 2023\n",
      "2023-07-03 17:57:02,405 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:02 2023\n",
      "2023-07-03 17:57:02,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10639\n",
      "2023-07-03 17:57:04,243 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10659\n",
      "2023-07-03 17:57:06,108 - \u001b[1;33mWARNING\u001b[1;0m - Request 10633 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:06,111 - \u001b[1;33mWARNING\u001b[1;0m - Request 10645 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89555 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:06,189 - \u001b[1;33mWARNING\u001b[1;0m - Request 10663 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:57:21,123 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:21 2023\n",
      "2023-07-03 17:57:21,191 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:21 2023\n",
      "2023-07-03 17:57:21,242 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10676\n",
      "2023-07-03 17:57:21,706 - \u001b[1;33mWARNING\u001b[1;0m - Request 10690 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89762 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:21,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 10695 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89635 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:36,720 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:36 2023\n",
      "2023-07-03 17:57:36,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10696\n",
      "2023-07-03 17:57:36,787 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:36 2023\n",
      "2023-07-03 17:57:36,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10714\n",
      "2023-07-03 17:57:37,470 - \u001b[1;33mWARNING\u001b[1;0m - Request 10725 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89652 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:37,473 - \u001b[1;33mWARNING\u001b[1;0m - Request 10706 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89643 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:52,485 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:57:52 2023\n",
      "2023-07-03 17:57:52,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10732\n",
      "2023-07-03 17:57:52,566 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10752\n",
      "2023-07-03 17:57:52,784 - \u001b[1;33mWARNING\u001b[1;0m - Request 10759 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89738 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:57:52,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 10750 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89449 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:07,790 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:07 2023\n",
      "2023-07-03 17:58:07,954 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:07 2023\n",
      "2023-07-03 17:58:07,995 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10770\n",
      "2023-07-03 17:58:08,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10790\n",
      "2023-07-03 17:58:08,223 - \u001b[1;33mWARNING\u001b[1;0m - Request 10791 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89532 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:08,240 - \u001b[1;33mWARNING\u001b[1;0m - Request 10790 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89508 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:08,330 - \u001b[1;33mWARNING\u001b[1;0m - Request 10759 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89374 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:23,233 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:23 2023\n",
      "2023-07-03 17:58:23,331 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:23 2023\n",
      "2023-07-03 17:58:23,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10807\n",
      "2023-07-03 17:58:23,821 - \u001b[1;33mWARNING\u001b[1;0m - Request 10823 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89697 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:23,841 - \u001b[1;33mWARNING\u001b[1;0m - Request 10824 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89672 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:38,836 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:38 2023\n",
      "2023-07-03 17:58:38,842 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:38 2023\n",
      "2023-07-03 17:58:38,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10823\n",
      "2023-07-03 17:58:38,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10845\n",
      "2023-07-03 17:58:39,161 - \u001b[1;33mWARNING\u001b[1;0m - Request 10857 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89497 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:39,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 10853 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:58:54,165 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:54 2023\n",
      "2023-07-03 17:58:54,328 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:58:54 2023\n",
      "2023-07-03 17:58:54,347 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10863\n",
      "2023-07-03 17:58:54,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10883\n",
      "2023-07-03 17:58:55,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 10885 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89588 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:10,765 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:10 2023\n",
      "2023-07-03 17:59:10,802 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10902\n",
      "2023-07-03 17:59:10,861 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10922\n",
      "2023-07-03 17:59:11,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 10907 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89738 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:11,905 - \u001b[1;33mWARNING\u001b[1;0m - Request 10899 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:59:11,925 - \u001b[1;33mWARNING\u001b[1;0m - Request 10914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:12,060 - \u001b[1;33mWARNING\u001b[1;0m - Request 10924 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89500 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:26,908 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:27 2023\n",
      "2023-07-03 17:59:27,061 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:27 2023\n",
      "2023-07-03 17:59:27,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10938\n",
      "2023-07-03 17:59:27,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10958\n",
      "2023-07-03 17:59:27,375 - \u001b[1;33mWARNING\u001b[1;0m - Request 10955 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89415 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:27,557 - \u001b[1;33mWARNING\u001b[1;0m - Request 10953 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89843 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:36,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 10350 failed with Exception \n",
      "2023-07-03 17:59:42,383 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:42 2023\n",
      "2023-07-03 17:59:42,558 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:42 2023\n",
      "2023-07-03 17:59:42,616 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10975\n",
      "2023-07-03 17:59:43,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 10981 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89465 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:43,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 10987 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89456 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:43,068 - \u001b[1;33mWARNING\u001b[1;0m - Request 10984 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:58,057 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:58 2023\n",
      "2023-07-03 17:59:58,070 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 17:59:58 2023\n",
      "2023-07-03 17:59:58,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10984\n",
      "2023-07-03 17:59:58,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11012\n",
      "2023-07-03 17:59:58,563 - \u001b[1;33mWARNING\u001b[1;0m - Request 11017 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89756 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 17:59:58,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 11021 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89721 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:13,579 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:13 2023\n",
      "2023-07-03 18:00:13,589 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:13 2023\n",
      "2023-07-03 18:00:13,620 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11030\n",
      "2023-07-03 18:00:13,678 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11050\n",
      "2023-07-03 18:00:13,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 11056 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89542 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:14,070 - \u001b[1;33mWARNING\u001b[1;0m - Request 11051 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:28,909 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:29 2023\n",
      "2023-07-03 18:00:29,071 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:29 2023\n",
      "2023-07-03 18:00:29,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11068\n",
      "2023-07-03 18:00:29,187 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11088\n",
      "2023-07-03 18:00:29,345 - \u001b[1;33mWARNING\u001b[1;0m - Request 11074 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89906 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:29,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 11076 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89814 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:29,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 11089 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89778 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:30,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10450 failed with Exception \n",
      "2023-07-03 18:00:44,350 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:44 2023\n",
      "2023-07-03 18:00:44,432 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:44 2023\n",
      "2023-07-03 18:00:44,488 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11104\n",
      "2023-07-03 18:00:44,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 11119 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89619 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:44,893 - \u001b[1;33mWARNING\u001b[1;0m - Request 11116 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89357 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:00:59,716 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:59 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:00:59,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:00:59 2023\n",
      "2023-07-03 18:00:59,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11122\n",
      "2023-07-03 18:00:59,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11142\n",
      "2023-07-03 18:01:00,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 11150 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89911 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:00,168 - \u001b[1;33mWARNING\u001b[1;0m - Request 11142 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89914 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10507 failed with Exception \n",
      "2023-07-03 18:01:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10516 failed with Exception \n",
      "2023-07-03 18:01:15,169 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:15 2023\n",
      "2023-07-03 18:01:15,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11158\n",
      "2023-07-03 18:01:15,262 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11178\n",
      "2023-07-03 18:01:15,440 - \u001b[1;33mWARNING\u001b[1;0m - Request 11175 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89666 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:15,483 - \u001b[1;33mWARNING\u001b[1;0m - Request 11181 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89605 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:15,681 - \u001b[1;33mWARNING\u001b[1;0m - Request 11177 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89335 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:30,445 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:30 2023\n",
      "2023-07-03 18:01:30,682 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:30 2023\n",
      "2023-07-03 18:01:30,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11195\n",
      "2023-07-03 18:01:30,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 11213 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:30,945 - \u001b[1;33mWARNING\u001b[1;0m - Request 11209 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:45,945 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:01:45 2023\n",
      "2023-07-03 18:01:45,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11215\n",
      "2023-07-03 18:01:46,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11233\n",
      "2023-07-03 18:01:46,327 - \u001b[1;33mWARNING\u001b[1;0m - Request 11246 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89783 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:01:46,410 - \u001b[1;33mWARNING\u001b[1;0m - Request 11218 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:01,339 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:01 2023\n",
      "2023-07-03 18:02:01,411 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:01 2023\n",
      "2023-07-03 18:02:01,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11251\n",
      "2023-07-03 18:02:01,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11271\n",
      "2023-07-03 18:02:02,640 - \u001b[1;33mWARNING\u001b[1;0m - Request 11259 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:02,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 11265 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:02,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 11274 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89281 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:17,648 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:17 2023\n",
      "2023-07-03 18:02:17,693 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:17 2023\n",
      "2023-07-03 18:02:17,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11288\n",
      "2023-07-03 18:02:17,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11308\n",
      "2023-07-03 18:02:18,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 11286 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89539 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:18,156 - \u001b[1;33mWARNING\u001b[1;0m - Request 11296 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89458 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:33,110 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:33 2023\n",
      "2023-07-03 18:02:33,157 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:33 2023\n",
      "2023-07-03 18:02:33,209 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11326\n",
      "2023-07-03 18:02:33,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 11343 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89587 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:33,777 - \u001b[1;33mWARNING\u001b[1;0m - Request 11344 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:02:48,697 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:48 2023\n",
      "2023-07-03 18:02:48,778 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:02:48 2023\n",
      "2023-07-03 18:02:48,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11343\n",
      "2023-07-03 18:02:48,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11364\n",
      "2023-07-03 18:02:49,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 11374 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89881 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:02:49,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 11373 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89887 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:04,048 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:04 2023\n",
      "2023-07-03 18:03:04,083 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11382\n",
      "2023-07-03 18:03:04,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11402\n",
      "2023-07-03 18:03:06,784 - \u001b[1;33mWARNING\u001b[1;0m - Request 11379 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89701 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:06,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 11380 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89690 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:06,800 - \u001b[1;33mWARNING\u001b[1;0m - Request 11385 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89680 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:21,789 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:21 2023\n",
      "2023-07-03 18:03:21,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:21 2023\n",
      "2023-07-03 18:03:21,835 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11419\n",
      "2023-07-03 18:03:21,892 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11439\n",
      "2023-07-03 18:03:22,075 - \u001b[1;33mWARNING\u001b[1;0m - Request 11423 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:22,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 11438 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89745 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:22,085 - \u001b[1;33mWARNING\u001b[1;0m - Request 11443 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89746 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:22,284 - \u001b[1;33mWARNING\u001b[1;0m - Request 11440 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89433 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:37,088 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:37 2023\n",
      "2023-07-03 18:03:37,285 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:37 2023\n",
      "2023-07-03 18:03:37,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11455\n",
      "2023-07-03 18:03:37,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 11473 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89840 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:37,602 - \u001b[1;33mWARNING\u001b[1;0m - Request 11472 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89803 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:52,588 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:52 2023\n",
      "2023-07-03 18:03:52,603 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:03:52 2023\n",
      "2023-07-03 18:03:52,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11473\n",
      "2023-07-03 18:03:52,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11493\n",
      "2023-07-03 18:03:53,577 - \u001b[1;33mWARNING\u001b[1;0m - Request 11472 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:03:53,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 11506 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89862 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:07,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 11467 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aef352e491160675c4f1656842c8cc62 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:08,581 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:08 2023\n",
      "2023-07-03 18:04:08,587 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:08 2023\n",
      "2023-07-03 18:04:08,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11510\n",
      "2023-07-03 18:04:08,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11530\n",
      "2023-07-03 18:04:09,038 - \u001b[1;33mWARNING\u001b[1;0m - Request 11520 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89322 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:09,049 - \u001b[1;33mWARNING\u001b[1;0m - Request 11519 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89321 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:24,053 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:24 2023\n",
      "2023-07-03 18:04:24,097 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11548\n",
      "2023-07-03 18:04:24,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:04:25,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 11555 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:25,452 - \u001b[1;33mWARNING\u001b[1;0m - Request 11569 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89403 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:25,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 11567 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89403 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:25,532 - \u001b[1;33mWARNING\u001b[1;0m - Request 11572 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89299 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:27,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10932 failed with Exception \n",
      "2023-07-03 18:04:40,464 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:40 2023\n",
      "2023-07-03 18:04:40,533 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:40 2023\n",
      "2023-07-03 18:04:40,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11583\n",
      "2023-07-03 18:04:40,945 - \u001b[1;33mWARNING\u001b[1;0m - Request 11569 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:41,005 - \u001b[1;33mWARNING\u001b[1;0m - Request 11601 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89502 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:55,959 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:56 2023\n",
      "2023-07-03 18:04:56,006 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:04:56 2023\n",
      "2023-07-03 18:04:56,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11569\n",
      "2023-07-03 18:04:56,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11621\n",
      "2023-07-03 18:04:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10997 failed with Exception \n",
      "2023-07-03 18:04:58,629 - \u001b[1;33mWARNING\u001b[1;0m - Request 11605 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89976 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:04:58,666 - \u001b[1;33mWARNING\u001b[1;0m - Request 11638 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89909 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:13,641 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:13 2023\n",
      "2023-07-03 18:05:13,669 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:13 2023\n",
      "2023-07-03 18:05:13,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11638\n",
      "2023-07-03 18:05:13,737 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11658\n",
      "2023-07-03 18:05:13,924 - \u001b[1;33mWARNING\u001b[1;0m - Request 11664 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89585 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:13,932 - \u001b[1;33mWARNING\u001b[1;0m - Request 11667 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89580 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:14,005 - \u001b[1;33mWARNING\u001b[1;0m - Request 11669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89476 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:28,937 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:29 2023\n",
      "2023-07-03 18:05:29,006 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:29 2023\n",
      "2023-07-03 18:05:29,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11675\n",
      "2023-07-03 18:05:29,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11695\n",
      "2023-07-03 18:05:29,558 - \u001b[1;33mWARNING\u001b[1;0m - Request 11677 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89725 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:29,595 - \u001b[1;33mWARNING\u001b[1;0m - Request 11691 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89672 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:29,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 11687 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89668 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:44,560 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:44 2023\n",
      "2023-07-03 18:05:44,604 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:05:44 2023\n",
      "2023-07-03 18:05:44,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11712\n",
      "2023-07-03 18:05:45,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11732\n",
      "2023-07-03 18:05:46,461 - \u001b[1;33mWARNING\u001b[1;0m - Request 11687 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:46,468 - \u001b[1;33mWARNING\u001b[1;0m - Request 11701 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89988 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:05:59,452 - \u001b[1;33mWARNING\u001b[1;0m - Request 11675 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42cb89dea1285fb374c175f233a76b73 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:06:01,465 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:01 2023\n",
      "2023-07-03 18:06:01,469 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:01 2023\n",
      "2023-07-03 18:06:01,524 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11749\n",
      "2023-07-03 18:06:02,808 - \u001b[1;33mWARNING\u001b[1;0m - Request 11755 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89553 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:02,812 - \u001b[1;33mWARNING\u001b[1;0m - Request 11675 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:17,822 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:17 2023\n",
      "2023-07-03 18:06:17,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11755\n",
      "2023-07-03 18:06:17,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11787\n",
      "2023-07-03 18:06:18,084 - \u001b[1;33mWARNING\u001b[1;0m - Request 11792 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89887 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:18,085 - \u001b[1;33mWARNING\u001b[1;0m - Request 11791 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89885 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:18,095 - \u001b[1;33mWARNING\u001b[1;0m - Request 11799 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89874 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:33,097 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:33 2023\n",
      "2023-07-03 18:06:33,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11804\n",
      "2023-07-03 18:06:33,187 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11824\n",
      "2023-07-03 18:06:33,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 11827 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89846 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:33,407 - \u001b[1;33mWARNING\u001b[1;0m - Request 11826 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89889 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:33,408 - \u001b[1;33mWARNING\u001b[1;0m - Request 11830 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89859 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:48,417 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:06:48 2023\n",
      "2023-07-03 18:06:48,460 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11841\n",
      "2023-07-03 18:06:48,607 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11861\n",
      "2023-07-03 18:06:48,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 11861 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89269 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:48,913 - \u001b[1;33mWARNING\u001b[1;0m - Request 11852 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89763 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:06:48,931 - \u001b[1;33mWARNING\u001b[1;0m - Request 11851 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89758 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:03,775 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:03 2023\n",
      "2023-07-03 18:07:03,933 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:03 2023\n",
      "2023-07-03 18:07:03,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11878\n",
      "2023-07-03 18:07:04,197 - \u001b[1;33mWARNING\u001b[1;0m - Request 11889 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:04,199 - \u001b[1;33mWARNING\u001b[1;0m - Request 11886 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:04,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 11890 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89360 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:18,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 11311 failed with Exception \n",
      "2023-07-03 18:07:19,199 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:19 2023\n",
      "2023-07-03 18:07:19,234 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:19 2023\n",
      "2023-07-03 18:07:19,243 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11894\n",
      "2023-07-03 18:07:19,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11914\n",
      "2023-07-03 18:07:19,605 - \u001b[1;33mWARNING\u001b[1;0m - Request 11922 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89674 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:19,713 - \u001b[1;33mWARNING\u001b[1;0m - Request 11918 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89503 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:33,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 11314 failed with Exception \n",
      "2023-07-03 18:07:34,607 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:34 2023\n",
      "2023-07-03 18:07:34,715 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:34 2023\n",
      "2023-07-03 18:07:34,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11931\n",
      "2023-07-03 18:07:34,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:07:34,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 11952 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:34,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 11950 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89339 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:49,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 11351 failed with Exception \n",
      "2023-07-03 18:07:49,977 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:49 2023\n",
      "2023-07-03 18:07:49,988 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:07:49 2023\n",
      "2023-07-03 18:07:50,048 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11968\n",
      "2023-07-03 18:07:50,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 11966 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:50,444 - \u001b[1;33mWARNING\u001b[1;0m - Request 11955 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89423 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:07:50,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 11984 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89344 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:05,433 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:05 2023\n",
      "2023-07-03 18:08:05,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11409 failed with Exception \n",
      "2023-07-03 18:08:05,501 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:05 2023\n",
      "2023-07-03 18:08:05,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11984\n",
      "2023-07-03 18:08:05,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12004\n",
      "2023-07-03 18:08:05,781 - \u001b[1;33mWARNING\u001b[1;0m - Request 12008 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89792 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:05,878 - \u001b[1;33mWARNING\u001b[1;0m - Request 12014 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:20,785 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:20 2023\n",
      "2023-07-03 18:08:20,879 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:20 2023\n",
      "2023-07-03 18:08:20,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12022\n",
      "2023-07-03 18:08:20,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12042\n",
      "2023-07-03 18:08:21,287 - \u001b[1;33mWARNING\u001b[1;0m - Request 12036 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89771 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:21,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 12017 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89728 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:36,289 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:36 2023\n",
      "2023-07-03 18:08:36,329 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:36 2023\n",
      "2023-07-03 18:08:36,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12060\n",
      "2023-07-03 18:08:37,459 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12080\n",
      "2023-07-03 18:08:38,780 - \u001b[1;33mWARNING\u001b[1;0m - Request 12078 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89862 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:38,784 - \u001b[1;33mWARNING\u001b[1;0m - Request 12077 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89863 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:53,795 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:08:53 2023\n",
      "2023-07-03 18:08:53,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12098\n",
      "2023-07-03 18:08:55,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12118\n",
      "2023-07-03 18:08:58,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 12118 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89369 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:58,604 - \u001b[1;33mWARNING\u001b[1;0m - Request 12121 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89938 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:08:58,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 12124 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89885 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:13,523 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:13 2023\n",
      "2023-07-03 18:09:13,645 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:13 2023\n",
      "2023-07-03 18:09:13,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12135\n",
      "2023-07-03 18:09:13,745 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12155\n",
      "2023-07-03 18:09:14,132 - \u001b[1;33mWARNING\u001b[1;0m - Request 12147 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89491 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:14,134 - \u001b[1;33mWARNING\u001b[1;0m - Request 12152 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89488 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:14,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 12155 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89486 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:09:29,146 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:29 2023\n",
      "2023-07-03 18:09:29,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12172\n",
      "2023-07-03 18:09:31,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12192\n",
      "2023-07-03 18:09:31,995 - \u001b[1;33mWARNING\u001b[1;0m - Request 12192 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89666 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:32,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 12168 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89570 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:47,009 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:47 2023\n",
      "2023-07-03 18:09:47,548 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:09:47 2023\n",
      "2023-07-03 18:09:47,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12210\n",
      "2023-07-03 18:09:49,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12230\n",
      "2023-07-03 18:09:52,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 12225 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89900 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:52,602 - \u001b[1;33mWARNING\u001b[1;0m - Request 12223 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89901 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:09:52,744 - \u001b[1;33mWARNING\u001b[1;0m - Request 12236 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89684 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:07,612 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:07 2023\n",
      "2023-07-03 18:10:07,745 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:07 2023\n",
      "2023-07-03 18:10:07,804 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12247\n",
      "2023-07-03 18:10:07,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12267\n",
      "2023-07-03 18:10:08,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 12265 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:08,028 - \u001b[1;33mWARNING\u001b[1;0m - Request 12264 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89434 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:08,057 - \u001b[1;33mWARNING\u001b[1;0m - Request 12262 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:23,041 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:23 2023\n",
      "2023-07-03 18:10:23,058 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:23 2023\n",
      "2023-07-03 18:10:23,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12284\n",
      "2023-07-03 18:10:23,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 12296 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89315 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:23,834 - \u001b[1;33mWARNING\u001b[1;0m - Request 12271 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:38,341 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:38 2023\n",
      "2023-07-03 18:10:38,836 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:38 2023\n",
      "2023-07-03 18:10:38,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12302\n",
      "2023-07-03 18:10:38,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12322\n",
      "2023-07-03 18:10:41,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 12332 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89441 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:41,455 - \u001b[1;33mWARNING\u001b[1;0m - Request 12333 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89823 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:56,239 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:56 2023\n",
      "2023-07-03 18:10:56,457 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:10:56 2023\n",
      "2023-07-03 18:10:56,477 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12340\n",
      "2023-07-03 18:10:56,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12360\n",
      "2023-07-03 18:10:56,724 - \u001b[1;33mWARNING\u001b[1;0m - Request 12354 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89503 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:56,728 - \u001b[1;33mWARNING\u001b[1;0m - Request 12366 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89497 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:56,730 - \u001b[1;33mWARNING\u001b[1;0m - Request 12367 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89498 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:10:56,733 - \u001b[1;33mWARNING\u001b[1;0m - Request 12348 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89504 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:01,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 11739 failed with Exception \n",
      "2023-07-03 18:11:11,735 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:11 2023\n",
      "2023-07-03 18:11:11,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:11:11,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12395\n",
      "2023-07-03 18:11:12,118 - \u001b[1;33mWARNING\u001b[1;0m - Request 12396 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89762 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:12,182 - \u001b[1;33mWARNING\u001b[1;0m - Request 12379 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89661 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:27,132 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:27 2023\n",
      "2023-07-03 18:11:27,182 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:27 2023\n",
      "2023-07-03 18:11:27,246 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12413\n",
      "2023-07-03 18:11:27,664 - \u001b[1;33mWARNING\u001b[1;0m - Request 12422 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89797 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:27,672 - \u001b[1;33mWARNING\u001b[1;0m - Request 12427 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89788 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:42,678 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:11:42 2023\n",
      "2023-07-03 18:11:42,689 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12431\n",
      "2023-07-03 18:11:42,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12451\n",
      "2023-07-03 18:11:45,054 - \u001b[1;33mWARNING\u001b[1;0m - Request 12443 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89892 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:11:45,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 12442 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89854 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:00,068 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:00 2023\n",
      "2023-07-03 18:12:00,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12469\n",
      "2023-07-03 18:12:00,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12489\n",
      "2023-07-03 18:12:00,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 12485 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89616 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:00,329 - \u001b[1;33mWARNING\u001b[1;0m - Request 12493 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89611 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:00,331 - \u001b[1;33mWARNING\u001b[1;0m - Request 12489 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89618 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:15,341 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:15 2023\n",
      "2023-07-03 18:12:15,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12506\n",
      "2023-07-03 18:12:15,461 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12526\n",
      "2023-07-03 18:12:15,625 - \u001b[1;33mWARNING\u001b[1;0m - Request 12526 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89967 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:15,784 - \u001b[1;33mWARNING\u001b[1;0m - Request 12506 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89728 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:30,638 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:30 2023\n",
      "2023-07-03 18:12:30,785 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:30 2023\n",
      "2023-07-03 18:12:30,843 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12544\n",
      "2023-07-03 18:12:31,310 - \u001b[1;33mWARNING\u001b[1;0m - Request 12559 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89813 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:31,312 - \u001b[1;33mWARNING\u001b[1;0m - Request 12557 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89818 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:31,460 - \u001b[1;33mWARNING\u001b[1;0m - Request 12560 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89591 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:46,325 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:46 2023\n",
      "2023-07-03 18:12:46,461 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:12:46 2023\n",
      "2023-07-03 18:12:46,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12560\n",
      "2023-07-03 18:12:46,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12581\n",
      "2023-07-03 18:12:47,524 - \u001b[1;33mWARNING\u001b[1;0m - Request 12567 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:12:47,526 - \u001b[1;33mWARNING\u001b[1;0m - Request 12581 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:02,534 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:02 2023\n",
      "2023-07-03 18:13:02,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12599\n",
      "2023-07-03 18:13:02,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12619\n",
      "2023-07-03 18:13:02,847 - \u001b[1;33mWARNING\u001b[1;0m - Request 12611 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:13:02,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 12619 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89795 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:17,862 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:17 2023\n",
      "2023-07-03 18:13:17,880 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:17 2023\n",
      "2023-07-03 18:13:17,928 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12637\n",
      "2023-07-03 18:13:18,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12657\n",
      "2023-07-03 18:13:18,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 12637 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89951 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:18,764 - \u001b[1;33mWARNING\u001b[1;0m - Request 12656 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89942 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:33,764 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:33 2023\n",
      "2023-07-03 18:13:33,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12675\n",
      "2023-07-03 18:13:34,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 12689 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89583 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:34,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 12670 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89591 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:34,036 - \u001b[1;33mWARNING\u001b[1;0m - Request 12684 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89574 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:49,044 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:13:49 2023\n",
      "2023-07-03 18:13:49,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12692\n",
      "2023-07-03 18:13:49,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12712\n",
      "2023-07-03 18:13:49,400 - \u001b[1;33mWARNING\u001b[1;0m - Request 12703 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89910 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:49,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 12689 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89701 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:13:54,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 12103 failed with Exception \n",
      "2023-07-03 18:14:04,411 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:04 2023\n",
      "2023-07-03 18:14:04,542 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:04 2023\n",
      "2023-07-03 18:14:04,582 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12729\n",
      "2023-07-03 18:14:04,640 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12749\n",
      "2023-07-03 18:14:04,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 12750 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89381 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:04,805 - \u001b[1;33mWARNING\u001b[1;0m - Request 12751 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89378 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:19,815 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:19 2023\n",
      "2023-07-03 18:14:19,877 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12767\n",
      "2023-07-03 18:14:20,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 12780 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89838 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:35,091 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:35 2023\n",
      "2023-07-03 18:14:35,102 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12786\n",
      "2023-07-03 18:14:35,166 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12806\n",
      "2023-07-03 18:14:35,348 - \u001b[1;33mWARNING\u001b[1;0m - Request 12811 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89562 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:35,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 12809 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89554 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:35,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 12815 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89547 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:35,366 - \u001b[1;33mWARNING\u001b[1;0m - Request 12814 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89537 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:35,482 - \u001b[1;33mWARNING\u001b[1;0m - Request 12816 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89370 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:14:48,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 12216 failed with Exception \n",
      "2023-07-03 18:14:50,351 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:50 2023\n",
      "2023-07-03 18:14:50,483 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:14:50 2023\n",
      "2023-07-03 18:14:50,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12820\n",
      "2023-07-03 18:14:50,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12840\n",
      "2023-07-03 18:14:50,984 - \u001b[1;33mWARNING\u001b[1;0m - Request 12832 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89476 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:15:05,990 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:05 2023\n",
      "2023-07-03 18:15:06,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12859\n",
      "2023-07-03 18:15:06,319 - \u001b[1;33mWARNING\u001b[1;0m - Request 12877 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89832 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:06,439 - \u001b[1;33mWARNING\u001b[1;0m - Request 12849 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89658 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:06,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 12875 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:21,335 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:21 2023\n",
      "2023-07-03 18:15:21,503 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:21 2023\n",
      "2023-07-03 18:15:21,503 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12877\n",
      "2023-07-03 18:15:21,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12896\n",
      "2023-07-03 18:15:21,979 - \u001b[1;33mWARNING\u001b[1;0m - Request 12901 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89702 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:23,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12281 failed with Exception \n",
      "2023-07-03 18:15:36,990 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:36 2023\n",
      "2023-07-03 18:15:37,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12914\n",
      "2023-07-03 18:15:37,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12934\n",
      "2023-07-03 18:15:37,489 - \u001b[1;33mWARNING\u001b[1;0m - Request 12934 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:37,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 12938 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89694 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:37,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 12929 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89694 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:37,540 - \u001b[1;33mWARNING\u001b[1;0m - Request 12941 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89633 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:52,501 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:52 2023\n",
      "2023-07-03 18:15:52,541 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:15:52 2023\n",
      "2023-07-03 18:15:52,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12950\n",
      "2023-07-03 18:15:52,678 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12970\n",
      "2023-07-03 18:15:52,837 - \u001b[1;33mWARNING\u001b[1;0m - Request 12962 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:15:52,841 - \u001b[1;33mWARNING\u001b[1;0m - Request 12969 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89317 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:07,849 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:07 2023\n",
      "2023-07-03 18:16:07,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12988\n",
      "2023-07-03 18:16:08,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 12989 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89633 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:08,334 - \u001b[1;33mWARNING\u001b[1;0m - Request 13000 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89352 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:08,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 13003 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:23,168 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:23 2023\n",
      "2023-07-03 18:16:23,494 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:23 2023\n",
      "2023-07-03 18:16:23,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13005\n",
      "2023-07-03 18:16:23,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13025\n",
      "2023-07-03 18:16:23,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 13034 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89337 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:23,805 - \u001b[1;33mWARNING\u001b[1;0m - Request 13012 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89328 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:38,800 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:38 2023\n",
      "2023-07-03 18:16:38,806 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:38 2023\n",
      "2023-07-03 18:16:38,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13043\n",
      "2023-07-03 18:16:38,920 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13063\n",
      "2023-07-03 18:16:39,090 - \u001b[1;33mWARNING\u001b[1;0m - Request 13066 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89711 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:39,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 13063 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89664 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:16:54,104 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:54 2023\n",
      "2023-07-03 18:16:54,127 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:16:54 2023\n",
      "2023-07-03 18:16:54,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13081\n",
      "2023-07-03 18:16:54,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 13096 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89312 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:16:54,436 - \u001b[1;33mWARNING\u001b[1;0m - Request 13095 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89295 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:09,433 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:09 2023\n",
      "2023-07-03 18:17:09,437 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:09 2023\n",
      "2023-07-03 18:17:09,439 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13095\n",
      "2023-07-03 18:17:09,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13119\n",
      "2023-07-03 18:17:09,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 13116 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89702 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:09,770 - \u001b[1;33mWARNING\u001b[1;0m - Request 13130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89654 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:09,881 - \u001b[1;33mWARNING\u001b[1;0m - Request 13112 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89489 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:24,759 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:24 2023\n",
      "2023-07-03 18:17:24,882 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:24 2023\n",
      "2023-07-03 18:17:25,024 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13136\n",
      "2023-07-03 18:17:25,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13156\n",
      "2023-07-03 18:17:28,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 13139 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89771 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:28,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 13153 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89747 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:31,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 12554 failed with Exception \n",
      "2023-07-03 18:17:43,208 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:43 2023\n",
      "2023-07-03 18:17:43,230 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:17:43 2023\n",
      "2023-07-03 18:17:43,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13173\n",
      "2023-07-03 18:17:43,323 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13193\n",
      "2023-07-03 18:17:47,491 - \u001b[1;33mWARNING\u001b[1;0m - Request 13205 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89885 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:47,531 - \u001b[1;33mWARNING\u001b[1;0m - Request 13206 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89819 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:17:47,680 - \u001b[1;33mWARNING\u001b[1;0m - Request 13201 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89595 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:02,505 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:02 2023\n",
      "2023-07-03 18:18:02,681 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:02 2023\n",
      "2023-07-03 18:18:02,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13210\n",
      "2023-07-03 18:18:02,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13230\n",
      "2023-07-03 18:18:02,940 - \u001b[1;33mWARNING\u001b[1;0m - Request 13237 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:02,941 - \u001b[1;33mWARNING\u001b[1;0m - Request 13236 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:02,964 - \u001b[1;33mWARNING\u001b[1;0m - Request 13238 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89347 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:17,952 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:17 2023\n",
      "2023-07-03 18:18:17,968 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:17 2023\n",
      "2023-07-03 18:18:18,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13247\n",
      "2023-07-03 18:18:18,061 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13267\n",
      "2023-07-03 18:18:18,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 13248 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89484 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:18,845 - \u001b[1;33mWARNING\u001b[1;0m - Request 13259 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89488 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:33,857 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:33 2023\n",
      "2023-07-03 18:18:33,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13285\n",
      "2023-07-03 18:18:34,167 - \u001b[1;33mWARNING\u001b[1;0m - Request 13287 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89768 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:18:34,321 - \u001b[1;33mWARNING\u001b[1;0m - Request 13299 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:34,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 12683 failed with Exception \n",
      "2023-07-03 18:18:49,173 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:49 2023\n",
      "2023-07-03 18:18:49,323 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:18:49 2023\n",
      "2023-07-03 18:18:49,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13299\n",
      "2023-07-03 18:18:49,393 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13322\n",
      "2023-07-03 18:18:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 12696 failed with Exception \n",
      "2023-07-03 18:18:49,582 - \u001b[1;33mWARNING\u001b[1;0m - Request 13333 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89886 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:49,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 13324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89877 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:18:49,714 - \u001b[1;33mWARNING\u001b[1;0m - Request 13334 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89690 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:04,587 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:04 2023\n",
      "2023-07-03 18:19:04,715 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:04 2023\n",
      "2023-07-03 18:19:04,736 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13338\n",
      "2023-07-03 18:19:04,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13358\n",
      "2023-07-03 18:19:04,974 - \u001b[1;33mWARNING\u001b[1;0m - Request 13356 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:04,994 - \u001b[1;33mWARNING\u001b[1;0m - Request 13362 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:19,986 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:19 2023\n",
      "2023-07-03 18:19:19,995 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:19 2023\n",
      "2023-07-03 18:19:20,043 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13376\n",
      "2023-07-03 18:19:20,290 - \u001b[1;33mWARNING\u001b[1;0m - Request 13392 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89718 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:20,298 - \u001b[1;33mWARNING\u001b[1;0m - Request 13394 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89706 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:35,293 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:35 2023\n",
      "2023-07-03 18:19:35,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13396\n",
      "2023-07-03 18:19:35,299 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:35 2023\n",
      "2023-07-03 18:19:35,367 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13414\n",
      "2023-07-03 18:19:35,567 - \u001b[1;33mWARNING\u001b[1;0m - Request 13415 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89397 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:35,570 - \u001b[1;33mWARNING\u001b[1;0m - Request 13424 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89396 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:35,580 - \u001b[1;33mWARNING\u001b[1;0m - Request 13418 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:50,581 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:19:50 2023\n",
      "2023-07-03 18:19:50,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13431\n",
      "2023-07-03 18:19:50,662 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13451\n",
      "2023-07-03 18:19:52,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 13452 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:19:53,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 13415 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89319 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:06,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 12851 failed with Exception \n",
      "2023-07-03 18:20:07,771 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:08 2023\n",
      "2023-07-03 18:20:08,042 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:08 2023\n",
      "2023-07-03 18:20:08,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13468\n",
      "2023-07-03 18:20:08,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13488\n",
      "2023-07-03 18:20:08,483 - \u001b[1;33mWARNING\u001b[1;0m - Request 13471 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89460 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:08,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 13492 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:23,489 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:23 2023\n",
      "2023-07-03 18:20:23,552 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:23 2023\n",
      "2023-07-03 18:20:23,598 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13506\n",
      "2023-07-03 18:20:23,655 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13526\n",
      "2023-07-03 18:20:23,853 - \u001b[1;33mWARNING\u001b[1;0m - Request 13524 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89752 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:23,866 - \u001b[1;33mWARNING\u001b[1;0m - Request 13526 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89730 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:23,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 13525 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89727 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:20:38,866 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:38 2023\n",
      "2023-07-03 18:20:38,870 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:38 2023\n",
      "2023-07-03 18:20:38,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13543\n",
      "2023-07-03 18:20:39,180 - \u001b[1;33mWARNING\u001b[1;0m - Request 13552 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89882 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:39,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 13540 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89643 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:53,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 12950 failed with Exception \n",
      "2023-07-03 18:20:54,182 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:54 2023\n",
      "2023-07-03 18:20:54,339 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:20:54 2023\n",
      "2023-07-03 18:20:54,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13560\n",
      "2023-07-03 18:20:54,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13580\n",
      "2023-07-03 18:20:55,090 - \u001b[1;33mWARNING\u001b[1;0m - Request 13585 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89904 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:20:55,099 - \u001b[1;33mWARNING\u001b[1;0m - Request 13586 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89892 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:10,097 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:10 2023\n",
      "2023-07-03 18:21:10,101 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:10 2023\n",
      "2023-07-03 18:21:10,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13598\n",
      "2023-07-03 18:21:10,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13618\n",
      "2023-07-03 18:21:10,940 - \u001b[1;33mWARNING\u001b[1;0m - Request 13586 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89514 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:11,105 - \u001b[1;33mWARNING\u001b[1;0m - Request 13599 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89981 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:25,953 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:26 2023\n",
      "2023-07-03 18:21:26,106 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:26 2023\n",
      "2023-07-03 18:21:26,158 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13636\n",
      "2023-07-03 18:21:26,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13656\n",
      "2023-07-03 18:21:26,904 - \u001b[1;33mWARNING\u001b[1;0m - Request 13639 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:26,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 13654 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89597 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:26,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 13653 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89608 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:26,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 13656 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89460 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:41,918 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:41 2023\n",
      "2023-07-03 18:21:41,991 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:41 2023\n",
      "2023-07-03 18:21:42,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13672\n",
      "2023-07-03 18:21:42,243 - \u001b[1;33mWARNING\u001b[1;0m - Request 13685 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89730 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:42,247 - \u001b[1;33mWARNING\u001b[1;0m - Request 13684 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:57,252 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:21:57 2023\n",
      "2023-07-03 18:21:57,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13690\n",
      "2023-07-03 18:21:57,354 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13710\n",
      "2023-07-03 18:21:57,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 13717 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89913 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:21:57,544 - \u001b[1;33mWARNING\u001b[1;0m - Request 13718 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89906 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:12,555 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:12 2023\n",
      "2023-07-03 18:22:12,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13728\n",
      "2023-07-03 18:22:12,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13748\n",
      "2023-07-03 18:22:14,108 - \u001b[1;33mWARNING\u001b[1;0m - Request 13734 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89758 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:14,204 - \u001b[1;33mWARNING\u001b[1;0m - Request 13753 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89608 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:22:25,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 13140 failed with Exception \n",
      "2023-07-03 18:22:29,114 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:29 2023\n",
      "2023-07-03 18:22:29,204 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:29 2023\n",
      "2023-07-03 18:22:29,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13765\n",
      "2023-07-03 18:22:29,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13785\n",
      "2023-07-03 18:22:31,725 - \u001b[1;33mWARNING\u001b[1;0m - Request 13789 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89369 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:31,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 13758 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89377 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:31,742 - \u001b[1;33mWARNING\u001b[1;0m - Request 13781 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89346 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:46,735 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:46 2023\n",
      "2023-07-03 18:22:46,743 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:22:46 2023\n",
      "2023-07-03 18:22:46,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13802\n",
      "2023-07-03 18:22:47,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13822\n",
      "2023-07-03 18:22:48,040 - \u001b[1;33mWARNING\u001b[1;0m - Request 13812 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89528 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:22:48,058 - \u001b[1;33mWARNING\u001b[1;0m - Request 13809 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:03,053 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:03 2023\n",
      "2023-07-03 18:23:03,059 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:03 2023\n",
      "2023-07-03 18:23:03,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13840\n",
      "2023-07-03 18:23:03,380 - \u001b[1;33mWARNING\u001b[1;0m - Request 13826 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89701 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:03,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 13845 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89701 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:03,406 - \u001b[1;33mWARNING\u001b[1;0m - Request 13833 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:18,384 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:18 2023\n",
      "2023-07-03 18:23:18,407 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:18 2023\n",
      "2023-07-03 18:23:18,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13857\n",
      "2023-07-03 18:23:18,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13877\n",
      "2023-07-03 18:23:18,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 13256 failed with Exception \n",
      "2023-07-03 18:23:18,664 - \u001b[1;33mWARNING\u001b[1;0m - Request 13883 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89878 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:18,680 - \u001b[1;33mWARNING\u001b[1;0m - Request 13882 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89859 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:33,666 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:33 2023\n",
      "2023-07-03 18:23:33,682 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:33 2023\n",
      "2023-07-03 18:23:33,722 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13894\n",
      "2023-07-03 18:23:33,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13914\n",
      "2023-07-03 18:23:33,930 - \u001b[1;33mWARNING\u001b[1;0m - Request 13915 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89495 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:33,946 - \u001b[1;33mWARNING\u001b[1;0m - Request 13916 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89483 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:33,977 - \u001b[1;33mWARNING\u001b[1;0m - Request 13895 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89461 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:48,942 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:48 2023\n",
      "2023-07-03 18:23:48,978 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:23:48 2023\n",
      "2023-07-03 18:23:49,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13931\n",
      "2023-07-03 18:23:49,242 - \u001b[1;33mWARNING\u001b[1;0m - Request 13945 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89732 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:23:49,423 - \u001b[1;33mWARNING\u001b[1;0m - Request 13929 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89463 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:04,257 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:04 2023\n",
      "2023-07-03 18:24:04,423 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:04 2023\n",
      "2023-07-03 18:24:04,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13949\n",
      "2023-07-03 18:24:04,502 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13969\n",
      "2023-07-03 18:24:04,692 - \u001b[1;33mWARNING\u001b[1;0m - Request 13979 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89844 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:04,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 13972 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89862 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:24:19,707 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:19 2023\n",
      "2023-07-03 18:24:19,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13987\n",
      "2023-07-03 18:24:19,797 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14007\n",
      "2023-07-03 18:24:19,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 14003 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89367 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:19,964 - \u001b[1;33mWARNING\u001b[1;0m - Request 14007 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:20,019 - \u001b[1;33mWARNING\u001b[1;0m - Request 14009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:34,964 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:35 2023\n",
      "2023-07-03 18:24:35,020 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:35 2023\n",
      "2023-07-03 18:24:35,072 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14024\n",
      "2023-07-03 18:24:35,692 - \u001b[1;33mWARNING\u001b[1;0m - Request 14037 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89544 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:35,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 14007 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89548 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:50,694 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:24:50 2023\n",
      "2023-07-03 18:24:50,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14044\n",
      "2023-07-03 18:24:50,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14062\n",
      "2023-07-03 18:24:52,118 - \u001b[1;33mWARNING\u001b[1;0m - Request 14078 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89568 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:24:52,473 - \u001b[1;33mWARNING\u001b[1;0m - Request 14044 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89775 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:07,120 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:07 2023\n",
      "2023-07-03 18:25:07,475 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:07 2023\n",
      "2023-07-03 18:25:07,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14080\n",
      "2023-07-03 18:25:07,550 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14100\n",
      "2023-07-03 18:25:07,728 - \u001b[1;33mWARNING\u001b[1;0m - Request 14110 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:07,734 - \u001b[1;33mWARNING\u001b[1;0m - Request 14106 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89341 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:07,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 14109 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:22,740 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:22 2023\n",
      "2023-07-03 18:25:22,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14117\n",
      "2023-07-03 18:25:22,846 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14137\n",
      "2023-07-03 18:25:23,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 14141 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89557 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:23,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 14139 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89515 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:23,081 - \u001b[1;33mWARNING\u001b[1;0m - Request 14142 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89446 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:38,037 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:38 2023\n",
      "2023-07-03 18:25:38,082 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:38 2023\n",
      "2023-07-03 18:25:38,244 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14154\n",
      "2023-07-03 18:25:38,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14174\n",
      "2023-07-03 18:25:39,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13524 failed with Exception \n",
      "2023-07-03 18:25:40,524 - \u001b[1;33mWARNING\u001b[1;0m - Request 14161 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89329 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:40,543 - \u001b[1;33mWARNING\u001b[1;0m - Request 14141 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89303 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:55,531 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:55 2023\n",
      "2023-07-03 18:25:55,545 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:25:55 2023\n",
      "2023-07-03 18:25:55,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14191\n",
      "2023-07-03 18:25:55,815 - \u001b[1;33mWARNING\u001b[1;0m - Request 14207 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89486 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:25:55,921 - \u001b[1;33mWARNING\u001b[1;0m - Request 14209 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:26:10,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 13597 failed with Exception \n",
      "2023-07-03 18:26:10,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 13595 failed with Exception \n",
      "2023-07-03 18:26:10,817 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:10 2023\n",
      "2023-07-03 18:26:10,922 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:10 2023\n",
      "2023-07-03 18:26:10,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14207\n",
      "2023-07-03 18:26:10,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14227\n",
      "2023-07-03 18:26:11,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 14236 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:11,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 14221 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89511 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:26,229 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:26 2023\n",
      "2023-07-03 18:26:26,727 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:26 2023\n",
      "2023-07-03 18:26:26,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14245\n",
      "2023-07-03 18:26:26,813 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14265\n",
      "2023-07-03 18:26:32,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 14275 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89796 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:32,132 - \u001b[1;33mWARNING\u001b[1;0m - Request 14274 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89784 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:32,134 - \u001b[1;33mWARNING\u001b[1;0m - Request 14281 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89785 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:32,245 - \u001b[1;33mWARNING\u001b[1;0m - Request 14284 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89614 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:47,138 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:47 2023\n",
      "2023-07-03 18:26:47,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14285\n",
      "2023-07-03 18:26:47,246 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:26:47 2023\n",
      "2023-07-03 18:26:47,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14301\n",
      "2023-07-03 18:26:47,598 - \u001b[1;33mWARNING\u001b[1;0m - Request 14313 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89633 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:26:47,678 - \u001b[1;33mWARNING\u001b[1;0m - Request 14298 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89521 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:02,600 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:02 2023\n",
      "2023-07-03 18:27:02,679 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:02 2023\n",
      "2023-07-03 18:27:02,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14319\n",
      "2023-07-03 18:27:02,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14339\n",
      "2023-07-03 18:27:02,995 - \u001b[1;33mWARNING\u001b[1;0m - Request 14342 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89530 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:02,998 - \u001b[1;33mWARNING\u001b[1;0m - Request 14329 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89533 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:03,144 - \u001b[1;33mWARNING\u001b[1;0m - Request 14347 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89293 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:18,007 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:18 2023\n",
      "2023-07-03 18:27:18,146 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:18 2023\n",
      "2023-07-03 18:27:18,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14356\n",
      "2023-07-03 18:27:18,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14376\n",
      "2023-07-03 18:27:18,412 - \u001b[1;33mWARNING\u001b[1;0m - Request 14371 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:33,426 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:33 2023\n",
      "2023-07-03 18:27:33,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14395\n",
      "2023-07-03 18:27:33,723 - \u001b[1;33mWARNING\u001b[1;0m - Request 14408 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89524 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:33,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 14410 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89517 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:33,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 14391 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89521 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:27:47,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 13803 failed with Exception \n",
      "2023-07-03 18:27:48,725 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:48 2023\n",
      "2023-07-03 18:27:48,770 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:27:48 2023\n",
      "2023-07-03 18:27:48,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14391\n",
      "2023-07-03 18:27:48,846 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14431\n",
      "2023-07-03 18:27:49,072 - \u001b[1;33mWARNING\u001b[1;0m - Request 14427 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89544 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:27:49,231 - \u001b[1;33mWARNING\u001b[1;0m - Request 14418 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89341 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:04,075 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:04 2023\n",
      "2023-07-03 18:28:04,232 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:04 2023\n",
      "2023-07-03 18:28:04,266 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14449\n",
      "2023-07-03 18:28:04,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14469\n",
      "2023-07-03 18:28:04,521 - \u001b[1;33mWARNING\u001b[1;0m - Request 14473 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89375 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:04,527 - \u001b[1;33mWARNING\u001b[1;0m - Request 14471 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89363 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:19,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:19 2023\n",
      "2023-07-03 18:28:19,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14487\n",
      "2023-07-03 18:28:19,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 14485 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89383 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:19,811 - \u001b[1;33mWARNING\u001b[1;0m - Request 14501 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89358 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:19,835 - \u001b[1;33mWARNING\u001b[1;0m - Request 14502 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89323 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:34,813 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:34 2023\n",
      "2023-07-03 18:28:34,813 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14507\n",
      "2023-07-03 18:28:34,837 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:34 2023\n",
      "2023-07-03 18:28:34,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14524\n",
      "2023-07-03 18:28:37,620 - \u001b[1;33mWARNING\u001b[1;0m - Request 14509 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89344 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:37,633 - \u001b[1;33mWARNING\u001b[1;0m - Request 14502 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:52,635 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:28:52 2023\n",
      "2023-07-03 18:28:52,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14544\n",
      "2023-07-03 18:28:52,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14562\n",
      "2023-07-03 18:28:52,932 - \u001b[1;33mWARNING\u001b[1;0m - Request 14560 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89300 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:28:52,948 - \u001b[1;33mWARNING\u001b[1;0m - Request 14554 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:07,948 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:07 2023\n",
      "2023-07-03 18:29:07,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14580\n",
      "2023-07-03 18:29:08,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14600\n",
      "2023-07-03 18:29:08,287 - \u001b[1;33mWARNING\u001b[1;0m - Request 14581 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89947 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:08,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 14608 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89783 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:08,439 - \u001b[1;33mWARNING\u001b[1;0m - Request 14607 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89721 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:23,291 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:23 2023\n",
      "2023-07-03 18:29:23,440 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:23 2023\n",
      "2023-07-03 18:29:23,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14617\n",
      "2023-07-03 18:29:23,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14637\n",
      "2023-07-03 18:29:28,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 14650 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89864 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:28,623 - \u001b[1;33mWARNING\u001b[1;0m - Request 14649 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:43,440 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:43 2023\n",
      "2023-07-03 18:29:43,624 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:43 2023\n",
      "2023-07-03 18:29:43,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14655\n",
      "2023-07-03 18:29:43,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14675\n",
      "2023-07-03 18:29:43,914 - \u001b[1;33mWARNING\u001b[1;0m - Request 14669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89657 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:43,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 14668 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89644 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:29:43,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 14682 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89658 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:44,065 - \u001b[1;33mWARNING\u001b[1;0m - Request 14683 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:29:58,929 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:59 2023\n",
      "2023-07-03 18:29:59,067 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:29:59 2023\n",
      "2023-07-03 18:29:59,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14691\n",
      "2023-07-03 18:29:59,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14711\n",
      "2023-07-03 18:29:59,330 - \u001b[1;33mWARNING\u001b[1;0m - Request 14701 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:14,337 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:14 2023\n",
      "2023-07-03 18:30:14,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14730\n",
      "2023-07-03 18:30:16,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14750\n",
      "2023-07-03 18:30:18,789 - \u001b[1;33mWARNING\u001b[1;0m - Request 14732 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89831 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:18,791 - \u001b[1;33mWARNING\u001b[1;0m - Request 14749 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89829 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:18,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 14756 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:19,085 - \u001b[1;33mWARNING\u001b[1;0m - Request 14743 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89384 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:33,804 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:34 2023\n",
      "2023-07-03 18:30:34,086 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:34 2023\n",
      "2023-07-03 18:30:34,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14766\n",
      "2023-07-03 18:30:34,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14786\n",
      "2023-07-03 18:30:34,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 14787 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89922 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:34,588 - \u001b[1;33mWARNING\u001b[1;0m - Request 14763 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89924 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:49,587 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:30:49 2023\n",
      "2023-07-03 18:30:49,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14804\n",
      "2023-07-03 18:30:49,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 14811 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89908 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:30:49,884 - \u001b[1;33mWARNING\u001b[1;0m - Request 14818 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89887 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:04,894 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:04 2023\n",
      "2023-07-03 18:31:04,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14822\n",
      "2023-07-03 18:31:04,972 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14842\n",
      "2023-07-03 18:31:05,244 - \u001b[1;33mWARNING\u001b[1;0m - Request 14839 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89737 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:05,402 - \u001b[1;33mWARNING\u001b[1;0m - Request 14846 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89524 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:05,449 - \u001b[1;33mWARNING\u001b[1;0m - Request 14852 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:20,258 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:20 2023\n",
      "2023-07-03 18:31:20,450 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:20 2023\n",
      "2023-07-03 18:31:20,485 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14859\n",
      "2023-07-03 18:31:20,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14879\n",
      "2023-07-03 18:31:22,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 14882 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89596 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:37,058 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:37 2023\n",
      "2023-07-03 18:31:37,104 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14898\n",
      "2023-07-03 18:31:37,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14918\n",
      "2023-07-03 18:31:37,322 - \u001b[1;33mWARNING\u001b[1;0m - Request 14918 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89514 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:37,386 - \u001b[1;33mWARNING\u001b[1;0m - Request 14920 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89426 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:31:37,403 - \u001b[1;33mWARNING\u001b[1;0m - Request 14910 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:37,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 14916 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89348 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:31:52,337 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:52 2023\n",
      "2023-07-03 18:31:52,448 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:31:52 2023\n",
      "2023-07-03 18:31:52,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14934\n",
      "2023-07-03 18:31:53,970 - \u001b[1;33mWARNING\u001b[1;0m - Request 14949 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:08,985 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:08 2023\n",
      "2023-07-03 18:32:08,986 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14954\n",
      "2023-07-03 18:32:09,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14973\n",
      "2023-07-03 18:32:09,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 14978 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89432 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:09,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 14985 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89803 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:18,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 14369 failed with Exception \n",
      "2023-07-03 18:32:24,271 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:24 2023\n",
      "2023-07-03 18:32:24,495 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:24 2023\n",
      "2023-07-03 18:32:24,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14990\n",
      "2023-07-03 18:32:24,571 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15010\n",
      "2023-07-03 18:32:24,837 - \u001b[1;33mWARNING\u001b[1;0m - Request 15009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89754 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:24,846 - \u001b[1;33mWARNING\u001b[1;0m - Request 15012 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89741 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:24,850 - \u001b[1;33mWARNING\u001b[1;0m - Request 15011 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:24,972 - \u001b[1;33mWARNING\u001b[1;0m - Request 15019 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89509 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:39,850 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:39 2023\n",
      "2023-07-03 18:32:39,973 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:39 2023\n",
      "2023-07-03 18:32:40,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15026\n",
      "2023-07-03 18:32:40,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15046\n",
      "2023-07-03 18:32:40,664 - \u001b[1;33mWARNING\u001b[1;0m - Request 15044 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89586 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:40,673 - \u001b[1;33mWARNING\u001b[1;0m - Request 15049 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89565 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:55,679 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:32:55 2023\n",
      "2023-07-03 18:32:55,731 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15064\n",
      "2023-07-03 18:32:56,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15084\n",
      "2023-07-03 18:32:59,464 - \u001b[1;33mWARNING\u001b[1;0m - Request 15081 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89854 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:59,467 - \u001b[1;33mWARNING\u001b[1;0m - Request 15090 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89859 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:32:59,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 15091 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89582 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:14,473 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:14 2023\n",
      "2023-07-03 18:33:14,678 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:14 2023\n",
      "2023-07-03 18:33:14,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15101\n",
      "2023-07-03 18:33:14,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15121\n",
      "2023-07-03 18:33:19,480 - \u001b[1;33mWARNING\u001b[1;0m - Request 15105 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89751 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:19,673 - \u001b[1;33mWARNING\u001b[1;0m - Request 15117 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89462 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:19,761 - \u001b[1;33mWARNING\u001b[1;0m - Request 15133 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:33:34,489 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:34 2023\n",
      "2023-07-03 18:33:34,762 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:34 2023\n",
      "2023-07-03 18:33:34,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15138\n",
      "2023-07-03 18:33:34,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15158\n",
      "2023-07-03 18:33:35,407 - \u001b[1;33mWARNING\u001b[1;0m - Request 15143 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89344 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:35,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 15166 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89924 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:50,417 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:50 2023\n",
      "2023-07-03 18:33:50,466 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:33:50 2023\n",
      "2023-07-03 18:33:50,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15176\n",
      "2023-07-03 18:33:50,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15196\n",
      "2023-07-03 18:33:50,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 15188 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89400 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:33:51,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 15183 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89327 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:05,976 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:06 2023\n",
      "2023-07-03 18:34:06,010 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:06 2023\n",
      "2023-07-03 18:34:06,059 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15214\n",
      "2023-07-03 18:34:07,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15234\n",
      "2023-07-03 18:34:07,382 - \u001b[1;33mWARNING\u001b[1;0m - Request 15233 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89461 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:07,414 - \u001b[1;33mWARNING\u001b[1;0m - Request 15229 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89466 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:22,383 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:22 2023\n",
      "2023-07-03 18:34:22,415 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:22 2023\n",
      "2023-07-03 18:34:22,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15252\n",
      "2023-07-03 18:34:25,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15272\n",
      "2023-07-03 18:34:28,018 - \u001b[1;33mWARNING\u001b[1;0m - Request 15272 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89801 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:28,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 15274 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:28,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 15271 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89720 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:28,105 - \u001b[1;33mWARNING\u001b[1;0m - Request 15278 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89665 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:43,032 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:43 2023\n",
      "2023-07-03 18:34:43,108 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:43 2023\n",
      "2023-07-03 18:34:43,149 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15288\n",
      "2023-07-03 18:34:43,268 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15308\n",
      "2023-07-03 18:34:43,453 - \u001b[1;33mWARNING\u001b[1;0m - Request 15301 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:43,798 - \u001b[1;33mWARNING\u001b[1;0m - Request 15300 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89502 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:58,465 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:58 2023\n",
      "2023-07-03 18:34:58,799 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:34:58 2023\n",
      "2023-07-03 18:34:58,862 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15326\n",
      "2023-07-03 18:34:59,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 15321 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89720 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:59,275 - \u001b[1;33mWARNING\u001b[1;0m - Request 15336 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89632 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:34:59,348 - \u001b[1;33mWARNING\u001b[1;0m - Request 15341 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:14,217 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:14 2023\n",
      "2023-07-03 18:35:14,349 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:14 2023\n",
      "2023-07-03 18:35:14,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15343\n",
      "2023-07-03 18:35:14,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15363\n",
      "2023-07-03 18:35:18,772 - \u001b[1;33mWARNING\u001b[1;0m - Request 15381 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89648 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:35:33,784 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:33 2023\n",
      "2023-07-03 18:35:33,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15381\n",
      "2023-07-03 18:35:33,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15402\n",
      "2023-07-03 18:35:34,123 - \u001b[1;33mWARNING\u001b[1;0m - Request 15405 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89318 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:34,144 - \u001b[1;33mWARNING\u001b[1;0m - Request 15407 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89299 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:34,361 - \u001b[1;33mWARNING\u001b[1;0m - Request 15384 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89702 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:34,471 - \u001b[1;33mWARNING\u001b[1;0m - Request 15404 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89545 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:34,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 14780 failed with Exception \n",
      "2023-07-03 18:35:49,125 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:49 2023\n",
      "2023-07-03 18:35:49,473 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:35:49 2023\n",
      "2023-07-03 18:35:49,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15417\n",
      "2023-07-03 18:35:49,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15437\n",
      "2023-07-03 18:35:49,855 - \u001b[1;33mWARNING\u001b[1;0m - Request 15427 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89825 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:35:49,856 - \u001b[1;33mWARNING\u001b[1;0m - Request 15440 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89822 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:04,869 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:04 2023\n",
      "2023-07-03 18:36:04,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15455\n",
      "2023-07-03 18:36:04,996 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15475\n",
      "2023-07-03 18:36:08,362 - \u001b[1;33mWARNING\u001b[1;0m - Request 15461 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89854 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:08,366 - \u001b[1;33mWARNING\u001b[1;0m - Request 15478 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89856 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:08,371 - \u001b[1;33mWARNING\u001b[1;0m - Request 15462 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89854 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:19,868 - \u001b[1;33mWARNING\u001b[1;0m - Request 15441 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c75b869095845bc86c33771288d4d587 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:23,367 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:23 2023\n",
      "2023-07-03 18:36:23,372 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:23 2023\n",
      "2023-07-03 18:36:23,410 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15491\n",
      "2023-07-03 18:36:23,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15511\n",
      "2023-07-03 18:36:24,149 - \u001b[1;33mWARNING\u001b[1;0m - Request 15513 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:24,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 15462 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:39,164 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:39 2023\n",
      "2023-07-03 18:36:39,442 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:39 2023\n",
      "2023-07-03 18:36:39,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15529\n",
      "2023-07-03 18:36:39,806 - \u001b[1;33mWARNING\u001b[1;0m - Request 15536 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89908 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:39,888 - \u001b[1;33mWARNING\u001b[1;0m - Request 15546 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89738 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:40,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 15523 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89501 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:53,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 15441 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e67ce73be30e4aa8fbab0ce112207991 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:54,809 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:55 2023\n",
      "2023-07-03 18:36:55,079 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:36:55 2023\n",
      "2023-07-03 18:36:55,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15546\n",
      "2023-07-03 18:36:55,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15565\n",
      "2023-07-03 18:36:55,457 - \u001b[1;33mWARNING\u001b[1;0m - Request 15569 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89695 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:36:55,465 - \u001b[1;33mWARNING\u001b[1;0m - Request 15575 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89686 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:37:10,471 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:10 2023\n",
      "2023-07-03 18:37:10,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15583\n",
      "2023-07-03 18:37:10,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15603\n",
      "2023-07-03 18:37:15,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 15618 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89867 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:15,336 - \u001b[1;33mWARNING\u001b[1;0m - Request 15580 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89761 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:15,585 - \u001b[1;33mWARNING\u001b[1;0m - Request 15579 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:30,279 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:30 2023\n",
      "2023-07-03 18:37:30,587 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:30 2023\n",
      "2023-07-03 18:37:30,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15620\n",
      "2023-07-03 18:37:30,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15640\n",
      "2023-07-03 18:37:31,086 - \u001b[1;33mWARNING\u001b[1;0m - Request 15647 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89400 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:31,098 - \u001b[1;33mWARNING\u001b[1;0m - Request 15650 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89435 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:46,098 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:37:46 2023\n",
      "2023-07-03 18:37:46,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15658\n",
      "2023-07-03 18:37:46,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15678\n",
      "2023-07-03 18:37:46,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 15682 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89771 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:46,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 15681 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89722 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:37:46,592 - \u001b[1;33mWARNING\u001b[1;0m - Request 15679 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89520 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:01,437 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:01 2023\n",
      "2023-07-03 18:38:01,594 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:01 2023\n",
      "2023-07-03 18:38:01,640 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15695\n",
      "2023-07-03 18:38:02,618 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15715\n",
      "2023-07-03 18:38:05,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 15699 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89684 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:05,047 - \u001b[1;33mWARNING\u001b[1;0m - Request 15720 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89688 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:20,062 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:20 2023\n",
      "2023-07-03 18:38:20,112 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15733\n",
      "2023-07-03 18:38:20,681 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15753\n",
      "2023-07-03 18:38:21,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 15755 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89408 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:36,753 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:36 2023\n",
      "2023-07-03 18:38:36,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15772\n",
      "2023-07-03 18:38:37,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 15766 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89380 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:37,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 15768 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89369 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:37,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 15776 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89336 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:37,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 15778 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89593 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:52,082 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:52 2023\n",
      "2023-07-03 18:38:52,425 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:38:52 2023\n",
      "2023-07-03 18:38:52,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15778\n",
      "2023-07-03 18:38:52,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15808\n",
      "2023-07-03 18:38:54,409 - \u001b[1;33mWARNING\u001b[1;0m - Request 15788 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89753 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:54,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 15776 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89735 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:38:54,459 - \u001b[1;33mWARNING\u001b[1;0m - Request 15805 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89743 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:38:54,549 - \u001b[1;33mWARNING\u001b[1;0m - Request 15822 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:09,412 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:09 2023\n",
      "2023-07-03 18:39:09,550 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:09 2023\n",
      "2023-07-03 18:39:09,559 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15824\n",
      "2023-07-03 18:39:09,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15844\n",
      "2023-07-03 18:39:10,215 - \u001b[1;33mWARNING\u001b[1;0m - Request 15842 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89480 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:10,238 - \u001b[1;33mWARNING\u001b[1;0m - Request 15846 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:25,229 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:25 2023\n",
      "2023-07-03 18:39:25,239 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:25 2023\n",
      "2023-07-03 18:39:25,277 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15862\n",
      "2023-07-03 18:39:25,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15882\n",
      "2023-07-03 18:39:25,569 - \u001b[1;33mWARNING\u001b[1;0m - Request 15869 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:25,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 15867 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89729 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:40,579 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:40 2023\n",
      "2023-07-03 18:39:40,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15900\n",
      "2023-07-03 18:39:41,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 15915 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89995 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:41,081 - \u001b[1;33mWARNING\u001b[1;0m - Request 15916 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89970 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:56,087 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:39:56 2023\n",
      "2023-07-03 18:39:56,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15918\n",
      "2023-07-03 18:39:56,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15938\n",
      "2023-07-03 18:39:56,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 15922 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89813 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:56,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 15942 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89762 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:39:56,744 - \u001b[1;33mWARNING\u001b[1;0m - Request 15929 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89289 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:11,398 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:11 2023\n",
      "2023-07-03 18:40:11,745 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:11 2023\n",
      "2023-07-03 18:40:11,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15955\n",
      "2023-07-03 18:40:11,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15975\n",
      "2023-07-03 18:40:12,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 15977 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89802 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:12,527 - \u001b[1;33mWARNING\u001b[1;0m - Request 15955 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:27,465 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:27 2023\n",
      "2023-07-03 18:40:27,528 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:27 2023\n",
      "2023-07-03 18:40:27,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #15993\n",
      "2023-07-03 18:40:27,890 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16013\n",
      "2023-07-03 18:40:28,156 - \u001b[1;33mWARNING\u001b[1;0m - Request 15988 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89662 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:28,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 15996 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89621 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:28,237 - \u001b[1;33mWARNING\u001b[1;0m - Request 16009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89543 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:43,169 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:43 2023\n",
      "2023-07-03 18:40:43,238 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:43 2023\n",
      "2023-07-03 18:40:43,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16030\n",
      "2023-07-03 18:40:43,666 - \u001b[1;33mWARNING\u001b[1;0m - Request 16041 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89796 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:43,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 16035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89611 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:40:58,673 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:58 2023\n",
      "2023-07-03 18:40:58,731 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:40:58 2023\n",
      "2023-07-03 18:40:58,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16048\n",
      "2023-07-03 18:40:58,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16068\n",
      "2023-07-03 18:40:59,239 - \u001b[1;33mWARNING\u001b[1;0m - Request 16076 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89662 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:59,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 16073 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:40:59,326 - \u001b[1;33mWARNING\u001b[1;0m - Request 16077 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89527 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:14,253 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:14 2023\n",
      "2023-07-03 18:41:14,328 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:14 2023\n",
      "2023-07-03 18:41:14,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16085\n",
      "2023-07-03 18:41:14,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16105\n",
      "2023-07-03 18:41:14,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 16108 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89742 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:15,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 16098 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89388 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:29,078 - \u001b[1;33mWARNING\u001b[1;0m - Request 16049 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fba03998340fed0c98dafdfa742f498b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:29,733 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:30 2023\n",
      "2023-07-03 18:41:30,001 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:30 2023\n",
      "2023-07-03 18:41:30,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16122\n",
      "2023-07-03 18:41:30,988 - \u001b[1;33mWARNING\u001b[1;0m - Request 16135 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89365 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:31,029 - \u001b[1;33mWARNING\u001b[1;0m - Request 16115 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:46,002 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:46 2023\n",
      "2023-07-03 18:41:46,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16142\n",
      "2023-07-03 18:41:46,030 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:41:46 2023\n",
      "2023-07-03 18:41:46,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16160\n",
      "2023-07-03 18:41:47,156 - \u001b[1;33mWARNING\u001b[1;0m - Request 16145 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89969 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:41:47,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 16174 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:02,171 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:02 2023\n",
      "2023-07-03 18:42:02,552 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:02 2023\n",
      "2023-07-03 18:42:02,568 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16178\n",
      "2023-07-03 18:42:02,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16198\n",
      "2023-07-03 18:42:03,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 16200 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89364 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:03,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 16205 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89350 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:03,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 16207 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89342 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:18,045 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:18 2023\n",
      "2023-07-03 18:42:18,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16215\n",
      "2023-07-03 18:42:18,137 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16235\n",
      "2023-07-03 18:42:18,680 - \u001b[1;33mWARNING\u001b[1;0m - Request 16212 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89428 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:18,697 - \u001b[1;33mWARNING\u001b[1;0m - Request 16220 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:18,701 - \u001b[1;33mWARNING\u001b[1;0m - Request 16223 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89399 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:33,693 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:33 2023\n",
      "2023-07-03 18:42:33,702 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:33 2023\n",
      "2023-07-03 18:42:33,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:42:34,216 - \u001b[1;33mWARNING\u001b[1;0m - Request 16259 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89651 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:34,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 16267 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89515 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:49,220 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:49 2023\n",
      "2023-07-03 18:42:49,274 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:42:49 2023\n",
      "2023-07-03 18:42:49,275 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16259\n",
      "2023-07-03 18:42:49,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16290\n",
      "2023-07-03 18:42:49,631 - \u001b[1;33mWARNING\u001b[1;0m - Request 16302 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89898 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:42:49,965 - \u001b[1;33mWARNING\u001b[1;0m - Request 16301 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:04,642 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:04 2023\n",
      "2023-07-03 18:43:04,966 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:04 2023\n",
      "2023-07-03 18:43:04,990 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16308\n",
      "2023-07-03 18:43:05,066 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16328\n",
      "2023-07-03 18:43:05,334 - \u001b[1;33mWARNING\u001b[1;0m - Request 16329 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89712 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:05,367 - \u001b[1;33mWARNING\u001b[1;0m - Request 16330 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89661 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:05,474 - \u001b[1;33mWARNING\u001b[1;0m - Request 16335 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89450 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:20,345 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:20 2023\n",
      "2023-07-03 18:43:20,474 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:20 2023\n",
      "2023-07-03 18:43:20,524 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16345\n",
      "2023-07-03 18:43:20,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16365\n",
      "2023-07-03 18:43:20,903 - \u001b[1;33mWARNING\u001b[1;0m - Request 16366 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89734 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:20,982 - \u001b[1;33mWARNING\u001b[1;0m - Request 16362 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89618 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:35,913 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:35 2023\n",
      "2023-07-03 18:43:35,983 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:35 2023\n",
      "2023-07-03 18:43:36,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16383\n",
      "2023-07-03 18:43:36,685 - \u001b[1;33mWARNING\u001b[1;0m - Request 16388 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:36,747 - \u001b[1;33mWARNING\u001b[1;0m - Request 16398 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89337 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:51,687 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:51 2023\n",
      "2023-07-03 18:43:51,749 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:43:51 2023\n",
      "2023-07-03 18:43:51,755 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16401\n",
      "2023-07-03 18:43:51,823 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16421\n",
      "2023-07-03 18:43:52,201 - \u001b[1;33mWARNING\u001b[1;0m - Request 16419 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:52,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 16425 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:52,221 - \u001b[1;33mWARNING\u001b[1;0m - Request 16420 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89394 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:43:52,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 15802 failed with Exception \n",
      "2023-07-03 18:44:07,203 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:07 2023\n",
      "2023-07-03 18:44:07,222 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:07 2023\n",
      "2023-07-03 18:44:07,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16437\n",
      "2023-07-03 18:44:07,311 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16457\n",
      "2023-07-03 18:44:07,524 - \u001b[1;33mWARNING\u001b[1;0m - Request 16461 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89818 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:07,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 16457 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89785 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:22,537 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:22 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:44:22,575 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:22 2023\n",
      "2023-07-03 18:44:22,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16475\n",
      "2023-07-03 18:44:22,970 - \u001b[1;33mWARNING\u001b[1;0m - Request 16493 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89333 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:22,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 16489 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89381 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:22,977 - \u001b[1;33mWARNING\u001b[1;0m - Request 16492 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89369 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:37,972 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:37 2023\n",
      "2023-07-03 18:44:37,978 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:37 2023\n",
      "2023-07-03 18:44:37,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16493\n",
      "2023-07-03 18:44:38,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16512\n",
      "2023-07-03 18:44:39,618 - \u001b[1;33mWARNING\u001b[1;0m - Request 16523 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89773 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:39,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 16527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89628 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:54,629 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:54 2023\n",
      "2023-07-03 18:44:54,688 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:44:54 2023\n",
      "2023-07-03 18:44:54,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16530\n",
      "2023-07-03 18:44:54,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16550\n",
      "2023-07-03 18:44:57,745 - \u001b[1;33mWARNING\u001b[1;0m - Request 16528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89378 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:44:58,041 - \u001b[1;33mWARNING\u001b[1;0m - Request 16565 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89660 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:12,759 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:13 2023\n",
      "2023-07-03 18:45:13,042 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:13 2023\n",
      "2023-07-03 18:45:13,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16568\n",
      "2023-07-03 18:45:13,118 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16588\n",
      "2023-07-03 18:45:13,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 16581 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89952 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:13,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 16596 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89918 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:28,437 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:28 2023\n",
      "2023-07-03 18:45:28,494 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:28 2023\n",
      "2023-07-03 18:45:28,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16606\n",
      "2023-07-03 18:45:28,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16626\n",
      "2023-07-03 18:45:32,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 16639 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89631 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:33,016 - \u001b[1;33mWARNING\u001b[1;0m - Request 16636 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89572 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:33,306 - \u001b[1;33mWARNING\u001b[1;0m - Request 16638 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89852 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:47,985 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:48 2023\n",
      "2023-07-03 18:45:48,308 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:45:48 2023\n",
      "2023-07-03 18:45:48,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16643\n",
      "2023-07-03 18:45:48,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16663\n",
      "2023-07-03 18:45:48,594 - \u001b[1;33mWARNING\u001b[1;0m - Request 16670 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:48,598 - \u001b[1;33mWARNING\u001b[1;0m - Request 16669 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89439 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:45:48,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 16667 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89443 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:03,605 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:03 2023\n",
      "2023-07-03 18:46:03,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16680\n",
      "2023-07-03 18:46:03,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16700\n",
      "2023-07-03 18:46:04,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 16689 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89566 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:04,102 - \u001b[1;33mWARNING\u001b[1;0m - Request 16678 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89560 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:46:04,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 16702 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89437 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:19,083 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:19 2023\n",
      "2023-07-03 18:46:19,166 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:19 2023\n",
      "2023-07-03 18:46:19,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16717\n",
      "2023-07-03 18:46:21,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16737\n",
      "2023-07-03 18:46:23,242 - \u001b[1;33mWARNING\u001b[1;0m - Request 16727 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89299 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:23,258 - \u001b[1;33mWARNING\u001b[1;0m - Request 16737 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:38,253 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:38 2023\n",
      "2023-07-03 18:46:38,259 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:38 2023\n",
      "2023-07-03 18:46:38,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16755\n",
      "2023-07-03 18:46:38,730 - \u001b[1;33mWARNING\u001b[1;0m - Request 16764 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89494 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:38,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 16769 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89481 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:38,759 - \u001b[1;33mWARNING\u001b[1;0m - Request 16752 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89452 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:53,741 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:53 2023\n",
      "2023-07-03 18:46:53,760 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:46:53 2023\n",
      "2023-07-03 18:46:53,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16764\n",
      "2023-07-03 18:46:53,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16792\n",
      "2023-07-03 18:46:54,592 - \u001b[1;33mWARNING\u001b[1;0m - Request 16797 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89895 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:46:54,605 - \u001b[1;33mWARNING\u001b[1;0m - Request 16781 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89894 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:09,597 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:09 2023\n",
      "2023-07-03 18:47:09,606 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:09 2023\n",
      "2023-07-03 18:47:09,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16810\n",
      "2023-07-03 18:47:09,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16830\n",
      "2023-07-03 18:47:09,979 - \u001b[1;33mWARNING\u001b[1;0m - Request 16821 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89458 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:10,005 - \u001b[1;33mWARNING\u001b[1;0m - Request 16837 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89413 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:10,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 16831 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:24,993 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:25 2023\n",
      "2023-07-03 18:47:25,081 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:25 2023\n",
      "2023-07-03 18:47:25,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16847\n",
      "2023-07-03 18:47:25,174 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16867\n",
      "2023-07-03 18:47:29,772 - \u001b[1;33mWARNING\u001b[1;0m - Request 16874 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89734 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:44,786 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:47:44 2023\n",
      "2023-07-03 18:47:44,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16886\n",
      "2023-07-03 18:47:44,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16906\n",
      "2023-07-03 18:47:45,041 - \u001b[1;33mWARNING\u001b[1;0m - Request 16906 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89409 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:45,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 16910 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:45,044 - \u001b[1;33mWARNING\u001b[1;0m - Request 16908 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89401 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:47:45,054 - \u001b[1;33mWARNING\u001b[1;0m - Request 16905 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89395 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:00,054 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:00 2023\n",
      "2023-07-03 18:48:00,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16922\n",
      "2023-07-03 18:48:00,309 - \u001b[1;33mWARNING\u001b[1;0m - Request 16940 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89895 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:00,315 - \u001b[1;33mWARNING\u001b[1;0m - Request 16938 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89886 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:48:15,325 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:15 2023\n",
      "2023-07-03 18:48:15,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16940\n",
      "2023-07-03 18:48:15,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16960\n",
      "2023-07-03 18:48:15,608 - \u001b[1;33mWARNING\u001b[1;0m - Request 16971 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89602 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:15,649 - \u001b[1;33mWARNING\u001b[1;0m - Request 16972 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89522 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:15,794 - \u001b[1;33mWARNING\u001b[1;0m - Request 16958 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89308 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:30,622 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:30 2023\n",
      "2023-07-03 18:48:30,795 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:30 2023\n",
      "2023-07-03 18:48:30,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16977\n",
      "2023-07-03 18:48:30,990 - \u001b[1;32mINFO\u001b[1;0m - Starting request #16997\n",
      "2023-07-03 18:48:31,153 - \u001b[1;33mWARNING\u001b[1;0m - Request 17001 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89592 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:31,156 - \u001b[1;33mWARNING\u001b[1;0m - Request 17002 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89587 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:46,167 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:48:46 2023\n",
      "2023-07-03 18:48:46,219 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17015\n",
      "2023-07-03 18:48:46,277 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17035\n",
      "2023-07-03 18:48:46,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 17035 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89660 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:48:46,680 - \u001b[1;33mWARNING\u001b[1;0m - Request 17033 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89659 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:01,684 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:01 2023\n",
      "2023-07-03 18:49:01,751 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17053\n",
      "2023-07-03 18:49:01,939 - \u001b[1;33mWARNING\u001b[1;0m - Request 17066 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89965 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:01,946 - \u001b[1;33mWARNING\u001b[1;0m - Request 17065 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89955 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:16,953 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:16 2023\n",
      "2023-07-03 18:49:16,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17071\n",
      "2023-07-03 18:49:17,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17091\n",
      "2023-07-03 18:49:17,211 - \u001b[1;33mWARNING\u001b[1;0m - Request 17099 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:17,218 - \u001b[1;33mWARNING\u001b[1;0m - Request 17096 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89505 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:17,266 - \u001b[1;33mWARNING\u001b[1;0m - Request 17084 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89458 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:32,224 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:32 2023\n",
      "2023-07-03 18:49:32,266 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:32 2023\n",
      "2023-07-03 18:49:32,304 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17108\n",
      "2023-07-03 18:49:32,363 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17128\n",
      "2023-07-03 18:49:32,530 - \u001b[1;33mWARNING\u001b[1;0m - Request 17130 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89804 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:32,689 - \u001b[1;33mWARNING\u001b[1;0m - Request 17104 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89562 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:47,545 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:47 2023\n",
      "2023-07-03 18:49:47,690 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:49:47 2023\n",
      "2023-07-03 18:49:47,748 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17146\n",
      "2023-07-03 18:49:47,946 - \u001b[1;33mWARNING\u001b[1;0m - Request 17151 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89269 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:49:47,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 17162 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89984 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:02,551 - \u001b[1;33mWARNING\u001b[1;0m - Request 17121 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3be25e58882b0aea9f81f5692b7a7373 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:50:02,948 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:02 2023\n",
      "2023-07-03 18:50:02,956 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:02 2023\n",
      "2023-07-03 18:50:02,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17121\n",
      "2023-07-03 18:50:03,031 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17183\n",
      "2023-07-03 18:50:03,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 17193 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89644 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:03,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 17185 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89640 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:03,217 - \u001b[1;33mWARNING\u001b[1;0m - Request 17186 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89627 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:13,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 16578 failed with Exception \n",
      "2023-07-03 18:50:18,215 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:18 2023\n",
      "2023-07-03 18:50:18,219 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:18 2023\n",
      "2023-07-03 18:50:18,251 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17199\n",
      "2023-07-03 18:50:18,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17219\n",
      "2023-07-03 18:50:22,038 - \u001b[1;33mWARNING\u001b[1;0m - Request 17214 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89663 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:22,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 17227 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89326 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:37,052 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:37 2023\n",
      "2023-07-03 18:50:37,759 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:37 2023\n",
      "2023-07-03 18:50:37,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17237\n",
      "2023-07-03 18:50:37,846 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17257\n",
      "2023-07-03 18:50:38,674 - \u001b[1;33mWARNING\u001b[1;0m - Request 17266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89415 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:53,686 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:50:53 2023\n",
      "2023-07-03 18:50:53,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17276\n",
      "2023-07-03 18:50:53,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17296\n",
      "2023-07-03 18:50:53,998 - \u001b[1;33mWARNING\u001b[1;0m - Request 17292 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:54,008 - \u001b[1;33mWARNING\u001b[1;0m - Request 17281 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89733 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:54,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 17290 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:54,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 17294 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89707 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:50:54,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 17299 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89630 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:09,012 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:09 2023\n",
      "2023-07-03 18:51:09,079 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:09 2023\n",
      "2023-07-03 18:51:09,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17311\n",
      "2023-07-03 18:51:09,381 - \u001b[1;33mWARNING\u001b[1;0m - Request 17324 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89948 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:09,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 17328 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89868 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:19,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 16707 failed with Exception \n",
      "2023-07-03 18:51:24,386 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:24 2023\n",
      "2023-07-03 18:51:24,434 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:24 2023\n",
      "2023-07-03 18:51:24,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17328\n",
      "2023-07-03 18:51:24,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17348\n",
      "2023-07-03 18:51:24,711 - \u001b[1;33mWARNING\u001b[1;0m - Request 17358 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89538 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:24,723 - \u001b[1;33mWARNING\u001b[1;0m - Request 17353 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89510 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:24,798 - \u001b[1;33mWARNING\u001b[1;0m - Request 17359 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89400 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:39,719 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:39 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:51:39,799 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:39 2023\n",
      "2023-07-03 18:51:39,828 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17365\n",
      "2023-07-03 18:51:39,888 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17385\n",
      "2023-07-03 18:51:40,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 17390 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89613 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:40,236 - \u001b[1;33mWARNING\u001b[1;0m - Request 17369 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:55,111 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:55 2023\n",
      "2023-07-03 18:51:55,237 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:51:55 2023\n",
      "2023-07-03 18:51:55,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17403\n",
      "2023-07-03 18:51:55,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17423\n",
      "2023-07-03 18:51:57,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 17396 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89745 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:51:57,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 17423 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89741 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:12,354 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:12 2023\n",
      "2023-07-03 18:52:12,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17441\n",
      "2023-07-03 18:52:13,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17461\n",
      "2023-07-03 18:52:16,982 - \u001b[1;33mWARNING\u001b[1;0m - Request 17461 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89862 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:17,240 - \u001b[1;33mWARNING\u001b[1;0m - Request 17465 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89467 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:17,298 - \u001b[1;33mWARNING\u001b[1;0m - Request 17467 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:31,997 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:32 2023\n",
      "2023-07-03 18:52:32,299 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:32 2023\n",
      "2023-07-03 18:52:32,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17478\n",
      "2023-07-03 18:52:32,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17498\n",
      "2023-07-03 18:52:32,779 - \u001b[1;33mWARNING\u001b[1;0m - Request 17497 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:32,790 - \u001b[1;33mWARNING\u001b[1;0m - Request 17499 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89468 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:32,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 17498 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89451 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:47,783 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:47 2023\n",
      "2023-07-03 18:52:47,803 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:52:47 2023\n",
      "2023-07-03 18:52:47,869 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17515\n",
      "2023-07-03 18:52:48,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 17528 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89390 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:52:48,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 17527 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:03,311 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:03 2023\n",
      "2023-07-03 18:53:03,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17533\n",
      "2023-07-03 18:53:03,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17553\n",
      "2023-07-03 18:53:03,808 - \u001b[1;33mWARNING\u001b[1;0m - Request 17562 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89316 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:03,823 - \u001b[1;33mWARNING\u001b[1;0m - Request 17564 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89303 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:03,825 - \u001b[1;33mWARNING\u001b[1;0m - Request 17559 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89308 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:18,811 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:18 2023\n",
      "2023-07-03 18:53:18,825 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:18 2023\n",
      "2023-07-03 18:53:18,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17570\n",
      "2023-07-03 18:53:18,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17590\n",
      "2023-07-03 18:53:19,273 - \u001b[1;33mWARNING\u001b[1;0m - Request 17580 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89343 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:19,304 - \u001b[1;33mWARNING\u001b[1;0m - Request 17589 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89302 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:53:34,289 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:34 2023\n",
      "2023-07-03 18:53:34,305 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:34 2023\n",
      "2023-07-03 18:53:34,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17608\n",
      "2023-07-03 18:53:34,570 - \u001b[1;33mWARNING\u001b[1;0m - Request 17627 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:34,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 17625 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89418 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:49,583 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:53:49 2023\n",
      "2023-07-03 18:53:49,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17628\n",
      "2023-07-03 18:53:49,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17646\n",
      "2023-07-03 18:53:49,850 - \u001b[1;33mWARNING\u001b[1;0m - Request 17655 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89696 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:53:49,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 17659 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89685 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:04,865 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:04 2023\n",
      "2023-07-03 18:54:04,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17664\n",
      "2023-07-03 18:54:04,955 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17684\n",
      "2023-07-03 18:54:05,254 - \u001b[1;33mWARNING\u001b[1;0m - Request 17679 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89671 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:05,318 - \u001b[1;33mWARNING\u001b[1;0m - Request 17661 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89583 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:05,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 17692 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89540 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:20,268 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:20 2023\n",
      "2023-07-03 18:54:20,337 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:20 2023\n",
      "2023-07-03 18:54:20,377 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17701\n",
      "2023-07-03 18:54:20,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17721\n",
      "2023-07-03 18:54:20,639 - \u001b[1;33mWARNING\u001b[1;0m - Request 17723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89763 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:20,853 - \u001b[1;33mWARNING\u001b[1;0m - Request 17679 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:35,653 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:35 2023\n",
      "2023-07-03 18:54:35,854 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:35 2023\n",
      "2023-07-03 18:54:35,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17739\n",
      "2023-07-03 18:54:36,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 17749 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89427 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:36,348 - \u001b[1;33mWARNING\u001b[1;0m - Request 17741 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89406 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:36,424 - \u001b[1;33mWARNING\u001b[1;0m - Request 17756 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:54:51,342 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:51 2023\n",
      "2023-07-03 18:54:51,424 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:54:51 2023\n",
      "2023-07-03 18:54:51,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17741\n",
      "2023-07-03 18:54:51,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17776\n",
      "2023-07-03 18:54:51,687 - \u001b[1;33mWARNING\u001b[1;0m - Request 17779 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89497 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:06,169 - \u001b[1;33mWARNING\u001b[1;0m - Request 17729 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 94475ec4fb77b48783ab922d405468a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:06,689 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:06 2023\n",
      "2023-07-03 18:55:06,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17794\n",
      "2023-07-03 18:55:06,791 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17814\n",
      "2023-07-03 18:55:06,959 - \u001b[1;33mWARNING\u001b[1;0m - Request 17818 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89720 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:07,184 - \u001b[1;33mWARNING\u001b[1;0m - Request 17817 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89384 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:07,190 - \u001b[1;33mWARNING\u001b[1;0m - Request 17806 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89377 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:55:21,973 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:22 2023\n",
      "2023-07-03 18:55:22,192 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:22 2023\n",
      "2023-07-03 18:55:22,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17831\n",
      "2023-07-03 18:55:22,448 - \u001b[1;33mWARNING\u001b[1;0m - Request 17849 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89547 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:22,457 - \u001b[1;33mWARNING\u001b[1;0m - Request 17848 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89537 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:37,449 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:37 2023\n",
      "2023-07-03 18:55:37,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17851\n",
      "2023-07-03 18:55:37,458 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:37 2023\n",
      "2023-07-03 18:55:37,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17869\n",
      "2023-07-03 18:55:37,740 - \u001b[1;33mWARNING\u001b[1;0m - Request 17872 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89667 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:52,746 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:55:52 2023\n",
      "2023-07-03 18:55:52,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17888\n",
      "2023-07-03 18:55:52,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17908\n",
      "2023-07-03 18:55:53,005 - \u001b[1;33mWARNING\u001b[1;0m - Request 17913 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:53,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 17914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89866 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:53,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 17907 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89847 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:55:53,151 - \u001b[1;33mWARNING\u001b[1;0m - Request 17916 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89654 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:07,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 17865 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 846fa6b75a1ee4ee57de12d5586c1986 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:08,006 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:08 2023\n",
      "2023-07-03 18:56:08,151 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:08 2023\n",
      "2023-07-03 18:56:08,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17923\n",
      "2023-07-03 18:56:08,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17943\n",
      "2023-07-03 18:56:08,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 17938 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89744 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:08,522 - \u001b[1;33mWARNING\u001b[1;0m - Request 17944 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89731 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:23,526 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:23 2023\n",
      "2023-07-03 18:56:23,600 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17961\n",
      "2023-07-03 18:56:23,879 - \u001b[1;33mWARNING\u001b[1;0m - Request 17975 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89649 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:23,885 - \u001b[1;33mWARNING\u001b[1;0m - Request 17973 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89642 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:38,893 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:38 2023\n",
      "2023-07-03 18:56:38,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17979\n",
      "2023-07-03 18:56:38,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #17999\n",
      "2023-07-03 18:56:39,171 - \u001b[1;33mWARNING\u001b[1;0m - Request 18009 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89736 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:39,180 - \u001b[1;33mWARNING\u001b[1;0m - Request 18007 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89721 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:54,177 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:54 2023\n",
      "2023-07-03 18:56:54,181 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:56:54 2023\n",
      "2023-07-03 18:56:54,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18017\n",
      "2023-07-03 18:56:54,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18037\n",
      "2023-07-03 18:56:54,444 - \u001b[1;33mWARNING\u001b[1;0m - Request 18040 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89855 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:54,449 - \u001b[1;33mWARNING\u001b[1;0m - Request 18041 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89848 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:56:54,556 - \u001b[1;33mWARNING\u001b[1;0m - Request 18042 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89695 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:57:09,459 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:09 2023\n",
      "2023-07-03 18:57:09,557 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:09 2023\n",
      "2023-07-03 18:57:09,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18054\n",
      "2023-07-03 18:57:10,011 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18074\n",
      "2023-07-03 18:57:13,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 18062 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89554 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:13,752 - \u001b[1;33mWARNING\u001b[1;0m - Request 18069 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89553 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:13,763 - \u001b[1;33mWARNING\u001b[1;0m - Request 18068 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89534 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:28,759 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:28 2023\n",
      "2023-07-03 18:57:28,764 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:28 2023\n",
      "2023-07-03 18:57:28,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18091\n",
      "2023-07-03 18:57:28,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18111\n",
      "2023-07-03 18:57:29,087 - \u001b[1;33mWARNING\u001b[1;0m - Request 18093 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89615 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:29,275 - \u001b[1;33mWARNING\u001b[1;0m - Request 18108 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89301 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:44,089 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:44 2023\n",
      "2023-07-03 18:57:44,277 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:44 2023\n",
      "2023-07-03 18:57:44,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18129\n",
      "2023-07-03 18:57:44,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 18145 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89357 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:44,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 18123 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89862 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:57:59,613 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:59 2023\n",
      "2023-07-03 18:57:59,730 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:57:59 2023\n",
      "2023-07-03 18:57:59,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18123\n",
      "2023-07-03 18:57:59,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18167\n",
      "2023-07-03 18:58:02,235 - \u001b[1;33mWARNING\u001b[1;0m - Request 18158 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:02,559 - \u001b[1;33mWARNING\u001b[1;0m - Request 18180 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89863 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:17,240 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:17 2023\n",
      "2023-07-03 18:58:17,561 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:17 2023\n",
      "2023-07-03 18:58:17,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18185\n",
      "2023-07-03 18:58:17,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18205\n",
      "2023-07-03 18:58:17,820 - \u001b[1;33mWARNING\u001b[1;0m - Request 18212 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89997 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:17,823 - \u001b[1;33mWARNING\u001b[1;0m - Request 18195 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89996 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:32,833 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:32 2023\n",
      "2023-07-03 18:58:32,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18223\n",
      "2023-07-03 18:58:32,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18243\n",
      "2023-07-03 18:58:33,093 - \u001b[1;33mWARNING\u001b[1;0m - Request 18247 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:33,094 - \u001b[1;33mWARNING\u001b[1;0m - Request 18246 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89290 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:33,097 - \u001b[1;33mWARNING\u001b[1;0m - Request 18227 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89305 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:33,099 - \u001b[1;33mWARNING\u001b[1;0m - Request 18248 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89292 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:48,108 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:58:48 2023\n",
      "2023-07-03 18:58:48,163 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18259\n",
      "2023-07-03 18:58:48,422 - \u001b[1;33mWARNING\u001b[1;0m - Request 18266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:58:48,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 18267 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89417 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:58:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 17652 failed with Exception \n",
      "2023-07-03 18:59:03,426 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:03 2023\n",
      "2023-07-03 18:59:03,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18279\n",
      "2023-07-03 18:59:03,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18296\n",
      "2023-07-03 18:59:03,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 18307 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89529 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:03,980 - \u001b[1;33mWARNING\u001b[1;0m - Request 18310 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89871 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:18,724 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:18 2023\n",
      "2023-07-03 18:59:18,982 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:18 2023\n",
      "2023-07-03 18:59:18,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18314\n",
      "2023-07-03 18:59:19,062 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18334\n",
      "2023-07-03 18:59:20,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 18345 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89592 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:20,654 - \u001b[1;33mWARNING\u001b[1;0m - Request 18316 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89287 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:35,465 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:35 2023\n",
      "2023-07-03 18:59:35,655 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:35 2023\n",
      "2023-07-03 18:59:35,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18352\n",
      "2023-07-03 18:59:35,747 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18372\n",
      "2023-07-03 18:59:35,931 - \u001b[1;33mWARNING\u001b[1;0m - Request 18373 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89431 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:35,935 - \u001b[1;33mWARNING\u001b[1;0m - Request 18377 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89436 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:50,943 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 18:59:50 2023\n",
      "2023-07-03 18:59:50,996 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18390\n",
      "2023-07-03 18:59:51,161 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18410\n",
      "2023-07-03 18:59:51,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 18409 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89507 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:51,228 - \u001b[1;33mWARNING\u001b[1;0m - Request 18403 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89475 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:51,284 - \u001b[1;33mWARNING\u001b[1;0m - Request 18402 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89393 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 18:59:51,314 - \u001b[1;33mWARNING\u001b[1;0m - Request 18410 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89343 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:06,220 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:06 2023\n",
      "2023-07-03 19:00:06,315 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:06 2023\n",
      "2023-07-03 19:00:06,383 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18426\n",
      "2023-07-03 19:00:09,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18446\n",
      "2023-07-03 19:00:10,620 - \u001b[1;33mWARNING\u001b[1;0m - Request 18424 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89899 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:10,905 - \u001b[1;33mWARNING\u001b[1;0m - Request 18429 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89484 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:25,635 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:25 2023\n",
      "2023-07-03 19:00:25,906 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:25 2023\n",
      "2023-07-03 19:00:25,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18464\n",
      "2023-07-03 19:00:26,237 - \u001b[1;33mWARNING\u001b[1;0m - Request 18482 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89324 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:26,477 - \u001b[1;33mWARNING\u001b[1;0m - Request 18429 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89681 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:38,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 17877 failed with Exception \n",
      "2023-07-03 19:00:41,241 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:41 2023\n",
      "2023-07-03 19:00:41,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:41 2023\n",
      "2023-07-03 19:00:41,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18482\n",
      "2023-07-03 19:00:41,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18501\n",
      "2023-07-03 19:00:42,318 - \u001b[1;33mWARNING\u001b[1;0m - Request 18501 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89617 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:42,327 - \u001b[1;33mWARNING\u001b[1;0m - Request 18486 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89612 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:00:42,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 18506 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89419 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:00:57,327 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:57 2023\n",
      "2023-07-03 19:00:57,452 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:00:57 2023\n",
      "2023-07-03 19:00:57,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18518\n",
      "2023-07-03 19:00:57,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18538\n",
      "2023-07-03 19:00:58,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 18544 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89548 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:13,077 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:13 2023\n",
      "2023-07-03 19:01:13,112 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18557\n",
      "2023-07-03 19:01:13,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18577\n",
      "2023-07-03 19:01:13,397 - \u001b[1;33mWARNING\u001b[1;0m - Request 18580 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89422 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:13,406 - \u001b[1;33mWARNING\u001b[1;0m - Request 18581 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89407 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:13,412 - \u001b[1;33mWARNING\u001b[1;0m - Request 18567 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89412 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:28,410 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:28 2023\n",
      "2023-07-03 19:01:28,413 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:28 2023\n",
      "2023-07-03 19:01:28,465 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18594\n",
      "2023-07-03 19:01:28,692 - \u001b[1;33mWARNING\u001b[1;0m - Request 18609 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89450 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:28,696 - \u001b[1;33mWARNING\u001b[1;0m - Request 18596 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89447 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:28,805 - \u001b[1;33mWARNING\u001b[1;0m - Request 18585 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89301 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:43,700 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:43 2023\n",
      "2023-07-03 19:01:43,807 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:43 2023\n",
      "2023-07-03 19:01:43,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18609\n",
      "2023-07-03 19:01:43,873 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18631\n",
      "2023-07-03 19:01:44,121 - \u001b[1;33mWARNING\u001b[1;0m - Request 18640 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89306 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:44,121 - \u001b[1;33mWARNING\u001b[1;0m - Request 18636 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89305 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:59,136 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:01:59 2023\n",
      "2023-07-03 19:01:59,158 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18649\n",
      "2023-07-03 19:01:59,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18669\n",
      "2023-07-03 19:01:59,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 18675 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89821 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:01:59,441 - \u001b[1;33mWARNING\u001b[1;0m - Request 18676 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89839 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:14,449 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:14 2023\n",
      "2023-07-03 19:02:14,492 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18687\n",
      "2023-07-03 19:02:14,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18707\n",
      "2023-07-03 19:02:14,722 - \u001b[1;33mWARNING\u001b[1;0m - Request 18708 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89720 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:14,760 - \u001b[1;33mWARNING\u001b[1;0m - Request 18699 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89673 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:14,815 - \u001b[1;33mWARNING\u001b[1;0m - Request 18709 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89579 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:29,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 18089 failed with Exception \n",
      "2023-07-03 19:02:29,724 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:29 2023\n",
      "2023-07-03 19:02:29,817 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:29 2023\n",
      "2023-07-03 19:02:29,871 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18723\n",
      "2023-07-03 19:02:30,067 - \u001b[1;33mWARNING\u001b[1;0m - Request 18739 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89519 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:30,079 - \u001b[1;33mWARNING\u001b[1;0m - Request 18738 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89512 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:02:45,075 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:45 2023\n",
      "2023-07-03 19:02:45,080 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:02:45 2023\n",
      "2023-07-03 19:02:45,087 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18741\n",
      "2023-07-03 19:02:45,157 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18761\n",
      "2023-07-03 19:02:45,339 - \u001b[1;33mWARNING\u001b[1;0m - Request 18771 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:02:45,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 18769 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89382 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:00,354 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:00 2023\n",
      "2023-07-03 19:03:00,359 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:00 2023\n",
      "2023-07-03 19:03:00,393 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18779\n",
      "2023-07-03 19:03:00,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18799\n",
      "2023-07-03 19:03:00,619 - \u001b[1;33mWARNING\u001b[1;0m - Request 18802 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89911 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:00,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 18804 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89872 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:15,634 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:15 2023\n",
      "2023-07-03 19:03:15,644 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:15 2023\n",
      "2023-07-03 19:03:15,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18817\n",
      "2023-07-03 19:03:16,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18837\n",
      "2023-07-03 19:03:16,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 18832 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89642 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:16,127 - \u001b[1;33mWARNING\u001b[1;0m - Request 18826 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89636 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:16,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 18837 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:31,136 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:31 2023\n",
      "2023-07-03 19:03:31,187 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:31 2023\n",
      "2023-07-03 19:03:31,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18854\n",
      "2023-07-03 19:03:31,678 - \u001b[1;33mWARNING\u001b[1;0m - Request 18863 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89582 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:31,688 - \u001b[1;33mWARNING\u001b[1;0m - Request 18862 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89567 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:46,692 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:03:46 2023\n",
      "2023-07-03 19:03:46,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18872\n",
      "2023-07-03 19:03:46,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18892\n",
      "2023-07-03 19:03:46,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 18897 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89362 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:03:47,136 - \u001b[1;33mWARNING\u001b[1;0m - Request 18883 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89868 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:01,971 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:02 2023\n",
      "2023-07-03 19:04:02,137 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:02 2023\n",
      "2023-07-03 19:04:02,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18910\n",
      "2023-07-03 19:04:02,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18930\n",
      "2023-07-03 19:04:02,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 18932 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89600 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:02,615 - \u001b[1;33mWARNING\u001b[1;0m - Request 18925 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:02,616 - \u001b[1;33mWARNING\u001b[1;0m - Request 18929 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89368 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:17,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:17 2023\n",
      "2023-07-03 19:04:17,617 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:17 2023\n",
      "2023-07-03 19:04:17,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18947\n",
      "2023-07-03 19:04:19,547 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18967\n",
      "2023-07-03 19:04:21,043 - \u001b[1;33mWARNING\u001b[1;0m - Request 18970 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89556 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:21,071 - \u001b[1;33mWARNING\u001b[1;0m - Request 18964 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89507 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:04:21,077 - \u001b[1;33mWARNING\u001b[1;0m - Request 18960 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89502 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:36,058 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:36 2023\n",
      "2023-07-03 19:04:36,078 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:36 2023\n",
      "2023-07-03 19:04:36,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #18984\n",
      "2023-07-03 19:04:37,218 - \u001b[1;33mWARNING\u001b[1;0m - Request 18997 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89387 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:37,288 - \u001b[1;33mWARNING\u001b[1;0m - Request 19001 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89297 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:52,232 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:52 2023\n",
      "2023-07-03 19:04:52,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19004\n",
      "2023-07-03 19:04:52,289 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:04:52 2023\n",
      "2023-07-03 19:04:52,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19022\n",
      "2023-07-03 19:04:55,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19042\n",
      "2023-07-03 19:04:57,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 19038 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:04:57,733 - \u001b[1;33mWARNING\u001b[1;0m - Request 19044 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89339 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:12,721 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:12 2023\n",
      "2023-07-03 19:05:12,736 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:12 2023\n",
      "2023-07-03 19:05:12,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19060\n",
      "2023-07-03 19:05:13,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 19071 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89487 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:13,215 - \u001b[1;33mWARNING\u001b[1;0m - Request 19073 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89479 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:13,487 - \u001b[1;33mWARNING\u001b[1;0m - Request 19078 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89814 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:28,217 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:28 2023\n",
      "2023-07-03 19:05:28,489 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:28 2023\n",
      "2023-07-03 19:05:28,489 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19071\n",
      "2023-07-03 19:05:28,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19097\n",
      "2023-07-03 19:05:28,982 - \u001b[1;33mWARNING\u001b[1;0m - Request 19107 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89920 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:28,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 19109 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89920 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:29,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 19110 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89811 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:43,995 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:44 2023\n",
      "2023-07-03 19:05:44,063 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:44 2023\n",
      "2023-07-03 19:05:44,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19114\n",
      "2023-07-03 19:05:44,142 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19134\n",
      "2023-07-03 19:05:44,549 - \u001b[1;33mWARNING\u001b[1;0m - Request 19138 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89887 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:44,555 - \u001b[1;33mWARNING\u001b[1;0m - Request 19139 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89876 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:05:59,551 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:59 2023\n",
      "2023-07-03 19:05:59,556 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:05:59 2023\n",
      "2023-07-03 19:05:59,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19152\n",
      "2023-07-03 19:05:59,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19172\n",
      "2023-07-03 19:06:00,714 - \u001b[1;33mWARNING\u001b[1;0m - Request 19166 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89743 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:00,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 19175 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89699 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:00,845 - \u001b[1;33mWARNING\u001b[1;0m - Request 19173 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:15,723 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:15 2023\n",
      "2023-07-03 19:06:15,846 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:15 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:06:15,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19189\n",
      "2023-07-03 19:06:16,182 - \u001b[1;33mWARNING\u001b[1;0m - Request 19206 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89284 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:16,529 - \u001b[1;33mWARNING\u001b[1;0m - Request 19173 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89468 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:31,190 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:31 2023\n",
      "2023-07-03 19:06:31,530 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:31 2023\n",
      "2023-07-03 19:06:31,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19173\n",
      "2023-07-03 19:06:31,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19227\n",
      "2023-07-03 19:06:32,016 - \u001b[1;33mWARNING\u001b[1;0m - Request 19235 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89477 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:32,025 - \u001b[1;33mWARNING\u001b[1;0m - Request 19234 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89473 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:47,023 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:47 2023\n",
      "2023-07-03 19:06:47,026 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:06:47 2023\n",
      "2023-07-03 19:06:47,056 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19245\n",
      "2023-07-03 19:06:47,122 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19265\n",
      "2023-07-03 19:06:47,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 19271 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89727 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:47,530 - \u001b[1;33mWARNING\u001b[1;0m - Request 19266 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89516 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:06:47,538 - \u001b[1;33mWARNING\u001b[1;0m - Request 19270 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89495 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:02,393 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:02 2023\n",
      "2023-07-03 19:07:02,539 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:02 2023\n",
      "2023-07-03 19:07:02,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19282\n",
      "2023-07-03 19:07:02,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19302\n",
      "2023-07-03 19:07:07,030 - \u001b[1;33mWARNING\u001b[1;0m - Request 19306 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:07,033 - \u001b[1;33mWARNING\u001b[1;0m - Request 19270 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89420 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:07,036 - \u001b[1;33mWARNING\u001b[1;0m - Request 19288 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89416 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:22,033 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:22 2023\n",
      "2023-07-03 19:07:22,038 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:22 2023\n",
      "2023-07-03 19:07:22,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19319\n",
      "2023-07-03 19:07:22,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19339\n",
      "2023-07-03 19:07:22,314 - \u001b[1;33mWARNING\u001b[1;0m - Request 19340 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89770 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:22,317 - \u001b[1;33mWARNING\u001b[1;0m - Request 19341 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89757 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:37,317 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:37 2023\n",
      "2023-07-03 19:07:37,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19357\n",
      "2023-07-03 19:07:37,659 - \u001b[1;33mWARNING\u001b[1;0m - Request 19372 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89468 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:37,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 19360 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89455 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:52,670 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:07:52 2023\n",
      "2023-07-03 19:07:52,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19360\n",
      "2023-07-03 19:07:52,855 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19395\n",
      "2023-07-03 19:07:53,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 19399 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89765 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:53,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 19400 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89764 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:07:53,093 - \u001b[1;33mWARNING\u001b[1;0m - Request 19403 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:08:08,065 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:08 2023\n",
      "2023-07-03 19:08:08,095 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:08 2023\n",
      "2023-07-03 19:08:08,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19412\n",
      "2023-07-03 19:08:08,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19432\n",
      "2023-07-03 19:08:08,369 - \u001b[1;33mWARNING\u001b[1;0m - Request 19436 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89491 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:08,403 - \u001b[1;33mWARNING\u001b[1;0m - Request 19428 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89454 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:08,489 - \u001b[1;33mWARNING\u001b[1;0m - Request 19437 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89311 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:23,383 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:23 2023\n",
      "2023-07-03 19:08:23,490 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:23 2023\n",
      "2023-07-03 19:08:23,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19449\n",
      "2023-07-03 19:08:23,766 - \u001b[1;33mWARNING\u001b[1;0m - Request 19459 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89801 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:23,911 - \u001b[1;33mWARNING\u001b[1;0m - Request 19468 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89583 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:38,779 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:38 2023\n",
      "2023-07-03 19:08:38,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19469\n",
      "2023-07-03 19:08:38,913 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:38 2023\n",
      "2023-07-03 19:08:38,981 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19487\n",
      "2023-07-03 19:08:39,204 - \u001b[1;33mWARNING\u001b[1;0m - Request 19494 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:39,365 - \u001b[1;33mWARNING\u001b[1;0m - Request 19500 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89822 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:54,216 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:54 2023\n",
      "2023-07-03 19:08:54,366 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:08:54 2023\n",
      "2023-07-03 19:08:54,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19505\n",
      "2023-07-03 19:08:54,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19525\n",
      "2023-07-03 19:08:54,668 - \u001b[1;33mWARNING\u001b[1;0m - Request 19530 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89494 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:08:54,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 19532 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89390 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:09,684 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:09 2023\n",
      "2023-07-03 19:09:09,730 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:09 2023\n",
      "2023-07-03 19:09:09,774 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19543\n",
      "2023-07-03 19:09:09,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19563\n",
      "2023-07-03 19:09:09,986 - \u001b[1;33mWARNING\u001b[1;0m - Request 19563 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89923 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:10,006 - \u001b[1;33mWARNING\u001b[1;0m - Request 19559 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89920 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:24,999 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:25 2023\n",
      "2023-07-03 19:09:25,007 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:25 2023\n",
      "2023-07-03 19:09:25,073 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19581\n",
      "2023-07-03 19:09:25,261 - \u001b[1;33mWARNING\u001b[1;0m - Request 19595 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89717 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:25,263 - \u001b[1;33mWARNING\u001b[1;0m - Request 19592 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89708 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:25,278 - \u001b[1;33mWARNING\u001b[1;0m - Request 19594 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89705 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:40,271 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:40 2023\n",
      "2023-07-03 19:09:40,279 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:40 2023\n",
      "2023-07-03 19:09:40,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19598\n",
      "2023-07-03 19:09:40,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19618\n",
      "2023-07-03 19:09:40,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 19621 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89391 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:09:40,611 - \u001b[1;33mWARNING\u001b[1;0m - Request 19626 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89354 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:09:55,598 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:55 2023\n",
      "2023-07-03 19:09:55,612 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:09:55 2023\n",
      "2023-07-03 19:09:55,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19636\n",
      "2023-07-03 19:09:55,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19656\n",
      "2023-07-03 19:09:57,634 - \u001b[1;33mWARNING\u001b[1;0m - Request 19638 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89278 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:12,648 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:12 2023\n",
      "2023-07-03 19:10:12,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19675\n",
      "2023-07-03 19:10:12,905 - \u001b[1;33mWARNING\u001b[1;0m - Request 19693 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89675 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:12,907 - \u001b[1;33mWARNING\u001b[1;0m - Request 19683 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89676 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:12,921 - \u001b[1;33mWARNING\u001b[1;0m - Request 19677 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89660 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:12,959 - \u001b[1;33mWARNING\u001b[1;0m - Request 19686 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89599 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:27,918 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:27 2023\n",
      "2023-07-03 19:10:27,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19695\n",
      "2023-07-03 19:10:27,960 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:27 2023\n",
      "2023-07-03 19:10:28,031 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19711\n",
      "2023-07-03 19:10:28,220 - \u001b[1;33mWARNING\u001b[1;0m - Request 19722 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89312 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:28,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 19724 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89299 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:28,227 - \u001b[1;33mWARNING\u001b[1;0m - Request 19723 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89294 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:43,235 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:43 2023\n",
      "2023-07-03 19:10:43,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19728\n",
      "2023-07-03 19:10:43,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19748\n",
      "2023-07-03 19:10:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 19754 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89817 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:43,524 - \u001b[1;33mWARNING\u001b[1;0m - Request 19752 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89774 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:10:58,495 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:58 2023\n",
      "2023-07-03 19:10:58,525 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:10:58 2023\n",
      "2023-07-03 19:10:58,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19766\n",
      "2023-07-03 19:10:58,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19786\n",
      "2023-07-03 19:11:01,522 - \u001b[1;33mWARNING\u001b[1;0m - Request 19793 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89656 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:01,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 19754 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89728 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:16,537 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:16 2023\n",
      "2023-07-03 19:11:16,964 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:16 2023\n",
      "2023-07-03 19:11:17,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19804\n",
      "2023-07-03 19:11:17,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19824\n",
      "2023-07-03 19:11:17,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 19820 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89339 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:17,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 19826 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89268 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:17,476 - \u001b[1;33mWARNING\u001b[1;0m - Request 19824 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89673 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:32,238 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:32 2023\n",
      "2023-07-03 19:11:32,478 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:32 2023\n",
      "2023-07-03 19:11:32,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19841\n",
      "2023-07-03 19:11:32,978 - \u001b[1;33mWARNING\u001b[1;0m - Request 19856 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89684 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:33,012 - \u001b[1;33mWARNING\u001b[1;0m - Request 19854 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89670 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:11:33,104 - \u001b[1;33mWARNING\u001b[1;0m - Request 19858 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89501 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:47,980 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:48 2023\n",
      "2023-07-03 19:11:48,105 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:11:48 2023\n",
      "2023-07-03 19:11:48,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19854\n",
      "2023-07-03 19:11:48,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19878\n",
      "2023-07-03 19:11:48,678 - \u001b[1;33mWARNING\u001b[1;0m - Request 19865 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89505 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:11:48,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 19889 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89408 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:03,691 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:03 2023\n",
      "2023-07-03 19:12:03,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19896\n",
      "2023-07-03 19:12:03,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19916\n",
      "2023-07-03 19:12:03,998 - \u001b[1;33mWARNING\u001b[1;0m - Request 19914 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89725 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:04,190 - \u001b[1;33mWARNING\u001b[1;0m - Request 19919 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89424 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:19,001 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:19 2023\n",
      "2023-07-03 19:12:19,191 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:19 2023\n",
      "2023-07-03 19:12:19,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19934\n",
      "2023-07-03 19:12:19,488 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19954\n",
      "2023-07-03 19:12:19,637 - \u001b[1;33mWARNING\u001b[1;0m - Request 19954 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89599 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:19,683 - \u001b[1;33mWARNING\u001b[1;0m - Request 19952 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89533 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:19,800 - \u001b[1;33mWARNING\u001b[1;0m - Request 19932 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89395 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:34,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 19917 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1bd31bcb9d2e3ba77eb7f415c41aae28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:34,639 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:34 2023\n",
      "2023-07-03 19:12:34,801 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:34 2023\n",
      "2023-07-03 19:12:34,862 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19970\n",
      "2023-07-03 19:12:35,102 - \u001b[1;33mWARNING\u001b[1;0m - Request 19981 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89713 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:35,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 19973 failed with error {'message': 'Rate limit reached for default-gpt-3.5-turbo in organization org-e6MEFBhPk9Kw8Z0GQH3hniqD on tokens per min. Limit: 90000 / min. Current: 89418 / min. Contact us through our help center at help.openai.com if you continue to have issues.', 'type': 'tokens', 'param': None, 'code': None}\n",
      "2023-07-03 19:12:50,112 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:50 2023\n",
      "2023-07-03 19:12:50,286 - \u001b[1;33mWARNING\u001b[1;0m - Pausing to cool down until Mon Jul  3 19:12:50 2023\n",
      "2023-07-03 19:12:50,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #19988\n",
      "2023-07-03 19:13:08,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 19434 failed with Exception \n",
      "2023-07-03 19:14:40,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 19610 failed with Exception \n",
      "2023-07-03 19:14:42,061 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_163148.jsonl\n",
      "2023-07-03 19:14:42,061 - \u001b[1;33mWARNING\u001b[1;0m - 1463 rate limit errors received. Consider running at a lower rate.\n",
      "2023-07-03 19:14:42,066 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230703_163148.jsonl\n",
      "2023-07-03 19:14:42,787 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure I understand your question. Could you please provide more context or clarify what you mean by \"Contents versus is some a\"?, returning []\n",
      "2023-07-03 19:14:42,788 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"discussed with Dr. 19:54.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,790 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"discussed with Hung at .\". Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,790 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... \"stop\"}], \"usage\": {\"prompt_tokens\": 387, \"completion_tokens\": 18, \"total_tokens\": 405}}, {\"sentence\": \"No new parenchymal opacities have go-cart.\"}] for sentence \"No new parenchymal opacities have go-cart.\": Expecting ',' delimiter: line 3 column 1 (char 33)\n",
      "2023-07-03 19:14:42,790 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're asking. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,791 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Occurrence into .\". Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"with NP- at on.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I'm not sure what you mean by \"Assigned for.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're referring to with \"at 3:13pm on .\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... other questions.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 376, \"completion_tokens\": 12, \"total_tokens\": 388}}, {\"sentence\": \"Stop.\"}] for sentence \"Stop.\": Could not parse output: Sure, let me know if you have any other questions.\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your response. Could you please provide the sentence from the chest x-ray report?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're trying to say. Could you please provide more information or clarify your statement?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"23:49\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"in ris.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"CONCUSION.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"demonstrated.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"P.S.\" Could you please clarify or provide more information?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"9PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Ref.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"23:51.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,794 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Here are the relevant facts extracted from the given examples:\n",
      "\n",
      "1. Example 1:\n",
      "   - Fact 1: \"opacity in the right lobe\"\n",
      "   - Fact 2: \"density in the right lobe\"\n",
      "\n",
      "2. Example 2:\n",
      "   - Fact 1: \"well inflated lungs\"\n",
      "   - Fact 2: \"lungs without evidence of focal airspace consolidation\"\n",
      "   - Fact 3: \"lungs without evidence of pneumonia\"\n",
      "\n",
      "3. Example 3:\n",
      "   - Fact 1: \"worsening of CHF\"\n",
      "   - Fact 2: \"new or significantly increased left pleural effusions\"\n",
      "   - Fact 3: \"new or significantly increased right pleural effusions\"\n",
      "   - Fact 4: \"underlying bibasilar collapse on the left\"\n",
      "   - Fact 5: \"underlying consolidation on the left\"\n",
      "\n",
      "4. Example 4:\n",
      "   - Fact 1: \"no acute cardiopulmonary abnormality\"\n",
      "\n",
      "Please let me know if you have any further questions., returning []\n",
      "2023-07-03 19:14:42,795 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for any confusion. Can you please clarify what specifically you are confused about?, returning []\n",
      "2023-07-03 19:14:42,795 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your response. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,795 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"21:01.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,795 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"538pm.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,795 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"9:10PM.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,796 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure I understand what you mean by \"dependent on intention where to place the line\". Could you please provide more information or clarify your statement?, returning []\n",
      "2023-07-03 19:14:42,804 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... in weeks after treatment was communicated to by by telephone at 4:37 p.m. on after attending radiologist review per attending radiologist request.\"}] for sentence \"FINAL ADDENDUM Attending radiologist recommendation for follow-up imaging to resolution of right lower lobe pneumonia in weeks after treatment was communicated to by by telephone at 4:37 p.m. on after attending radiologist review per attending radiologist request.\": Expecting value: line 3 column 1 (char 67)\n",
      "2023-07-03 19:14:42,806 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... explanation could be that the patient during the latest examination interval was mostly located on the right side explaining gravitational forces.\"}] for sentence \"An explanation could be that the patient during the latest examination interval was mostly located on the right side explaining gravitational forces.\": Could not parse output: Based on the given explanation, it seems that the relevant fact is:\n",
      "\n",
      "- Patient was mostly located on the right side during the latest examination interval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:14:42,808 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to understand your input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,815 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"5:16 PM d chest is.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,821 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to review or analyze medical reports. My purpose is to assist with generating relevant facts from sentences. If you have any specific sentences from the report that you would like me to extract facts from, please provide them and I will be happy to help., returning []\n",
      "2023-07-03 19:14:42,823 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...n\": \"stop\"}], \"usage\": {\"prompt_tokens\": 382, \"completion_tokens\": 14, \"total_tokens\": 396}}, {\"sentence\": \"Team is aware at time of communication.\"}] for sentence \"Team is aware at time of communication.\": Could not parse output: Thank you for letting us know. How can I assist you today?\n",
      "2023-07-03 19:14:42,823 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sure, I can do that. Please provide the sentence from the chest x-ray report that you would like me to extract relevant facts from., returning []\n",
      "2023-07-03 19:14:42,824 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... to ask.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 377, \"completion_tokens\": 22, \"total_tokens\": 399}}, {\"sentence\": \"Team informed.\"}] for sentence \"Team informed.\": Could not parse output: Thank you for letting us know. If you have any questions or need further assistance, feel free to ask.\n",
      "2023-07-03 19:14:42,824 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 384, \"completion_tokens\": 11, \"total_tokens\": 395}}, {\"sentence\": \"ptx, please do at 5PM.\"}] for sentence \"ptx, please do at 5PM.\": Could not parse output: Sure, I will do it at 5PM.\n",
      "2023-07-03 19:14:42,830 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ason\": \"length\"}], \"usage\": {\"prompt_tokens\": 383, \"completion_tokens\": 256, \"total_tokens\": 639}}, {\"sentence\": \"RECOMMEND FOLLOWUP TO RESOLUTION.\"}] for sentence \"RECOMMEND FOLLOWUP TO RESOLUTION.\": Could not parse output: Based on the provided examples, it seems that the task is to extract relevant facts from a chest x-ray report. The extracted facts can be used for further analysis or to recommend appropriate follow-up actions based on the observations made in the report.\n",
      "\n",
      "To generate the JSON list of relevant facts, you can use natural language processing techniques such as sentence parsing and keyword extraction. Here is a possible approach to implement this task:\n",
      "\n",
      "1. Preprocess the input sentence: Remove any unnecessary punctuation and convert the sentence to lowercase for easier processing.\n",
      "\n",
      "2. Identify the anatomical location: Look for keywords or phrases that indicate the anatomical location mentioned in the sentence. This can include terms like \"right lobe\", \"left pleural effusion\", or \"bibasilar collapse\". Extract and store the anatomical location for each fact.\n",
      "\n",
      "3. Identify the observations: Look for keywords or phrases that indicate observations or abnormalities mentioned in the sentence. This can include terms like \"opacity\", \"density\", \"well inflated lungs\", or \"focal airspace consolidation\". Extract and store each observation as a separate fact.\n",
      "\n",
      "4. Generate the JSON list: Create a JSON list of relevant facts, where each fact includes the anatomical location and the observation. Return this JSON list as the output.\n",
      "\n",
      "Here is a Python\n",
      "2023-07-03 19:14:42,831 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...evant facts.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 378, \"completion_tokens\": 30, \"total_tokens\": 408}}, {\"sentence\": \"ok to use.\"}] for sentence \"ok to use.\": Could not parse output: Great! Let's start by defining a function called \"extract_facts\" that takes a sentence as input and returns a JSON list of relevant facts.\n",
      "2023-07-03 19:14:42,837 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to provide medical advice or recommendations. It's best to consult with a healthcare professional for clinical correlation and guidance regarding point tenderness/acuity., returning []\n",
      "2023-07-03 19:14:42,840 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, but I'm not able to generate a response based on the input you provided., returning []\n",
      "2023-07-03 19:14:42,843 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"AT 22:56.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,846 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to correlate the given sentence with prior imaging/history. My task is to generate a JSON list of relevant facts based on the sentence provided., returning []\n",
      "2023-07-03 19:14:42,846 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to correlate the extracted facts with lab values. My task is to extract relevant facts from the given sentence., returning []\n",
      "2023-07-03 19:14:42,853 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Comparison 2, 14:11.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your response. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not familiar with RISweb. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide the sentence from the chest x-ray report?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Dx.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"HH.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"w/r\". Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"23:48\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"20:03.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"20:21\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"23:52.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,860 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ion_tokens\": 15, \"total_tokens\": 406}}, {\"sentence\": \"Please note the patient is weeks pregnant and consent provided prior to performing the x-ray.\"}] for sentence \"Please note the patient is weeks pregnant and consent provided prior to performing the x-ray.\": Could not parse output: This information does not provide any relevant facts about the chest x-ray report.\n",
      "2023-07-03 19:14:42,860 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"23:05.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,861 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"A.m.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,862 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate a response without any input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,863 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate a JSON list of relevant facts for you. My capabilities are limited to providing information and answering questions. Is there anything specific you would like to know about chest x-ray reports?, returning []\n",
      "2023-07-03 19:14:42,864 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"C. Hostage p 23:37.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:42,868 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...mpt_tokens\": 389, \"completion_tokens\": 14, \"total_tokens\": 403}}, {\"sentence\": \"The findings are to substantial to treat them as atelectasis chole.\"}] for sentence \"The findings are to substantial to treat them as atelectasis chole.\": Expecting ',' delimiter: line 3 column 1 (char 25)\n",
      "2023-07-03 19:14:42,869 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the inconvenience. If you have any other questions or need assistance with anything else, please let me know., returning []\n",
      "2023-07-03 19:14:42,873 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to take any immediate action. I can only provide information and answer questions. Is there something specific you would like to know or discuss?, returning []\n",
      "2023-07-03 19:14:42,875 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...\": {\"prompt_tokens\": 384, \"completion_tokens\": 10, \"total_tokens\": 394}}, {\"sentence\": \"Does this patient have any history of injected substances?.\"}] for sentence \"Does this patient have any history of injected substances?.\": Could not parse output: No relevant facts are mentioned in the given sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:14:43,041 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to assist with that request., returning []\n",
      "2023-07-03 19:14:43,047 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to generate facts from a procedure report. My capabilities are limited to generating facts from the given sentence., returning []\n",
      "2023-07-03 19:14:43,056 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate a response to that request., returning []\n",
      "2023-07-03 19:14:43,057 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ens\": 394, \"completion_tokens\": 5, \"total_tokens\": 399}}, {\"sentence\": \"on the telephone on at 01:00 AM, 1 minutes after discovery of the findings.\"}] for sentence \"on the telephone on at 01:00 AM, 1 minutes after discovery of the findings.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:14:43,057 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can't assist with that., returning []\n",
      "2023-07-03 19:14:43,058 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"by Dr telephone at 11:30pm.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,059 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am specifically trained to generate relevant facts from chest x-ray reports. I am not able to correlate with mammography., returning []\n",
      "2023-07-03 19:14:43,059 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, but I'm not able to generate that response., returning []\n",
      "2023-07-03 19:14:43,062 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...n\": \"stop\"}], \"usage\": {\"prompt_tokens\": 381, \"completion_tokens\": 62, \"total_tokens\": 443}}, {\"sentence\": \"Please assess clinical appropriateness.\"}] for sentence \"Please assess clinical appropriateness.\": Could not parse output: The solution correctly extracts relevant facts from the given sentences. It identifies the observations mentioned in the sentences and includes the anatomical location where each observation was made. The solution handles sentences with multiple observations and negations appropriately. Overall, the solution appears to be clinically appropriate for extracting relevant facts from chest x-ray reports.\n",
      "2023-07-03 19:14:43,065 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Comparison 2, 00:09.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"23:00.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"19:47.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"23:02.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"W/r .\". Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"23:46.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"20:56\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"22:57\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"22:15\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"19:50.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"23:17\". Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,070 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"18:42.\" Could you please provide more context or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,071 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to assist with that request., returning []\n",
      "2023-07-03 19:14:43,071 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to understand your input. Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,071 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...nish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 386, \"completion_tokens\": 14, \"total_tokens\": 400}}, {\"sentence\": \"dw Dr. by at 8p on via phone.\"}] for sentence \"dw Dr. by at 8p on via phone.\": Could not parse output: Sure, I'm here to help. How can I assist you?\n",
      "2023-07-03 19:14:43,072 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to provide clinical correlation. My function is to generate a JSON list of relevant facts based on the given sentence from a chest x-ray report. If you have any specific questions or need assistance with generating the relevant facts, please let me know and I'll be happy to help., returning []\n",
      "2023-07-03 19:14:43,077 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...slightly more pronounced and does reassessment of the patient in 4 weeks for documentation of improvement/resolution of those findings is required.\"}] for sentence \"As compared to the chest radiograph from via opacities are slightly more pronounced and does reassessment of the patient in 4 weeks for documentation of improvement/resolution of those findings is required.\": Expecting ',' delimiter: line 3 column 1 (char 39)\n",
      "2023-07-03 19:14:43,081 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am an AI language model and I am not capable of performing tasks at specific times. Is there anything else I can help you with?, returning []\n",
      "2023-07-03 19:14:43,082 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Wetread entered in CCC by.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,083 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 386, \"completion_tokens\": 5, \"total_tokens\": 391}}, {\"sentence\": \"d/w dr. at 9pm on via tel.\"}] for sentence \"d/w dr. at 9pm on via tel.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:14:43,086 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to correlate the given chest x-ray report with a CT abd/pelvis. My task is to generate a JSON list of relevant facts based on the information provided in the chest x-ray report. If you have any specific questions or need further assistance with the chest x-ray report, please let me know., returning []\n",
      "2023-07-03 19:14:43,087 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I cannot see any impression below as I am a text-based AI model. However, if you provide me with the text of the impression, I can help you generate the relevant facts from it., returning []\n",
      "2023-07-03 19:14:43,088 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"the above recommendation.\" Could you please provide more information or clarify your request?, returning []\n",
      "2023-07-03 19:14:43,094 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...], \"usage\": {\"prompt_tokens\": 384, \"completion_tokens\": 60, \"total_tokens\": 444}}, {\"sentence\": \"Please refer to the official report of that study.\"}] for sentence \"Please refer to the official report of that study.\": Could not parse output: I apologize, but as an AI language model, I don't have access to personal or official documents. I can only provide assistance based on the information you provide. If you can provide the relevant information from the report, I'll be happy to help generate the JSON list of relevant facts for you.\n",
      "2023-07-03 19:14:43,094 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...393, \"completion_tokens\": 15, \"total_tokens\": 408}}, {\"sentence\": \"Right apical mass-like opacity may be due to scarring from prior infection (e.g.\"}] for sentence \"Right apical mass-like opacity may be due to scarring from prior infection (e.g.\": Could not parse output: \"right apical mass-like opacity due to scarring from prior infection\"\n",
      "2023-07-03 19:14:43,100 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need a sentence from the chest x-ray report in order to generate the relevant facts. Could you please provide a sentence from the report?, returning []\n",
      "2023-07-03 19:14:43,103 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ens\": 394, \"completion_tokens\": 5, \"total_tokens\": 399}}, {\"sentence\": \"on the telephone on at 01:30 AM, 1 minutes after discovery of the findings.\"}] for sentence \"on the telephone on at 01:30 AM, 1 minutes after discovery of the findings.\": Could not parse output: No relevant facts mentioned.\n",
      "2023-07-03 19:14:43,106 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, but I can't generate the response you're looking for., returning []\n",
      "2023-07-03 19:14:43,108 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...ompt_tokens\": 391, \"completion_tokens\": 9, \"total_tokens\": 400}}, {\"sentence\": \"In the appropriate clinical setting, other alveolar opacities (e.g.\"}] for sentence \"In the appropriate clinical setting, other alveolar opacities (e.g.\": Could not parse output: \"other alveolar opacities\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:14:43,114 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Needs to be removed.\" Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,114 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I'm not sure what you mean by \"discussed with 19:58.\" Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,114 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you're referring to with \"this at 3:45pm.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"insert leads.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Yet still.\" Could you please provide more context or clarify your statement?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"20:14\". Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate a response based on the input \"are 23:12.\" Could you please provide more information or ask a specific question?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"23:10\". Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"22:36.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Please provide a sentence from a chest x-ray report., returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Drs.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"these items.\" Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,115 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your response. Could you please provide the sentence from the chest x-ray report?, returning []\r\n",
      "2023-07-03 19:14:43,117 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...op\"}], \"usage\": {\"prompt_tokens\": 381, \"completion_tokens\": 5, \"total_tokens\": 386}}, {\"sentence\": \"Does the patient have swallowing difficulties?.\"}] for sentence \"Does the patient have swallowing difficulties?.\": Could not parse output: No relevant facts mentioned.\r\n",
      "2023-07-03 19:14:43,118 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for any confusion. Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,125 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...nish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 380, \"completion_tokens\": 10, \"total_tokens\": 390}}, {\"sentence\": \"Good morning over years fine.\"}] for sentence \"Good morning over years fine.\": Could not parse output: Good morning! How can I assist you today?\r\n",
      "2023-07-03 19:14:43,126 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... 405, \"completion_tokens\": 5, \"total_tokens\": 410}}, {\"sentence\": \"Ktalati , 8:40 PM, D/w Dr. mins after observation WET READ VERSION #1 8:44 PM 1.\"}] for sentence \"Ktalati , 8:40 PM, D/w Dr. mins after observation WET READ VERSION #1 8:44 PM 1.\": Could not parse output: No relevant facts mentioned.\r\n",
      "2023-07-03 19:14:43,132 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to correlate the given information with the patient's CD4 count as it is not provided in the given sentence. My task is to extract relevant facts from the sentence related to chest x-ray observations., returning []\r\n",
      "2023-07-03 19:14:43,135 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the error. Could you please provide the correct transcription so that I can assist you further?, returning []\r\n",
      "2023-07-03 19:14:43,140 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Detail blurred by ?\". Could you please provide more information or clarify your question?, returning []\r\n",
      "2023-07-03 19:14:43,141 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sorry, but I'm not able to generate recommendations based on the given information. My task is to extract relevant facts from a sentence. Is there anything else I can help you with?, returning []\r\n",
      "2023-07-03 19:14:43,142 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to assist with scheduling appointments. Is there anything else I can help you with?, returning []\r\n",
      "2023-07-03 19:14:43,143 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...: {\"prompt_tokens\": 388, \"completion_tokens\": 7, \"total_tokens\": 395}}, {\"sentence\": \"CHF findings are definitely increased compared with at 08:19.\"}] for sentence \"CHF findings are definitely increased compared with at 08:19.\": Could not parse output: \"worsening of CHF\"\r\n",
      "2023-07-03 19:14:43,148 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...n\": \"stop\"}], \"usage\": {\"prompt_tokens\": 385, \"completion_tokens\": 67, \"total_tokens\": 452}}, {\"sentence\": \"DOUBT SIGNIFICANT CHANGE COMPARED WITH.\"}] for sentence \"DOUBT SIGNIFICANT CHANGE COMPARED WITH.\": Could not parse output: In the context of the task, \"significant change compared with\" refers to a comparison between the current observation and a previous study or baseline. It indicates that there has been a noticeable difference or alteration in the observed findings when compared to a previous examination. This comparison helps in identifying any changes or developments in the patient's condition over time.\r\n",
      "2023-07-03 19:14:43,152 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Comparison , 09:40.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,152 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Comparison , 04:11.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,152 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the mistake. Could you please provide the correct sentence from the chest x-ray report?, returning []\r\n",
      "2023-07-03 19:14:43,153 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...mentioned.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 380, \"completion_tokens\": 5, \"total_tokens\": 385}}, {\"sentence\": \"PROCEDURE: 1.\"}] for sentence \"PROCEDURE: 1.\": Could not parse output: No relevant facts mentioned.\r\n",
      "2023-07-03 19:14:43,154 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"discussed with :58.\" Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,154 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I didn't understand your response. Could you please provide the sentence from the chest x-ray report?, returning []\r\n",
      "2023-07-03 19:14:43,154 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, I don't understand what you mean by \"17:16\". Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,154 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need a sentence from a chest x-ray report in order to generate the relevant facts. Could you please provide a sentence for me to work with?, returning []\r\n",
      "2023-07-03 19:14:43,154 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"20:28.\" Could you please provide more context or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,158 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate a response based on the input you provided. Could you please provide a sentence from a chest x-ray report?, returning []\r\n",
      "2023-07-03 19:14:43,158 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"Ktalati at 9:40 PM, mins of observation of findings d/w Dr.\" Could you please provide more information or clarify your request?, returning []\r\n",
      "2023-07-03 19:14:43,160 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d... \"completion_tokens\": 18, \"total_tokens\": 408}}, {\"sentence\": \"It would be prudent to advance the tube somewhat to minimize the risk of aspiration.\"}] for sentence \"It would be prudent to advance the tube somewhat to minimize the risk of aspiration.\": Expecting ',' delimiter: line 3 column 1 (char 28)\r\n",
      "2023-07-03 19:14:43,164 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I am not able to provide information on whether or not a patient has been treated since the chest x-ray report. My function is to generate relevant facts based on the given sentence., returning []\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03 19:14:43,165 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Relevant facts:\\n\\n1. observations of abnormalities\\n2. observations of d...\"}], \"usage\": {\"prompt_tokens\": 384, \"completion_tokens\": 5, \"total_tokens\": 389}}, {\"sentence\": \"Dr. us that the patient has subsequently expired.\"}] for sentence \"Dr. us that the patient has subsequently expired.\": Could not parse output: No relevant facts mentioned.\r\n",
      "2023-07-03 19:14:43,166 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the mistake. Could you please provide the correct sentence from the chest x-ray report?, returning []\r\n",
      "2023-07-03 19:14:43,168 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\r\n",
      "2023-07-03 19:14:43,179 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 19971 of 20000 API responses.\r\n",
      "                    29 of 20000 API responses could not be processed.\r\n",
      "                    Saving parsed sentences to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_facts_from_report_sentences_with_openai.py \\\n",
    "    --preprocessed_reports_filename \"background_findings_and_impression_20230612_174143.json\" \\\n",
    "    --offset 10000 \\\n",
    "    --num_sentences 20000 \\\n",
    "    --rank_sentences_by_difficulty \\\n",
    "    --max_requests_per_minute 3300 \\\n",
    "    --max_tokens_per_minute 87000 \\\n",
    "    --max_tokens_per_request 256 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_1\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f633648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdadc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5702acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3726dc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'sentence': 'A second region of more focal edema in the right upper lobe sitting on the minor fissure is probably due to disturbed lymphatic drainage from the radiated lung.'},\n",
       " 'parsed_response': ['focal edema in the right upper lobe',\n",
       "  'focal edema sitting on the minor fissure',\n",
       "  'disturbed lymphatic drainage from the radiated lung']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
