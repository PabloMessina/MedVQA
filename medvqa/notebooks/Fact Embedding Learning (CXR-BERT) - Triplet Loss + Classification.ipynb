{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c052a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   batch_size: 200\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(1605733,297669,1315702,4001000,20002000,1000,2000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [1.0, 1.0, 1.0], 'observations': [1.0, 1.0, 1.0, 1.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl']\n",
      "   dataset_name: MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "   triplets_weight: 1.0\n",
      "   classification_weight: 1.0\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "1e-06 3 0.0002 8 1e-06 0.0002 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(1605733,297669,1315702,4001000,20002000,1000,2000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1504492\n",
      "\tWeight: 1.0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1493944\n",
      "\tWeight: 1.0\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1315582\n",
      "\tWeight: 1.0\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 5382918\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 5372563\n",
      "\tWeight: 1.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 4440269\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 4909633\n",
      "\tWeight: 1.0\n",
      "----\n",
      "\u001b[1mBuilding train classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Number of sentences with paraphrases: 59901\n",
      "Number of paraphrases: 599166\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 1455640\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1015229\n",
      "Category: tubes and lines -> 179581\n",
      "Category: technical assessment -> 97422\n",
      "Category: disease -> 82909\n",
      "Category: device -> 78769\n",
      "Category: other -> 1730\n",
      "Health status: abnormal -> 830476\n",
      "Health status: unknown -> 365562\n",
      "Health status: normal -> 168102\n",
      "Health status: ambiguous -> 90968\n",
      "Health status: other -> 532\n",
      "Comparison status: no comparison -> 821179\n",
      "Comparison status: stable/unchanged -> 161806\n",
      "Comparison status: worsened -> 78594\n",
      "Comparison status: improved -> 61567\n",
      "Comparison status: resolved -> 58491\n",
      "Comparison status: new finding -> 54389\n",
      "Comparison status: position changed -> 49909\n",
      "Comparison status: unclear comparison -> 48953\n",
      "Comparison status: increase -> 36937\n",
      "Comparison status: decrease -> 24308\n",
      "Comparison status: progressed -> 19529\n",
      "Comparison status: smaller -> 15232\n",
      "Comparison status: larger -> 14403\n",
      "Comparison status: reappeared -> 10084\n",
      "Comparison status: other -> 259\n",
      "\u001b[1mExample fact: no focal infiltrate in the remaining aerated lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: thickening of the wall around the bronchi without clear focal consolidation\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: opacification shows no difference\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison status: no comparison\n",
      "\tNumber of samples: 821179\n",
      "\tWeight: 7584.223051637783\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 78594\n",
      "\tWeight: 4300.633270502103\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 58491\n",
      "\tWeight: 3971.2797023757703\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 161806\n",
      "\tWeight: 5181.224495202725\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 19529\n",
      "\tWeight: 2895.6699714847914\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 14403\n",
      "\tWeight: 2636.1253812589207\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 61567\n",
      "\tWeight: 4027.1690868518713\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 10084\n",
      "\tWeight: 2352.5204683090246\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 15232\n",
      "\tWeight: 2682.6163398845774\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 49909\n",
      "\tWeight: 3801.537897984162\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 54389\n",
      "\tWeight: 3892.8821154862517\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 48953\n",
      "\tWeight: 3781.184791746964\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 36937\n",
      "\tWeight: 3492.9744015057554\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 24308\n",
      "\tWeight: 3092.4456077564887\n",
      "Comparison status: other\n",
      "\tNumber of samples: 259\n",
      "\tWeight: 515.2339764293102\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 334\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 334\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 334\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob3\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_121846_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_121846_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_121846_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.30874, triplet_loss 0.51524, c_loss 1.78307, hs_loss 1.61036, cs_loss 2.70880, cacc 0.30677, hsacc 0.09180, csacc 0.09557, 46.92 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.93114, tacc(al1) 0.63174, tacc(al2) 0.99401, tacc(ob0) 0.97800, tacc(ob1) 0.73800, tacc(ob2) 1.00000, tacc(ob3) 0.78800, 2.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.7957.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.26763, triplet_loss 0.48881, c_loss 1.74758, hs_loss 1.59622, cs_loss 2.70265, cacc 0.41303, hsacc 0.10367, csacc 0.11043, 45.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.96707, tacc(al1) 0.80838, tacc(al2) 0.93413, tacc(ob0) 0.98200, tacc(ob1) 0.88000, tacc(ob2) 0.95400, tacc(ob3) 0.88800, 2.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8455.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 3.14299, triplet_loss 0.47320, c_loss 1.59204, hs_loss 1.54192, cs_loss 2.67882, cacc 0.68550, hsacc 0.27730, csacc 0.16237, 45.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.85629, tacc(al2) 0.86527, tacc(ob0) 0.97800, tacc(ob1) 0.91600, tacc(ob2) 0.86000, tacc(ob3) 0.95400, 2.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8622.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.90082, triplet_loss 0.46340, c_loss 1.38650, hs_loss 1.34997, cs_loss 2.60178, cacc 0.81117, hsacc 0.73477, csacc 0.26757, 46.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.88323, tacc(al2) 0.85030, tacc(ob0) 0.96400, tacc(ob1) 0.90600, tacc(ob2) 0.83200, tacc(ob3) 0.93800, 2.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8776.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000103) ...\n",
      "loss 2.72651, triplet_loss 0.44969, c_loss 1.27734, hs_loss 1.23100, cs_loss 2.49500, cacc 0.81467, hsacc 0.78547, csacc 0.41340, 46.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.87425, tacc(al2) 0.84132, tacc(ob0) 0.95600, tacc(ob1) 0.91200, tacc(ob2) 0.81800, tacc(ob3) 0.94400, 2.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8807.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 2.65200, triplet_loss 0.44628, c_loss 1.23170, hs_loss 1.17821, cs_loss 2.44781, cacc 0.82463, hsacc 0.80477, csacc 0.44623, 46.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.89820, tacc(al2) 0.84431, tacc(ob0) 0.96400, tacc(ob1) 0.92200, tacc(ob2) 0.81400, tacc(ob3) 0.93800, 2.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8876.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.61674, triplet_loss 0.44323, c_loss 1.20662, hs_loss 1.16190, cs_loss 2.42173, cacc 0.82963, hsacc 0.81067, csacc 0.46317, 45.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.89521, tacc(al2) 0.85629, tacc(ob0) 0.97600, tacc(ob1) 0.91800, tacc(ob2) 0.80200, tacc(ob3) 0.94600, 2.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8902.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.59577, triplet_loss 0.44197, c_loss 1.19765, hs_loss 1.14413, cs_loss 2.40778, cacc 0.81963, hsacc 0.81453, csacc 0.47257, 46.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.90120, tacc(al2) 0.85629, tacc(ob0) 0.97000, tacc(ob1) 0.92200, tacc(ob2) 0.81000, tacc(ob3) 0.94800, 2.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8917.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.58949, triplet_loss 0.43914, c_loss 1.19889, hs_loss 1.13891, cs_loss 2.40204, cacc 0.82560, hsacc 0.81913, csacc 0.47167, 46.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.89820, tacc(al2) 0.85030, tacc(ob0) 0.97000, tacc(ob1) 0.92200, tacc(ob2) 0.81200, tacc(ob3) 0.94200, 2.27 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.58041, triplet_loss 0.43944, c_loss 1.18628, hs_loss 1.13947, cs_loss 2.39564, cacc 0.82667, hsacc 0.81717, csacc 0.47823, 45.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.85329, tacc(ob0) 0.97000, tacc(ob1) 0.92400, tacc(ob2) 0.81200, tacc(ob3) 0.94400, 2.33 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8922.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.57875, triplet_loss 0.44064, c_loss 1.18437, hs_loss 1.13794, cs_loss 2.39455, cacc 0.82403, hsacc 0.81977, csacc 0.47980, 46.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.85329, tacc(ob0) 0.96800, tacc(ob1) 0.92400, tacc(ob2) 0.81200, tacc(ob3) 0.94400, 2.31 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.57977, triplet_loss 0.43893, c_loss 1.18934, hs_loss 1.13657, cs_loss 2.39469, cacc 0.82183, hsacc 0.81307, csacc 0.47643, 47.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.85329, tacc(ob0) 0.97000, tacc(ob1) 0.92200, tacc(ob2) 0.81800, tacc(ob3) 0.94200, 2.36 secs\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.55381, triplet_loss 0.44877, c_loss 1.15979, hs_loss 1.12649, cs_loss 2.37257, cacc 0.81673, hsacc 0.79703, csacc 0.46553, 46.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97904, tacc(al1) 0.89222, tacc(al2) 0.82934, tacc(ob0) 0.96400, tacc(ob1) 0.91600, tacc(ob2) 0.81600, tacc(ob3) 0.94200, 2.38 secs\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 2.45265, triplet_loss 0.44629, c_loss 1.08928, hs_loss 1.06318, cs_loss 2.30655, cacc 0.82320, hsacc 0.81060, csacc 0.48123, 47.24 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.90120, tacc(al2) 0.85329, tacc(ob0) 0.97200, tacc(ob1) 0.93200, tacc(ob2) 0.80400, tacc(ob3) 0.94800, 3.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8924.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 2.40241, triplet_loss 0.44280, c_loss 1.06929, hs_loss 1.02933, cs_loss 2.26339, cacc 0.81853, hsacc 0.82703, csacc 0.50027, 48.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97904, tacc(al1) 0.91018, tacc(al2) 0.86527, tacc(ob0) 0.96600, tacc(ob1) 0.93000, tacc(ob2) 0.81400, tacc(ob3) 0.95200, 2.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8965.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 2.37547, triplet_loss 0.44082, c_loss 1.04573, hs_loss 1.01696, cs_loss 2.24742, cacc 0.82193, hsacc 0.82867, csacc 0.50243, 49.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.91916, tacc(al2) 0.85629, tacc(ob0) 0.97000, tacc(ob1) 0.93400, tacc(ob2) 0.81800, tacc(ob3) 0.94600, 3.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.8979.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.36183, triplet_loss 0.44053, c_loss 1.03229, hs_loss 1.01204, cs_loss 2.23880, cacc 0.82353, hsacc 0.83143, csacc 0.50707, 46.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.91617, tacc(al2) 0.85629, tacc(ob0) 0.96400, tacc(ob1) 0.92800, tacc(ob2) 0.81600, tacc(ob3) 0.93800, 3.70 secs\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.35833, triplet_loss 0.43981, c_loss 1.03621, hs_loss 1.01111, cs_loss 2.22954, cacc 0.82063, hsacc 0.82933, csacc 0.51460, 47.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97904, tacc(al1) 0.91617, tacc(al2) 0.85329, tacc(ob0) 0.96600, tacc(ob1) 0.92600, tacc(ob2) 0.81400, tacc(ob3) 0.94200, 3.32 secs\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.35911, triplet_loss 0.43838, c_loss 1.03931, hs_loss 1.00761, cs_loss 2.23292, cacc 0.81920, hsacc 0.83157, csacc 0.50767, 51.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.91018, tacc(al2) 0.85928, tacc(ob0) 0.96600, tacc(ob1) 0.92600, tacc(ob2) 0.81600, tacc(ob3) 0.93600, 4.06 secs\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.35209, triplet_loss 0.43925, c_loss 1.03195, hs_loss 1.00208, cs_loss 2.23090, cacc 0.82413, hsacc 0.83050, csacc 0.51193, 53.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.91018, tacc(al2) 0.85329, tacc(ob0) 0.96600, tacc(ob1) 0.92400, tacc(ob2) 0.81600, tacc(ob3) 0.93600, 3.66 secs\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.33597, triplet_loss 0.44804, c_loss 1.00592, hs_loss 1.00197, cs_loss 2.21600, cacc 0.81990, hsacc 0.81687, csacc 0.49387, 55.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.90719, tacc(al2) 0.82335, tacc(ob0) 0.96400, tacc(ob1) 0.92000, tacc(ob2) 0.82600, tacc(ob3) 0.93200, 4.09 secs\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 2.25410, triplet_loss 0.44373, c_loss 0.95606, hs_loss 0.95207, cs_loss 2.15633, cacc 0.81927, hsacc 0.82653, csacc 0.50673, 55.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.88323, tacc(al2) 0.85030, tacc(ob0) 0.96800, tacc(ob1) 0.93000, tacc(ob2) 0.82000, tacc(ob3) 0.93400, 4.83 secs\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 2.21247, triplet_loss 0.44120, c_loss 0.93528, hs_loss 0.92969, cs_loss 2.11877, cacc 0.82003, hsacc 0.83287, csacc 0.52143, 57.91 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.90419, tacc(al2) 0.85030, tacc(ob0) 0.96800, tacc(ob1) 0.93600, tacc(ob2) 0.81800, tacc(ob3) 0.95200, 3.73 secs\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 2.18112, triplet_loss 0.43872, c_loss 0.91575, hs_loss 0.90915, cs_loss 2.09862, cacc 0.82417, hsacc 0.83890, csacc 0.53007, 58.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.91317, tacc(al2) 0.86228, tacc(ob0) 0.97000, tacc(ob1) 0.92400, tacc(ob2) 0.82800, tacc(ob3) 0.95400, 3.45 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9010.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.17165, triplet_loss 0.43793, c_loss 0.91135, hs_loss 0.90281, cs_loss 2.09120, cacc 0.82327, hsacc 0.84237, csacc 0.53370, 59.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.86826, tacc(ob0) 0.96800, tacc(ob1) 0.92400, tacc(ob2) 0.82200, tacc(ob3) 0.95200, 3.78 secs\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.15762, triplet_loss 0.43883, c_loss 0.89491, hs_loss 0.89269, cs_loss 2.08881, cacc 0.82480, hsacc 0.84930, csacc 0.53143, 59.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90419, tacc(al2) 0.86527, tacc(ob0) 0.96800, tacc(ob1) 0.93000, tacc(ob2) 0.82200, tacc(ob3) 0.95000, 3.71 secs\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.16163, triplet_loss 0.43850, c_loss 0.90266, hs_loss 0.89558, cs_loss 2.08652, cacc 0.82550, hsacc 0.84567, csacc 0.53610, 58.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.91018, tacc(al2) 0.86228, tacc(ob0) 0.96800, tacc(ob1) 0.93000, tacc(ob2) 0.82400, tacc(ob3) 0.95200, 3.86 secs\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.15775, triplet_loss 0.43918, c_loss 0.90025, hs_loss 0.89438, cs_loss 2.08170, cacc 0.82337, hsacc 0.84797, csacc 0.53753, 59.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.91018, tacc(al2) 0.86228, tacc(ob0) 0.96800, tacc(ob1) 0.92800, tacc(ob2) 0.82200, tacc(ob3) 0.95000, 4.34 secs\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.15830, triplet_loss 0.44501, c_loss 0.89348, hs_loss 0.90575, cs_loss 2.07236, cacc 0.82293, hsacc 0.82547, csacc 0.51907, 60.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97904, tacc(al1) 0.88323, tacc(al2) 0.85329, tacc(ob0) 0.96800, tacc(ob1) 0.92600, tacc(ob2) 0.82800, tacc(ob3) 0.93200, 3.51 secs\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 2.08085, triplet_loss 0.44310, c_loss 0.84077, hs_loss 0.86213, cs_loss 2.01570, cacc 0.83107, hsacc 0.83963, csacc 0.53200, 58.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.90120, tacc(al2) 0.85329, tacc(ob0) 0.97200, tacc(ob1) 0.93200, tacc(ob2) 0.81600, tacc(ob3) 0.95000, 3.75 secs\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 2.03104, triplet_loss 0.44175, c_loss 0.80783, hs_loss 0.82893, cs_loss 1.98359, cacc 0.82580, hsacc 0.84797, csacc 0.53863, 56.79 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.84431, tacc(ob0) 0.96800, tacc(ob1) 0.94400, tacc(ob2) 0.81800, tacc(ob3) 0.93600, 4.00 secs\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 2.01524, triplet_loss 0.44027, c_loss 0.81240, hs_loss 0.81865, cs_loss 1.95917, cacc 0.82963, hsacc 0.85137, csacc 0.55337, 56.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90719, tacc(al2) 0.84731, tacc(ob0) 0.97200, tacc(ob1) 0.94600, tacc(ob2) 0.82600, tacc(ob3) 0.95000, 3.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9016.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.00181, triplet_loss 0.43751, c_loss 0.80241, hs_loss 0.80804, cs_loss 1.95565, cacc 0.82257, hsacc 0.85263, csacc 0.54737, 56.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90419, tacc(al2) 0.85030, tacc(ob0) 0.97800, tacc(ob1) 0.94400, tacc(ob2) 0.82400, tacc(ob3) 0.94800, 3.54 secs\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.00107, triplet_loss 0.43710, c_loss 0.79517, hs_loss 0.81694, cs_loss 1.95294, cacc 0.83337, hsacc 0.85700, csacc 0.55223, 58.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.85030, tacc(ob0) 0.97400, tacc(ob1) 0.93800, tacc(ob2) 0.82200, tacc(ob3) 0.95000, 3.60 secs\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.99653, triplet_loss 0.43626, c_loss 0.80400, hs_loss 0.80240, cs_loss 1.95040, cacc 0.82877, hsacc 0.85333, csacc 0.55107, 59.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90719, tacc(al2) 0.85030, tacc(ob0) 0.97600, tacc(ob1) 0.94600, tacc(ob2) 0.82200, tacc(ob3) 0.94800, 3.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9017.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.00342, triplet_loss 0.43751, c_loss 0.80858, hs_loss 0.81055, cs_loss 1.95019, cacc 0.83067, hsacc 0.85637, csacc 0.55353, 59.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.91018, tacc(al2) 0.85030, tacc(ob0) 0.97600, tacc(ob1) 0.94600, tacc(ob2) 0.82200, tacc(ob3) 0.94800, 4.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_36_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9024.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.99674, triplet_loss 0.44340, c_loss 0.78677, hs_loss 0.82067, cs_loss 1.94264, cacc 0.82833, hsacc 0.83803, csacc 0.53487, 61.76 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.90120, tacc(al2) 0.85928, tacc(ob0) 0.96600, tacc(ob1) 0.93200, tacc(ob2) 0.79800, tacc(ob3) 0.93600, 4.53 secs\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 1.92976, triplet_loss 0.44055, c_loss 0.74750, hs_loss 0.78457, cs_loss 1.88691, cacc 0.82703, hsacc 0.84583, csacc 0.54697, 61.51 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.91018, tacc(al2) 0.85329, tacc(ob0) 0.97000, tacc(ob1) 0.93800, tacc(ob2) 0.81000, tacc(ob3) 0.94200, 3.85 secs\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 1.88441, triplet_loss 0.44130, c_loss 0.71822, hs_loss 0.76220, cs_loss 1.84709, cacc 0.83383, hsacc 0.84967, csacc 0.56077, 58.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.89820, tacc(al2) 0.85928, tacc(ob0) 0.97200, tacc(ob1) 0.93000, tacc(ob2) 0.82400, tacc(ob3) 0.94800, 3.48 secs\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 1.86572, triplet_loss 0.43934, c_loss 0.70694, hs_loss 0.74485, cs_loss 1.84032, cacc 0.83540, hsacc 0.86337, csacc 0.55683, 59.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.85928, tacc(ob0) 0.97200, tacc(ob1) 0.94600, tacc(ob2) 0.82600, tacc(ob3) 0.94600, 3.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_40_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9026.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.86440, triplet_loss 0.43833, c_loss 0.71942, hs_loss 0.74496, cs_loss 1.82610, cacc 0.83193, hsacc 0.85757, csacc 0.56013, 57.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90120, tacc(al2) 0.85329, tacc(ob0) 0.97400, tacc(ob1) 0.94400, tacc(ob2) 0.81800, tacc(ob3) 0.95600, 4.89 secs\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.85429, triplet_loss 0.43708, c_loss 0.71111, hs_loss 0.73524, cs_loss 1.82514, cacc 0.83090, hsacc 0.86123, csacc 0.56383, 57.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90719, tacc(al2) 0.85629, tacc(ob0) 0.97400, tacc(ob1) 0.94400, tacc(ob2) 0.82200, tacc(ob3) 0.95400, 3.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9035.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.84432, triplet_loss 0.43756, c_loss 0.70388, hs_loss 0.72819, cs_loss 1.81902, cacc 0.83430, hsacc 0.86360, csacc 0.56647, 56.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90419, tacc(al2) 0.85329, tacc(ob0) 0.97400, tacc(ob1) 0.93800, tacc(ob2) 0.82200, tacc(ob3) 0.95600, 3.63 secs\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.83997, triplet_loss 0.43681, c_loss 0.69315, hs_loss 0.72881, cs_loss 1.82117, cacc 0.83680, hsacc 0.86337, csacc 0.56517, 55.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.90419, tacc(al2) 0.85329, tacc(ob0) 0.97600, tacc(ob1) 0.94000, tacc(ob2) 0.82000, tacc(ob3) 0.95600, 3.82 secs\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.85557, triplet_loss 0.44289, c_loss 0.70259, hs_loss 0.74573, cs_loss 1.81993, cacc 0.83440, hsacc 0.84660, csacc 0.54797, 59.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98503, tacc(al1) 0.88922, tacc(al2) 0.82036, tacc(ob0) 0.97400, tacc(ob1) 0.93000, tacc(ob2) 0.80200, tacc(ob3) 0.94800, 3.47 secs\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 1.80287, triplet_loss 0.44285, c_loss 0.67007, hs_loss 0.71574, cs_loss 1.77709, cacc 0.83427, hsacc 0.85280, csacc 0.55377, 56.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97904, tacc(al1) 0.91617, tacc(al2) 0.84431, tacc(ob0) 0.97800, tacc(ob1) 0.93200, tacc(ob2) 0.81000, tacc(ob3) 0.95200, 4.19 secs\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 1.76265, triplet_loss 0.44175, c_loss 0.64521, hs_loss 0.70520, cs_loss 1.73314, cacc 0.83723, hsacc 0.85850, csacc 0.56943, 59.94 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.91916, tacc(al2) 0.84731, tacc(ob0) 0.97400, tacc(ob1) 0.93800, tacc(ob2) 0.81800, tacc(ob3) 0.95400, 4.24 secs\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 1.73889, triplet_loss 0.43937, c_loss 0.64131, hs_loss 0.68303, cs_loss 1.71408, cacc 0.83810, hsacc 0.86627, csacc 0.58063, 59.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98204, tacc(al1) 0.91916, tacc(al2) 0.85030, tacc(ob0) 0.98000, tacc(ob1) 0.94200, tacc(ob2) 0.80800, tacc(ob3) 0.94800, 4.35 secs\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.73613, triplet_loss 0.43871, c_loss 0.63660, hs_loss 0.68891, cs_loss 1.70804, cacc 0.84170, hsacc 0.86540, csacc 0.57863, 60.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.92216, tacc(al2) 0.86527, tacc(ob0) 0.97600, tacc(ob1) 0.94200, tacc(ob2) 0.82200, tacc(ob3) 0.94600, 4.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9069.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.71973, triplet_loss 0.43663, c_loss 0.62033, hs_loss 0.68190, cs_loss 1.70061, cacc 0.84527, hsacc 0.86643, csacc 0.58027, 61.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.91916, tacc(al2) 0.86228, tacc(ob0) 0.98000, tacc(ob1) 0.94400, tacc(ob2) 0.82000, tacc(ob3) 0.94600, 4.36 secs\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.71905, triplet_loss 0.43699, c_loss 0.62128, hs_loss 0.68017, cs_loss 1.69966, cacc 0.84320, hsacc 0.86847, csacc 0.58180, 61.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.91617, tacc(al2) 0.86228, tacc(ob0) 0.97800, tacc(ob1) 0.94400, tacc(ob2) 0.82000, tacc(ob3) 0.94600, 4.28 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.73005, triplet_loss 0.43816, c_loss 0.64683, hs_loss 0.67365, cs_loss 1.70146, cacc 0.84183, hsacc 0.86423, csacc 0.57947, 58.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.91317, tacc(al2) 0.86527, tacc(ob0) 0.97600, tacc(ob1) 0.94200, tacc(ob2) 0.82200, tacc(ob3) 0.94600, 3.50 secs\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.74213, triplet_loss 0.44419, c_loss 0.63594, hs_loss 0.69635, cs_loss 1.70778, cacc 0.84293, hsacc 0.84710, csacc 0.56440, 56.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97605, tacc(al1) 0.88922, tacc(al2) 0.83832, tacc(ob0) 0.97600, tacc(ob1) 0.93200, tacc(ob2) 0.80600, tacc(ob3) 0.94400, 4.16 secs\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 1.68754, triplet_loss 0.44400, c_loss 0.59424, hs_loss 0.66842, cs_loss 1.66843, cacc 0.85183, hsacc 0.85990, csacc 0.56713, 53.44 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.89521, tacc(al2) 0.84731, tacc(ob0) 0.97600, tacc(ob1) 0.93600, tacc(ob2) 0.82400, tacc(ob3) 0.94800, 4.33 secs\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 1.64633, triplet_loss 0.43859, c_loss 0.58309, hs_loss 0.64233, cs_loss 1.62865, cacc 0.84900, hsacc 0.86727, csacc 0.58400, 56.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.89521, tacc(al2) 0.85030, tacc(ob0) 0.98400, tacc(ob1) 0.94400, tacc(ob2) 0.82200, tacc(ob3) 0.95800, 3.41 secs\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 1.62899, triplet_loss 0.44018, c_loss 0.57785, hs_loss 0.62978, cs_loss 1.61016, cacc 0.85163, hsacc 0.86783, csacc 0.58743, 60.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.90120, tacc(al2) 0.85928, tacc(ob0) 0.97800, tacc(ob1) 0.94600, tacc(ob2) 0.81800, tacc(ob3) 0.95800, 3.79 secs\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.62349, triplet_loss 0.43930, c_loss 0.56961, hs_loss 0.63802, cs_loss 1.60006, cacc 0.85763, hsacc 0.87150, csacc 0.59087, 61.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.90419, tacc(al2) 0.85629, tacc(ob0) 0.97800, tacc(ob1) 0.94600, tacc(ob2) 0.82200, tacc(ob3) 0.95400, 4.20 secs\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.61282, triplet_loss 0.43867, c_loss 0.56260, hs_loss 0.62577, cs_loss 1.59860, cacc 0.85560, hsacc 0.86977, csacc 0.59100, 59.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.90419, tacc(al2) 0.85629, tacc(ob0) 0.97800, tacc(ob1) 0.94600, tacc(ob2) 0.82000, tacc(ob3) 0.95400, 3.66 secs\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "   iteration 17475\r"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "    --epochs 60 \\\n",
    "    --batches_per_epoch 300 \\\n",
    "    --batch_size 200 \\\n",
    "    --num_workers 3 \\\n",
    "    --iters_to_accumulate 4 \\\n",
    "    --optimizer_name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\" \\\n",
    "    --triplets_filepath \\\n",
    "        \"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(1605733,297669,1315702,4001000,20002000,1000,2000).pkl\" \\\n",
    "    --triplet_rule_weights \\\n",
    "        \"{'anatomical_locations': [1., 1., 1.], 'observations': [1., 1., 1., 1.]}\" \\\n",
    "    --integrated_facts_metadata_jsonl_filepath \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "    --paraphrases_jsonl_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "    --dataset_name \"MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\" \\\n",
    "    --huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "    --embedding_size 128 \\\n",
    "    --use_amp \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c822c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "    --pretrained_checkpoint_folder_path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_121846_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "    --epochs 100 \\\n",
    "    --batches_per_epoch 400 \\\n",
    "    --batch_size 200 \\\n",
    "    --num_workers 3 \\\n",
    "    --iters_to_accumulate 4 \\\n",
    "    --optimizer_name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "    --triplets_filepath \\\n",
    "        \"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(1605733,297669,1315702,4001000,20002000,1000,2000).pkl\" \\\n",
    "    --triplet_rule_weights \\\n",
    "        \"{'anatomical_locations': [1., 1., 1.], 'observations': [1., 1., 1., 1.]}\" \\\n",
    "    --integrated_facts_metadata_jsonl_filepath \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "    --paraphrases_jsonl_filepaths \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "        \"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "    --dataset_name \"MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\" \\\n",
    "    --huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "    --embedding_size 128 \\\n",
    "    --use_amp \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d79f2f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 400\n",
      "   batch_size: 200\n",
      "   checkpoint_folder: models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   huggingface_model_name: None\n",
      "   embedding_size: 128\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: None\n",
      "   iters_to_accumulate: 1\n",
      "   override_lr: False\n",
      "   triplets_filepath: None\n",
      "   triplet_rule_weights: None\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrases_jsonl_filepaths: None\n",
      "   dataset_name: None\n",
      "   triplets_weight: 1.0\n",
      "   classification_weight: 1.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(1605733,297669,1315702,4001000,20002000,1000,2000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1504492\n",
      "\tWeight: 1.0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1493944\n",
      "\tWeight: 1.0\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1315582\n",
      "\tWeight: 1.0\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 5382918\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 5372563\n",
      "\tWeight: 1.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 4440269\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 4909633\n",
      "\tWeight: 1.0\n",
      "----\n",
      "\u001b[1mBuilding train classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Number of sentences with paraphrases: 59901\n",
      "Number of paraphrases: 599166\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 1455640\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1015229\n",
      "Category: tubes and lines -> 179581\n",
      "Category: technical assessment -> 97422\n",
      "Category: disease -> 82909\n",
      "Category: device -> 78769\n",
      "Category: other -> 1730\n",
      "Health status: abnormal -> 830476\n",
      "Health status: unknown -> 365562\n",
      "Health status: normal -> 168102\n",
      "Health status: ambiguous -> 90968\n",
      "Health status: other -> 532\n",
      "Comparison status: no comparison -> 821179\n",
      "Comparison status: stable/unchanged -> 161806\n",
      "Comparison status: worsened -> 78594\n",
      "Comparison status: improved -> 61567\n",
      "Comparison status: resolved -> 58491\n",
      "Comparison status: new finding -> 54389\n",
      "Comparison status: position changed -> 49909\n",
      "Comparison status: unclear comparison -> 48953\n",
      "Comparison status: increase -> 36937\n",
      "Comparison status: decrease -> 24308\n",
      "Comparison status: progressed -> 19529\n",
      "Comparison status: smaller -> 15232\n",
      "Comparison status: larger -> 14403\n",
      "Comparison status: reappeared -> 10084\n",
      "Comparison status: other -> 259\n",
      "\u001b[1mExample fact: diffuse opacities in the left lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: no evidence of acute trauma\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: existing prominent hiatal hernia\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: cluster of microcalcifications\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: endotracheal tube tip is positioned roughly 3.4 cm from the carina\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: potential for an early infiltrate\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: ambiguous\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: AP view of the chest compared to previous exam from earlier the same day at 3:58 a.m.\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: resolved\n",
      "\u001b[1mExample fact: decreased pre-existing effusion\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: decrease\n",
      "\u001b[1mExample fact: old healed rib fractures\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: multifocal airspace opacities\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison status: no comparison\n",
      "\tNumber of samples: 821179\n",
      "\tWeight: 7584.223051637783\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 78594\n",
      "\tWeight: 4300.633270502103\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 58491\n",
      "\tWeight: 3971.2797023757703\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 161806\n",
      "\tWeight: 5181.224495202725\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 19529\n",
      "\tWeight: 2895.6699714847914\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 14403\n",
      "\tWeight: 2636.1253812589207\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 61567\n",
      "\tWeight: 4027.1690868518713\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 10084\n",
      "\tWeight: 2352.5204683090246\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 15232\n",
      "\tWeight: 2682.6163398845774\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 49909\n",
      "\tWeight: 3801.537897984162\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 54389\n",
      "\tWeight: 3892.8821154862517\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 48953\n",
      "\tWeight: 3781.184791746964\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 36937\n",
      "\tWeight: 3492.9744015057554\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 24308\n",
      "\tWeight: 3092.4456077564887\n",
      "Comparison status: other\n",
      "\tNumber of samples: 259\n",
      "\tWeight: 515.2339764293102\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 334\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 334\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 334\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 500\n",
      "\tRule ID: ob3\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_42_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9201.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_42_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9201.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 43/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.30076, triplet_loss 0.43789, c_loss 0.40257, hs_loss 0.47345, cs_loss 1.28760, cacc 0.89633, hsacc 0.89080, csacc 0.64435, 62.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.93413, tacc(al2) 0.87425, tacc(ob0) 0.98200, tacc(ob1) 0.94600, tacc(ob2) 0.84600, tacc(ob3) 0.96600, 2.61 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_43_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9218.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 44/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.30242, triplet_loss 0.43684, c_loss 0.40075, hs_loss 0.48043, cs_loss 1.28682, cacc 0.89397, hsacc 0.88705, csacc 0.64390, 61.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92814, tacc(al2) 0.87425, tacc(ob0) 0.98200, tacc(ob1) 0.94600, tacc(ob2) 0.84400, tacc(ob3) 0.96600, 2.45 secs\n",
      "\u001b[1m---- Epoch 45/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.32254, triplet_loss 0.43825, c_loss 0.41024, hs_loss 0.49234, cs_loss 1.30424, cacc 0.89318, hsacc 0.88153, csacc 0.63215, 62.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.92515, tacc(al2) 0.85629, tacc(ob0) 0.97600, tacc(ob1) 0.94800, tacc(ob2) 0.85400, tacc(ob3) 0.97000, 2.65 secs\n",
      "\u001b[1m---- Epoch 46/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.29931, triplet_loss 0.43965, c_loss 0.39799, hs_loss 0.48437, cs_loss 1.27661, cacc 0.89230, hsacc 0.88328, csacc 0.63865, 61.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.93114, tacc(al2) 0.86527, tacc(ob0) 0.98200, tacc(ob1) 0.95200, tacc(ob2) 0.84200, tacc(ob3) 0.97000, 2.68 secs\n",
      "\u001b[1m---- Epoch 47/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.27259, triplet_loss 0.43792, c_loss 0.37353, hs_loss 0.48101, cs_loss 1.25272, cacc 0.89995, hsacc 0.88735, csacc 0.64640, 63.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92814, tacc(al2) 0.87126, tacc(ob0) 0.98000, tacc(ob1) 0.94800, tacc(ob2) 0.84000, tacc(ob3) 0.96600, 2.67 secs\n",
      "\u001b[1m---- Epoch 48/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.25436, triplet_loss 0.43769, c_loss 0.36909, hs_loss 0.45800, cs_loss 1.24394, cacc 0.89917, hsacc 0.89015, csacc 0.64928, 63.92 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92814, tacc(al2) 0.86527, tacc(ob0) 0.97800, tacc(ob1) 0.94600, tacc(ob2) 0.84200, tacc(ob3) 0.97000, 2.72 secs\n",
      "\u001b[1m---- Epoch 49/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.25144, triplet_loss 0.43756, c_loss 0.36485, hs_loss 0.45861, cs_loss 1.24186, cacc 0.90360, hsacc 0.89140, csacc 0.64667, 62.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93413, tacc(al2) 0.86826, tacc(ob0) 0.98200, tacc(ob1) 0.95000, tacc(ob2) 0.84000, tacc(ob3) 0.96800, 2.83 secs\n",
      "\u001b[1m---- Epoch 50/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.25093, triplet_loss 0.43736, c_loss 0.37261, hs_loss 0.46048, cs_loss 1.23141, cacc 0.90428, hsacc 0.88985, csacc 0.65410, 63.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93413, tacc(al2) 0.86527, tacc(ob0) 0.98400, tacc(ob1) 0.95000, tacc(ob2) 0.84200, tacc(ob3) 0.97000, 2.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_50_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9224.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 51/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.25674, triplet_loss 0.43662, c_loss 0.37957, hs_loss 0.46134, cs_loss 1.23595, cacc 0.90363, hsacc 0.89118, csacc 0.64770, 64.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93413, tacc(al2) 0.86826, tacc(ob0) 0.98200, tacc(ob1) 0.95200, tacc(ob2) 0.84000, tacc(ob3) 0.97200, 3.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_51_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9226.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 52/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.24977, triplet_loss 0.43837, c_loss 0.37034, hs_loss 0.46390, cs_loss 1.22692, cacc 0.90285, hsacc 0.88733, csacc 0.65458, 64.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93413, tacc(al2) 0.86527, tacc(ob0) 0.98400, tacc(ob1) 0.95200, tacc(ob2) 0.84000, tacc(ob3) 0.97200, 3.53 secs\n",
      "\u001b[1m---- Epoch 53/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.27032, triplet_loss 0.43836, c_loss 0.39067, hs_loss 0.47348, cs_loss 1.23813, cacc 0.89692, hsacc 0.88448, csacc 0.64502, 69.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.91916, tacc(al2) 0.85629, tacc(ob0) 0.97800, tacc(ob1) 0.95000, tacc(ob2) 0.85400, tacc(ob3) 0.96200, 4.17 secs\n",
      "\u001b[1m---- Epoch 54/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.25403, triplet_loss 0.44028, c_loss 0.37739, hs_loss 0.47403, cs_loss 1.21638, cacc 0.90365, hsacc 0.87950, csacc 0.64682, 71.15 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99102, tacc(al1) 0.93114, tacc(al2) 0.85629, tacc(ob0) 0.98400, tacc(ob1) 0.95000, tacc(ob2) 0.83800, tacc(ob3) 0.96600, 4.60 secs\n",
      "\u001b[1m---- Epoch 55/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.22044, triplet_loss 0.43780, c_loss 0.35657, hs_loss 0.44616, cs_loss 1.20035, cacc 0.90845, hsacc 0.88833, csacc 0.65220, 76.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.93114, tacc(al2) 0.85928, tacc(ob0) 0.98000, tacc(ob1) 0.95200, tacc(ob2) 0.83600, tacc(ob3) 0.96400, 4.98 secs\n",
      "\u001b[1m---- Epoch 56/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.20871, triplet_loss 0.43729, c_loss 0.35324, hs_loss 0.43534, cs_loss 1.19155, cacc 0.90570, hsacc 0.89280, csacc 0.65360, 82.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.93114, tacc(al2) 0.86826, tacc(ob0) 0.98200, tacc(ob1) 0.95600, tacc(ob2) 0.84000, tacc(ob3) 0.97200, 4.60 secs\n",
      "\u001b[1m---- Epoch 57/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.21414, triplet_loss 0.43828, c_loss 0.36304, hs_loss 0.44098, cs_loss 1.18597, cacc 0.90785, hsacc 0.89245, csacc 0.65715, 88.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.92515, tacc(al2) 0.86826, tacc(ob0) 0.98400, tacc(ob1) 0.95600, tacc(ob2) 0.83600, tacc(ob3) 0.97400, 5.72 secs\n",
      "\u001b[1m---- Epoch 58/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.21604, triplet_loss 0.43744, c_loss 0.35496, hs_loss 0.45651, cs_loss 1.18318, cacc 0.90510, hsacc 0.88975, csacc 0.65682, 90.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92515, tacc(al2) 0.86826, tacc(ob0) 0.98400, tacc(ob1) 0.95400, tacc(ob2) 0.84000, tacc(ob3) 0.97200, 6.06 secs\n",
      "\u001b[1m---- Epoch 59/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.21074, triplet_loss 0.43813, c_loss 0.35839, hs_loss 0.44758, cs_loss 1.17737, cacc 0.90680, hsacc 0.88833, csacc 0.65910, 95.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.93114, tacc(al2) 0.86826, tacc(ob0) 0.98400, tacc(ob1) 0.95400, tacc(ob2) 0.84200, tacc(ob3) 0.97200, 5.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_59_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9226.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 60/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.20991, triplet_loss 0.43938, c_loss 0.34914, hs_loss 0.45643, cs_loss 1.17487, cacc 0.91078, hsacc 0.88875, csacc 0.66102, 87.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92814, tacc(al2) 0.86826, tacc(ob0) 0.98400, tacc(ob1) 0.95400, tacc(ob2) 0.84200, tacc(ob3) 0.97200, 5.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_60_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9228.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 61/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.22890, triplet_loss 0.43845, c_loss 0.35279, hs_loss 0.46426, cs_loss 1.20231, cacc 0.90368, hsacc 0.88180, csacc 0.64530, 76.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.92814, tacc(al2) 0.87126, tacc(ob0) 0.98400, tacc(ob1) 0.95800, tacc(ob2) 0.83400, tacc(ob3) 0.96800, 4.45 secs\n",
      "\u001b[1m---- Epoch 62/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.19884, triplet_loss 0.44027, c_loss 0.34742, hs_loss 0.44248, cs_loss 1.16751, cacc 0.91005, hsacc 0.88933, csacc 0.65528, 77.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92515, tacc(al2) 0.87725, tacc(ob0) 0.97800, tacc(ob1) 0.94200, tacc(ob2) 0.83200, tacc(ob3) 0.96800, 4.58 secs\n",
      "\u001b[1m---- Epoch 63/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.18842, triplet_loss 0.43821, c_loss 0.34605, hs_loss 0.43630, cs_loss 1.15628, cacc 0.91033, hsacc 0.88758, csacc 0.65912, 74.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92515, tacc(al2) 0.88024, tacc(ob0) 0.97600, tacc(ob1) 0.93800, tacc(ob2) 0.83800, tacc(ob3) 0.97000, 4.02 secs\n",
      "\u001b[1m---- Epoch 64/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.17554, triplet_loss 0.43785, c_loss 0.34140, hs_loss 0.42058, cs_loss 1.15125, cacc 0.91635, hsacc 0.89045, csacc 0.66030, 83.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.92515, tacc(al2) 0.88024, tacc(ob0) 0.97800, tacc(ob1) 0.94400, tacc(ob2) 0.84000, tacc(ob3) 0.96800, 6.03 secs\n",
      "\u001b[1m---- Epoch 65/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.16893, triplet_loss 0.43824, c_loss 0.34345, hs_loss 0.42062, cs_loss 1.13556, cacc 0.91350, hsacc 0.89463, csacc 0.66560, 88.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93114, tacc(al2) 0.88623, tacc(ob0) 0.98000, tacc(ob1) 0.93800, tacc(ob2) 0.83600, tacc(ob3) 0.97200, 6.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_65_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9230.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 66/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.16223, triplet_loss 0.43815, c_loss 0.33068, hs_loss 0.42209, cs_loss 1.13355, cacc 0.91568, hsacc 0.88955, csacc 0.66797, 99.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93114, tacc(al2) 0.88323, tacc(ob0) 0.98000, tacc(ob1) 0.94200, tacc(ob2) 0.84000, tacc(ob3) 0.97400, 5.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_66_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9239.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 67/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.15856, triplet_loss 0.43880, c_loss 0.33293, hs_loss 0.41905, cs_loss 1.12634, cacc 0.91360, hsacc 0.89210, csacc 0.67322, 102.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93114, tacc(al2) 0.88623, tacc(ob0) 0.98000, tacc(ob1) 0.94000, tacc(ob2) 0.83800, tacc(ob3) 0.97000, 6.22 secs\n",
      "\u001b[1m---- Epoch 68/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.16147, triplet_loss 0.43961, c_loss 0.33210, hs_loss 0.42566, cs_loss 1.12556, cacc 0.91343, hsacc 0.89092, csacc 0.67027, 84.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99401, tacc(al1) 0.93114, tacc(al2) 0.88623, tacc(ob0) 0.98000, tacc(ob1) 0.94000, tacc(ob2) 0.84000, tacc(ob3) 0.96800, 6.13 secs\n",
      "\u001b[1m---- Epoch 69/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.17491, triplet_loss 0.44224, c_loss 0.33448, hs_loss 0.43291, cs_loss 1.14019, cacc 0.91487, hsacc 0.88940, csacc 0.65885, 80.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99701, tacc(al1) 0.91617, tacc(al2) 0.88024, tacc(ob0) 0.98400, tacc(ob1) 0.94600, tacc(ob2) 0.83600, tacc(ob3) 0.97400, 5.30 secs\n",
      "\u001b[1m---- Epoch 70/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.15876, triplet_loss 0.43869, c_loss 0.32981, hs_loss 0.42265, cs_loss 1.12636, cacc 0.91030, hsacc 0.88658, csacc 0.66335, 84.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92515, tacc(al2) 0.87425, tacc(ob0) 0.98400, tacc(ob1) 0.96000, tacc(ob2) 0.84200, tacc(ob3) 0.97400, 5.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_70_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9242.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 71/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.13995, triplet_loss 0.43881, c_loss 0.31892, hs_loss 0.41338, cs_loss 1.10879, cacc 0.91607, hsacc 0.89225, csacc 0.66880, 83.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.91916, tacc(al2) 0.87425, tacc(ob0) 0.98000, tacc(ob1) 0.95600, tacc(ob2) 0.84600, tacc(ob3) 0.97400, 6.25 secs\n",
      "\u001b[1m---- Epoch 72/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.13319, triplet_loss 0.43940, c_loss 0.32206, hs_loss 0.41482, cs_loss 1.09009, cacc 0.91770, hsacc 0.88955, csacc 0.67273, 91.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98802, tacc(al1) 0.92515, tacc(al2) 0.88024, tacc(ob0) 0.98200, tacc(ob1) 0.94800, tacc(ob2) 0.85200, tacc(ob3) 0.97600, 6.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_72_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9250.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 73/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.12491, triplet_loss 0.43847, c_loss 0.31682, hs_loss 0.40927, cs_loss 1.08526, cacc 0.92025, hsacc 0.89302, csacc 0.67437, 126.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99102, tacc(al1) 0.92216, tacc(al2) 0.86826, tacc(ob0) 0.98200, tacc(ob1) 0.94600, tacc(ob2) 0.85000, tacc(ob3) 0.97600, 11.55 secs\n",
      "\u001b[1m---- Epoch 74/82\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "^C iteration 12600\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "    --checkpoint_folder \"models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "    --epochs 40 \\\n",
    "    --batches_per_epoch 400 \\\n",
    "    --batch_size 200 \\\n",
    "    --num_workers 2 \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf75b2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 400\n",
      "   batch_size: 80\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   dataset_name: MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "   triplets_weight: 1.0\n",
      "   classification_weight: 1.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: prominent irregular opacification along the right lateral chest wall\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: Complete disappearance of earlier noted consolidations in the right lower lobe\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: resolved\n",
      "\u001b[1mExample fact: fluid collection in the pleural space at the lower part\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: greater than normal fluid in the left side\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: worsened\n",
      "\u001b[1mExample fact: Potential slight worsening of atelectasis in the left base\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: worsened\n",
      "\u001b[1mExample fact: prior surgical procedure in the mid trachea\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: medial opacity\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: unobstructed central airways\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: opacification not well localized on the lateral view\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: ambiguous\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: There has been a progression in the parenchymal consolidations compared to the previous imaging\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: increase\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_045133_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_045133_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_72_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9250.pt', 'checkpoint_42_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9201.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_72_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)=0.9250.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_045133_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.22880, triplet_loss 0.45542, c_loss 0.33476, hs_loss 0.45061, cs_loss 1.21680, cacc 0.91681, hsacc 0.87294, csacc 0.64075, 51.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.92400, tacc(al2) 0.87500, tacc(ob0) 0.97400, tacc(ob1) 0.94000, tacc(ob2) 0.86900, tacc(ob3) 0.98000, tacc(ob4) 0.90900, 6.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9204.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.22613, triplet_loss 0.45501, c_loss 0.32306, hs_loss 0.45390, cs_loss 1.22029, cacc 0.91175, hsacc 0.87313, csacc 0.62731, 49.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.92600, tacc(al2) 0.87800, tacc(ob0) 0.97500, tacc(ob1) 0.94200, tacc(ob2) 0.86200, tacc(ob3) 0.98000, tacc(ob4) 0.90700, 6.59 secs\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.21733, triplet_loss 0.45470, c_loss 0.32814, hs_loss 0.46505, cs_loss 1.18677, cacc 0.91144, hsacc 0.87100, csacc 0.64094, 49.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.92600, tacc(al2) 0.87900, tacc(ob0) 0.97700, tacc(ob1) 0.93800, tacc(ob2) 0.86400, tacc(ob3) 0.97700, tacc(ob4) 0.92000, 6.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9214.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.23806, triplet_loss 0.45816, c_loss 0.34126, hs_loss 0.47589, cs_loss 1.20081, cacc 0.91181, hsacc 0.86700, csacc 0.63294, 46.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.92300, tacc(al2) 0.86500, tacc(ob0) 0.97000, tacc(ob1) 0.94200, tacc(ob2) 0.86700, tacc(ob3) 0.98100, tacc(ob4) 0.90600, 6.76 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 1.21442, triplet_loss 0.45583, c_loss 0.32931, hs_loss 0.47450, cs_loss 1.16921, cacc 0.90731, hsacc 0.86744, csacc 0.63013, 50.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.91800, tacc(al2) 0.86600, tacc(ob0) 0.97700, tacc(ob1) 0.94500, tacc(ob2) 0.86600, tacc(ob3) 0.97800, tacc(ob4) 0.91400, 6.75 secs\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.19710, triplet_loss 0.45186, c_loss 0.33631, hs_loss 0.44423, cs_loss 1.16179, cacc 0.91206, hsacc 0.87175, csacc 0.63913, 50.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.92300, tacc(al2) 0.86400, tacc(ob0) 0.97600, tacc(ob1) 0.94500, tacc(ob2) 0.86400, tacc(ob3) 0.97600, tacc(ob4) 0.91600, 6.79 secs\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 1.17031, triplet_loss 0.45266, c_loss 0.30281, hs_loss 0.43928, cs_loss 1.14588, cacc 0.91225, hsacc 0.87175, csacc 0.64538, 50.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.92100, tacc(al2) 0.86200, tacc(ob0) 0.97600, tacc(ob1) 0.95000, tacc(ob2) 0.86600, tacc(ob3) 0.97900, tacc(ob4) 0.91700, 6.74 secs\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.17447, triplet_loss 0.45061, c_loss 0.30848, hs_loss 0.45150, cs_loss 1.13834, cacc 0.91344, hsacc 0.87156, csacc 0.65069, 50.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.92200, tacc(al2) 0.86400, tacc(ob0) 0.97700, tacc(ob1) 0.94500, tacc(ob2) 0.87000, tacc(ob3) 0.98000, tacc(ob4) 0.91700, 6.83 secs\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.16579, triplet_loss 0.44926, c_loss 0.30670, hs_loss 0.44565, cs_loss 1.12996, cacc 0.91506, hsacc 0.87294, csacc 0.64581, 51.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.92500, tacc(al2) 0.86200, tacc(ob0) 0.97600, tacc(ob1) 0.94700, tacc(ob2) 0.87000, tacc(ob3) 0.98000, tacc(ob4) 0.91600, 6.93 secs\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.17173, triplet_loss 0.45031, c_loss 0.29664, hs_loss 0.45029, cs_loss 1.14622, cacc 0.91569, hsacc 0.87106, csacc 0.63925, 51.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.92400, tacc(al2) 0.86300, tacc(ob0) 0.97800, tacc(ob1) 0.94800, tacc(ob2) 0.87200, tacc(ob3) 0.98100, tacc(ob4) 0.91500, 6.98 secs\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.16001, triplet_loss 0.45085, c_loss 0.29569, hs_loss 0.45086, cs_loss 1.12262, cacc 0.91669, hsacc 0.86769, csacc 0.64431, 51.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.92500, tacc(al2) 0.86200, tacc(ob0) 0.97800, tacc(ob1) 0.94600, tacc(ob2) 0.87100, tacc(ob3) 0.98000, tacc(ob4) 0.91300, 6.97 secs\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.17202, triplet_loss 0.45140, c_loss 0.31561, hs_loss 0.44551, cs_loss 1.13152, cacc 0.91894, hsacc 0.86806, csacc 0.64900, 51.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.92500, tacc(al2) 0.86100, tacc(ob0) 0.97800, tacc(ob1) 0.94700, tacc(ob2) 0.87100, tacc(ob3) 0.98000, tacc(ob4) 0.91500, 7.04 secs\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.19389, triplet_loss 0.45340, c_loss 0.32025, hs_loss 0.45822, cs_loss 1.15592, cacc 0.90725, hsacc 0.86475, csacc 0.63775, 50.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92400, tacc(al2) 0.86600, tacc(ob0) 0.98000, tacc(ob1) 0.94400, tacc(ob2) 0.86600, tacc(ob3) 0.97700, tacc(ob4) 0.91100, 7.01 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.18089, triplet_loss 0.45596, c_loss 0.30729, hs_loss 0.45154, cs_loss 1.14700, cacc 0.91450, hsacc 0.86725, csacc 0.63444, 50.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92400, tacc(al2) 0.84900, tacc(ob0) 0.97800, tacc(ob1) 0.95000, tacc(ob2) 0.86300, tacc(ob3) 0.97500, tacc(ob4) 0.91600, 7.12 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.16436, triplet_loss 0.45139, c_loss 0.28146, hs_loss 0.46121, cs_loss 1.13466, cacc 0.91919, hsacc 0.86638, csacc 0.64044, 50.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93100, tacc(al2) 0.85800, tacc(ob0) 0.97700, tacc(ob1) 0.95200, tacc(ob2) 0.86400, tacc(ob3) 0.97700, tacc(ob4) 0.91800, 6.90 secs\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.15318, triplet_loss 0.45213, c_loss 0.30530, hs_loss 0.43358, cs_loss 1.11534, cacc 0.91706, hsacc 0.87862, csacc 0.64463, 50.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.92600, tacc(al2) 0.85400, tacc(ob0) 0.97700, tacc(ob1) 0.95100, tacc(ob2) 0.86800, tacc(ob3) 0.97800, tacc(ob4) 0.91300, 7.07 secs\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.13593, triplet_loss 0.45063, c_loss 0.28775, hs_loss 0.42331, cs_loss 1.11018, cacc 0.91894, hsacc 0.88175, csacc 0.64856, 52.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.92900, tacc(al2) 0.85300, tacc(ob0) 0.97600, tacc(ob1) 0.94900, tacc(ob2) 0.87400, tacc(ob3) 0.97700, tacc(ob4) 0.91600, 7.04 secs\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.13219, triplet_loss 0.45215, c_loss 0.28875, hs_loss 0.41612, cs_loss 1.10736, cacc 0.91750, hsacc 0.88269, csacc 0.65706, 52.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.92900, tacc(al2) 0.85500, tacc(ob0) 0.97700, tacc(ob1) 0.94700, tacc(ob2) 0.87100, tacc(ob3) 0.97600, tacc(ob4) 0.91300, 7.08 secs\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.13588, triplet_loss 0.45105, c_loss 0.29071, hs_loss 0.43660, cs_loss 1.09340, cacc 0.91300, hsacc 0.87287, csacc 0.66038, 51.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.92700, tacc(al2) 0.85600, tacc(ob0) 0.97700, tacc(ob1) 0.94800, tacc(ob2) 0.87500, tacc(ob3) 0.97500, tacc(ob4) 0.91500, 6.92 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.13131, triplet_loss 0.45040, c_loss 0.27947, hs_loss 0.42761, cs_loss 1.10515, cacc 0.92012, hsacc 0.87894, csacc 0.65125, 52.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.92800, tacc(al2) 0.85600, tacc(ob0) 0.97700, tacc(ob1) 0.94900, tacc(ob2) 0.87200, tacc(ob3) 0.97500, tacc(ob4) 0.91400, 6.97 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.17986, triplet_loss 0.45392, c_loss 0.32257, hs_loss 0.43843, cs_loss 1.14480, cacc 0.90663, hsacc 0.87206, csacc 0.63738, 52.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92700, tacc(al2) 0.86200, tacc(ob0) 0.98000, tacc(ob1) 0.95100, tacc(ob2) 0.85500, tacc(ob3) 0.97800, tacc(ob4) 0.92000, 7.08 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.17535, triplet_loss 0.45183, c_loss 0.30876, hs_loss 0.45072, cs_loss 1.13938, cacc 0.90987, hsacc 0.86581, csacc 0.63631, 51.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92900, tacc(al2) 0.84800, tacc(ob0) 0.97400, tacc(ob1) 0.94700, tacc(ob2) 0.86500, tacc(ob3) 0.97700, tacc(ob4) 0.92000, 7.06 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.13125, triplet_loss 0.45401, c_loss 0.27285, hs_loss 0.43229, cs_loss 1.10336, cacc 0.91587, hsacc 0.87519, csacc 0.64838, 51.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92800, tacc(al2) 0.85100, tacc(ob0) 0.98000, tacc(ob1) 0.95300, tacc(ob2) 0.86700, tacc(ob3) 0.98100, tacc(ob4) 0.91900, 6.99 secs\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.11983, triplet_loss 0.45285, c_loss 0.28006, hs_loss 0.41901, cs_loss 1.08774, cacc 0.91650, hsacc 0.87369, csacc 0.65400, 51.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.92800, tacc(al2) 0.85400, tacc(ob0) 0.98100, tacc(ob1) 0.95500, tacc(ob2) 0.86400, tacc(ob3) 0.97900, tacc(ob4) 0.92200, 7.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9217.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.11527, triplet_loss 0.45220, c_loss 0.28049, hs_loss 0.42601, cs_loss 1.07184, cacc 0.91669, hsacc 0.87256, csacc 0.65750, 51.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.92700, tacc(al2) 0.85300, tacc(ob0) 0.97800, tacc(ob1) 0.95400, tacc(ob2) 0.86800, tacc(ob3) 0.98100, tacc(ob4) 0.92000, 7.10 secs\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.12586, triplet_loss 0.45258, c_loss 0.28219, hs_loss 0.43620, cs_loss 1.08075, cacc 0.91712, hsacc 0.87287, csacc 0.65675, 52.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.92800, tacc(al2) 0.85400, tacc(ob0) 0.97800, tacc(ob1) 0.95400, tacc(ob2) 0.86700, tacc(ob3) 0.97900, tacc(ob4) 0.91800, 7.04 secs\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.12272, triplet_loss 0.45267, c_loss 0.29502, hs_loss 0.41948, cs_loss 1.07827, cacc 0.91575, hsacc 0.87387, csacc 0.65625, 51.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.92800, tacc(al2) 0.85400, tacc(ob0) 0.97800, tacc(ob1) 0.95600, tacc(ob2) 0.86900, tacc(ob3) 0.98000, tacc(ob4) 0.92100, 7.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9220.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.10789, triplet_loss 0.45309, c_loss 0.27983, hs_loss 0.41738, cs_loss 1.06549, cacc 0.91225, hsacc 0.87644, csacc 0.66119, 50.92 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.92800, tacc(al2) 0.85600, tacc(ob0) 0.97800, tacc(ob1) 0.95700, tacc(ob2) 0.86800, tacc(ob3) 0.98000, tacc(ob4) 0.92100, 6.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9224.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.13706, triplet_loss 0.45370, c_loss 0.27350, hs_loss 0.43787, cs_loss 1.10905, cacc 0.91300, hsacc 0.86919, csacc 0.64169, 51.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97900, tacc(al1) 0.93400, tacc(al2) 0.85100, tacc(ob0) 0.98000, tacc(ob1) 0.95600, tacc(ob2) 0.86200, tacc(ob3) 0.97700, tacc(ob4) 0.91000, 7.00 secs\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.12897, triplet_loss 0.45260, c_loss 0.27210, hs_loss 0.43566, cs_loss 1.09759, cacc 0.91831, hsacc 0.86681, csacc 0.64925, 52.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93100, tacc(al2) 0.84300, tacc(ob0) 0.97900, tacc(ob1) 0.95700, tacc(ob2) 0.87100, tacc(ob3) 0.98000, tacc(ob4) 0.91900, 6.87 secs\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.11707, triplet_loss 0.44936, c_loss 0.26707, hs_loss 0.43005, cs_loss 1.08768, cacc 0.92344, hsacc 0.87050, csacc 0.64794, 51.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93100, tacc(al2) 0.85600, tacc(ob0) 0.98100, tacc(ob1) 0.95600, tacc(ob2) 0.86900, tacc(ob3) 0.97500, tacc(ob4) 0.92300, 6.99 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.09527, triplet_loss 0.45047, c_loss 0.27041, hs_loss 0.41700, cs_loss 1.05265, cacc 0.91975, hsacc 0.87469, csacc 0.66538, 50.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93000, tacc(al2) 0.84600, tacc(ob0) 0.97900, tacc(ob1) 0.95200, tacc(ob2) 0.86000, tacc(ob3) 0.97700, tacc(ob4) 0.92200, 7.16 secs\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.09625, triplet_loss 0.45081, c_loss 0.26727, hs_loss 0.42164, cs_loss 1.05278, cacc 0.92525, hsacc 0.87456, csacc 0.66544, 52.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92900, tacc(al2) 0.85100, tacc(ob0) 0.98200, tacc(ob1) 0.95500, tacc(ob2) 0.85700, tacc(ob3) 0.97700, tacc(ob4) 0.92200, 7.16 secs\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.08732, triplet_loss 0.45094, c_loss 0.27049, hs_loss 0.41070, cs_loss 1.04251, cacc 0.92506, hsacc 0.87931, csacc 0.66994, 51.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.92600, tacc(al2) 0.85200, tacc(ob0) 0.98100, tacc(ob1) 0.95500, tacc(ob2) 0.86100, tacc(ob3) 0.97800, tacc(ob4) 0.92100, 7.17 secs\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.08436, triplet_loss 0.45207, c_loss 0.25936, hs_loss 0.40511, cs_loss 1.05220, cacc 0.92388, hsacc 0.87356, csacc 0.66212, 50.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.92700, tacc(al2) 0.85000, tacc(ob0) 0.98000, tacc(ob1) 0.95600, tacc(ob2) 0.85700, tacc(ob3) 0.97800, tacc(ob4) 0.92000, 7.12 secs\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.09287, triplet_loss 0.44854, c_loss 0.26164, hs_loss 0.42090, cs_loss 1.05467, cacc 0.92381, hsacc 0.87687, csacc 0.66419, 51.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92700, tacc(al2) 0.84900, tacc(ob0) 0.98100, tacc(ob1) 0.95600, tacc(ob2) 0.85700, tacc(ob3) 0.97800, tacc(ob4) 0.92000, 7.19 secs\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.13382, triplet_loss 0.45436, c_loss 0.28107, hs_loss 0.45169, cs_loss 1.08053, cacc 0.91456, hsacc 0.86325, csacc 0.65250, 52.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93000, tacc(al2) 0.85200, tacc(ob0) 0.97600, tacc(ob1) 0.95100, tacc(ob2) 0.86200, tacc(ob3) 0.97300, tacc(ob4) 0.91600, 7.05 secs\n",
      "\u001b[1m---- Epoch 38/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.10889, triplet_loss 0.45147, c_loss 0.27482, hs_loss 0.41824, cs_loss 1.07326, cacc 0.91938, hsacc 0.87075, csacc 0.65244, 51.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93800, tacc(al2) 0.85300, tacc(ob0) 0.98300, tacc(ob1) 0.94900, tacc(ob2) 0.87600, tacc(ob3) 0.97800, tacc(ob4) 0.91800, 7.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_38_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9227.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 39/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.10692, triplet_loss 0.45180, c_loss 0.26055, hs_loss 0.42731, cs_loss 1.07417, cacc 0.92319, hsacc 0.87313, csacc 0.65212, 50.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93100, tacc(al2) 0.84700, tacc(ob0) 0.98200, tacc(ob1) 0.95500, tacc(ob2) 0.87100, tacc(ob3) 0.97500, tacc(ob4) 0.92100, 6.92 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 40/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.09332, triplet_loss 0.45135, c_loss 0.26455, hs_loss 0.41365, cs_loss 1.05710, cacc 0.92000, hsacc 0.87613, csacc 0.65463, 51.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93300, tacc(al2) 0.84400, tacc(ob0) 0.98300, tacc(ob1) 0.95200, tacc(ob2) 0.86800, tacc(ob3) 0.97600, tacc(ob4) 0.92700, 6.81 secs\n",
      "\u001b[1m---- Epoch 41/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.08246, triplet_loss 0.44927, c_loss 0.27170, hs_loss 0.40423, cs_loss 1.03973, cacc 0.91912, hsacc 0.87981, csacc 0.66912, 51.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93400, tacc(al2) 0.84000, tacc(ob0) 0.98300, tacc(ob1) 0.95200, tacc(ob2) 0.87100, tacc(ob3) 0.97600, tacc(ob4) 0.92400, 6.98 secs\n",
      "\u001b[1m---- Epoch 42/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.06859, triplet_loss 0.45072, c_loss 0.25365, hs_loss 0.40851, cs_loss 1.02431, cacc 0.92275, hsacc 0.87987, csacc 0.67050, 51.76 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93400, tacc(al2) 0.84100, tacc(ob0) 0.98200, tacc(ob1) 0.95300, tacc(ob2) 0.87200, tacc(ob3) 0.97500, tacc(ob4) 0.92400, 6.97 secs\n",
      "\u001b[1m---- Epoch 43/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.07806, triplet_loss 0.45049, c_loss 0.27202, hs_loss 0.41278, cs_loss 1.02083, cacc 0.92081, hsacc 0.87619, csacc 0.67063, 51.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93500, tacc(al2) 0.83900, tacc(ob0) 0.98200, tacc(ob1) 0.95200, tacc(ob2) 0.87100, tacc(ob3) 0.97600, tacc(ob4) 0.92300, 6.98 secs\n",
      "\u001b[1m---- Epoch 44/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.07574, triplet_loss 0.45108, c_loss 0.26366, hs_loss 0.40550, cs_loss 1.03125, cacc 0.92337, hsacc 0.87575, csacc 0.66744, 51.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93500, tacc(al2) 0.83700, tacc(ob0) 0.98200, tacc(ob1) 0.95300, tacc(ob2) 0.87100, tacc(ob3) 0.97600, tacc(ob4) 0.92400, 7.07 secs\n",
      "\u001b[1m---- Epoch 45/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.11295, triplet_loss 0.45142, c_loss 0.27732, hs_loss 0.43509, cs_loss 1.06206, cacc 0.92325, hsacc 0.86956, csacc 0.65512, 51.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93500, tacc(al2) 0.85000, tacc(ob0) 0.98200, tacc(ob1) 0.94500, tacc(ob2) 0.86200, tacc(ob3) 0.97600, tacc(ob4) 0.91800, 6.94 secs\n",
      "\u001b[1m---- Epoch 46/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.10116, triplet_loss 0.45179, c_loss 0.26729, hs_loss 0.41569, cs_loss 1.06755, cacc 0.92600, hsacc 0.87038, csacc 0.64981, 52.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93200, tacc(al2) 0.85000, tacc(ob0) 0.98600, tacc(ob1) 0.95700, tacc(ob2) 0.86300, tacc(ob3) 0.98200, tacc(ob4) 0.92500, 7.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_46_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9227.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 47/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.07100, triplet_loss 0.45163, c_loss 0.25116, hs_loss 0.41182, cs_loss 1.02739, cacc 0.92463, hsacc 0.87475, csacc 0.66663, 49.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93500, tacc(al2) 0.84800, tacc(ob0) 0.98400, tacc(ob1) 0.95800, tacc(ob2) 0.87300, tacc(ob3) 0.98100, tacc(ob4) 0.92300, 7.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_47_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9244.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 48/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.06426, triplet_loss 0.44994, c_loss 0.25581, hs_loss 0.40190, cs_loss 1.02088, cacc 0.92519, hsacc 0.88119, csacc 0.66887, 49.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93700, tacc(al2) 0.84600, tacc(ob0) 0.98600, tacc(ob1) 0.95400, tacc(ob2) 0.86500, tacc(ob3) 0.98000, tacc(ob4) 0.92900, 7.05 secs\n",
      "\u001b[1m---- Epoch 49/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.06009, triplet_loss 0.45191, c_loss 0.24778, hs_loss 0.40771, cs_loss 1.01278, cacc 0.92925, hsacc 0.88138, csacc 0.66506, 49.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93900, tacc(al2) 0.84400, tacc(ob0) 0.98500, tacc(ob1) 0.95700, tacc(ob2) 0.87000, tacc(ob3) 0.98300, tacc(ob4) 0.92400, 7.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9245.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.05516, triplet_loss 0.45195, c_loss 0.24786, hs_loss 0.40658, cs_loss 1.00393, cacc 0.92806, hsacc 0.87625, csacc 0.67394, 49.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93800, tacc(al2) 0.84300, tacc(ob0) 0.98500, tacc(ob1) 0.95400, tacc(ob2) 0.87400, tacc(ob3) 0.98200, tacc(ob4) 0.92500, 7.09 secs\n",
      "\u001b[1m---- Epoch 51/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.06738, triplet_loss 0.45054, c_loss 0.26000, hs_loss 0.40620, cs_loss 1.01802, cacc 0.92400, hsacc 0.87750, csacc 0.66981, 50.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94000, tacc(al2) 0.84200, tacc(ob0) 0.98500, tacc(ob1) 0.95600, tacc(ob2) 0.87400, tacc(ob3) 0.98200, tacc(ob4) 0.92500, 6.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_51_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9246.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 52/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.05972, triplet_loss 0.44911, c_loss 0.25537, hs_loss 0.39583, cs_loss 1.01914, cacc 0.92650, hsacc 0.87881, csacc 0.66700, 49.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94100, tacc(al2) 0.84200, tacc(ob0) 0.98500, tacc(ob1) 0.95600, tacc(ob2) 0.87400, tacc(ob3) 0.98200, tacc(ob4) 0.92600, 6.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_52_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9249.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 53/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.07694, triplet_loss 0.45195, c_loss 0.23681, hs_loss 0.41892, cs_loss 1.04620, cacc 0.92237, hsacc 0.87619, csacc 0.65500, 48.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.93700, tacc(al2) 0.84600, tacc(ob0) 0.98600, tacc(ob1) 0.94300, tacc(ob2) 0.87200, tacc(ob3) 0.98000, tacc(ob4) 0.92000, 6.97 secs\n",
      "\u001b[1m---- Epoch 54/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.07854, triplet_loss 0.45112, c_loss 0.25840, hs_loss 0.40430, cs_loss 1.04327, cacc 0.92363, hsacc 0.87275, csacc 0.65863, 51.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94500, tacc(al2) 0.84200, tacc(ob0) 0.98400, tacc(ob1) 0.95400, tacc(ob2) 0.87600, tacc(ob3) 0.98200, tacc(ob4) 0.92800, 6.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_54_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9256.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 55/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.05516, triplet_loss 0.45111, c_loss 0.24512, hs_loss 0.40158, cs_loss 1.01251, cacc 0.92250, hsacc 0.87213, csacc 0.66712, 51.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94000, tacc(al2) 0.84000, tacc(ob0) 0.98600, tacc(ob1) 0.95700, tacc(ob2) 0.87400, tacc(ob3) 0.97800, tacc(ob4) 0.92800, 7.09 secs\n",
      "\u001b[1m---- Epoch 56/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.05116, triplet_loss 0.44891, c_loss 0.24996, hs_loss 0.40483, cs_loss 0.99862, cacc 0.92250, hsacc 0.87500, csacc 0.67150, 52.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.84500, tacc(ob0) 0.98500, tacc(ob1) 0.96000, tacc(ob2) 0.87100, tacc(ob3) 0.98100, tacc(ob4) 0.92600, 7.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_56_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9259.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 57/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.04102, triplet_loss 0.45251, c_loss 0.24225, hs_loss 0.39145, cs_loss 0.99584, cacc 0.92056, hsacc 0.88087, csacc 0.67537, 50.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.84200, tacc(ob0) 0.98500, tacc(ob1) 0.95700, tacc(ob2) 0.86400, tacc(ob3) 0.98100, tacc(ob4) 0.92800, 7.10 secs\n",
      "\u001b[1m---- Epoch 58/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.04743, triplet_loss 0.45049, c_loss 0.23738, hs_loss 0.40454, cs_loss 1.00244, cacc 0.92575, hsacc 0.88419, csacc 0.67050, 52.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94200, tacc(al2) 0.84100, tacc(ob0) 0.98700, tacc(ob1) 0.95600, tacc(ob2) 0.86600, tacc(ob3) 0.98100, tacc(ob4) 0.93000, 7.14 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 59/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.04710, triplet_loss 0.44925, c_loss 0.25657, hs_loss 0.39626, cs_loss 0.99212, cacc 0.92950, hsacc 0.87656, csacc 0.67106, 51.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.84000, tacc(ob0) 0.98600, tacc(ob1) 0.95700, tacc(ob2) 0.86600, tacc(ob3) 0.98200, tacc(ob4) 0.93000, 6.83 secs\n",
      "\u001b[1m---- Epoch 60/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.04702, triplet_loss 0.44970, c_loss 0.24903, hs_loss 0.39334, cs_loss 1.00196, cacc 0.92506, hsacc 0.87400, csacc 0.67138, 51.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.84000, tacc(ob0) 0.98500, tacc(ob1) 0.95700, tacc(ob2) 0.86600, tacc(ob3) 0.98100, tacc(ob4) 0.93000, 6.95 secs\n",
      "\u001b[1m---- Epoch 61/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.08219, triplet_loss 0.45488, c_loss 0.25121, hs_loss 0.41368, cs_loss 1.04460, cacc 0.93137, hsacc 0.87300, csacc 0.65506, 51.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94200, tacc(al2) 0.84000, tacc(ob0) 0.98300, tacc(ob1) 0.95200, tacc(ob2) 0.86400, tacc(ob3) 0.97700, tacc(ob4) 0.92500, 7.02 secs\n",
      "\u001b[1m---- Epoch 62/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.07309, triplet_loss 0.45376, c_loss 0.25706, hs_loss 0.40901, cs_loss 1.02635, cacc 0.92400, hsacc 0.86950, csacc 0.65844, 52.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93700, tacc(al2) 0.84800, tacc(ob0) 0.98100, tacc(ob1) 0.95800, tacc(ob2) 0.86200, tacc(ob3) 0.97800, tacc(ob4) 0.92100, 6.99 secs\n",
      "\u001b[1m---- Epoch 63/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.04928, triplet_loss 0.45267, c_loss 0.24660, hs_loss 0.39926, cs_loss 1.00002, cacc 0.92619, hsacc 0.87438, csacc 0.67156, 51.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94000, tacc(al2) 0.84300, tacc(ob0) 0.98300, tacc(ob1) 0.96000, tacc(ob2) 0.86200, tacc(ob3) 0.98100, tacc(ob4) 0.92800, 7.00 secs\n",
      "\u001b[1m---- Epoch 64/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.03947, triplet_loss 0.45060, c_loss 0.24091, hs_loss 0.39275, cs_loss 0.99467, cacc 0.92919, hsacc 0.87950, csacc 0.67319, 51.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93800, tacc(al2) 0.84200, tacc(ob0) 0.98400, tacc(ob1) 0.95700, tacc(ob2) 0.86500, tacc(ob3) 0.97800, tacc(ob4) 0.93200, 6.95 secs\n",
      "\u001b[1m---- Epoch 65/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.02626, triplet_loss 0.44894, c_loss 0.23806, hs_loss 0.38842, cs_loss 0.97710, cacc 0.93137, hsacc 0.87981, csacc 0.68244, 50.76 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93500, tacc(al2) 0.84500, tacc(ob0) 0.98300, tacc(ob1) 0.95700, tacc(ob2) 0.86400, tacc(ob3) 0.97900, tacc(ob4) 0.92700, 7.15 secs\n",
      "\u001b[1m---- Epoch 66/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.01145, triplet_loss 0.45074, c_loss 0.23362, hs_loss 0.37531, cs_loss 0.96323, cacc 0.93019, hsacc 0.87900, csacc 0.67994, 52.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93600, tacc(al2) 0.84500, tacc(ob0) 0.98300, tacc(ob1) 0.95800, tacc(ob2) 0.86300, tacc(ob3) 0.98000, tacc(ob4) 0.92800, 7.13 secs\n",
      "\u001b[1m---- Epoch 67/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.04122, triplet_loss 0.45075, c_loss 0.23681, hs_loss 0.39631, cs_loss 0.99857, cacc 0.93181, hsacc 0.87969, csacc 0.67544, 52.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.93500, tacc(al2) 0.84400, tacc(ob0) 0.98300, tacc(ob1) 0.95900, tacc(ob2) 0.86400, tacc(ob3) 0.97800, tacc(ob4) 0.92700, 7.17 secs\n",
      "\u001b[1m---- Epoch 68/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.02579, triplet_loss 0.45018, c_loss 0.23233, hs_loss 0.38182, cs_loss 0.98726, cacc 0.93012, hsacc 0.87787, csacc 0.67050, 52.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93600, tacc(al2) 0.84300, tacc(ob0) 0.98300, tacc(ob1) 0.95900, tacc(ob2) 0.86500, tacc(ob3) 0.97900, tacc(ob4) 0.92800, 7.12 secs\n",
      "\u001b[1m---- Epoch 69/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.04725, triplet_loss 0.45150, c_loss 0.23109, hs_loss 0.40155, cs_loss 1.01035, cacc 0.92600, hsacc 0.87556, csacc 0.66275, 52.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93600, tacc(al2) 0.84400, tacc(ob0) 0.98200, tacc(ob1) 0.95000, tacc(ob2) 0.86600, tacc(ob3) 0.98100, tacc(ob4) 0.92100, 7.12 secs\n",
      "\u001b[1m---- Epoch 70/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.04464, triplet_loss 0.45205, c_loss 0.24293, hs_loss 0.40208, cs_loss 0.99222, cacc 0.92875, hsacc 0.87262, csacc 0.67231, 51.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94200, tacc(al2) 0.84700, tacc(ob0) 0.98700, tacc(ob1) 0.95800, tacc(ob2) 0.87000, tacc(ob3) 0.98100, tacc(ob4) 0.92700, 7.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_70_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9261.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 71/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.04569, triplet_loss 0.45157, c_loss 0.23818, hs_loss 0.41803, cs_loss 0.98359, cacc 0.92888, hsacc 0.87356, csacc 0.67656, 51.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93800, tacc(al2) 0.83700, tacc(ob0) 0.98500, tacc(ob1) 0.95700, tacc(ob2) 0.86600, tacc(ob3) 0.98100, tacc(ob4) 0.93100, 6.87 secs\n",
      "\u001b[1m---- Epoch 72/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.03548, triplet_loss 0.45179, c_loss 0.24578, hs_loss 0.40222, cs_loss 0.97115, cacc 0.92888, hsacc 0.87862, csacc 0.67700, 51.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93600, tacc(al2) 0.84100, tacc(ob0) 0.98500, tacc(ob1) 0.96000, tacc(ob2) 0.86400, tacc(ob3) 0.98500, tacc(ob4) 0.93000, 7.07 secs\n",
      "\u001b[1m---- Epoch 73/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.01442, triplet_loss 0.44898, c_loss 0.23328, hs_loss 0.38678, cs_loss 0.95981, cacc 0.93100, hsacc 0.88419, csacc 0.68306, 52.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93400, tacc(al2) 0.84200, tacc(ob0) 0.98600, tacc(ob1) 0.95800, tacc(ob2) 0.86700, tacc(ob3) 0.98300, tacc(ob4) 0.93200, 6.85 secs\n",
      "\u001b[1m---- Epoch 74/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.02227, triplet_loss 0.44718, c_loss 0.23213, hs_loss 0.37584, cs_loss 0.98938, cacc 0.93150, hsacc 0.88638, csacc 0.66794, 51.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93300, tacc(al2) 0.84100, tacc(ob0) 0.98600, tacc(ob1) 0.95800, tacc(ob2) 0.86500, tacc(ob3) 0.98200, tacc(ob4) 0.93200, 6.99 secs\n",
      "\u001b[1m---- Epoch 75/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.00744, triplet_loss 0.44822, c_loss 0.23733, hs_loss 0.37305, cs_loss 0.95628, cacc 0.92988, hsacc 0.88231, csacc 0.68531, 51.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93500, tacc(al2) 0.84000, tacc(ob0) 0.98600, tacc(ob1) 0.95700, tacc(ob2) 0.86600, tacc(ob3) 0.98200, tacc(ob4) 0.93200, 7.06 secs\n",
      "\u001b[1m---- Epoch 76/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.01087, triplet_loss 0.44831, c_loss 0.22926, hs_loss 0.37883, cs_loss 0.96534, cacc 0.92788, hsacc 0.88575, csacc 0.67937, 51.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.93400, tacc(al2) 0.83800, tacc(ob0) 0.98700, tacc(ob1) 0.95900, tacc(ob2) 0.86700, tacc(ob3) 0.98200, tacc(ob4) 0.93300, 7.11 secs\n",
      "\u001b[1m---- Epoch 77/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.05132, triplet_loss 0.45257, c_loss 0.25263, hs_loss 0.40186, cs_loss 0.99557, cacc 0.92412, hsacc 0.87250, csacc 0.66769, 51.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93500, tacc(al2) 0.85000, tacc(ob0) 0.98700, tacc(ob1) 0.95500, tacc(ob2) 0.86700, tacc(ob3) 0.98200, tacc(ob4) 0.92400, 7.00 secs\n",
      "\u001b[1m---- Epoch 78/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 1.04793, triplet_loss 0.44881, c_loss 0.23701, hs_loss 0.42138, cs_loss 0.98866, cacc 0.92206, hsacc 0.86800, csacc 0.66769, 51.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93100, tacc(al2) 0.85300, tacc(ob0) 0.98800, tacc(ob1) 0.95500, tacc(ob2) 0.87000, tacc(ob3) 0.98100, tacc(ob4) 0.93700, 7.05 secs\n",
      "\u001b[1m---- Epoch 79/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.01997, triplet_loss 0.44904, c_loss 0.23358, hs_loss 0.37542, cs_loss 0.98191, cacc 0.92563, hsacc 0.88106, csacc 0.66944, 49.41 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98300, tacc(al1) 0.93200, tacc(al2) 0.84300, tacc(ob0) 0.98600, tacc(ob1) 0.95800, tacc(ob2) 0.85900, tacc(ob3) 0.98100, tacc(ob4) 0.93500, 7.10 secs\n",
      "\u001b[1m---- Epoch 80/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.99661, triplet_loss 0.44946, c_loss 0.22802, hs_loss 0.36781, cs_loss 0.94793, cacc 0.92750, hsacc 0.87975, csacc 0.68294, 49.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93300, tacc(al2) 0.84500, tacc(ob0) 0.98300, tacc(ob1) 0.95700, tacc(ob2) 0.86200, tacc(ob3) 0.98100, tacc(ob4) 0.93100, 7.14 secs\n",
      "\u001b[1m---- Epoch 81/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.01322, triplet_loss 0.44986, c_loss 0.22876, hs_loss 0.38458, cs_loss 0.96324, cacc 0.93288, hsacc 0.87925, csacc 0.68194, 50.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93000, tacc(al2) 0.84700, tacc(ob0) 0.98400, tacc(ob1) 0.95600, tacc(ob2) 0.86200, tacc(ob3) 0.98200, tacc(ob4) 0.93500, 7.01 secs\n",
      "\u001b[1m---- Epoch 82/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.99694, triplet_loss 0.44924, c_loss 0.22994, hs_loss 0.36981, cs_loss 0.94490, cacc 0.92844, hsacc 0.88281, csacc 0.67850, 52.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93000, tacc(al2) 0.84400, tacc(ob0) 0.98500, tacc(ob1) 0.95700, tacc(ob2) 0.86200, tacc(ob3) 0.98200, tacc(ob4) 0.93500, 7.07 secs\n",
      "\u001b[1m---- Epoch 83/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.99561, triplet_loss 0.44858, c_loss 0.22177, hs_loss 0.37209, cs_loss 0.94878, cacc 0.92819, hsacc 0.88294, csacc 0.68306, 51.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93100, tacc(al2) 0.84400, tacc(ob0) 0.98400, tacc(ob1) 0.95700, tacc(ob2) 0.86700, tacc(ob3) 0.98200, tacc(ob4) 0.93500, 6.96 secs\n",
      "\u001b[1m---- Epoch 84/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "Current run is terminating due to exception: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 10.76 GiB total capacity; 8.71 GiB already allocated; 216.56 MiB free; 9.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Engine run is terminating due to exception: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 10.76 GiB total capacity; 8.71 GiB already allocated; 216.56 MiB free; 9.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 463, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 374, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 231, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 121, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1087, in _run_once_on_dataset_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/fact_embedding.py\", line 124, in step_fn_wrapper\n",
      "    output = step_fn__triplet_ranking(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/fact_embedding.py\", line 45, in step_fn__triplet_ranking\n",
      "    n_embeddings = model(input_ids=n_input_ids, attention_mask=n_attention_mask)['text_embeddings']\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/nlp/fact_encoder.py\", line 58, in forward\n",
      "    text_embeddings = self.model.get_projected_text_embeddings(input_ids=input_ids, attention_mask=attention_mask)\n",
      "  File \"/home/pamessina/.cache/huggingface/modules/transformers_modules/microsoft/BiomedVLP-CXR-BERT-specialized/b59c09e51ab2410b24f4be214bbb49043fe63fc2/modeling_cxrbert.py\", line 123, in get_projected_text_embeddings\n",
      "    outputs = self.forward(input_ids=input_ids, attention_mask=attention_mask, \n",
      "  File \"/home/pamessina/.cache/huggingface/modules/transformers_modules/microsoft/BiomedVLP-CXR-BERT-specialized/b59c09e51ab2410b24f4be214bbb49043fe63fc2/modeling_cxrbert.py\", line 84, in forward\n",
      "    bert_for_masked_lm_output = super().forward(input_ids=input_ids,\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1373, in forward\n",
      "    prediction_scores = self.cls(sequence_output)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 710, in forward\n",
      "    prediction_scores = self.predictions(sequence_output)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 700, in forward\n",
      "    hidden_states = self.decoder(hidden_states)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 10.76 GiB total capacity; 8.71 GiB already allocated; 216.56 MiB free; 9.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230719_132018_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 400 \\\n",
    "--batch_size 80 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132aa588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 75\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_045133_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   iters_to_accumulate: 8\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   dataset_name: MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "   triplets_weight: 1.0\n",
      "   classification_weight: 1.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 8\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: increased opacification in the left lower zone has decreased\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: decrease\n",
      "\u001b[1mExample fact: X-ray does not show any indication of tooth aspiration\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: the proximal bronchus intermedius is partially obstructed by the tip of the Dobbhoff feeding tube\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: all other lines in standard positions\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: Multifocal infiltrates are observed in the alveoli\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: Consolidation seen, possibly secondary to aspiration\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: ambiguous\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: postoperative changes projecting over the neck\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: slightly improved atelectasis\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: improved\n",
      "\u001b[1mExample fact: stable small bibasilar effusions\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: patchy relatively confluent opacities\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_061431_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_061431_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_70_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9261.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_045133_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_70_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9261.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_061431_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.02588, triplet_loss 0.45110, c_loss 0.24075, hs_loss 0.38914, cs_loss 0.97076, cacc 0.93293, hsacc 0.87875, csacc 0.68053, 117.42 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94000, tacc(al2) 0.84400, tacc(ob0) 0.98700, tacc(ob1) 0.95900, tacc(ob2) 0.87200, tacc(ob3) 0.98300, tacc(ob4) 0.92800, 6.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9268.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.02187, triplet_loss 0.44861, c_loss 0.24315, hs_loss 0.37860, cs_loss 0.97338, cacc 0.92936, hsacc 0.88147, csacc 0.68067, 121.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93800, tacc(al2) 0.84300, tacc(ob0) 0.98600, tacc(ob1) 0.95700, tacc(ob2) 0.86900, tacc(ob3) 0.98000, tacc(ob4) 0.92900, 7.11 secs\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.01520, triplet_loss 0.44918, c_loss 0.22307, hs_loss 0.38401, cs_loss 0.97412, cacc 0.93083, hsacc 0.87963, csacc 0.67568, 123.31 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93200, tacc(al2) 0.84300, tacc(ob0) 0.98100, tacc(ob1) 0.95800, tacc(ob2) 0.86700, tacc(ob3) 0.97900, tacc(ob4) 0.92700, 7.09 secs\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 1.02659, triplet_loss 0.45243, c_loss 0.22752, hs_loss 0.38916, cs_loss 0.98407, cacc 0.92824, hsacc 0.87603, csacc 0.67187, 120.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93300, tacc(al2) 0.84400, tacc(ob0) 0.98100, tacc(ob1) 0.95700, tacc(ob2) 0.87300, tacc(ob3) 0.97200, tacc(ob4) 0.93400, 7.08 secs\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 1.01621, triplet_loss 0.45117, c_loss 0.22220, hs_loss 0.38565, cs_loss 0.97340, cacc 0.93075, hsacc 0.87803, csacc 0.67757, 122.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93900, tacc(al2) 0.83200, tacc(ob0) 0.98200, tacc(ob1) 0.95400, tacc(ob2) 0.86700, tacc(ob3) 0.98400, tacc(ob4) 0.92900, 6.93 secs\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.99523, triplet_loss 0.45130, c_loss 0.21911, hs_loss 0.36708, cs_loss 0.95297, cacc 0.93029, hsacc 0.88331, csacc 0.68363, 123.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93900, tacc(al2) 0.83200, tacc(ob0) 0.98100, tacc(ob1) 0.95900, tacc(ob2) 0.87100, tacc(ob3) 0.98500, tacc(ob4) 0.93300, 6.92 secs\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.98757, triplet_loss 0.44894, c_loss 0.22577, hs_loss 0.36010, cs_loss 0.94034, cacc 0.93171, hsacc 0.88621, csacc 0.68867, 124.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93300, tacc(al2) 0.83100, tacc(ob0) 0.98300, tacc(ob1) 0.95800, tacc(ob2) 0.87200, tacc(ob3) 0.98300, tacc(ob4) 0.93000, 7.07 secs\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.98659, triplet_loss 0.44794, c_loss 0.21413, hs_loss 0.37335, cs_loss 0.93777, cacc 0.93523, hsacc 0.88021, csacc 0.68584, 124.91 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93900, tacc(al2) 0.83200, tacc(ob0) 0.98200, tacc(ob1) 0.95600, tacc(ob2) 0.87300, tacc(ob3) 0.97900, tacc(ob4) 0.93600, 6.91 secs\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.97228, triplet_loss 0.44771, c_loss 0.21665, hs_loss 0.36024, cs_loss 0.91997, cacc 0.93261, hsacc 0.88643, csacc 0.69304, 123.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94000, tacc(al2) 0.82900, tacc(ob0) 0.98300, tacc(ob1) 0.95800, tacc(ob2) 0.87200, tacc(ob3) 0.98000, tacc(ob4) 0.93100, 6.88 secs\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.97903, triplet_loss 0.44929, c_loss 0.21318, hs_loss 0.36945, cs_loss 0.92613, cacc 0.93331, hsacc 0.88475, csacc 0.69357, 120.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94000, tacc(al2) 0.83100, tacc(ob0) 0.98300, tacc(ob1) 0.95700, tacc(ob2) 0.87200, tacc(ob3) 0.98000, tacc(ob4) 0.93300, 6.85 secs\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "   iteration 10175\r"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_045133_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 75 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 8 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d81503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 150\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_labels: 76\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_061431_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   chest_imagenome_phrase2labels_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\n",
      "   dataset_name: MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 1.0\n",
      "   chest_imagenome_classification_weight: 1.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome: True\n",
      "  n_chest_imagenome_labels: 76\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "1e-06 3 0.0002 8 1e-06 0.0002 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train metadata classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: unchanged vascular crowding in close proximity to the right lower lobe\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: unknown\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: A significant amount of fluid is seen in the pleural space\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: worsened\n",
      "\u001b[1mExample fact: pulmonary vasculature without overlying edema\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: superimposed moderate pleural effusions\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: unclear comparison\n",
      "\u001b[1mExample fact: A 2 mm granuloma with calcification\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: comparison to 20:36\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: resolved\n",
      "\u001b[1mExample fact: Lung collapse is present\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: extensive residual consolidation\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: right chest wall Port-A-Cath unchanged\u001b[0m\n",
      "Category: device\n",
      "Health status: normal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: calcified thoracic aorta appears the same\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding train chest imagenome labels classification dataset and dataloader...\u001b[0m\n",
      "Loading chest imagenome phrase2labels from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl...\n",
      "len(phrases): 556111\n",
      "len(label_names): 76\n",
      "labels.shape: (556111, 76)\n",
      "Label: nlp|abnormal\n",
      "\tNumber of non-omitted rows: 398889\n",
      "\tWeight: 6440.70\n",
      "Label: anatomicalfinding|lung opacity\n",
      "\tNumber of non-omitted rows: 305904\n",
      "\tWeight: 6051.17\n",
      "Label: anatomicalfinding|pleural effusion\n",
      "\tNumber of non-omitted rows: 100696\n",
      "\tWeight: 4590.56\n",
      "Label: anatomicalfinding|atelectasis\n",
      "\tNumber of non-omitted rows: 90101\n",
      "\tWeight: 4458.93\n",
      "Label: anatomicalfinding|pulmonary edema/hazy opacity\n",
      "\tNumber of non-omitted rows: 54992\n",
      "\tWeight: 3904.70\n",
      "Label: disease|pneumonia\n",
      "\tNumber of non-omitted rows: 54542\n",
      "\tWeight: 3895.89\n",
      "Label: anatomicalfinding|enlarged cardiac silhouette\n",
      "\tNumber of non-omitted rows: 44699\n",
      "\tWeight: 3686.49\n",
      "Label: nlp|normal\n",
      "\tNumber of non-omitted rows: 39410\n",
      "\tWeight: 3557.94\n",
      "Label: anatomicalfinding|consolidation\n",
      "\tNumber of non-omitted rows: 35449\n",
      "\tWeight: 3452.16\n",
      "Label: anatomicalfinding|pneumothorax\n",
      "\tNumber of non-omitted rows: 32738\n",
      "\tWeight: 3374.11\n",
      "Label: anatomicalfinding|vascular congestion\n",
      "\tNumber of non-omitted rows: 27593\n",
      "\tWeight: 3210.36\n",
      "Label: tubesandlines|enteric tube\n",
      "\tNumber of non-omitted rows: 25308\n",
      "\tWeight: 3129.63\n",
      "Label: tubesandlines|endotracheal tube\n",
      "\tNumber of non-omitted rows: 20291\n",
      "\tWeight: 2929.46\n",
      "Label: anatomicalfinding|lung lesion\n",
      "\tNumber of non-omitted rows: 19884\n",
      "\tWeight: 2911.54\n",
      "Label: technicalassessment|low lung volumes\n",
      "\tNumber of non-omitted rows: 17780\n",
      "\tWeight: 2813.95\n",
      "Label: anatomicalfinding|pleural/parenchymal scarring\n",
      "\tNumber of non-omitted rows: 15919\n",
      "\tWeight: 2719.65\n",
      "Label: anatomicalfinding|enlarged hilum\n",
      "\tNumber of non-omitted rows: 13987\n",
      "\tWeight: 2611.99\n",
      "Label: tubesandlines|chest tube\n",
      "\tNumber of non-omitted rows: 12496\n",
      "\tWeight: 2520.55\n",
      "Label: anatomicalfinding|mediastinal widening\n",
      "\tNumber of non-omitted rows: 12438\n",
      "\tWeight: 2516.83\n",
      "Label: tubesandlines|picc\n",
      "\tNumber of non-omitted rows: 12300\n",
      "\tWeight: 2507.90\n",
      "Label: anatomicalfinding|mediastinal displacement\n",
      "\tNumber of non-omitted rows: 11776\n",
      "\tWeight: 2473.28\n",
      "Label: disease|aspiration\n",
      "\tNumber of non-omitted rows: 11534\n",
      "\tWeight: 2456.88\n",
      "Label: anatomicalfinding|mass/nodule (not otherwise specified)\n",
      "\tNumber of non-omitted rows: 11341\n",
      "\tWeight: 2443.61\n",
      "Label: anatomicalfinding|linear/patchy atelectasis\n",
      "\tNumber of non-omitted rows: 11262\n",
      "\tWeight: 2438.12\n",
      "Label: device|cardiac pacer and wires\n",
      "\tNumber of non-omitted rows: 10982\n",
      "\tWeight: 2418.44\n",
      "Label: anatomicalfinding|lobar/segmental collapse\n",
      "\tNumber of non-omitted rows: 10953\n",
      "\tWeight: 2416.37\n",
      "Label: anatomicalfinding|superior mediastinal mass/enlargement\n",
      "\tNumber of non-omitted rows: 10695\n",
      "\tWeight: 2397.84\n",
      "Label: anatomicalfinding|airspace opacity\n",
      "\tNumber of non-omitted rows: 10482\n",
      "\tWeight: 2382.28\n",
      "Label: tubesandlines|ij line\n",
      "\tNumber of non-omitted rows: 9936\n",
      "\tWeight: 2341.22\n",
      "Label: anatomicalfinding|rib fracture\n",
      "\tNumber of non-omitted rows: 8398\n",
      "\tWeight: 2215.22\n",
      "Label: disease|fluid overload/heart failure\n",
      "\tNumber of non-omitted rows: 7636\n",
      "\tWeight: 2145.99\n",
      "Label: anatomicalfinding|tortuous aorta\n",
      "\tNumber of non-omitted rows: 6965\n",
      "\tWeight: 2080.44\n",
      "Label: anatomicalfinding|hyperaeration\n",
      "\tNumber of non-omitted rows: 6898\n",
      "\tWeight: 2073.63\n",
      "Label: disease|copd/emphysema\n",
      "\tNumber of non-omitted rows: 6508\n",
      "\tWeight: 2032.94\n",
      "Label: tubesandlines|chest port\n",
      "\tNumber of non-omitted rows: 5678\n",
      "\tWeight: 1939.64\n",
      "Label: anatomicalfinding|costophrenic angle blunting\n",
      "\tNumber of non-omitted rows: 5642\n",
      "\tWeight: 1935.36\n",
      "Label: anatomicalfinding|multiple masses/nodules\n",
      "\tNumber of non-omitted rows: 5480\n",
      "\tWeight: 1915.85\n",
      "Label: anatomicalfinding|elevated hemidiaphragm\n",
      "\tNumber of non-omitted rows: 5358\n",
      "\tWeight: 1900.85\n",
      "Label: anatomicalfinding|vascular calcification\n",
      "\tNumber of non-omitted rows: 5133\n",
      "\tWeight: 1872.50\n",
      "Label: anatomicalfinding|infiltration\n",
      "\tNumber of non-omitted rows: 5105\n",
      "\tWeight: 1868.91\n",
      "Label: tubesandlines|pigtail catheter\n",
      "\tNumber of non-omitted rows: 4099\n",
      "\tWeight: 1728.46\n",
      "Label: anatomicalfinding|spinal fracture\n",
      "\tNumber of non-omitted rows: 3775\n",
      "\tWeight: 1677.63\n",
      "Label: anatomicalfinding|subcutaneous air\n",
      "\tNumber of non-omitted rows: 3698\n",
      "\tWeight: 1665.07\n",
      "Label: anatomicalfinding|spinal degenerative changes\n",
      "\tNumber of non-omitted rows: 3406\n",
      "\tWeight: 1615.56\n",
      "Label: tubesandlines|subclavian line\n",
      "\tNumber of non-omitted rows: 3121\n",
      "\tWeight: 1564.04\n",
      "Label: anatomicalfinding|hernia\n",
      "\tNumber of non-omitted rows: 3013\n",
      "\tWeight: 1543.60\n",
      "Label: anatomicalfinding|sub-diaphragmatic air\n",
      "\tNumber of non-omitted rows: 3011\n",
      "\tWeight: 1543.21\n",
      "Label: tubesandlines|tracheostomy tube\n",
      "\tNumber of non-omitted rows: 2963\n",
      "\tWeight: 1533.94\n",
      "Label: anatomicalfinding|vascular redistribution\n",
      "\tNumber of non-omitted rows: 2843\n",
      "\tWeight: 1510.27\n",
      "Label: disease|granulomatous disease\n",
      "\tNumber of non-omitted rows: 2788\n",
      "\tWeight: 1499.16\n",
      "Label: anatomicalfinding|calcified nodule\n",
      "\tNumber of non-omitted rows: 2734\n",
      "\tWeight: 1488.10\n",
      "Label: anatomicalfinding|bone lesion\n",
      "\tNumber of non-omitted rows: 2667\n",
      "\tWeight: 1474.15\n",
      "Label: disease|interstitial lung disease\n",
      "\tNumber of non-omitted rows: 2663\n",
      "\tWeight: 1473.31\n",
      "Label: anatomicalfinding|scoliosis\n",
      "\tNumber of non-omitted rows: 2490\n",
      "\tWeight: 1435.99\n",
      "Label: tubesandlines|swan-ganz catheter\n",
      "\tNumber of non-omitted rows: 2462\n",
      "\tWeight: 1429.77\n",
      "Label: disease|alveolar hemorrhage\n",
      "\tNumber of non-omitted rows: 2241\n",
      "\tWeight: 1378.72\n",
      "Label: disease|lung cancer\n",
      "\tNumber of non-omitted rows: 2156\n",
      "\tWeight: 1358.10\n",
      "Label: device|prosthetic valve\n",
      "\tNumber of non-omitted rows: 2094\n",
      "\tWeight: 1342.67\n",
      "Label: technicalassessment|rotated\n",
      "\tNumber of non-omitted rows: 1955\n",
      "\tWeight: 1306.81\n",
      "Label: anatomicalfinding|increased reticular markings/ild pattern\n",
      "\tNumber of non-omitted rows: 1819\n",
      "\tWeight: 1269.86\n",
      "Label: anatomicalfinding|shoulder osteoarthritis\n",
      "\tNumber of non-omitted rows: 1805\n",
      "\tWeight: 1265.94\n",
      "Label: anatomicalfinding|pneumomediastinum\n",
      "\tNumber of non-omitted rows: 1797\n",
      "\tWeight: 1263.70\n",
      "Label: device|cabg grafts\n",
      "\tNumber of non-omitted rows: 1797\n",
      "\tWeight: 1263.70\n",
      "Label: disease|pericardial effusion\n",
      "\tNumber of non-omitted rows: 1693\n",
      "\tWeight: 1233.78\n",
      "Label: anatomicalfinding|hydropneumothorax\n",
      "\tNumber of non-omitted rows: 1286\n",
      "\tWeight: 1101.88\n",
      "Label: anatomicalfinding|bronchiectasis\n",
      "\tNumber of non-omitted rows: 1180\n",
      "\tWeight: 1062.64\n",
      "Label: technicalassessment|breast/nipple shadows\n",
      "\tNumber of non-omitted rows: 1173\n",
      "\tWeight: 1059.96\n",
      "Label: anatomicalfinding|cyst/bullae\n",
      "\tNumber of non-omitted rows: 997\n",
      "\tWeight: 988.48\n",
      "Label: anatomicalfinding|clavicle fracture\n",
      "\tNumber of non-omitted rows: 916\n",
      "\tWeight: 952.53\n",
      "Label: tubesandlines|intra-aortic balloon pump\n",
      "\tNumber of non-omitted rows: 716\n",
      "\tWeight: 853.00\n",
      "Label: disease|goiter\n",
      "\tNumber of non-omitted rows: 704\n",
      "\tWeight: 846.44\n",
      "Label: tubesandlines|mediastinal drain\n",
      "\tNumber of non-omitted rows: 697\n",
      "\tWeight: 842.57\n",
      "Label: technicalassessment|artifact\n",
      "\tNumber of non-omitted rows: 486\n",
      "\tWeight: 710.88\n",
      "Label: technicalassessment|skin fold\n",
      "\tNumber of non-omitted rows: 206\n",
      "\tWeight: 454.14\n",
      "Label: device|aortic graft/repair\n",
      "\tNumber of non-omitted rows: 106\n",
      "\tWeight: 304.54\n",
      "Label: anatomicalfinding|diaphragmatic eventration (benign)\n",
      "\tNumber of non-omitted rows: 61\n",
      "\tWeight: 208.61\n",
      "Label: \"omitted\"\n",
      "\tNumber of rows: 640\n",
      "\tWeight: 810.0601087978947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_005945_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_005945_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_200_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9365.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_061431_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_200_cacc+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9365.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_005945_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.85630, triplet_loss 0.44206, c_loss 0.13963, hs_loss 0.25171, cs_loss 0.64636, cacc 0.95183, hsacc 0.90388, csacc 0.75688, chstimgn_loss 1.09039, chestimg_macro_f1 0.16417, 126.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.96100, tacc(al2) 0.81700, tacc(ob0) 0.98900, tacc(ob1) 0.97400, tacc(ob2) 0.88200, tacc(ob3) 0.98800, tacc(ob4) 0.94600, 7.48 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9010.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.85571, triplet_loss 0.44214, c_loss 0.13004, hs_loss 0.26018, cs_loss 0.64877, cacc 0.95305, hsacc 0.90575, csacc 0.75469, chstimgn_loss 1.08544, chestimg_macro_f1 0.16890, 129.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.96500, tacc(al2) 0.81400, tacc(ob0) 0.99000, tacc(ob1) 0.97300, tacc(ob2) 0.87900, tacc(ob3) 0.98800, tacc(ob4) 0.94300, 5.74 secs\n",
      "\u001b[1m---- Epoch 3/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 0.85637, triplet_loss 0.44355, c_loss 0.13606, hs_loss 0.26428, cs_loss 0.66678, cacc 0.95289, hsacc 0.90274, csacc 0.75265, chstimgn_loss 1.05783, chestimg_macro_f1 0.19953, 134.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.96300, tacc(al2) 0.82200, tacc(ob0) 0.99100, tacc(ob1) 0.97900, tacc(ob2) 0.87600, tacc(ob3) 0.98500, tacc(ob4) 0.94500, 5.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9030.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.93498, triplet_loss 0.45427, c_loss 0.21404, hs_loss 0.36494, cs_loss 0.87581, cacc 0.93111, hsacc 0.86841, csacc 0.67886, chstimgn_loss 0.89732, chestimg_macro_f1 0.28311, 137.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98000, tacc(al1) 0.95100, tacc(al2) 0.81500, tacc(ob0) 0.98200, tacc(ob1) 0.97300, tacc(ob2) 0.85900, tacc(ob3) 0.98700, tacc(ob4) 0.94000, 5.79 secs\n",
      "\u001b[1m---- Epoch 5/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000103) ...\n",
      "loss 0.83877, triplet_loss 0.44925, c_loss 0.18208, hs_loss 0.34394, cs_loss 0.81796, cacc 0.94000, hsacc 0.87691, csacc 0.69934, chstimgn_loss 0.72155, chestimg_macro_f1 0.30109, 136.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95000, tacc(al2) 0.81600, tacc(ob0) 0.99000, tacc(ob1) 0.97600, tacc(ob2) 0.86500, tacc(ob3) 0.98200, tacc(ob4) 0.94300, 6.03 secs\n",
      "\u001b[1m---- Epoch 6/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 0.77221, triplet_loss 0.44650, c_loss 0.15194, hs_loss 0.30758, cs_loss 0.75800, cacc 0.94537, hsacc 0.89055, csacc 0.71758, chstimgn_loss 0.65297, chestimg_macro_f1 0.30749, 137.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.96100, tacc(al2) 0.80700, tacc(ob0) 0.98900, tacc(ob1) 0.98200, tacc(ob2) 0.86800, tacc(ob3) 0.98800, tacc(ob4) 0.94500, 6.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9046.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.74535, triplet_loss 0.44639, c_loss 0.15966, hs_loss 0.28111, cs_loss 0.72701, cacc 0.94935, hsacc 0.89339, csacc 0.72545, chstimgn_loss 0.62278, chestimg_macro_f1 0.31106, 136.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95800, tacc(al2) 0.81000, tacc(ob0) 0.98900, tacc(ob1) 0.97500, tacc(ob2) 0.86800, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 6.80 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9047.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.73376, triplet_loss 0.44449, c_loss 0.14030, hs_loss 0.29203, cs_loss 0.71284, cacc 0.94583, hsacc 0.89178, csacc 0.73321, chstimgn_loss 0.61036, chestimg_macro_f1 0.31178, 137.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95600, tacc(al2) 0.81100, tacc(ob0) 0.98900, tacc(ob1) 0.97300, tacc(ob2) 0.86300, tacc(ob3) 0.98700, tacc(ob4) 0.95300, 6.92 secs\n",
      "\u001b[1m---- Epoch 9/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.72621, triplet_loss 0.44348, c_loss 0.14328, hs_loss 0.28208, cs_loss 0.70824, cacc 0.94893, hsacc 0.89606, csacc 0.73604, chstimgn_loss 0.60193, chestimg_macro_f1 0.31234, 141.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95900, tacc(al2) 0.81100, tacc(ob0) 0.98900, tacc(ob1) 0.97500, tacc(ob2) 0.87000, tacc(ob3) 0.98800, tacc(ob4) 0.95000, 9.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9059.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.72037, triplet_loss 0.44381, c_loss 0.13366, hs_loss 0.28280, cs_loss 0.70224, cacc 0.95143, hsacc 0.89600, csacc 0.73702, chstimgn_loss 0.59943, chestimg_macro_f1 0.31312, 145.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.96000, tacc(al2) 0.81600, tacc(ob0) 0.98900, tacc(ob1) 0.97400, tacc(ob2) 0.86200, tacc(ob3) 0.98800, tacc(ob4) 0.95300, 9.47 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9061.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.72469, triplet_loss 0.44309, c_loss 0.15405, hs_loss 0.28341, cs_loss 0.69432, cacc 0.94994, hsacc 0.89918, csacc 0.73982, chstimgn_loss 0.59797, chestimg_macro_f1 0.31272, 143.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95800, tacc(al2) 0.81500, tacc(ob0) 0.98900, tacc(ob1) 0.97500, tacc(ob2) 0.87000, tacc(ob3) 0.99000, tacc(ob4) 0.95000, 9.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9066.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.71554, triplet_loss 0.44290, c_loss 0.13576, hs_loss 0.27891, cs_loss 0.69213, cacc 0.95051, hsacc 0.89610, csacc 0.73990, chstimgn_loss 0.59729, chestimg_macro_f1 0.31310, 152.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.96000, tacc(al2) 0.81400, tacc(ob0) 0.98900, tacc(ob1) 0.97500, tacc(ob2) 0.86700, tacc(ob3) 0.99000, tacc(ob4) 0.95100, 9.96 secs\n",
      "\u001b[1m---- Epoch 13/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.82088, triplet_loss 0.45026, c_loss 0.20599, hs_loss 0.37698, cs_loss 0.86756, cacc 0.93371, hsacc 0.86773, csacc 0.67866, chstimgn_loss 0.56296, chestimg_macro_f1 0.31819, 152.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95800, tacc(al2) 0.81800, tacc(ob0) 0.98500, tacc(ob1) 0.97100, tacc(ob2) 0.86100, tacc(ob3) 0.98000, tacc(ob4) 0.93700, 10.05 secs\n",
      "\u001b[1m---- Epoch 14/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.76224, triplet_loss 0.44650, c_loss 0.18101, hs_loss 0.33983, cs_loss 0.80582, cacc 0.93832, hsacc 0.87725, csacc 0.70232, chstimgn_loss 0.51185, chestimg_macro_f1 0.32293, 154.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95400, tacc(al2) 0.83100, tacc(ob0) 0.98900, tacc(ob1) 0.97400, tacc(ob2) 0.87600, tacc(ob3) 0.98500, tacc(ob4) 0.94300, 10.37 secs\n",
      "\u001b[1m---- Epoch 15/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "^C iteration 14075\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 500, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 411, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 257, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 121, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/fact_embedding.py\", line 160, in step_fn_wrapper\n",
      "    output = step_fn__triplet_ranking(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/fact_embedding.py\", line 59, in step_fn__triplet_ranking\n",
      "    gradient_accumulator.step(batch_loss)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 26, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 488, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230721_061431_MIMIC-CXR(GPT3.5+CXR-Bert-based-labels)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 150 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--chest_imagenome_phrase2labels_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\" \\\n",
    "--n_chest_imagenome_labels 76 \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb6f599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 100\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_labels: 76\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_005945_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "   iters_to_accumulate: 5\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   chest_imagenome_phrase2labels_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\n",
      "   dataset_name: MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 1.0\n",
      "   chest_imagenome_classification_weight: 3.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome: True\n",
      "  n_chest_imagenome_labels: 76\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "1e-06 3 0.0002 8 2e-06 0.0002 8 2e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train metadata classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: The chest X-ray image exhibits a very similar appearance to the one taken on the previous day\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: resolved\n",
      "\u001b[1mExample fact: circumscribed left pleural effusion\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: no significant advancement of pulmonary edema\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: resolved\n",
      "\u001b[1mExample fact: new compression deformity since the prior radiographs\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: new finding\n",
      "\u001b[1mExample fact: slight interval increase in the right upper zone opacity\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: increase\n",
      "\u001b[1mExample fact: no appreciable change in right basilar consolidation\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: There is an increased consolidation\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: worsened\n",
      "\u001b[1mExample fact: varus angulation\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: opacity could be scarring\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: ambiguous\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: A newly observed nodule\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding train chest imagenome labels classification dataset and dataloader...\u001b[0m\n",
      "Loading chest imagenome phrase2labels from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl...\n",
      "len(phrases): 556111\n",
      "len(label_names): 76\n",
      "labels.shape: (556111, 76)\n",
      "Label: nlp|abnormal\n",
      "\tNumber of non-omitted rows: 398889\n",
      "\tWeight: 6440.70\n",
      "Label: anatomicalfinding|lung opacity\n",
      "\tNumber of non-omitted rows: 305904\n",
      "\tWeight: 6051.17\n",
      "Label: anatomicalfinding|pleural effusion\n",
      "\tNumber of non-omitted rows: 100696\n",
      "\tWeight: 4590.56\n",
      "Label: anatomicalfinding|atelectasis\n",
      "\tNumber of non-omitted rows: 90101\n",
      "\tWeight: 4458.93\n",
      "Label: anatomicalfinding|pulmonary edema/hazy opacity\n",
      "\tNumber of non-omitted rows: 54992\n",
      "\tWeight: 3904.70\n",
      "Label: disease|pneumonia\n",
      "\tNumber of non-omitted rows: 54542\n",
      "\tWeight: 3895.89\n",
      "Label: anatomicalfinding|enlarged cardiac silhouette\n",
      "\tNumber of non-omitted rows: 44699\n",
      "\tWeight: 3686.49\n",
      "Label: nlp|normal\n",
      "\tNumber of non-omitted rows: 39410\n",
      "\tWeight: 3557.94\n",
      "Label: anatomicalfinding|consolidation\n",
      "\tNumber of non-omitted rows: 35449\n",
      "\tWeight: 3452.16\n",
      "Label: anatomicalfinding|pneumothorax\n",
      "\tNumber of non-omitted rows: 32738\n",
      "\tWeight: 3374.11\n",
      "Label: anatomicalfinding|vascular congestion\n",
      "\tNumber of non-omitted rows: 27593\n",
      "\tWeight: 3210.36\n",
      "Label: tubesandlines|enteric tube\n",
      "\tNumber of non-omitted rows: 25308\n",
      "\tWeight: 3129.63\n",
      "Label: tubesandlines|endotracheal tube\n",
      "\tNumber of non-omitted rows: 20291\n",
      "\tWeight: 2929.46\n",
      "Label: anatomicalfinding|lung lesion\n",
      "\tNumber of non-omitted rows: 19884\n",
      "\tWeight: 2911.54\n",
      "Label: technicalassessment|low lung volumes\n",
      "\tNumber of non-omitted rows: 17780\n",
      "\tWeight: 2813.95\n",
      "Label: anatomicalfinding|pleural/parenchymal scarring\n",
      "\tNumber of non-omitted rows: 15919\n",
      "\tWeight: 2719.65\n",
      "Label: anatomicalfinding|enlarged hilum\n",
      "\tNumber of non-omitted rows: 13987\n",
      "\tWeight: 2611.99\n",
      "Label: tubesandlines|chest tube\n",
      "\tNumber of non-omitted rows: 12496\n",
      "\tWeight: 2520.55\n",
      "Label: anatomicalfinding|mediastinal widening\n",
      "\tNumber of non-omitted rows: 12438\n",
      "\tWeight: 2516.83\n",
      "Label: tubesandlines|picc\n",
      "\tNumber of non-omitted rows: 12300\n",
      "\tWeight: 2507.90\n",
      "Label: anatomicalfinding|mediastinal displacement\n",
      "\tNumber of non-omitted rows: 11776\n",
      "\tWeight: 2473.28\n",
      "Label: disease|aspiration\n",
      "\tNumber of non-omitted rows: 11534\n",
      "\tWeight: 2456.88\n",
      "Label: anatomicalfinding|mass/nodule (not otherwise specified)\n",
      "\tNumber of non-omitted rows: 11341\n",
      "\tWeight: 2443.61\n",
      "Label: anatomicalfinding|linear/patchy atelectasis\n",
      "\tNumber of non-omitted rows: 11262\n",
      "\tWeight: 2438.12\n",
      "Label: device|cardiac pacer and wires\n",
      "\tNumber of non-omitted rows: 10982\n",
      "\tWeight: 2418.44\n",
      "Label: anatomicalfinding|lobar/segmental collapse\n",
      "\tNumber of non-omitted rows: 10953\n",
      "\tWeight: 2416.37\n",
      "Label: anatomicalfinding|superior mediastinal mass/enlargement\n",
      "\tNumber of non-omitted rows: 10695\n",
      "\tWeight: 2397.84\n",
      "Label: anatomicalfinding|airspace opacity\n",
      "\tNumber of non-omitted rows: 10482\n",
      "\tWeight: 2382.28\n",
      "Label: tubesandlines|ij line\n",
      "\tNumber of non-omitted rows: 9936\n",
      "\tWeight: 2341.22\n",
      "Label: anatomicalfinding|rib fracture\n",
      "\tNumber of non-omitted rows: 8398\n",
      "\tWeight: 2215.22\n",
      "Label: disease|fluid overload/heart failure\n",
      "\tNumber of non-omitted rows: 7636\n",
      "\tWeight: 2145.99\n",
      "Label: anatomicalfinding|tortuous aorta\n",
      "\tNumber of non-omitted rows: 6965\n",
      "\tWeight: 2080.44\n",
      "Label: anatomicalfinding|hyperaeration\n",
      "\tNumber of non-omitted rows: 6898\n",
      "\tWeight: 2073.63\n",
      "Label: disease|copd/emphysema\n",
      "\tNumber of non-omitted rows: 6508\n",
      "\tWeight: 2032.94\n",
      "Label: tubesandlines|chest port\n",
      "\tNumber of non-omitted rows: 5678\n",
      "\tWeight: 1939.64\n",
      "Label: anatomicalfinding|costophrenic angle blunting\n",
      "\tNumber of non-omitted rows: 5642\n",
      "\tWeight: 1935.36\n",
      "Label: anatomicalfinding|multiple masses/nodules\n",
      "\tNumber of non-omitted rows: 5480\n",
      "\tWeight: 1915.85\n",
      "Label: anatomicalfinding|elevated hemidiaphragm\n",
      "\tNumber of non-omitted rows: 5358\n",
      "\tWeight: 1900.85\n",
      "Label: anatomicalfinding|vascular calcification\n",
      "\tNumber of non-omitted rows: 5133\n",
      "\tWeight: 1872.50\n",
      "Label: anatomicalfinding|infiltration\n",
      "\tNumber of non-omitted rows: 5105\n",
      "\tWeight: 1868.91\n",
      "Label: tubesandlines|pigtail catheter\n",
      "\tNumber of non-omitted rows: 4099\n",
      "\tWeight: 1728.46\n",
      "Label: anatomicalfinding|spinal fracture\n",
      "\tNumber of non-omitted rows: 3775\n",
      "\tWeight: 1677.63\n",
      "Label: anatomicalfinding|subcutaneous air\n",
      "\tNumber of non-omitted rows: 3698\n",
      "\tWeight: 1665.07\n",
      "Label: anatomicalfinding|spinal degenerative changes\n",
      "\tNumber of non-omitted rows: 3406\n",
      "\tWeight: 1615.56\n",
      "Label: tubesandlines|subclavian line\n",
      "\tNumber of non-omitted rows: 3121\n",
      "\tWeight: 1564.04\n",
      "Label: anatomicalfinding|hernia\n",
      "\tNumber of non-omitted rows: 3013\n",
      "\tWeight: 1543.60\n",
      "Label: anatomicalfinding|sub-diaphragmatic air\n",
      "\tNumber of non-omitted rows: 3011\n",
      "\tWeight: 1543.21\n",
      "Label: tubesandlines|tracheostomy tube\n",
      "\tNumber of non-omitted rows: 2963\n",
      "\tWeight: 1533.94\n",
      "Label: anatomicalfinding|vascular redistribution\n",
      "\tNumber of non-omitted rows: 2843\n",
      "\tWeight: 1510.27\n",
      "Label: disease|granulomatous disease\n",
      "\tNumber of non-omitted rows: 2788\n",
      "\tWeight: 1499.16\n",
      "Label: anatomicalfinding|calcified nodule\n",
      "\tNumber of non-omitted rows: 2734\n",
      "\tWeight: 1488.10\n",
      "Label: anatomicalfinding|bone lesion\n",
      "\tNumber of non-omitted rows: 2667\n",
      "\tWeight: 1474.15\n",
      "Label: disease|interstitial lung disease\n",
      "\tNumber of non-omitted rows: 2663\n",
      "\tWeight: 1473.31\n",
      "Label: anatomicalfinding|scoliosis\n",
      "\tNumber of non-omitted rows: 2490\n",
      "\tWeight: 1435.99\n",
      "Label: tubesandlines|swan-ganz catheter\n",
      "\tNumber of non-omitted rows: 2462\n",
      "\tWeight: 1429.77\n",
      "Label: disease|alveolar hemorrhage\n",
      "\tNumber of non-omitted rows: 2241\n",
      "\tWeight: 1378.72\n",
      "Label: disease|lung cancer\n",
      "\tNumber of non-omitted rows: 2156\n",
      "\tWeight: 1358.10\n",
      "Label: device|prosthetic valve\n",
      "\tNumber of non-omitted rows: 2094\n",
      "\tWeight: 1342.67\n",
      "Label: technicalassessment|rotated\n",
      "\tNumber of non-omitted rows: 1955\n",
      "\tWeight: 1306.81\n",
      "Label: anatomicalfinding|increased reticular markings/ild pattern\n",
      "\tNumber of non-omitted rows: 1819\n",
      "\tWeight: 1269.86\n",
      "Label: anatomicalfinding|shoulder osteoarthritis\n",
      "\tNumber of non-omitted rows: 1805\n",
      "\tWeight: 1265.94\n",
      "Label: anatomicalfinding|pneumomediastinum\n",
      "\tNumber of non-omitted rows: 1797\n",
      "\tWeight: 1263.70\n",
      "Label: device|cabg grafts\n",
      "\tNumber of non-omitted rows: 1797\n",
      "\tWeight: 1263.70\n",
      "Label: disease|pericardial effusion\n",
      "\tNumber of non-omitted rows: 1693\n",
      "\tWeight: 1233.78\n",
      "Label: anatomicalfinding|hydropneumothorax\n",
      "\tNumber of non-omitted rows: 1286\n",
      "\tWeight: 1101.88\n",
      "Label: anatomicalfinding|bronchiectasis\n",
      "\tNumber of non-omitted rows: 1180\n",
      "\tWeight: 1062.64\n",
      "Label: technicalassessment|breast/nipple shadows\n",
      "\tNumber of non-omitted rows: 1173\n",
      "\tWeight: 1059.96\n",
      "Label: anatomicalfinding|cyst/bullae\n",
      "\tNumber of non-omitted rows: 997\n",
      "\tWeight: 988.48\n",
      "Label: anatomicalfinding|clavicle fracture\n",
      "\tNumber of non-omitted rows: 916\n",
      "\tWeight: 952.53\n",
      "Label: tubesandlines|intra-aortic balloon pump\n",
      "\tNumber of non-omitted rows: 716\n",
      "\tWeight: 853.00\n",
      "Label: disease|goiter\n",
      "\tNumber of non-omitted rows: 704\n",
      "\tWeight: 846.44\n",
      "Label: tubesandlines|mediastinal drain\n",
      "\tNumber of non-omitted rows: 697\n",
      "\tWeight: 842.57\n",
      "Label: technicalassessment|artifact\n",
      "\tNumber of non-omitted rows: 486\n",
      "\tWeight: 710.88\n",
      "Label: technicalassessment|skin fold\n",
      "\tNumber of non-omitted rows: 206\n",
      "\tWeight: 454.14\n",
      "Label: device|aortic graft/repair\n",
      "\tNumber of non-omitted rows: 106\n",
      "\tWeight: 304.54\n",
      "Label: anatomicalfinding|diaphragmatic eventration (benign)\n",
      "\tNumber of non-omitted rows: 61\n",
      "\tWeight: 208.61\n",
      "Label: \"omitted\"\n",
      "\tNumber of rows: 640\n",
      "\tWeight: 810.0601087978947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_015329_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_015329_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_11_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9066.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_005945_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_11_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9066.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_015329_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68504, triplet_loss 0.44419, c_loss 0.14212, hs_loss 0.27562, cs_loss 0.68543, cacc 0.95120, hsacc 0.89908, csacc 0.74192, chstimgn_loss 0.59641, chestimg_macro_f1 0.31307, 112.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95900, tacc(al2) 0.81500, tacc(ob0) 0.98900, tacc(ob1) 0.97700, tacc(ob2) 0.86600, tacc(ob3) 0.99000, tacc(ob4) 0.95000, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9065.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.67908, triplet_loss 0.44305, c_loss 0.13799, hs_loss 0.27113, cs_loss 0.67478, cacc 0.94956, hsacc 0.90180, csacc 0.74444, chstimgn_loss 0.59468, chestimg_macro_f1 0.31353, 108.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.96100, tacc(al2) 0.81400, tacc(ob0) 0.98900, tacc(ob1) 0.97700, tacc(ob2) 0.86300, tacc(ob3) 0.99000, tacc(ob4) 0.94700, 5.67 secs\n",
      "\u001b[1m---- Epoch 3/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 0.67823, triplet_loss 0.44373, c_loss 0.12688, hs_loss 0.28260, cs_loss 0.69307, cacc 0.95280, hsacc 0.89564, csacc 0.73620, chstimgn_loss 0.58332, chestimg_macro_f1 0.31439, 105.13 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.96200, tacc(al2) 0.80900, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86400, tacc(ob3) 0.99000, tacc(ob4) 0.94400, 5.67 secs\n",
      "\u001b[1m---- Epoch 4/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.76757, triplet_loss 0.45567, c_loss 0.21883, hs_loss 0.39517, cs_loss 0.90508, cacc 0.92976, hsacc 0.85916, csacc 0.67112, chstimgn_loss 0.54777, chestimg_macro_f1 0.31895, 110.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.83000, tacc(ob0) 0.99100, tacc(ob1) 0.95800, tacc(ob2) 0.86400, tacc(ob3) 0.98100, tacc(ob4) 0.93500, 5.74 secs\n",
      "\u001b[1m---- Epoch 5/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000112) ...\n",
      "loss 0.71592, triplet_loss 0.45038, c_loss 0.20673, hs_loss 0.34775, cs_loss 0.85347, cacc 0.93072, hsacc 0.87404, csacc 0.68440, chstimgn_loss 0.50268, chestimg_macro_f1 0.32510, 109.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95600, tacc(al2) 0.81200, tacc(ob0) 0.99000, tacc(ob1) 0.96900, tacc(ob2) 0.87300, tacc(ob3) 0.98200, tacc(ob4) 0.94100, 5.91 secs\n",
      "\u001b[1m---- Epoch 6/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 0.67913, triplet_loss 0.44758, c_loss 0.17450, hs_loss 0.32977, cs_loss 0.80307, cacc 0.94028, hsacc 0.88008, csacc 0.70216, chstimgn_loss 0.48081, chestimg_macro_f1 0.32826, 110.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95600, tacc(al2) 0.81400, tacc(ob0) 0.99500, tacc(ob1) 0.97400, tacc(ob2) 0.86800, tacc(ob3) 0.98800, tacc(ob4) 0.94400, 6.15 secs\n",
      "\u001b[1m---- Epoch 7/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 0.65970, triplet_loss 0.44553, c_loss 0.17669, hs_loss 0.32769, cs_loss 0.75805, cacc 0.94412, hsacc 0.88148, csacc 0.71864, chstimgn_loss 0.46541, chestimg_macro_f1 0.33191, 110.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.82300, tacc(ob0) 0.99200, tacc(ob1) 0.97000, tacc(ob2) 0.88100, tacc(ob3) 0.98700, tacc(ob4) 0.93600, 6.78 secs\n",
      "\u001b[1m---- Epoch 8/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.64318, triplet_loss 0.44491, c_loss 0.15941, hs_loss 0.30212, cs_loss 0.74459, cacc 0.94224, hsacc 0.88768, csacc 0.71952, chstimgn_loss 0.46084, chestimg_macro_f1 0.33526, 107.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.82000, tacc(ob0) 0.99300, tacc(ob1) 0.97200, tacc(ob2) 0.88000, tacc(ob3) 0.98800, tacc(ob4) 0.94400, 6.45 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9072.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.63546, triplet_loss 0.44492, c_loss 0.15343, hs_loss 0.30106, cs_loss 0.72995, cacc 0.94328, hsacc 0.89164, csacc 0.72576, chstimgn_loss 0.45625, chestimg_macro_f1 0.33840, 113.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95400, tacc(al2) 0.81400, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.94200, 7.68 secs\n",
      "\u001b[1m---- Epoch 10/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.62690, triplet_loss 0.44443, c_loss 0.15019, hs_loss 0.28726, cs_loss 0.72127, cacc 0.94348, hsacc 0.89336, csacc 0.72780, chstimgn_loss 0.45222, chestimg_macro_f1 0.33979, 113.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95500, tacc(al2) 0.82000, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.87400, tacc(ob3) 0.98900, tacc(ob4) 0.94400, 8.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9079.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.62550, triplet_loss 0.44413, c_loss 0.13579, hs_loss 0.29415, cs_loss 0.71965, cacc 0.94736, hsacc 0.89568, csacc 0.72860, chstimgn_loss 0.45413, chestimg_macro_f1 0.34041, 117.10 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98900, tacc(al1) 0.95500, tacc(al2) 0.82100, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.87400, tacc(ob3) 0.98900, tacc(ob4) 0.94200, 8.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9080.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.62639, triplet_loss 0.44439, c_loss 0.15204, hs_loss 0.28933, cs_loss 0.71595, cacc 0.94364, hsacc 0.89228, csacc 0.72924, chstimgn_loss 0.45193, chestimg_macro_f1 0.34115, 119.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95400, tacc(al2) 0.82100, tacc(ob0) 0.99300, tacc(ob1) 0.97500, tacc(ob2) 0.87300, tacc(ob3) 0.98900, tacc(ob4) 0.94300, 8.74 secs\n",
      "\u001b[1m---- Epoch 13/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.68812, triplet_loss 0.45038, c_loss 0.18094, hs_loss 0.37516, cs_loss 0.86220, cacc 0.92892, hsacc 0.86152, csacc 0.68052, chstimgn_loss 0.44191, chestimg_macro_f1 0.34576, 121.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98100, tacc(al1) 0.94100, tacc(al2) 0.79700, tacc(ob0) 0.98900, tacc(ob1) 0.97400, tacc(ob2) 0.88200, tacc(ob3) 0.98100, tacc(ob4) 0.93300, 9.49 secs\n",
      "\u001b[1m---- Epoch 14/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.66347, triplet_loss 0.44814, c_loss 0.18996, hs_loss 0.35018, cs_loss 0.83442, cacc 0.92992, hsacc 0.87104, csacc 0.69008, chstimgn_loss 0.41559, chestimg_macro_f1 0.35773, 122.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.82800, tacc(ob0) 0.99300, tacc(ob1) 0.97800, tacc(ob2) 0.86700, tacc(ob3) 0.98600, tacc(ob4) 0.94000, 9.23 secs\n",
      "\u001b[1m---- Epoch 15/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.62973, triplet_loss 0.44807, c_loss 0.17234, hs_loss 0.32669, cs_loss 0.77942, cacc 0.93832, hsacc 0.87848, csacc 0.70796, chstimgn_loss 0.39619, chestimg_macro_f1 0.36586, 123.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.82100, tacc(ob0) 0.99200, tacc(ob1) 0.97700, tacc(ob2) 0.87300, tacc(ob3) 0.98700, tacc(ob4) 0.94200, 9.02 secs\n",
      "\u001b[1m---- Epoch 16/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.61205, triplet_loss 0.44395, c_loss 0.15832, hs_loss 0.30968, cs_loss 0.75110, cacc 0.94000, hsacc 0.88704, csacc 0.71796, chstimgn_loss 0.39258, chestimg_macro_f1 0.36909, 123.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95200, tacc(al2) 0.81200, tacc(ob0) 0.99400, tacc(ob1) 0.97500, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.94500, 9.57 secs\n",
      "\u001b[1m---- Epoch 17/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.60326, triplet_loss 0.44493, c_loss 0.14630, hs_loss 0.30386, cs_loss 0.74447, cacc 0.94648, hsacc 0.88572, csacc 0.72196, chstimgn_loss 0.38673, chestimg_macro_f1 0.37078, 124.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95300, tacc(al2) 0.81700, tacc(ob0) 0.99500, tacc(ob1) 0.97500, tacc(ob2) 0.87300, tacc(ob3) 0.98600, tacc(ob4) 0.94500, 9.40 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9088.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.59799, triplet_loss 0.44441, c_loss 0.14899, hs_loss 0.28825, cs_loss 0.74216, cacc 0.94380, hsacc 0.88596, csacc 0.72060, chstimgn_loss 0.38408, chestimg_macro_f1 0.37273, 124.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95400, tacc(al2) 0.81500, tacc(ob0) 0.99400, tacc(ob1) 0.97600, tacc(ob2) 0.87500, tacc(ob3) 0.98800, tacc(ob4) 0.94700, 9.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9094.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.59617, triplet_loss 0.44265, c_loss 0.15306, hs_loss 0.29668, cs_loss 0.72500, cacc 0.94352, hsacc 0.88832, csacc 0.72560, chstimgn_loss 0.38364, chestimg_macro_f1 0.37420, 123.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.81500, tacc(ob0) 0.99400, tacc(ob1) 0.97500, tacc(ob2) 0.87100, tacc(ob3) 0.98600, tacc(ob4) 0.94500, 9.67 secs\n",
      "\u001b[1m---- Epoch 20/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59692, triplet_loss 0.44385, c_loss 0.14791, hs_loss 0.30131, cs_loss 0.72894, cacc 0.94412, hsacc 0.88948, csacc 0.72956, chstimgn_loss 0.38283, chestimg_macro_f1 0.37486, 122.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.81500, tacc(ob0) 0.99400, tacc(ob1) 0.97400, tacc(ob2) 0.87100, tacc(ob3) 0.98700, tacc(ob4) 0.94500, 9.59 secs\n",
      "\u001b[1m---- Epoch 21/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.67695, triplet_loss 0.45466, c_loss 0.21122, hs_loss 0.38729, cs_loss 0.89401, cacc 0.92996, hsacc 0.86132, csacc 0.67120, chstimgn_loss 0.38031, chestimg_macro_f1 0.37398, 122.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93700, tacc(al2) 0.82400, tacc(ob0) 0.98600, tacc(ob1) 0.96700, tacc(ob2) 0.89100, tacc(ob3) 0.98300, tacc(ob4) 0.94700, 10.33 secs\n",
      "\u001b[1m---- Epoch 22/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.64008, triplet_loss 0.44835, c_loss 0.18662, hs_loss 0.36988, cs_loss 0.83823, cacc 0.93212, hsacc 0.86576, csacc 0.69052, chstimgn_loss 0.35862, chestimg_macro_f1 0.38929, 124.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95000, tacc(al2) 0.81500, tacc(ob0) 0.99300, tacc(ob1) 0.97000, tacc(ob2) 0.87700, tacc(ob3) 0.98900, tacc(ob4) 0.94100, 9.46 secs\n",
      "\u001b[1m---- Epoch 23/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.61026, triplet_loss 0.44727, c_loss 0.16266, hs_loss 0.33560, cs_loss 0.80518, cacc 0.94084, hsacc 0.87516, csacc 0.69796, chstimgn_loss 0.34517, chestimg_macro_f1 0.39930, 124.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95200, tacc(al2) 0.81800, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.88200, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 9.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9102.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.58818, triplet_loss 0.44443, c_loss 0.16567, hs_loss 0.31043, cs_loss 0.75927, cacc 0.94088, hsacc 0.88480, csacc 0.71492, chstimgn_loss 0.33645, chestimg_macro_f1 0.40320, 122.94 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.80600, tacc(ob0) 0.99000, tacc(ob1) 0.97000, tacc(ob2) 0.88400, tacc(ob3) 0.99000, tacc(ob4) 0.94200, 9.89 secs\n",
      "\u001b[1m---- Epoch 25/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.57030, triplet_loss 0.44420, c_loss 0.14963, hs_loss 0.29337, cs_loss 0.72607, cacc 0.94068, hsacc 0.88992, csacc 0.72508, chstimgn_loss 0.33396, chestimg_macro_f1 0.40672, 121.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95200, tacc(al2) 0.80500, tacc(ob0) 0.99000, tacc(ob1) 0.96800, tacc(ob2) 0.88800, tacc(ob3) 0.98900, tacc(ob4) 0.95100, 9.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9103.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.57255, triplet_loss 0.44441, c_loss 0.14674, hs_loss 0.30592, cs_loss 0.72929, cacc 0.94428, hsacc 0.88684, csacc 0.72276, chstimgn_loss 0.33192, chestimg_macro_f1 0.40714, 123.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95500, tacc(al2) 0.80700, tacc(ob0) 0.99200, tacc(ob1) 0.97000, tacc(ob2) 0.88700, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 9.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9108.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.57507, triplet_loss 0.44376, c_loss 0.16043, hs_loss 0.30130, cs_loss 0.73276, cacc 0.94444, hsacc 0.88496, csacc 0.72524, chstimgn_loss 0.33101, chestimg_macro_f1 0.40950, 124.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95600, tacc(al2) 0.80400, tacc(ob0) 0.99000, tacc(ob1) 0.97100, tacc(ob2) 0.88900, tacc(ob3) 0.98800, tacc(ob4) 0.94900, 9.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9110.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.57281, triplet_loss 0.44378, c_loss 0.15737, hs_loss 0.29682, cs_loss 0.73057, cacc 0.94352, hsacc 0.88908, csacc 0.72648, chstimgn_loss 0.33135, chestimg_macro_f1 0.40782, 123.98 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99000, tacc(al1) 0.95700, tacc(al2) 0.81000, tacc(ob0) 0.98900, tacc(ob1) 0.97100, tacc(ob2) 0.88700, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 9.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9114.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.63636, triplet_loss 0.45197, c_loss 0.20296, hs_loss 0.37527, cs_loss 0.85768, cacc 0.92872, hsacc 0.86596, csacc 0.68052, chstimgn_loss 0.32879, chestimg_macro_f1 0.40711, 123.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95200, tacc(al2) 0.81600, tacc(ob0) 0.98500, tacc(ob1) 0.96600, tacc(ob2) 0.86700, tacc(ob3) 0.98200, tacc(ob4) 0.93100, 9.43 secs\n",
      "\u001b[1m---- Epoch 30/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.60939, triplet_loss 0.44588, c_loss 0.18118, hs_loss 0.35169, cs_loss 0.84167, cacc 0.93304, hsacc 0.87656, csacc 0.68656, chstimgn_loss 0.30857, chestimg_macro_f1 0.41868, 117.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94300, tacc(al2) 0.82500, tacc(ob0) 0.98600, tacc(ob1) 0.96700, tacc(ob2) 0.87200, tacc(ob3) 0.98800, tacc(ob4) 0.94600, 10.33 secs\n",
      "\u001b[1m---- Epoch 31/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.57767, triplet_loss 0.44733, c_loss 0.17551, hs_loss 0.32321, cs_loss 0.77079, cacc 0.94144, hsacc 0.87884, csacc 0.71200, chstimgn_loss 0.29693, chestimg_macro_f1 0.42390, 123.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.80800, tacc(ob0) 0.99000, tacc(ob1) 0.97700, tacc(ob2) 0.88000, tacc(ob3) 0.98700, tacc(ob4) 0.94100, 9.81 secs\n",
      "\u001b[1m---- Epoch 32/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.56605, triplet_loss 0.44575, c_loss 0.17056, hs_loss 0.31598, cs_loss 0.74839, cacc 0.93992, hsacc 0.88400, csacc 0.71908, chstimgn_loss 0.29176, chestimg_macro_f1 0.42953, 126.31 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.82400, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.87800, tacc(ob3) 0.98600, tacc(ob4) 0.94200, 9.73 secs\n",
      "\u001b[1m---- Epoch 33/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.55997, triplet_loss 0.44517, c_loss 0.15397, hs_loss 0.32254, cs_loss 0.74212, cacc 0.94600, hsacc 0.88464, csacc 0.72560, chstimgn_loss 0.28803, chestimg_macro_f1 0.43133, 124.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.82600, tacc(ob0) 0.99200, tacc(ob1) 0.97500, tacc(ob2) 0.87400, tacc(ob3) 0.98400, tacc(ob4) 0.94300, 9.51 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9116.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.54686, triplet_loss 0.44305, c_loss 0.15361, hs_loss 0.29077, cs_loss 0.72789, cacc 0.94460, hsacc 0.89060, csacc 0.72452, chstimgn_loss 0.28605, chestimg_macro_f1 0.43232, 124.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.82400, tacc(ob0) 0.99000, tacc(ob1) 0.97600, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.94300, 9.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_34_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9120.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 35/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.54941, triplet_loss 0.44369, c_loss 0.15226, hs_loss 0.30425, cs_loss 0.72546, cacc 0.94184, hsacc 0.88852, csacc 0.72556, chstimgn_loss 0.28599, chestimg_macro_f1 0.43379, 114.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.82600, tacc(ob0) 0.99100, tacc(ob1) 0.97700, tacc(ob2) 0.87700, tacc(ob3) 0.98500, tacc(ob4) 0.94100, 9.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9124.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.54807, triplet_loss 0.44391, c_loss 0.15012, hs_loss 0.30558, cs_loss 0.72096, cacc 0.94080, hsacc 0.88564, csacc 0.72772, chstimgn_loss 0.28586, chestimg_macro_f1 0.43423, 125.91 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.82500, tacc(ob0) 0.99100, tacc(ob1) 0.97600, tacc(ob2) 0.87800, tacc(ob3) 0.98500, tacc(ob4) 0.94000, 9.44 secs\n",
      "\u001b[1m---- Epoch 37/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.64780, triplet_loss 0.45329, c_loss 0.22372, hs_loss 0.41455, cs_loss 0.90858, cacc 0.92780, hsacc 0.85940, csacc 0.66660, chstimgn_loss 0.29553, chestimg_macro_f1 0.42563, 125.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94200, tacc(al2) 0.81400, tacc(ob0) 0.98900, tacc(ob1) 0.97400, tacc(ob2) 0.85400, tacc(ob3) 0.98500, tacc(ob4) 0.92800, 10.07 secs\n",
      "\u001b[1m---- Epoch 38/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.60524, triplet_loss 0.44843, c_loss 0.19481, hs_loss 0.36758, cs_loss 0.85925, cacc 0.92772, hsacc 0.86272, csacc 0.68180, chstimgn_loss 0.27544, chestimg_macro_f1 0.43699, 125.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94100, tacc(al2) 0.81300, tacc(ob0) 0.98600, tacc(ob1) 0.98000, tacc(ob2) 0.86600, tacc(ob3) 0.98600, tacc(ob4) 0.95300, 10.29 secs\n",
      "\u001b[1m---- Epoch 39/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.57083, triplet_loss 0.44570, c_loss 0.18452, hs_loss 0.33773, cs_loss 0.79257, cacc 0.93552, hsacc 0.87916, csacc 0.70328, chstimgn_loss 0.26140, chestimg_macro_f1 0.44471, 125.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.81300, tacc(ob0) 0.98700, tacc(ob1) 0.98200, tacc(ob2) 0.87000, tacc(ob3) 0.98500, tacc(ob4) 0.95000, 10.39 secs\n",
      "\u001b[1m---- Epoch 40/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.54967, triplet_loss 0.44461, c_loss 0.15647, hs_loss 0.32246, cs_loss 0.76272, cacc 0.93908, hsacc 0.88024, csacc 0.71404, chstimgn_loss 0.25620, chestimg_macro_f1 0.44810, 124.10 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94900, tacc(al2) 0.80700, tacc(ob0) 0.98700, tacc(ob1) 0.97900, tacc(ob2) 0.86900, tacc(ob3) 0.98800, tacc(ob4) 0.95100, 9.53 secs\n",
      "\u001b[1m---- Epoch 41/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.54163, triplet_loss 0.44338, c_loss 0.16287, hs_loss 0.30965, cs_loss 0.74135, cacc 0.94240, hsacc 0.87924, csacc 0.71952, chstimgn_loss 0.25463, chestimg_macro_f1 0.44920, 124.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95400, tacc(al2) 0.81000, tacc(ob0) 0.98800, tacc(ob1) 0.98300, tacc(ob2) 0.87100, tacc(ob3) 0.98900, tacc(ob4) 0.94800, 10.55 secs\n",
      "\u001b[1m---- Epoch 42/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53794, triplet_loss 0.44410, c_loss 0.14456, hs_loss 0.32109, cs_loss 0.73369, cacc 0.94080, hsacc 0.88900, csacc 0.72184, chstimgn_loss 0.25416, chestimg_macro_f1 0.45037, 126.10 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95300, tacc(al2) 0.81200, tacc(ob0) 0.98700, tacc(ob1) 0.98300, tacc(ob2) 0.87300, tacc(ob3) 0.98900, tacc(ob4) 0.95200, 10.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9132.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.53099, triplet_loss 0.44429, c_loss 0.16253, hs_loss 0.28969, cs_loss 0.72361, cacc 0.94112, hsacc 0.89084, csacc 0.72076, chstimgn_loss 0.25191, chestimg_macro_f1 0.45034, 125.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95300, tacc(al2) 0.81300, tacc(ob0) 0.98800, tacc(ob1) 0.98200, tacc(ob2) 0.87200, tacc(ob3) 0.98800, tacc(ob4) 0.95100, 10.03 secs\n",
      "\u001b[1m---- Epoch 44/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.53112, triplet_loss 0.44270, c_loss 0.14401, hs_loss 0.30367, cs_loss 0.73512, cacc 0.94376, hsacc 0.88632, csacc 0.72376, chstimgn_loss 0.24950, chestimg_macro_f1 0.45164, 124.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.81300, tacc(ob0) 0.98700, tacc(ob1) 0.98300, tacc(ob2) 0.87400, tacc(ob3) 0.98900, tacc(ob4) 0.95100, 9.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_44_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9133.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 45/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.60168, triplet_loss 0.44860, c_loss 0.21751, hs_loss 0.36582, cs_loss 0.86406, cacc 0.92868, hsacc 0.86628, csacc 0.67784, chstimgn_loss 0.25536, chestimg_macro_f1 0.44633, 125.96 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98600, tacc(al1) 0.94800, tacc(al2) 0.79300, tacc(ob0) 0.99200, tacc(ob1) 0.96700, tacc(ob2) 0.87300, tacc(ob3) 0.98400, tacc(ob4) 0.93900, 8.45 secs\n",
      "\u001b[1m---- Epoch 46/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.57797, triplet_loss 0.44843, c_loss 0.17154, hs_loss 0.35968, cs_loss 0.84538, cacc 0.93496, hsacc 0.86248, csacc 0.68672, chstimgn_loss 0.24343, chestimg_macro_f1 0.45211, 124.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.82600, tacc(ob0) 0.99000, tacc(ob1) 0.97500, tacc(ob2) 0.87700, tacc(ob3) 0.98100, tacc(ob4) 0.94600, 9.90 secs\n",
      "\u001b[1m---- Epoch 47/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.54528, triplet_loss 0.44773, c_loss 0.16576, hs_loss 0.32059, cs_loss 0.78418, cacc 0.93544, hsacc 0.87900, csacc 0.70284, chstimgn_loss 0.23143, chestimg_macro_f1 0.46073, 125.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.82000, tacc(ob0) 0.99100, tacc(ob1) 0.96900, tacc(ob2) 0.88100, tacc(ob3) 0.98400, tacc(ob4) 0.94700, 10.11 secs\n",
      "\u001b[1m---- Epoch 48/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.53072, triplet_loss 0.44403, c_loss 0.16199, hs_loss 0.30724, cs_loss 0.75601, cacc 0.93824, hsacc 0.88440, csacc 0.71308, chstimgn_loss 0.22680, chestimg_macro_f1 0.46246, 119.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.82800, tacc(ob0) 0.99100, tacc(ob1) 0.96600, tacc(ob2) 0.87600, tacc(ob3) 0.98800, tacc(ob4) 0.95000, 9.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_48_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9137.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 49/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.52751, triplet_loss 0.44235, c_loss 0.15178, hs_loss 0.30980, cs_loss 0.75724, cacc 0.94352, hsacc 0.88552, csacc 0.71332, chstimgn_loss 0.22444, chestimg_macro_f1 0.46344, 121.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95600, tacc(al2) 0.82600, tacc(ob0) 0.99100, tacc(ob1) 0.96900, tacc(ob2) 0.87700, tacc(ob3) 0.98900, tacc(ob4) 0.95000, 9.96 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9145.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.52254, triplet_loss 0.44358, c_loss 0.16549, hs_loss 0.30105, cs_loss 0.73166, cacc 0.94028, hsacc 0.88868, csacc 0.72372, chstimgn_loss 0.22418, chestimg_macro_f1 0.46490, 124.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95700, tacc(al2) 0.81600, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.87400, tacc(ob3) 0.98900, tacc(ob4) 0.95200, 9.68 secs\n",
      "\u001b[1m---- Epoch 51/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.51884, triplet_loss 0.44323, c_loss 0.16473, hs_loss 0.29054, cs_loss 0.73261, cacc 0.94304, hsacc 0.89120, csacc 0.72460, chstimgn_loss 0.22211, chestimg_macro_f1 0.46551, 125.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95700, tacc(al2) 0.81800, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.87000, tacc(ob3) 0.98900, tacc(ob4) 0.94800, 10.17 secs\n",
      "\u001b[1m---- Epoch 52/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.52336, triplet_loss 0.44278, c_loss 0.16190, hs_loss 0.30916, cs_loss 0.73011, cacc 0.94212, hsacc 0.88696, csacc 0.72448, chstimgn_loss 0.22473, chestimg_macro_f1 0.46506, 125.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95700, tacc(al2) 0.81600, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.87200, tacc(ob3) 0.99000, tacc(ob4) 0.94900, 10.20 secs\n",
      "\u001b[1m---- Epoch 53/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.59010, triplet_loss 0.45116, c_loss 0.21357, hs_loss 0.36847, cs_loss 0.87433, cacc 0.92788, hsacc 0.86860, csacc 0.68084, chstimgn_loss 0.22643, chestimg_macro_f1 0.45990, 123.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94200, tacc(al2) 0.81700, tacc(ob0) 0.99100, tacc(ob1) 0.96100, tacc(ob2) 0.87500, tacc(ob3) 0.97800, tacc(ob4) 0.94400, 9.82 secs\n",
      "\u001b[1m---- Epoch 54/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.56108, triplet_loss 0.44794, c_loss 0.17952, hs_loss 0.34719, cs_loss 0.83576, cacc 0.93140, hsacc 0.87008, csacc 0.68628, chstimgn_loss 0.21696, chestimg_macro_f1 0.46582, 125.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94100, tacc(al2) 0.83900, tacc(ob0) 0.99100, tacc(ob1) 0.96100, tacc(ob2) 0.88400, tacc(ob3) 0.98400, tacc(ob4) 0.93800, 9.91 secs\n",
      "\u001b[1m---- Epoch 55/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.52912, triplet_loss 0.44710, c_loss 0.16305, hs_loss 0.32222, cs_loss 0.77221, cacc 0.93732, hsacc 0.88000, csacc 0.70832, chstimgn_loss 0.20595, chestimg_macro_f1 0.47225, 124.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.82300, tacc(ob0) 0.99000, tacc(ob1) 0.96900, tacc(ob2) 0.86700, tacc(ob3) 0.98700, tacc(ob4) 0.94500, 10.12 secs\n",
      "\u001b[1m---- Epoch 56/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.52253, triplet_loss 0.44515, c_loss 0.16759, hs_loss 0.31983, cs_loss 0.75323, cacc 0.94304, hsacc 0.88092, csacc 0.71844, chstimgn_loss 0.20216, chestimg_macro_f1 0.47610, 123.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95000, tacc(al2) 0.82200, tacc(ob0) 0.99100, tacc(ob1) 0.97500, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.94900, 9.61 secs\n",
      "\u001b[1m---- Epoch 57/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.50927, triplet_loss 0.44287, c_loss 0.16398, hs_loss 0.30106, cs_loss 0.72658, cacc 0.94424, hsacc 0.88304, csacc 0.72692, chstimgn_loss 0.20129, chestimg_macro_f1 0.47745, 120.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.82000, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.86700, tacc(ob3) 0.98900, tacc(ob4) 0.94900, 9.51 secs\n",
      "\u001b[1m---- Epoch 58/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.51104, triplet_loss 0.44324, c_loss 0.14446, hs_loss 0.31979, cs_loss 0.73624, cacc 0.94380, hsacc 0.88072, csacc 0.71952, chstimgn_loss 0.20022, chestimg_macro_f1 0.47951, 119.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.81900, tacc(ob0) 0.99000, tacc(ob1) 0.97200, tacc(ob2) 0.87300, tacc(ob3) 0.99000, tacc(ob4) 0.94800, 9.79 secs\n",
      "\u001b[1m---- Epoch 59/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.50734, triplet_loss 0.44403, c_loss 0.15144, hs_loss 0.30398, cs_loss 0.73325, cacc 0.94264, hsacc 0.88528, csacc 0.72488, chstimgn_loss 0.19833, chestimg_macro_f1 0.47904, 123.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95000, tacc(al2) 0.81800, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.86600, tacc(ob3) 0.98900, tacc(ob4) 0.94700, 9.74 secs\n",
      "\u001b[1m---- Epoch 60/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.50146, triplet_loss 0.44304, c_loss 0.14846, hs_loss 0.28972, cs_loss 0.72611, cacc 0.94492, hsacc 0.88980, csacc 0.72756, chstimgn_loss 0.19926, chestimg_macro_f1 0.47956, 123.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.81900, tacc(ob0) 0.99000, tacc(ob1) 0.97400, tacc(ob2) 0.86600, tacc(ob3) 0.98900, tacc(ob4) 0.94600, 10.21 secs\n",
      "\u001b[1m---- Epoch 61/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.56376, triplet_loss 0.44962, c_loss 0.19230, hs_loss 0.36369, cs_loss 0.83735, cacc 0.92920, hsacc 0.86248, csacc 0.68220, chstimgn_loss 0.20604, chestimg_macro_f1 0.47445, 123.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94200, tacc(al2) 0.80700, tacc(ob0) 0.99100, tacc(ob1) 0.96900, tacc(ob2) 0.87100, tacc(ob3) 0.98000, tacc(ob4) 0.94500, 9.87 secs\n",
      "\u001b[1m---- Epoch 62/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.54278, triplet_loss 0.44796, c_loss 0.17046, hs_loss 0.35063, cs_loss 0.81375, cacc 0.93824, hsacc 0.87068, csacc 0.69600, chstimgn_loss 0.19415, chestimg_macro_f1 0.47993, 124.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94800, tacc(al2) 0.81400, tacc(ob0) 0.99200, tacc(ob1) 0.96800, tacc(ob2) 0.87800, tacc(ob3) 0.98400, tacc(ob4) 0.94900, 9.42 secs\n",
      "\u001b[1m---- Epoch 63/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.51724, triplet_loss 0.44458, c_loss 0.15987, hs_loss 0.33500, cs_loss 0.75877, cacc 0.93908, hsacc 0.87980, csacc 0.71176, chstimgn_loss 0.18538, chestimg_macro_f1 0.48712, 122.28 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98400, tacc(al1) 0.94900, tacc(al2) 0.81200, tacc(ob0) 0.98900, tacc(ob1) 0.97200, tacc(ob2) 0.87500, tacc(ob3) 0.98400, tacc(ob4) 0.94800, 10.41 secs\n",
      "\u001b[1m---- Epoch 64/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.50554, triplet_loss 0.44342, c_loss 0.16508, hs_loss 0.31963, cs_loss 0.73217, cacc 0.94136, hsacc 0.88224, csacc 0.72028, chstimgn_loss 0.18094, chestimg_macro_f1 0.48858, 123.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95700, tacc(al2) 0.80500, tacc(ob0) 0.99000, tacc(ob1) 0.97300, tacc(ob2) 0.87500, tacc(ob3) 0.98300, tacc(ob4) 0.94700, 9.60 secs\n",
      "\u001b[1m---- Epoch 65/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.49352, triplet_loss 0.44292, c_loss 0.14158, hs_loss 0.30278, cs_loss 0.72586, cacc 0.94248, hsacc 0.88312, csacc 0.72700, chstimgn_loss 0.18048, chestimg_macro_f1 0.49091, 124.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95600, tacc(al2) 0.81300, tacc(ob0) 0.99200, tacc(ob1) 0.97300, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.94700, 9.82 secs\n",
      "\u001b[1m---- Epoch 66/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.48618, triplet_loss 0.44294, c_loss 0.14570, hs_loss 0.28844, cs_loss 0.70804, cacc 0.94368, hsacc 0.88972, csacc 0.73048, chstimgn_loss 0.17979, chestimg_macro_f1 0.49247, 123.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95600, tacc(al2) 0.81200, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.87500, tacc(ob3) 0.98700, tacc(ob4) 0.94800, 10.24 secs\n",
      "\u001b[1m---- Epoch 67/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.49078, triplet_loss 0.44112, c_loss 0.14822, hs_loss 0.30019, cs_loss 0.71613, cacc 0.94480, hsacc 0.88772, csacc 0.72836, chstimgn_loss 0.17874, chestimg_macro_f1 0.49163, 122.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95700, tacc(al2) 0.81000, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.87900, tacc(ob3) 0.98700, tacc(ob4) 0.94500, 9.57 secs\n",
      "\u001b[1m---- Epoch 68/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.49493, triplet_loss 0.44348, c_loss 0.15350, hs_loss 0.30722, cs_loss 0.71572, cacc 0.94340, hsacc 0.88528, csacc 0.72896, chstimgn_loss 0.17990, chestimg_macro_f1 0.49131, 124.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95700, tacc(al2) 0.81100, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.87600, tacc(ob3) 0.98700, tacc(ob4) 0.94600, 9.03 secs\n",
      "\u001b[1m---- Epoch 69/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.56416, triplet_loss 0.45211, c_loss 0.19465, hs_loss 0.37436, cs_loss 0.85641, cacc 0.92740, hsacc 0.85628, csacc 0.68088, chstimgn_loss 0.18955, chestimg_macro_f1 0.48388, 122.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94200, tacc(al2) 0.82600, tacc(ob0) 0.99000, tacc(ob1) 0.96900, tacc(ob2) 0.87300, tacc(ob3) 0.99000, tacc(ob4) 0.94800, 9.72 secs\n",
      "\u001b[1m---- Epoch 70/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.54366, triplet_loss 0.44724, c_loss 0.18808, hs_loss 0.36116, cs_loss 0.82131, cacc 0.93412, hsacc 0.87092, csacc 0.69316, chstimgn_loss 0.17843, chestimg_macro_f1 0.49141, 125.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94600, tacc(al2) 0.81900, tacc(ob0) 0.98700, tacc(ob1) 0.97300, tacc(ob2) 0.86500, tacc(ob3) 0.98500, tacc(ob4) 0.95300, 10.40 secs\n",
      "\u001b[1m---- Epoch 71/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.51003, triplet_loss 0.44313, c_loss 0.16372, hs_loss 0.32170, cs_loss 0.76795, cacc 0.94304, hsacc 0.87924, csacc 0.70892, chstimgn_loss 0.17180, chestimg_macro_f1 0.49887, 123.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94700, tacc(al2) 0.81100, tacc(ob0) 0.98700, tacc(ob1) 0.97400, tacc(ob2) 0.87000, tacc(ob3) 0.98800, tacc(ob4) 0.95000, 10.00 secs\n",
      "\u001b[1m---- Epoch 72/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.50031, triplet_loss 0.44390, c_loss 0.16161, hs_loss 0.31351, cs_loss 0.74829, cacc 0.93924, hsacc 0.88436, csacc 0.71412, chstimgn_loss 0.16696, chestimg_macro_f1 0.50131, 124.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94700, tacc(al2) 0.80500, tacc(ob0) 0.99000, tacc(ob1) 0.97300, tacc(ob2) 0.87100, tacc(ob3) 0.98900, tacc(ob4) 0.94500, 9.86 secs\n",
      "\u001b[1m---- Epoch 73/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.49265, triplet_loss 0.44546, c_loss 0.15102, hs_loss 0.30251, cs_loss 0.73865, cacc 0.94400, hsacc 0.88760, csacc 0.72060, chstimgn_loss 0.16647, chestimg_macro_f1 0.50280, 123.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94300, tacc(al2) 0.80500, tacc(ob0) 0.98900, tacc(ob1) 0.97700, tacc(ob2) 0.86200, tacc(ob3) 0.98900, tacc(ob4) 0.94600, 9.60 secs\n",
      "\u001b[1m---- Epoch 74/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.48924, triplet_loss 0.44169, c_loss 0.15860, hs_loss 0.29864, cs_loss 0.73065, cacc 0.94392, hsacc 0.89048, csacc 0.71992, chstimgn_loss 0.16370, chestimg_macro_f1 0.50491, 123.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.80500, tacc(ob0) 0.99000, tacc(ob1) 0.97800, tacc(ob2) 0.86400, tacc(ob3) 0.98900, tacc(ob4) 0.94800, 9.77 secs\n",
      "\u001b[1m---- Epoch 75/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.48746, triplet_loss 0.44178, c_loss 0.15664, hs_loss 0.30913, cs_loss 0.71328, cacc 0.94136, hsacc 0.88748, csacc 0.73016, chstimgn_loss 0.16449, chestimg_macro_f1 0.50423, 124.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94600, tacc(al2) 0.80900, tacc(ob0) 0.98900, tacc(ob1) 0.97700, tacc(ob2) 0.86600, tacc(ob3) 0.98900, tacc(ob4) 0.94700, 9.69 secs\n",
      "\u001b[1m---- Epoch 76/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.48699, triplet_loss 0.44316, c_loss 0.15327, hs_loss 0.29532, cs_loss 0.72939, cacc 0.94560, hsacc 0.89048, csacc 0.72464, chstimgn_loss 0.16341, chestimg_macro_f1 0.50601, 124.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.80900, tacc(ob0) 0.98900, tacc(ob1) 0.97700, tacc(ob2) 0.86700, tacc(ob3) 0.98900, tacc(ob4) 0.94700, 9.82 secs\n",
      "\u001b[1m---- Epoch 77/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.55673, triplet_loss 0.45087, c_loss 0.21691, hs_loss 0.35757, cs_loss 0.85407, cacc 0.92788, hsacc 0.86468, csacc 0.68168, chstimgn_loss 0.17375, chestimg_macro_f1 0.49618, 122.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97700, tacc(al1) 0.93900, tacc(al2) 0.81700, tacc(ob0) 0.99100, tacc(ob1) 0.97300, tacc(ob2) 0.88000, tacc(ob3) 0.98100, tacc(ob4) 0.93800, 9.79 secs\n",
      "\u001b[1m---- Epoch 78/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.53173, triplet_loss 0.45116, c_loss 0.17510, hs_loss 0.34279, cs_loss 0.83002, cacc 0.93464, hsacc 0.86964, csacc 0.68988, chstimgn_loss 0.16393, chestimg_macro_f1 0.50222, 122.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94600, tacc(al2) 0.81100, tacc(ob0) 0.98500, tacc(ob1) 0.96700, tacc(ob2) 0.86900, tacc(ob3) 0.98800, tacc(ob4) 0.94300, 9.53 secs\n",
      "\u001b[1m---- Epoch 79/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.51206, triplet_loss 0.44488, c_loss 0.16948, hs_loss 0.33460, cs_loss 0.78448, cacc 0.94008, hsacc 0.88152, csacc 0.70656, chstimgn_loss 0.15740, chestimg_macro_f1 0.50933, 123.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95000, tacc(al2) 0.81700, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.87800, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 9.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_79_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9157.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 80/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.48451, triplet_loss 0.44366, c_loss 0.14921, hs_loss 0.29754, cs_loss 0.73847, cacc 0.94516, hsacc 0.88376, csacc 0.71740, chstimgn_loss 0.15458, chestimg_macro_f1 0.51261, 122.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94700, tacc(al2) 0.80700, tacc(ob0) 0.99300, tacc(ob1) 0.97300, tacc(ob2) 0.87600, tacc(ob3) 0.99100, tacc(ob4) 0.95200, 9.90 secs\n",
      "\u001b[1m---- Epoch 81/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.48264, triplet_loss 0.44290, c_loss 0.16327, hs_loss 0.30098, cs_loss 0.71958, cacc 0.94388, hsacc 0.88740, csacc 0.72612, chstimgn_loss 0.15192, chestimg_macro_f1 0.51485, 124.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95200, tacc(al2) 0.80900, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.88000, tacc(ob3) 0.99000, tacc(ob4) 0.94900, 10.23 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 82/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.48090, triplet_loss 0.44315, c_loss 0.15586, hs_loss 0.30064, cs_loss 0.71987, cacc 0.94244, hsacc 0.88752, csacc 0.72540, chstimgn_loss 0.15204, chestimg_macro_f1 0.51647, 124.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94900, tacc(al2) 0.81000, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.88100, tacc(ob3) 0.99000, tacc(ob4) 0.94800, 9.61 secs\n",
      "\u001b[1m---- Epoch 83/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.47742, triplet_loss 0.44456, c_loss 0.14649, hs_loss 0.30338, cs_loss 0.71450, cacc 0.94532, hsacc 0.88392, csacc 0.72744, chstimgn_loss 0.15038, chestimg_macro_f1 0.51698, 125.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95000, tacc(al2) 0.80800, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.87800, tacc(ob3) 0.99000, tacc(ob4) 0.94900, 9.83 secs\n",
      "\u001b[1m---- Epoch 84/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.47589, triplet_loss 0.44346, c_loss 0.14456, hs_loss 0.29364, cs_loss 0.71912, cacc 0.94632, hsacc 0.88772, csacc 0.72612, chstimgn_loss 0.15140, chestimg_macro_f1 0.51638, 124.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94800, tacc(al2) 0.80600, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.87900, tacc(ob3) 0.99000, tacc(ob4) 0.94800, 9.58 secs\n",
      "\u001b[1m---- Epoch 85/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.55385, triplet_loss 0.44806, c_loss 0.21270, hs_loss 0.36887, cs_loss 0.86238, cacc 0.92900, hsacc 0.86956, csacc 0.67864, chstimgn_loss 0.16168, chestimg_macro_f1 0.50590, 123.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94500, tacc(al2) 0.81100, tacc(ob0) 0.98900, tacc(ob1) 0.96700, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.94100, 9.54 secs\n",
      "\u001b[1m---- Epoch 86/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.53027, triplet_loss 0.44829, c_loss 0.18862, hs_loss 0.34781, cs_loss 0.82900, cacc 0.93564, hsacc 0.86924, csacc 0.68800, chstimgn_loss 0.15368, chestimg_macro_f1 0.51469, 125.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94400, tacc(al2) 0.82200, tacc(ob0) 0.99500, tacc(ob1) 0.96500, tacc(ob2) 0.87700, tacc(ob3) 0.98400, tacc(ob4) 0.94900, 9.75 secs\n",
      "\u001b[1m---- Epoch 87/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.49947, triplet_loss 0.44523, c_loss 0.16525, hs_loss 0.31808, cs_loss 0.77707, cacc 0.93632, hsacc 0.87796, csacc 0.70720, chstimgn_loss 0.14612, chestimg_macro_f1 0.52069, 123.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95100, tacc(al2) 0.81300, tacc(ob0) 0.99200, tacc(ob1) 0.97100, tacc(ob2) 0.88900, tacc(ob3) 0.98500, tacc(ob4) 0.94900, 9.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_87_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9157.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 88/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.48644, triplet_loss 0.44265, c_loss 0.17497, hs_loss 0.30402, cs_loss 0.73864, cacc 0.93676, hsacc 0.88392, csacc 0.71788, chstimgn_loss 0.14274, chestimg_macro_f1 0.52349, 122.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.80300, tacc(ob0) 0.99300, tacc(ob1) 0.97200, tacc(ob2) 0.88100, tacc(ob3) 0.98400, tacc(ob4) 0.94900, 9.69 secs\n",
      "\u001b[1m---- Epoch 89/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.48377, triplet_loss 0.44260, c_loss 0.16960, hs_loss 0.30899, cs_loss 0.72936, cacc 0.93864, hsacc 0.88412, csacc 0.72284, chstimgn_loss 0.14226, chestimg_macro_f1 0.52556, 124.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.81200, tacc(ob0) 0.99300, tacc(ob1) 0.97400, tacc(ob2) 0.88100, tacc(ob3) 0.98700, tacc(ob4) 0.94900, 9.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_89_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9159.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 90/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.47727, triplet_loss 0.44274, c_loss 0.15980, hs_loss 0.30344, cs_loss 0.72173, cacc 0.94164, hsacc 0.88156, csacc 0.72568, chstimgn_loss 0.14069, chestimg_macro_f1 0.52722, 125.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.81000, tacc(ob0) 0.99500, tacc(ob1) 0.97300, tacc(ob2) 0.88200, tacc(ob3) 0.98800, tacc(ob4) 0.95000, 9.48 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_90_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9165.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 91/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.47597, triplet_loss 0.44349, c_loss 0.15397, hs_loss 0.29737, cs_loss 0.72848, cacc 0.94176, hsacc 0.88828, csacc 0.72420, chstimgn_loss 0.14029, chestimg_macro_f1 0.52761, 123.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.80600, tacc(ob0) 0.99400, tacc(ob1) 0.97400, tacc(ob2) 0.88400, tacc(ob3) 0.98800, tacc(ob4) 0.94900, 9.66 secs\n",
      "\u001b[1m---- Epoch 92/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.48275, triplet_loss 0.44314, c_loss 0.17185, hs_loss 0.32248, cs_loss 0.71601, cacc 0.94004, hsacc 0.87968, csacc 0.72472, chstimgn_loss 0.13877, chestimg_macro_f1 0.53185, 122.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.80500, tacc(ob0) 0.99400, tacc(ob1) 0.97400, tacc(ob2) 0.88400, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 9.68 secs\n",
      "\u001b[1m---- Epoch 93/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.53027, triplet_loss 0.44741, c_loss 0.18657, hs_loss 0.36348, cs_loss 0.82212, cacc 0.92804, hsacc 0.86784, csacc 0.68800, chstimgn_loss 0.15076, chestimg_macro_f1 0.51686, 122.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93800, tacc(al2) 0.80500, tacc(ob0) 0.98700, tacc(ob1) 0.97300, tacc(ob2) 0.87400, tacc(ob3) 0.98400, tacc(ob4) 0.94700, 9.91 secs\n",
      "\u001b[1m---- Epoch 94/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.51212, triplet_loss 0.44585, c_loss 0.17900, hs_loss 0.32835, cs_loss 0.81358, cacc 0.93304, hsacc 0.87792, csacc 0.69532, chstimgn_loss 0.14085, chestimg_macro_f1 0.52464, 123.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95100, tacc(al2) 0.83500, tacc(ob0) 0.99400, tacc(ob1) 0.97600, tacc(ob2) 0.87900, tacc(ob3) 0.98400, tacc(ob4) 0.95500, 12.28 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_94_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9184.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 95/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.48968, triplet_loss 0.44450, c_loss 0.16195, hs_loss 0.31975, cs_loss 0.76122, cacc 0.94024, hsacc 0.88096, csacc 0.71172, chstimgn_loss 0.13566, chestimg_macro_f1 0.53992, 123.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94500, tacc(al2) 0.81200, tacc(ob0) 0.99200, tacc(ob1) 0.97000, tacc(ob2) 0.87700, tacc(ob3) 0.98400, tacc(ob4) 0.95500, 9.96 secs\n",
      "\u001b[1m---- Epoch 96/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.47485, triplet_loss 0.44371, c_loss 0.15360, hs_loss 0.31204, cs_loss 0.72441, cacc 0.94136, hsacc 0.88612, csacc 0.72204, chstimgn_loss 0.13282, chestimg_macro_f1 0.53646, 123.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94800, tacc(al2) 0.81700, tacc(ob0) 0.99000, tacc(ob1) 0.97000, tacc(ob2) 0.87600, tacc(ob3) 0.98600, tacc(ob4) 0.95200, 8.35 secs\n",
      "\u001b[1m---- Epoch 97/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.46776, triplet_loss 0.44236, c_loss 0.14673, hs_loss 0.29514, cs_loss 0.72435, cacc 0.94408, hsacc 0.88744, csacc 0.72516, chstimgn_loss 0.13123, chestimg_macro_f1 0.53759, 123.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94600, tacc(al2) 0.81700, tacc(ob0) 0.99200, tacc(ob1) 0.97300, tacc(ob2) 0.88000, tacc(ob3) 0.98400, tacc(ob4) 0.95400, 9.49 secs\n",
      "\u001b[1m---- Epoch 98/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.46575, triplet_loss 0.44383, c_loss 0.13685, hs_loss 0.30987, cs_loss 0.71293, cacc 0.94332, hsacc 0.88848, csacc 0.72512, chstimgn_loss 0.12976, chestimg_macro_f1 0.53977, 124.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94400, tacc(al2) 0.82000, tacc(ob0) 0.99400, tacc(ob1) 0.97100, tacc(ob2) 0.87700, tacc(ob3) 0.98400, tacc(ob4) 0.95000, 9.67 secs\n",
      "\u001b[1m---- Epoch 99/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.46201, triplet_loss 0.44126, c_loss 0.13456, hs_loss 0.29303, cs_loss 0.71984, cacc 0.94516, hsacc 0.88988, csacc 0.72140, chstimgn_loss 0.12967, chestimg_macro_f1 0.54040, 124.59 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98400, tacc(al1) 0.94400, tacc(al2) 0.81800, tacc(ob0) 0.99300, tacc(ob1) 0.97100, tacc(ob2) 0.87900, tacc(ob3) 0.98400, tacc(ob4) 0.95100, 9.28 secs\n",
      "\u001b[1m---- Epoch 100/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.46676, triplet_loss 0.44220, c_loss 0.14301, hs_loss 0.29776, cs_loss 0.72395, cacc 0.94444, hsacc 0.88876, csacc 0.72300, chstimgn_loss 0.13006, chestimg_macro_f1 0.54008, 124.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94500, tacc(al2) 0.82100, tacc(ob0) 0.99300, tacc(ob1) 0.97100, tacc(ob2) 0.87700, tacc(ob3) 0.98500, tacc(ob4) 0.95200, 9.45 secs\n",
      "\u001b[1m---- Epoch 101/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.52395, triplet_loss 0.44640, c_loss 0.19981, hs_loss 0.34679, cs_loss 0.82503, cacc 0.92964, hsacc 0.87152, csacc 0.68872, chstimgn_loss 0.13888, chestimg_macro_f1 0.53660, 124.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.81700, tacc(ob0) 0.98700, tacc(ob1) 0.97800, tacc(ob2) 0.87000, tacc(ob3) 0.98100, tacc(ob4) 0.94700, 10.35 secs\n",
      "\u001b[1m---- Epoch 102/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.50503, triplet_loss 0.44482, c_loss 0.18196, hs_loss 0.32901, cs_loss 0.79700, cacc 0.93360, hsacc 0.87256, csacc 0.70012, chstimgn_loss 0.13366, chestimg_macro_f1 0.53800, 124.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.81400, tacc(ob0) 0.99100, tacc(ob1) 0.97600, tacc(ob2) 0.87900, tacc(ob3) 0.98400, tacc(ob4) 0.94900, 9.68 secs\n",
      "\u001b[1m---- Epoch 103/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.48002, triplet_loss 0.44301, c_loss 0.15291, hs_loss 0.32211, cs_loss 0.74615, cacc 0.94296, hsacc 0.87360, csacc 0.71692, chstimgn_loss 0.12796, chestimg_macro_f1 0.54309, 124.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.82000, tacc(ob0) 0.99300, tacc(ob1) 0.98000, tacc(ob2) 0.87900, tacc(ob3) 0.98400, tacc(ob4) 0.95200, 9.96 secs\n",
      "\u001b[1m---- Epoch 104/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.47383, triplet_loss 0.44402, c_loss 0.16726, hs_loss 0.30064, cs_loss 0.73243, cacc 0.94264, hsacc 0.88732, csacc 0.72004, chstimgn_loss 0.12549, chestimg_macro_f1 0.54700, 123.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94900, tacc(al2) 0.81600, tacc(ob0) 0.99300, tacc(ob1) 0.97700, tacc(ob2) 0.87900, tacc(ob3) 0.98600, tacc(ob4) 0.95100, 9.83 secs\n",
      "\u001b[1m---- Epoch 105/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.46158, triplet_loss 0.44145, c_loss 0.13985, hs_loss 0.29767, cs_loss 0.72328, cacc 0.94524, hsacc 0.88556, csacc 0.72428, chstimgn_loss 0.12205, chestimg_macro_f1 0.54911, 124.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95200, tacc(al2) 0.82100, tacc(ob0) 0.99200, tacc(ob1) 0.97500, tacc(ob2) 0.87600, tacc(ob3) 0.98900, tacc(ob4) 0.95000, 8.90 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_105_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9187.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 106/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.45784, triplet_loss 0.44227, c_loss 0.14313, hs_loss 0.29530, cs_loss 0.70702, cacc 0.94336, hsacc 0.88940, csacc 0.73120, chstimgn_loss 0.12183, chestimg_macro_f1 0.55030, 124.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.81700, tacc(ob0) 0.99300, tacc(ob1) 0.97700, tacc(ob2) 0.87900, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 9.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_106_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9189.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 107/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.45632, triplet_loss 0.44258, c_loss 0.13877, hs_loss 0.29494, cs_loss 0.70666, cacc 0.94428, hsacc 0.88732, csacc 0.72684, chstimgn_loss 0.12117, chestimg_macro_f1 0.55413, 123.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95400, tacc(al2) 0.81800, tacc(ob0) 0.99000, tacc(ob1) 0.97700, tacc(ob2) 0.87900, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 9.51 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_107_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9190.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 108/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.45323, triplet_loss 0.44170, c_loss 0.14139, hs_loss 0.28349, cs_loss 0.70406, cacc 0.94292, hsacc 0.89020, csacc 0.72808, chstimgn_loss 0.12114, chestimg_macro_f1 0.55329, 123.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95500, tacc(al2) 0.81500, tacc(ob0) 0.99100, tacc(ob1) 0.97700, tacc(ob2) 0.87900, tacc(ob3) 0.98700, tacc(ob4) 0.94900, 10.22 secs\n",
      "\u001b[1m---- Epoch 109/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.51093, triplet_loss 0.44631, c_loss 0.16873, hs_loss 0.34863, cs_loss 0.81523, cacc 0.93744, hsacc 0.87040, csacc 0.69336, chstimgn_loss 0.13240, chestimg_macro_f1 0.53907, 125.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94200, tacc(al2) 0.82500, tacc(ob0) 0.99200, tacc(ob1) 0.97600, tacc(ob2) 0.87000, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 9.41 secs\n",
      "\u001b[1m---- Epoch 110/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.49403, triplet_loss 0.44651, c_loss 0.17383, hs_loss 0.32247, cs_loss 0.78324, cacc 0.93432, hsacc 0.87756, csacc 0.69964, chstimgn_loss 0.12505, chestimg_macro_f1 0.54849, 125.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95700, tacc(al2) 0.81800, tacc(ob0) 0.99500, tacc(ob1) 0.97500, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.95100, 10.30 secs\n",
      "\u001b[1m---- Epoch 111/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.47694, triplet_loss 0.44460, c_loss 0.16163, hs_loss 0.30854, cs_loss 0.75750, cacc 0.94284, hsacc 0.88256, csacc 0.71240, chstimgn_loss 0.11775, chestimg_macro_f1 0.55885, 124.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95200, tacc(al2) 0.81700, tacc(ob0) 0.99400, tacc(ob1) 0.97500, tacc(ob2) 0.87800, tacc(ob3) 0.98600, tacc(ob4) 0.94700, 10.24 secs\n",
      "\u001b[1m---- Epoch 112/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.46267, triplet_loss 0.44363, c_loss 0.15201, hs_loss 0.29577, cs_loss 0.72506, cacc 0.94516, hsacc 0.88604, csacc 0.72540, chstimgn_loss 0.11710, chestimg_macro_f1 0.55927, 123.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95200, tacc(al2) 0.81200, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.88100, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 9.73 secs\n",
      "\u001b[1m---- Epoch 113/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.45820, triplet_loss 0.44308, c_loss 0.14618, hs_loss 0.29185, cs_loss 0.72006, cacc 0.94320, hsacc 0.88884, csacc 0.72636, chstimgn_loss 0.11582, chestimg_macro_f1 0.56056, 125.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.81700, tacc(ob0) 0.99300, tacc(ob1) 0.98000, tacc(ob2) 0.88000, tacc(ob3) 0.98700, tacc(ob4) 0.95300, 9.46 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_113_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9202.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 114/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.45219, triplet_loss 0.44281, c_loss 0.13932, hs_loss 0.29359, cs_loss 0.70499, cacc 0.94488, hsacc 0.89188, csacc 0.72840, chstimgn_loss 0.11402, chestimg_macro_f1 0.56243, 123.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.82100, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.95300, 9.79 secs\n",
      "\u001b[1m---- Epoch 115/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.44801, triplet_loss 0.44179, c_loss 0.13615, hs_loss 0.28223, cs_loss 0.70736, cacc 0.94580, hsacc 0.89464, csacc 0.73040, chstimgn_loss 0.11225, chestimg_macro_f1 0.56285, 124.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.81900, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.88100, tacc(ob3) 0.98600, tacc(ob4) 0.95400, 9.58 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_115_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9210.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 116/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44747, triplet_loss 0.44121, c_loss 0.14331, hs_loss 0.27887, cs_loss 0.69806, cacc 0.94676, hsacc 0.89052, csacc 0.73232, chstimgn_loss 0.11421, chestimg_macro_f1 0.56154, 123.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.81600, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.88000, tacc(ob3) 0.98600, tacc(ob4) 0.95300, 9.63 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 117/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.51662, triplet_loss 0.44725, c_loss 0.18539, hs_loss 0.35751, cs_loss 0.82674, cacc 0.92880, hsacc 0.86448, csacc 0.69096, chstimgn_loss 0.12479, chestimg_macro_f1 0.55094, 123.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94200, tacc(al2) 0.81600, tacc(ob0) 0.98700, tacc(ob1) 0.97200, tacc(ob2) 0.86800, tacc(ob3) 0.98400, tacc(ob4) 0.94000, 9.52 secs\n",
      "\u001b[1m---- Epoch 118/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.50839, triplet_loss 0.44607, c_loss 0.18165, hs_loss 0.34806, cs_loss 0.81464, cacc 0.92900, hsacc 0.87044, csacc 0.69148, chstimgn_loss 0.12157, chestimg_macro_f1 0.55501, 125.42 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94700, tacc(al2) 0.81700, tacc(ob0) 0.99100, tacc(ob1) 0.96900, tacc(ob2) 0.87200, tacc(ob3) 0.98500, tacc(ob4) 0.94400, 9.87 secs\n",
      "\u001b[1m---- Epoch 119/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.47855, triplet_loss 0.44435, c_loss 0.16096, hs_loss 0.31727, cs_loss 0.76183, cacc 0.94148, hsacc 0.88292, csacc 0.71096, chstimgn_loss 0.11490, chestimg_macro_f1 0.56148, 128.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95000, tacc(al2) 0.81400, tacc(ob0) 0.99200, tacc(ob1) 0.97500, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 9.91 secs\n",
      "\u001b[1m---- Epoch 120/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.46312, triplet_loss 0.44161, c_loss 0.14671, hs_loss 0.32025, cs_loss 0.72434, cacc 0.94300, hsacc 0.87700, csacc 0.72272, chstimgn_loss 0.10979, chestimg_macro_f1 0.56660, 127.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94500, tacc(al2) 0.81300, tacc(ob0) 0.99300, tacc(ob1) 0.97500, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.95100, 10.09 secs\n",
      "\u001b[1m---- Epoch 121/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.45491, triplet_loss 0.44122, c_loss 0.14047, hs_loss 0.29775, cs_loss 0.71953, cacc 0.94208, hsacc 0.88788, csacc 0.72256, chstimgn_loss 0.11034, chestimg_macro_f1 0.56873, 127.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94900, tacc(al2) 0.81200, tacc(ob0) 0.99100, tacc(ob1) 0.97700, tacc(ob2) 0.87300, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 9.82 secs\n",
      "\u001b[1m---- Epoch 122/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.45506, triplet_loss 0.44281, c_loss 0.14862, hs_loss 0.30205, cs_loss 0.70738, cacc 0.94896, hsacc 0.88424, csacc 0.72880, chstimgn_loss 0.10969, chestimg_macro_f1 0.57200, 126.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.80900, tacc(ob0) 0.99100, tacc(ob1) 0.98000, tacc(ob2) 0.87100, tacc(ob3) 0.98600, tacc(ob4) 0.95100, 9.65 secs\n",
      "\u001b[1m---- Epoch 123/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.44864, triplet_loss 0.44234, c_loss 0.13664, hs_loss 0.28970, cs_loss 0.70968, cacc 0.94604, hsacc 0.88988, csacc 0.72800, chstimgn_loss 0.10810, chestimg_macro_f1 0.56914, 125.51 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94700, tacc(al2) 0.80900, tacc(ob0) 0.99200, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.98700, tacc(ob4) 0.94900, 9.85 secs\n",
      "\u001b[1m---- Epoch 124/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44882, triplet_loss 0.44294, c_loss 0.14135, hs_loss 0.28995, cs_loss 0.70789, cacc 0.94436, hsacc 0.89400, csacc 0.72832, chstimgn_loss 0.10657, chestimg_macro_f1 0.58603, 124.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94700, tacc(al2) 0.80800, tacc(ob0) 0.99100, tacc(ob1) 0.97800, tacc(ob2) 0.87100, tacc(ob3) 0.98600, tacc(ob4) 0.95200, 9.26 secs\n",
      "\u001b[1m---- Epoch 125/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.53690, triplet_loss 0.45161, c_loss 0.21690, hs_loss 0.37090, cs_loss 0.85519, cacc 0.92040, hsacc 0.86060, csacc 0.68068, chstimgn_loss 0.12650, chestimg_macro_f1 0.54717, 124.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94100, tacc(al2) 0.81200, tacc(ob0) 0.99100, tacc(ob1) 0.96600, tacc(ob2) 0.84900, tacc(ob3) 0.98100, tacc(ob4) 0.94000, 9.92 secs\n",
      "\u001b[1m---- Epoch 126/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.50739, triplet_loss 0.44595, c_loss 0.18677, hs_loss 0.35686, cs_loss 0.81470, cacc 0.93160, hsacc 0.86472, csacc 0.69420, chstimgn_loss 0.11264, chestimg_macro_f1 0.56409, 121.94 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93500, tacc(al2) 0.80200, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.87200, tacc(ob3) 0.98200, tacc(ob4) 0.94600, 9.66 secs\n",
      "\u001b[1m---- Epoch 127/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.47457, triplet_loss 0.44362, c_loss 0.17768, hs_loss 0.31469, cs_loss 0.74609, cacc 0.93668, hsacc 0.88372, csacc 0.71692, chstimgn_loss 0.10809, chestimg_macro_f1 0.57253, 122.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93600, tacc(al2) 0.79200, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.87800, tacc(ob3) 0.98500, tacc(ob4) 0.95000, 9.43 secs\n",
      "\u001b[1m---- Epoch 128/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.45721, triplet_loss 0.44430, c_loss 0.16436, hs_loss 0.28885, cs_loss 0.72323, cacc 0.93628, hsacc 0.88840, csacc 0.72164, chstimgn_loss 0.10405, chestimg_macro_f1 0.57804, 121.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93600, tacc(al2) 0.79400, tacc(ob0) 0.99300, tacc(ob1) 0.97000, tacc(ob2) 0.88000, tacc(ob3) 0.98200, tacc(ob4) 0.95200, 9.04 secs\n",
      "\u001b[1m---- Epoch 129/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.45896, triplet_loss 0.44076, c_loss 0.16215, hs_loss 0.30105, cs_loss 0.72228, cacc 0.94296, hsacc 0.88776, csacc 0.72248, chstimgn_loss 0.10479, chestimg_macro_f1 0.57625, 121.19 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93500, tacc(al2) 0.79400, tacc(ob0) 0.99200, tacc(ob1) 0.97000, tacc(ob2) 0.88100, tacc(ob3) 0.98400, tacc(ob4) 0.95000, 9.34 secs\n",
      "\u001b[1m---- Epoch 130/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.44636, triplet_loss 0.44290, c_loss 0.14593, hs_loss 0.29203, cs_loss 0.69961, cacc 0.94320, hsacc 0.88836, csacc 0.73088, chstimgn_loss 0.10248, chestimg_macro_f1 0.58658, 123.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93400, tacc(al2) 0.79700, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.88100, tacc(ob3) 0.98200, tacc(ob4) 0.94800, 9.67 secs\n",
      "\u001b[1m---- Epoch 131/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.44788, triplet_loss 0.44227, c_loss 0.13672, hs_loss 0.29896, cs_loss 0.70932, cacc 0.94404, hsacc 0.89308, csacc 0.72904, chstimgn_loss 0.10213, chestimg_macro_f1 0.58167, 122.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93600, tacc(al2) 0.79600, tacc(ob0) 0.99200, tacc(ob1) 0.97000, tacc(ob2) 0.87900, tacc(ob3) 0.98300, tacc(ob4) 0.95000, 9.06 secs\n",
      "\u001b[1m---- Epoch 132/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44512, triplet_loss 0.44174, c_loss 0.14657, hs_loss 0.28528, cs_loss 0.70499, cacc 0.94408, hsacc 0.89396, csacc 0.72940, chstimgn_loss 0.10096, chestimg_macro_f1 0.57848, 122.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93700, tacc(al2) 0.79600, tacc(ob0) 0.99200, tacc(ob1) 0.97100, tacc(ob2) 0.87900, tacc(ob3) 0.98300, tacc(ob4) 0.94900, 9.13 secs\n",
      "\u001b[1m---- Epoch 133/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.50708, triplet_loss 0.44801, c_loss 0.17552, hs_loss 0.35831, cs_loss 0.81841, cacc 0.93648, hsacc 0.86572, csacc 0.68948, chstimgn_loss 0.11404, chestimg_macro_f1 0.56485, 121.92 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93200, tacc(al2) 0.80600, tacc(ob0) 0.98700, tacc(ob1) 0.96800, tacc(ob2) 0.86900, tacc(ob3) 0.98200, tacc(ob4) 0.94800, 9.14 secs\n",
      "\u001b[1m---- Epoch 134/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.49141, triplet_loss 0.44755, c_loss 0.16420, hs_loss 0.34442, cs_loss 0.79289, cacc 0.93464, hsacc 0.87416, csacc 0.69748, chstimgn_loss 0.10829, chestimg_macro_f1 0.57006, 120.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.80500, tacc(ob0) 0.98900, tacc(ob1) 0.98000, tacc(ob2) 0.87000, tacc(ob3) 0.98200, tacc(ob4) 0.94600, 9.36 secs\n",
      "\u001b[1m---- Epoch 135/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.46737, triplet_loss 0.44414, c_loss 0.15997, hs_loss 0.32706, cs_loss 0.73465, cacc 0.93748, hsacc 0.87936, csacc 0.72128, chstimgn_loss 0.10183, chestimg_macro_f1 0.58006, 121.18 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98600, tacc(al1) 0.94700, tacc(al2) 0.80400, tacc(ob0) 0.99000, tacc(ob1) 0.97300, tacc(ob2) 0.87400, tacc(ob3) 0.98200, tacc(ob4) 0.95400, 9.51 secs\n",
      "\u001b[1m---- Epoch 136/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.45359, triplet_loss 0.44157, c_loss 0.14599, hs_loss 0.30545, cs_loss 0.72222, cacc 0.93972, hsacc 0.88164, csacc 0.72020, chstimgn_loss 0.09957, chestimg_macro_f1 0.59361, 121.42 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94400, tacc(al2) 0.80400, tacc(ob0) 0.99000, tacc(ob1) 0.97000, tacc(ob2) 0.87200, tacc(ob3) 0.98400, tacc(ob4) 0.95800, 8.82 secs\n",
      "\u001b[1m---- Epoch 137/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.45254, triplet_loss 0.44342, c_loss 0.15156, hs_loss 0.29513, cs_loss 0.72393, cacc 0.93960, hsacc 0.88416, csacc 0.71860, chstimgn_loss 0.09807, chestimg_macro_f1 0.58524, 119.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94700, tacc(al2) 0.80700, tacc(ob0) 0.99000, tacc(ob1) 0.97400, tacc(ob2) 0.86900, tacc(ob3) 0.98500, tacc(ob4) 0.95400, 9.58 secs\n",
      "\u001b[1m---- Epoch 138/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.44448, triplet_loss 0.44048, c_loss 0.14979, hs_loss 0.28826, cs_loss 0.70409, cacc 0.94368, hsacc 0.88516, csacc 0.72860, chstimgn_loss 0.09765, chestimg_macro_f1 0.58656, 119.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94300, tacc(al2) 0.80600, tacc(ob0) 0.99000, tacc(ob1) 0.97400, tacc(ob2) 0.87500, tacc(ob3) 0.98500, tacc(ob4) 0.95300, 9.47 secs\n",
      "\u001b[1m---- Epoch 139/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.44448, triplet_loss 0.44170, c_loss 0.14179, hs_loss 0.28593, cs_loss 0.71309, cacc 0.94044, hsacc 0.88952, csacc 0.72676, chstimgn_loss 0.09771, chestimg_macro_f1 0.58847, 120.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94300, tacc(al2) 0.80400, tacc(ob0) 0.99000, tacc(ob1) 0.97400, tacc(ob2) 0.87200, tacc(ob3) 0.98500, tacc(ob4) 0.95300, 9.69 secs\n",
      "\u001b[1m---- Epoch 140/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44895, triplet_loss 0.44212, c_loss 0.15290, hs_loss 0.30458, cs_loss 0.70320, cacc 0.94080, hsacc 0.88472, csacc 0.73056, chstimgn_loss 0.09650, chestimg_macro_f1 0.59114, 118.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94200, tacc(al2) 0.80500, tacc(ob0) 0.99000, tacc(ob1) 0.97400, tacc(ob2) 0.87200, tacc(ob3) 0.98300, tacc(ob4) 0.95300, 8.39 secs\n",
      "\u001b[1m---- Epoch 141/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.49245, triplet_loss 0.44632, c_loss 0.17728, hs_loss 0.33559, cs_loss 0.79918, cacc 0.93140, hsacc 0.87136, csacc 0.69780, chstimgn_loss 0.10570, chestimg_macro_f1 0.57585, 117.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94300, tacc(al2) 0.81600, tacc(ob0) 0.99000, tacc(ob1) 0.96800, tacc(ob2) 0.86700, tacc(ob3) 0.98300, tacc(ob4) 0.94400, 8.84 secs\n",
      "\u001b[1m---- Epoch 142/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.47810, triplet_loss 0.44459, c_loss 0.17588, hs_loss 0.31898, cs_loss 0.77137, cacc 0.93396, hsacc 0.88088, csacc 0.70624, chstimgn_loss 0.10080, chestimg_macro_f1 0.58221, 117.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94900, tacc(al2) 0.80000, tacc(ob0) 0.99300, tacc(ob1) 0.97800, tacc(ob2) 0.88400, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 9.08 secs\n",
      "\u001b[1m---- Epoch 143/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.45516, triplet_loss 0.44555, c_loss 0.15821, hs_loss 0.30423, cs_loss 0.72261, cacc 0.93832, hsacc 0.88724, csacc 0.72316, chstimgn_loss 0.09503, chestimg_macro_f1 0.59138, 117.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94800, tacc(al2) 0.79900, tacc(ob0) 0.99000, tacc(ob1) 0.97500, tacc(ob2) 0.87700, tacc(ob3) 0.98300, tacc(ob4) 0.94800, 8.16 secs\n",
      "\u001b[1m---- Epoch 144/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.44694, triplet_loss 0.44181, c_loss 0.14887, hs_loss 0.29852, cs_loss 0.71372, cacc 0.94500, hsacc 0.88456, csacc 0.72260, chstimgn_loss 0.09242, chestimg_macro_f1 0.59393, 115.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95100, tacc(al2) 0.80500, tacc(ob0) 0.99000, tacc(ob1) 0.97600, tacc(ob2) 0.87400, tacc(ob3) 0.98400, tacc(ob4) 0.95300, 7.34 secs\n",
      "\u001b[1m---- Epoch 145/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.43808, triplet_loss 0.44047, c_loss 0.14121, hs_loss 0.28504, cs_loss 0.70223, cacc 0.94220, hsacc 0.88884, csacc 0.73112, chstimgn_loss 0.09168, chestimg_macro_f1 0.60499, 116.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.80000, tacc(ob0) 0.99200, tacc(ob1) 0.97100, tacc(ob2) 0.86800, tacc(ob3) 0.98600, tacc(ob4) 0.95400, 8.09 secs\n",
      "\u001b[1m---- Epoch 146/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.43962, triplet_loss 0.44175, c_loss 0.14171, hs_loss 0.30142, cs_loss 0.68929, cacc 0.94300, hsacc 0.88960, csacc 0.73380, chstimgn_loss 0.09215, chestimg_macro_f1 0.59885, 116.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.80500, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.87200, tacc(ob3) 0.98600, tacc(ob4) 0.95500, 8.36 secs\n",
      "\u001b[1m---- Epoch 147/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.43649, triplet_loss 0.44337, c_loss 0.12614, hs_loss 0.29070, cs_loss 0.70376, cacc 0.94568, hsacc 0.89216, csacc 0.73116, chstimgn_loss 0.09099, chestimg_macro_f1 0.59730, 114.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95200, tacc(al2) 0.80200, tacc(ob0) 0.99100, tacc(ob1) 0.97000, tacc(ob2) 0.87600, tacc(ob3) 0.98400, tacc(ob4) 0.95500, 8.57 secs\n",
      "\u001b[1m---- Epoch 148/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.43906, triplet_loss 0.44109, c_loss 0.14417, hs_loss 0.29528, cs_loss 0.69163, cacc 0.94264, hsacc 0.88776, csacc 0.73260, chstimgn_loss 0.09203, chestimg_macro_f1 0.60242, 114.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95300, tacc(al2) 0.80300, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.87400, tacc(ob3) 0.98500, tacc(ob4) 0.95600, 7.64 secs\n",
      "\u001b[1m---- Epoch 149/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.49949, triplet_loss 0.44744, c_loss 0.18651, hs_loss 0.35787, cs_loss 0.80373, cacc 0.93424, hsacc 0.86704, csacc 0.69544, chstimgn_loss 0.10120, chestimg_macro_f1 0.59869, 115.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.81200, tacc(ob0) 0.98800, tacc(ob1) 0.96400, tacc(ob2) 0.86300, tacc(ob3) 0.98600, tacc(ob4) 0.94300, 8.88 secs\n",
      "\u001b[1m---- Epoch 150/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.47973, triplet_loss 0.44372, c_loss 0.16971, hs_loss 0.32557, cs_loss 0.78914, cacc 0.93632, hsacc 0.87972, csacc 0.69916, chstimgn_loss 0.09538, chestimg_macro_f1 0.58863, 114.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95400, tacc(al2) 0.80600, tacc(ob0) 0.98900, tacc(ob1) 0.97100, tacc(ob2) 0.86400, tacc(ob3) 0.98400, tacc(ob4) 0.95100, 8.51 secs\n",
      "\u001b[1m---- Epoch 151/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.45382, triplet_loss 0.44258, c_loss 0.15184, hs_loss 0.31333, cs_loss 0.72483, cacc 0.94360, hsacc 0.88892, csacc 0.72308, chstimgn_loss 0.09135, chestimg_macro_f1 0.60194, 114.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95400, tacc(al2) 0.81000, tacc(ob0) 0.99000, tacc(ob1) 0.97100, tacc(ob2) 0.87300, tacc(ob3) 0.98900, tacc(ob4) 0.94900, 7.92 secs\n",
      "\u001b[1m---- Epoch 152/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.44226, triplet_loss 0.44088, c_loss 0.13452, hs_loss 0.29664, cs_loss 0.71850, cacc 0.94284, hsacc 0.89124, csacc 0.72476, chstimgn_loss 0.08925, chestimg_macro_f1 0.62447, 115.23 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95700, tacc(al2) 0.80900, tacc(ob0) 0.99000, tacc(ob1) 0.96900, tacc(ob2) 0.87200, tacc(ob3) 0.98900, tacc(ob4) 0.95600, 7.36 secs\n",
      "\u001b[1m---- Epoch 153/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.44234, triplet_loss 0.44089, c_loss 0.15865, hs_loss 0.28424, cs_loss 0.71131, cacc 0.94516, hsacc 0.89336, csacc 0.72864, chstimgn_loss 0.08714, chestimg_macro_f1 0.60721, 111.51 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.80600, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.95200, 7.64 secs\n",
      "\u001b[1m---- Epoch 154/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.43195, triplet_loss 0.43964, c_loss 0.13689, hs_loss 0.29785, cs_loss 0.68085, cacc 0.94516, hsacc 0.89180, csacc 0.73704, chstimgn_loss 0.08629, chestimg_macro_f1 0.61130, 112.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95300, tacc(al2) 0.80900, tacc(ob0) 0.99100, tacc(ob1) 0.97100, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.95400, 7.59 secs\n",
      "\u001b[1m---- Epoch 155/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.43240, triplet_loss 0.44013, c_loss 0.13831, hs_loss 0.27975, cs_loss 0.69947, cacc 0.94604, hsacc 0.89296, csacc 0.72928, chstimgn_loss 0.08597, chestimg_macro_f1 0.63064, 113.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95300, tacc(al2) 0.80900, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.95500, 7.25 secs\n",
      "\u001b[1m---- Epoch 156/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.42893, triplet_loss 0.44043, c_loss 0.13370, hs_loss 0.28235, cs_loss 0.68675, cacc 0.94668, hsacc 0.89284, csacc 0.73228, chstimgn_loss 0.08625, chestimg_macro_f1 0.60445, 113.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95600, tacc(al2) 0.81200, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.87700, tacc(ob3) 0.98500, tacc(ob4) 0.95300, 7.65 secs\n",
      "\u001b[1m---- Epoch 157/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.49070, triplet_loss 0.44709, c_loss 0.17925, hs_loss 0.33611, cs_loss 0.80322, cacc 0.93352, hsacc 0.87660, csacc 0.69952, chstimgn_loss 0.09856, chestimg_macro_f1 0.58600, 113.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94100, tacc(al2) 0.80800, tacc(ob0) 0.99000, tacc(ob1) 0.96900, tacc(ob2) 0.88000, tacc(ob3) 0.98500, tacc(ob4) 0.94200, 7.45 secs\n",
      "\u001b[1m---- Epoch 158/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.47665, triplet_loss 0.44588, c_loss 0.15704, hs_loss 0.33416, cs_loss 0.78298, cacc 0.93856, hsacc 0.87632, csacc 0.70376, chstimgn_loss 0.09327, chestimg_macro_f1 0.62238, 113.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94100, tacc(al2) 0.80300, tacc(ob0) 0.99200, tacc(ob1) 0.97600, tacc(ob2) 0.88800, tacc(ob3) 0.98700, tacc(ob4) 0.94800, 7.61 secs\n",
      "\u001b[1m---- Epoch 159/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.45230, triplet_loss 0.44155, c_loss 0.15797, hs_loss 0.31490, cs_loss 0.72112, cacc 0.94296, hsacc 0.87904, csacc 0.72556, chstimgn_loss 0.08683, chestimg_macro_f1 0.61199, 98.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.80600, tacc(ob0) 0.99000, tacc(ob1) 0.97600, tacc(ob2) 0.88700, tacc(ob3) 0.98800, tacc(ob4) 0.94900, 6.86 secs\n",
      "\u001b[1m---- Epoch 160/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.44461, triplet_loss 0.44145, c_loss 0.15398, hs_loss 0.29610, cs_loss 0.71561, cacc 0.94068, hsacc 0.88904, csacc 0.72168, chstimgn_loss 0.08566, chestimg_macro_f1 0.60793, 113.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.80200, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.88200, tacc(ob3) 0.99000, tacc(ob4) 0.94800, 6.99 secs\n",
      "\u001b[1m---- Epoch 161/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.43852, triplet_loss 0.44075, c_loss 0.15171, hs_loss 0.28512, cs_loss 0.70804, cacc 0.94376, hsacc 0.88996, csacc 0.72660, chstimgn_loss 0.08423, chestimg_macro_f1 0.61153, 100.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94600, tacc(al2) 0.80200, tacc(ob0) 0.99200, tacc(ob1) 0.97600, tacc(ob2) 0.87600, tacc(ob3) 0.98800, tacc(ob4) 0.94900, 8.17 secs\n",
      "\u001b[1m---- Epoch 162/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.42806, triplet_loss 0.44002, c_loss 0.14257, hs_loss 0.28098, cs_loss 0.68364, cacc 0.94144, hsacc 0.89332, csacc 0.73568, chstimgn_loss 0.08251, chestimg_macro_f1 0.61799, 104.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94900, tacc(al2) 0.80000, tacc(ob0) 0.99200, tacc(ob1) 0.97300, tacc(ob2) 0.87900, tacc(ob3) 0.98900, tacc(ob4) 0.95000, 8.40 secs\n",
      "\u001b[1m---- Epoch 163/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.43016, triplet_loss 0.44241, c_loss 0.14100, hs_loss 0.28682, cs_loss 0.68444, cacc 0.94384, hsacc 0.88916, csacc 0.73572, chstimgn_loss 0.08298, chestimg_macro_f1 0.61136, 113.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94900, tacc(al2) 0.79900, tacc(ob0) 0.99200, tacc(ob1) 0.97600, tacc(ob2) 0.87900, tacc(ob3) 0.98900, tacc(ob4) 0.94900, 7.72 secs\n",
      "\u001b[1m---- Epoch 164/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.43045, triplet_loss 0.44004, c_loss 0.14868, hs_loss 0.28516, cs_loss 0.68292, cacc 0.94372, hsacc 0.89080, csacc 0.73700, chstimgn_loss 0.08250, chestimg_macro_f1 0.63329, 114.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95000, tacc(al2) 0.80200, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.87900, tacc(ob3) 0.98900, tacc(ob4) 0.94900, 7.65 secs\n",
      "\u001b[1m---- Epoch 165/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.49658, triplet_loss 0.44497, c_loss 0.20717, hs_loss 0.33970, cs_loss 0.80411, cacc 0.93288, hsacc 0.87076, csacc 0.69300, chstimgn_loss 0.09520, chestimg_macro_f1 0.59545, 113.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95300, tacc(al2) 0.79700, tacc(ob0) 0.99400, tacc(ob1) 0.96900, tacc(ob2) 0.85500, tacc(ob3) 0.98500, tacc(ob4) 0.94700, 7.84 secs\n",
      "\u001b[1m---- Epoch 166/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.47785, triplet_loss 0.44537, c_loss 0.17851, hs_loss 0.33377, cs_loss 0.77367, cacc 0.93420, hsacc 0.87120, csacc 0.70692, chstimgn_loss 0.09004, chestimg_macro_f1 0.60497, 112.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95400, tacc(al2) 0.79500, tacc(ob0) 0.99300, tacc(ob1) 0.97100, tacc(ob2) 0.87800, tacc(ob3) 0.98800, tacc(ob4) 0.94900, 7.12 secs\n",
      "\u001b[1m---- Epoch 167/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.45133, triplet_loss 0.44100, c_loss 0.15482, hs_loss 0.31390, cs_loss 0.72979, cacc 0.94084, hsacc 0.88148, csacc 0.71976, chstimgn_loss 0.08290, chestimg_macro_f1 0.61697, 115.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95800, tacc(al2) 0.80600, tacc(ob0) 0.99200, tacc(ob1) 0.97100, tacc(ob2) 0.88000, tacc(ob3) 0.98700, tacc(ob4) 0.94700, 7.48 secs\n",
      "\u001b[1m---- Epoch 168/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.43788, triplet_loss 0.44183, c_loss 0.15470, hs_loss 0.28533, cs_loss 0.70455, cacc 0.93980, hsacc 0.89008, csacc 0.72836, chstimgn_loss 0.08256, chestimg_macro_f1 0.61519, 114.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.80300, tacc(ob0) 0.99200, tacc(ob1) 0.97000, tacc(ob2) 0.87600, tacc(ob3) 0.98900, tacc(ob4) 0.95100, 6.73 secs\n",
      "\u001b[1m---- Epoch 169/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.43421, triplet_loss 0.44160, c_loss 0.14317, hs_loss 0.29214, cs_loss 0.69978, cacc 0.94440, hsacc 0.88624, csacc 0.73348, chstimgn_loss 0.08008, chestimg_macro_f1 0.61879, 112.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95600, tacc(al2) 0.80400, tacc(ob0) 0.99300, tacc(ob1) 0.97300, tacc(ob2) 0.87700, tacc(ob3) 0.98800, tacc(ob4) 0.95100, 7.10 secs\n",
      "\u001b[1m---- Epoch 170/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.43468, triplet_loss 0.44029, c_loss 0.15508, hs_loss 0.28852, cs_loss 0.69399, cacc 0.94204, hsacc 0.89024, csacc 0.73348, chstimgn_loss 0.08043, chestimg_macro_f1 0.62548, 111.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95600, tacc(al2) 0.80400, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.87800, tacc(ob3) 0.98900, tacc(ob4) 0.94900, 7.43 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_170_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9212.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 171/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.43136, triplet_loss 0.44017, c_loss 0.16023, hs_loss 0.28514, cs_loss 0.68069, cacc 0.94184, hsacc 0.89256, csacc 0.73684, chstimgn_loss 0.07960, chestimg_macro_f1 0.63133, 112.23 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.80600, tacc(ob0) 0.99200, tacc(ob1) 0.97400, tacc(ob2) 0.87800, tacc(ob3) 0.98900, tacc(ob4) 0.95000, 6.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_171_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9217.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 172/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.42424, triplet_loss 0.44070, c_loss 0.13566, hs_loss 0.27767, cs_loss 0.68460, cacc 0.94588, hsacc 0.89284, csacc 0.73300, chstimgn_loss 0.07917, chestimg_macro_f1 0.61434, 111.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.80400, tacc(ob0) 0.99200, tacc(ob1) 0.97300, tacc(ob2) 0.87700, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 6.53 secs\n",
      "\u001b[1m---- Epoch 173/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.47995, triplet_loss 0.44513, c_loss 0.16606, hs_loss 0.34285, cs_loss 0.78706, cacc 0.93768, hsacc 0.87168, csacc 0.70192, chstimgn_loss 0.08935, chestimg_macro_f1 0.60340, 112.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94400, tacc(al2) 0.80800, tacc(ob0) 0.99300, tacc(ob1) 0.97400, tacc(ob2) 0.87400, tacc(ob3) 0.98900, tacc(ob4) 0.95500, 7.52 secs\n",
      "\u001b[1m---- Epoch 174/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.47800, triplet_loss 0.44290, c_loss 0.17881, hs_loss 0.33460, cs_loss 0.78281, cacc 0.93644, hsacc 0.87348, csacc 0.70320, chstimgn_loss 0.08644, chestimg_macro_f1 0.61833, 112.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94100, tacc(al2) 0.80000, tacc(ob0) 0.99300, tacc(ob1) 0.97700, tacc(ob2) 0.86800, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 6.61 secs\n",
      "\u001b[1m---- Epoch 175/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.45178, triplet_loss 0.44137, c_loss 0.16553, hs_loss 0.30927, cs_loss 0.73078, cacc 0.93920, hsacc 0.88168, csacc 0.71844, chstimgn_loss 0.08008, chestimg_macro_f1 0.62010, 112.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94200, tacc(al2) 0.80300, tacc(ob0) 0.99300, tacc(ob1) 0.97700, tacc(ob2) 0.86400, tacc(ob3) 0.98600, tacc(ob4) 0.94900, 6.70 secs\n",
      "\u001b[1m---- Epoch 176/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.43570, triplet_loss 0.43961, c_loss 0.14697, hs_loss 0.29528, cs_loss 0.70432, cacc 0.93848, hsacc 0.88520, csacc 0.72912, chstimgn_loss 0.07831, chestimg_macro_f1 0.62695, 112.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94200, tacc(al2) 0.80500, tacc(ob0) 0.99200, tacc(ob1) 0.97900, tacc(ob2) 0.87000, tacc(ob3) 0.98700, tacc(ob4) 0.95100, 7.27 secs\n",
      "\u001b[1m---- Epoch 177/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.42903, triplet_loss 0.44073, c_loss 0.13461, hs_loss 0.28153, cs_loss 0.70383, cacc 0.94532, hsacc 0.89112, csacc 0.73048, chstimgn_loss 0.07772, chestimg_macro_f1 0.64832, 99.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94300, tacc(al2) 0.81000, tacc(ob0) 0.99200, tacc(ob1) 0.98200, tacc(ob2) 0.87200, tacc(ob3) 0.98500, tacc(ob4) 0.94900, 7.68 secs\n",
      "\u001b[1m---- Epoch 178/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.42221, triplet_loss 0.43992, c_loss 0.13284, hs_loss 0.27691, cs_loss 0.68527, cacc 0.94700, hsacc 0.89400, csacc 0.73276, chstimgn_loss 0.07695, chestimg_macro_f1 0.62143, 112.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94700, tacc(al2) 0.80700, tacc(ob0) 0.99100, tacc(ob1) 0.98000, tacc(ob2) 0.87600, tacc(ob3) 0.98700, tacc(ob4) 0.94900, 6.87 secs\n",
      "\u001b[1m---- Epoch 179/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "   iteration 178300\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.40286, triplet_loss 0.43856, c_loss 0.14065, hs_loss 0.27985, cs_loss 0.65360, cacc 0.94716, hsacc 0.89372, csacc 0.74068, chstimgn_loss 0.04940, chestimg_macro_f1 0.70388, 110.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95200, tacc(al2) 0.79800, tacc(ob0) 0.99700, tacc(ob1) 0.98000, tacc(ob2) 0.86700, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 7.09 secs\n",
      "\u001b[1m---- Epoch 276/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.40238, triplet_loss 0.43752, c_loss 0.13964, hs_loss 0.27538, cs_loss 0.65907, cacc 0.94396, hsacc 0.89316, csacc 0.74164, chstimgn_loss 0.04895, chestimg_macro_f1 0.70599, 93.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.80000, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.86600, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 7.08 secs\n",
      "\u001b[1m---- Epoch 277/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44856, triplet_loss 0.44233, c_loss 0.18075, hs_loss 0.31693, cs_loss 0.73949, cacc 0.93316, hsacc 0.87924, csacc 0.71528, chstimgn_loss 0.05738, chestimg_macro_f1 0.69784, 110.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.95300, tacc(al2) 0.81100, tacc(ob0) 0.99300, tacc(ob1) 0.97800, tacc(ob2) 0.86600, tacc(ob3) 0.98500, tacc(ob4) 0.94700, 7.02 secs\n",
      "\u001b[1m---- Epoch 278/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.42783, triplet_loss 0.44132, c_loss 0.14243, hs_loss 0.29912, cs_loss 0.72299, cacc 0.94360, hsacc 0.88692, csacc 0.72148, chstimgn_loss 0.05273, chestimg_macro_f1 0.70876, 112.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94900, tacc(al2) 0.79600, tacc(ob0) 0.99400, tacc(ob1) 0.98500, tacc(ob2) 0.86700, tacc(ob3) 0.98100, tacc(ob4) 0.94800, 6.67 secs\n",
      "\u001b[1m---- Epoch 279/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41464, triplet_loss 0.43718, c_loss 0.15586, hs_loss 0.28908, cs_loss 0.67657, cacc 0.94220, hsacc 0.88888, csacc 0.73504, chstimgn_loss 0.04994, chestimg_macro_f1 0.69892, 112.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95000, tacc(al2) 0.79300, tacc(ob0) 0.99600, tacc(ob1) 0.98000, tacc(ob2) 0.87000, tacc(ob3) 0.98400, tacc(ob4) 0.95000, 6.79 secs\n",
      "\u001b[1m---- Epoch 280/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.41021, triplet_loss 0.43924, c_loss 0.15562, hs_loss 0.27747, cs_loss 0.67118, cacc 0.94296, hsacc 0.89684, csacc 0.73712, chstimgn_loss 0.04866, chestimg_macro_f1 0.71987, 111.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95300, tacc(al2) 0.79100, tacc(ob0) 0.99800, tacc(ob1) 0.98200, tacc(ob2) 0.87100, tacc(ob3) 0.98200, tacc(ob4) 0.95700, 6.88 secs\n",
      "\u001b[1m---- Epoch 281/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40020, triplet_loss 0.43918, c_loss 0.13456, hs_loss 0.27874, cs_loss 0.65312, cacc 0.94428, hsacc 0.89476, csacc 0.74384, chstimgn_loss 0.04760, chestimg_macro_f1 0.70629, 113.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95200, tacc(al2) 0.79200, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.87300, tacc(ob3) 0.98400, tacc(ob4) 0.95400, 7.54 secs\n",
      "\u001b[1m---- Epoch 282/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39827, triplet_loss 0.43710, c_loss 0.13818, hs_loss 0.27490, cs_loss 0.64710, cacc 0.94624, hsacc 0.89732, csacc 0.74648, chstimgn_loss 0.04789, chestimg_macro_f1 0.72725, 113.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.79400, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.86900, tacc(ob3) 0.98400, tacc(ob4) 0.95600, 7.24 secs\n",
      "\u001b[1m---- Epoch 283/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.40322, triplet_loss 0.43782, c_loss 0.14170, hs_loss 0.28366, cs_loss 0.65439, cacc 0.94632, hsacc 0.89388, csacc 0.74504, chstimgn_loss 0.04766, chestimg_macro_f1 0.71558, 93.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.79000, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.86900, tacc(ob3) 0.98500, tacc(ob4) 0.95600, 8.24 secs\n",
      "\u001b[1m---- Epoch 284/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39107, triplet_loss 0.43885, c_loss 0.12152, hs_loss 0.25321, cs_loss 0.65810, cacc 0.94888, hsacc 0.89704, csacc 0.74252, chstimgn_loss 0.04630, chestimg_macro_f1 0.72714, 113.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95200, tacc(al2) 0.78900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.86800, tacc(ob3) 0.98600, tacc(ob4) 0.95600, 7.29 secs\n",
      "\u001b[1m---- Epoch 285/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.43984, triplet_loss 0.44123, c_loss 0.16186, hs_loss 0.31262, cs_loss 0.72839, cacc 0.93988, hsacc 0.88216, csacc 0.72068, chstimgn_loss 0.05762, chestimg_macro_f1 0.68789, 113.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94600, tacc(al2) 0.80500, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.85800, tacc(ob3) 0.98700, tacc(ob4) 0.94900, 6.72 secs\n",
      "\u001b[1m---- Epoch 286/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44339, triplet_loss 0.44114, c_loss 0.15618, hs_loss 0.32284, cs_loss 0.74012, cacc 0.94144, hsacc 0.87880, csacc 0.71620, chstimgn_loss 0.05664, chestimg_macro_f1 0.70482, 112.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.78800, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86400, tacc(ob3) 0.98900, tacc(ob4) 0.95500, 7.32 secs\n",
      "\u001b[1m---- Epoch 287/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.42129, triplet_loss 0.44107, c_loss 0.15908, hs_loss 0.28962, cs_loss 0.69357, cacc 0.94284, hsacc 0.88800, csacc 0.73028, chstimgn_loss 0.05091, chestimg_macro_f1 0.71415, 112.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95100, tacc(al2) 0.79700, tacc(ob0) 0.99600, tacc(ob1) 0.97300, tacc(ob2) 0.86900, tacc(ob3) 0.99200, tacc(ob4) 0.95600, 7.26 secs\n",
      "\u001b[1m---- Epoch 288/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40602, triplet_loss 0.43833, c_loss 0.13771, hs_loss 0.28654, cs_loss 0.66627, cacc 0.94392, hsacc 0.89052, csacc 0.73772, chstimgn_loss 0.04760, chestimg_macro_f1 0.72439, 111.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95100, tacc(al2) 0.79300, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.86800, tacc(ob3) 0.98900, tacc(ob4) 0.96100, 7.03 secs\n",
      "\u001b[1m---- Epoch 289/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39997, triplet_loss 0.43913, c_loss 0.13038, hs_loss 0.27698, cs_loss 0.65877, cacc 0.94876, hsacc 0.89376, csacc 0.74044, chstimgn_loss 0.04731, chestimg_macro_f1 0.71118, 112.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95400, tacc(al2) 0.78900, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.86700, tacc(ob3) 0.98900, tacc(ob4) 0.96300, 7.55 secs\n",
      "\u001b[1m---- Epoch 290/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39946, triplet_loss 0.43938, c_loss 0.12766, hs_loss 0.27268, cs_loss 0.66417, cacc 0.94832, hsacc 0.89272, csacc 0.74064, chstimgn_loss 0.04697, chestimg_macro_f1 0.72846, 111.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95600, tacc(al2) 0.79200, tacc(ob0) 0.99600, tacc(ob1) 0.97800, tacc(ob2) 0.86800, tacc(ob3) 0.98900, tacc(ob4) 0.96300, 7.19 secs\n",
      "\u001b[1m---- Epoch 291/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39530, triplet_loss 0.43920, c_loss 0.12976, hs_loss 0.26821, cs_loss 0.65162, cacc 0.94848, hsacc 0.89312, csacc 0.74304, chstimgn_loss 0.04621, chestimg_macro_f1 0.72703, 111.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95400, tacc(al2) 0.79300, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.86700, tacc(ob3) 0.99000, tacc(ob4) 0.96400, 7.54 secs\n",
      "\u001b[1m---- Epoch 292/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39240, triplet_loss 0.43860, c_loss 0.12486, hs_loss 0.26536, cs_loss 0.64714, cacc 0.94840, hsacc 0.89384, csacc 0.74780, chstimgn_loss 0.04682, chestimg_macro_f1 0.70777, 111.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95400, tacc(al2) 0.79200, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.86700, tacc(ob3) 0.99000, tacc(ob4) 0.96400, 7.11 secs\n",
      "\u001b[1m---- Epoch 293/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.43021, triplet_loss 0.44293, c_loss 0.14064, hs_loss 0.30318, cs_loss 0.72305, cacc 0.94516, hsacc 0.88148, csacc 0.71836, chstimgn_loss 0.05552, chestimg_macro_f1 0.70864, 112.00 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98400, tacc(al1) 0.94400, tacc(al2) 0.79600, tacc(ob0) 0.99400, tacc(ob1) 0.97500, tacc(ob2) 0.86600, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 7.03 secs\n",
      "\u001b[1m---- Epoch 294/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43623, triplet_loss 0.44241, c_loss 0.15197, hs_loss 0.31445, cs_loss 0.72802, cacc 0.94012, hsacc 0.88164, csacc 0.71900, chstimgn_loss 0.05403, chestimg_macro_f1 0.70823, 112.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95000, tacc(al2) 0.78300, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.86000, tacc(ob3) 0.98900, tacc(ob4) 0.96000, 7.35 secs\n",
      "\u001b[1m---- Epoch 295/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.40648, triplet_loss 0.43954, c_loss 0.13663, hs_loss 0.27689, cs_loss 0.67702, cacc 0.94336, hsacc 0.89304, csacc 0.73828, chstimgn_loss 0.04792, chestimg_macro_f1 0.69846, 112.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.80300, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.86000, tacc(ob3) 0.99100, tacc(ob4) 0.95900, 6.65 secs\n",
      "\u001b[1m---- Epoch 296/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40181, triplet_loss 0.43920, c_loss 0.14435, hs_loss 0.27438, cs_loss 0.65680, cacc 0.94620, hsacc 0.89400, csacc 0.74436, chstimgn_loss 0.04624, chestimg_macro_f1 0.72961, 111.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95300, tacc(al2) 0.79700, tacc(ob0) 0.99600, tacc(ob1) 0.98200, tacc(ob2) 0.85700, tacc(ob3) 0.99200, tacc(ob4) 0.95800, 6.97 secs\n",
      "\u001b[1m---- Epoch 297/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39888, triplet_loss 0.43914, c_loss 0.13955, hs_loss 0.27177, cs_loss 0.65327, cacc 0.94600, hsacc 0.89464, csacc 0.74168, chstimgn_loss 0.04590, chestimg_macro_f1 0.73233, 110.13 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95300, tacc(al2) 0.79800, tacc(ob0) 0.99600, tacc(ob1) 0.98100, tacc(ob2) 0.85400, tacc(ob3) 0.99200, tacc(ob4) 0.95700, 6.69 secs\n",
      "\u001b[1m---- Epoch 298/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38806, triplet_loss 0.43824, c_loss 0.12513, hs_loss 0.25872, cs_loss 0.63839, cacc 0.94700, hsacc 0.89616, csacc 0.74628, chstimgn_loss 0.04589, chestimg_macro_f1 0.71665, 112.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95700, tacc(al2) 0.79800, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.85400, tacc(ob3) 0.99100, tacc(ob4) 0.95600, 7.98 secs\n",
      "\u001b[1m---- Epoch 299/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39543, triplet_loss 0.43739, c_loss 0.13031, hs_loss 0.27427, cs_loss 0.64778, cacc 0.94644, hsacc 0.89784, csacc 0.74380, chstimgn_loss 0.04599, chestimg_macro_f1 0.71327, 112.23 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95900, tacc(al2) 0.79700, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.85500, tacc(ob3) 0.99100, tacc(ob4) 0.95700, 7.25 secs\n",
      "\u001b[1m---- Epoch 300/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.38731, triplet_loss 0.43931, c_loss 0.12042, hs_loss 0.26026, cs_loss 0.63856, cacc 0.94824, hsacc 0.90020, csacc 0.74856, chstimgn_loss 0.04535, chestimg_macro_f1 0.73300, 111.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95900, tacc(al2) 0.79700, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.85600, tacc(ob3) 0.99100, tacc(ob4) 0.95800, 7.72 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_005945_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--chest_imagenome_phrase2labels_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\" \\\n",
    "--n_chest_imagenome_labels 76 \\\n",
    "--triplets_weight 1.0 \\\n",
    "--metadata_classification_weight 1.0 \\\n",
    "--chest_imagenome_classification_weight 3.0 \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6db5b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 100\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_labels: 76\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_015329_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   chest_imagenome_phrase2labels_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\n",
      "   dataset_name: MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 1.0\n",
      "   chest_imagenome_classification_weight: 2.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome: True\n",
      "  n_chest_imagenome_labels: 76\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "1e-06 3 0.0002 8 2e-06 0.0002 8 2e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train metadata classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: The air-fluid levels within the multicystic basilar component of the lesion have expanded\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: no localized lung opacity\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: There is a collapse observed at the base of the left lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: worsened\n",
      "\u001b[1mExample fact: no appreciable right pleural\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: An underlying infection may be present\u001b[0m\n",
      "Category: disease\n",
      "Health status: ambiguous\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: substantial new right lower lobe atelectasis\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: new finding\n",
      "\u001b[1mExample fact: No further extraction is required\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: Identification of new multifocal opacities in the left lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: new finding\n",
      "\u001b[1mExample fact: Fluid accumulation easily observed in the lower regions of the left lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: heart size not taken into account\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding train chest imagenome labels classification dataset and dataloader...\u001b[0m\n",
      "Loading chest imagenome phrase2labels from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl...\n",
      "len(phrases): 556111\n",
      "len(label_names): 76\n",
      "labels.shape: (556111, 76)\n",
      "Label: nlp|abnormal\n",
      "\tNumber of non-omitted rows: 398889\n",
      "\tWeight: 6440.70\n",
      "Label: anatomicalfinding|lung opacity\n",
      "\tNumber of non-omitted rows: 305904\n",
      "\tWeight: 6051.17\n",
      "Label: anatomicalfinding|pleural effusion\n",
      "\tNumber of non-omitted rows: 100696\n",
      "\tWeight: 4590.56\n",
      "Label: anatomicalfinding|atelectasis\n",
      "\tNumber of non-omitted rows: 90101\n",
      "\tWeight: 4458.93\n",
      "Label: anatomicalfinding|pulmonary edema/hazy opacity\n",
      "\tNumber of non-omitted rows: 54992\n",
      "\tWeight: 3904.70\n",
      "Label: disease|pneumonia\n",
      "\tNumber of non-omitted rows: 54542\n",
      "\tWeight: 3895.89\n",
      "Label: anatomicalfinding|enlarged cardiac silhouette\n",
      "\tNumber of non-omitted rows: 44699\n",
      "\tWeight: 3686.49\n",
      "Label: nlp|normal\n",
      "\tNumber of non-omitted rows: 39410\n",
      "\tWeight: 3557.94\n",
      "Label: anatomicalfinding|consolidation\n",
      "\tNumber of non-omitted rows: 35449\n",
      "\tWeight: 3452.16\n",
      "Label: anatomicalfinding|pneumothorax\n",
      "\tNumber of non-omitted rows: 32738\n",
      "\tWeight: 3374.11\n",
      "Label: anatomicalfinding|vascular congestion\n",
      "\tNumber of non-omitted rows: 27593\n",
      "\tWeight: 3210.36\n",
      "Label: tubesandlines|enteric tube\n",
      "\tNumber of non-omitted rows: 25308\n",
      "\tWeight: 3129.63\n",
      "Label: tubesandlines|endotracheal tube\n",
      "\tNumber of non-omitted rows: 20291\n",
      "\tWeight: 2929.46\n",
      "Label: anatomicalfinding|lung lesion\n",
      "\tNumber of non-omitted rows: 19884\n",
      "\tWeight: 2911.54\n",
      "Label: technicalassessment|low lung volumes\n",
      "\tNumber of non-omitted rows: 17780\n",
      "\tWeight: 2813.95\n",
      "Label: anatomicalfinding|pleural/parenchymal scarring\n",
      "\tNumber of non-omitted rows: 15919\n",
      "\tWeight: 2719.65\n",
      "Label: anatomicalfinding|enlarged hilum\n",
      "\tNumber of non-omitted rows: 13987\n",
      "\tWeight: 2611.99\n",
      "Label: tubesandlines|chest tube\n",
      "\tNumber of non-omitted rows: 12496\n",
      "\tWeight: 2520.55\n",
      "Label: anatomicalfinding|mediastinal widening\n",
      "\tNumber of non-omitted rows: 12438\n",
      "\tWeight: 2516.83\n",
      "Label: tubesandlines|picc\n",
      "\tNumber of non-omitted rows: 12300\n",
      "\tWeight: 2507.90\n",
      "Label: anatomicalfinding|mediastinal displacement\n",
      "\tNumber of non-omitted rows: 11776\n",
      "\tWeight: 2473.28\n",
      "Label: disease|aspiration\n",
      "\tNumber of non-omitted rows: 11534\n",
      "\tWeight: 2456.88\n",
      "Label: anatomicalfinding|mass/nodule (not otherwise specified)\n",
      "\tNumber of non-omitted rows: 11341\n",
      "\tWeight: 2443.61\n",
      "Label: anatomicalfinding|linear/patchy atelectasis\n",
      "\tNumber of non-omitted rows: 11262\n",
      "\tWeight: 2438.12\n",
      "Label: device|cardiac pacer and wires\n",
      "\tNumber of non-omitted rows: 10982\n",
      "\tWeight: 2418.44\n",
      "Label: anatomicalfinding|lobar/segmental collapse\n",
      "\tNumber of non-omitted rows: 10953\n",
      "\tWeight: 2416.37\n",
      "Label: anatomicalfinding|superior mediastinal mass/enlargement\n",
      "\tNumber of non-omitted rows: 10695\n",
      "\tWeight: 2397.84\n",
      "Label: anatomicalfinding|airspace opacity\n",
      "\tNumber of non-omitted rows: 10482\n",
      "\tWeight: 2382.28\n",
      "Label: tubesandlines|ij line\n",
      "\tNumber of non-omitted rows: 9936\n",
      "\tWeight: 2341.22\n",
      "Label: anatomicalfinding|rib fracture\n",
      "\tNumber of non-omitted rows: 8398\n",
      "\tWeight: 2215.22\n",
      "Label: disease|fluid overload/heart failure\n",
      "\tNumber of non-omitted rows: 7636\n",
      "\tWeight: 2145.99\n",
      "Label: anatomicalfinding|tortuous aorta\n",
      "\tNumber of non-omitted rows: 6965\n",
      "\tWeight: 2080.44\n",
      "Label: anatomicalfinding|hyperaeration\n",
      "\tNumber of non-omitted rows: 6898\n",
      "\tWeight: 2073.63\n",
      "Label: disease|copd/emphysema\n",
      "\tNumber of non-omitted rows: 6508\n",
      "\tWeight: 2032.94\n",
      "Label: tubesandlines|chest port\n",
      "\tNumber of non-omitted rows: 5678\n",
      "\tWeight: 1939.64\n",
      "Label: anatomicalfinding|costophrenic angle blunting\n",
      "\tNumber of non-omitted rows: 5642\n",
      "\tWeight: 1935.36\n",
      "Label: anatomicalfinding|multiple masses/nodules\n",
      "\tNumber of non-omitted rows: 5480\n",
      "\tWeight: 1915.85\n",
      "Label: anatomicalfinding|elevated hemidiaphragm\n",
      "\tNumber of non-omitted rows: 5358\n",
      "\tWeight: 1900.85\n",
      "Label: anatomicalfinding|vascular calcification\n",
      "\tNumber of non-omitted rows: 5133\n",
      "\tWeight: 1872.50\n",
      "Label: anatomicalfinding|infiltration\n",
      "\tNumber of non-omitted rows: 5105\n",
      "\tWeight: 1868.91\n",
      "Label: tubesandlines|pigtail catheter\n",
      "\tNumber of non-omitted rows: 4099\n",
      "\tWeight: 1728.46\n",
      "Label: anatomicalfinding|spinal fracture\n",
      "\tNumber of non-omitted rows: 3775\n",
      "\tWeight: 1677.63\n",
      "Label: anatomicalfinding|subcutaneous air\n",
      "\tNumber of non-omitted rows: 3698\n",
      "\tWeight: 1665.07\n",
      "Label: anatomicalfinding|spinal degenerative changes\n",
      "\tNumber of non-omitted rows: 3406\n",
      "\tWeight: 1615.56\n",
      "Label: tubesandlines|subclavian line\n",
      "\tNumber of non-omitted rows: 3121\n",
      "\tWeight: 1564.04\n",
      "Label: anatomicalfinding|hernia\n",
      "\tNumber of non-omitted rows: 3013\n",
      "\tWeight: 1543.60\n",
      "Label: anatomicalfinding|sub-diaphragmatic air\n",
      "\tNumber of non-omitted rows: 3011\n",
      "\tWeight: 1543.21\n",
      "Label: tubesandlines|tracheostomy tube\n",
      "\tNumber of non-omitted rows: 2963\n",
      "\tWeight: 1533.94\n",
      "Label: anatomicalfinding|vascular redistribution\n",
      "\tNumber of non-omitted rows: 2843\n",
      "\tWeight: 1510.27\n",
      "Label: disease|granulomatous disease\n",
      "\tNumber of non-omitted rows: 2788\n",
      "\tWeight: 1499.16\n",
      "Label: anatomicalfinding|calcified nodule\n",
      "\tNumber of non-omitted rows: 2734\n",
      "\tWeight: 1488.10\n",
      "Label: anatomicalfinding|bone lesion\n",
      "\tNumber of non-omitted rows: 2667\n",
      "\tWeight: 1474.15\n",
      "Label: disease|interstitial lung disease\n",
      "\tNumber of non-omitted rows: 2663\n",
      "\tWeight: 1473.31\n",
      "Label: anatomicalfinding|scoliosis\n",
      "\tNumber of non-omitted rows: 2490\n",
      "\tWeight: 1435.99\n",
      "Label: tubesandlines|swan-ganz catheter\n",
      "\tNumber of non-omitted rows: 2462\n",
      "\tWeight: 1429.77\n",
      "Label: disease|alveolar hemorrhage\n",
      "\tNumber of non-omitted rows: 2241\n",
      "\tWeight: 1378.72\n",
      "Label: disease|lung cancer\n",
      "\tNumber of non-omitted rows: 2156\n",
      "\tWeight: 1358.10\n",
      "Label: device|prosthetic valve\n",
      "\tNumber of non-omitted rows: 2094\n",
      "\tWeight: 1342.67\n",
      "Label: technicalassessment|rotated\n",
      "\tNumber of non-omitted rows: 1955\n",
      "\tWeight: 1306.81\n",
      "Label: anatomicalfinding|increased reticular markings/ild pattern\n",
      "\tNumber of non-omitted rows: 1819\n",
      "\tWeight: 1269.86\n",
      "Label: anatomicalfinding|shoulder osteoarthritis\n",
      "\tNumber of non-omitted rows: 1805\n",
      "\tWeight: 1265.94\n",
      "Label: anatomicalfinding|pneumomediastinum\n",
      "\tNumber of non-omitted rows: 1797\n",
      "\tWeight: 1263.70\n",
      "Label: device|cabg grafts\n",
      "\tNumber of non-omitted rows: 1797\n",
      "\tWeight: 1263.70\n",
      "Label: disease|pericardial effusion\n",
      "\tNumber of non-omitted rows: 1693\n",
      "\tWeight: 1233.78\n",
      "Label: anatomicalfinding|hydropneumothorax\n",
      "\tNumber of non-omitted rows: 1286\n",
      "\tWeight: 1101.88\n",
      "Label: anatomicalfinding|bronchiectasis\n",
      "\tNumber of non-omitted rows: 1180\n",
      "\tWeight: 1062.64\n",
      "Label: technicalassessment|breast/nipple shadows\n",
      "\tNumber of non-omitted rows: 1173\n",
      "\tWeight: 1059.96\n",
      "Label: anatomicalfinding|cyst/bullae\n",
      "\tNumber of non-omitted rows: 997\n",
      "\tWeight: 988.48\n",
      "Label: anatomicalfinding|clavicle fracture\n",
      "\tNumber of non-omitted rows: 916\n",
      "\tWeight: 952.53\n",
      "Label: tubesandlines|intra-aortic balloon pump\n",
      "\tNumber of non-omitted rows: 716\n",
      "\tWeight: 853.00\n",
      "Label: disease|goiter\n",
      "\tNumber of non-omitted rows: 704\n",
      "\tWeight: 846.44\n",
      "Label: tubesandlines|mediastinal drain\n",
      "\tNumber of non-omitted rows: 697\n",
      "\tWeight: 842.57\n",
      "Label: technicalassessment|artifact\n",
      "\tNumber of non-omitted rows: 486\n",
      "\tWeight: 710.88\n",
      "Label: technicalassessment|skin fold\n",
      "\tNumber of non-omitted rows: 206\n",
      "\tWeight: 454.14\n",
      "Label: device|aortic graft/repair\n",
      "\tNumber of non-omitted rows: 106\n",
      "\tWeight: 304.54\n",
      "Label: anatomicalfinding|diaphragmatic eventration (benign)\n",
      "\tNumber of non-omitted rows: 61\n",
      "\tWeight: 208.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: \"omitted\"\n",
      "\tNumber of rows: 640\n",
      "\tWeight: 810.0601087978947\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_122122_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_122122_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_260_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9266.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_015329_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_260_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9266.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_122122_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.40327, triplet_loss 0.44061, c_loss 0.13058, hs_loss 0.28628, cs_loss 0.64990, cacc 0.94804, hsacc 0.89084, csacc 0.74668, chstimgn_loss 0.05286, chestimg_macro_f1 0.69218, 115.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95200, tacc(al2) 0.80500, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.87000, tacc(ob3) 0.99200, tacc(ob4) 0.95400, 6.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9386.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.39913, triplet_loss 0.43820, c_loss 0.13257, hs_loss 0.27000, cs_loss 0.65107, cacc 0.94612, hsacc 0.89684, csacc 0.74104, chstimgn_loss 0.05235, chestimg_macro_f1 0.71042, 111.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.80100, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.87000, tacc(ob3) 0.99200, tacc(ob4) 0.95400, 6.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9394.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 0.39409, triplet_loss 0.43886, c_loss 0.12268, hs_loss 0.26099, cs_loss 0.64850, cacc 0.95128, hsacc 0.89872, csacc 0.74840, chstimgn_loss 0.05265, chestimg_macro_f1 0.70954, 91.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95500, tacc(al2) 0.79700, tacc(ob0) 0.99600, tacc(ob1) 0.97900, tacc(ob2) 0.86300, tacc(ob3) 0.99400, tacc(ob4) 0.95100, 6.17 secs\n",
      "\u001b[1m---- Epoch 4/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.45462, triplet_loss 0.44460, c_loss 0.15218, hs_loss 0.33908, cs_loss 0.75647, cacc 0.93964, hsacc 0.86952, csacc 0.71320, chstimgn_loss 0.06308, chestimg_macro_f1 0.66133, 91.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98000, tacc(al1) 0.94600, tacc(al2) 0.79000, tacc(ob0) 0.99000, tacc(ob1) 0.97300, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.93900, 6.37 secs\n",
      "\u001b[1m---- Epoch 5/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000112) ...\n",
      "loss 0.45512, triplet_loss 0.44303, c_loss 0.16366, hs_loss 0.32980, cs_loss 0.76326, cacc 0.93508, hsacc 0.87384, csacc 0.70880, chstimgn_loss 0.06036, chestimg_macro_f1 0.68328, 112.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95100, tacc(al2) 0.79900, tacc(ob0) 0.99300, tacc(ob1) 0.97500, tacc(ob2) 0.86000, tacc(ob3) 0.98800, tacc(ob4) 0.94500, 6.95 secs\n",
      "\u001b[1m---- Epoch 6/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 0.42035, triplet_loss 0.44130, c_loss 0.13796, hs_loss 0.28773, cs_loss 0.70491, cacc 0.94344, hsacc 0.88536, csacc 0.72244, chstimgn_loss 0.05474, chestimg_macro_f1 0.70378, 113.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95200, tacc(al2) 0.80500, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.86800, tacc(ob3) 0.99000, tacc(ob4) 0.95600, 6.26 secs\n",
      "\u001b[1m---- Epoch 7/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 0.41365, triplet_loss 0.43967, c_loss 0.13253, hs_loss 0.29932, cs_loss 0.67802, cacc 0.94420, hsacc 0.89288, csacc 0.73608, chstimgn_loss 0.05253, chestimg_macro_f1 0.69836, 114.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95600, tacc(al2) 0.80500, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.85800, tacc(ob3) 0.98900, tacc(ob4) 0.95300, 6.67 secs\n",
      "\u001b[1m---- Epoch 8/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.40117, triplet_loss 0.43965, c_loss 0.12889, hs_loss 0.27640, cs_loss 0.65725, cacc 0.94888, hsacc 0.88916, csacc 0.74220, chstimgn_loss 0.05125, chestimg_macro_f1 0.71538, 111.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95500, tacc(al2) 0.80600, tacc(ob0) 0.99600, tacc(ob1) 0.97900, tacc(ob2) 0.86100, tacc(ob3) 0.99000, tacc(ob4) 0.95100, 7.34 secs\n",
      "\u001b[1m---- Epoch 9/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.39788, triplet_loss 0.43917, c_loss 0.12421, hs_loss 0.26823, cs_loss 0.65979, cacc 0.94948, hsacc 0.89160, csacc 0.74508, chstimgn_loss 0.05006, chestimg_macro_f1 0.71738, 115.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95300, tacc(al2) 0.80100, tacc(ob0) 0.99700, tacc(ob1) 0.97700, tacc(ob2) 0.85600, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 7.10 secs\n",
      "\u001b[1m---- Epoch 10/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.40356, triplet_loss 0.43876, c_loss 0.13662, hs_loss 0.27405, cs_loss 0.66403, cacc 0.94840, hsacc 0.89372, csacc 0.73820, chstimgn_loss 0.05039, chestimg_macro_f1 0.69348, 115.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95400, tacc(al2) 0.80400, tacc(ob0) 0.99700, tacc(ob1) 0.97900, tacc(ob2) 0.86000, tacc(ob3) 0.98800, tacc(ob4) 0.95000, 7.04 secs\n",
      "\u001b[1m---- Epoch 11/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.40011, triplet_loss 0.43828, c_loss 0.14306, hs_loss 0.27280, cs_loss 0.64716, cacc 0.94464, hsacc 0.89572, csacc 0.74696, chstimgn_loss 0.04958, chestimg_macro_f1 0.71659, 112.86 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98200, tacc(al1) 0.95600, tacc(al2) 0.80100, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.85800, tacc(ob3) 0.98900, tacc(ob4) 0.95300, 6.91 secs\n",
      "\u001b[1m---- Epoch 12/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.40100, triplet_loss 0.43591, c_loss 0.14020, hs_loss 0.27423, cs_loss 0.65366, cacc 0.94928, hsacc 0.89344, csacc 0.74372, chstimgn_loss 0.05000, chestimg_macro_f1 0.71990, 114.35 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.95600, tacc(al2) 0.80200, tacc(ob0) 0.99600, tacc(ob1) 0.97900, tacc(ob2) 0.85900, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 6.67 secs\n",
      "\u001b[1m---- Epoch 13/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.45806, triplet_loss 0.44245, c_loss 0.17871, hs_loss 0.32915, cs_loss 0.75725, cacc 0.93568, hsacc 0.87316, csacc 0.70772, chstimgn_loss 0.06234, chestimg_macro_f1 0.67189, 114.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94500, tacc(al2) 0.80500, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.86000, tacc(ob3) 0.98300, tacc(ob4) 0.94300, 7.16 secs\n",
      "\u001b[1m---- Epoch 14/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.45351, triplet_loss 0.44320, c_loss 0.15823, hs_loss 0.33510, cs_loss 0.75917, cacc 0.93592, hsacc 0.87568, csacc 0.70948, chstimgn_loss 0.05916, chestimg_macro_f1 0.69250, 115.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95100, tacc(al2) 0.79500, tacc(ob0) 0.99400, tacc(ob1) 0.98100, tacc(ob2) 0.86100, tacc(ob3) 0.98900, tacc(ob4) 0.95200, 6.68 secs\n",
      "\u001b[1m---- Epoch 15/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41931, triplet_loss 0.43930, c_loss 0.14506, hs_loss 0.28919, cs_loss 0.69691, cacc 0.94564, hsacc 0.88808, csacc 0.73216, chstimgn_loss 0.05339, chestimg_macro_f1 0.70764, 115.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95300, tacc(al2) 0.80700, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.86400, tacc(ob3) 0.98800, tacc(ob4) 0.95700, 6.91 secs\n",
      "\u001b[1m---- Epoch 16/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.41556, triplet_loss 0.44081, c_loss 0.13863, hs_loss 0.29112, cs_loss 0.68874, cacc 0.94324, hsacc 0.88708, csacc 0.73276, chstimgn_loss 0.05147, chestimg_macro_f1 0.70481, 114.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95300, tacc(al2) 0.80600, tacc(ob0) 0.99700, tacc(ob1) 0.97400, tacc(ob2) 0.86800, tacc(ob3) 0.99000, tacc(ob4) 0.95400, 6.87 secs\n",
      "\u001b[1m---- Epoch 17/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40421, triplet_loss 0.44061, c_loss 0.13413, hs_loss 0.26968, cs_loss 0.67404, cacc 0.94332, hsacc 0.89296, csacc 0.73724, chstimgn_loss 0.04920, chestimg_macro_f1 0.71777, 114.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95600, tacc(al2) 0.80400, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.86900, tacc(ob3) 0.98900, tacc(ob4) 0.95300, 7.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9398.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.41025, triplet_loss 0.43797, c_loss 0.15689, hs_loss 0.29376, cs_loss 0.65406, cacc 0.94676, hsacc 0.88736, csacc 0.74084, chstimgn_loss 0.04916, chestimg_macro_f1 0.71914, 114.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95400, tacc(al2) 0.80900, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.86400, tacc(ob3) 0.98900, tacc(ob4) 0.95200, 7.45 secs\n",
      "\u001b[1m---- Epoch 19/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39903, triplet_loss 0.43773, c_loss 0.13678, hs_loss 0.27353, cs_loss 0.65194, cacc 0.94628, hsacc 0.89176, csacc 0.74444, chstimgn_loss 0.04807, chestimg_macro_f1 0.70518, 115.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95500, tacc(al2) 0.80700, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.86700, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 7.30 secs\n",
      "\u001b[1m---- Epoch 20/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39988, triplet_loss 0.43949, c_loss 0.13309, hs_loss 0.27005, cs_loss 0.65863, cacc 0.94536, hsacc 0.89216, csacc 0.74088, chstimgn_loss 0.04914, chestimg_macro_f1 0.71476, 113.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95400, tacc(al2) 0.80800, tacc(ob0) 0.99500, tacc(ob1) 0.97600, tacc(ob2) 0.86600, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 7.06 secs\n",
      "\u001b[1m---- Epoch 21/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.46130, triplet_loss 0.44464, c_loss 0.17406, hs_loss 0.33408, cs_loss 0.77623, cacc 0.93036, hsacc 0.86996, csacc 0.70304, chstimgn_loss 0.05810, chestimg_macro_f1 0.69511, 113.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94100, tacc(al2) 0.80300, tacc(ob0) 0.99300, tacc(ob1) 0.97400, tacc(ob2) 0.86500, tacc(ob3) 0.98400, tacc(ob4) 0.95500, 7.29 secs\n",
      "\u001b[1m---- Epoch 22/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44105, triplet_loss 0.44324, c_loss 0.16529, hs_loss 0.30407, cs_loss 0.74245, cacc 0.93824, hsacc 0.88408, csacc 0.71520, chstimgn_loss 0.05459, chestimg_macro_f1 0.70603, 114.99 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.78100, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.86800, tacc(ob3) 0.98400, tacc(ob4) 0.95500, 6.67 secs\n",
      "\u001b[1m---- Epoch 23/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.42212, triplet_loss 0.44154, c_loss 0.15032, hs_loss 0.29383, cs_loss 0.70102, cacc 0.94512, hsacc 0.88712, csacc 0.72608, chstimgn_loss 0.05089, chestimg_macro_f1 0.69406, 115.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.78500, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.86200, tacc(ob3) 0.99100, tacc(ob4) 0.94900, 7.09 secs\n",
      "\u001b[1m---- Epoch 24/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.41462, triplet_loss 0.43959, c_loss 0.15387, hs_loss 0.28431, cs_loss 0.68333, cacc 0.94436, hsacc 0.89440, csacc 0.73520, chstimgn_loss 0.04869, chestimg_macro_f1 0.71817, 114.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94900, tacc(al2) 0.79300, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.86800, tacc(ob3) 0.99000, tacc(ob4) 0.94700, 7.05 secs\n",
      "\u001b[1m---- Epoch 25/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40119, triplet_loss 0.43819, c_loss 0.13542, hs_loss 0.27129, cs_loss 0.66505, cacc 0.94760, hsacc 0.89368, csacc 0.74184, chstimgn_loss 0.04740, chestimg_macro_f1 0.71881, 114.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94800, tacc(al2) 0.79300, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.86900, tacc(ob3) 0.99100, tacc(ob4) 0.95200, 6.84 secs\n",
      "\u001b[1m---- Epoch 26/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.40092, triplet_loss 0.43806, c_loss 0.12851, hs_loss 0.27389, cs_loss 0.66701, cacc 0.94816, hsacc 0.89272, csacc 0.74288, chstimgn_loss 0.04810, chestimg_macro_f1 0.71779, 114.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95000, tacc(al2) 0.78900, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.86600, tacc(ob3) 0.99100, tacc(ob4) 0.95400, 7.67 secs\n",
      "\u001b[1m---- Epoch 27/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39982, triplet_loss 0.43884, c_loss 0.13205, hs_loss 0.27280, cs_loss 0.66236, cacc 0.94720, hsacc 0.89480, csacc 0.74208, chstimgn_loss 0.04662, chestimg_macro_f1 0.71928, 117.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.79400, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.87100, tacc(ob3) 0.99100, tacc(ob4) 0.95300, 7.83 secs\n",
      "\u001b[1m---- Epoch 28/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39551, triplet_loss 0.43797, c_loss 0.12605, hs_loss 0.26280, cs_loss 0.66175, cacc 0.94556, hsacc 0.90116, csacc 0.74336, chstimgn_loss 0.04673, chestimg_macro_f1 0.72805, 105.31 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94800, tacc(al2) 0.79300, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.87000, tacc(ob3) 0.99100, tacc(ob4) 0.95500, 6.99 secs\n",
      "\u001b[1m---- Epoch 29/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.45513, triplet_loss 0.44182, c_loss 0.17363, hs_loss 0.32472, cs_loss 0.76215, cacc 0.93736, hsacc 0.87696, csacc 0.70928, chstimgn_loss 0.05910, chestimg_macro_f1 0.69870, 96.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.81000, tacc(ob0) 0.99600, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.95600, 7.62 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 30/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44176, triplet_loss 0.44238, c_loss 0.15915, hs_loss 0.31648, cs_loss 0.73978, cacc 0.93784, hsacc 0.87748, csacc 0.71672, chstimgn_loss 0.05463, chestimg_macro_f1 0.69346, 97.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94700, tacc(al2) 0.80400, tacc(ob0) 0.99100, tacc(ob1) 0.97600, tacc(ob2) 0.87300, tacc(ob3) 0.98600, tacc(ob4) 0.95200, 8.17 secs\n",
      "\u001b[1m---- Epoch 31/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.42568, triplet_loss 0.44217, c_loss 0.15063, hs_loss 0.29852, cs_loss 0.70910, cacc 0.94112, hsacc 0.87896, csacc 0.72828, chstimgn_loss 0.05115, chestimg_macro_f1 0.72290, 99.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95200, tacc(al2) 0.81200, tacc(ob0) 0.99000, tacc(ob1) 0.97500, tacc(ob2) 0.86700, tacc(ob3) 0.98600, tacc(ob4) 0.95600, 8.00 secs\n",
      "\u001b[1m---- Epoch 32/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40506, triplet_loss 0.43898, c_loss 0.12946, hs_loss 0.28158, cs_loss 0.67352, cacc 0.94804, hsacc 0.89224, csacc 0.73856, chstimgn_loss 0.04834, chestimg_macro_f1 0.71518, 100.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94700, tacc(al2) 0.80500, tacc(ob0) 0.99100, tacc(ob1) 0.97600, tacc(ob2) 0.86600, tacc(ob3) 0.98700, tacc(ob4) 0.96100, 8.45 secs\n",
      "\u001b[1m---- Epoch 33/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40551, triplet_loss 0.43831, c_loss 0.14650, hs_loss 0.28203, cs_loss 0.66023, cacc 0.94636, hsacc 0.89008, csacc 0.74120, chstimgn_loss 0.04748, chestimg_macro_f1 0.72752, 101.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.79900, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.86400, tacc(ob3) 0.99000, tacc(ob4) 0.96000, 7.26 secs\n",
      "\u001b[1m---- Epoch 34/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.40164, triplet_loss 0.43893, c_loss 0.13758, hs_loss 0.27274, cs_loss 0.66565, cacc 0.94456, hsacc 0.89116, csacc 0.73904, chstimgn_loss 0.04583, chestimg_macro_f1 0.72912, 116.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94700, tacc(al2) 0.79800, tacc(ob0) 0.99100, tacc(ob1) 0.97300, tacc(ob2) 0.86200, tacc(ob3) 0.99000, tacc(ob4) 0.96000, 7.79 secs\n",
      "\u001b[1m---- Epoch 35/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39705, triplet_loss 0.43943, c_loss 0.13282, hs_loss 0.27925, cs_loss 0.64430, cacc 0.94636, hsacc 0.89004, csacc 0.74896, chstimgn_loss 0.04620, chestimg_macro_f1 0.71695, 116.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.80100, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.86200, tacc(ob3) 0.98900, tacc(ob4) 0.96000, 7.88 secs\n",
      "\u001b[1m---- Epoch 36/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39952, triplet_loss 0.43890, c_loss 0.12864, hs_loss 0.27506, cs_loss 0.66357, cacc 0.94752, hsacc 0.89188, csacc 0.74096, chstimgn_loss 0.04595, chestimg_macro_f1 0.71549, 113.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.80200, tacc(ob0) 0.99100, tacc(ob1) 0.97500, tacc(ob2) 0.86000, tacc(ob3) 0.98900, tacc(ob4) 0.96000, 6.85 secs\n",
      "\u001b[1m---- Epoch 37/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44955, triplet_loss 0.44367, c_loss 0.16326, hs_loss 0.31341, cs_loss 0.76774, cacc 0.93488, hsacc 0.87756, csacc 0.70512, chstimgn_loss 0.05507, chestimg_macro_f1 0.70689, 116.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94100, tacc(al2) 0.78500, tacc(ob0) 0.99400, tacc(ob1) 0.98100, tacc(ob2) 0.85700, tacc(ob3) 0.98800, tacc(ob4) 0.95000, 7.14 secs\n",
      "\u001b[1m---- Epoch 38/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.45125, triplet_loss 0.44402, c_loss 0.17567, hs_loss 0.33167, cs_loss 0.74896, cacc 0.93328, hsacc 0.87468, csacc 0.71088, chstimgn_loss 0.05234, chestimg_macro_f1 0.69779, 116.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.79800, tacc(ob0) 0.99200, tacc(ob1) 0.97900, tacc(ob2) 0.86900, tacc(ob3) 0.98400, tacc(ob4) 0.95000, 6.65 secs\n",
      "\u001b[1m---- Epoch 39/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.42203, triplet_loss 0.43938, c_loss 0.14930, hs_loss 0.30091, cs_loss 0.70231, cacc 0.94204, hsacc 0.88516, csacc 0.72604, chstimgn_loss 0.04811, chestimg_macro_f1 0.72425, 116.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.79600, tacc(ob0) 0.99100, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.98600, tacc(ob4) 0.95500, 7.20 secs\n",
      "\u001b[1m---- Epoch 40/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.41463, triplet_loss 0.44041, c_loss 0.14556, hs_loss 0.29125, cs_loss 0.68817, cacc 0.94568, hsacc 0.88740, csacc 0.73200, chstimgn_loss 0.04656, chestimg_macro_f1 0.73056, 115.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.80200, tacc(ob0) 0.99200, tacc(ob1) 0.97700, tacc(ob2) 0.87400, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 6.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_40_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9399.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 41/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40912, triplet_loss 0.43833, c_loss 0.14347, hs_loss 0.28450, cs_loss 0.67745, cacc 0.94364, hsacc 0.89376, csacc 0.73620, chstimgn_loss 0.04636, chestimg_macro_f1 0.72684, 116.51 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95000, tacc(al2) 0.80900, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 7.13 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_41_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9407.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 42/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39993, triplet_loss 0.43771, c_loss 0.13178, hs_loss 0.27749, cs_loss 0.66210, cacc 0.94772, hsacc 0.89196, csacc 0.74024, chstimgn_loss 0.04532, chestimg_macro_f1 0.72260, 115.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95100, tacc(al2) 0.80400, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87200, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 7.78 secs\n",
      "\u001b[1m---- Epoch 43/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39971, triplet_loss 0.43978, c_loss 0.12973, hs_loss 0.27815, cs_loss 0.66024, cacc 0.94936, hsacc 0.89520, csacc 0.74248, chstimgn_loss 0.04548, chestimg_macro_f1 0.71685, 116.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.80700, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87100, tacc(ob3) 0.98800, tacc(ob4) 0.95700, 6.82 secs\n",
      "\u001b[1m---- Epoch 44/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39917, triplet_loss 0.43879, c_loss 0.14366, hs_loss 0.26692, cs_loss 0.65727, cacc 0.94668, hsacc 0.89248, csacc 0.74280, chstimgn_loss 0.04502, chestimg_macro_f1 0.73594, 115.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.80600, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 7.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_44_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9412.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 45/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.45170, triplet_loss 0.44323, c_loss 0.16843, hs_loss 0.32259, cs_loss 0.76560, cacc 0.93804, hsacc 0.87744, csacc 0.70652, chstimgn_loss 0.05346, chestimg_macro_f1 0.70011, 114.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.93800, tacc(al2) 0.79600, tacc(ob0) 0.99300, tacc(ob1) 0.97300, tacc(ob2) 0.85200, tacc(ob3) 0.98000, tacc(ob4) 0.94600, 6.79 secs\n",
      "\u001b[1m---- Epoch 46/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.45102, triplet_loss 0.44539, c_loss 0.16880, hs_loss 0.32601, cs_loss 0.76080, cacc 0.93584, hsacc 0.87684, csacc 0.70980, chstimgn_loss 0.05153, chestimg_macro_f1 0.70828, 115.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94100, tacc(al2) 0.79700, tacc(ob0) 0.99200, tacc(ob1) 0.97600, tacc(ob2) 0.86600, tacc(ob3) 0.98600, tacc(ob4) 0.94900, 6.69 secs\n",
      "\u001b[1m---- Epoch 47/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.42101, triplet_loss 0.43989, c_loss 0.14775, hs_loss 0.31215, cs_loss 0.68903, cacc 0.94104, hsacc 0.88620, csacc 0.73184, chstimgn_loss 0.04760, chestimg_macro_f1 0.72389, 113.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.79500, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86300, tacc(ob3) 0.98500, tacc(ob4) 0.95000, 6.74 secs\n",
      "\u001b[1m---- Epoch 48/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.41225, triplet_loss 0.43745, c_loss 0.15403, hs_loss 0.29011, cs_loss 0.67576, cacc 0.93924, hsacc 0.88760, csacc 0.73544, chstimgn_loss 0.04583, chestimg_macro_f1 0.73411, 114.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94900, tacc(al2) 0.80000, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.86400, tacc(ob3) 0.98800, tacc(ob4) 0.95500, 7.41 secs\n",
      "\u001b[1m---- Epoch 49/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40476, triplet_loss 0.44090, c_loss 0.14185, hs_loss 0.27895, cs_loss 0.66966, cacc 0.94500, hsacc 0.88952, csacc 0.73600, chstimgn_loss 0.04385, chestimg_macro_f1 0.73594, 113.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95400, tacc(al2) 0.80200, tacc(ob0) 0.99400, tacc(ob1) 0.97500, tacc(ob2) 0.86700, tacc(ob3) 0.99000, tacc(ob4) 0.95100, 7.60 secs\n",
      "\u001b[1m---- Epoch 50/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.40219, triplet_loss 0.43896, c_loss 0.13342, hs_loss 0.28314, cs_loss 0.66506, cacc 0.94752, hsacc 0.89164, csacc 0.73924, chstimgn_loss 0.04410, chestimg_macro_f1 0.72141, 114.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95200, tacc(al2) 0.80700, tacc(ob0) 0.99500, tacc(ob1) 0.97400, tacc(ob2) 0.86500, tacc(ob3) 0.98800, tacc(ob4) 0.94900, 7.65 secs\n",
      "\u001b[1m---- Epoch 51/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39645, triplet_loss 0.43765, c_loss 0.12031, hs_loss 0.27684, cs_loss 0.66407, cacc 0.94712, hsacc 0.89000, csacc 0.74160, chstimgn_loss 0.04347, chestimg_macro_f1 0.73645, 115.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95300, tacc(al2) 0.80600, tacc(ob0) 0.99500, tacc(ob1) 0.97400, tacc(ob2) 0.86400, tacc(ob3) 0.98900, tacc(ob4) 0.95200, 6.67 secs\n",
      "\u001b[1m---- Epoch 52/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.40281, triplet_loss 0.43984, c_loss 0.13835, hs_loss 0.28522, cs_loss 0.66091, cacc 0.94636, hsacc 0.89336, csacc 0.74520, chstimgn_loss 0.04346, chestimg_macro_f1 0.73622, 115.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95200, tacc(al2) 0.80700, tacc(ob0) 0.99500, tacc(ob1) 0.97300, tacc(ob2) 0.86400, tacc(ob3) 0.98800, tacc(ob4) 0.95300, 7.25 secs\n",
      "\u001b[1m---- Epoch 53/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.46262, triplet_loss 0.44414, c_loss 0.20460, hs_loss 0.33543, cs_loss 0.75476, cacc 0.93100, hsacc 0.87616, csacc 0.70736, chstimgn_loss 0.05578, chestimg_macro_f1 0.69471, 112.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94700, tacc(al2) 0.78500, tacc(ob0) 0.99100, tacc(ob1) 0.97900, tacc(ob2) 0.86200, tacc(ob3) 0.98500, tacc(ob4) 0.94000, 7.49 secs\n",
      "\u001b[1m---- Epoch 54/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43789, triplet_loss 0.44204, c_loss 0.15808, hs_loss 0.30988, cs_loss 0.74010, cacc 0.94076, hsacc 0.88372, csacc 0.71308, chstimgn_loss 0.05074, chestimg_macro_f1 0.71052, 114.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.79300, tacc(ob0) 0.99200, tacc(ob1) 0.97700, tacc(ob2) 0.86700, tacc(ob3) 0.98700, tacc(ob4) 0.94800, 7.29 secs\n",
      "\u001b[1m---- Epoch 55/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41483, triplet_loss 0.43922, c_loss 0.14710, hs_loss 0.28645, cs_loss 0.69363, cacc 0.94064, hsacc 0.88840, csacc 0.72836, chstimgn_loss 0.04645, chestimg_macro_f1 0.73275, 115.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95200, tacc(al2) 0.79400, tacc(ob0) 0.99200, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.94700, 7.01 secs\n",
      "\u001b[1m---- Epoch 56/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40679, triplet_loss 0.43934, c_loss 0.14514, hs_loss 0.28350, cs_loss 0.66921, cacc 0.94536, hsacc 0.89336, csacc 0.73784, chstimgn_loss 0.04498, chestimg_macro_f1 0.73562, 106.99 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95500, tacc(al2) 0.80100, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.94600, 6.81 secs\n",
      "\u001b[1m---- Epoch 57/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40601, triplet_loss 0.43813, c_loss 0.14434, hs_loss 0.28642, cs_loss 0.66854, cacc 0.94632, hsacc 0.89396, csacc 0.74012, chstimgn_loss 0.04331, chestimg_macro_f1 0.72269, 113.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.79800, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.87200, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 7.47 secs\n",
      "\u001b[1m---- Epoch 58/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39606, triplet_loss 0.43867, c_loss 0.12887, hs_loss 0.27512, cs_loss 0.65507, cacc 0.94736, hsacc 0.89312, csacc 0.74432, chstimgn_loss 0.04326, chestimg_macro_f1 0.73818, 114.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95600, tacc(al2) 0.80100, tacc(ob0) 0.99300, tacc(ob1) 0.98200, tacc(ob2) 0.87300, tacc(ob3) 0.98900, tacc(ob4) 0.94800, 7.20 secs\n",
      "\u001b[1m---- Epoch 59/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39414, triplet_loss 0.43898, c_loss 0.13353, hs_loss 0.27179, cs_loss 0.64777, cacc 0.94880, hsacc 0.89524, csacc 0.74628, chstimgn_loss 0.04224, chestimg_macro_f1 0.74368, 112.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95600, tacc(al2) 0.80300, tacc(ob0) 0.99200, tacc(ob1) 0.98200, tacc(ob2) 0.87100, tacc(ob3) 0.98900, tacc(ob4) 0.95000, 6.69 secs\n",
      "\u001b[1m---- Epoch 60/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39029, triplet_loss 0.43906, c_loss 0.11765, hs_loss 0.26470, cs_loss 0.65525, cacc 0.94904, hsacc 0.89164, csacc 0.74340, chstimgn_loss 0.04224, chestimg_macro_f1 0.74315, 114.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95600, tacc(al2) 0.80400, tacc(ob0) 0.99200, tacc(ob1) 0.98200, tacc(ob2) 0.87000, tacc(ob3) 0.98800, tacc(ob4) 0.95100, 6.81 secs\n",
      "\u001b[1m---- Epoch 61/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.46452, triplet_loss 0.44285, c_loss 0.19143, hs_loss 0.34741, cs_loss 0.76886, cacc 0.92952, hsacc 0.86764, csacc 0.70920, chstimgn_loss 0.05376, chestimg_macro_f1 0.70641, 113.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94000, tacc(al2) 0.79400, tacc(ob0) 0.99100, tacc(ob1) 0.97700, tacc(ob2) 0.86500, tacc(ob3) 0.98200, tacc(ob4) 0.94700, 7.09 secs\n",
      "\u001b[1m---- Epoch 62/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44664, triplet_loss 0.44381, c_loss 0.17396, hs_loss 0.31287, cs_loss 0.75211, cacc 0.93272, hsacc 0.87960, csacc 0.71132, chstimgn_loss 0.05191, chestimg_macro_f1 0.71688, 114.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94200, tacc(al2) 0.78100, tacc(ob0) 0.99000, tacc(ob1) 0.97400, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.95400, 6.94 secs\n",
      "\u001b[1m---- Epoch 63/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41743, triplet_loss 0.44086, c_loss 0.13577, hs_loss 0.29006, cs_loss 0.71160, cacc 0.94128, hsacc 0.88816, csacc 0.72196, chstimgn_loss 0.04571, chestimg_macro_f1 0.73264, 116.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.79300, tacc(ob0) 0.99000, tacc(ob1) 0.97900, tacc(ob2) 0.85900, tacc(ob3) 0.98900, tacc(ob4) 0.95300, 6.46 secs\n",
      "\u001b[1m---- Epoch 64/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.41132, triplet_loss 0.43915, c_loss 0.14731, hs_loss 0.29232, cs_loss 0.67926, cacc 0.94220, hsacc 0.89004, csacc 0.73416, chstimgn_loss 0.04362, chestimg_macro_f1 0.73429, 116.91 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95000, tacc(al2) 0.78500, tacc(ob0) 0.99000, tacc(ob1) 0.97900, tacc(ob2) 0.87300, tacc(ob3) 0.98600, tacc(ob4) 0.95100, 6.48 secs\n",
      "\u001b[1m---- Epoch 65/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40335, triplet_loss 0.43911, c_loss 0.14461, hs_loss 0.27703, cs_loss 0.66736, cacc 0.94528, hsacc 0.89564, csacc 0.73764, chstimgn_loss 0.04264, chestimg_macro_f1 0.73508, 114.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95200, tacc(al2) 0.79300, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 6.55 secs\n",
      "\u001b[1m---- Epoch 66/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.40446, triplet_loss 0.43919, c_loss 0.14976, hs_loss 0.28169, cs_loss 0.66128, cacc 0.94360, hsacc 0.89464, csacc 0.74312, chstimgn_loss 0.04297, chestimg_macro_f1 0.73829, 112.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.79500, tacc(ob0) 0.99100, tacc(ob1) 0.98000, tacc(ob2) 0.87500, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 6.69 secs\n",
      "\u001b[1m---- Epoch 67/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.40502, triplet_loss 0.43809, c_loss 0.14441, hs_loss 0.29186, cs_loss 0.66362, cacc 0.94396, hsacc 0.89028, csacc 0.74048, chstimgn_loss 0.04105, chestimg_macro_f1 0.74457, 114.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.79100, tacc(ob0) 0.99100, tacc(ob1) 0.98200, tacc(ob2) 0.87100, tacc(ob3) 0.98600, tacc(ob4) 0.95400, 6.28 secs\n",
      "\u001b[1m---- Epoch 68/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39944, triplet_loss 0.43884, c_loss 0.13974, hs_loss 0.27364, cs_loss 0.66256, cacc 0.94524, hsacc 0.89492, csacc 0.74164, chstimgn_loss 0.04149, chestimg_macro_f1 0.74446, 113.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95200, tacc(al2) 0.79100, tacc(ob0) 0.99100, tacc(ob1) 0.98000, tacc(ob2) 0.87200, tacc(ob3) 0.98600, tacc(ob4) 0.95500, 6.41 secs\n",
      "\u001b[1m---- Epoch 69/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.45639, triplet_loss 0.44236, c_loss 0.17980, hs_loss 0.32377, cs_loss 0.77473, cacc 0.93212, hsacc 0.87256, csacc 0.70592, chstimgn_loss 0.05244, chestimg_macro_f1 0.71785, 113.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94900, tacc(al2) 0.81800, tacc(ob0) 0.98900, tacc(ob1) 0.98000, tacc(ob2) 0.87600, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 6.92 secs\n",
      "\u001b[1m---- Epoch 70/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44033, triplet_loss 0.44290, c_loss 0.15693, hs_loss 0.31663, cs_loss 0.74876, cacc 0.93976, hsacc 0.87696, csacc 0.71076, chstimgn_loss 0.04805, chestimg_macro_f1 0.70966, 113.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.79000, tacc(ob0) 0.99000, tacc(ob1) 0.97900, tacc(ob2) 0.86600, tacc(ob3) 0.98600, tacc(ob4) 0.95200, 6.81 secs\n",
      "\u001b[1m---- Epoch 71/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41514, triplet_loss 0.43922, c_loss 0.15756, hs_loss 0.28380, cs_loss 0.69041, cacc 0.93916, hsacc 0.88480, csacc 0.73132, chstimgn_loss 0.04478, chestimg_macro_f1 0.73334, 113.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94700, tacc(al2) 0.79400, tacc(ob0) 0.99400, tacc(ob1) 0.97900, tacc(ob2) 0.86500, tacc(ob3) 0.98500, tacc(ob4) 0.95300, 6.05 secs\n",
      "\u001b[1m---- Epoch 72/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40405, triplet_loss 0.43968, c_loss 0.13749, hs_loss 0.27365, cs_loss 0.67959, cacc 0.94416, hsacc 0.89272, csacc 0.73612, chstimgn_loss 0.04289, chestimg_macro_f1 0.73993, 100.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.79000, tacc(ob0) 0.99200, tacc(ob1) 0.97900, tacc(ob2) 0.86700, tacc(ob3) 0.98500, tacc(ob4) 0.95400, 6.71 secs\n",
      "\u001b[1m---- Epoch 73/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40685, triplet_loss 0.43943, c_loss 0.15402, hs_loss 0.27859, cs_loss 0.67153, cacc 0.94372, hsacc 0.88912, csacc 0.73476, chstimgn_loss 0.04192, chestimg_macro_f1 0.74246, 92.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.79300, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.86800, tacc(ob3) 0.98700, tacc(ob4) 0.95300, 6.59 secs\n",
      "\u001b[1m---- Epoch 74/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39757, triplet_loss 0.43765, c_loss 0.12541, hs_loss 0.29042, cs_loss 0.65533, cacc 0.94636, hsacc 0.89168, csacc 0.74476, chstimgn_loss 0.04073, chestimg_macro_f1 0.74533, 92.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.79000, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.86900, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 6.73 secs\n",
      "\u001b[1m---- Epoch 75/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39656, triplet_loss 0.43783, c_loss 0.12612, hs_loss 0.27294, cs_loss 0.66857, cacc 0.94552, hsacc 0.89268, csacc 0.73824, chstimgn_loss 0.04039, chestimg_macro_f1 0.74835, 112.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.79000, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.86700, tacc(ob3) 0.98800, tacc(ob4) 0.95300, 6.93 secs\n",
      "\u001b[1m---- Epoch 76/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39190, triplet_loss 0.43860, c_loss 0.12516, hs_loss 0.26738, cs_loss 0.65459, cacc 0.94572, hsacc 0.89328, csacc 0.74632, chstimgn_loss 0.04093, chestimg_macro_f1 0.74424, 114.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.79100, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.86400, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 6.22 secs\n",
      "\u001b[1m---- Epoch 77/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44697, triplet_loss 0.44094, c_loss 0.16028, hs_loss 0.32385, cs_loss 0.76334, cacc 0.93836, hsacc 0.87684, csacc 0.71076, chstimgn_loss 0.04974, chestimg_macro_f1 0.72175, 108.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98100, tacc(al1) 0.95600, tacc(al2) 0.79700, tacc(ob0) 0.98900, tacc(ob1) 0.98000, tacc(ob2) 0.85100, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 6.82 secs\n",
      "\u001b[1m---- Epoch 78/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43214, triplet_loss 0.44289, c_loss 0.14236, hs_loss 0.31569, cs_loss 0.73287, cacc 0.93832, hsacc 0.87968, csacc 0.72008, chstimgn_loss 0.04738, chestimg_macro_f1 0.72862, 92.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93800, tacc(al2) 0.77900, tacc(ob0) 0.99300, tacc(ob1) 0.98400, tacc(ob2) 0.85800, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 7.02 secs\n",
      "\u001b[1m---- Epoch 79/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.42079, triplet_loss 0.44055, c_loss 0.15258, hs_loss 0.30103, cs_loss 0.70123, cacc 0.93940, hsacc 0.88748, csacc 0.72648, chstimgn_loss 0.04388, chestimg_macro_f1 0.73590, 92.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94100, tacc(al2) 0.79000, tacc(ob0) 0.99000, tacc(ob1) 0.98200, tacc(ob2) 0.86000, tacc(ob3) 0.98500, tacc(ob4) 0.95700, 6.66 secs\n",
      "\u001b[1m---- Epoch 80/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40495, triplet_loss 0.43706, c_loss 0.14888, hs_loss 0.27375, cs_loss 0.67690, cacc 0.94392, hsacc 0.89132, csacc 0.73432, chstimgn_loss 0.04161, chestimg_macro_f1 0.72555, 93.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94800, tacc(al2) 0.79000, tacc(ob0) 0.99300, tacc(ob1) 0.97800, tacc(ob2) 0.86200, tacc(ob3) 0.98800, tacc(ob4) 0.95600, 6.48 secs\n",
      "\u001b[1m---- Epoch 81/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40185, triplet_loss 0.43850, c_loss 0.14226, hs_loss 0.28037, cs_loss 0.66430, cacc 0.94688, hsacc 0.89168, csacc 0.74288, chstimgn_loss 0.04099, chestimg_macro_f1 0.74711, 113.19 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94300, tacc(al2) 0.78100, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86200, tacc(ob3) 0.98700, tacc(ob4) 0.95500, 6.48 secs\n",
      "\u001b[1m---- Epoch 82/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39516, triplet_loss 0.43882, c_loss 0.13566, hs_loss 0.26686, cs_loss 0.65891, cacc 0.94672, hsacc 0.89384, csacc 0.73892, chstimgn_loss 0.04020, chestimg_macro_f1 0.74968, 112.31 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94400, tacc(al2) 0.78300, tacc(ob0) 0.99300, tacc(ob1) 0.98000, tacc(ob2) 0.86200, tacc(ob3) 0.98700, tacc(ob4) 0.95400, 6.76 secs\n",
      "\u001b[1m---- Epoch 83/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39735, triplet_loss 0.43631, c_loss 0.12912, hs_loss 0.28160, cs_loss 0.66197, cacc 0.94576, hsacc 0.89300, csacc 0.74520, chstimgn_loss 0.04020, chestimg_macro_f1 0.74738, 112.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94600, tacc(al2) 0.78500, tacc(ob0) 0.99300, tacc(ob1) 0.97800, tacc(ob2) 0.86500, tacc(ob3) 0.98700, tacc(ob4) 0.95500, 6.48 secs\n",
      "\u001b[1m---- Epoch 84/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39370, triplet_loss 0.43790, c_loss 0.12919, hs_loss 0.27915, cs_loss 0.65007, cacc 0.94708, hsacc 0.89440, csacc 0.74672, chstimgn_loss 0.03924, chestimg_macro_f1 0.75309, 114.06 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98600, tacc(al1) 0.94600, tacc(al2) 0.78400, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86400, tacc(ob3) 0.98700, tacc(ob4) 0.95500, 6.66 secs\n",
      "\u001b[1m---- Epoch 85/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.45198, triplet_loss 0.44425, c_loss 0.17631, hs_loss 0.32759, cs_loss 0.75796, cacc 0.93312, hsacc 0.87468, csacc 0.71148, chstimgn_loss 0.05090, chestimg_macro_f1 0.72046, 111.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94400, tacc(al2) 0.79000, tacc(ob0) 0.99100, tacc(ob1) 0.96800, tacc(ob2) 0.85600, tacc(ob3) 0.98400, tacc(ob4) 0.93700, 6.25 secs\n",
      "\u001b[1m---- Epoch 86/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44071, triplet_loss 0.44242, c_loss 0.15896, hs_loss 0.31494, cs_loss 0.74937, cacc 0.93184, hsacc 0.87416, csacc 0.71124, chstimgn_loss 0.04858, chestimg_macro_f1 0.72787, 113.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.78700, tacc(ob0) 0.99000, tacc(ob1) 0.97700, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.95200, 6.35 secs\n",
      "\u001b[1m---- Epoch 87/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41415, triplet_loss 0.43822, c_loss 0.14997, hs_loss 0.28923, cs_loss 0.69232, cacc 0.94280, hsacc 0.88420, csacc 0.72864, chstimgn_loss 0.04343, chestimg_macro_f1 0.74496, 110.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95600, tacc(al2) 0.79200, tacc(ob0) 0.98900, tacc(ob1) 0.97500, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 6.34 secs\n",
      "\u001b[1m---- Epoch 88/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40681, triplet_loss 0.43797, c_loss 0.14788, hs_loss 0.29291, cs_loss 0.66485, cacc 0.94380, hsacc 0.88752, csacc 0.73820, chstimgn_loss 0.04181, chestimg_macro_f1 0.74451, 112.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.78800, tacc(ob0) 0.99100, tacc(ob1) 0.97500, tacc(ob2) 0.87300, tacc(ob3) 0.98500, tacc(ob4) 0.94700, 6.34 secs\n",
      "\u001b[1m---- Epoch 89/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39449, triplet_loss 0.43949, c_loss 0.12747, hs_loss 0.27070, cs_loss 0.66087, cacc 0.94544, hsacc 0.89568, csacc 0.74116, chstimgn_loss 0.03972, chestimg_macro_f1 0.75077, 112.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.78300, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 6.56 secs\n",
      "\u001b[1m---- Epoch 90/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39593, triplet_loss 0.43951, c_loss 0.13515, hs_loss 0.27318, cs_loss 0.65722, cacc 0.94204, hsacc 0.89332, csacc 0.74372, chstimgn_loss 0.03934, chestimg_macro_f1 0.75324, 113.25 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.78400, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.87200, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 6.34 secs\n",
      "\u001b[1m---- Epoch 91/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39016, triplet_loss 0.43728, c_loss 0.12423, hs_loss 0.26821, cs_loss 0.65166, cacc 0.94600, hsacc 0.89812, csacc 0.74408, chstimgn_loss 0.03963, chestimg_macro_f1 0.75348, 113.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95000, tacc(al2) 0.78500, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.86800, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 6.67 secs\n",
      "\u001b[1m---- Epoch 92/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39180, triplet_loss 0.43843, c_loss 0.13035, hs_loss 0.26122, cs_loss 0.65954, cacc 0.94636, hsacc 0.89748, csacc 0.74148, chstimgn_loss 0.03883, chestimg_macro_f1 0.75575, 112.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.78600, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.87100, tacc(ob3) 0.98700, tacc(ob4) 0.94800, 6.03 secs\n",
      "\u001b[1m---- Epoch 93/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44707, triplet_loss 0.44258, c_loss 0.16987, hs_loss 0.32302, cs_loss 0.75601, cacc 0.93708, hsacc 0.88088, csacc 0.71024, chstimgn_loss 0.04841, chestimg_macro_f1 0.72662, 110.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94300, tacc(al2) 0.79600, tacc(ob0) 0.99300, tacc(ob1) 0.97100, tacc(ob2) 0.86300, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 6.20 secs\n",
      "\u001b[1m---- Epoch 94/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43538, triplet_loss 0.44213, c_loss 0.15050, hs_loss 0.31696, cs_loss 0.74074, cacc 0.93708, hsacc 0.88120, csacc 0.71488, chstimgn_loss 0.04560, chestimg_macro_f1 0.73283, 110.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94900, tacc(al2) 0.80400, tacc(ob0) 0.99100, tacc(ob1) 0.96300, tacc(ob2) 0.85900, tacc(ob3) 0.98700, tacc(ob4) 0.94700, 6.08 secs\n",
      "\u001b[1m---- Epoch 95/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41868, triplet_loss 0.43930, c_loss 0.14957, hs_loss 0.29591, cs_loss 0.70561, cacc 0.94404, hsacc 0.88964, csacc 0.72484, chstimgn_loss 0.04216, chestimg_macro_f1 0.72355, 113.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.79900, tacc(ob0) 0.99400, tacc(ob1) 0.97300, tacc(ob2) 0.85700, tacc(ob3) 0.98400, tacc(ob4) 0.95100, 6.22 secs\n",
      "\u001b[1m---- Epoch 96/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40777, triplet_loss 0.43770, c_loss 0.15601, hs_loss 0.28136, cs_loss 0.67778, cacc 0.94408, hsacc 0.89416, csacc 0.73480, chstimgn_loss 0.03911, chestimg_macro_f1 0.75038, 113.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95400, tacc(al2) 0.79000, tacc(ob0) 0.99200, tacc(ob1) 0.97500, tacc(ob2) 0.86400, tacc(ob3) 0.98500, tacc(ob4) 0.95000, 6.29 secs\n",
      "\u001b[1m---- Epoch 97/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39897, triplet_loss 0.43774, c_loss 0.13245, hs_loss 0.27939, cs_loss 0.66916, cacc 0.94552, hsacc 0.89612, csacc 0.73388, chstimgn_loss 0.03857, chestimg_macro_f1 0.75607, 112.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95500, tacc(al2) 0.78700, tacc(ob0) 0.99400, tacc(ob1) 0.97700, tacc(ob2) 0.86400, tacc(ob3) 0.98500, tacc(ob4) 0.95400, 6.70 secs\n",
      "\u001b[1m---- Epoch 98/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39466, triplet_loss 0.43803, c_loss 0.13601, hs_loss 0.27076, cs_loss 0.65602, cacc 0.94700, hsacc 0.89704, csacc 0.73968, chstimgn_loss 0.03891, chestimg_macro_f1 0.75141, 109.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95700, tacc(al2) 0.78500, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.86600, tacc(ob3) 0.98500, tacc(ob4) 0.95400, 6.22 secs\n",
      "\u001b[1m---- Epoch 99/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39699, triplet_loss 0.43734, c_loss 0.14556, hs_loss 0.27989, cs_loss 0.65017, cacc 0.94520, hsacc 0.89380, csacc 0.74364, chstimgn_loss 0.03750, chestimg_macro_f1 0.75615, 109.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95500, tacc(al2) 0.78600, tacc(ob0) 0.99400, tacc(ob1) 0.97800, tacc(ob2) 0.86600, tacc(ob3) 0.98600, tacc(ob4) 0.95100, 6.85 secs\n",
      "\u001b[1m---- Epoch 100/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39581, triplet_loss 0.43777, c_loss 0.13587, hs_loss 0.27819, cs_loss 0.65652, cacc 0.94412, hsacc 0.89388, csacc 0.74476, chstimgn_loss 0.03744, chestimg_macro_f1 0.75880, 109.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95600, tacc(al2) 0.78600, tacc(ob0) 0.99400, tacc(ob1) 0.97700, tacc(ob2) 0.86600, tacc(ob3) 0.98400, tacc(ob4) 0.95100, 6.13 secs\n",
      "\u001b[1m---- Epoch 101/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44418, triplet_loss 0.44145, c_loss 0.15399, hs_loss 0.32878, cs_loss 0.75261, cacc 0.94088, hsacc 0.87304, csacc 0.71080, chstimgn_loss 0.04995, chestimg_macro_f1 0.72121, 110.94 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94300, tacc(al2) 0.81400, tacc(ob0) 0.98900, tacc(ob1) 0.96900, tacc(ob2) 0.87100, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 6.18 secs\n",
      "\u001b[1m---- Epoch 102/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43402, triplet_loss 0.44050, c_loss 0.15851, hs_loss 0.31625, cs_loss 0.73114, cacc 0.93796, hsacc 0.88316, csacc 0.72044, chstimgn_loss 0.04483, chestimg_macro_f1 0.73549, 105.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.79700, tacc(ob0) 0.99100, tacc(ob1) 0.97600, tacc(ob2) 0.87300, tacc(ob3) 0.98700, tacc(ob4) 0.95400, 6.26 secs\n",
      "\u001b[1m---- Epoch 103/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.41551, triplet_loss 0.44012, c_loss 0.14549, hs_loss 0.29813, cs_loss 0.69574, cacc 0.94140, hsacc 0.88692, csacc 0.72760, chstimgn_loss 0.04128, chestimg_macro_f1 0.74750, 94.44 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95000, tacc(al2) 0.78800, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87800, tacc(ob3) 0.99300, tacc(ob4) 0.95300, 6.80 secs\n",
      "\u001b[1m---- Epoch 104/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40352, triplet_loss 0.43993, c_loss 0.14600, hs_loss 0.28555, cs_loss 0.66368, cacc 0.94028, hsacc 0.88976, csacc 0.73780, chstimgn_loss 0.03947, chestimg_macro_f1 0.75213, 111.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95000, tacc(al2) 0.78300, tacc(ob0) 0.99600, tacc(ob1) 0.98100, tacc(ob2) 0.87400, tacc(ob3) 0.99100, tacc(ob4) 0.95000, 6.30 secs\n",
      "\u001b[1m---- Epoch 105/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39664, triplet_loss 0.43735, c_loss 0.13602, hs_loss 0.27543, cs_loss 0.66024, cacc 0.94464, hsacc 0.89472, csacc 0.73964, chstimgn_loss 0.03875, chestimg_macro_f1 0.74465, 112.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95300, tacc(al2) 0.78500, tacc(ob0) 0.99400, tacc(ob1) 0.97900, tacc(ob2) 0.87800, tacc(ob3) 0.99100, tacc(ob4) 0.94900, 6.24 secs\n",
      "\u001b[1m---- Epoch 106/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38989, triplet_loss 0.43910, c_loss 0.12378, hs_loss 0.27454, cs_loss 0.64587, cacc 0.94492, hsacc 0.89244, csacc 0.74424, chstimgn_loss 0.03813, chestimg_macro_f1 0.75931, 112.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95400, tacc(al2) 0.78800, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87500, tacc(ob3) 0.99100, tacc(ob4) 0.94700, 6.08 secs\n",
      "\u001b[1m---- Epoch 107/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.38866, triplet_loss 0.43808, c_loss 0.13163, hs_loss 0.26384, cs_loss 0.64568, cacc 0.94700, hsacc 0.89720, csacc 0.74424, chstimgn_loss 0.03772, chestimg_macro_f1 0.75640, 113.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95200, tacc(al2) 0.79200, tacc(ob0) 0.99600, tacc(ob1) 0.98000, tacc(ob2) 0.87300, tacc(ob3) 0.99100, tacc(ob4) 0.94700, 6.11 secs\n",
      "\u001b[1m---- Epoch 108/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39807, triplet_loss 0.43971, c_loss 0.14338, hs_loss 0.28110, cs_loss 0.65339, cacc 0.94864, hsacc 0.89340, csacc 0.74364, chstimgn_loss 0.03734, chestimg_macro_f1 0.75741, 112.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95600, tacc(al2) 0.79000, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.87300, tacc(ob3) 0.99100, tacc(ob4) 0.94700, 6.26 secs\n",
      "\u001b[1m---- Epoch 109/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.43102, triplet_loss 0.44024, c_loss 0.14822, hs_loss 0.31649, cs_loss 0.72546, cacc 0.94016, hsacc 0.88064, csacc 0.72140, chstimgn_loss 0.04684, chestimg_macro_f1 0.73788, 113.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.79800, tacc(ob0) 0.99100, tacc(ob1) 0.96700, tacc(ob2) 0.86300, tacc(ob3) 0.98900, tacc(ob4) 0.94100, 6.02 secs\n",
      "\u001b[1m---- Epoch 110/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43792, triplet_loss 0.44044, c_loss 0.16462, hs_loss 0.31323, cs_loss 0.74146, cacc 0.94056, hsacc 0.88180, csacc 0.71404, chstimgn_loss 0.04596, chestimg_macro_f1 0.72141, 111.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95500, tacc(al2) 0.78800, tacc(ob0) 0.99200, tacc(ob1) 0.97900, tacc(ob2) 0.87200, tacc(ob3) 0.98100, tacc(ob4) 0.95400, 6.52 secs\n",
      "\u001b[1m---- Epoch 111/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41428, triplet_loss 0.43887, c_loss 0.15317, hs_loss 0.29309, cs_loss 0.69082, cacc 0.94164, hsacc 0.88480, csacc 0.73500, chstimgn_loss 0.04059, chestimg_macro_f1 0.74487, 111.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95500, tacc(al2) 0.79200, tacc(ob0) 0.99100, tacc(ob1) 0.98100, tacc(ob2) 0.87300, tacc(ob3) 0.98400, tacc(ob4) 0.94700, 6.08 secs\n",
      "\u001b[1m---- Epoch 112/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.40223, triplet_loss 0.43965, c_loss 0.14136, hs_loss 0.29152, cs_loss 0.66162, cacc 0.94040, hsacc 0.88624, csacc 0.73984, chstimgn_loss 0.03738, chestimg_macro_f1 0.75207, 107.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95800, tacc(al2) 0.79300, tacc(ob0) 0.99400, tacc(ob1) 0.98300, tacc(ob2) 0.86700, tacc(ob3) 0.98500, tacc(ob4) 0.95100, 6.10 secs\n",
      "\u001b[1m---- Epoch 113/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39184, triplet_loss 0.43911, c_loss 0.13395, hs_loss 0.27022, cs_loss 0.65022, cacc 0.94520, hsacc 0.88912, csacc 0.74592, chstimgn_loss 0.03694, chestimg_macro_f1 0.74487, 112.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95700, tacc(al2) 0.78900, tacc(ob0) 0.99200, tacc(ob1) 0.97800, tacc(ob2) 0.86600, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 6.13 secs\n",
      "\u001b[1m---- Epoch 114/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39262, triplet_loss 0.43762, c_loss 0.13495, hs_loss 0.27282, cs_loss 0.65220, cacc 0.94680, hsacc 0.89124, csacc 0.74196, chstimgn_loss 0.03644, chestimg_macro_f1 0.74859, 109.24 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95700, tacc(al2) 0.79100, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86500, tacc(ob3) 0.98700, tacc(ob4) 0.95400, 5.87 secs\n",
      "\u001b[1m---- Epoch 115/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39081, triplet_loss 0.43810, c_loss 0.13043, hs_loss 0.27673, cs_loss 0.64502, cacc 0.94752, hsacc 0.89200, csacc 0.74492, chstimgn_loss 0.03647, chestimg_macro_f1 0.76049, 109.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95700, tacc(al2) 0.78900, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86900, tacc(ob3) 0.98700, tacc(ob4) 0.95500, 6.14 secs\n",
      "\u001b[1m---- Epoch 116/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39172, triplet_loss 0.43845, c_loss 0.13852, hs_loss 0.26566, cs_loss 0.65009, cacc 0.94528, hsacc 0.89544, csacc 0.74616, chstimgn_loss 0.03708, chestimg_macro_f1 0.76405, 110.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95600, tacc(al2) 0.78900, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.86900, tacc(ob3) 0.98600, tacc(ob4) 0.95500, 6.79 secs\n",
      "\u001b[1m---- Epoch 117/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44370, triplet_loss 0.44216, c_loss 0.16700, hs_loss 0.32687, cs_loss 0.74727, cacc 0.93644, hsacc 0.87892, csacc 0.71316, chstimgn_loss 0.04574, chestimg_macro_f1 0.73675, 112.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94700, tacc(al2) 0.78100, tacc(ob0) 0.98800, tacc(ob1) 0.96700, tacc(ob2) 0.85200, tacc(ob3) 0.98500, tacc(ob4) 0.95400, 6.20 secs\n",
      "\u001b[1m---- Epoch 118/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.42493, triplet_loss 0.44168, c_loss 0.15126, hs_loss 0.29734, cs_loss 0.72441, cacc 0.93976, hsacc 0.88408, csacc 0.71860, chstimgn_loss 0.04252, chestimg_macro_f1 0.73894, 109.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95300, tacc(al2) 0.78200, tacc(ob0) 0.98600, tacc(ob1) 0.97500, tacc(ob2) 0.87600, tacc(ob3) 0.98600, tacc(ob4) 0.95900, 6.18 secs\n",
      "\u001b[1m---- Epoch 119/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41281, triplet_loss 0.44017, c_loss 0.14876, hs_loss 0.28994, cs_loss 0.69532, cacc 0.94132, hsacc 0.88868, csacc 0.72728, chstimgn_loss 0.03852, chestimg_macro_f1 0.75659, 114.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95200, tacc(al2) 0.78300, tacc(ob0) 0.98600, tacc(ob1) 0.97600, tacc(ob2) 0.87000, tacc(ob3) 0.98800, tacc(ob4) 0.95100, 6.19 secs\n",
      "\u001b[1m---- Epoch 120/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.39793, triplet_loss 0.43917, c_loss 0.13141, hs_loss 0.27866, cs_loss 0.66588, cacc 0.94604, hsacc 0.89536, csacc 0.73772, chstimgn_loss 0.03828, chestimg_macro_f1 0.75772, 112.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95100, tacc(al2) 0.78300, tacc(ob0) 0.99000, tacc(ob1) 0.97300, tacc(ob2) 0.87400, tacc(ob3) 0.98400, tacc(ob4) 0.95400, 6.58 secs\n",
      "\u001b[1m---- Epoch 121/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39286, triplet_loss 0.43906, c_loss 0.13099, hs_loss 0.27354, cs_loss 0.65353, cacc 0.94524, hsacc 0.89304, csacc 0.73852, chstimgn_loss 0.03717, chestimg_macro_f1 0.74910, 113.15 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95400, tacc(al2) 0.77900, tacc(ob0) 0.99000, tacc(ob1) 0.97700, tacc(ob2) 0.86900, tacc(ob3) 0.98400, tacc(ob4) 0.95500, 6.55 secs\n",
      "\u001b[1m---- Epoch 122/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39352, triplet_loss 0.43879, c_loss 0.12991, hs_loss 0.27619, cs_loss 0.65805, cacc 0.94720, hsacc 0.89384, csacc 0.74360, chstimgn_loss 0.03557, chestimg_macro_f1 0.76514, 110.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95400, tacc(al2) 0.78100, tacc(ob0) 0.99000, tacc(ob1) 0.98000, tacc(ob2) 0.86800, tacc(ob3) 0.98500, tacc(ob4) 0.95600, 7.22 secs\n",
      "\u001b[1m---- Epoch 123/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39388, triplet_loss 0.43610, c_loss 0.13592, hs_loss 0.27172, cs_loss 0.65914, cacc 0.94760, hsacc 0.89412, csacc 0.74028, chstimgn_loss 0.03631, chestimg_macro_f1 0.75980, 111.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95400, tacc(al2) 0.78100, tacc(ob0) 0.99100, tacc(ob1) 0.98000, tacc(ob2) 0.86900, tacc(ob3) 0.98500, tacc(ob4) 0.95700, 6.80 secs\n",
      "\u001b[1m---- Epoch 124/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39318, triplet_loss 0.43724, c_loss 0.14509, hs_loss 0.27407, cs_loss 0.64582, cacc 0.94412, hsacc 0.89292, csacc 0.74640, chstimgn_loss 0.03525, chestimg_macro_f1 0.76201, 112.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95400, tacc(al2) 0.78000, tacc(ob0) 0.99100, tacc(ob1) 0.98000, tacc(ob2) 0.87000, tacc(ob3) 0.98300, tacc(ob4) 0.95700, 6.52 secs\n",
      "\u001b[1m---- Epoch 125/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.44986, triplet_loss 0.44423, c_loss 0.18246, hs_loss 0.33739, cs_loss 0.74359, cacc 0.93364, hsacc 0.87168, csacc 0.71340, chstimgn_loss 0.04588, chestimg_macro_f1 0.73558, 112.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94100, tacc(al2) 0.80500, tacc(ob0) 0.99400, tacc(ob1) 0.96400, tacc(ob2) 0.86700, tacc(ob3) 0.98400, tacc(ob4) 0.95300, 6.90 secs\n",
      "\u001b[1m---- Epoch 126/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.43278, triplet_loss 0.44119, c_loss 0.16699, hs_loss 0.32095, cs_loss 0.71579, cacc 0.93596, hsacc 0.88156, csacc 0.72308, chstimgn_loss 0.04311, chestimg_macro_f1 0.74615, 114.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.80300, tacc(ob0) 0.99500, tacc(ob1) 0.97400, tacc(ob2) 0.88700, tacc(ob3) 0.98700, tacc(ob4) 0.95000, 6.76 secs\n",
      "\u001b[1m---- Epoch 127/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.40930, triplet_loss 0.43932, c_loss 0.14839, hs_loss 0.29265, cs_loss 0.68025, cacc 0.94164, hsacc 0.88848, csacc 0.72848, chstimgn_loss 0.03830, chestimg_macro_f1 0.75553, 114.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.78600, tacc(ob0) 0.99600, tacc(ob1) 0.98000, tacc(ob2) 0.87600, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 6.69 secs\n",
      "\u001b[1m---- Epoch 128/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.39899, triplet_loss 0.43883, c_loss 0.14855, hs_loss 0.27881, cs_loss 0.65674, cacc 0.94472, hsacc 0.89216, csacc 0.74384, chstimgn_loss 0.03652, chestimg_macro_f1 0.76194, 114.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.78700, tacc(ob0) 0.99600, tacc(ob1) 0.98200, tacc(ob2) 0.87900, tacc(ob3) 0.98600, tacc(ob4) 0.95300, 7.50 secs\n",
      "\u001b[1m---- Epoch 129/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39455, triplet_loss 0.43796, c_loss 0.13441, hs_loss 0.27771, cs_loss 0.65667, cacc 0.94548, hsacc 0.89592, csacc 0.74196, chstimgn_loss 0.03573, chestimg_macro_f1 0.76180, 137.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.79100, tacc(ob0) 0.99600, tacc(ob1) 0.98200, tacc(ob2) 0.87700, tacc(ob3) 0.98500, tacc(ob4) 0.95000, 8.78 secs\n",
      "\u001b[1m---- Epoch 130/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38866, triplet_loss 0.43739, c_loss 0.12505, hs_loss 0.27053, cs_loss 0.65212, cacc 0.94636, hsacc 0.89712, csacc 0.74584, chstimgn_loss 0.03478, chestimg_macro_f1 0.76572, 133.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.78900, tacc(ob0) 0.99600, tacc(ob1) 0.98100, tacc(ob2) 0.88100, tacc(ob3) 0.98500, tacc(ob4) 0.95100, 9.05 secs\n",
      "\u001b[1m---- Epoch 131/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.38864, triplet_loss 0.43838, c_loss 0.13717, hs_loss 0.27147, cs_loss 0.63620, cacc 0.94500, hsacc 0.89184, csacc 0.74968, chstimgn_loss 0.03567, chestimg_macro_f1 0.77319, 146.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.78900, tacc(ob0) 0.99600, tacc(ob1) 0.98200, tacc(ob2) 0.88300, tacc(ob3) 0.98700, tacc(ob4) 0.95100, 9.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_131_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9415.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 132/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39032, triplet_loss 0.43871, c_loss 0.13344, hs_loss 0.27122, cs_loss 0.64921, cacc 0.94592, hsacc 0.89392, csacc 0.74672, chstimgn_loss 0.03435, chestimg_macro_f1 0.76828, 141.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95000, tacc(al2) 0.78800, tacc(ob0) 0.99600, tacc(ob1) 0.98200, tacc(ob2) 0.88200, tacc(ob3) 0.98500, tacc(ob4) 0.95100, 11.23 secs\n",
      "\u001b[1m---- Epoch 133/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.43574, triplet_loss 0.44477, c_loss 0.15781, hs_loss 0.31033, cs_loss 0.73676, cacc 0.93852, hsacc 0.87820, csacc 0.71436, chstimgn_loss 0.04663, chestimg_macro_f1 0.72663, 146.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94200, tacc(al2) 0.79400, tacc(ob0) 0.99100, tacc(ob1) 0.97600, tacc(ob2) 0.87400, tacc(ob3) 0.98600, tacc(ob4) 0.95400, 10.71 secs\n",
      "\u001b[1m---- Epoch 134/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.41962, triplet_loss 0.44040, c_loss 0.14942, hs_loss 0.30006, cs_loss 0.70676, cacc 0.94136, hsacc 0.88188, csacc 0.72644, chstimgn_loss 0.04092, chestimg_macro_f1 0.75038, 149.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95200, tacc(al2) 0.79000, tacc(ob0) 0.99700, tacc(ob1) 0.97800, tacc(ob2) 0.87100, tacc(ob3) 0.98600, tacc(ob4) 0.95100, 10.21 secs\n",
      "\u001b[1m---- Epoch 135/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.40363, triplet_loss 0.43955, c_loss 0.14682, hs_loss 0.27932, cs_loss 0.67182, cacc 0.94456, hsacc 0.89144, csacc 0.73752, chstimgn_loss 0.03850, chestimg_macro_f1 0.75883, 146.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.79400, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.87200, tacc(ob3) 0.98800, tacc(ob4) 0.94800, 9.10 secs\n",
      "\u001b[1m---- Epoch 136/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.39927, triplet_loss 0.43985, c_loss 0.14280, hs_loss 0.27461, cs_loss 0.66880, cacc 0.94564, hsacc 0.89124, csacc 0.74020, chstimgn_loss 0.03551, chestimg_macro_f1 0.76069, 148.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.78000, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.87400, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 9.54 secs\n",
      "\u001b[1m---- Epoch 137/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39092, triplet_loss 0.43775, c_loss 0.13533, hs_loss 0.26218, cs_loss 0.65660, cacc 0.94768, hsacc 0.89540, csacc 0.74304, chstimgn_loss 0.03592, chestimg_macro_f1 0.76653, 149.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94800, tacc(al2) 0.78500, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87300, tacc(ob3) 0.99000, tacc(ob4) 0.95000, 11.08 secs\n",
      "\u001b[1m---- Epoch 138/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38292, triplet_loss 0.43725, c_loss 0.12705, hs_loss 0.26140, cs_loss 0.63714, cacc 0.94716, hsacc 0.89668, csacc 0.74980, chstimgn_loss 0.03442, chestimg_macro_f1 0.76998, 149.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94700, tacc(al2) 0.79000, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.87800, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 9.34 secs\n",
      "\u001b[1m---- Epoch 139/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.39052, triplet_loss 0.43800, c_loss 0.14086, hs_loss 0.27280, cs_loss 0.64158, cacc 0.94972, hsacc 0.89852, csacc 0.74868, chstimgn_loss 0.03442, chestimg_macro_f1 0.76915, 149.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94700, tacc(al2) 0.79000, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.87700, tacc(ob3) 0.99000, tacc(ob4) 0.95100, 11.13 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 140/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.38609, triplet_loss 0.43760, c_loss 0.12415, hs_loss 0.27132, cs_loss 0.64218, cacc 0.94544, hsacc 0.89824, csacc 0.74616, chstimgn_loss 0.03456, chestimg_macro_f1 0.76830, 148.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94800, tacc(al2) 0.79000, tacc(ob0) 0.99300, tacc(ob1) 0.98000, tacc(ob2) 0.87600, tacc(ob3) 0.99000, tacc(ob4) 0.95100, 10.95 secs\n",
      "\u001b[1m---- Epoch 141/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.43385, triplet_loss 0.44169, c_loss 0.15952, hs_loss 0.32201, cs_loss 0.72391, cacc 0.93608, hsacc 0.87364, csacc 0.72016, chstimgn_loss 0.04412, chestimg_macro_f1 0.74583, 147.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97700, tacc(al1) 0.93700, tacc(al2) 0.76200, tacc(ob0) 0.98800, tacc(ob1) 0.97400, tacc(ob2) 0.85900, tacc(ob3) 0.97900, tacc(ob4) 0.93700, 10.68 secs\n",
      "\u001b[1m---- Epoch 142/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.44186, triplet_loss 0.44273, c_loss 0.15603, hs_loss 0.32738, cs_loss 0.75365, cacc 0.93772, hsacc 0.87456, csacc 0.71188, chstimgn_loss 0.04382, chestimg_macro_f1 0.73838, 147.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94400, tacc(al2) 0.78200, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.86800, tacc(ob3) 0.98200, tacc(ob4) 0.94900, 11.40 secs\n",
      "\u001b[1m---- Epoch 143/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.41327, triplet_loss 0.44235, c_loss 0.14300, hs_loss 0.29751, cs_loss 0.69610, cacc 0.93896, hsacc 0.88684, csacc 0.72660, chstimgn_loss 0.03705, chestimg_macro_f1 0.76212, 146.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94900, tacc(al2) 0.77900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.86700, tacc(ob3) 0.98800, tacc(ob4) 0.95500, 11.65 secs\n",
      "\u001b[1m---- Epoch 144/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.39895, triplet_loss 0.43927, c_loss 0.13538, hs_loss 0.28063, cs_loss 0.66689, cacc 0.94368, hsacc 0.89052, csacc 0.73464, chstimgn_loss 0.03680, chestimg_macro_f1 0.76189, 146.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95000, tacc(al2) 0.79100, tacc(ob0) 0.99700, tacc(ob1) 0.98200, tacc(ob2) 0.88000, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 10.77 secs\n",
      "\u001b[1m---- Epoch 145/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.39376, triplet_loss 0.43883, c_loss 0.12583, hs_loss 0.28121, cs_loss 0.66018, cacc 0.94672, hsacc 0.89392, csacc 0.74272, chstimgn_loss 0.03450, chestimg_macro_f1 0.77126, 144.10 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.79200, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.86900, tacc(ob3) 0.99100, tacc(ob4) 0.95200, 11.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_145_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9420.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 146/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39295, triplet_loss 0.43783, c_loss 0.13533, hs_loss 0.28678, cs_loss 0.64084, cacc 0.94624, hsacc 0.88996, csacc 0.74584, chstimgn_loss 0.03551, chestimg_macro_f1 0.76781, 150.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94800, tacc(al2) 0.78600, tacc(ob0) 0.99700, tacc(ob1) 0.98200, tacc(ob2) 0.87100, tacc(ob3) 0.98800, tacc(ob4) 0.95200, 10.70 secs\n",
      "\u001b[1m---- Epoch 147/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.38643, triplet_loss 0.43815, c_loss 0.13115, hs_loss 0.27083, cs_loss 0.63775, cacc 0.94664, hsacc 0.89552, csacc 0.74764, chstimgn_loss 0.03393, chestimg_macro_f1 0.77044, 147.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95100, tacc(al2) 0.78200, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.87000, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 11.13 secs\n",
      "\u001b[1m---- Epoch 148/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.38956, triplet_loss 0.43765, c_loss 0.13232, hs_loss 0.26723, cs_loss 0.65273, cacc 0.94656, hsacc 0.89616, csacc 0.74160, chstimgn_loss 0.03415, chestimg_macro_f1 0.77025, 149.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94900, tacc(al2) 0.78300, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.87200, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 10.47 secs\n",
      "\u001b[1m---- Epoch 149/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.42947, triplet_loss 0.44245, c_loss 0.16154, hs_loss 0.30508, cs_loss 0.72667, cacc 0.93740, hsacc 0.88244, csacc 0.71936, chstimgn_loss 0.04106, chestimg_macro_f1 0.75136, 147.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94600, tacc(al2) 0.78500, tacc(ob0) 0.99100, tacc(ob1) 0.97300, tacc(ob2) 0.86000, tacc(ob3) 0.98700, tacc(ob4) 0.94300, 9.16 secs\n",
      "\u001b[1m---- Epoch 150/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.42284, triplet_loss 0.44148, c_loss 0.14548, hs_loss 0.30385, cs_loss 0.72380, cacc 0.94084, hsacc 0.88492, csacc 0.72356, chstimgn_loss 0.03838, chestimg_macro_f1 0.75871, 149.51 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.79400, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.87700, tacc(ob3) 0.98900, tacc(ob4) 0.94400, 10.89 secs\n",
      "\u001b[1m---- Epoch 151/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.39899, triplet_loss 0.43974, c_loss 0.14757, hs_loss 0.26627, cs_loss 0.67098, cacc 0.94520, hsacc 0.88792, csacc 0.73668, chstimgn_loss 0.03571, chestimg_macro_f1 0.76585, 149.19 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.95400, tacc(al2) 0.78400, tacc(ob0) 0.99400, tacc(ob1) 0.97800, tacc(ob2) 0.87200, tacc(ob3) 0.98400, tacc(ob4) 0.95300, 10.65 secs\n",
      "\u001b[1m---- Epoch 152/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.39543, triplet_loss 0.43893, c_loss 0.13702, hs_loss 0.28313, cs_loss 0.65372, cacc 0.94344, hsacc 0.89508, csacc 0.74288, chstimgn_loss 0.03446, chestimg_macro_f1 0.76662, 149.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95000, tacc(al2) 0.78600, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.87300, tacc(ob3) 0.98800, tacc(ob4) 0.95300, 11.10 secs\n",
      "\u001b[1m---- Epoch 153/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.38827, triplet_loss 0.43848, c_loss 0.12445, hs_loss 0.27285, cs_loss 0.65035, cacc 0.94812, hsacc 0.89524, csacc 0.74612, chstimgn_loss 0.03347, chestimg_macro_f1 0.77339, 147.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95100, tacc(al2) 0.79100, tacc(ob0) 0.99500, tacc(ob1) 0.97400, tacc(ob2) 0.87000, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 10.89 secs\n",
      "\u001b[1m---- Epoch 154/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39117, triplet_loss 0.43783, c_loss 0.13809, hs_loss 0.27964, cs_loss 0.64282, cacc 0.94340, hsacc 0.89232, csacc 0.74764, chstimgn_loss 0.03314, chestimg_macro_f1 0.77633, 148.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.78900, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.86700, tacc(ob3) 0.99000, tacc(ob4) 0.95400, 9.93 secs\n",
      "\u001b[1m---- Epoch 155/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.38595, triplet_loss 0.43765, c_loss 0.13053, hs_loss 0.27205, cs_loss 0.63697, cacc 0.94624, hsacc 0.89740, csacc 0.74780, chstimgn_loss 0.03331, chestimg_macro_f1 0.77239, 148.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.79100, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.86600, tacc(ob3) 0.99100, tacc(ob4) 0.95500, 10.98 secs\n",
      "\u001b[1m---- Epoch 156/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "^C iteration 155300\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 502, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 413, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_fact_embedding.py\", line 259, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 121, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/fact_embedding.py\", line 162, in step_fn_wrapper\n",
      "    output = step_fn__metadata_classification(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/fact_embedding.py\", line 103, in step_fn__metadata_classification\n",
      "    gradient_accumulator.step(batch_loss)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 26, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 488, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_015329_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--chest_imagenome_phrase2labels_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels(num_labels=76,num_phrases=556111).pkl\" \\\n",
    "--n_chest_imagenome_labels 76 \\\n",
    "--triplets_weight 1.0 \\\n",
    "--metadata_classification_weight 1.0 \\\n",
    "--chest_imagenome_classification_weight 2.0 \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9342f593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 100\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_labels: 74\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_122122_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   integrated_chest_imagenome_labels_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl\n",
      "   dataset_name: MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 1.0\n",
      "   chest_imagenome_classification_weight: 2.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome: True\n",
      "  n_chest_imagenome_labels: 74\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "1e-06 3 0.0002 8 2e-06 0.0002 8 2e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train metadata classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: greater size of pleural effusions compared to prior study\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: larger\n",
      "\u001b[1mExample fact: consolidation at the lower part of the right lung possibly caused by inhalation\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: multiple loops of distended large bowel\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: Reduced opacification is seen in the lingula\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: smaller\n",
      "\u001b[1mExample fact: The endotracheal tube tip is situated about 4.9 cm above the carina\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: hazy soft tissue density in the right paratracheal region\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: Translucency at the base of the right lung is amplified\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: increase\n",
      "\u001b[1mExample fact: malpositioned left PICC terminates in the azygos vein\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: no obvious residual basilar hydropneumothorax appreciated\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: uncertain localization of the tip due to reduced lung volumes\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding train chest imagenome labels classification dataset and dataloader...\u001b[0m\n",
      "Loading chest integrated chest imagenome labels from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl...\n",
      "len(phrases): 2552490\n",
      "len(label_names): 74\n",
      "labels.shape: (2552490, 74)\n",
      "Label: lung opacity\n",
      "\tNumber of idxs: 545396\n",
      "\tWeight: 6920.86\n",
      "Label: pleural effusion\n",
      "\tNumber of idxs: 210024\n",
      "\tWeight: 5526.64\n",
      "Label: atelectasis\n",
      "\tNumber of idxs: 157638\n",
      "\tWeight: 5147.48\n",
      "Label: pneumonia\n",
      "\tNumber of idxs: 102321\n",
      "\tWeight: 4609.72\n",
      "Label: lung lesion\n",
      "\tNumber of idxs: 91567\n",
      "\tWeight: 4477.88\n",
      "Label: pulmonary edema/hazy opacity\n",
      "\tNumber of idxs: 90170\n",
      "\tWeight: 4459.83\n",
      "Label: enteric tube\n",
      "\tNumber of idxs: 89660\n",
      "\tWeight: 4453.18\n",
      "Label: consolidation\n",
      "\tNumber of idxs: 86042\n",
      "\tWeight: 4405.10\n",
      "Label: airspace opacity\n",
      "\tNumber of idxs: 74463\n",
      "\tWeight: 4239.13\n",
      "Label: mass/nodule (not otherwise specified)\n",
      "\tNumber of idxs: 71602\n",
      "\tWeight: 4194.87\n",
      "Label: ij line\n",
      "\tNumber of idxs: 71363\n",
      "\tWeight: 4191.11\n",
      "Label: increased reticular markings/ild pattern\n",
      "\tNumber of idxs: 71151\n",
      "\tWeight: 4187.76\n",
      "Label: vascular congestion\n",
      "\tNumber of idxs: 68126\n",
      "\tWeight: 4139.10\n",
      "Label: enlarged cardiac silhouette\n",
      "\tNumber of idxs: 66476\n",
      "\tWeight: 4111.80\n",
      "Label: endotracheal tube\n",
      "\tNumber of idxs: 57767\n",
      "\tWeight: 3957.78\n",
      "Label: pleural/parenchymal scarring\n",
      "\tNumber of idxs: 55741\n",
      "\tWeight: 3919.24\n",
      "Label: infiltration\n",
      "\tNumber of idxs: 53996\n",
      "\tWeight: 3885.12\n",
      "Label: picc\n",
      "\tNumber of idxs: 52338\n",
      "\tWeight: 3851.86\n",
      "Label: cardiac pacer and wires\n",
      "\tNumber of idxs: 51132\n",
      "\tWeight: 3827.12\n",
      "Label: lobar/segmental collapse\n",
      "\tNumber of idxs: 49855\n",
      "\tWeight: 3800.40\n",
      "Label: rib fracture\n",
      "\tNumber of idxs: 48249\n",
      "\tWeight: 3765.99\n",
      "Label: pneumothorax\n",
      "\tNumber of idxs: 47137\n",
      "\tWeight: 3741.61\n",
      "Label: sub-diaphragmatic air\n",
      "\tNumber of idxs: 45808\n",
      "\tWeight: 3711.86\n",
      "Label: artifact\n",
      "\tNumber of idxs: 44545\n",
      "\tWeight: 3682.93\n",
      "Label: mediastinal widening\n",
      "\tNumber of idxs: 43575\n",
      "\tWeight: 3660.25\n",
      "Label: chest tube\n",
      "\tNumber of idxs: 43310\n",
      "\tWeight: 3653.98\n",
      "Label: enlarged hilum\n",
      "\tNumber of idxs: 39792\n",
      "\tWeight: 3567.68\n",
      "Label: hyperaeration\n",
      "\tNumber of idxs: 36155\n",
      "\tWeight: 3471.70\n",
      "Label: linear/patchy atelectasis\n",
      "\tNumber of idxs: 35090\n",
      "\tWeight: 3442.11\n",
      "Label: subcutaneous air\n",
      "\tNumber of idxs: 31502\n",
      "\tWeight: 3336.78\n",
      "Label: vascular calcification\n",
      "\tNumber of idxs: 29081\n",
      "\tWeight: 3260.09\n",
      "Label: low lung volumes\n",
      "\tNumber of idxs: 27898\n",
      "\tWeight: 3220.73\n",
      "Label: subclavian line\n",
      "\tNumber of idxs: 26390\n",
      "\tWeight: 3168.56\n",
      "Label: chest port\n",
      "\tNumber of idxs: 25350\n",
      "\tWeight: 3131.17\n",
      "Label: aspiration\n",
      "\tNumber of idxs: 25239\n",
      "\tWeight: 3127.10\n",
      "Label: spinal fracture\n",
      "\tNumber of idxs: 23897\n",
      "\tWeight: 3076.81\n",
      "Label: spinal degenerative changes\n",
      "\tNumber of idxs: 22873\n",
      "\tWeight: 3036.88\n",
      "Label: costophrenic angle blunting\n",
      "\tNumber of idxs: 21655\n",
      "\tWeight: 2987.49\n",
      "Label: interstitial lung disease\n",
      "\tNumber of idxs: 19411\n",
      "\tWeight: 2890.34\n",
      "Label: mediastinal displacement\n",
      "\tNumber of idxs: 19259\n",
      "\tWeight: 2883.45\n",
      "Label: pigtail catheter\n",
      "\tNumber of idxs: 19083\n",
      "\tWeight: 2875.40\n",
      "Label: swan-ganz catheter\n",
      "\tNumber of idxs: 18702\n",
      "\tWeight: 2857.79\n",
      "Label: bone lesion\n",
      "\tNumber of idxs: 18335\n",
      "\tWeight: 2840.55\n",
      "Label: fluid overload/heart failure\n",
      "\tNumber of idxs: 17658\n",
      "\tWeight: 2808.02\n",
      "Label: aortic graft/repair\n",
      "\tNumber of idxs: 16289\n",
      "\tWeight: 2739.07\n",
      "Label: vascular redistribution\n",
      "\tNumber of idxs: 16287\n",
      "\tWeight: 2738.97\n",
      "Label: elevated hemidiaphragm\n",
      "\tNumber of idxs: 15943\n",
      "\tWeight: 2720.92\n",
      "Label: tortuous aorta\n",
      "\tNumber of idxs: 15726\n",
      "\tWeight: 2709.37\n",
      "Label: copd/emphysema\n",
      "\tNumber of idxs: 13639\n",
      "\tWeight: 2591.37\n",
      "Label: tracheostomy tube\n",
      "\tNumber of idxs: 13575\n",
      "\tWeight: 2587.53\n",
      "Label: superior mediastinal mass/enlargement\n",
      "\tNumber of idxs: 12376\n",
      "\tWeight: 2512.83\n",
      "Label: calcified nodule\n",
      "\tNumber of idxs: 12277\n",
      "\tWeight: 2506.41\n",
      "Label: bronchiectasis\n",
      "\tNumber of idxs: 12016\n",
      "\tWeight: 2489.28\n",
      "Label: mediastinal drain\n",
      "\tNumber of idxs: 11868\n",
      "\tWeight: 2479.45\n",
      "Label: clavicle fracture\n",
      "\tNumber of idxs: 11411\n",
      "\tWeight: 2448.44\n",
      "Label: shoulder osteoarthritis\n",
      "\tNumber of idxs: 10526\n",
      "\tWeight: 2385.52\n",
      "Label: hernia\n",
      "\tNumber of idxs: 10022\n",
      "\tWeight: 2347.80\n",
      "Label: scoliosis\n",
      "\tNumber of idxs: 9382\n",
      "\tWeight: 2297.71\n",
      "Label: granulomatous disease\n",
      "\tNumber of idxs: 9099\n",
      "\tWeight: 2274.71\n",
      "Label: prosthetic valve\n",
      "\tNumber of idxs: 8946\n",
      "\tWeight: 2262.03\n",
      "Label: intra-aortic balloon pump\n",
      "\tNumber of idxs: 8936\n",
      "\tWeight: 2261.20\n",
      "Label: lung cancer\n",
      "\tNumber of idxs: 8480\n",
      "\tWeight: 2222.37\n",
      "Label: alveolar hemorrhage\n",
      "\tNumber of idxs: 8389\n",
      "\tWeight: 2214.43\n",
      "Label: multiple masses/nodules\n",
      "\tNumber of idxs: 7411\n",
      "\tWeight: 2124.53\n",
      "Label: diaphragmatic eventration (benign)\n",
      "\tNumber of idxs: 7196\n",
      "\tWeight: 2103.54\n",
      "Label: hydropneumothorax\n",
      "\tNumber of idxs: 6501\n",
      "\tWeight: 2032.19\n",
      "Label: rotated\n",
      "\tNumber of idxs: 6231\n",
      "\tWeight: 2002.88\n",
      "Label: breast/nipple shadows\n",
      "\tNumber of idxs: 6005\n",
      "\tWeight: 1977.58\n",
      "Label: cabg grafts\n",
      "\tNumber of idxs: 5306\n",
      "\tWeight: 1894.38\n",
      "Label: cyst/bullae\n",
      "\tNumber of idxs: 4896\n",
      "\tWeight: 1841.59\n",
      "Label: pericardial effusion\n",
      "\tNumber of idxs: 4729\n",
      "\tWeight: 1819.12\n",
      "Label: pneumomediastinum\n",
      "\tNumber of idxs: 4012\n",
      "\tWeight: 1715.12\n",
      "Label: goiter\n",
      "\tNumber of idxs: 3945\n",
      "\tWeight: 1704.70\n",
      "Label: skin fold\n",
      "\tNumber of idxs: 2048\n",
      "\tWeight: 1331.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: \"omitted\"\n",
      "\tNumber of idxs: 372746\n",
      "\tWeight: 6339.671293242993\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_145_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9420.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_122122_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_145_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9420.pt\n",
      "Skip loading parameter: chest_imagenome_classifier.weight, required shape: torch.Size([74, 128]), loaded shape: torch.Size([228, 128])\n",
      "Skip loading parameter: chest_imagenome_classifier.bias, required shape: torch.Size([74]), loaded shape: torch.Size([228])\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.42969, triplet_loss 0.43779, c_loss 0.13178, hs_loss 0.26835, cs_loss 0.64211, cacc 0.94752, hsacc 0.89332, csacc 0.74672, chstimgn_loss 2.11938, chestimg_macro_f1 0.05341, 192.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95200, tacc(al2) 0.79000, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.87100, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 5.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9060.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.42900, triplet_loss 0.43992, c_loss 0.13001, hs_loss 0.27107, cs_loss 0.64370, cacc 0.94812, hsacc 0.89876, csacc 0.74772, chstimgn_loss 2.11566, chestimg_macro_f1 0.05297, 181.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.79000, tacc(ob0) 0.99700, tacc(ob1) 0.98200, tacc(ob2) 0.86600, tacc(ob3) 0.99000, tacc(ob4) 0.95200, 5.65 secs\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 1.41371, triplet_loss 0.44445, c_loss 0.13030, hs_loss 0.25924, cs_loss 0.64234, cacc 0.94700, hsacc 0.90060, csacc 0.75028, chstimgn_loss 2.08926, chestimg_macro_f1 0.05334, 186.76 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.78900, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.86100, tacc(ob3) 0.99100, tacc(ob4) 0.95400, 5.62 secs\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.41311, triplet_loss 0.51258, c_loss 0.18663, hs_loss 0.34780, cs_loss 0.79924, cacc 0.93684, hsacc 0.88044, csacc 0.71372, chstimgn_loss 1.90309, chestimg_macro_f1 0.02149, 188.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97500, tacc(al1) 0.92200, tacc(al2) 0.74800, tacc(ob0) 0.97800, tacc(ob1) 0.96000, tacc(ob2) 0.82600, tacc(ob3) 0.98100, tacc(ob4) 0.91500, 5.52 secs\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000112) ...\n",
      "loss 1.40265, triplet_loss 0.54991, c_loss 0.18566, hs_loss 0.33872, cs_loss 0.80816, cacc 0.94356, hsacc 0.89064, csacc 0.72024, chstimgn_loss 1.86408, chestimg_macro_f1 0.00089, 189.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97500, tacc(al1) 0.93100, tacc(al2) 0.75200, tacc(ob0) 0.98500, tacc(ob1) 0.96300, tacc(ob2) 0.83500, tacc(ob3) 0.98700, tacc(ob4) 0.91900, 5.64 secs\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 1.41248, triplet_loss 0.55034, c_loss 0.16919, hs_loss 0.32721, cs_loss 0.78551, cacc 0.94636, hsacc 0.89128, csacc 0.72512, chstimgn_loss 1.90884, chestimg_macro_f1 0.00018, 190.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97800, tacc(al1) 0.93000, tacc(al2) 0.74300, tacc(ob0) 0.98200, tacc(ob1) 0.95900, tacc(ob2) 0.83700, tacc(ob3) 0.98700, tacc(ob4) 0.91800, 5.69 secs\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 1.41138, triplet_loss 0.54803, c_loss 0.17274, hs_loss 0.31887, cs_loss 0.75605, cacc 0.94948, hsacc 0.89456, csacc 0.73220, chstimgn_loss 1.92490, chestimg_macro_f1 0.00055, 191.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97700, tacc(al1) 0.92700, tacc(al2) 0.75200, tacc(ob0) 0.98500, tacc(ob1) 0.95700, tacc(ob2) 0.84100, tacc(ob3) 0.98700, tacc(ob4) 0.91800, 5.64 secs\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 1.40557, triplet_loss 0.54546, c_loss 0.18003, hs_loss 0.30827, cs_loss 0.72703, cacc 0.94632, hsacc 0.89460, csacc 0.74408, chstimgn_loss 1.93075, chestimg_macro_f1 0.00026, 190.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97500, tacc(al1) 0.93500, tacc(al2) 0.75700, tacc(ob0) 0.98700, tacc(ob1) 0.95500, tacc(ob2) 0.84100, tacc(ob3) 0.98800, tacc(ob4) 0.92100, 5.56 secs\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.40210, triplet_loss 0.54497, c_loss 0.17784, hs_loss 0.29860, cs_loss 0.72773, cacc 0.94668, hsacc 0.89808, csacc 0.74228, chstimgn_loss 1.92963, chestimg_macro_f1 0.00028, 189.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97600, tacc(al1) 0.93200, tacc(al2) 0.75900, tacc(ob0) 0.98600, tacc(ob1) 0.95800, tacc(ob2) 0.84300, tacc(ob3) 0.98600, tacc(ob4) 0.91900, 5.66 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.40015, triplet_loss 0.54386, c_loss 0.16990, hs_loss 0.30446, cs_loss 0.71508, cacc 0.94840, hsacc 0.89476, csacc 0.74612, chstimgn_loss 1.93366, chestimg_macro_f1 0.00041, 192.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97600, tacc(al1) 0.93600, tacc(al2) 0.75900, tacc(ob0) 0.98600, tacc(ob1) 0.95500, tacc(ob2) 0.83600, tacc(ob3) 0.98700, tacc(ob4) 0.92000, 5.62 secs\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.39248, triplet_loss 0.54404, c_loss 0.15764, hs_loss 0.29477, cs_loss 0.70803, cacc 0.94656, hsacc 0.89916, csacc 0.74704, chstimgn_loss 1.93273, chestimg_macro_f1 0.00033, 163.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97600, tacc(al1) 0.93400, tacc(al2) 0.75900, tacc(ob0) 0.98500, tacc(ob1) 0.95400, tacc(ob2) 0.84100, tacc(ob3) 0.99000, tacc(ob4) 0.92100, 5.57 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.39666, triplet_loss 0.54172, c_loss 0.16886, hs_loss 0.29923, cs_loss 0.71017, cacc 0.94688, hsacc 0.90004, csacc 0.74924, chstimgn_loss 1.93334, chestimg_macro_f1 0.00065, 189.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97600, tacc(al1) 0.93500, tacc(al2) 0.75700, tacc(ob0) 0.98600, tacc(ob1) 0.95700, tacc(ob2) 0.83900, tacc(ob3) 0.98900, tacc(ob4) 0.92000, 5.65 secs\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.43216, triplet_loss 0.54641, c_loss 0.18581, hs_loss 0.33117, cs_loss 0.78873, cacc 0.94124, hsacc 0.88688, csacc 0.71780, chstimgn_loss 1.93826, chestimg_macro_f1 0.00070, 186.13 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93500, tacc(al2) 0.78100, tacc(ob0) 0.98300, tacc(ob1) 0.97000, tacc(ob2) 0.85100, tacc(ob3) 0.97700, tacc(ob4) 0.92300, 5.66 secs\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 1.40230, triplet_loss 0.53754, c_loss 0.17560, hs_loss 0.31716, cs_loss 0.76357, cacc 0.94152, hsacc 0.88412, csacc 0.72244, chstimgn_loss 1.90766, chestimg_macro_f1 0.00196, 180.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97700, tacc(al1) 0.94200, tacc(al2) 0.77600, tacc(ob0) 0.97900, tacc(ob1) 0.96100, tacc(ob2) 0.86300, tacc(ob3) 0.98300, tacc(ob4) 0.93000, 5.68 secs\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 1.36818, triplet_loss 0.52899, c_loss 0.16691, hs_loss 0.29441, cs_loss 0.72383, cacc 0.94480, hsacc 0.89592, csacc 0.73204, chstimgn_loss 1.87930, chestimg_macro_f1 0.00313, 166.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97700, tacc(al1) 0.94200, tacc(al2) 0.78200, tacc(ob0) 0.98500, tacc(ob1) 0.96800, tacc(ob2) 0.85300, tacc(ob3) 0.98300, tacc(ob4) 0.93200, 5.63 secs\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 1.34673, triplet_loss 0.52586, c_loss 0.14652, hs_loss 0.28788, cs_loss 0.70063, cacc 0.94528, hsacc 0.89404, csacc 0.74172, chstimgn_loss 1.86302, chestimg_macro_f1 0.00447, 189.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98000, tacc(al1) 0.93900, tacc(al2) 0.78500, tacc(ob0) 0.98600, tacc(ob1) 0.96400, tacc(ob2) 0.86200, tacc(ob3) 0.98300, tacc(ob4) 0.93400, 5.65 secs\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.33677, triplet_loss 0.52627, c_loss 0.14496, hs_loss 0.28785, cs_loss 0.68426, cacc 0.94780, hsacc 0.89644, csacc 0.74388, chstimgn_loss 1.85187, chestimg_macro_f1 0.00500, 188.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94000, tacc(al2) 0.77700, tacc(ob0) 0.98700, tacc(ob1) 0.96600, tacc(ob2) 0.86800, tacc(ob3) 0.98400, tacc(ob4) 0.93400, 5.59 secs\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.33489, triplet_loss 0.52295, c_loss 0.14390, hs_loss 0.27634, cs_loss 0.69501, cacc 0.94720, hsacc 0.89700, csacc 0.74312, chstimgn_loss 1.85068, chestimg_macro_f1 0.00552, 189.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94000, tacc(al2) 0.77500, tacc(ob0) 0.98800, tacc(ob1) 0.96600, tacc(ob2) 0.87000, tacc(ob3) 0.98400, tacc(ob4) 0.93300, 5.67 secs\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.33647, triplet_loss 0.52372, c_loss 0.14649, hs_loss 0.28721, cs_loss 0.69492, cacc 0.94928, hsacc 0.89836, csacc 0.73996, chstimgn_loss 1.84677, chestimg_macro_f1 0.00648, 187.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94200, tacc(al2) 0.77700, tacc(ob0) 0.98800, tacc(ob1) 0.96600, tacc(ob2) 0.86900, tacc(ob3) 0.98500, tacc(ob4) 0.93600, 5.67 secs\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.33864, triplet_loss 0.52404, c_loss 0.15520, hs_loss 0.29387, cs_loss 0.68544, cacc 0.94680, hsacc 0.89688, csacc 0.74472, chstimgn_loss 1.84800, chestimg_macro_f1 0.00635, 182.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94100, tacc(al2) 0.77300, tacc(ob0) 0.98800, tacc(ob1) 0.96600, tacc(ob2) 0.86900, tacc(ob3) 0.98300, tacc(ob4) 0.93500, 5.63 secs\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.37567, triplet_loss 0.52927, c_loss 0.20258, hs_loss 0.33973, cs_loss 0.78937, cacc 0.93228, hsacc 0.87632, csacc 0.71100, chstimgn_loss 1.82087, chestimg_macro_f1 0.01963, 184.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93900, tacc(al2) 0.77500, tacc(ob0) 0.98400, tacc(ob1) 0.96700, tacc(ob2) 0.87900, tacc(ob3) 0.98300, tacc(ob4) 0.94400, 5.61 secs\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 1.32071, triplet_loss 0.51897, c_loss 0.18052, hs_loss 0.31182, cs_loss 0.76769, cacc 0.93380, hsacc 0.88424, csacc 0.71412, chstimgn_loss 1.75192, chestimg_macro_f1 0.04906, 187.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93900, tacc(al2) 0.78100, tacc(ob0) 0.98700, tacc(ob1) 0.96600, tacc(ob2) 0.87900, tacc(ob3) 0.98000, tacc(ob4) 0.94700, 5.64 secs\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 1.27955, triplet_loss 0.51574, c_loss 0.15705, hs_loss 0.30576, cs_loss 0.72156, cacc 0.94140, hsacc 0.88824, csacc 0.72856, chstimgn_loss 1.70904, chestimg_macro_f1 0.07266, 189.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93400, tacc(al2) 0.79100, tacc(ob0) 0.99100, tacc(ob1) 0.97200, tacc(ob2) 0.88700, tacc(ob3) 0.98400, tacc(ob4) 0.94900, 5.62 secs\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 1.25603, triplet_loss 0.51018, c_loss 0.14836, hs_loss 0.28428, cs_loss 0.69977, cacc 0.94440, hsacc 0.89448, csacc 0.73476, chstimgn_loss 1.69075, chestimg_macro_f1 0.07286, 188.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94200, tacc(al2) 0.78200, tacc(ob0) 0.99200, tacc(ob1) 0.97300, tacc(ob2) 0.88200, tacc(ob3) 0.98400, tacc(ob4) 0.94600, 5.65 secs\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.24613, triplet_loss 0.50935, c_loss 0.15940, hs_loss 0.27427, cs_loss 0.68736, cacc 0.94040, hsacc 0.89648, csacc 0.73960, chstimgn_loss 1.67707, chestimg_macro_f1 0.08017, 184.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93600, tacc(al2) 0.77700, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.88000, tacc(ob3) 0.98200, tacc(ob4) 0.95100, 5.68 secs\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.25292, triplet_loss 0.51017, c_loss 0.16189, hs_loss 0.29680, cs_loss 0.69495, cacc 0.94308, hsacc 0.89264, csacc 0.73520, chstimgn_loss 1.67393, chestimg_macro_f1 0.08307, 184.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94500, tacc(al2) 0.78100, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.88400, tacc(ob3) 0.98300, tacc(ob4) 0.95200, 5.63 secs\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.24430, triplet_loss 0.51082, c_loss 0.15674, hs_loss 0.28290, cs_loss 0.68363, cacc 0.94456, hsacc 0.89720, csacc 0.73956, chstimgn_loss 1.67155, chestimg_macro_f1 0.08421, 185.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94500, tacc(al2) 0.78400, tacc(ob0) 0.99200, tacc(ob1) 0.97100, tacc(ob2) 0.88300, tacc(ob3) 0.98300, tacc(ob4) 0.95200, 5.66 secs\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.24393, triplet_loss 0.50921, c_loss 0.15657, hs_loss 0.28458, cs_loss 0.68302, cacc 0.94536, hsacc 0.89680, csacc 0.74068, chstimgn_loss 1.67116, chestimg_macro_f1 0.08316, 187.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94500, tacc(al2) 0.78600, tacc(ob0) 0.99200, tacc(ob1) 0.97200, tacc(ob2) 0.88000, tacc(ob3) 0.98400, tacc(ob4) 0.95200, 5.59 secs\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.25235, triplet_loss 0.51248, c_loss 0.16081, hs_loss 0.30872, cs_loss 0.75892, cacc 0.93860, hsacc 0.88120, csacc 0.71624, chstimgn_loss 1.63424, chestimg_macro_f1 0.09299, 187.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.92200, tacc(al2) 0.80800, tacc(ob0) 0.99100, tacc(ob1) 0.97400, tacc(ob2) 0.86700, tacc(ob3) 0.98200, tacc(ob4) 0.94000, 5.65 secs\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 1.21054, triplet_loss 0.50562, c_loss 0.16067, hs_loss 0.31277, cs_loss 0.74071, cacc 0.93652, hsacc 0.88300, csacc 0.72104, chstimgn_loss 1.56119, chestimg_macro_f1 0.11639, 184.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93300, tacc(al2) 0.78500, tacc(ob0) 0.99600, tacc(ob1) 0.96900, tacc(ob2) 0.87800, tacc(ob3) 0.98300, tacc(ob4) 0.94900, 5.65 secs\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 1.18515, triplet_loss 0.50219, c_loss 0.17373, hs_loss 0.30196, cs_loss 0.72636, cacc 0.93752, hsacc 0.88808, csacc 0.72608, chstimgn_loss 1.51817, chestimg_macro_f1 0.13413, 186.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97900, tacc(al1) 0.94000, tacc(al2) 0.79100, tacc(ob0) 0.99700, tacc(ob1) 0.97000, tacc(ob2) 0.88100, tacc(ob3) 0.98300, tacc(ob4) 0.95900, 5.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_31_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9060.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 1.16068, triplet_loss 0.50268, c_loss 0.16478, hs_loss 0.29017, cs_loss 0.69126, cacc 0.94228, hsacc 0.89132, csacc 0.73596, chstimgn_loss 1.49692, chestimg_macro_f1 0.13746, 185.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.94200, tacc(al2) 0.79600, tacc(ob0) 0.99700, tacc(ob1) 0.97100, tacc(ob2) 0.88100, tacc(ob3) 0.98400, tacc(ob4) 0.95600, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9073.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.15243, triplet_loss 0.50084, c_loss 0.14116, hs_loss 0.29376, cs_loss 0.69374, cacc 0.94356, hsacc 0.89252, csacc 0.73728, chstimgn_loss 1.49011, chestimg_macro_f1 0.14025, 186.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98100, tacc(al1) 0.94200, tacc(al2) 0.78600, tacc(ob0) 0.99800, tacc(ob1) 0.97300, tacc(ob2) 0.87600, tacc(ob3) 0.98500, tacc(ob4) 0.95400, 5.65 secs\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.14611, triplet_loss 0.49989, c_loss 0.16075, hs_loss 0.27971, cs_loss 0.68372, cacc 0.94084, hsacc 0.89276, csacc 0.74008, chstimgn_loss 1.48017, chestimg_macro_f1 0.14531, 188.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98000, tacc(al1) 0.94300, tacc(al2) 0.79000, tacc(ob0) 0.99700, tacc(ob1) 0.97200, tacc(ob2) 0.88100, tacc(ob3) 0.98500, tacc(ob4) 0.95500, 5.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_34_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9074.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.14467, triplet_loss 0.49871, c_loss 0.15050, hs_loss 0.28674, cs_loss 0.68522, cacc 0.94572, hsacc 0.89884, csacc 0.73816, chstimgn_loss 1.47876, chestimg_macro_f1 0.14571, 189.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98100, tacc(al1) 0.94200, tacc(al2) 0.79200, tacc(ob0) 0.99700, tacc(ob1) 0.97200, tacc(ob2) 0.87900, tacc(ob3) 0.98600, tacc(ob4) 0.95600, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9078.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.14252, triplet_loss 0.49779, c_loss 0.14724, hs_loss 0.28827, cs_loss 0.68616, cacc 0.94220, hsacc 0.89360, csacc 0.74068, chstimgn_loss 1.47531, chestimg_macro_f1 0.14670, 185.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98100, tacc(al1) 0.94200, tacc(al2) 0.79100, tacc(ob0) 0.99700, tacc(ob1) 0.97200, tacc(ob2) 0.88000, tacc(ob3) 0.98600, tacc(ob4) 0.95400, 5.63 secs\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.16810, triplet_loss 0.50185, c_loss 0.17686, hs_loss 0.33088, cs_loss 0.75811, cacc 0.93580, hsacc 0.87864, csacc 0.71412, chstimgn_loss 1.45235, chestimg_macro_f1 0.14792, 189.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94000, tacc(al2) 0.79300, tacc(ob0) 0.99700, tacc(ob1) 0.97800, tacc(ob2) 0.87700, tacc(ob3) 0.98000, tacc(ob4) 0.94700, 5.64 secs\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 1.12436, triplet_loss 0.49598, c_loss 0.16330, hs_loss 0.31278, cs_loss 0.75569, cacc 0.93500, hsacc 0.88160, csacc 0.71328, chstimgn_loss 1.38485, chestimg_macro_f1 0.16387, 188.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93700, tacc(al2) 0.79500, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.88100, tacc(ob3) 0.98100, tacc(ob4) 0.95400, 5.66 secs\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 1.09565, triplet_loss 0.49766, c_loss 0.15537, hs_loss 0.30576, cs_loss 0.72844, cacc 0.94032, hsacc 0.89136, csacc 0.72708, chstimgn_loss 1.34768, chestimg_macro_f1 0.17718, 189.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.93900, tacc(al2) 0.79300, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.89300, tacc(ob3) 0.98200, tacc(ob4) 0.95700, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9098.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 1.07700, triplet_loss 0.49532, c_loss 0.16237, hs_loss 0.30352, cs_loss 0.69010, cacc 0.93796, hsacc 0.88976, csacc 0.73640, chstimgn_loss 1.32835, chestimg_macro_f1 0.18115, 187.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93400, tacc(al2) 0.79500, tacc(ob0) 0.99500, tacc(ob1) 0.97600, tacc(ob2) 0.88600, tacc(ob3) 0.98200, tacc(ob4) 0.95800, 5.62 secs\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.06597, triplet_loss 0.49349, c_loss 0.15436, hs_loss 0.29914, cs_loss 0.68028, cacc 0.94348, hsacc 0.89088, csacc 0.74160, chstimgn_loss 1.31830, chestimg_macro_f1 0.18436, 186.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93600, tacc(al2) 0.80100, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.88200, tacc(ob3) 0.98200, tacc(ob4) 0.96100, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_41_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9113.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.05674, triplet_loss 0.49392, c_loss 0.14818, hs_loss 0.28443, cs_loss 0.67629, cacc 0.94100, hsacc 0.89488, csacc 0.74024, chstimgn_loss 1.31206, chestimg_macro_f1 0.18432, 189.19 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93700, tacc(al2) 0.79800, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.88200, tacc(ob3) 0.98400, tacc(ob4) 0.95700, 5.67 secs\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.05551, triplet_loss 0.49282, c_loss 0.13775, hs_loss 0.28578, cs_loss 0.68073, cacc 0.94324, hsacc 0.89064, csacc 0.73584, chstimgn_loss 1.31247, chestimg_macro_f1 0.18618, 188.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93500, tacc(al2) 0.79800, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.88500, tacc(ob3) 0.98400, tacc(ob4) 0.95800, 5.64 secs\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.06209, triplet_loss 0.49367, c_loss 0.16165, hs_loss 0.28247, cs_loss 0.68854, cacc 0.94168, hsacc 0.89708, csacc 0.73764, chstimgn_loss 1.31101, chestimg_macro_f1 0.18744, 187.51 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.93500, tacc(al2) 0.79600, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.88600, tacc(ob3) 0.98400, tacc(ob4) 0.95800, 5.65 secs\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.09614, triplet_loss 0.49498, c_loss 0.17353, hs_loss 0.34176, cs_loss 0.77222, cacc 0.93636, hsacc 0.87696, csacc 0.70704, chstimgn_loss 1.30103, chestimg_macro_f1 0.18638, 186.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.93500, tacc(al2) 0.79700, tacc(ob0) 0.99300, tacc(ob1) 0.97100, tacc(ob2) 0.89900, tacc(ob3) 0.98200, tacc(ob4) 0.94600, 5.65 secs\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 1.05346, triplet_loss 0.49467, c_loss 0.18105, hs_loss 0.31797, cs_loss 0.74214, cacc 0.93692, hsacc 0.88272, csacc 0.71708, chstimgn_loss 1.23901, chestimg_macro_f1 0.21284, 183.88 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.98600, tacc(al1) 0.94400, tacc(al2) 0.79500, tacc(ob0) 0.99400, tacc(ob1) 0.97800, tacc(ob2) 0.88800, tacc(ob3) 0.98700, tacc(ob4) 0.94500, 5.66 secs\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 1.02693, triplet_loss 0.49367, c_loss 0.17204, hs_loss 0.29569, cs_loss 0.72257, cacc 0.93788, hsacc 0.88816, csacc 0.72884, chstimgn_loss 1.21188, chestimg_macro_f1 0.22821, 189.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94200, tacc(al2) 0.79700, tacc(ob0) 0.99700, tacc(ob1) 0.97900, tacc(ob2) 0.89300, tacc(ob3) 0.98500, tacc(ob4) 0.94300, 5.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_47_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9123.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 1.00611, triplet_loss 0.49018, c_loss 0.16011, hs_loss 0.30198, cs_loss 0.69501, cacc 0.94316, hsacc 0.88660, csacc 0.73668, chstimgn_loss 1.18857, chestimg_macro_f1 0.24018, 189.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.93700, tacc(al2) 0.79600, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.89300, tacc(ob3) 0.98800, tacc(ob4) 0.94700, 5.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_48_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9133.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.99398, triplet_loss 0.49026, c_loss 0.15318, hs_loss 0.28461, cs_loss 0.68858, cacc 0.94176, hsacc 0.89456, csacc 0.73944, chstimgn_loss 1.17964, chestimg_macro_f1 0.24122, 189.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93700, tacc(al2) 0.80000, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.89200, tacc(ob3) 0.98700, tacc(ob4) 0.94900, 5.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9137.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.98784, triplet_loss 0.48971, c_loss 0.15268, hs_loss 0.27939, cs_loss 0.68249, cacc 0.94340, hsacc 0.89540, csacc 0.74064, chstimgn_loss 1.17354, chestimg_macro_f1 0.24955, 186.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.93700, tacc(al2) 0.80300, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.89200, tacc(ob3) 0.98600, tacc(ob4) 0.94900, 5.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_50_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9145.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.99062, triplet_loss 0.48851, c_loss 0.15768, hs_loss 0.27980, cs_loss 0.67691, cacc 0.94220, hsacc 0.89460, csacc 0.74140, chstimgn_loss 1.17979, chestimg_macro_f1 0.24660, 186.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.93600, tacc(al2) 0.79900, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.89100, tacc(ob3) 0.98600, tacc(ob4) 0.95000, 5.64 secs\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.99221, triplet_loss 0.49088, c_loss 0.14944, hs_loss 0.28636, cs_loss 0.68708, cacc 0.94292, hsacc 0.89308, csacc 0.73748, chstimgn_loss 1.17753, chestimg_macro_f1 0.24525, 186.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.93700, tacc(al2) 0.80000, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.89100, tacc(ob3) 0.98700, tacc(ob4) 0.94800, 5.65 secs\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.02701, triplet_loss 0.49500, c_loss 0.17139, hs_loss 0.33507, cs_loss 0.77224, cacc 0.93172, hsacc 0.87584, csacc 0.71052, chstimgn_loss 1.16716, chestimg_macro_f1 0.25760, 190.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.93900, tacc(al2) 0.78000, tacc(ob0) 0.99500, tacc(ob1) 0.97500, tacc(ob2) 0.89100, tacc(ob3) 0.98000, tacc(ob4) 0.95800, 5.62 secs\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.98976, triplet_loss 0.48975, c_loss 0.15912, hs_loss 0.30902, cs_loss 0.74889, cacc 0.93744, hsacc 0.88576, csacc 0.71676, chstimgn_loss 1.12613, chestimg_macro_f1 0.29585, 183.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.79100, tacc(ob0) 0.99600, tacc(ob1) 0.97900, tacc(ob2) 0.89400, tacc(ob3) 0.98300, tacc(ob4) 0.95900, 5.85 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_54_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9180.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.95986, triplet_loss 0.48677, c_loss 0.15132, hs_loss 0.29566, cs_loss 0.71390, cacc 0.94104, hsacc 0.88768, csacc 0.72940, chstimgn_loss 1.09590, chestimg_macro_f1 0.31890, 188.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95000, tacc(al2) 0.79200, tacc(ob0) 0.99600, tacc(ob1) 0.98000, tacc(ob2) 0.88300, tacc(ob3) 0.98600, tacc(ob4) 0.95500, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_55_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9192.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.94418, triplet_loss 0.48638, c_loss 0.15043, hs_loss 0.29032, cs_loss 0.69297, cacc 0.94264, hsacc 0.89176, csacc 0.73260, chstimgn_loss 1.07831, chestimg_macro_f1 0.33793, 189.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94700, tacc(al2) 0.79300, tacc(ob0) 0.99600, tacc(ob1) 0.98200, tacc(ob2) 0.89500, tacc(ob3) 0.98500, tacc(ob4) 0.95600, 5.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_56_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9205.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.93875, triplet_loss 0.48745, c_loss 0.14084, hs_loss 0.29210, cs_loss 0.68886, cacc 0.94404, hsacc 0.89168, csacc 0.73484, chstimgn_loss 1.07287, chestimg_macro_f1 0.34389, 188.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94700, tacc(al2) 0.79700, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.89600, tacc(ob3) 0.98300, tacc(ob4) 0.96000, 5.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_57_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9215.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.93849, triplet_loss 0.48552, c_loss 0.14418, hs_loss 0.30111, cs_loss 0.67973, cacc 0.94312, hsacc 0.89008, csacc 0.74220, chstimgn_loss 1.07171, chestimg_macro_f1 0.34743, 189.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94500, tacc(al2) 0.79800, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.89600, tacc(ob3) 0.98400, tacc(ob4) 0.96100, 5.67 secs\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.92998, triplet_loss 0.48512, c_loss 0.14534, hs_loss 0.28689, cs_loss 0.67244, cacc 0.94380, hsacc 0.89392, csacc 0.74684, chstimgn_loss 1.06506, chestimg_macro_f1 0.35054, 188.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94600, tacc(al2) 0.79600, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.89400, tacc(ob3) 0.98300, tacc(ob4) 0.96200, 5.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_59_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9216.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.93708, triplet_loss 0.48563, c_loss 0.15873, hs_loss 0.28589, cs_loss 0.68813, cacc 0.94332, hsacc 0.89416, csacc 0.73568, chstimgn_loss 1.06498, chestimg_macro_f1 0.35309, 187.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94600, tacc(al2) 0.79300, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.89600, tacc(ob3) 0.98300, tacc(ob4) 0.96200, 5.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_60_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9216.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230723_122122_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 60 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--integrated_chest_imagenome_labels_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl\" \\\n",
    "--n_chest_imagenome_labels 74 \\\n",
    "--triplets_weight 1.0 \\\n",
    "--metadata_classification_weight 1.0 \\\n",
    "--chest_imagenome_classification_weight 2.0 \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46102116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 120\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 100\n",
      "   checkpoint_folder: models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   huggingface_model_name: None\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_labels: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: None\n",
      "   iters_to_accumulate: 1\n",
      "   override_lr: False\n",
      "   triplets_filepath: None\n",
      "   triplet_rule_weights: None\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrases_jsonl_filepaths: None\n",
      "   integrated_chest_imagenome_labels_filepath: None\n",
      "   dataset_name: None\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 1.0\n",
      "   chest_imagenome_classification_weight: 1.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome: True\n",
      "  n_chest_imagenome_labels: 74\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "1e-06 3 0.0002 8 2e-06 0.0002 8 2e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2286627,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880494\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2868295\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 2001430\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769449\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762709\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2217029\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2473084\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429094\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding train metadata classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: generalized edematous findings\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: reappeared\n",
      "\u001b[1mExample fact: Severe collapse of the lower left lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: The calcified nodule in the middle of the right lung remains unchanged in its appearance\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: multiple infiltrates with a predominant involvement of the pleura\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: probability of aspiration\u001b[0m\n",
      "Category: disease\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: dialysis catheter tip has not shifted\u001b[0m\n",
      "Category: tubes and lines\n",
      "Health status: normal\n",
      "Comparison status: resolved\n",
      "\u001b[1mExample fact: The position of the tip is more central than that\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: unknown\n",
      "Comparison status: position changed\n",
      "\u001b[1mExample fact: There has been a decrease in the overall severity of mild pulmonary edema\u001b[0m\n",
      "Category: disease\n",
      "Health status: abnormal\n",
      "Comparison status: decrease\n",
      "\u001b[1mExample fact: Revealing better findings than the previous test\u001b[0m\n",
      "Category: other\n",
      "Health status: other\n",
      "Comparison status: improved\n",
      "\u001b[1mExample fact: implanted pacemaker identified\u001b[0m\n",
      "Category: device\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding train chest imagenome labels classification dataset and dataloader...\u001b[0m\n",
      "Loading chest integrated chest imagenome labels from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl...\n",
      "len(phrases): 2552490\n",
      "len(label_names): 74\n",
      "labels.shape: (2552490, 74)\n",
      "Label: lung opacity\n",
      "\tNumber of idxs: 545396\n",
      "\tWeight: 6920.86\n",
      "Label: pleural effusion\n",
      "\tNumber of idxs: 210024\n",
      "\tWeight: 5526.64\n",
      "Label: atelectasis\n",
      "\tNumber of idxs: 157638\n",
      "\tWeight: 5147.48\n",
      "Label: pneumonia\n",
      "\tNumber of idxs: 102321\n",
      "\tWeight: 4609.72\n",
      "Label: lung lesion\n",
      "\tNumber of idxs: 91567\n",
      "\tWeight: 4477.88\n",
      "Label: pulmonary edema/hazy opacity\n",
      "\tNumber of idxs: 90170\n",
      "\tWeight: 4459.83\n",
      "Label: enteric tube\n",
      "\tNumber of idxs: 89660\n",
      "\tWeight: 4453.18\n",
      "Label: consolidation\n",
      "\tNumber of idxs: 86042\n",
      "\tWeight: 4405.10\n",
      "Label: airspace opacity\n",
      "\tNumber of idxs: 74463\n",
      "\tWeight: 4239.13\n",
      "Label: mass/nodule (not otherwise specified)\n",
      "\tNumber of idxs: 71602\n",
      "\tWeight: 4194.87\n",
      "Label: ij line\n",
      "\tNumber of idxs: 71363\n",
      "\tWeight: 4191.11\n",
      "Label: increased reticular markings/ild pattern\n",
      "\tNumber of idxs: 71151\n",
      "\tWeight: 4187.76\n",
      "Label: vascular congestion\n",
      "\tNumber of idxs: 68126\n",
      "\tWeight: 4139.10\n",
      "Label: enlarged cardiac silhouette\n",
      "\tNumber of idxs: 66476\n",
      "\tWeight: 4111.80\n",
      "Label: endotracheal tube\n",
      "\tNumber of idxs: 57767\n",
      "\tWeight: 3957.78\n",
      "Label: pleural/parenchymal scarring\n",
      "\tNumber of idxs: 55741\n",
      "\tWeight: 3919.24\n",
      "Label: infiltration\n",
      "\tNumber of idxs: 53996\n",
      "\tWeight: 3885.12\n",
      "Label: picc\n",
      "\tNumber of idxs: 52338\n",
      "\tWeight: 3851.86\n",
      "Label: cardiac pacer and wires\n",
      "\tNumber of idxs: 51132\n",
      "\tWeight: 3827.12\n",
      "Label: lobar/segmental collapse\n",
      "\tNumber of idxs: 49855\n",
      "\tWeight: 3800.40\n",
      "Label: rib fracture\n",
      "\tNumber of idxs: 48249\n",
      "\tWeight: 3765.99\n",
      "Label: pneumothorax\n",
      "\tNumber of idxs: 47137\n",
      "\tWeight: 3741.61\n",
      "Label: sub-diaphragmatic air\n",
      "\tNumber of idxs: 45808\n",
      "\tWeight: 3711.86\n",
      "Label: artifact\n",
      "\tNumber of idxs: 44545\n",
      "\tWeight: 3682.93\n",
      "Label: mediastinal widening\n",
      "\tNumber of idxs: 43575\n",
      "\tWeight: 3660.25\n",
      "Label: chest tube\n",
      "\tNumber of idxs: 43310\n",
      "\tWeight: 3653.98\n",
      "Label: enlarged hilum\n",
      "\tNumber of idxs: 39792\n",
      "\tWeight: 3567.68\n",
      "Label: hyperaeration\n",
      "\tNumber of idxs: 36155\n",
      "\tWeight: 3471.70\n",
      "Label: linear/patchy atelectasis\n",
      "\tNumber of idxs: 35090\n",
      "\tWeight: 3442.11\n",
      "Label: subcutaneous air\n",
      "\tNumber of idxs: 31502\n",
      "\tWeight: 3336.78\n",
      "Label: vascular calcification\n",
      "\tNumber of idxs: 29081\n",
      "\tWeight: 3260.09\n",
      "Label: low lung volumes\n",
      "\tNumber of idxs: 27898\n",
      "\tWeight: 3220.73\n",
      "Label: subclavian line\n",
      "\tNumber of idxs: 26390\n",
      "\tWeight: 3168.56\n",
      "Label: chest port\n",
      "\tNumber of idxs: 25350\n",
      "\tWeight: 3131.17\n",
      "Label: aspiration\n",
      "\tNumber of idxs: 25239\n",
      "\tWeight: 3127.10\n",
      "Label: spinal fracture\n",
      "\tNumber of idxs: 23897\n",
      "\tWeight: 3076.81\n",
      "Label: spinal degenerative changes\n",
      "\tNumber of idxs: 22873\n",
      "\tWeight: 3036.88\n",
      "Label: costophrenic angle blunting\n",
      "\tNumber of idxs: 21655\n",
      "\tWeight: 2987.49\n",
      "Label: interstitial lung disease\n",
      "\tNumber of idxs: 19411\n",
      "\tWeight: 2890.34\n",
      "Label: mediastinal displacement\n",
      "\tNumber of idxs: 19259\n",
      "\tWeight: 2883.45\n",
      "Label: pigtail catheter\n",
      "\tNumber of idxs: 19083\n",
      "\tWeight: 2875.40\n",
      "Label: swan-ganz catheter\n",
      "\tNumber of idxs: 18702\n",
      "\tWeight: 2857.79\n",
      "Label: bone lesion\n",
      "\tNumber of idxs: 18335\n",
      "\tWeight: 2840.55\n",
      "Label: fluid overload/heart failure\n",
      "\tNumber of idxs: 17658\n",
      "\tWeight: 2808.02\n",
      "Label: aortic graft/repair\n",
      "\tNumber of idxs: 16289\n",
      "\tWeight: 2739.07\n",
      "Label: vascular redistribution\n",
      "\tNumber of idxs: 16287\n",
      "\tWeight: 2738.97\n",
      "Label: elevated hemidiaphragm\n",
      "\tNumber of idxs: 15943\n",
      "\tWeight: 2720.92\n",
      "Label: tortuous aorta\n",
      "\tNumber of idxs: 15726\n",
      "\tWeight: 2709.37\n",
      "Label: copd/emphysema\n",
      "\tNumber of idxs: 13639\n",
      "\tWeight: 2591.37\n",
      "Label: tracheostomy tube\n",
      "\tNumber of idxs: 13575\n",
      "\tWeight: 2587.53\n",
      "Label: superior mediastinal mass/enlargement\n",
      "\tNumber of idxs: 12376\n",
      "\tWeight: 2512.83\n",
      "Label: calcified nodule\n",
      "\tNumber of idxs: 12277\n",
      "\tWeight: 2506.41\n",
      "Label: bronchiectasis\n",
      "\tNumber of idxs: 12016\n",
      "\tWeight: 2489.28\n",
      "Label: mediastinal drain\n",
      "\tNumber of idxs: 11868\n",
      "\tWeight: 2479.45\n",
      "Label: clavicle fracture\n",
      "\tNumber of idxs: 11411\n",
      "\tWeight: 2448.44\n",
      "Label: shoulder osteoarthritis\n",
      "\tNumber of idxs: 10526\n",
      "\tWeight: 2385.52\n",
      "Label: hernia\n",
      "\tNumber of idxs: 10022\n",
      "\tWeight: 2347.80\n",
      "Label: scoliosis\n",
      "\tNumber of idxs: 9382\n",
      "\tWeight: 2297.71\n",
      "Label: granulomatous disease\n",
      "\tNumber of idxs: 9099\n",
      "\tWeight: 2274.71\n",
      "Label: prosthetic valve\n",
      "\tNumber of idxs: 8946\n",
      "\tWeight: 2262.03\n",
      "Label: intra-aortic balloon pump\n",
      "\tNumber of idxs: 8936\n",
      "\tWeight: 2261.20\n",
      "Label: lung cancer\n",
      "\tNumber of idxs: 8480\n",
      "\tWeight: 2222.37\n",
      "Label: alveolar hemorrhage\n",
      "\tNumber of idxs: 8389\n",
      "\tWeight: 2214.43\n",
      "Label: multiple masses/nodules\n",
      "\tNumber of idxs: 7411\n",
      "\tWeight: 2124.53\n",
      "Label: diaphragmatic eventration (benign)\n",
      "\tNumber of idxs: 7196\n",
      "\tWeight: 2103.54\n",
      "Label: hydropneumothorax\n",
      "\tNumber of idxs: 6501\n",
      "\tWeight: 2032.19\n",
      "Label: rotated\n",
      "\tNumber of idxs: 6231\n",
      "\tWeight: 2002.88\n",
      "Label: breast/nipple shadows\n",
      "\tNumber of idxs: 6005\n",
      "\tWeight: 1977.58\n",
      "Label: cabg grafts\n",
      "\tNumber of idxs: 5306\n",
      "\tWeight: 1894.38\n",
      "Label: cyst/bullae\n",
      "\tNumber of idxs: 4896\n",
      "\tWeight: 1841.59\n",
      "Label: pericardial effusion\n",
      "\tNumber of idxs: 4729\n",
      "\tWeight: 1819.12\n",
      "Label: pneumomediastinum\n",
      "\tNumber of idxs: 4012\n",
      "\tWeight: 1715.12\n",
      "Label: goiter\n",
      "\tNumber of idxs: 3945\n",
      "\tWeight: 1704.70\n",
      "Label: skin fold\n",
      "\tNumber of idxs: 2048\n",
      "\tWeight: 1331.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: \"omitted\"\n",
      "\tNumber of idxs: 372746\n",
      "\tWeight: 6339.671293242993\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_180_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9534.pt', 'checkpoint_60_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9216.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_180_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9534.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 181/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.66680, triplet_loss 0.47566, c_loss 0.15155, hs_loss 0.30116, cs_loss 0.71707, cacc 0.94104, hsacc 0.88672, csacc 0.72616, chstimgn_loss 0.51089, chestimg_macro_f1 0.86219, 189.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.93400, tacc(al2) 0.79400, tacc(ob0) 0.99600, tacc(ob1) 0.98100, tacc(ob2) 0.89800, tacc(ob3) 0.98500, tacc(ob4) 0.96100, 5.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_181_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9461.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 182/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.65396, triplet_loss 0.47477, c_loss 0.14489, hs_loss 0.30787, cs_loss 0.69514, cacc 0.94352, hsacc 0.88480, csacc 0.73360, chstimgn_loss 0.49658, chestimg_macro_f1 0.86804, 187.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.93700, tacc(al2) 0.81000, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.89500, tacc(ob3) 0.98500, tacc(ob4) 0.95700, 5.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_182_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9472.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 183/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.63190, triplet_loss 0.47528, c_loss 0.14209, hs_loss 0.27656, cs_loss 0.66734, cacc 0.94548, hsacc 0.89388, csacc 0.74448, chstimgn_loss 0.48316, chestimg_macro_f1 0.87643, 187.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.81300, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.89900, tacc(ob3) 0.98800, tacc(ob4) 0.96600, 5.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_183_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9523.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 184/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.62274, triplet_loss 0.47343, c_loss 0.14133, hs_loss 0.27135, cs_loss 0.64884, cacc 0.94656, hsacc 0.90132, csacc 0.75196, chstimgn_loss 0.47800, chestimg_macro_f1 0.87655, 183.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94700, tacc(al2) 0.80700, tacc(ob0) 0.99400, tacc(ob1) 0.98400, tacc(ob2) 0.90200, tacc(ob3) 0.98900, tacc(ob4) 0.96200, 5.59 secs\n",
      "\u001b[1m---- Epoch 185/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.61700, triplet_loss 0.47107, c_loss 0.13871, hs_loss 0.26711, cs_loss 0.65244, cacc 0.94628, hsacc 0.89804, csacc 0.74888, chstimgn_loss 0.46933, chestimg_macro_f1 0.88126, 189.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94700, tacc(al2) 0.80500, tacc(ob0) 0.99400, tacc(ob1) 0.98400, tacc(ob2) 0.90200, tacc(ob3) 0.98900, tacc(ob4) 0.96200, 5.63 secs\n",
      "\u001b[1m---- Epoch 186/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.60725, triplet_loss 0.47133, c_loss 0.12069, hs_loss 0.26624, cs_loss 0.64155, cacc 0.94800, hsacc 0.89852, csacc 0.75428, chstimgn_loss 0.46459, chestimg_macro_f1 0.88399, 190.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.80400, tacc(ob0) 0.99400, tacc(ob1) 0.98600, tacc(ob2) 0.90400, tacc(ob3) 0.98900, tacc(ob4) 0.96200, 5.65 secs\n",
      "\u001b[1m---- Epoch 187/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.61111, triplet_loss 0.47195, c_loss 0.13470, hs_loss 0.26286, cs_loss 0.64329, cacc 0.94996, hsacc 0.90020, csacc 0.75320, chstimgn_loss 0.46581, chestimg_macro_f1 0.88469, 189.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.80600, tacc(ob0) 0.99400, tacc(ob1) 0.98600, tacc(ob2) 0.90300, tacc(ob3) 0.99000, tacc(ob4) 0.96200, 5.64 secs\n",
      "\u001b[1m---- Epoch 188/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.60797, triplet_loss 0.47037, c_loss 0.13004, hs_loss 0.26054, cs_loss 0.64020, cacc 0.94864, hsacc 0.90172, csacc 0.75488, chstimgn_loss 0.46537, chestimg_macro_f1 0.88345, 190.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94700, tacc(al2) 0.80700, tacc(ob0) 0.99400, tacc(ob1) 0.98600, tacc(ob2) 0.90300, tacc(ob3) 0.99000, tacc(ob4) 0.96200, 5.57 secs\n",
      "\u001b[1m---- Epoch 189/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.66262, triplet_loss 0.47415, c_loss 0.15373, hs_loss 0.31014, cs_loss 0.71471, cacc 0.94084, hsacc 0.88104, csacc 0.72948, chstimgn_loss 0.49887, chestimg_macro_f1 0.86512, 187.44 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94700, tacc(al2) 0.80200, tacc(ob0) 0.99400, tacc(ob1) 0.97500, tacc(ob2) 0.88200, tacc(ob3) 0.98000, tacc(ob4) 0.96300, 5.69 secs\n",
      "\u001b[1m---- Epoch 190/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.65650, triplet_loss 0.47477, c_loss 0.16346, hs_loss 0.30536, cs_loss 0.70328, cacc 0.93816, hsacc 0.88232, csacc 0.73120, chstimgn_loss 0.48958, chestimg_macro_f1 0.86879, 188.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94100, tacc(al2) 0.80000, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.90000, tacc(ob3) 0.98100, tacc(ob4) 0.96100, 5.67 secs\n",
      "\u001b[1m---- Epoch 191/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.62612, triplet_loss 0.47319, c_loss 0.14120, hs_loss 0.27052, cs_loss 0.67794, cacc 0.94500, hsacc 0.89336, csacc 0.74172, chstimgn_loss 0.47081, chestimg_macro_f1 0.87725, 187.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94600, tacc(al2) 0.79300, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.89700, tacc(ob3) 0.98400, tacc(ob4) 0.96300, 5.65 secs\n",
      "\u001b[1m---- Epoch 192/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.61766, triplet_loss 0.47162, c_loss 0.13963, hs_loss 0.26042, cs_loss 0.66426, cacc 0.94336, hsacc 0.89736, csacc 0.74240, chstimgn_loss 0.46736, chestimg_macro_f1 0.87846, 188.85 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99000, tacc(al1) 0.94700, tacc(al2) 0.80500, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.89200, tacc(ob3) 0.98200, tacc(ob4) 0.96200, 5.52 secs\n",
      "\u001b[1m---- Epoch 193/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.61262, triplet_loss 0.46959, c_loss 0.14755, hs_loss 0.26617, cs_loss 0.65052, cacc 0.94316, hsacc 0.89432, csacc 0.74948, chstimgn_loss 0.45834, chestimg_macro_f1 0.88436, 174.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.80700, tacc(ob0) 0.99500, tacc(ob1) 0.98600, tacc(ob2) 0.89700, tacc(ob3) 0.98500, tacc(ob4) 0.96100, 5.63 secs\n",
      "\u001b[1m---- Epoch 194/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.60282, triplet_loss 0.47053, c_loss 0.12982, hs_loss 0.25811, cs_loss 0.63816, cacc 0.94836, hsacc 0.89760, csacc 0.75460, chstimgn_loss 0.45733, chestimg_macro_f1 0.88517, 185.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94500, tacc(al2) 0.80900, tacc(ob0) 0.99400, tacc(ob1) 0.98600, tacc(ob2) 0.89800, tacc(ob3) 0.98400, tacc(ob4) 0.95900, 5.69 secs\n",
      "\u001b[1m---- Epoch 195/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.61020, triplet_loss 0.47120, c_loss 0.14723, hs_loss 0.25763, cs_loss 0.64500, cacc 0.94656, hsacc 0.90016, csacc 0.75252, chstimgn_loss 0.45987, chestimg_macro_f1 0.88575, 189.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.80900, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.89900, tacc(ob3) 0.98400, tacc(ob4) 0.96000, 5.64 secs\n",
      "\u001b[1m---- Epoch 196/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.61159, triplet_loss 0.46966, c_loss 0.16200, hs_loss 0.26264, cs_loss 0.63949, cacc 0.94708, hsacc 0.90048, csacc 0.75524, chstimgn_loss 0.45628, chestimg_macro_f1 0.88561, 188.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.81000, tacc(ob0) 0.99500, tacc(ob1) 0.98600, tacc(ob2) 0.89900, tacc(ob3) 0.98400, tacc(ob4) 0.96000, 5.64 secs\n",
      "\u001b[1m---- Epoch 197/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.65801, triplet_loss 0.47357, c_loss 0.17044, hs_loss 0.30243, cs_loss 0.71487, cacc 0.93840, hsacc 0.88768, csacc 0.72884, chstimgn_loss 0.48536, chestimg_macro_f1 0.86919, 182.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93800, tacc(al2) 0.80000, tacc(ob0) 0.99600, tacc(ob1) 0.97800, tacc(ob2) 0.89800, tacc(ob3) 0.98300, tacc(ob4) 0.95600, 5.65 secs\n",
      "\u001b[1m---- Epoch 198/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.64571, triplet_loss 0.47396, c_loss 0.15488, hs_loss 0.29427, cs_loss 0.70180, cacc 0.93996, hsacc 0.88400, csacc 0.72964, chstimgn_loss 0.47897, chestimg_macro_f1 0.87175, 193.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94100, tacc(al2) 0.81100, tacc(ob0) 0.99700, tacc(ob1) 0.98200, tacc(ob2) 0.89800, tacc(ob3) 0.98300, tacc(ob4) 0.96500, 5.64 secs\n",
      "\u001b[1m---- Epoch 199/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.61965, triplet_loss 0.47131, c_loss 0.13936, hs_loss 0.28097, cs_loss 0.66716, cacc 0.94616, hsacc 0.89136, csacc 0.74072, chstimgn_loss 0.45991, chestimg_macro_f1 0.88180, 192.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.80200, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.90200, tacc(ob3) 0.98200, tacc(ob4) 0.96300, 5.66 secs\n",
      "\u001b[1m---- Epoch 200/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.60310, triplet_loss 0.47052, c_loss 0.12759, hs_loss 0.26607, cs_loss 0.64497, cacc 0.94860, hsacc 0.89732, csacc 0.75084, chstimgn_loss 0.45161, chestimg_macro_f1 0.88617, 186.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.80300, tacc(ob0) 0.99600, tacc(ob1) 0.98000, tacc(ob2) 0.89800, tacc(ob3) 0.98500, tacc(ob4) 0.95800, 5.67 secs\n",
      "\u001b[1m---- Epoch 201/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.60627, triplet_loss 0.47078, c_loss 0.15172, hs_loss 0.25629, cs_loss 0.64289, cacc 0.94716, hsacc 0.90204, csacc 0.75324, chstimgn_loss 0.45169, chestimg_macro_f1 0.88626, 188.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94400, tacc(al2) 0.80300, tacc(ob0) 0.99800, tacc(ob1) 0.98100, tacc(ob2) 0.89900, tacc(ob3) 0.98400, tacc(ob4) 0.96000, 5.65 secs\n",
      "\u001b[1m---- Epoch 202/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.59953, triplet_loss 0.47048, c_loss 0.14230, hs_loss 0.26818, cs_loss 0.62996, cacc 0.94720, hsacc 0.90128, csacc 0.75644, chstimgn_loss 0.44359, chestimg_macro_f1 0.89020, 185.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94400, tacc(al2) 0.80500, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.90000, tacc(ob3) 0.98500, tacc(ob4) 0.96000, 5.65 secs\n",
      "\u001b[1m---- Epoch 203/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.59904, triplet_loss 0.46890, c_loss 0.13812, hs_loss 0.26855, cs_loss 0.63523, cacc 0.94780, hsacc 0.90072, csacc 0.75768, chstimgn_loss 0.44268, chestimg_macro_f1 0.88806, 183.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94400, tacc(al2) 0.80800, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.90000, tacc(ob3) 0.98400, tacc(ob4) 0.96000, 5.64 secs\n",
      "\u001b[1m---- Epoch 204/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59640, triplet_loss 0.47053, c_loss 0.13969, hs_loss 0.25530, cs_loss 0.63815, cacc 0.94620, hsacc 0.90188, csacc 0.75496, chstimgn_loss 0.44097, chestimg_macro_f1 0.88984, 186.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94400, tacc(al2) 0.80600, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.90100, tacc(ob3) 0.98500, tacc(ob4) 0.96000, 5.65 secs\n",
      "\u001b[1m---- Epoch 205/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.64993, triplet_loss 0.47455, c_loss 0.15987, hs_loss 0.30255, cs_loss 0.71583, cacc 0.93620, hsacc 0.88156, csacc 0.72548, chstimgn_loss 0.47347, chestimg_macro_f1 0.87183, 189.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94000, tacc(al2) 0.79900, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.90700, tacc(ob3) 0.98700, tacc(ob4) 0.95200, 5.64 secs\n",
      "\u001b[1m---- Epoch 206/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.64643, triplet_loss 0.47465, c_loss 0.16779, hs_loss 0.30510, cs_loss 0.71106, cacc 0.93928, hsacc 0.88480, csacc 0.73120, chstimgn_loss 0.46356, chestimg_macro_f1 0.87754, 184.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.93900, tacc(al2) 0.80600, tacc(ob0) 0.99300, tacc(ob1) 0.98400, tacc(ob2) 0.90000, tacc(ob3) 0.98600, tacc(ob4) 0.95800, 5.63 secs\n",
      "\u001b[1m---- Epoch 207/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.61530, triplet_loss 0.47341, c_loss 0.15025, hs_loss 0.27005, cs_loss 0.67226, cacc 0.94304, hsacc 0.89396, csacc 0.74292, chstimgn_loss 0.44761, chestimg_macro_f1 0.88518, 177.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94200, tacc(al2) 0.80400, tacc(ob0) 0.99400, tacc(ob1) 0.98300, tacc(ob2) 0.90200, tacc(ob3) 0.98700, tacc(ob4) 0.96400, 5.74 secs\n",
      "\u001b[1m---- Epoch 208/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.60660, triplet_loss 0.47111, c_loss 0.14764, hs_loss 0.27418, cs_loss 0.65282, cacc 0.94356, hsacc 0.89912, csacc 0.74912, chstimgn_loss 0.44032, chestimg_macro_f1 0.88899, 189.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.80700, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.90000, tacc(ob3) 0.98400, tacc(ob4) 0.96300, 5.62 secs\n",
      "\u001b[1m---- Epoch 209/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.59833, triplet_loss 0.47094, c_loss 0.14066, hs_loss 0.27789, cs_loss 0.63551, cacc 0.94648, hsacc 0.89896, csacc 0.75540, chstimgn_loss 0.43416, chestimg_macro_f1 0.89014, 190.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.80400, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.89700, tacc(ob3) 0.98500, tacc(ob4) 0.96600, 5.64 secs\n",
      "\u001b[1m---- Epoch 210/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.59267, triplet_loss 0.47010, c_loss 0.13105, hs_loss 0.25964, cs_loss 0.64103, cacc 0.94508, hsacc 0.89884, csacc 0.75240, chstimgn_loss 0.43443, chestimg_macro_f1 0.89292, 190.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94900, tacc(al2) 0.80200, tacc(ob0) 0.99400, tacc(ob1) 0.98500, tacc(ob2) 0.89800, tacc(ob3) 0.98400, tacc(ob4) 0.96400, 5.66 secs\n",
      "\u001b[1m---- Epoch 211/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.58945, triplet_loss 0.47069, c_loss 0.13214, hs_loss 0.24833, cs_loss 0.62837, cacc 0.94636, hsacc 0.90408, csacc 0.75652, chstimgn_loss 0.43914, chestimg_macro_f1 0.88876, 188.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95000, tacc(al2) 0.80000, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.89900, tacc(ob3) 0.98400, tacc(ob4) 0.96500, 5.63 secs\n",
      "\u001b[1m---- Epoch 212/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59152, triplet_loss 0.47000, c_loss 0.13050, hs_loss 0.25743, cs_loss 0.63732, cacc 0.94764, hsacc 0.90304, csacc 0.75380, chstimgn_loss 0.43541, chestimg_macro_f1 0.89133, 183.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.80000, tacc(ob0) 0.99400, tacc(ob1) 0.98500, tacc(ob2) 0.90000, tacc(ob3) 0.98400, tacc(ob4) 0.96400, 5.60 secs\n",
      "\u001b[1m---- Epoch 213/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.64448, triplet_loss 0.47498, c_loss 0.15575, hs_loss 0.29957, cs_loss 0.71174, cacc 0.93992, hsacc 0.88484, csacc 0.72496, chstimgn_loss 0.46795, chestimg_macro_f1 0.87223, 190.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.93500, tacc(al2) 0.82000, tacc(ob0) 0.99400, tacc(ob1) 0.97700, tacc(ob2) 0.91100, tacc(ob3) 0.98200, tacc(ob4) 0.95600, 5.74 secs\n",
      "\u001b[1m---- Epoch 214/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.62661, triplet_loss 0.47300, c_loss 0.13849, hs_loss 0.29347, cs_loss 0.69419, cacc 0.94032, hsacc 0.88776, csacc 0.73172, chstimgn_loss 0.45365, chestimg_macro_f1 0.87987, 188.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.93900, tacc(al2) 0.82000, tacc(ob0) 0.99300, tacc(ob1) 0.97900, tacc(ob2) 0.89600, tacc(ob3) 0.98500, tacc(ob4) 0.96400, 5.63 secs\n",
      "\u001b[1m---- Epoch 215/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.60518, triplet_loss 0.47126, c_loss 0.13599, hs_loss 0.28052, cs_loss 0.65745, cacc 0.94300, hsacc 0.89292, csacc 0.75040, chstimgn_loss 0.43774, chestimg_macro_f1 0.88781, 185.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94400, tacc(al2) 0.81600, tacc(ob0) 0.99300, tacc(ob1) 0.98300, tacc(ob2) 0.89600, tacc(ob3) 0.98500, tacc(ob4) 0.96300, 5.70 secs\n",
      "\u001b[1m---- Epoch 216/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.60018, triplet_loss 0.47153, c_loss 0.14789, hs_loss 0.28130, cs_loss 0.64343, cacc 0.94344, hsacc 0.89328, csacc 0.74928, chstimgn_loss 0.42828, chestimg_macro_f1 0.89207, 184.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94300, tacc(al2) 0.81400, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.89800, tacc(ob3) 0.98300, tacc(ob4) 0.96200, 5.62 secs\n",
      "\u001b[1m---- Epoch 217/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.59217, triplet_loss 0.47171, c_loss 0.14352, hs_loss 0.26515, cs_loss 0.63867, cacc 0.94480, hsacc 0.89836, csacc 0.75360, chstimgn_loss 0.42482, chestimg_macro_f1 0.89315, 183.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94300, tacc(al2) 0.82100, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.90300, tacc(ob3) 0.98400, tacc(ob4) 0.96200, 5.59 secs\n",
      "\u001b[1m---- Epoch 218/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.58501, triplet_loss 0.47019, c_loss 0.13352, hs_loss 0.25542, cs_loss 0.62578, cacc 0.94716, hsacc 0.90192, csacc 0.75816, chstimgn_loss 0.42757, chestimg_macro_f1 0.89066, 188.42 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94300, tacc(al2) 0.81800, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.90300, tacc(ob3) 0.98500, tacc(ob4) 0.96200, 5.62 secs\n",
      "\u001b[1m---- Epoch 219/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.58706, triplet_loss 0.46989, c_loss 0.13502, hs_loss 0.25925, cs_loss 0.62501, cacc 0.94664, hsacc 0.90244, csacc 0.75792, chstimgn_loss 0.42952, chestimg_macro_f1 0.89161, 190.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94200, tacc(al2) 0.81900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.90200, tacc(ob3) 0.98500, tacc(ob4) 0.96200, 5.65 secs\n",
      "\u001b[1m---- Epoch 220/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58677, triplet_loss 0.47053, c_loss 0.13005, hs_loss 0.26161, cs_loss 0.63474, cacc 0.94688, hsacc 0.89968, csacc 0.75696, chstimgn_loss 0.42507, chestimg_macro_f1 0.89370, 189.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94300, tacc(al2) 0.81900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.90400, tacc(ob3) 0.98500, tacc(ob4) 0.96200, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_220_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9525.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 221/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.63433, triplet_loss 0.47233, c_loss 0.16334, hs_loss 0.29993, cs_loss 0.69942, cacc 0.93856, hsacc 0.88680, csacc 0.73444, chstimgn_loss 0.45115, chestimg_macro_f1 0.87715, 189.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.83500, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.89600, tacc(ob3) 0.98100, tacc(ob4) 0.95500, 5.65 secs\n",
      "\u001b[1m---- Epoch 222/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.62868, triplet_loss 0.47361, c_loss 0.15567, hs_loss 0.29649, cs_loss 0.69328, cacc 0.93748, hsacc 0.88336, csacc 0.73596, chstimgn_loss 0.44783, chestimg_macro_f1 0.88073, 189.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94100, tacc(al2) 0.82400, tacc(ob0) 0.99300, tacc(ob1) 0.98000, tacc(ob2) 0.89600, tacc(ob3) 0.98300, tacc(ob4) 0.96300, 5.66 secs\n",
      "\u001b[1m---- Epoch 223/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.59809, triplet_loss 0.47261, c_loss 0.13559, hs_loss 0.27502, cs_loss 0.65390, cacc 0.94596, hsacc 0.89636, csacc 0.74584, chstimgn_loss 0.42762, chestimg_macro_f1 0.89054, 191.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.82800, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.90100, tacc(ob3) 0.98500, tacc(ob4) 0.96900, 5.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_223_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9530.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 224/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.58495, triplet_loss 0.47078, c_loss 0.13487, hs_loss 0.26716, cs_loss 0.63472, cacc 0.94724, hsacc 0.89984, csacc 0.75608, chstimgn_loss 0.41614, chestimg_macro_f1 0.89555, 185.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94100, tacc(al2) 0.82300, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.89900, tacc(ob3) 0.98300, tacc(ob4) 0.96600, 5.63 secs\n",
      "\u001b[1m---- Epoch 225/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.58187, triplet_loss 0.47045, c_loss 0.13521, hs_loss 0.26270, cs_loss 0.62684, cacc 0.94860, hsacc 0.89952, csacc 0.76008, chstimgn_loss 0.41614, chestimg_macro_f1 0.89498, 186.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94300, tacc(al2) 0.82100, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.89900, tacc(ob3) 0.98400, tacc(ob4) 0.96400, 5.63 secs\n",
      "\u001b[1m---- Epoch 226/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.58376, triplet_loss 0.47166, c_loss 0.14002, hs_loss 0.25636, cs_loss 0.63211, cacc 0.94936, hsacc 0.90024, csacc 0.75728, chstimgn_loss 0.41745, chestimg_macro_f1 0.89344, 190.35 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94200, tacc(al2) 0.81600, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.90200, tacc(ob3) 0.98300, tacc(ob4) 0.96600, 5.58 secs\n",
      "\u001b[1m---- Epoch 227/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.58295, triplet_loss 0.46974, c_loss 0.13377, hs_loss 0.26591, cs_loss 0.63635, cacc 0.94840, hsacc 0.89952, csacc 0.75492, chstimgn_loss 0.41301, chestimg_macro_f1 0.89858, 187.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94200, tacc(al2) 0.81600, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.90000, tacc(ob3) 0.98300, tacc(ob4) 0.96500, 5.66 secs\n",
      "\u001b[1m---- Epoch 228/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.57643, triplet_loss 0.46912, c_loss 0.12123, hs_loss 0.26151, cs_loss 0.63325, cacc 0.94928, hsacc 0.90192, csacc 0.75508, chstimgn_loss 0.41031, chestimg_macro_f1 0.89844, 190.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94200, tacc(al2) 0.81800, tacc(ob0) 0.99300, tacc(ob1) 0.98100, tacc(ob2) 0.90100, tacc(ob3) 0.98400, tacc(ob4) 0.96600, 5.32 secs\n",
      "\u001b[1m---- Epoch 229/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.63455, triplet_loss 0.47368, c_loss 0.16104, hs_loss 0.29426, cs_loss 0.70660, cacc 0.93632, hsacc 0.88716, csacc 0.72880, chstimgn_loss 0.45130, chestimg_macro_f1 0.87785, 191.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94600, tacc(al2) 0.80400, tacc(ob0) 0.99400, tacc(ob1) 0.98300, tacc(ob2) 0.89300, tacc(ob3) 0.98500, tacc(ob4) 0.96500, 5.65 secs\n",
      "\u001b[1m---- Epoch 230/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.62243, triplet_loss 0.47116, c_loss 0.14676, hs_loss 0.30920, cs_loss 0.69730, cacc 0.93724, hsacc 0.88344, csacc 0.73264, chstimgn_loss 0.43266, chestimg_macro_f1 0.88414, 187.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.82500, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.90000, tacc(ob3) 0.98700, tacc(ob4) 0.96400, 5.65 secs\n",
      "\u001b[1m---- Epoch 231/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.59768, triplet_loss 0.47160, c_loss 0.13069, hs_loss 0.27252, cs_loss 0.66965, cacc 0.94284, hsacc 0.89308, csacc 0.74112, chstimgn_loss 0.42312, chestimg_macro_f1 0.88917, 188.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94900, tacc(al2) 0.82500, tacc(ob0) 0.99300, tacc(ob1) 0.98200, tacc(ob2) 0.90200, tacc(ob3) 0.98500, tacc(ob4) 0.96300, 5.63 secs\n",
      "\u001b[1m---- Epoch 232/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.59106, triplet_loss 0.46931, c_loss 0.14807, hs_loss 0.27072, cs_loss 0.64717, cacc 0.94556, hsacc 0.89668, csacc 0.74788, chstimgn_loss 0.41449, chestimg_macro_f1 0.89476, 185.94 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.81900, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.90400, tacc(ob3) 0.98500, tacc(ob4) 0.96600, 5.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_232_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9534.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 233/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.58032, triplet_loss 0.46952, c_loss 0.14417, hs_loss 0.26760, cs_loss 0.62166, cacc 0.94656, hsacc 0.89640, csacc 0.75680, chstimgn_loss 0.40917, chestimg_macro_f1 0.89432, 186.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94700, tacc(al2) 0.81900, tacc(ob0) 0.99400, tacc(ob1) 0.98100, tacc(ob2) 0.90500, tacc(ob3) 0.98600, tacc(ob4) 0.96600, 5.65 secs\n",
      "\u001b[1m---- Epoch 234/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.57476, triplet_loss 0.46889, c_loss 0.13187, hs_loss 0.26412, cs_loss 0.61797, cacc 0.94748, hsacc 0.89564, csacc 0.75976, chstimgn_loss 0.40810, chestimg_macro_f1 0.89694, 188.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94800, tacc(al2) 0.82100, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90000, tacc(ob3) 0.98600, tacc(ob4) 0.96500, 5.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_234_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9534.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 235/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.57145, triplet_loss 0.47060, c_loss 0.13412, hs_loss 0.25477, cs_loss 0.61808, cacc 0.94812, hsacc 0.89916, csacc 0.76084, chstimgn_loss 0.40412, chestimg_macro_f1 0.89841, 185.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94600, tacc(al2) 0.82200, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90300, tacc(ob3) 0.98500, tacc(ob4) 0.96600, 5.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_235_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9536.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 236/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58135, triplet_loss 0.47040, c_loss 0.15710, hs_loss 0.26503, cs_loss 0.63024, cacc 0.94652, hsacc 0.90024, csacc 0.75688, chstimgn_loss 0.40130, chestimg_macro_f1 0.89822, 187.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.82000, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.90200, tacc(ob3) 0.98600, tacc(ob4) 0.96600, 5.66 secs\n",
      "\u001b[1m---- Epoch 237/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.62122, triplet_loss 0.47295, c_loss 0.15143, hs_loss 0.29023, cs_loss 0.70547, cacc 0.94196, hsacc 0.89032, csacc 0.73196, chstimgn_loss 0.43240, chestimg_macro_f1 0.88384, 187.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.93900, tacc(al2) 0.81900, tacc(ob0) 0.99400, tacc(ob1) 0.97700, tacc(ob2) 0.89800, tacc(ob3) 0.98600, tacc(ob4) 0.96300, 5.57 secs\n",
      "\u001b[1m---- Epoch 238/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.61098, triplet_loss 0.47235, c_loss 0.16352, hs_loss 0.27576, cs_loss 0.68349, cacc 0.94052, hsacc 0.89192, csacc 0.73480, chstimgn_loss 0.42440, chestimg_macro_f1 0.88633, 185.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94600, tacc(al2) 0.82300, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.89300, tacc(ob3) 0.98500, tacc(ob4) 0.96200, 5.64 secs\n",
      "\u001b[1m---- Epoch 239/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.58850, triplet_loss 0.47263, c_loss 0.14021, hs_loss 0.26895, cs_loss 0.65315, cacc 0.94660, hsacc 0.89916, csacc 0.74684, chstimgn_loss 0.40954, chestimg_macro_f1 0.89279, 175.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.82000, tacc(ob0) 0.99400, tacc(ob1) 0.98100, tacc(ob2) 0.90100, tacc(ob3) 0.98500, tacc(ob4) 0.96300, 5.64 secs\n",
      "\u001b[1m---- Epoch 240/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.57641, triplet_loss 0.46878, c_loss 0.12334, hs_loss 0.26663, cs_loss 0.63561, cacc 0.94628, hsacc 0.89784, csacc 0.75504, chstimgn_loss 0.40565, chestimg_macro_f1 0.89666, 188.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.82100, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.89600, tacc(ob3) 0.98600, tacc(ob4) 0.96100, 5.62 secs\n",
      "\u001b[1m---- Epoch 241/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.57557, triplet_loss 0.46845, c_loss 0.14160, hs_loss 0.25801, cs_loss 0.63049, cacc 0.94720, hsacc 0.90204, csacc 0.75612, chstimgn_loss 0.40187, chestimg_macro_f1 0.89838, 180.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94600, tacc(al2) 0.81900, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.90200, tacc(ob3) 0.98700, tacc(ob4) 0.96100, 5.73 secs\n",
      "\u001b[1m---- Epoch 242/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.56363, triplet_loss 0.46812, c_loss 0.12946, hs_loss 0.24624, cs_loss 0.61883, cacc 0.94828, hsacc 0.90632, csacc 0.76116, chstimgn_loss 0.39593, chestimg_macro_f1 0.89908, 168.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.81600, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.90200, tacc(ob3) 0.98700, tacc(ob4) 0.96000, 5.69 secs\n",
      "\u001b[1m---- Epoch 243/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.56890, triplet_loss 0.46976, c_loss 0.13017, hs_loss 0.26052, cs_loss 0.61941, cacc 0.94876, hsacc 0.90472, csacc 0.76008, chstimgn_loss 0.39787, chestimg_macro_f1 0.89915, 168.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.81500, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.90300, tacc(ob3) 0.98700, tacc(ob4) 0.96000, 5.69 secs\n",
      "\u001b[1m---- Epoch 244/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.56348, triplet_loss 0.46827, c_loss 0.12218, hs_loss 0.24720, cs_loss 0.61780, cacc 0.94752, hsacc 0.90444, csacc 0.76100, chstimgn_loss 0.39923, chestimg_macro_f1 0.89918, 183.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94600, tacc(al2) 0.81500, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.90200, tacc(ob3) 0.98700, tacc(ob4) 0.96000, 5.66 secs\n",
      "\u001b[1m---- Epoch 245/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.61167, triplet_loss 0.47187, c_loss 0.15647, hs_loss 0.28114, cs_loss 0.68753, cacc 0.94376, hsacc 0.89244, csacc 0.73708, chstimgn_loss 0.42484, chestimg_macro_f1 0.88577, 190.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.80800, tacc(ob0) 0.99200, tacc(ob1) 0.98000, tacc(ob2) 0.90400, tacc(ob3) 0.98400, tacc(ob4) 0.95700, 5.52 secs\n",
      "\u001b[1m---- Epoch 246/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.60439, triplet_loss 0.46988, c_loss 0.15933, hs_loss 0.28680, cs_loss 0.66683, cacc 0.94116, hsacc 0.89044, csacc 0.74328, chstimgn_loss 0.41737, chestimg_macro_f1 0.88959, 188.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.80700, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.91100, tacc(ob3) 0.98400, tacc(ob4) 0.96100, 5.62 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 247/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.57846, triplet_loss 0.46969, c_loss 0.13638, hs_loss 0.25887, cs_loss 0.64682, cacc 0.94252, hsacc 0.89852, csacc 0.75224, chstimgn_loss 0.40103, chestimg_macro_f1 0.89530, 190.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94600, tacc(al2) 0.80900, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.91000, tacc(ob3) 0.98800, tacc(ob4) 0.95900, 5.64 secs\n",
      "\u001b[1m---- Epoch 248/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.57002, triplet_loss 0.46996, c_loss 0.13059, hs_loss 0.25898, cs_loss 0.62966, cacc 0.94700, hsacc 0.89924, csacc 0.75784, chstimgn_loss 0.39545, chestimg_macro_f1 0.89847, 184.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95000, tacc(al2) 0.80700, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.90600, tacc(ob3) 0.98800, tacc(ob4) 0.96600, 5.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_248_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9537.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 249/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.56246, triplet_loss 0.46888, c_loss 0.13021, hs_loss 0.25158, cs_loss 0.62094, cacc 0.94924, hsacc 0.90208, csacc 0.75776, chstimgn_loss 0.38913, chestimg_macro_f1 0.90165, 188.85 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95100, tacc(al2) 0.80500, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90500, tacc(ob3) 0.98700, tacc(ob4) 0.96400, 5.67 secs\n",
      "\u001b[1m---- Epoch 250/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.56008, triplet_loss 0.46755, c_loss 0.13905, hs_loss 0.25466, cs_loss 0.61050, cacc 0.94752, hsacc 0.90236, csacc 0.76392, chstimgn_loss 0.38428, chestimg_macro_f1 0.90287, 184.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.80500, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90900, tacc(ob3) 0.98600, tacc(ob4) 0.96500, 5.60 secs\n",
      "\u001b[1m---- Epoch 251/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.56183, triplet_loss 0.46934, c_loss 0.13189, hs_loss 0.25768, cs_loss 0.62039, cacc 0.94788, hsacc 0.89816, csacc 0.76012, chstimgn_loss 0.38401, chestimg_macro_f1 0.90351, 184.75 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94800, tacc(al2) 0.80700, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90900, tacc(ob3) 0.98700, tacc(ob4) 0.96300, 5.69 secs\n",
      "\u001b[1m---- Epoch 252/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.56094, triplet_loss 0.46914, c_loss 0.12911, hs_loss 0.25398, cs_loss 0.61610, cacc 0.94904, hsacc 0.90280, csacc 0.76296, chstimgn_loss 0.38772, chestimg_macro_f1 0.90223, 188.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94600, tacc(al2) 0.80400, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90800, tacc(ob3) 0.98800, tacc(ob4) 0.96400, 5.55 secs\n",
      "\u001b[1m---- Epoch 253/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.61432, triplet_loss 0.47050, c_loss 0.16212, hs_loss 0.29827, cs_loss 0.68234, cacc 0.94016, hsacc 0.88784, csacc 0.73700, chstimgn_loss 0.42204, chestimg_macro_f1 0.88454, 187.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94100, tacc(al2) 0.81000, tacc(ob0) 0.99500, tacc(ob1) 0.97500, tacc(ob2) 0.89200, tacc(ob3) 0.98800, tacc(ob4) 0.95800, 5.56 secs\n",
      "\u001b[1m---- Epoch 254/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.60035, triplet_loss 0.47096, c_loss 0.15068, hs_loss 0.27520, cs_loss 0.68141, cacc 0.94104, hsacc 0.89152, csacc 0.73640, chstimgn_loss 0.41158, chestimg_macro_f1 0.89124, 188.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94600, tacc(al2) 0.82100, tacc(ob0) 0.99500, tacc(ob1) 0.97500, tacc(ob2) 0.90100, tacc(ob3) 0.99000, tacc(ob4) 0.95600, 5.65 secs\n",
      "\u001b[1m---- Epoch 255/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.58101, triplet_loss 0.46819, c_loss 0.13997, hs_loss 0.27238, cs_loss 0.64714, cacc 0.94620, hsacc 0.89716, csacc 0.74880, chstimgn_loss 0.39817, chestimg_macro_f1 0.89695, 190.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.81300, tacc(ob0) 0.99300, tacc(ob1) 0.98300, tacc(ob2) 0.89500, tacc(ob3) 0.98700, tacc(ob4) 0.96000, 5.68 secs\n",
      "\u001b[1m---- Epoch 256/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.56884, triplet_loss 0.46925, c_loss 0.13748, hs_loss 0.26181, cs_loss 0.62457, cacc 0.94472, hsacc 0.90016, csacc 0.75640, chstimgn_loss 0.39114, chestimg_macro_f1 0.90084, 188.25 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94400, tacc(al2) 0.80900, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.90000, tacc(ob3) 0.98800, tacc(ob4) 0.95900, 5.62 secs\n",
      "\u001b[1m---- Epoch 257/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.55649, triplet_loss 0.46716, c_loss 0.12799, hs_loss 0.24850, cs_loss 0.60940, cacc 0.94692, hsacc 0.90368, csacc 0.76216, chstimgn_loss 0.38646, chestimg_macro_f1 0.90128, 189.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94300, tacc(al2) 0.81600, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.90300, tacc(ob3) 0.98800, tacc(ob4) 0.96000, 5.62 secs\n",
      "\u001b[1m---- Epoch 258/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.56967, triplet_loss 0.46900, c_loss 0.13308, hs_loss 0.27685, cs_loss 0.62514, cacc 0.94632, hsacc 0.89816, csacc 0.75540, chstimgn_loss 0.38729, chestimg_macro_f1 0.90287, 188.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94400, tacc(al2) 0.81700, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.89900, tacc(ob3) 0.98800, tacc(ob4) 0.95900, 5.64 secs\n",
      "\u001b[1m---- Epoch 259/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.55660, triplet_loss 0.46744, c_loss 0.13874, hs_loss 0.24494, cs_loss 0.61007, cacc 0.94788, hsacc 0.90068, csacc 0.76196, chstimgn_loss 0.38260, chestimg_macro_f1 0.90422, 186.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94600, tacc(al2) 0.81600, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.89800, tacc(ob3) 0.98800, tacc(ob4) 0.95900, 5.62 secs\n",
      "\u001b[1m---- Epoch 260/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.55887, triplet_loss 0.46643, c_loss 0.12419, hs_loss 0.25870, cs_loss 0.62447, cacc 0.94800, hsacc 0.90292, csacc 0.75620, chstimgn_loss 0.38084, chestimg_macro_f1 0.90379, 183.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94500, tacc(al2) 0.81400, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.89800, tacc(ob3) 0.98800, tacc(ob4) 0.96000, 5.65 secs\n",
      "\u001b[1m---- Epoch 261/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.59738, triplet_loss 0.47194, c_loss 0.14177, hs_loss 0.28654, cs_loss 0.67963, cacc 0.94344, hsacc 0.88916, csacc 0.73784, chstimgn_loss 0.40482, chestimg_macro_f1 0.89183, 185.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98000, tacc(al1) 0.94800, tacc(al2) 0.80300, tacc(ob0) 0.99300, tacc(ob1) 0.98300, tacc(ob2) 0.90100, tacc(ob3) 0.98800, tacc(ob4) 0.96000, 5.65 secs\n",
      "\u001b[1m---- Epoch 262/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.60583, triplet_loss 0.47046, c_loss 0.16319, hs_loss 0.30360, cs_loss 0.68264, cacc 0.93852, hsacc 0.88624, csacc 0.73812, chstimgn_loss 0.40171, chestimg_macro_f1 0.89165, 191.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.95000, tacc(al2) 0.80200, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.89900, tacc(ob3) 0.98900, tacc(ob4) 0.96200, 5.65 secs\n",
      "\u001b[1m---- Epoch 263/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.57375, triplet_loss 0.46982, c_loss 0.12882, hs_loss 0.26716, cs_loss 0.64601, cacc 0.94420, hsacc 0.89668, csacc 0.75220, chstimgn_loss 0.39159, chestimg_macro_f1 0.89629, 191.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.81300, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.90200, tacc(ob3) 0.98600, tacc(ob4) 0.96100, 5.65 secs\n",
      "\u001b[1m---- Epoch 264/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.56700, triplet_loss 0.46957, c_loss 0.13552, hs_loss 0.26093, cs_loss 0.63281, cacc 0.94564, hsacc 0.90360, csacc 0.75752, chstimgn_loss 0.38459, chestimg_macro_f1 0.90083, 188.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.81600, tacc(ob0) 0.99400, tacc(ob1) 0.98100, tacc(ob2) 0.90400, tacc(ob3) 0.98600, tacc(ob4) 0.96400, 5.66 secs\n",
      "\u001b[1m---- Epoch 265/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.56205, triplet_loss 0.47103, c_loss 0.13430, hs_loss 0.27063, cs_loss 0.61884, cacc 0.95012, hsacc 0.89904, csacc 0.75692, chstimgn_loss 0.37670, chestimg_macro_f1 0.90435, 190.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94900, tacc(al2) 0.81900, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.90200, tacc(ob3) 0.98400, tacc(ob4) 0.96300, 5.67 secs\n",
      "\u001b[1m---- Epoch 266/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.55135, triplet_loss 0.46878, c_loss 0.12584, hs_loss 0.25413, cs_loss 0.61619, cacc 0.95088, hsacc 0.90052, csacc 0.76148, chstimgn_loss 0.37023, chestimg_macro_f1 0.90685, 189.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95100, tacc(al2) 0.81700, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90300, tacc(ob3) 0.98400, tacc(ob4) 0.96300, 5.55 secs\n",
      "\u001b[1m---- Epoch 267/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.55784, triplet_loss 0.46787, c_loss 0.13318, hs_loss 0.25773, cs_loss 0.62429, cacc 0.94832, hsacc 0.90428, csacc 0.76060, chstimgn_loss 0.37415, chestimg_macro_f1 0.90467, 189.25 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.81900, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.90300, tacc(ob3) 0.98400, tacc(ob4) 0.96300, 5.62 secs\n",
      "\u001b[1m---- Epoch 268/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "   iteration 87425\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 120 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 2 \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc675eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 120\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 100\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_labels: 74\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2842463,297669,1996654,2501000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1.0, 2.0, 1.0, 1.0, 2.0, 2.5]}\n",
      "   integrated_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\n",
      "   paraphrases_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl']\n",
      "   integrated_chest_imagenome_labels_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl\n",
      "   dataset_name: MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 1.0\n",
      "   chest_imagenome_classification_weight: 2.0\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: True\n",
      "  n_categories: 6\n",
      "  classify_health_status: True\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: True\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome: True\n",
      "  n_chest_imagenome_labels: 74\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\n",
      "1e-06 3 0.0002 8 2e-06 0.0002 8 2e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2842463,297669,1996654,2501000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 2880495\n",
      "\tWeight: 0.8\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 2871477\n",
      "\tWeight: 1.6\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1985876\n",
      "\tWeight: 0.8\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3769457\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3762631\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 2222660\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2471362\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 4429015\n",
      "\tWeight: 2.0\n",
      "observations -> rule 5: \"Rank triplets according to Chest ImaGenome labels\"\n",
      "\tNumber of triplets: 2830670\n",
      "\tWeight: 2.5\n",
      "----\n",
      "\u001b[1mBuilding train metadata classification dataset and dataloader...\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "Loading paraphrases from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl...\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "Number of sentences with paraphrases: 109887\n",
      "Number of paraphrases: 1299918\n",
      "Loading integrated facts metadata...\n",
      "Number of facts: 2188212\n",
      "Number of improved comparisons: 521435/578733\n",
      "Category: anatomical finding -> 1564922\n",
      "Category: tubes and lines -> 235687\n",
      "Category: technical assessment -> 150516\n",
      "Category: disease -> 122596\n",
      "Category: device -> 111660\n",
      "Category: other -> 2831\n",
      "Health status: abnormal -> 1283130\n",
      "Health status: unknown -> 520758\n",
      "Health status: normal -> 246373\n",
      "Health status: ambiguous -> 136998\n",
      "Health status: other -> 953\n",
      "Comparison status: no comparison -> 1204429\n",
      "Comparison status: stable/unchanged -> 248878\n",
      "Comparison status: worsened -> 125579\n",
      "Comparison status: improved -> 99848\n",
      "Comparison status: resolved -> 91368\n",
      "Comparison status: new finding -> 83889\n",
      "Comparison status: unclear comparison -> 75262\n",
      "Comparison status: position changed -> 67257\n",
      "Comparison status: increase -> 58489\n",
      "Comparison status: decrease -> 38620\n",
      "Comparison status: progressed -> 31572\n",
      "Comparison status: smaller -> 24358\n",
      "Comparison status: larger -> 22410\n",
      "Comparison status: reappeared -> 15813\n",
      "Comparison status: other -> 440\n",
      "\u001b[1mExample fact: The pleural effusion demonstrates a component of layering, which is very small\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: smaller\n",
      "\u001b[1mExample fact: slight improved aeration in the right lower lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: improved\n",
      "\u001b[1mExample fact: There is evidence of callus formation due to the healing of the fractures\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: normal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: The X-ray exhibits a sudden change in course\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: unknown\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: symmetrically inflated lungs bilaterally\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: nodular opacities\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: no comparison\n",
      "\u001b[1mExample fact: increase at the left base\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: increase\n",
      "\u001b[1mExample fact: not large pleural effusion\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: stable/unchanged\n",
      "\u001b[1mExample fact: expanded consolidation in the uppermost section of the right lung\u001b[0m\n",
      "Category: anatomical finding\n",
      "Health status: abnormal\n",
      "Comparison status: worsened\n",
      "\u001b[1mExample fact: decrease in the free intraperitoneal gas\u001b[0m\n",
      "Category: technical assessment\n",
      "Health status: normal\n",
      "Comparison status: improved\n",
      "Comparison status: no comparison\n",
      "\tNumber of samples: 1204429\n",
      "\tWeight: 8242.307524442282\n",
      "Comparison status: worsened\n",
      "\tNumber of samples: 125579\n",
      "\tWeight: 4859.644675613537\n",
      "Comparison status: resolved\n",
      "\tNumber of samples: 91368\n",
      "\tWeight: 4475.3220512437665\n",
      "Comparison status: stable/unchanged\n",
      "\tNumber of samples: 248878\n",
      "\tWeight: 5759.479652244662\n",
      "Comparison status: progressed\n",
      "\tNumber of samples: 31572\n",
      "\tWeight: 3338.9210042448967\n",
      "Comparison status: larger\n",
      "\tNumber of samples: 22410\n",
      "\tWeight: 3018.358277880451\n",
      "Comparison status: improved\n",
      "\tNumber of samples: 99848\n",
      "\tWeight: 4580.4541460194605\n",
      "Comparison status: reappeared\n",
      "\tNumber of samples: 15813\n",
      "\tWeight: 2714.0180702391563\n",
      "Comparison status: smaller\n",
      "\tNumber of samples: 24358\n",
      "\tWeight: 3094.333715211565\n",
      "Comparison status: position changed\n",
      "\tNumber of samples: 67257\n",
      "\tWeight: 4124.787930176123\n",
      "Comparison status: new finding\n",
      "\tNumber of samples: 83889\n",
      "\tWeight: 4375.692166468171\n",
      "Comparison status: unclear comparison\n",
      "\tNumber of samples: 75262\n",
      "\tWeight: 4251.23985322021\n",
      "Comparison status: increase\n",
      "\tNumber of samples: 58489\n",
      "\tWeight: 3971.242589056373\n",
      "Comparison status: decrease\n",
      "\tNumber of samples: 38620\n",
      "\tWeight: 3537.55808591334\n",
      "Comparison status: other\n",
      "\tNumber of samples: 440\n",
      "\tWeight: 677.1506551206787\n",
      "----\n",
      "\u001b[1mBuilding train chest imagenome labels classification dataset and dataloader...\u001b[0m\n",
      "Loading chest integrated chest imagenome labels from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl...\n",
      "len(phrases): 2552490\n",
      "len(label_names): 74\n",
      "labels.shape: (2552490, 74)\n",
      "Label: lung opacity\n",
      "\tNumber of idxs: 545396\n",
      "\tWeight: 6920.86\n",
      "Label: pleural effusion\n",
      "\tNumber of idxs: 210024\n",
      "\tWeight: 5526.64\n",
      "Label: atelectasis\n",
      "\tNumber of idxs: 157638\n",
      "\tWeight: 5147.48\n",
      "Label: pneumonia\n",
      "\tNumber of idxs: 102321\n",
      "\tWeight: 4609.72\n",
      "Label: lung lesion\n",
      "\tNumber of idxs: 91567\n",
      "\tWeight: 4477.88\n",
      "Label: pulmonary edema/hazy opacity\n",
      "\tNumber of idxs: 90170\n",
      "\tWeight: 4459.83\n",
      "Label: enteric tube\n",
      "\tNumber of idxs: 89660\n",
      "\tWeight: 4453.18\n",
      "Label: consolidation\n",
      "\tNumber of idxs: 86042\n",
      "\tWeight: 4405.10\n",
      "Label: airspace opacity\n",
      "\tNumber of idxs: 74463\n",
      "\tWeight: 4239.13\n",
      "Label: mass/nodule (not otherwise specified)\n",
      "\tNumber of idxs: 71602\n",
      "\tWeight: 4194.87\n",
      "Label: ij line\n",
      "\tNumber of idxs: 71363\n",
      "\tWeight: 4191.11\n",
      "Label: increased reticular markings/ild pattern\n",
      "\tNumber of idxs: 71151\n",
      "\tWeight: 4187.76\n",
      "Label: vascular congestion\n",
      "\tNumber of idxs: 68126\n",
      "\tWeight: 4139.10\n",
      "Label: enlarged cardiac silhouette\n",
      "\tNumber of idxs: 66476\n",
      "\tWeight: 4111.80\n",
      "Label: endotracheal tube\n",
      "\tNumber of idxs: 57767\n",
      "\tWeight: 3957.78\n",
      "Label: pleural/parenchymal scarring\n",
      "\tNumber of idxs: 55741\n",
      "\tWeight: 3919.24\n",
      "Label: infiltration\n",
      "\tNumber of idxs: 53996\n",
      "\tWeight: 3885.12\n",
      "Label: picc\n",
      "\tNumber of idxs: 52338\n",
      "\tWeight: 3851.86\n",
      "Label: cardiac pacer and wires\n",
      "\tNumber of idxs: 51132\n",
      "\tWeight: 3827.12\n",
      "Label: lobar/segmental collapse\n",
      "\tNumber of idxs: 49855\n",
      "\tWeight: 3800.40\n",
      "Label: rib fracture\n",
      "\tNumber of idxs: 48249\n",
      "\tWeight: 3765.99\n",
      "Label: pneumothorax\n",
      "\tNumber of idxs: 47137\n",
      "\tWeight: 3741.61\n",
      "Label: sub-diaphragmatic air\n",
      "\tNumber of idxs: 45808\n",
      "\tWeight: 3711.86\n",
      "Label: artifact\n",
      "\tNumber of idxs: 44545\n",
      "\tWeight: 3682.93\n",
      "Label: mediastinal widening\n",
      "\tNumber of idxs: 43575\n",
      "\tWeight: 3660.25\n",
      "Label: chest tube\n",
      "\tNumber of idxs: 43310\n",
      "\tWeight: 3653.98\n",
      "Label: enlarged hilum\n",
      "\tNumber of idxs: 39792\n",
      "\tWeight: 3567.68\n",
      "Label: hyperaeration\n",
      "\tNumber of idxs: 36155\n",
      "\tWeight: 3471.70\n",
      "Label: linear/patchy atelectasis\n",
      "\tNumber of idxs: 35090\n",
      "\tWeight: 3442.11\n",
      "Label: subcutaneous air\n",
      "\tNumber of idxs: 31502\n",
      "\tWeight: 3336.78\n",
      "Label: vascular calcification\n",
      "\tNumber of idxs: 29081\n",
      "\tWeight: 3260.09\n",
      "Label: low lung volumes\n",
      "\tNumber of idxs: 27898\n",
      "\tWeight: 3220.73\n",
      "Label: subclavian line\n",
      "\tNumber of idxs: 26390\n",
      "\tWeight: 3168.56\n",
      "Label: chest port\n",
      "\tNumber of idxs: 25350\n",
      "\tWeight: 3131.17\n",
      "Label: aspiration\n",
      "\tNumber of idxs: 25239\n",
      "\tWeight: 3127.10\n",
      "Label: spinal fracture\n",
      "\tNumber of idxs: 23897\n",
      "\tWeight: 3076.81\n",
      "Label: spinal degenerative changes\n",
      "\tNumber of idxs: 22873\n",
      "\tWeight: 3036.88\n",
      "Label: costophrenic angle blunting\n",
      "\tNumber of idxs: 21655\n",
      "\tWeight: 2987.49\n",
      "Label: interstitial lung disease\n",
      "\tNumber of idxs: 19411\n",
      "\tWeight: 2890.34\n",
      "Label: mediastinal displacement\n",
      "\tNumber of idxs: 19259\n",
      "\tWeight: 2883.45\n",
      "Label: pigtail catheter\n",
      "\tNumber of idxs: 19083\n",
      "\tWeight: 2875.40\n",
      "Label: swan-ganz catheter\n",
      "\tNumber of idxs: 18702\n",
      "\tWeight: 2857.79\n",
      "Label: bone lesion\n",
      "\tNumber of idxs: 18335\n",
      "\tWeight: 2840.55\n",
      "Label: fluid overload/heart failure\n",
      "\tNumber of idxs: 17658\n",
      "\tWeight: 2808.02\n",
      "Label: aortic graft/repair\n",
      "\tNumber of idxs: 16289\n",
      "\tWeight: 2739.07\n",
      "Label: vascular redistribution\n",
      "\tNumber of idxs: 16287\n",
      "\tWeight: 2738.97\n",
      "Label: elevated hemidiaphragm\n",
      "\tNumber of idxs: 15943\n",
      "\tWeight: 2720.92\n",
      "Label: tortuous aorta\n",
      "\tNumber of idxs: 15726\n",
      "\tWeight: 2709.37\n",
      "Label: copd/emphysema\n",
      "\tNumber of idxs: 13639\n",
      "\tWeight: 2591.37\n",
      "Label: tracheostomy tube\n",
      "\tNumber of idxs: 13575\n",
      "\tWeight: 2587.53\n",
      "Label: superior mediastinal mass/enlargement\n",
      "\tNumber of idxs: 12376\n",
      "\tWeight: 2512.83\n",
      "Label: calcified nodule\n",
      "\tNumber of idxs: 12277\n",
      "\tWeight: 2506.41\n",
      "Label: bronchiectasis\n",
      "\tNumber of idxs: 12016\n",
      "\tWeight: 2489.28\n",
      "Label: mediastinal drain\n",
      "\tNumber of idxs: 11868\n",
      "\tWeight: 2479.45\n",
      "Label: clavicle fracture\n",
      "\tNumber of idxs: 11411\n",
      "\tWeight: 2448.44\n",
      "Label: shoulder osteoarthritis\n",
      "\tNumber of idxs: 10526\n",
      "\tWeight: 2385.52\n",
      "Label: hernia\n",
      "\tNumber of idxs: 10022\n",
      "\tWeight: 2347.80\n",
      "Label: scoliosis\n",
      "\tNumber of idxs: 9382\n",
      "\tWeight: 2297.71\n",
      "Label: granulomatous disease\n",
      "\tNumber of idxs: 9099\n",
      "\tWeight: 2274.71\n",
      "Label: prosthetic valve\n",
      "\tNumber of idxs: 8946\n",
      "\tWeight: 2262.03\n",
      "Label: intra-aortic balloon pump\n",
      "\tNumber of idxs: 8936\n",
      "\tWeight: 2261.20\n",
      "Label: lung cancer\n",
      "\tNumber of idxs: 8480\n",
      "\tWeight: 2222.37\n",
      "Label: alveolar hemorrhage\n",
      "\tNumber of idxs: 8389\n",
      "\tWeight: 2214.43\n",
      "Label: multiple masses/nodules\n",
      "\tNumber of idxs: 7411\n",
      "\tWeight: 2124.53\n",
      "Label: diaphragmatic eventration (benign)\n",
      "\tNumber of idxs: 7196\n",
      "\tWeight: 2103.54\n",
      "Label: hydropneumothorax\n",
      "\tNumber of idxs: 6501\n",
      "\tWeight: 2032.19\n",
      "Label: rotated\n",
      "\tNumber of idxs: 6231\n",
      "\tWeight: 2002.88\n",
      "Label: breast/nipple shadows\n",
      "\tNumber of idxs: 6005\n",
      "\tWeight: 1977.58\n",
      "Label: cabg grafts\n",
      "\tNumber of idxs: 5306\n",
      "\tWeight: 1894.38\n",
      "Label: cyst/bullae\n",
      "\tNumber of idxs: 4896\n",
      "\tWeight: 1841.59\n",
      "Label: pericardial effusion\n",
      "\tNumber of idxs: 4729\n",
      "\tWeight: 1819.12\n",
      "Label: pneumomediastinum\n",
      "\tNumber of idxs: 4012\n",
      "\tWeight: 1715.12\n",
      "Label: goiter\n",
      "\tNumber of idxs: 3945\n",
      "\tWeight: 1704.70\n",
      "Label: skin fold\n",
      "\tNumber of idxs: 2048\n",
      "\tWeight: 1331.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: \"omitted\"\n",
      "\tNumber of idxs: 372746\n",
      "\tWeight: 6339.671293242993\n",
      "----\n",
      "\u001b[1mBuilding val dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "observations -> rule 5: \"Rank triplets according to Chest ImaGenome labels\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob5\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230730_012705_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230730_012705_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_180_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9534.pt', 'checkpoint_60_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9216.pt', 'checkpoint_282_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9541.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_282_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)=0.9541.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230730_012705_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.53890, triplet_loss 0.47196, c_loss 0.12709, hs_loss 0.23575, cs_loss 0.60504, cacc 0.94876, hsacc 0.90928, csacc 0.76380, chstimgn_loss 0.35787, chestimg_macro_f1 0.90956, 194.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.82900, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.88500, tacc(ob3) 0.98700, tacc(ob4) 0.95900, tacc(ob5) 0.96900, 6.58 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9532.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.54441, triplet_loss 0.47286, c_loss 0.13194, hs_loss 0.25045, cs_loss 0.61011, cacc 0.94808, hsacc 0.90168, csacc 0.76064, chstimgn_loss 0.35614, chestimg_macro_f1 0.90967, 191.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.82700, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.89000, tacc(ob3) 0.98800, tacc(ob4) 0.95700, tacc(ob5) 0.97000, 6.61 secs\n",
      "\u001b[1m---- Epoch 3/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 0.54574, triplet_loss 0.47150, c_loss 0.13329, hs_loss 0.24666, cs_loss 0.61339, cacc 0.95132, hsacc 0.90384, csacc 0.75680, chstimgn_loss 0.35906, chestimg_macro_f1 0.90790, 185.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94900, tacc(al2) 0.82400, tacc(ob0) 0.99200, tacc(ob1) 0.97800, tacc(ob2) 0.88500, tacc(ob3) 0.99100, tacc(ob4) 0.95700, tacc(ob5) 0.96500, 6.61 secs\n",
      "\u001b[1m---- Epoch 4/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.60097, triplet_loss 0.47503, c_loss 0.15518, hs_loss 0.29533, cs_loss 0.69331, cacc 0.93768, hsacc 0.88588, csacc 0.73404, chstimgn_loss 0.39250, chestimg_macro_f1 0.89054, 171.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.81400, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88700, tacc(ob3) 0.98800, tacc(ob4) 0.95700, tacc(ob5) 0.96900, 6.64 secs\n",
      "\u001b[1m---- Epoch 5/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000112) ...\n",
      "loss 0.58805, triplet_loss 0.47662, c_loss 0.15030, hs_loss 0.29005, cs_loss 0.67433, cacc 0.94316, hsacc 0.88596, csacc 0.74148, chstimgn_loss 0.38045, chestimg_macro_f1 0.89803, 172.10 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.82700, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.87800, tacc(ob3) 0.98900, tacc(ob4) 0.95700, tacc(ob5) 0.97500, 6.63 secs\n",
      "\u001b[1m---- Epoch 6/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 0.56891, triplet_loss 0.47360, c_loss 0.14924, hs_loss 0.26680, cs_loss 0.64261, cacc 0.94604, hsacc 0.89696, csacc 0.75152, chstimgn_loss 0.37170, chestimg_macro_f1 0.90111, 184.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95200, tacc(al2) 0.82500, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.88200, tacc(ob3) 0.99100, tacc(ob4) 0.95900, tacc(ob5) 0.97400, 6.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9540.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 0.55347, triplet_loss 0.47388, c_loss 0.13291, hs_loss 0.26553, cs_loss 0.62434, cacc 0.94900, hsacc 0.89564, csacc 0.75844, chstimgn_loss 0.35862, chestimg_macro_f1 0.90644, 174.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94600, tacc(al2) 0.82700, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.88200, tacc(ob3) 0.99100, tacc(ob4) 0.95700, tacc(ob5) 0.97400, 6.65 secs\n",
      "\u001b[1m---- Epoch 8/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.54607, triplet_loss 0.47347, c_loss 0.12644, hs_loss 0.25575, cs_loss 0.62069, cacc 0.94900, hsacc 0.89900, csacc 0.75552, chstimgn_loss 0.35396, chestimg_macro_f1 0.90904, 192.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.82400, tacc(ob0) 0.99600, tacc(ob1) 0.97800, tacc(ob2) 0.88800, tacc(ob3) 0.99200, tacc(ob4) 0.95900, tacc(ob5) 0.97600, 6.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9543.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.54373, triplet_loss 0.47145, c_loss 0.12592, hs_loss 0.24699, cs_loss 0.61317, cacc 0.95108, hsacc 0.90392, csacc 0.75940, chstimgn_loss 0.35870, chestimg_macro_f1 0.90649, 191.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94500, tacc(al2) 0.82600, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88200, tacc(ob3) 0.99100, tacc(ob4) 0.95700, tacc(ob5) 0.97400, 6.56 secs\n",
      "\u001b[1m---- Epoch 10/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.53993, triplet_loss 0.47364, c_loss 0.13375, hs_loss 0.24890, cs_loss 0.60483, cacc 0.94872, hsacc 0.90400, csacc 0.76468, chstimgn_loss 0.34930, chestimg_macro_f1 0.91028, 191.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94700, tacc(al2) 0.82700, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88500, tacc(ob3) 0.99000, tacc(ob4) 0.95600, tacc(ob5) 0.97500, 6.65 secs\n",
      "\u001b[1m---- Epoch 11/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.54484, triplet_loss 0.47318, c_loss 0.12916, hs_loss 0.26522, cs_loss 0.60755, cacc 0.94864, hsacc 0.90244, csacc 0.76344, chstimgn_loss 0.35213, chestimg_macro_f1 0.91126, 190.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.82600, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88300, tacc(ob3) 0.99100, tacc(ob4) 0.95700, tacc(ob5) 0.97500, 6.57 secs\n",
      "\u001b[1m---- Epoch 12/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.53947, triplet_loss 0.47316, c_loss 0.12045, hs_loss 0.24769, cs_loss 0.61076, cacc 0.95088, hsacc 0.90260, csacc 0.75988, chstimgn_loss 0.35291, chestimg_macro_f1 0.90945, 185.92 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.82500, tacc(ob0) 0.99500, tacc(ob1) 0.97600, tacc(ob2) 0.88200, tacc(ob3) 0.99100, tacc(ob4) 0.95700, tacc(ob5) 0.97600, 6.61 secs\n",
      "\u001b[1m---- Epoch 13/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.59467, triplet_loss 0.47484, c_loss 0.16651, hs_loss 0.29469, cs_loss 0.68286, cacc 0.94064, hsacc 0.89004, csacc 0.73792, chstimgn_loss 0.37989, chestimg_macro_f1 0.89432, 187.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94000, tacc(al2) 0.81500, tacc(ob0) 0.99500, tacc(ob1) 0.97400, tacc(ob2) 0.88700, tacc(ob3) 0.98800, tacc(ob4) 0.95600, tacc(ob5) 0.96600, 6.67 secs\n",
      "\u001b[1m---- Epoch 14/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.58086, triplet_loss 0.47485, c_loss 0.14912, hs_loss 0.28250, cs_loss 0.66239, cacc 0.94412, hsacc 0.89548, csacc 0.74540, chstimgn_loss 0.37729, chestimg_macro_f1 0.89715, 176.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94400, tacc(al2) 0.81700, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.88700, tacc(ob3) 0.98700, tacc(ob4) 0.95300, tacc(ob5) 0.96500, 6.74 secs\n",
      "\u001b[1m---- Epoch 15/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.55746, triplet_loss 0.47328, c_loss 0.15270, hs_loss 0.26978, cs_loss 0.61385, cacc 0.94280, hsacc 0.89660, csacc 0.75492, chstimgn_loss 0.36012, chestimg_macro_f1 0.90448, 193.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94200, tacc(al2) 0.81800, tacc(ob0) 0.99700, tacc(ob1) 0.97600, tacc(ob2) 0.88200, tacc(ob3) 0.98500, tacc(ob4) 0.96100, tacc(ob5) 0.96500, 6.69 secs\n",
      "\u001b[1m---- Epoch 16/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.54859, triplet_loss 0.47295, c_loss 0.12872, hs_loss 0.25940, cs_loss 0.62659, cacc 0.94876, hsacc 0.90228, csacc 0.75560, chstimgn_loss 0.35335, chestimg_macro_f1 0.90842, 192.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.81200, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88600, tacc(ob3) 0.98700, tacc(ob4) 0.96100, tacc(ob5) 0.96800, 6.64 secs\n",
      "\u001b[1m---- Epoch 17/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.54286, triplet_loss 0.47089, c_loss 0.13969, hs_loss 0.25924, cs_loss 0.61468, cacc 0.94600, hsacc 0.90224, csacc 0.76504, chstimgn_loss 0.34347, chestimg_macro_f1 0.91020, 192.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94700, tacc(al2) 0.81900, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.88800, tacc(ob3) 0.98700, tacc(ob4) 0.96100, tacc(ob5) 0.96900, 6.60 secs\n",
      "\u001b[1m---- Epoch 18/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53946, triplet_loss 0.47271, c_loss 0.13676, hs_loss 0.25202, cs_loss 0.59939, cacc 0.94980, hsacc 0.90484, csacc 0.76988, chstimgn_loss 0.34848, chestimg_macro_f1 0.90921, 189.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.82000, tacc(ob0) 0.99700, tacc(ob1) 0.97400, tacc(ob2) 0.88400, tacc(ob3) 0.98500, tacc(ob4) 0.96100, tacc(ob5) 0.97000, 6.61 secs\n",
      "\u001b[1m---- Epoch 19/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.53950, triplet_loss 0.47187, c_loss 0.13231, hs_loss 0.26139, cs_loss 0.59765, cacc 0.94820, hsacc 0.89952, csacc 0.76536, chstimgn_loss 0.34740, chestimg_macro_f1 0.90919, 191.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.81900, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.88400, tacc(ob3) 0.98600, tacc(ob4) 0.96200, tacc(ob5) 0.97000, 6.70 secs\n",
      "\u001b[1m---- Epoch 20/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.53868, triplet_loss 0.47287, c_loss 0.12582, hs_loss 0.25023, cs_loss 0.62192, cacc 0.95004, hsacc 0.89960, csacc 0.76144, chstimgn_loss 0.34195, chestimg_macro_f1 0.91276, 192.99 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94500, tacc(al2) 0.81700, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.88300, tacc(ob3) 0.98600, tacc(ob4) 0.96100, tacc(ob5) 0.96700, 6.73 secs\n",
      "\u001b[1m---- Epoch 21/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.58907, triplet_loss 0.47458, c_loss 0.15500, hs_loss 0.28399, cs_loss 0.68649, cacc 0.94060, hsacc 0.89264, csacc 0.73476, chstimgn_loss 0.37812, chestimg_macro_f1 0.89550, 192.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.82100, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.89000, tacc(ob3) 0.98600, tacc(ob4) 0.96400, tacc(ob5) 0.96500, 6.60 secs\n",
      "\u001b[1m---- Epoch 22/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.57248, triplet_loss 0.47406, c_loss 0.15183, hs_loss 0.27835, cs_loss 0.65460, cacc 0.94220, hsacc 0.89276, csacc 0.74580, chstimgn_loss 0.36554, chestimg_macro_f1 0.89982, 191.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.82500, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.89000, tacc(ob3) 0.99000, tacc(ob4) 0.95900, tacc(ob5) 0.96600, 6.69 secs\n",
      "\u001b[1m---- Epoch 23/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.55191, triplet_loss 0.47191, c_loss 0.12911, hs_loss 0.26766, cs_loss 0.63738, cacc 0.94456, hsacc 0.89820, csacc 0.75336, chstimgn_loss 0.35079, chestimg_macro_f1 0.90746, 190.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94600, tacc(al2) 0.83000, tacc(ob0) 0.99700, tacc(ob1) 0.97500, tacc(ob2) 0.89000, tacc(ob3) 0.98600, tacc(ob4) 0.96800, tacc(ob5) 0.96500, 6.70 secs\n",
      "\u001b[1m---- Epoch 24/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.54136, triplet_loss 0.47255, c_loss 0.12801, hs_loss 0.25058, cs_loss 0.62450, cacc 0.94856, hsacc 0.90420, csacc 0.76076, chstimgn_loss 0.34490, chestimg_macro_f1 0.90880, 190.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.82400, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.88600, tacc(ob3) 0.98600, tacc(ob4) 0.96500, tacc(ob5) 0.97200, 6.65 secs\n",
      "\u001b[1m---- Epoch 25/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.53895, triplet_loss 0.47315, c_loss 0.12365, hs_loss 0.24567, cs_loss 0.61907, cacc 0.94672, hsacc 0.90504, csacc 0.75800, chstimgn_loss 0.34714, chestimg_macro_f1 0.90854, 190.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.82600, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.88500, tacc(ob3) 0.98600, tacc(ob4) 0.96400, tacc(ob5) 0.96800, 6.63 secs\n",
      "\u001b[1m---- Epoch 26/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53482, triplet_loss 0.47248, c_loss 0.12885, hs_loss 0.25028, cs_loss 0.60746, cacc 0.94820, hsacc 0.90500, csacc 0.76548, chstimgn_loss 0.34011, chestimg_macro_f1 0.91154, 189.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94600, tacc(al2) 0.82700, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88500, tacc(ob3) 0.98700, tacc(ob4) 0.96500, tacc(ob5) 0.96800, 6.67 secs\n",
      "\u001b[1m---- Epoch 27/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.52917, triplet_loss 0.47184, c_loss 0.12579, hs_loss 0.24762, cs_loss 0.59315, cacc 0.94796, hsacc 0.90240, csacc 0.76816, chstimgn_loss 0.33913, chestimg_macro_f1 0.91254, 187.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94600, tacc(al2) 0.82700, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88400, tacc(ob3) 0.98600, tacc(ob4) 0.96400, tacc(ob5) 0.96800, 6.72 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 28/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.53295, triplet_loss 0.47082, c_loss 0.12585, hs_loss 0.25224, cs_loss 0.61038, cacc 0.94736, hsacc 0.90444, csacc 0.76176, chstimgn_loss 0.33626, chestimg_macro_f1 0.91477, 186.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94500, tacc(al2) 0.82700, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88300, tacc(ob3) 0.98600, tacc(ob4) 0.96400, tacc(ob5) 0.96800, 6.74 secs\n",
      "\u001b[1m---- Epoch 29/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.59187, triplet_loss 0.47540, c_loss 0.16047, hs_loss 0.29019, cs_loss 0.68434, cacc 0.93824, hsacc 0.88852, csacc 0.73944, chstimgn_loss 0.37855, chestimg_macro_f1 0.89442, 181.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98300, tacc(al1) 0.94300, tacc(al2) 0.80300, tacc(ob0) 0.99700, tacc(ob1) 0.97500, tacc(ob2) 0.88600, tacc(ob3) 0.98400, tacc(ob4) 0.96600, tacc(ob5) 0.96900, 6.78 secs\n",
      "\u001b[1m---- Epoch 30/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.56712, triplet_loss 0.47856, c_loss 0.13498, hs_loss 0.27064, cs_loss 0.66505, cacc 0.94420, hsacc 0.89444, csacc 0.74172, chstimgn_loss 0.35963, chestimg_macro_f1 0.90281, 181.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.95000, tacc(al2) 0.81500, tacc(ob0) 0.99300, tacc(ob1) 0.98000, tacc(ob2) 0.89100, tacc(ob3) 0.98700, tacc(ob4) 0.95800, tacc(ob5) 0.96500, 6.69 secs\n",
      "\u001b[1m---- Epoch 31/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.55311, triplet_loss 0.47540, c_loss 0.14450, hs_loss 0.26339, cs_loss 0.63282, cacc 0.94460, hsacc 0.89860, csacc 0.75084, chstimgn_loss 0.34817, chestimg_macro_f1 0.90826, 179.65 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94700, tacc(al2) 0.81300, tacc(ob0) 0.99200, tacc(ob1) 0.97700, tacc(ob2) 0.88400, tacc(ob3) 0.98600, tacc(ob4) 0.96000, tacc(ob5) 0.96500, 6.71 secs\n",
      "\u001b[1m---- Epoch 32/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.54354, triplet_loss 0.47374, c_loss 0.13519, hs_loss 0.25648, cs_loss 0.61813, cacc 0.94560, hsacc 0.89924, csacc 0.76008, chstimgn_loss 0.34530, chestimg_macro_f1 0.90910, 192.04 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94600, tacc(al2) 0.81900, tacc(ob0) 0.99300, tacc(ob1) 0.97800, tacc(ob2) 0.88400, tacc(ob3) 0.98700, tacc(ob4) 0.96200, tacc(ob5) 0.96900, 6.65 secs\n",
      "\u001b[1m---- Epoch 33/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.53660, triplet_loss 0.47353, c_loss 0.13110, hs_loss 0.25024, cs_loss 0.60516, cacc 0.94792, hsacc 0.90628, csacc 0.76260, chstimgn_loss 0.34318, chestimg_macro_f1 0.90850, 191.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94600, tacc(al2) 0.82300, tacc(ob0) 0.99200, tacc(ob1) 0.97500, tacc(ob2) 0.88700, tacc(ob3) 0.98700, tacc(ob4) 0.95900, tacc(ob5) 0.96900, 6.71 secs\n",
      "\u001b[1m---- Epoch 34/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53479, triplet_loss 0.47191, c_loss 0.12568, hs_loss 0.24352, cs_loss 0.61574, cacc 0.94700, hsacc 0.90360, csacc 0.75916, chstimgn_loss 0.34115, chestimg_macro_f1 0.91092, 190.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94500, tacc(al2) 0.81800, tacc(ob0) 0.99200, tacc(ob1) 0.97700, tacc(ob2) 0.88800, tacc(ob3) 0.98700, tacc(ob4) 0.96000, tacc(ob5) 0.96900, 6.75 secs\n",
      "\u001b[1m---- Epoch 35/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.53198, triplet_loss 0.47314, c_loss 0.13216, hs_loss 0.24790, cs_loss 0.59615, cacc 0.94736, hsacc 0.90172, csacc 0.76796, chstimgn_loss 0.33929, chestimg_macro_f1 0.91141, 190.42 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94400, tacc(al2) 0.82100, tacc(ob0) 0.99200, tacc(ob1) 0.97700, tacc(ob2) 0.88500, tacc(ob3) 0.98700, tacc(ob4) 0.96000, tacc(ob5) 0.96900, 6.63 secs\n",
      "\u001b[1m---- Epoch 36/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.53056, triplet_loss 0.47122, c_loss 0.12341, hs_loss 0.25193, cs_loss 0.60832, cacc 0.95000, hsacc 0.90332, csacc 0.76292, chstimgn_loss 0.33368, chestimg_macro_f1 0.91352, 187.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94400, tacc(al2) 0.82100, tacc(ob0) 0.99100, tacc(ob1) 0.97700, tacc(ob2) 0.88500, tacc(ob3) 0.98700, tacc(ob4) 0.96100, tacc(ob5) 0.96900, 6.73 secs\n",
      "\u001b[1m---- Epoch 37/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.58871, triplet_loss 0.47405, c_loss 0.15695, hs_loss 0.29407, cs_loss 0.68766, cacc 0.94232, hsacc 0.88632, csacc 0.73540, chstimgn_loss 0.37106, chestimg_macro_f1 0.89669, 189.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94600, tacc(al2) 0.82300, tacc(ob0) 0.99400, tacc(ob1) 0.97700, tacc(ob2) 0.88500, tacc(ob3) 0.98600, tacc(ob4) 0.95900, tacc(ob5) 0.97100, 6.64 secs\n",
      "\u001b[1m---- Epoch 38/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.57478, triplet_loss 0.47286, c_loss 0.15440, hs_loss 0.28138, cs_loss 0.67256, cacc 0.94280, hsacc 0.89256, csacc 0.73940, chstimgn_loss 0.35896, chestimg_macro_f1 0.90198, 173.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94300, tacc(al2) 0.82300, tacc(ob0) 0.99300, tacc(ob1) 0.97500, tacc(ob2) 0.88400, tacc(ob3) 0.98200, tacc(ob4) 0.96200, tacc(ob5) 0.97100, 6.68 secs\n",
      "\u001b[1m---- Epoch 39/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.54736, triplet_loss 0.47401, c_loss 0.12969, hs_loss 0.26707, cs_loss 0.63311, cacc 0.94300, hsacc 0.89660, csacc 0.75420, chstimgn_loss 0.34278, chestimg_macro_f1 0.90887, 188.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94500, tacc(al2) 0.83100, tacc(ob0) 0.99300, tacc(ob1) 0.97600, tacc(ob2) 0.88700, tacc(ob3) 0.98100, tacc(ob4) 0.96100, tacc(ob5) 0.97300, 6.82 secs\n",
      "\u001b[1m---- Epoch 40/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.53834, triplet_loss 0.47171, c_loss 0.12014, hs_loss 0.26789, cs_loss 0.61978, cacc 0.94736, hsacc 0.90200, csacc 0.75764, chstimgn_loss 0.33692, chestimg_macro_f1 0.90993, 194.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94500, tacc(al2) 0.82800, tacc(ob0) 0.99300, tacc(ob1) 0.97200, tacc(ob2) 0.89300, tacc(ob3) 0.98300, tacc(ob4) 0.96600, tacc(ob5) 0.97200, 6.63 secs\n",
      "\u001b[1m---- Epoch 41/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.53249, triplet_loss 0.47073, c_loss 0.13418, hs_loss 0.24292, cs_loss 0.60623, cacc 0.95000, hsacc 0.90544, csacc 0.76288, chstimgn_loss 0.33794, chestimg_macro_f1 0.91113, 188.29 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94600, tacc(al2) 0.82600, tacc(ob0) 0.99300, tacc(ob1) 0.97500, tacc(ob2) 0.89000, tacc(ob3) 0.98200, tacc(ob4) 0.95900, tacc(ob5) 0.97100, 6.66 secs\n",
      "\u001b[1m---- Epoch 42/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.52961, triplet_loss 0.47159, c_loss 0.12509, hs_loss 0.25123, cs_loss 0.60162, cacc 0.94936, hsacc 0.90356, csacc 0.76292, chstimgn_loss 0.33446, chestimg_macro_f1 0.91420, 191.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.82700, tacc(ob0) 0.99300, tacc(ob1) 0.97400, tacc(ob2) 0.88800, tacc(ob3) 0.98100, tacc(ob4) 0.95900, tacc(ob5) 0.97300, 6.67 secs\n",
      "\u001b[1m---- Epoch 43/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.52627, triplet_loss 0.47210, c_loss 0.11258, hs_loss 0.25674, cs_loss 0.59567, cacc 0.95332, hsacc 0.90460, csacc 0.76824, chstimgn_loss 0.33400, chestimg_macro_f1 0.91184, 190.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.82900, tacc(ob0) 0.99300, tacc(ob1) 0.97300, tacc(ob2) 0.88900, tacc(ob3) 0.98200, tacc(ob4) 0.95900, tacc(ob5) 0.97300, 6.72 secs\n",
      "\u001b[1m---- Epoch 44/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.53018, triplet_loss 0.47128, c_loss 0.13477, hs_loss 0.25108, cs_loss 0.60122, cacc 0.94804, hsacc 0.90320, csacc 0.76464, chstimgn_loss 0.33118, chestimg_macro_f1 0.91354, 190.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.82900, tacc(ob0) 0.99300, tacc(ob1) 0.97300, tacc(ob2) 0.88900, tacc(ob3) 0.98200, tacc(ob4) 0.96000, tacc(ob5) 0.97300, 6.60 secs\n",
      "\u001b[1m---- Epoch 45/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.57964, triplet_loss 0.47413, c_loss 0.15661, hs_loss 0.29045, cs_loss 0.67432, cacc 0.93676, hsacc 0.88744, csacc 0.73732, chstimgn_loss 0.36153, chestimg_macro_f1 0.90026, 187.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94900, tacc(al2) 0.81500, tacc(ob0) 0.99400, tacc(ob1) 0.97400, tacc(ob2) 0.88400, tacc(ob3) 0.98700, tacc(ob4) 0.96500, tacc(ob5) 0.97800, 6.71 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 46/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.57650, triplet_loss 0.47320, c_loss 0.15280, hs_loss 0.28488, cs_loss 0.67987, cacc 0.94204, hsacc 0.89172, csacc 0.73780, chstimgn_loss 0.35763, chestimg_macro_f1 0.90090, 192.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94200, tacc(al2) 0.84300, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.88100, tacc(ob3) 0.98500, tacc(ob4) 0.96200, tacc(ob5) 0.97500, 6.66 secs\n",
      "\u001b[1m---- Epoch 47/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.55291, triplet_loss 0.47254, c_loss 0.14548, hs_loss 0.27378, cs_loss 0.63074, cacc 0.94288, hsacc 0.89864, csacc 0.75748, chstimgn_loss 0.34454, chestimg_macro_f1 0.90763, 194.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98500, tacc(al1) 0.94200, tacc(al2) 0.83400, tacc(ob0) 0.99500, tacc(ob1) 0.97600, tacc(ob2) 0.87800, tacc(ob3) 0.98500, tacc(ob4) 0.96100, tacc(ob5) 0.97600, 6.62 secs\n",
      "\u001b[1m---- Epoch 48/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.53869, triplet_loss 0.47211, c_loss 0.13848, hs_loss 0.26596, cs_loss 0.60231, cacc 0.94448, hsacc 0.89980, csacc 0.76332, chstimgn_loss 0.33795, chestimg_macro_f1 0.91043, 193.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94300, tacc(al2) 0.82200, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.88000, tacc(ob3) 0.98600, tacc(ob4) 0.95700, tacc(ob5) 0.97800, 6.66 secs\n",
      "\u001b[1m---- Epoch 49/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.53360, triplet_loss 0.47104, c_loss 0.14699, hs_loss 0.25133, cs_loss 0.60042, cacc 0.94596, hsacc 0.90372, csacc 0.76648, chstimgn_loss 0.33232, chestimg_macro_f1 0.91262, 193.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98400, tacc(al1) 0.94300, tacc(al2) 0.82400, tacc(ob0) 0.99600, tacc(ob1) 0.97800, tacc(ob2) 0.88500, tacc(ob3) 0.98700, tacc(ob4) 0.95900, tacc(ob5) 0.97800, 6.63 secs\n",
      "\u001b[1m---- Epoch 50/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.52906, triplet_loss 0.47082, c_loss 0.13079, hs_loss 0.25467, cs_loss 0.60715, cacc 0.94900, hsacc 0.90264, csacc 0.76264, chstimgn_loss 0.32640, chestimg_macro_f1 0.91660, 192.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94400, tacc(al2) 0.81800, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.87900, tacc(ob3) 0.98600, tacc(ob4) 0.95800, tacc(ob5) 0.97700, 6.69 secs\n",
      "\u001b[1m---- Epoch 51/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.52278, triplet_loss 0.46999, c_loss 0.12930, hs_loss 0.25059, cs_loss 0.59015, cacc 0.95004, hsacc 0.90032, csacc 0.76820, chstimgn_loss 0.32554, chestimg_macro_f1 0.91455, 186.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94400, tacc(al2) 0.81700, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.87900, tacc(ob3) 0.98500, tacc(ob4) 0.95800, tacc(ob5) 0.97800, 6.59 secs\n",
      "\u001b[1m---- Epoch 52/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.52334, triplet_loss 0.47133, c_loss 0.13134, hs_loss 0.23814, cs_loss 0.60330, cacc 0.94576, hsacc 0.90548, csacc 0.76648, chstimgn_loss 0.32462, chestimg_macro_f1 0.91436, 192.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94400, tacc(al2) 0.81800, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.87900, tacc(ob3) 0.98500, tacc(ob4) 0.95800, tacc(ob5) 0.97600, 6.70 secs\n",
      "\u001b[1m---- Epoch 53/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.58072, triplet_loss 0.47375, c_loss 0.15978, hs_loss 0.28623, cs_loss 0.68580, cacc 0.93884, hsacc 0.88848, csacc 0.73760, chstimgn_loss 0.35866, chestimg_macro_f1 0.89905, 189.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.80300, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.88000, tacc(ob3) 0.98500, tacc(ob4) 0.96300, tacc(ob5) 0.97100, 6.69 secs\n",
      "\u001b[1m---- Epoch 54/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.56561, triplet_loss 0.47477, c_loss 0.13850, hs_loss 0.27591, cs_loss 0.67681, cacc 0.94640, hsacc 0.89304, csacc 0.73800, chstimgn_loss 0.34824, chestimg_macro_f1 0.90411, 188.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.80500, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.88200, tacc(ob3) 0.98900, tacc(ob4) 0.95700, tacc(ob5) 0.97700, 6.75 secs\n",
      "\u001b[1m---- Epoch 55/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.53605, triplet_loss 0.47153, c_loss 0.12238, hs_loss 0.25995, cs_loss 0.62494, cacc 0.94940, hsacc 0.90208, csacc 0.75796, chstimgn_loss 0.33270, chestimg_macro_f1 0.91058, 192.25 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94600, tacc(al2) 0.82300, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.88600, tacc(ob3) 0.98900, tacc(ob4) 0.95800, tacc(ob5) 0.97700, 6.65 secs\n",
      "\u001b[1m---- Epoch 56/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.53263, triplet_loss 0.47330, c_loss 0.13413, hs_loss 0.25299, cs_loss 0.61135, cacc 0.94632, hsacc 0.90028, csacc 0.75916, chstimgn_loss 0.32939, chestimg_macro_f1 0.91198, 191.35 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94700, tacc(al2) 0.82400, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.88400, tacc(ob3) 0.98800, tacc(ob4) 0.96300, tacc(ob5) 0.97500, 6.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_56_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9552.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 57/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.52524, triplet_loss 0.47147, c_loss 0.13045, hs_loss 0.25146, cs_loss 0.59471, cacc 0.94920, hsacc 0.90192, csacc 0.76788, chstimgn_loss 0.32643, chestimg_macro_f1 0.91391, 188.17 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95000, tacc(al2) 0.81600, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.88300, tacc(ob3) 0.98700, tacc(ob4) 0.96100, tacc(ob5) 0.97700, 6.68 secs\n",
      "\u001b[1m---- Epoch 58/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.52290, triplet_loss 0.47092, c_loss 0.13448, hs_loss 0.25647, cs_loss 0.58857, cacc 0.94856, hsacc 0.90596, csacc 0.76532, chstimgn_loss 0.32059, chestimg_macro_f1 0.91557, 190.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94800, tacc(al2) 0.82000, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.88400, tacc(ob3) 0.98800, tacc(ob4) 0.96300, tacc(ob5) 0.97700, 6.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_58_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9554.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 59/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.52113, triplet_loss 0.46948, c_loss 0.11913, hs_loss 0.24985, cs_loss 0.60341, cacc 0.95188, hsacc 0.90328, csacc 0.76528, chstimgn_loss 0.32132, chestimg_macro_f1 0.91495, 189.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95000, tacc(al2) 0.82000, tacc(ob0) 0.99500, tacc(ob1) 0.98100, tacc(ob2) 0.88600, tacc(ob3) 0.98900, tacc(ob4) 0.96200, tacc(ob5) 0.97600, 6.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_59_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9556.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 60/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.52054, triplet_loss 0.47093, c_loss 0.12427, hs_loss 0.24164, cs_loss 0.59261, cacc 0.94932, hsacc 0.90556, csacc 0.76928, chstimgn_loss 0.32635, chestimg_macro_f1 0.91451, 192.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.94900, tacc(al2) 0.82000, tacc(ob0) 0.99500, tacc(ob1) 0.98000, tacc(ob2) 0.88500, tacc(ob3) 0.98900, tacc(ob4) 0.96100, tacc(ob5) 0.97600, 6.65 secs\n",
      "\u001b[1m---- Epoch 61/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.57633, triplet_loss 0.47293, c_loss 0.15163, hs_loss 0.29880, cs_loss 0.68507, cacc 0.94204, hsacc 0.88948, csacc 0.73764, chstimgn_loss 0.34843, chestimg_macro_f1 0.90272, 193.57 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94600, tacc(al2) 0.80700, tacc(ob0) 0.99200, tacc(ob1) 0.97800, tacc(ob2) 0.88100, tacc(ob3) 0.98900, tacc(ob4) 0.96100, tacc(ob5) 0.97600, 6.69 secs\n",
      "\u001b[1m---- Epoch 62/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.56732, triplet_loss 0.47205, c_loss 0.15085, hs_loss 0.28402, cs_loss 0.66808, cacc 0.94308, hsacc 0.89076, csacc 0.74108, chstimgn_loss 0.34714, chestimg_macro_f1 0.90367, 189.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95100, tacc(al2) 0.80700, tacc(ob0) 0.99300, tacc(ob1) 0.97700, tacc(ob2) 0.88000, tacc(ob3) 0.98800, tacc(ob4) 0.95500, tacc(ob5) 0.97800, 6.56 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 63/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.53793, triplet_loss 0.47460, c_loss 0.12648, hs_loss 0.25833, cs_loss 0.63805, cacc 0.94692, hsacc 0.89800, csacc 0.75084, chstimgn_loss 0.32713, chestimg_macro_f1 0.91240, 191.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95000, tacc(al2) 0.82900, tacc(ob0) 0.99400, tacc(ob1) 0.98200, tacc(ob2) 0.89000, tacc(ob3) 0.98500, tacc(ob4) 0.96100, tacc(ob5) 0.97900, 6.68 secs\n",
      "\u001b[1m---- Epoch 64/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.53199, triplet_loss 0.47316, c_loss 0.13455, hs_loss 0.26536, cs_loss 0.60810, cacc 0.94468, hsacc 0.89496, csacc 0.76272, chstimgn_loss 0.32340, chestimg_macro_f1 0.91286, 190.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.95000, tacc(al2) 0.82300, tacc(ob0) 0.99400, tacc(ob1) 0.98000, tacc(ob2) 0.88700, tacc(ob3) 0.98600, tacc(ob4) 0.95800, tacc(ob5) 0.98000, 6.67 secs\n",
      "\u001b[1m---- Epoch 65/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.52449, triplet_loss 0.47267, c_loss 0.12080, hs_loss 0.24877, cs_loss 0.61258, cacc 0.94940, hsacc 0.90288, csacc 0.75948, chstimgn_loss 0.32156, chestimg_macro_f1 0.91494, 189.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94900, tacc(al2) 0.82600, tacc(ob0) 0.99400, tacc(ob1) 0.98300, tacc(ob2) 0.88300, tacc(ob3) 0.98700, tacc(ob4) 0.95600, tacc(ob5) 0.97600, 6.78 secs\n",
      "\u001b[1m---- Epoch 66/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.52246, triplet_loss 0.47224, c_loss 0.13696, hs_loss 0.25390, cs_loss 0.59535, cacc 0.94636, hsacc 0.90072, csacc 0.76472, chstimgn_loss 0.31569, chestimg_macro_f1 0.91582, 193.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.82400, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.88300, tacc(ob3) 0.98800, tacc(ob4) 0.95900, tacc(ob5) 0.97700, 6.64 secs\n",
      "\u001b[1m---- Epoch 67/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.52164, triplet_loss 0.47113, c_loss 0.12628, hs_loss 0.25154, cs_loss 0.59923, cacc 0.95080, hsacc 0.90244, csacc 0.76652, chstimgn_loss 0.31919, chestimg_macro_f1 0.91583, 194.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94900, tacc(al2) 0.82700, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.88300, tacc(ob3) 0.98800, tacc(ob4) 0.95900, tacc(ob5) 0.97600, 6.60 secs\n",
      "\u001b[1m---- Epoch 68/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.56723, triplet_loss 0.47470, c_loss 0.14518, hs_loss 0.28766, cs_loss 0.67696, cacc 0.94196, hsacc 0.89464, csacc 0.73768, chstimgn_loss 0.34220, chestimg_macro_f1 0.90383, 193.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.82400, tacc(ob0) 0.99600, tacc(ob1) 0.97300, tacc(ob2) 0.89000, tacc(ob3) 0.98900, tacc(ob4) 0.96300, tacc(ob5) 0.97000, 6.80 secs\n",
      "\u001b[1m---- Epoch 78/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.55931, triplet_loss 0.47578, c_loss 0.14509, hs_loss 0.28440, cs_loss 0.66621, cacc 0.94256, hsacc 0.89228, csacc 0.74360, chstimgn_loss 0.33289, chestimg_macro_f1 0.90689, 191.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94800, tacc(al2) 0.84000, tacc(ob0) 0.99700, tacc(ob1) 0.97500, tacc(ob2) 0.87500, tacc(ob3) 0.98600, tacc(ob4) 0.96300, tacc(ob5) 0.97700, 6.82 secs\n",
      "\u001b[1m---- Epoch 79/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.53761, triplet_loss 0.47290, c_loss 0.13715, hs_loss 0.25213, cs_loss 0.63171, cacc 0.94460, hsacc 0.90020, csacc 0.75128, chstimgn_loss 0.32827, chestimg_macro_f1 0.91032, 192.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95000, tacc(al2) 0.84200, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.87900, tacc(ob3) 0.98800, tacc(ob4) 0.95700, tacc(ob5) 0.98000, 6.73 secs\n",
      "\u001b[1m---- Epoch 80/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.51870, triplet_loss 0.47110, c_loss 0.12174, hs_loss 0.24700, cs_loss 0.60135, cacc 0.94640, hsacc 0.90260, csacc 0.76424, chstimgn_loss 0.31680, chestimg_macro_f1 0.91672, 191.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95400, tacc(al2) 0.84200, tacc(ob0) 0.99700, tacc(ob1) 0.97400, tacc(ob2) 0.88300, tacc(ob3) 0.98600, tacc(ob4) 0.95700, tacc(ob5) 0.97500, 6.66 secs\n",
      "\u001b[1m---- Epoch 81/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.51874, triplet_loss 0.47106, c_loss 0.12052, hs_loss 0.24943, cs_loss 0.60552, cacc 0.95004, hsacc 0.90288, csacc 0.76264, chstimgn_loss 0.31422, chestimg_macro_f1 0.91656, 191.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.95400, tacc(al2) 0.83700, tacc(ob0) 0.99700, tacc(ob1) 0.97700, tacc(ob2) 0.88000, tacc(ob3) 0.98600, tacc(ob4) 0.96000, tacc(ob5) 0.97800, 6.61 secs\n",
      "\u001b[1m---- Epoch 82/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.51812, triplet_loss 0.47228, c_loss 0.13147, hs_loss 0.24696, cs_loss 0.59614, cacc 0.94620, hsacc 0.90132, csacc 0.76600, chstimgn_loss 0.31282, chestimg_macro_f1 0.91699, 193.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95400, tacc(al2) 0.83800, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.87900, tacc(ob3) 0.98500, tacc(ob4) 0.95800, tacc(ob5) 0.97800, 6.64 secs\n",
      "\u001b[1m---- Epoch 83/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.51363, triplet_loss 0.47214, c_loss 0.12248, hs_loss 0.24933, cs_loss 0.59175, cacc 0.94944, hsacc 0.90400, csacc 0.76676, chstimgn_loss 0.30942, chestimg_macro_f1 0.91850, 192.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95500, tacc(al2) 0.83600, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.87900, tacc(ob3) 0.98700, tacc(ob4) 0.95700, tacc(ob5) 0.97800, 6.65 secs\n",
      "\u001b[1m---- Epoch 84/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.50964, triplet_loss 0.47238, c_loss 0.12536, hs_loss 0.24008, cs_loss 0.58231, cacc 0.94928, hsacc 0.90740, csacc 0.77228, chstimgn_loss 0.30922, chestimg_macro_f1 0.91875, 190.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95300, tacc(al2) 0.83600, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.87700, tacc(ob3) 0.98700, tacc(ob4) 0.95700, tacc(ob5) 0.97700, 6.64 secs\n",
      "\u001b[1m---- Epoch 85/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.56285, triplet_loss 0.47249, c_loss 0.15348, hs_loss 0.28260, cs_loss 0.66976, cacc 0.94016, hsacc 0.88924, csacc 0.74052, chstimgn_loss 0.33653, chestimg_macro_f1 0.90641, 183.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.93900, tacc(al2) 0.81500, tacc(ob0) 0.99300, tacc(ob1) 0.98200, tacc(ob2) 0.87600, tacc(ob3) 0.98800, tacc(ob4) 0.96100, tacc(ob5) 0.97400, 6.72 secs\n",
      "\u001b[1m---- Epoch 86/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.55557, triplet_loss 0.47194, c_loss 0.14311, hs_loss 0.28298, cs_loss 0.65183, cacc 0.94352, hsacc 0.89484, csacc 0.74988, chstimgn_loss 0.33621, chestimg_macro_f1 0.90517, 192.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99000, tacc(al1) 0.94700, tacc(al2) 0.82300, tacc(ob0) 0.99600, tacc(ob1) 0.98000, tacc(ob2) 0.88500, tacc(ob3) 0.98800, tacc(ob4) 0.96300, tacc(ob5) 0.97400, 6.68 secs\n",
      "\u001b[1m---- Epoch 87/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.53076, triplet_loss 0.47180, c_loss 0.13016, hs_loss 0.25579, cs_loss 0.63170, cacc 0.94680, hsacc 0.90124, csacc 0.75548, chstimgn_loss 0.31680, chestimg_macro_f1 0.91383, 192.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94600, tacc(al2) 0.82900, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.88200, tacc(ob3) 0.98900, tacc(ob4) 0.96100, tacc(ob5) 0.96800, 6.69 secs\n",
      "\u001b[1m---- Epoch 88/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.52143, triplet_loss 0.47295, c_loss 0.13140, hs_loss 0.25434, cs_loss 0.60801, cacc 0.94776, hsacc 0.90176, csacc 0.76364, chstimgn_loss 0.30950, chestimg_macro_f1 0.91649, 193.25 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94300, tacc(al2) 0.83100, tacc(ob0) 0.99500, tacc(ob1) 0.97900, tacc(ob2) 0.88500, tacc(ob3) 0.98900, tacc(ob4) 0.96500, tacc(ob5) 0.97300, 6.63 secs\n",
      "\u001b[1m---- Epoch 89/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.52572, triplet_loss 0.47080, c_loss 0.13274, hs_loss 0.26118, cs_loss 0.60989, cacc 0.94708, hsacc 0.89824, csacc 0.76168, chstimgn_loss 0.31414, chestimg_macro_f1 0.91511, 192.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94600, tacc(al2) 0.82900, tacc(ob0) 0.99700, tacc(ob1) 0.97900, tacc(ob2) 0.88900, tacc(ob3) 0.98800, tacc(ob4) 0.96500, tacc(ob5) 0.97200, 6.65 secs\n",
      "\u001b[1m---- Epoch 90/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.50807, triplet_loss 0.47103, c_loss 0.12608, hs_loss 0.23879, cs_loss 0.58689, cacc 0.94816, hsacc 0.90324, csacc 0.76916, chstimgn_loss 0.30475, chestimg_macro_f1 0.91843, 183.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94600, tacc(al2) 0.82500, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.88600, tacc(ob3) 0.98800, tacc(ob4) 0.96800, tacc(ob5) 0.97200, 6.70 secs\n",
      "\u001b[1m---- Epoch 91/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.51016, triplet_loss 0.47001, c_loss 0.12117, hs_loss 0.24795, cs_loss 0.59147, cacc 0.95236, hsacc 0.90488, csacc 0.76724, chstimgn_loss 0.30502, chestimg_macro_f1 0.91816, 191.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94600, tacc(al2) 0.82400, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.88600, tacc(ob3) 0.98900, tacc(ob4) 0.96700, tacc(ob5) 0.97200, 6.69 secs\n",
      "\u001b[1m---- Epoch 92/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.50841, triplet_loss 0.47056, c_loss 0.12920, hs_loss 0.24364, cs_loss 0.58293, cacc 0.94860, hsacc 0.90480, csacc 0.77236, chstimgn_loss 0.30365, chestimg_macro_f1 0.91917, 190.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94500, tacc(al2) 0.82500, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.88700, tacc(ob3) 0.98800, tacc(ob4) 0.96600, tacc(ob5) 0.97200, 6.62 secs\n",
      "\u001b[1m---- Epoch 93/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.56531, triplet_loss 0.47329, c_loss 0.15388, hs_loss 0.29155, cs_loss 0.66470, cacc 0.93904, hsacc 0.88576, csacc 0.74224, chstimgn_loss 0.33890, chestimg_macro_f1 0.90304, 191.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94900, tacc(al2) 0.82100, tacc(ob0) 0.99700, tacc(ob1) 0.97700, tacc(ob2) 0.88100, tacc(ob3) 0.98700, tacc(ob4) 0.95300, tacc(ob5) 0.97500, 6.71 secs\n",
      "\u001b[1m---- Epoch 94/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.55290, triplet_loss 0.47214, c_loss 0.14653, hs_loss 0.27682, cs_loss 0.66035, cacc 0.94352, hsacc 0.89188, csacc 0.74368, chstimgn_loss 0.32788, chestimg_macro_f1 0.90893, 192.25 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94500, tacc(al2) 0.80900, tacc(ob0) 0.99800, tacc(ob1) 0.97200, tacc(ob2) 0.88700, tacc(ob3) 0.99000, tacc(ob4) 0.96000, tacc(ob5) 0.97400, 6.71 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 95/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.52396, triplet_loss 0.47271, c_loss 0.12673, hs_loss 0.25807, cs_loss 0.61179, cacc 0.94580, hsacc 0.90080, csacc 0.75784, chstimgn_loss 0.31327, chestimg_macro_f1 0.91296, 191.43 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94800, tacc(al2) 0.81200, tacc(ob0) 0.99800, tacc(ob1) 0.97700, tacc(ob2) 0.89300, tacc(ob3) 0.98900, tacc(ob4) 0.95800, tacc(ob5) 0.97700, 6.65 secs\n",
      "\u001b[1m---- Epoch 96/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.52517, triplet_loss 0.47068, c_loss 0.14387, hs_loss 0.25423, cs_loss 0.61667, cacc 0.94628, hsacc 0.89988, csacc 0.75896, chstimgn_loss 0.30761, chestimg_macro_f1 0.91735, 192.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94900, tacc(al2) 0.82000, tacc(ob0) 0.99800, tacc(ob1) 0.97600, tacc(ob2) 0.89300, tacc(ob3) 0.99000, tacc(ob4) 0.96100, tacc(ob5) 0.97400, 6.66 secs\n",
      "\u001b[1m---- Epoch 97/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.51198, triplet_loss 0.46964, c_loss 0.12644, hs_loss 0.24470, cs_loss 0.59600, cacc 0.94368, hsacc 0.90744, csacc 0.76544, chstimgn_loss 0.30558, chestimg_macro_f1 0.91793, 192.18 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.81900, tacc(ob0) 0.99700, tacc(ob1) 0.97700, tacc(ob2) 0.89300, tacc(ob3) 0.98900, tacc(ob4) 0.95900, tacc(ob5) 0.97700, 6.64 secs\n",
      "\u001b[1m---- Epoch 98/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.50172, triplet_loss 0.46945, c_loss 0.12371, hs_loss 0.23660, cs_loss 0.58281, cacc 0.94704, hsacc 0.91080, csacc 0.76808, chstimgn_loss 0.29715, chestimg_macro_f1 0.92081, 193.35 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95000, tacc(al2) 0.81900, tacc(ob0) 0.99700, tacc(ob1) 0.97700, tacc(ob2) 0.89500, tacc(ob3) 0.99000, tacc(ob4) 0.96100, tacc(ob5) 0.97500, 6.67 secs\n",
      "\u001b[1m---- Epoch 99/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.50362, triplet_loss 0.47051, c_loss 0.11810, hs_loss 0.23608, cs_loss 0.58680, cacc 0.94828, hsacc 0.90704, csacc 0.77180, chstimgn_loss 0.30149, chestimg_macro_f1 0.92083, 192.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.82000, tacc(ob0) 0.99800, tacc(ob1) 0.97500, tacc(ob2) 0.89600, tacc(ob3) 0.99000, tacc(ob4) 0.96100, tacc(ob5) 0.97700, 6.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_99_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9559.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 100/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.50954, triplet_loss 0.46886, c_loss 0.12904, hs_loss 0.24343, cs_loss 0.58935, cacc 0.94592, hsacc 0.90776, csacc 0.76996, chstimgn_loss 0.30374, chestimg_macro_f1 0.92063, 191.19 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95100, tacc(al2) 0.81900, tacc(ob0) 0.99800, tacc(ob1) 0.97600, tacc(ob2) 0.89300, tacc(ob3) 0.99000, tacc(ob4) 0.96200, tacc(ob5) 0.97700, 6.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_100_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9559.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 101/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.56493, triplet_loss 0.47341, c_loss 0.14411, hs_loss 0.29110, cs_loss 0.67672, cacc 0.94460, hsacc 0.88640, csacc 0.73440, chstimgn_loss 0.33719, chestimg_macro_f1 0.90258, 188.19 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95300, tacc(al2) 0.80800, tacc(ob0) 0.99400, tacc(ob1) 0.97600, tacc(ob2) 0.88400, tacc(ob3) 0.98200, tacc(ob4) 0.95900, tacc(ob5) 0.97400, 6.61 secs\n",
      "\u001b[1m---- Epoch 102/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.55175, triplet_loss 0.47278, c_loss 0.14643, hs_loss 0.27307, cs_loss 0.66039, cacc 0.94184, hsacc 0.89416, csacc 0.74576, chstimgn_loss 0.32717, chestimg_macro_f1 0.90613, 186.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94200, tacc(al2) 0.82500, tacc(ob0) 0.99600, tacc(ob1) 0.97600, tacc(ob2) 0.89100, tacc(ob3) 0.98900, tacc(ob4) 0.95700, tacc(ob5) 0.97400, 6.63 secs\n",
      "\u001b[1m---- Epoch 103/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.53615, triplet_loss 0.47244, c_loss 0.14280, hs_loss 0.26031, cs_loss 0.63706, cacc 0.94496, hsacc 0.90180, csacc 0.75148, chstimgn_loss 0.31600, chestimg_macro_f1 0.91204, 190.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94300, tacc(al2) 0.83500, tacc(ob0) 0.99500, tacc(ob1) 0.97800, tacc(ob2) 0.89500, tacc(ob3) 0.98800, tacc(ob4) 0.95900, tacc(ob5) 0.97300, 6.66 secs\n",
      "\u001b[1m---- Epoch 104/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.52044, triplet_loss 0.47068, c_loss 0.12764, hs_loss 0.25166, cs_loss 0.61110, cacc 0.94480, hsacc 0.90220, csacc 0.76296, chstimgn_loss 0.31035, chestimg_macro_f1 0.91573, 187.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.95000, tacc(al2) 0.82900, tacc(ob0) 0.99500, tacc(ob1) 0.97700, tacc(ob2) 0.89300, tacc(ob3) 0.98600, tacc(ob4) 0.95700, tacc(ob5) 0.97100, 6.77 secs\n",
      "\u001b[1m---- Epoch 105/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.50982, triplet_loss 0.46912, c_loss 0.11861, hs_loss 0.24623, cs_loss 0.59532, cacc 0.95076, hsacc 0.90568, csacc 0.76800, chstimgn_loss 0.30500, chestimg_macro_f1 0.91845, 185.88 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.83200, tacc(ob0) 0.99600, tacc(ob1) 0.97500, tacc(ob2) 0.89200, tacc(ob3) 0.98700, tacc(ob4) 0.95500, tacc(ob5) 0.97300, 6.63 secs\n",
      "\u001b[1m---- Epoch 106/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.50768, triplet_loss 0.46933, c_loss 0.12228, hs_loss 0.23852, cs_loss 0.59022, cacc 0.94924, hsacc 0.90744, csacc 0.76820, chstimgn_loss 0.30517, chestimg_macro_f1 0.91863, 192.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94800, tacc(al2) 0.83200, tacc(ob0) 0.99600, tacc(ob1) 0.97800, tacc(ob2) 0.89500, tacc(ob3) 0.98700, tacc(ob4) 0.95700, tacc(ob5) 0.97400, 6.63 secs\n",
      "\u001b[1m---- Epoch 107/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.50632, triplet_loss 0.47063, c_loss 0.11480, hs_loss 0.25637, cs_loss 0.58003, cacc 0.95064, hsacc 0.90304, csacc 0.77188, chstimgn_loss 0.30174, chestimg_macro_f1 0.91872, 189.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.82800, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.89300, tacc(ob3) 0.98700, tacc(ob4) 0.95700, tacc(ob5) 0.97300, 6.66 secs\n",
      "\u001b[1m---- Epoch 108/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.51033, triplet_loss 0.47064, c_loss 0.12372, hs_loss 0.24688, cs_loss 0.59391, cacc 0.94900, hsacc 0.90496, csacc 0.76684, chstimgn_loss 0.30309, chestimg_macro_f1 0.91968, 192.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94800, tacc(al2) 0.82600, tacc(ob0) 0.99600, tacc(ob1) 0.97700, tacc(ob2) 0.89300, tacc(ob3) 0.98700, tacc(ob4) 0.95700, tacc(ob5) 0.97200, 6.71 secs\n",
      "\u001b[1m---- Epoch 109/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.54974, triplet_loss 0.47427, c_loss 0.14249, hs_loss 0.27814, cs_loss 0.64887, cacc 0.94348, hsacc 0.88920, csacc 0.74788, chstimgn_loss 0.32760, chestimg_macro_f1 0.90561, 190.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.95100, tacc(al2) 0.82300, tacc(ob0) 0.99700, tacc(ob1) 0.97600, tacc(ob2) 0.89500, tacc(ob3) 0.98800, tacc(ob4) 0.96200, tacc(ob5) 0.96900, 6.77 secs\n",
      "\u001b[1m---- Epoch 110/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.54703, triplet_loss 0.47043, c_loss 0.14081, hs_loss 0.27552, cs_loss 0.65196, cacc 0.94428, hsacc 0.88960, csacc 0.74628, chstimgn_loss 0.32470, chestimg_macro_f1 0.90874, 192.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94700, tacc(al2) 0.82600, tacc(ob0) 0.99800, tacc(ob1) 0.98000, tacc(ob2) 0.89000, tacc(ob3) 0.98600, tacc(ob4) 0.95300, tacc(ob5) 0.97100, 6.63 secs\n",
      "\u001b[1m---- Epoch 111/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.52660, triplet_loss 0.47140, c_loss 0.13953, hs_loss 0.26312, cs_loss 0.60510, cacc 0.94484, hsacc 0.89812, csacc 0.76432, chstimgn_loss 0.31362, chestimg_macro_f1 0.91334, 191.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94400, tacc(al2) 0.82400, tacc(ob0) 0.99800, tacc(ob1) 0.97800, tacc(ob2) 0.89000, tacc(ob3) 0.98500, tacc(ob4) 0.95700, tacc(ob5) 0.96800, 6.67 secs\n",
      "\u001b[1m---- Epoch 112/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.52219, triplet_loss 0.47054, c_loss 0.14272, hs_loss 0.26161, cs_loss 0.60356, cacc 0.94644, hsacc 0.89872, csacc 0.76140, chstimgn_loss 0.30517, chestimg_macro_f1 0.91628, 191.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94400, tacc(al2) 0.82400, tacc(ob0) 0.99800, tacc(ob1) 0.97900, tacc(ob2) 0.88600, tacc(ob3) 0.98400, tacc(ob4) 0.95900, tacc(ob5) 0.97300, 6.67 secs\n",
      "\u001b[1m---- Epoch 113/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.51481, triplet_loss 0.47002, c_loss 0.14860, hs_loss 0.24375, cs_loss 0.59713, cacc 0.94712, hsacc 0.90532, csacc 0.76888, chstimgn_loss 0.29987, chestimg_macro_f1 0.91870, 188.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94400, tacc(al2) 0.82300, tacc(ob0) 0.99700, tacc(ob1) 0.97700, tacc(ob2) 0.89000, tacc(ob3) 0.98600, tacc(ob4) 0.95600, tacc(ob5) 0.96800, 6.69 secs\n",
      "\u001b[1m---- Epoch 114/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.50230, triplet_loss 0.46921, c_loss 0.11536, hs_loss 0.23943, cs_loss 0.59076, cacc 0.95016, hsacc 0.90808, csacc 0.76920, chstimgn_loss 0.29722, chestimg_macro_f1 0.92066, 190.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94500, tacc(al2) 0.82400, tacc(ob0) 0.99700, tacc(ob1) 0.97800, tacc(ob2) 0.88600, tacc(ob3) 0.98600, tacc(ob4) 0.95700, tacc(ob5) 0.96900, 6.69 secs\n",
      "\u001b[1m---- Epoch 115/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.50350, triplet_loss 0.47096, c_loss 0.12375, hs_loss 0.24765, cs_loss 0.58196, cacc 0.95100, hsacc 0.90344, csacc 0.77304, chstimgn_loss 0.29484, chestimg_macro_f1 0.92176, 189.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98700, tacc(al1) 0.94600, tacc(al2) 0.82700, tacc(ob0) 0.99700, tacc(ob1) 0.97800, tacc(ob2) 0.88700, tacc(ob3) 0.98600, tacc(ob4) 0.95600, tacc(ob5) 0.96800, 6.61 secs\n",
      "\u001b[1m---- Epoch 116/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.50094, triplet_loss 0.47064, c_loss 0.12300, hs_loss 0.24152, cs_loss 0.57817, cacc 0.95144, hsacc 0.90732, csacc 0.77452, chstimgn_loss 0.29522, chestimg_macro_f1 0.92124, 191.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.94600, tacc(al2) 0.82800, tacc(ob0) 0.99700, tacc(ob1) 0.97800, tacc(ob2) 0.88600, tacc(ob3) 0.98600, tacc(ob4) 0.95600, tacc(ob5) 0.96800, 6.65 secs\n",
      "\u001b[1m---- Epoch 117/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.54606, triplet_loss 0.47219, c_loss 0.13965, hs_loss 0.26359, cs_loss 0.64988, cacc 0.94352, hsacc 0.89600, csacc 0.74752, chstimgn_loss 0.32947, chestimg_macro_f1 0.90574, 182.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98800, tacc(al1) 0.95100, tacc(al2) 0.83300, tacc(ob0) 0.99600, tacc(ob1) 0.97400, tacc(ob2) 0.88900, tacc(ob3) 0.98800, tacc(ob4) 0.96000, tacc(ob5) 0.96700, 6.68 secs\n",
      "\u001b[1m---- Epoch 118/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000104) ...\n",
      "loss 0.54677, triplet_loss 0.47175, c_loss 0.13495, hs_loss 0.28112, cs_loss 0.65456, cacc 0.94336, hsacc 0.89020, csacc 0.74896, chstimgn_loss 0.32234, chestimg_macro_f1 0.90768, 191.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98900, tacc(al1) 0.94700, tacc(al2) 0.82900, tacc(ob0) 0.99400, tacc(ob1) 0.97400, tacc(ob2) 0.89700, tacc(ob3) 0.98500, tacc(ob4) 0.96100, tacc(ob5) 0.97000, 6.69 secs\n",
      "\u001b[1m---- Epoch 119/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.51900, triplet_loss 0.47112, c_loss 0.13161, hs_loss 0.25968, cs_loss 0.60277, cacc 0.94400, hsacc 0.90088, csacc 0.76792, chstimgn_loss 0.30542, chestimg_macro_f1 0.91679, 192.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98600, tacc(al1) 0.94800, tacc(al2) 0.82400, tacc(ob0) 0.99500, tacc(ob1) 0.97600, tacc(ob2) 0.89700, tacc(ob3) 0.98600, tacc(ob4) 0.96200, tacc(ob5) 0.97600, 6.72 secs\n",
      "\u001b[1m---- Epoch 120/120\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.51478, triplet_loss 0.46985, c_loss 0.12221, hs_loss 0.25506, cs_loss 0.60290, cacc 0.94992, hsacc 0.89920, csacc 0.76296, chstimgn_loss 0.30455, chestimg_macro_f1 0.91721, 193.45 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95300, tacc(al2) 0.82800, tacc(ob0) 0.99600, tacc(ob1) 0.97900, tacc(ob2) 0.89500, tacc(ob3) 0.98600, tacc(ob4) 0.95900, tacc(ob5) 0.97300, 6.67 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230728_075327_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 120 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(2842463,297669,1996654,2501000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 2., 1., 1., 2., 2.5]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--integrated_chest_imagenome_labels_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl\" \\\n",
    "--n_chest_imagenome_labels 74 \\\n",
    "--triplets_weight 1.0 \\\n",
    "--metadata_classification_weight 1.0 \\\n",
    "--chest_imagenome_classification_weight 2.0 \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb329b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230730_012705_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 60 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 50 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 8 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,2e-6,2e-4,8,2e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(3471872,297669,1996654,2502000,1000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [0.8, 1.6, 0.8], 'observations': [1., 1., 1., 1., 1.5, 1.5, 2., 2.]}\" \\\n",
    "--integrated_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).improved_comparison(6526297).jsonl\" \\\n",
    "--paraphrases_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "--integrated_chest_imagenome_labels_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl\" \\\n",
    "--n_chest_imagenome_labels 74 \\\n",
    "--triplets_weight 2.0 \\\n",
    "--metadata_classification_weight 1.0 \\\n",
    "--chest_imagenome_classification_weight 1.0 \\\n",
    "--dataset_name \"MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf97a4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'checkpoint_100_cacc+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)=0.9559.pt'\r\n",
      " metadata.json\r\n",
      " metrics_logs.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230730_012705_MIMIC-CXR(GPT3.5,GPT4,CXR-BERT,triplet_loss,ChestImaGenome)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc56205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_pickle\n",
    "\n",
    "tmp = load_pickle(\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_chest_imagenome_labels(6).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7099a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label_names', 'groups'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49fd44f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chest-imagenome'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['groups'][0]['extraction_method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81634686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2552490"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(g['sentences']) for g in tmp['groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf2de592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0613\n",
      "dub off tube coils within the stomach\n",
      "['enteric tube']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "gi = 2\n",
    "g = tmp['groups'][gi]\n",
    "print(g['extraction_method'])\n",
    "\n",
    "i = random.randint(0, len(g['sentences'])-1)\n",
    "print(g['sentences'][i])\n",
    "labels = []\n",
    "for j, x in enumerate(g['labels'][i]):\n",
    "    if x:\n",
    "        labels.append(tmp['label_names'][j])\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
