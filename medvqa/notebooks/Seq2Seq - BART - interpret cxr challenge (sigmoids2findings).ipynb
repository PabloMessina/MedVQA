{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1500\n",
      "   batch_size: 3\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 30\n",
      "   override_lr: False\n",
      "   task_name: fact_classifier_predictions2report_section\n",
      "   experiment_name: sigmoids2findings\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\n",
      "   interpret_cxr_challenge_data_dir: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\n",
      "   mimiccxr_integrated_report_nli_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   report_section_to_generate: findings\n",
      "   include_public_test_in_train: True\n",
      "   best_k_classes: 60\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 30, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl...\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_probs(hash=234,1770274675398037115).pkl...\n",
      "thresholds.shape: (93,)\n",
      "f1s.shape: (93,)\n",
      "accs.shape: (93,)\n",
      "probs.shape: (607342, 93)\n",
      "len(image_paths): 607342\n",
      "len(class_names): 93\n",
      "Class names:\n",
      "1: cardiac pacer and wires, f1: 0.726, acc: 0.968\n",
      "2: endotracheal tube, f1: 0.688, acc: 0.942\n",
      "3: enteric tube, f1: 0.694, acc: 0.935\n",
      "4: pleural effusion, f1: 0.735, acc: 0.862\n",
      "5: pleural abnormalities, f1: 0.754, acc: 0.820\n",
      "6: pigtail catheter, f1: 0.569, acc: 0.990\n",
      "7: lung opacity, f1: 0.778, acc: 0.778\n",
      "8: opacity texture, f1: 0.780, acc: 0.769\n",
      "9: tracheostomy tube, f1: 0.555, acc: 0.988\n",
      "10: no abnormalities, f1: 0.651, acc: 0.860\n",
      "11: support devices, f1: 0.686, acc: 0.811\n",
      "12: fluid overload/heart failure, f1: 0.675, acc: 0.799\n",
      "13: edema, f1: 0.624, acc: 0.835\n",
      "14: subcutaneous air, f1: 0.475, acc: 0.983\n",
      "15: enlarged cardiac silhouette, f1: 0.630, acc: 0.812\n",
      "16: pulmonary edema/hazy opacity, f1: 0.578, acc: 0.863\n",
      "17: cardiomegaly, f1: 0.626, acc: 0.808\n",
      "18: subcutaneous emphysema, f1: 0.448, acc: 0.982\n",
      "19: airspace opacity, f1: 0.673, acc: 0.750\n",
      "20: vascular congestion, f1: 0.573, acc: 0.829\n",
      "21: chest tube, f1: 0.449, acc: 0.949\n",
      "22: costophrenic angle blunting, f1: 0.566, acc: 0.828\n",
      "23: ij line, f1: 0.450, acc: 0.942\n",
      "24: pneumothorax, f1: 0.420, acc: 0.957\n",
      "25: linear/patchy atelectasis, f1: 0.657, acc: 0.711\n",
      "26: chest port, f1: 0.405, acc: 0.961\n",
      "27: atelectasis, f1: 0.633, acc: 0.724\n",
      "28: hyperaeration, f1: 0.405, acc: 0.934\n",
      "29: enlarged cardiomediastinum, f1: 0.542, acc: 0.796\n",
      "30: cabg grafts, f1: 0.365, acc: 0.967\n",
      "31: swan-ganz catheter, f1: 0.340, acc: 0.986\n",
      "32: lobar/segmental collapse, f1: 0.600, acc: 0.722\n",
      "33: pneumonia, f1: 0.534, acc: 0.778\n",
      "34: consolidation, f1: 0.563, acc: 0.749\n",
      "35: emphysema, f1: 0.340, acc: 0.953\n",
      "36: interstitial texture, f1: 0.634, acc: 0.659\n",
      "37: copd/emphysema, f1: 0.367, acc: 0.924\n",
      "38: hydropneumothorax, f1: 0.305, acc: 0.979\n",
      "39: infiltration, f1: 0.519, acc: 0.762\n",
      "40: tortuous aorta, f1: 0.388, acc: 0.890\n",
      "41: low lung volumes, f1: 0.464, acc: 0.799\n",
      "42: picc, f1: 0.348, acc: 0.910\n",
      "43: prosthetic valve, f1: 0.273, acc: 0.975\n",
      "44: elevated hemidiaphragm, f1: 0.285, acc: 0.955\n",
      "45: lung cancer, f1: 0.310, acc: 0.928\n",
      "46: alveolar texture, f1: 0.588, acc: 0.631\n",
      "47: hernia, f1: 0.215, acc: 0.983\n",
      "48: pneumomediastinum, f1: 0.206, acc: 0.987\n",
      "49: calcification of the aorta, f1: 0.300, acc: 0.889\n",
      "50: vascular calcification, f1: 0.257, acc: 0.932\n",
      "51: multiple masses/nodules, f1: 0.223, acc: 0.962\n",
      "52: interstitial lung disease, f1: 0.253, acc: 0.929\n",
      "53: subclavian line, f1: 0.207, acc: 0.974\n",
      "54: vascular redistribution, f1: 0.273, acc: 0.900\n",
      "55: nodule, f1: 0.241, acc: 0.929\n",
      "56: mediastinal displacement, f1: 0.214, acc: 0.950\n",
      "57: aortic graft/repair, f1: 0.194, acc: 0.963\n",
      "58: mass, f1: 0.247, acc: 0.899\n",
      "59: cyst/bullae, f1: 0.186, acc: 0.959\n",
      "60: pleural/parenchymal scarring, f1: 0.295, acc: 0.849\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing MIMIC-CXR inputs/outputs...\n",
      "100%|█████████████████████████████████| 217190/217190 [00:45<00:00, 4792.35it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 72/217190 reports without facts\u001b[0m\n",
      "len(mimiccxr_train_input_texts): 217118\n",
      "100%|█████████████████████████████████████| 5568/5568 [00:01<00:00, 4891.19it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 3/5568 reports without facts\u001b[0m\n",
      "len(mimiccxr_val_input_texts): 5565\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:7\n",
      "endotracheal tube:79\n",
      "enteric tube:73\n",
      "pleural effusion:76\n",
      "pleural abnormalities:85\n",
      "pigtail catheter:15\n",
      "lung opacity:86\n",
      "opacity texture:64\n",
      "tracheostomy tube:25\n",
      "no abnormalities:6\n",
      "support devices:75\n",
      "fluid overload/heart failure:13\n",
      "edema:19\n",
      "subcutaneous air:16\n",
      "enlarged cardiac silhouette:17\n",
      "pulmonary edema/hazy opacity:17\n",
      "cardiomegaly:14\n",
      "subcutaneous emphysema:12\n",
      "airspace opacity:80\n",
      "vascular congestion:21\n",
      "chest tube:47\n",
      "costophrenic angle blunting:56\n",
      "ij line:67\n",
      "pneumothorax:15\n",
      "linear/patchy atelectasis:78\n",
      "chest port:16\n",
      "atelectasis:84\n",
      "hyperaeration:9\n",
      "enlarged cardiomediastinum:21\n",
      "cabg grafts:8\n",
      "swan-ganz catheter:14\n",
      "lobar/segmental collapse:78\n",
      "pneumonia:44\n",
      "consolidation:66\n",
      "emphysema:5\n",
      "interstitial texture:20\n",
      "copd/emphysema:5\n",
      "hydropneumothorax:8\n",
      "infiltration:47\n",
      "tortuous aorta:8\n",
      "low lung volumes:20\n",
      "picc:24\n",
      "prosthetic valve:18\n",
      "elevated hemidiaphragm:35\n",
      "lung cancer:15\n",
      "alveolar texture:28\n",
      "hernia:13\n",
      "pneumomediastinum:20\n",
      "calcification of the aorta:9\n",
      "vascular calcification:13\n",
      "multiple masses/nodules:12\n",
      "interstitial lung disease:12\n",
      "subclavian line:16\n",
      "vascular redistribution:13\n",
      "nodule:12\n",
      "mediastinal displacement:29\n",
      "aortic graft/repair:23\n",
      "mass:17\n",
      "cyst/bullae:5\n",
      "pleural/parenchymal scarring:5\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mplacement of an endotracheal tube with its tip at the lower clavicular level. placement of an endotracheal tube approximately 5 cm above the carina. opacification at the right base. volume loss at the right base. pleural effusion at the right base. possible superimposed pneumonia at the right base.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 3\n",
      "cardiac pacer and wires:7 8 8\n",
      "endotracheal tube:1 1 1\n",
      "enteric tube:2 2 2\n",
      "pleural effusion:37 9 5\n",
      "pleural abnormalities:66 24 14\n",
      "pigtail catheter:6 4 4\n",
      "lung opacity:36 16 9\n",
      "opacity texture:25 17 12\n",
      "tracheostomy tube:6 7 6\n",
      "no abnormalities:20 57 51\n",
      "support devices:7 8 11\n",
      "fluid overload/heart failure:13 6 5\n",
      "edema:11 5 3\n",
      "subcutaneous air:11 7 7\n",
      "enlarged cardiac silhouette:54 32 32\n",
      "pulmonary edema/hazy opacity:6 3 2\n",
      "cardiomegaly:55 32 35\n",
      "subcutaneous emphysema:10 6 5\n",
      "airspace opacity:9 11 7\n",
      "vascular congestion:12 11 7\n",
      "chest tube:2 2 2\n",
      "costophrenic angle blunting:38 19 17\n",
      "ij line:3 4 4\n",
      "pneumothorax:4 2 2\n",
      "linear/patchy atelectasis:38 28 18\n",
      "chest port:3 4 4\n",
      "atelectasis:30 19 9\n",
      "hyperaeration:21 14 11\n",
      "enlarged cardiomediastinum:33 23 24\n",
      "cabg grafts:9 16 16\n",
      "swan-ganz catheter:2 3 3\n",
      "lobar/segmental collapse:19 13 6\n",
      "pneumonia:11 5 3\n",
      "consolidation:15 6 4\n",
      "emphysema:20 11 10\n",
      "interstitial texture:32 22 20\n",
      "copd/emphysema:16 10 10\n",
      "hydropneumothorax:6 4 3\n",
      "infiltration:13 7 4\n",
      "tortuous aorta:74 61 62\n",
      "low lung volumes:23 21 12\n",
      "picc:7 4 4\n",
      "prosthetic valve:27 35 31\n",
      "elevated hemidiaphragm:43 42 42\n",
      "lung cancer:9 9 7\n",
      "alveolar texture:22 14 13\n",
      "hernia:25 24 21\n",
      "pneumomediastinum:11 8 8\n",
      "calcification of the aorta:69 65 66\n",
      "vascular calcification:29 35 44\n",
      "multiple masses/nodules:8 8 7\n",
      "interstitial lung disease:6 4 3\n",
      "subclavian line:5 4 3\n",
      "vascular redistribution:24 24 21\n",
      "nodule:19 15 12\n",
      "mediastinal displacement:7 10 9\n",
      "aortic graft/repair:9 18 15\n",
      "mass:11 9 7\n",
      "cyst/bullae:16 9 8\n",
      "pleural/parenchymal scarring:41 22 17\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mclear lungs. lungs without focal consolidation. lungs without effusion. lungs without edema. stable cardiomediastinal silhouette. tortuosity of the descending thoracic aorta. no acute osseous abnormalities. surgical material projecting in the posterior subcutaneous tissues of the back.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing CheXpert inputs/outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWARNING: Skipped 136708/182199 reports with empty output\u001b[0m\n",
      "len(chexpert_train_input_texts): 45491\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 3491/4603 reports with empty output\u001b[0m\n",
      "len(chexpert_val_input_texts): 1112\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:50\n",
      "endotracheal tube:28\n",
      "enteric tube:29\n",
      "pleural effusion:84\n",
      "pleural abnormalities:86\n",
      "pigtail catheter:24\n",
      "lung opacity:89\n",
      "opacity texture:74\n",
      "tracheostomy tube:28\n",
      "no abnormalities:3\n",
      "support devices:84\n",
      "fluid overload/heart failure:72\n",
      "edema:59\n",
      "subcutaneous air:18\n",
      "enlarged cardiac silhouette:73\n",
      "pulmonary edema/hazy opacity:65\n",
      "cardiomegaly:74\n",
      "subcutaneous emphysema:16\n",
      "airspace opacity:82\n",
      "vascular congestion:78\n",
      "chest tube:21\n",
      "costophrenic angle blunting:74\n",
      "ij line:86\n",
      "pneumothorax:10\n",
      "linear/patchy atelectasis:80\n",
      "chest port:47\n",
      "atelectasis:84\n",
      "hyperaeration:13\n",
      "enlarged cardiomediastinum:71\n",
      "cabg grafts:26\n",
      "swan-ganz catheter:76\n",
      "lobar/segmental collapse:76\n",
      "pneumonia:41\n",
      "consolidation:68\n",
      "emphysema:5\n",
      "interstitial texture:39\n",
      "copd/emphysema:5\n",
      "hydropneumothorax:7\n",
      "infiltration:63\n",
      "tortuous aorta:22\n",
      "low lung volumes:37\n",
      "picc:32\n",
      "prosthetic valve:64\n",
      "elevated hemidiaphragm:23\n",
      "lung cancer:13\n",
      "alveolar texture:42\n",
      "hernia:5\n",
      "pneumomediastinum:13\n",
      "calcification of the aorta:30\n",
      "vascular calcification:67\n",
      "multiple masses/nodules:16\n",
      "interstitial lung disease:16\n",
      "subclavian line:27\n",
      "vascular redistribution:30\n",
      "nodule:11\n",
      "mediastinal displacement:52\n",
      "aortic graft/repair:53\n",
      "mass:17\n",
      "cyst/bullae:4\n",
      "pleural/parenchymal scarring:7\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mSternal wires, prosthetic aortic valve, and right IJ Swan-Ganz catheter, with tip in the right pulmonary artery. Large right pleural effusion, with asymmetric opacity in the right hemithorax, likely secondary to atelectasis. There is also atelectasis in the lung bases.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:23\n",
      "endotracheal tube:79\n",
      "enteric tube:66\n",
      "pleural effusion:22\n",
      "pleural abnormalities:65\n",
      "pigtail catheter:16\n",
      "lung opacity:81\n",
      "opacity texture:66\n",
      "tracheostomy tube:31\n",
      "no abnormalities:9\n",
      "support devices:87\n",
      "fluid overload/heart failure:37\n",
      "edema:34\n",
      "subcutaneous air:21\n",
      "enlarged cardiac silhouette:27\n",
      "pulmonary edema/hazy opacity:29\n",
      "cardiomegaly:24\n",
      "subcutaneous emphysema:19\n",
      "airspace opacity:70\n",
      "vascular congestion:52\n",
      "chest tube:35\n",
      "costophrenic angle blunting:21\n",
      "ij line:82\n",
      "pneumothorax:12\n",
      "linear/patchy atelectasis:69\n",
      "chest port:44\n",
      "atelectasis:53\n",
      "hyperaeration:24\n",
      "enlarged cardiomediastinum:38\n",
      "cabg grafts:13\n",
      "swan-ganz catheter:26\n",
      "lobar/segmental collapse:52\n",
      "pneumonia:39\n",
      "consolidation:46\n",
      "emphysema:14\n",
      "interstitial texture:46\n",
      "copd/emphysema:13\n",
      "hydropneumothorax:7\n",
      "infiltration:43\n",
      "tortuous aorta:33\n",
      "low lung volumes:41\n",
      "picc:33\n",
      "prosthetic valve:26\n",
      "elevated hemidiaphragm:22\n",
      "lung cancer:19\n",
      "alveolar texture:44\n",
      "hernia:6\n",
      "pneumomediastinum:16\n",
      "calcification of the aorta:30\n",
      "vascular calcification:32\n",
      "multiple masses/nodules:28\n",
      "interstitial lung disease:27\n",
      "subclavian line:31\n",
      "vascular redistribution:42\n",
      "nodule:27\n",
      "mediastinal displacement:31\n",
      "aortic graft/repair:33\n",
      "mass:34\n",
      "cyst/bullae:9\n",
      "pleural/parenchymal scarring:13\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThere is an endotracheal tube with the tip above the level of the carina in appropriate position. There is a left subclavian central venous catheter with tip seen at the proximal SVC. A nasogastric tube is present. Linear opacities are seen within the bilateral lung bases, which could represent atelectatic changes or consolidation. Lung volumes are slightly low. Cardiomediastinal silhouette otherwise appears unremarkable.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing OpenI inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 477/3729 reports with empty output\u001b[0m\n",
      "len(openi_train_input_texts): 3252\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 12/97 reports with empty output\u001b[0m\n",
      "len(openi_val_input_texts): 85\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "cardiac pacer and wires:4 10\n",
      "endotracheal tube:1 3\n",
      "enteric tube:3 2\n",
      "pleural effusion:4 6\n",
      "pleural abnormalities:15 33\n",
      "pigtail catheter:6 5\n",
      "lung opacity:6 30\n",
      "opacity texture:8 27\n",
      "tracheostomy tube:7 10\n",
      "no abnormalities:88 35\n",
      "support devices:7 12\n",
      "fluid overload/heart failure:1 13\n",
      "edema:1 14\n",
      "subcutaneous air:10 9\n",
      "enlarged cardiac silhouette:1 10\n",
      "pulmonary edema/hazy opacity:1 10\n",
      "cardiomegaly:1 8\n",
      "subcutaneous emphysema:7 9\n",
      "airspace opacity:5 13\n",
      "vascular congestion:1 22\n",
      "chest tube:2 3\n",
      "costophrenic angle blunting:15 12\n",
      "ij line:2 6\n",
      "pneumothorax:2 6\n",
      "linear/patchy atelectasis:13 10\n",
      "chest port:5 5\n",
      "atelectasis:6 6\n",
      "hyperaeration:6 19\n",
      "enlarged cardiomediastinum:2 23\n",
      "cabg grafts:5 11\n",
      "swan-ganz catheter:2 3\n",
      "lobar/segmental collapse:5 6\n",
      "pneumonia:2 18\n",
      "consolidation:4 12\n",
      "emphysema:7 24\n",
      "interstitial texture:8 41\n",
      "copd/emphysema:5 23\n",
      "hydropneumothorax:4 11\n",
      "infiltration:3 24\n",
      "tortuous aorta:23 63\n",
      "low lung volumes:8 17\n",
      "picc:7 7\n",
      "prosthetic valve:6 14\n",
      "elevated hemidiaphragm:15 16\n",
      "lung cancer:4 20\n",
      "alveolar texture:9 27\n",
      "hernia:30 18\n",
      "pneumomediastinum:9 17\n",
      "calcification of the aorta:24 50\n",
      "vascular calcification:6 26\n",
      "multiple masses/nodules:4 31\n",
      "interstitial lung disease:1 27\n",
      "subclavian line:5 8\n",
      "vascular redistribution:7 34\n",
      "nodule:11 32\n",
      "mediastinal displacement:4 15\n",
      "aortic graft/repair:5 14\n",
      "mass:5 24\n",
      "cyst/bullae:11 16\n",
      "pleural/parenchymal scarring:15 33\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe XXXX examination consists of frontal and lateral radiographs of the chest. The cardiomediastinal contours are within normal limits. Pulmonary vascularity is within normal limits. No focal consolidation, pleural effusion, or pneumothorax identified. Old healed left 5th and 6th rib fractures are seen laterally.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:83\n",
      "endotracheal tube:1\n",
      "enteric tube:2\n",
      "pleural effusion:4\n",
      "pleural abnormalities:15\n",
      "pigtail catheter:23\n",
      "lung opacity:13\n",
      "opacity texture:14\n",
      "tracheostomy tube:7\n",
      "no abnormalities:48\n",
      "support devices:59\n",
      "fluid overload/heart failure:4\n",
      "edema:2\n",
      "subcutaneous air:6\n",
      "enlarged cardiac silhouette:23\n",
      "pulmonary edema/hazy opacity:1\n",
      "cardiomegaly:28\n",
      "subcutaneous emphysema:5\n",
      "airspace opacity:6\n",
      "vascular congestion:8\n",
      "chest tube:3\n",
      "costophrenic angle blunting:19\n",
      "ij line:21\n",
      "pneumothorax:2\n",
      "linear/patchy atelectasis:8\n",
      "chest port:52\n",
      "atelectasis:4\n",
      "hyperaeration:9\n",
      "enlarged cardiomediastinum:26\n",
      "cabg grafts:31\n",
      "swan-ganz catheter:35\n",
      "lobar/segmental collapse:4\n",
      "pneumonia:4\n",
      "consolidation:5\n",
      "emphysema:4\n",
      "interstitial texture:15\n",
      "copd/emphysema:4\n",
      "hydropneumothorax:3\n",
      "infiltration:8\n",
      "tortuous aorta:54\n",
      "low lung volumes:6\n",
      "picc:21\n",
      "prosthetic valve:50\n",
      "elevated hemidiaphragm:23\n",
      "lung cancer:7\n",
      "alveolar texture:14\n",
      "hernia:8\n",
      "pneumomediastinum:6\n",
      "calcification of the aorta:50\n",
      "vascular calcification:25\n",
      "multiple masses/nodules:7\n",
      "interstitial lung disease:3\n",
      "subclavian line:7\n",
      "vascular redistribution:14\n",
      "nodule:13\n",
      "mediastinal displacement:5\n",
      "aortic graft/repair:40\n",
      "mass:6\n",
      "cyst/bullae:6\n",
      "pleural/parenchymal scarring:16\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mNormal heart size. Stable position of 2 pacemaker electrodes, with a XXXX tip in the expected region of the right atrium and another XXXX tip in the expected region of the right ventricle. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of pleural effusion. There is no evidence of pneumothorax. XXXX are unremarkable.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing Interpret-CXR public test set inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 985/3677 reports without images or empty output\u001b[0m\n",
      "len(public_test_input_texts): 2692\n",
      "Examples:\n",
      "\u001b[1mPublic test example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:28\n",
      "endotracheal tube:16\n",
      "enteric tube:18\n",
      "pleural effusion:75\n",
      "pleural abnormalities:89\n",
      "pigtail catheter:18\n",
      "lung opacity:87\n",
      "opacity texture:63\n",
      "tracheostomy tube:28\n",
      "no abnormalities:3\n",
      "support devices:83\n",
      "fluid overload/heart failure:58\n",
      "edema:40\n",
      "subcutaneous air:16\n",
      "enlarged cardiac silhouette:46\n",
      "pulmonary edema/hazy opacity:40\n",
      "cardiomegaly:46\n",
      "subcutaneous emphysema:15\n",
      "airspace opacity:69\n",
      "vascular congestion:62\n",
      "chest tube:11\n",
      "costophrenic angle blunting:66\n",
      "ij line:80\n",
      "pneumothorax:9\n",
      "linear/patchy atelectasis:83\n",
      "chest port:35\n",
      "atelectasis:82\n",
      "hyperaeration:10\n",
      "enlarged cardiomediastinum:49\n",
      "cabg grafts:17\n",
      "swan-ganz catheter:80\n",
      "lobar/segmental collapse:77\n",
      "pneumonia:40\n",
      "consolidation:61\n",
      "emphysema:8\n",
      "interstitial texture:37\n",
      "copd/emphysema:7\n",
      "hydropneumothorax:6\n",
      "infiltration:50\n",
      "tortuous aorta:15\n",
      "low lung volumes:22\n",
      "picc:17\n",
      "prosthetic valve:42\n",
      "elevated hemidiaphragm:13\n",
      "lung cancer:15\n",
      "alveolar texture:34\n",
      "hernia:7\n",
      "pneumomediastinum:9\n",
      "calcification of the aorta:22\n",
      "vascular calcification:44\n",
      "multiple masses/nodules:20\n",
      "interstitial lung disease:17\n",
      "subclavian line:27\n",
      "vascular redistribution:32\n",
      "nodule:13\n",
      "mediastinal displacement:21\n",
      "aortic graft/repair:37\n",
      "mass:19\n",
      "cyst/bullae:5\n",
      "pleural/parenchymal scarring:7\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mSwan-Ganz catheter has been advanced beyond the right hilum, and should be withdrawn for standard positioning, as discussed by telephone with Dr. ___ at 9:45 a.m. on ___. New airspace opacity distal to the catheter tip could potentially represent pulmonary hemorrhage, but other etiologies such as atelectasis or aspiration are also possible. Improving atelectasis in left lower lobe and persistent small left pleural effusion. Incidental calcified granulomas within the left upper lobe.\u001b[0m\n",
      "\n",
      "Including public test set in training dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No labels: 301\n",
      "low lung volumes: 358\n",
      "cyst/bullae: 1202\n",
      "hyperaeration: 4337\n",
      "nodule: 4369\n",
      "alveolar texture: 4709\n",
      "hydropneumothorax: 6117\n",
      "pneumomediastinum: 8745\n",
      "subcutaneous emphysema: 10109\n",
      "copd/emphysema: 10161\n",
      "mass: 11375\n",
      "pneumothorax: 11697\n",
      "hernia: 12233\n",
      "fluid overload/heart failure: 13423\n",
      "subclavian line: 16170\n",
      "cabg grafts: 16623\n",
      "tracheostomy tube: 20025\n",
      "cardiomegaly: 20573\n",
      "interstitial lung disease: 21515\n",
      "picc: 26525\n",
      "subcutaneous air: 26971\n",
      "pigtail catheter: 27007\n",
      "chest port: 29654\n",
      "swan-ganz catheter: 32952\n",
      "aortic graft/repair: 34120\n",
      "pleural/parenchymal scarring: 34444\n",
      "multiple masses/nodules: 35968\n",
      "emphysema: 36825\n",
      "lung cancer: 36864\n",
      "elevated hemidiaphragm: 37009\n",
      "infiltration: 42921\n",
      "cardiac pacer and wires: 46692\n",
      "mediastinal displacement: 52621\n",
      "endotracheal tube: 55494\n",
      "enlarged cardiac silhouette: 56021\n",
      "pulmonary edema/hazy opacity: 56056\n",
      "pneumonia: 56427\n",
      "chest tube: 57499\n",
      "edema: 59465\n",
      "no abnormalities: 61197\n",
      "enteric tube: 72907\n",
      "costophrenic angle blunting: 83212\n",
      "pleural effusion: 84966\n",
      "vascular redistribution: 94789\n",
      "interstitial texture: 97080\n",
      "prosthetic valve: 97718\n",
      "support devices: 103679\n",
      "enlarged cardiomediastinum: 108408\n",
      "ij line: 108938\n",
      "lobar/segmental collapse: 114213\n",
      "tortuous aorta: 133867\n",
      "atelectasis: 145522\n",
      "vascular calcification: 147457\n",
      "vascular congestion: 150633\n",
      "consolidation: 154238\n",
      "calcification of the aorta: 155233\n",
      "airspace opacity: 155941\n",
      "opacity texture: 177088\n",
      "lung opacity: 201682\n",
      "linear/patchy atelectasis: 209089\n",
      "pleural abnormalities: 212996\n",
      "Group sizes: [43523, 15187, 14103, 13844, 12055, 10082, 10003, 9225, 9020, 8383, 7993, 7691, 7373, 6804, 6719, 6624, 6463, 5882, 4985, 4895, 4841, 4838, 4688, 4675, 4672, 4157, 4081, 3686, 3342, 3209, 2917, 2739, 1846, 1775, 1707, 1609, 1558, 1417, 1202, 1058, 588, 466, 396, 358, 321, 301, 264, 263, 241, 212, 172, 132, 131, 115, 97, 97, 86, 70, 134]\n",
      "  len(indices) = 43523, weight = 3659.0203798033235\n",
      "  len(indices) = 15187, weight = 2680.1448093756107\n",
      "  len(indices) = 14103, weight = 2618.7787243981556\n",
      "  len(indices) = 13844, weight = 2603.566507872474\n",
      "  len(indices) = 12055, weight = 2491.861214919121\n",
      "  len(indices) = 10082, weight = 2352.368618021158\n",
      "  len(indices) = 10003, weight = 2346.351578308155\n",
      "  len(indices) = 9225, weight = 2285.0158072811428\n",
      "  len(indices) = 9020, weight = 2268.1834837555966\n",
      "  len(indices) = 8383, weight = 2213.9013695192834\n",
      "  len(indices) = 7993, weight = 2179.0613824912807\n",
      "  len(indices) = 7691, weight = 2151.1629474076462\n",
      "  len(indices) = 7373, weight = 2120.851392537928\n",
      "  len(indices) = 6804, weight = 2063.987309259501\n",
      "  len(indices) = 6719, weight = 2055.1795936912936\n",
      "  len(indices) = 6624, weight = 2045.2331500403482\n",
      "  len(indices) = 6463, weight = 2028.1219590183837\n",
      "  len(indices) = 5882, weight = 1963.4984998962632\n",
      "  len(indices) = 4985, weight = 1853.3328680224597\n",
      "  len(indices) = 4895, weight = 1841.4607193341226\n",
      "  len(indices) = 4841, weight = 1834.2570919578895\n",
      "  len(indices) = 4838, weight = 1833.8550929544867\n",
      "  len(indices) = 4688, weight = 1813.5078366475504\n",
      "  len(indices) = 4675, weight = 1811.72111044358\n",
      "  len(indices) = 4672, weight = 1811.308250526977\n",
      "  len(indices) = 4157, weight = 1737.2296621177059\n",
      "  len(indices) = 4081, weight = 1725.7144303755824\n",
      "  len(indices) = 3686, weight = 1663.0970028130573\n",
      "  len(indices) = 3342, weight = 1604.2822011699063\n",
      "  len(indices) = 3209, weight = 1580.3155137725375\n",
      "  len(indices) = 2917, weight = 1524.9531315937966\n",
      "  len(indices) = 2739, weight = 1489.133676159285\n",
      "  len(indices) = 1846, weight = 1277.3551111205359\n",
      "  len(indices) = 1775, weight = 1257.4749954532429\n",
      "  len(indices) = 1707, weight = 1237.880930987841\n",
      "  len(indices) = 1609, weight = 1208.6127952235652\n",
      "  len(indices) = 1558, weight = 1192.8639909115088\n",
      "  len(indices) = 1417, weight = 1147.2783815035605\n",
      "  len(indices) = 1202, weight = 1070.982613077825\n",
      "  len(indices) = 1058, weight = 1014.2038981733282\n",
      "  len(indices) = 588, weight = 778.6048047638925\n",
      "  len(indices) = 466, weight = 696.4927538988583\n",
      "  len(indices) = 396, weight = 642.5919068906027\n",
      "  len(indices) = 358, weight = 610.623744674081\n",
      "  len(indices) = 321, weight = 577.266593657993\n",
      "  len(indices) = 301, weight = 558.1776041492743\n",
      "  len(indices) = 264, weight = 520.5710585184399\n",
      "  len(indices) = 263, weight = 519.5088573996983\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 212, weight = 461.51724066478397\n",
      "  len(indices) = 172, weight = 409.5541064098074\n",
      "  len(indices) = 132, weight = 349.56741063380855\n",
      "  len(indices) = 131, weight = 347.9366776004082\n",
      "  len(indices) = 115, weight = 320.7846886341935\n",
      "  len(indices) = 97, weight = 287.4846103674236\n",
      "  len(indices) = 97, weight = 287.4846103674236\n",
      "  len(indices) = 86, weight = 265.3846760531219\n",
      "  len(indices) = 70, weight = 230.2655804515992\n",
      "  len(indices) = 134, weight = 352.80712306341184\n",
      "seq2seq_trainer.name =  fact_classifier_predictions2report_section(sigmoids2findings)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_204636_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_204636_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_204636_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 6.57517, s2s_loss 5.49585, 128.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 4.12911, 22.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_s2s_loss=0.1909.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.72706, s2s_loss 3.95300, 130.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 3.52341, 22.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_s2s_loss=0.2192.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 3.44461, s2s_loss 3.08393, 127.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.93818, 22.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_s2s_loss=0.2530.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 3.53845, s2s_loss 2.38565, 126.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.39610, 22.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_s2s_loss=0.2945.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 1.92084, s2s_loss 2.08504, 131.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.28267, 22.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_s2s_loss=0.3066.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.54503, s2s_loss 2.01615, 125.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.22292, 22.55 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_s2s_loss=0.3124.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.93297, s2s_loss 1.96047, 126.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.18400, 22.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_s2s_loss=0.3164.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.20833, s2s_loss 1.94832, 126.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.17085, 22.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_s2s_loss=0.3178.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.69923, s2s_loss 1.92553, 126.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.16125, 22.05 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_s2s_loss=0.3189.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.93423, s2s_loss 1.92957, 126.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.16007, 22.46 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_s2s_loss=0.3189.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.35622, s2s_loss 1.91498, 126.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.15645, 22.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_s2s_loss=0.3194.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.62262, s2s_loss 1.90664, 127.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.15314, 22.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_s2s_loss=0.3198.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.68604, s2s_loss 1.87574, 126.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.07392, 22.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_s2s_loss=0.3276.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.30067, s2s_loss 1.80808, 126.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.01233, 22.45 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_s2s_loss=0.3344.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.39914, s2s_loss 1.77080, 126.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.99409, 22.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_s2s_loss=0.3367.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 2.65349, s2s_loss 1.74661, 128.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.98617, 21.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_s2s_loss=0.3378.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.89927, s2s_loss 1.74790, 129.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.97463, 22.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_s2s_loss=0.3390.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.73524, s2s_loss 1.74416, 126.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.97380, 22.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_s2s_loss=0.3391.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.36663, s2s_loss 1.74009, 127.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.97200, 22.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_s2s_loss=0.3393.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.92913, s2s_loss 1.74795, 126.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.97171, 22.59 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.97886, s2s_loss 1.73949, 127.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.94324, 22.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_s2s_loss=0.3423.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.56677, s2s_loss 1.68490, 126.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.91089, 22.39 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_s2s_loss=0.3464.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.80442, s2s_loss 1.66103, 127.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.88344, 22.55 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_s2s_loss=0.3497.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 2.22113, s2s_loss 1.64814, 127.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.88114, 22.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_s2s_loss=0.3501.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.87284, s2s_loss 1.65252, 125.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.87485, 22.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_s2s_loss=0.3508.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.58020, s2s_loss 1.64206, 127.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.87315, 22.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_s2s_loss=0.3511.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.49235, s2s_loss 1.62684, 126.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.87181, 22.39 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_s2s_loss=0.3515.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.51655, s2s_loss 1.64376, 126.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.86954, 22.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_s2s_loss=0.3515.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 43050\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 588, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 499, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 326, in train_model\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/seq2seq.py\", line 97, in step_fn_wrapper\n",
      "    output = step_fn(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/seq2seq.py\", line 63, in step_fn\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/nlp/seq2seq.py\", line 41, in forward\n",
      "    output = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py\", line 1373, in forward\n",
      "    outputs = self.model(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py\", line 1255, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py\", line 1043, in forward\n",
      "    attention_mask = self._prepare_decoder_attention_mask(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py\", line 922, in _prepare_decoder_attention_mask\n",
      "    combined_attention_mask = _make_causal_mask(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py\", line 95, in _make_causal_mask\n",
      "    mask = torch.full((tgt_len, tgt_len), torch.tensor(torch.finfo(dtype).min))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1500 \\\n",
    "--batch_size 3 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 30 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"fact_classifier_predictions2report_section\" \\\n",
    "--experiment_name \"sigmoids2findings\" \\\n",
    "--interpret_cxr__label_based_predictions_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\" \\\n",
    "--interpret_cxr_challenge_data_dir \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\" \\\n",
    "--mimiccxr_integrated_report_nli_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--report_section_to_generate \"findings\" \\\n",
    "--best_k_classes 60 \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--bart_model_name \"facebook/bart-base\" \\\n",
    "--include_public_test_in_train \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1500\n",
      "   batch_size: 3\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_204636_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 30\n",
      "   override_lr: False\n",
      "   task_name: fact_classifier_predictions2report_section\n",
      "   experiment_name: sigmoids2findings\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\n",
      "   interpret_cxr_challenge_data_dir: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\n",
      "   mimiccxr_integrated_report_nli_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   report_section_to_generate: findings\n",
      "   include_public_test_in_train: True\n",
      "   best_k_classes: 75\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 30, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl...\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_probs(hash=234,1770274675398037115).pkl...\n",
      "thresholds.shape: (93,)\n",
      "f1s.shape: (93,)\n",
      "accs.shape: (93,)\n",
      "probs.shape: (607342, 93)\n",
      "len(image_paths): 607342\n",
      "len(class_names): 93\n",
      "Class names:\n",
      "1: cardiac pacer and wires, f1: 0.726, acc: 0.968\n",
      "2: endotracheal tube, f1: 0.688, acc: 0.942\n",
      "3: enteric tube, f1: 0.694, acc: 0.935\n",
      "4: pleural effusion, f1: 0.735, acc: 0.862\n",
      "5: pleural abnormalities, f1: 0.754, acc: 0.820\n",
      "6: pigtail catheter, f1: 0.569, acc: 0.990\n",
      "7: lung opacity, f1: 0.778, acc: 0.778\n",
      "8: opacity texture, f1: 0.780, acc: 0.769\n",
      "9: tracheostomy tube, f1: 0.555, acc: 0.988\n",
      "10: no abnormalities, f1: 0.651, acc: 0.860\n",
      "11: support devices, f1: 0.686, acc: 0.811\n",
      "12: fluid overload/heart failure, f1: 0.675, acc: 0.799\n",
      "13: edema, f1: 0.624, acc: 0.835\n",
      "14: subcutaneous air, f1: 0.475, acc: 0.983\n",
      "15: enlarged cardiac silhouette, f1: 0.630, acc: 0.812\n",
      "16: pulmonary edema/hazy opacity, f1: 0.578, acc: 0.863\n",
      "17: cardiomegaly, f1: 0.626, acc: 0.808\n",
      "18: subcutaneous emphysema, f1: 0.448, acc: 0.982\n",
      "19: airspace opacity, f1: 0.673, acc: 0.750\n",
      "20: vascular congestion, f1: 0.573, acc: 0.829\n",
      "21: chest tube, f1: 0.449, acc: 0.949\n",
      "22: costophrenic angle blunting, f1: 0.566, acc: 0.828\n",
      "23: ij line, f1: 0.450, acc: 0.942\n",
      "24: pneumothorax, f1: 0.420, acc: 0.957\n",
      "25: linear/patchy atelectasis, f1: 0.657, acc: 0.711\n",
      "26: chest port, f1: 0.405, acc: 0.961\n",
      "27: atelectasis, f1: 0.633, acc: 0.724\n",
      "28: hyperaeration, f1: 0.405, acc: 0.934\n",
      "29: enlarged cardiomediastinum, f1: 0.542, acc: 0.796\n",
      "30: cabg grafts, f1: 0.365, acc: 0.967\n",
      "31: swan-ganz catheter, f1: 0.340, acc: 0.986\n",
      "32: lobar/segmental collapse, f1: 0.600, acc: 0.722\n",
      "33: pneumonia, f1: 0.534, acc: 0.778\n",
      "34: consolidation, f1: 0.563, acc: 0.749\n",
      "35: emphysema, f1: 0.340, acc: 0.953\n",
      "36: interstitial texture, f1: 0.634, acc: 0.659\n",
      "37: copd/emphysema, f1: 0.367, acc: 0.924\n",
      "38: hydropneumothorax, f1: 0.305, acc: 0.979\n",
      "39: infiltration, f1: 0.519, acc: 0.762\n",
      "40: tortuous aorta, f1: 0.388, acc: 0.890\n",
      "41: low lung volumes, f1: 0.464, acc: 0.799\n",
      "42: picc, f1: 0.348, acc: 0.910\n",
      "43: prosthetic valve, f1: 0.273, acc: 0.975\n",
      "44: elevated hemidiaphragm, f1: 0.285, acc: 0.955\n",
      "45: lung cancer, f1: 0.310, acc: 0.928\n",
      "46: alveolar texture, f1: 0.588, acc: 0.631\n",
      "47: hernia, f1: 0.215, acc: 0.983\n",
      "48: pneumomediastinum, f1: 0.206, acc: 0.987\n",
      "49: calcification of the aorta, f1: 0.300, acc: 0.889\n",
      "50: vascular calcification, f1: 0.257, acc: 0.932\n",
      "51: multiple masses/nodules, f1: 0.223, acc: 0.962\n",
      "52: interstitial lung disease, f1: 0.253, acc: 0.929\n",
      "53: subclavian line, f1: 0.207, acc: 0.974\n",
      "54: vascular redistribution, f1: 0.273, acc: 0.900\n",
      "55: nodule, f1: 0.241, acc: 0.929\n",
      "56: mediastinal displacement, f1: 0.214, acc: 0.950\n",
      "57: aortic graft/repair, f1: 0.194, acc: 0.963\n",
      "58: mass, f1: 0.247, acc: 0.899\n",
      "59: cyst/bullae, f1: 0.186, acc: 0.959\n",
      "60: pleural/parenchymal scarring, f1: 0.295, acc: 0.849\n",
      "61: lung lesion, f1: 0.295, acc: 0.846\n",
      "62: fibrosis, f1: 0.277, acc: 0.862\n",
      "63: intra-aortic balloon pump, f1: 0.149, acc: 0.989\n",
      "64: granulomatous disease, f1: 0.167, acc: 0.967\n",
      "65: bronchiectasis, f1: 0.147, acc: 0.987\n",
      "66: mediastinal widening, f1: 0.218, acc: 0.914\n",
      "67: sub-diaphragmatic air, f1: 0.140, acc: 0.991\n",
      "68: mass/nodule (not otherwise specified), f1: 0.231, acc: 0.889\n",
      "69: increased reticular markings/ild pattern, f1: 0.281, acc: 0.830\n",
      "70: pericardial effusion, f1: 0.124, acc: 0.985\n",
      "71: alveolar hemorrhage, f1: 0.125, acc: 0.967\n",
      "72: calcified nodule, f1: 0.125, acc: 0.965\n",
      "73: scoliosis, f1: 0.129, acc: 0.953\n",
      "74: goiter, f1: 0.094, acc: 0.987\n",
      "75: superior mediastinal mass/enlargement, f1: 0.083, acc: 0.990\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing MIMIC-CXR inputs/outputs...\n",
      "100%|█████████████████████████████████| 217190/217190 [00:23<00:00, 9200.90it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 72/217190 reports without facts\u001b[0m\n",
      "len(mimiccxr_train_input_texts): 217118\n",
      "100%|█████████████████████████████████████| 5568/5568 [00:00<00:00, 9495.46it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 3/5568 reports without facts\u001b[0m\n",
      "len(mimiccxr_val_input_texts): 5565\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:yes 3\n",
      "pleural effusion:yes 6\n",
      "pleural abnormalities:yes 8\n",
      "lung opacity:yes 6\n",
      "opacity texture:yes 4\n",
      "support devices:yes 6\n",
      "subcutaneous air:yes 3\n",
      "enlarged cardiac silhouette:yes 5\n",
      "vascular congestion:yes 4\n",
      "costophrenic angle blunting:yes 5\n",
      "ij line:yes 3\n",
      "linear/patchy atelectasis:yes 7\n",
      "atelectasis:yes 6\n",
      "enlarged cardiomediastinum:yes 6\n",
      "cabg grafts:yes 4\n",
      "lobar/segmental collapse:yes 5\n",
      "consolidation:yes 3\n",
      "tortuous aorta:yes 4\n",
      "prosthetic valve:yes 7\n",
      "calcification of the aorta:yes 5\n",
      "vascular calcification:yes 5\n",
      "vascular redistribution:yes 3\n",
      "mediastinal displacement:yes 4\n",
      "aortic graft/repair:yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35msubstantial decrease in the bibasilar opacification. clearing of most of the pleural fluid. atelectatic changes. no evidence of vascular congestion. no evidence of pneumothorax.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 3\n",
      "pleural abnormalities:no 1,no 1,yes 6\n",
      "lung opacity:no 1,no 1,yes 4\n",
      "no abnormalities:yes 5,yes 5,no 1\n",
      "linear/patchy atelectasis:no 1,no 1,yes 4\n",
      "tortuous aorta:yes 7,yes 5,yes 5\n",
      "elevated hemidiaphragm:no 2,no 3,yes 4\n",
      "hernia:no 2,no 2,yes 4\n",
      "calcification of the aorta:yes 7,yes 4,yes 5\n",
      "vascular calcification:yes 3,no 1,yes 3\n",
      "vascular redistribution:no 1,no 1,yes 3\n",
      "pleural/parenchymal scarring:no 1,no 1,yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mnormal cardiac size. aorta is tortuous. clear lungs. no evidence of pneumonia. no evidence of pneumothorax. no evidence of pleural effusion. no evidence of pulmonary edema.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing CheXpert inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 136708/182199 reports with empty output\u001b[0m\n",
      "len(chexpert_train_input_texts): 45491\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 3491/4603 reports with empty output\u001b[0m\n",
      "len(chexpert_val_input_texts): 1112\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "cardiac pacer and wires:yes 7,yes 5\n",
      "pleural effusion:yes 8,yes 8\n",
      "pleural abnormalities:yes 9,yes 9\n",
      "lung opacity:yes 8,yes 8\n",
      "opacity texture:yes 6,yes 6\n",
      "support devices:yes 6,yes 6\n",
      "edema:no 3,yes 4\n",
      "enlarged cardiac silhouette:no 5,yes 6\n",
      "pulmonary edema/hazy opacity:yes 4,yes 4\n",
      "airspace opacity:yes 6,yes 6\n",
      "vascular congestion:yes 5,yes 6\n",
      "costophrenic angle blunting:yes 7,yes 7\n",
      "ij line:no 2,yes 4\n",
      "linear/patchy atelectasis:yes 8,yes 8\n",
      "atelectasis:yes 8,yes 8\n",
      "enlarged cardiomediastinum:yes 5,yes 6\n",
      "lobar/segmental collapse:yes 8,yes 7\n",
      "consolidation:yes 6,yes 6\n",
      "tortuous aorta:no 3,yes 4\n",
      "prosthetic valve:yes 4,yes 5\n",
      "calcification of the aorta:yes 3,yes 4\n",
      "vascular calcification:yes 3,yes 4\n",
      "mediastinal displacement:no 1,yes 5\n",
      "intra-aortic balloon pump:yes 3,no 2\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThere has been interval placement of a left-sided pacemaker device with a lead in the right atrium and a lead in the right ventricle. The cardiomediastinal silhouette appears unchanged. No definite pneumothorax. There are small bilateral pleural effusions and bilateral basilar atelectasis. Interval fine opacity is seen within the right upper lung zone, which is superimposed on the upper right ribs. Recommend dedicated PA and lateral of the chest when patient is able in full upright position for better evaluation.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "pleural abnormalities:yes 5,yes 7\n",
      "lung opacity:yes 4,yes 5\n",
      "enlarged cardiac silhouette:yes 5,no 3\n",
      "vascular congestion:yes 3,no 2\n",
      "costophrenic angle blunting:no 3,yes 4\n",
      "linear/patchy atelectasis:yes 4,yes 4\n",
      "hyperaeration:no 4,yes 6\n",
      "enlarged cardiomediastinum:yes 4,no 2\n",
      "consolidation:no 2,yes 3\n",
      "emphysema:no 2,yes 5\n",
      "interstitial texture:no 3,yes 4\n",
      "copd/emphysema:no 1,yes 4\n",
      "tortuous aorta:yes 5,yes 4\n",
      "calcification of the aorta:yes 4,yes 4\n",
      "vascular calcification:no 2,yes 3\n",
      "pleural/parenchymal scarring:no 2,yes 5\n",
      "lung lesion:no 1,yes 4\n",
      "fibrosis:no 3,yes 5\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe cardiomediastinal silhouette is normal. The lung parenchyma is clear. There is mild blunting of the left costophrenic angle, which may represent a trace left pleural effusion versus chronic pleural thickening. There are no significant bony abnormalities.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing OpenI inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 477/3729 reports with empty output\u001b[0m\n",
      "len(openi_train_input_texts): 3252\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 12/97 reports with empty output\u001b[0m\n",
      "len(openi_val_input_texts): 85\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "no abnormalities:yes 6,yes 8\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe heart size and pulmonary vascularity appear within normal limits. Lungs are free of focal airspace disease. No pleural effusion or pneumothorax is seen. VP shunt tubing is identified. The bony structures, as visualized, appear unremarkable.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "no abnormalities:yes 8,yes 7\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe heart and lungs have XXXX XXXX in the interval. Both lungs are clear and expanded. Heart and mediastinum normal.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing Interpret-CXR public test set inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 985/3677 reports without images or empty output\u001b[0m\n",
      "len(public_test_input_texts): 2692\n",
      "Examples:\n",
      "\u001b[1mPublic test example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "pleural abnormalities:yes 6\n",
      "lung opacity:yes 7\n",
      "opacity texture:yes 6\n",
      "support devices:yes 6\n",
      "edema:yes 6\n",
      "enlarged cardiac silhouette:yes 6\n",
      "pulmonary edema/hazy opacity:yes 6\n",
      "airspace opacity:yes 5\n",
      "vascular congestion:yes 7\n",
      "ij line:yes 7\n",
      "linear/patchy atelectasis:yes 5\n",
      "atelectasis:yes 6\n",
      "enlarged cardiomediastinum:yes 6\n",
      "swan-ganz catheter:yes 6\n",
      "consolidation:yes 3\n",
      "interstitial texture:yes 5\n",
      "prosthetic valve:yes 5\n",
      "calcification of the aorta:yes 3\n",
      "vascular calcification:yes 6\n",
      "vascular redistribution:yes 4\n",
      "increased reticular markings/ild pattern:yes 5\n",
      "pericardial effusion:yes 3\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe patient is status post median sternotomy and aortic valve replacement. A right internal jugular central venous catheter is unchanged in position with the tip terminating in the low SVC. A small caliber left IJ line is also noted. The lung volumes are slightly decreased. There is slight elevation of the left hemidiaphragm compared to the right. The cardiac silhouette remains enlarged but stable. The mediastinal contours are prominent postoperatively. There is mild calcification of the aortic knob. Mild to moderate pulmonary edema is increased from the most recent prior study. There is increased streaky opacification at the right lung base compared to the most recent prior study. In the absence of aspiration, this most likely reflects atelectasis. Mild opacification of the left lung base is unchanged and compatible with mild atelectasis. No significant pleural effusion or pneumothorax is detected.\u001b[0m\n",
      "\n",
      "Including public test set in training dataset...\n",
      "bronchiectasis: 16\n",
      "scoliosis: 22\n",
      "sub-diaphragmatic air: 47\n",
      "No labels: 277\n",
      "low lung volumes: 358\n",
      "granulomatous disease: 527\n",
      "cyst/bullae: 1202\n",
      "hyperaeration: 4337\n",
      "nodule: 4369\n",
      "alveolar texture: 4709\n",
      "hydropneumothorax: 6117\n",
      "alveolar hemorrhage: 7558\n",
      "pneumomediastinum: 8745\n",
      "subcutaneous emphysema: 10109\n",
      "copd/emphysema: 10161\n",
      "mass: 11375\n",
      "pneumothorax: 11697\n",
      "hernia: 12233\n",
      "fluid overload/heart failure: 13423\n",
      "subclavian line: 16170\n",
      "cabg grafts: 16623\n",
      "calcified nodule: 18234\n",
      "goiter: 18474\n",
      "mass/nodule (not otherwise specified): 18969\n",
      "tracheostomy tube: 20025\n",
      "cardiomegaly: 20573\n",
      "interstitial lung disease: 21515\n",
      "mediastinal widening: 22931\n",
      "picc: 26525\n",
      "subcutaneous air: 26971\n",
      "pigtail catheter: 27007\n",
      "superior mediastinal mass/enlargement: 29615\n",
      "chest port: 29654\n",
      "intra-aortic balloon pump: 30826\n",
      "swan-ganz catheter: 32952\n",
      "aortic graft/repair: 34120\n",
      "pleural/parenchymal scarring: 34444\n",
      "multiple masses/nodules: 35968\n",
      "emphysema: 36825\n",
      "lung cancer: 36864\n",
      "elevated hemidiaphragm: 37009\n",
      "pericardial effusion: 41989\n",
      "infiltration: 42921\n",
      "cardiac pacer and wires: 46692\n",
      "fibrosis: 49319\n",
      "mediastinal displacement: 52621\n",
      "endotracheal tube: 55494\n",
      "enlarged cardiac silhouette: 56021\n",
      "pulmonary edema/hazy opacity: 56056\n",
      "pneumonia: 56427\n",
      "chest tube: 57499\n",
      "edema: 59465\n",
      "no abnormalities: 61197\n",
      "increased reticular markings/ild pattern: 65106\n",
      "lung lesion: 67627\n",
      "enteric tube: 72907\n",
      "costophrenic angle blunting: 83212\n",
      "pleural effusion: 84966\n",
      "vascular redistribution: 94789\n",
      "interstitial texture: 97080\n",
      "prosthetic valve: 97718\n",
      "support devices: 103679\n",
      "enlarged cardiomediastinum: 108408\n",
      "ij line: 108938\n",
      "lobar/segmental collapse: 114213\n",
      "tortuous aorta: 133867\n",
      "atelectasis: 145522\n",
      "vascular calcification: 147457\n",
      "vascular congestion: 150633\n",
      "consolidation: 154238\n",
      "calcification of the aorta: 155233\n",
      "airspace opacity: 155941\n",
      "opacity texture: 177088\n",
      "lung opacity: 201682\n",
      "linear/patchy atelectasis: 209089\n",
      "pleural abnormalities: 212996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes: [36792, 14067, 13800, 12710, 11741, 10292, 9775, 9712, 8961, 7707, 6475, 5986, 5905, 5903, 5878, 5772, 5650, 5246, 5068, 4919, 4771, 4640, 4532, 4507, 4073, 4010, 3829, 3537, 3443, 3372, 3183, 3031, 3026, 3022, 2792, 2712, 2228, 2113, 2079, 1672, 1634, 1526, 1505, 1350, 1263, 1043, 967, 742, 725, 704, 668, 518, 446, 399, 358, 278, 277, 270, 223, 195, 184, 169, 168, 124, 108, 98, 80, 76, 54, 49, 48, 135]\n",
      "  len(indices) = 36792, weight = 3489.056767678069\n",
      "  len(indices) = 14067, weight = 2616.677569701033\n",
      "  len(indices) = 13800, weight = 2600.9598817636793\n",
      "  len(indices) = 12710, weight = 2534.1886758172827\n",
      "  len(indices) = 11741, weight = 2470.924641019512\n",
      "  len(indices) = 10292, weight = 2368.18565972543\n",
      "  len(indices) = 9775, weight = 2328.774827005463\n",
      "  len(indices) = 9712, weight = 2323.8615770803394\n",
      "  len(indices) = 8961, weight = 2263.2837630583954\n",
      "  len(indices) = 7707, weight = 2152.6621650457887\n",
      "  len(indices) = 6475, weight = 2029.4086113409926\n",
      "  len(indices) = 5986, weight = 1975.417040682102\n",
      "  len(indices) = 5905, weight = 1966.148219171306\n",
      "  len(indices) = 5903, weight = 1965.9181244413182\n",
      "  len(indices) = 5878, weight = 1963.0368655079449\n",
      "  len(indices) = 5772, weight = 1950.7145475320117\n",
      "  len(indices) = 5650, weight = 1936.314936204985\n",
      "  len(indices) = 5246, weight = 1886.858621731186\n",
      "  len(indices) = 5068, weight = 1864.1371449440821\n",
      "  len(indices) = 4919, weight = 1844.6428411996344\n",
      "  len(indices) = 4771, weight = 1824.8270820881846\n",
      "  len(indices) = 4640, weight = 1806.8917721585833\n",
      "  len(indices) = 4532, weight = 1791.8124576759558\n",
      "  len(indices) = 4507, weight = 1788.282879232502\n",
      "  len(indices) = 4073, weight = 1724.4928501529423\n",
      "  len(indices) = 4010, weight = 1714.80868719209\n",
      "  len(indices) = 3829, weight = 1686.3283791147912\n",
      "  len(indices) = 3537, weight = 1638.1538992177043\n",
      "  len(indices) = 3443, weight = 1622.006775353154\n",
      "  len(indices) = 3372, weight = 1609.5886094009054\n",
      "  len(indices) = 3183, weight = 1575.543266272346\n",
      "  len(indices) = 3031, weight = 1547.041774762268\n",
      "  len(indices) = 3026, weight = 1546.0861584176546\n",
      "  len(indices) = 3022, weight = 1545.3208117763515\n",
      "  len(indices) = 2792, weight = 1499.9767282026453\n",
      "  len(indices) = 2712, weight = 1483.5494578483074\n",
      "  len(indices) = 2228, weight = 1375.6058849552123\n",
      "  len(indices) = 2113, weight = 1347.4301154864438\n",
      "  len(indices) = 2079, weight = 1338.8831899556926\n",
      "  len(indices) = 1672, weight = 1227.5723799284503\n",
      "  len(indices) = 1634, weight = 1216.2001810036945\n",
      "  len(indices) = 1526, weight = 1182.7897815319836\n",
      "  len(indices) = 1505, weight = 1176.0947918484187\n",
      "  len(indices) = 1350, weight = 1124.4564024013926\n",
      "  len(indices) = 1263, weight = 1093.5671054773313\n",
      "  len(indices) = 1043, weight = 1007.9781562050789\n",
      "  len(indices) = 967, weight = 975.4158809088976\n",
      "  len(indices) = 742, weight = 866.9613161526532\n",
      "  len(indices) = 725, weight = 857.872514013076\n",
      "  len(indices) = 704, weight = 846.4379490955091\n",
      "  len(indices) = 668, weight = 826.2718180340576\n",
      "  len(indices) = 518, weight = 733.0920466569294\n",
      "  len(indices) = 446, weight = 681.6810861294584\n",
      "  len(indices) = 399, weight = 645.0273987281234\n",
      "  len(indices) = 358, weight = 610.623744674081\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 277, weight = 534.1504621238341\n",
      "  len(indices) = 270, weight = 526.8906631574398\n",
      "  len(indices) = 223, weight = 474.71626868396766\n",
      "  len(indices) = 195, weight = 440.2474222842083\n",
      "  len(indices) = 184, weight = 425.8635843953102\n",
      "  len(indices) = 169, weight = 405.3684909627789\n",
      "  len(indices) = 168, weight = 403.96321604889306\n",
      "  len(indices) = 124, weight = 336.310819069364\n",
      "  len(indices) = 108, weight = 308.2154192941874\n",
      "  len(indices) = 98, weight = 289.4225699262594\n",
      "  len(indices) = 80, weight = 252.66707670360077\n",
      "  len(indices) = 76, weight = 243.89783600777827\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 48, weight = 174.20506759073166\n",
      "  len(indices) = 135, weight = 354.4162593823014\n",
      "seq2seq_trainer.name =  fact_classifier_predictions2report_section(sigmoids2findings)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_28_s2s_loss=0.3515.pt', 'checkpoint_50_s2s_loss=0.3683.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_204636_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/checkpoint_50_s2s_loss=0.3683.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.39525, s2s_loss 1.49595, 120.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74942, 19.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_s2s_loss=0.3674.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.08438, s2s_loss 1.50012, 119.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74080, 19.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_s2s_loss=0.3684.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 2.26724, s2s_loss 1.49523, 116.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73725, 19.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_s2s_loss=0.3689.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.08618, s2s_loss 1.49606, 118.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76123, 20.25 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 1.63482, s2s_loss 1.48590, 116.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73172, 20.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_s2s_loss=0.3697.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.76780, s2s_loss 1.47195, 113.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.71730, 19.81 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_s2s_loss=0.3717.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.21111, s2s_loss 1.46541, 116.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.70774, 20.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_s2s_loss=0.3729.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.65114, s2s_loss 1.45819, 116.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.70470, 19.98 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_s2s_loss=0.3734.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.23868, s2s_loss 1.45072, 115.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69872, 19.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_s2s_loss=0.3743.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.32713, s2s_loss 1.43858, 117.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69848, 19.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_s2s_loss=0.3745.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.48268, s2s_loss 1.44869, 116.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69606, 19.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_s2s_loss=0.3747.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.29354, s2s_loss 1.45737, 116.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69677, 20.20 secs\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.10606, s2s_loss 1.47590, 117.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73270, 20.34 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.34073, s2s_loss 1.45975, 116.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69794, 20.13 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.32114, s2s_loss 1.43781, 116.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69161, 19.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_s2s_loss=0.3754.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.76023, s2s_loss 1.42792, 117.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68093, 20.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_s2s_loss=0.3769.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.33720, s2s_loss 1.43186, 115.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67831, 20.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_s2s_loss=0.3772.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.67398, s2s_loss 1.43243, 116.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67578, 20.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_s2s_loss=0.3775.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.40310, s2s_loss 1.42860, 116.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67586, 20.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_s2s_loss=0.3775.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.21144, s2s_loss 1.43749, 117.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67419, 20.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_s2s_loss=0.3776.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.10987, s2s_loss 1.44971, 116.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69659, 20.07 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 2.03170, s2s_loss 1.42088, 116.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67273, 19.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_s2s_loss=0.3780.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "   iteration 33925\r"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_204636_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1500 \\\n",
    "--batch_size 3 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 30 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"fact_classifier_predictions2report_section\" \\\n",
    "--experiment_name \"sigmoids2findings\" \\\n",
    "--interpret_cxr__label_based_predictions_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\" \\\n",
    "--interpret_cxr_challenge_data_dir \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\" \\\n",
    "--mimiccxr_integrated_report_nli_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--report_section_to_generate \"findings\" \\\n",
    "--best_k_classes 75 \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--bart_model_name \"facebook/bart-base\" \\\n",
    "--include_public_test_in_train \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 1500\n",
      "   batch_size: 3\n",
      "   checkpoint_folder: models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 30\n",
      "   override_lr: False\n",
      "   task_name: fact_classifier_predictions2report_section\n",
      "   experiment_name: sigmoids2findings\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\n",
      "   interpret_cxr_challenge_data_dir: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\n",
      "   mimiccxr_integrated_report_nli_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   report_section_to_generate: findings\n",
      "   include_public_test_in_train: True\n",
      "   best_k_classes: 75\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 30, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl...\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_probs(hash=234,1770274675398037115).pkl...\n",
      "thresholds.shape: (93,)\n",
      "f1s.shape: (93,)\n",
      "accs.shape: (93,)\n",
      "probs.shape: (607342, 93)\n",
      "len(image_paths): 607342\n",
      "len(class_names): 93\n",
      "Class names:\n",
      "1: cardiac pacer and wires, f1: 0.726, acc: 0.968\n",
      "2: endotracheal tube, f1: 0.688, acc: 0.942\n",
      "3: enteric tube, f1: 0.694, acc: 0.935\n",
      "4: pleural effusion, f1: 0.735, acc: 0.862\n",
      "5: pleural abnormalities, f1: 0.754, acc: 0.820\n",
      "6: pigtail catheter, f1: 0.569, acc: 0.990\n",
      "7: lung opacity, f1: 0.778, acc: 0.778\n",
      "8: opacity texture, f1: 0.780, acc: 0.769\n",
      "9: tracheostomy tube, f1: 0.555, acc: 0.988\n",
      "10: no abnormalities, f1: 0.651, acc: 0.860\n",
      "11: support devices, f1: 0.686, acc: 0.811\n",
      "12: fluid overload/heart failure, f1: 0.675, acc: 0.799\n",
      "13: edema, f1: 0.624, acc: 0.835\n",
      "14: subcutaneous air, f1: 0.475, acc: 0.983\n",
      "15: enlarged cardiac silhouette, f1: 0.630, acc: 0.812\n",
      "16: pulmonary edema/hazy opacity, f1: 0.578, acc: 0.863\n",
      "17: cardiomegaly, f1: 0.626, acc: 0.808\n",
      "18: subcutaneous emphysema, f1: 0.448, acc: 0.982\n",
      "19: airspace opacity, f1: 0.673, acc: 0.750\n",
      "20: vascular congestion, f1: 0.573, acc: 0.829\n",
      "21: chest tube, f1: 0.449, acc: 0.949\n",
      "22: costophrenic angle blunting, f1: 0.566, acc: 0.828\n",
      "23: ij line, f1: 0.450, acc: 0.942\n",
      "24: pneumothorax, f1: 0.420, acc: 0.957\n",
      "25: linear/patchy atelectasis, f1: 0.657, acc: 0.711\n",
      "26: chest port, f1: 0.405, acc: 0.961\n",
      "27: atelectasis, f1: 0.633, acc: 0.724\n",
      "28: hyperaeration, f1: 0.405, acc: 0.934\n",
      "29: enlarged cardiomediastinum, f1: 0.542, acc: 0.796\n",
      "30: cabg grafts, f1: 0.365, acc: 0.967\n",
      "31: swan-ganz catheter, f1: 0.340, acc: 0.986\n",
      "32: lobar/segmental collapse, f1: 0.600, acc: 0.722\n",
      "33: pneumonia, f1: 0.534, acc: 0.778\n",
      "34: consolidation, f1: 0.563, acc: 0.749\n",
      "35: emphysema, f1: 0.340, acc: 0.953\n",
      "36: interstitial texture, f1: 0.634, acc: 0.659\n",
      "37: copd/emphysema, f1: 0.367, acc: 0.924\n",
      "38: hydropneumothorax, f1: 0.305, acc: 0.979\n",
      "39: infiltration, f1: 0.519, acc: 0.762\n",
      "40: tortuous aorta, f1: 0.388, acc: 0.890\n",
      "41: low lung volumes, f1: 0.464, acc: 0.799\n",
      "42: picc, f1: 0.348, acc: 0.910\n",
      "43: prosthetic valve, f1: 0.273, acc: 0.975\n",
      "44: elevated hemidiaphragm, f1: 0.285, acc: 0.955\n",
      "45: lung cancer, f1: 0.310, acc: 0.928\n",
      "46: alveolar texture, f1: 0.588, acc: 0.631\n",
      "47: hernia, f1: 0.215, acc: 0.983\n",
      "48: pneumomediastinum, f1: 0.206, acc: 0.987\n",
      "49: calcification of the aorta, f1: 0.300, acc: 0.889\n",
      "50: vascular calcification, f1: 0.257, acc: 0.932\n",
      "51: multiple masses/nodules, f1: 0.223, acc: 0.962\n",
      "52: interstitial lung disease, f1: 0.253, acc: 0.929\n",
      "53: subclavian line, f1: 0.207, acc: 0.974\n",
      "54: vascular redistribution, f1: 0.273, acc: 0.900\n",
      "55: nodule, f1: 0.241, acc: 0.929\n",
      "56: mediastinal displacement, f1: 0.214, acc: 0.950\n",
      "57: aortic graft/repair, f1: 0.194, acc: 0.963\n",
      "58: mass, f1: 0.247, acc: 0.899\n",
      "59: cyst/bullae, f1: 0.186, acc: 0.959\n",
      "60: pleural/parenchymal scarring, f1: 0.295, acc: 0.849\n",
      "61: lung lesion, f1: 0.295, acc: 0.846\n",
      "62: fibrosis, f1: 0.277, acc: 0.862\n",
      "63: intra-aortic balloon pump, f1: 0.149, acc: 0.989\n",
      "64: granulomatous disease, f1: 0.167, acc: 0.967\n",
      "65: bronchiectasis, f1: 0.147, acc: 0.987\n",
      "66: mediastinal widening, f1: 0.218, acc: 0.914\n",
      "67: sub-diaphragmatic air, f1: 0.140, acc: 0.991\n",
      "68: mass/nodule (not otherwise specified), f1: 0.231, acc: 0.889\n",
      "69: increased reticular markings/ild pattern, f1: 0.281, acc: 0.830\n",
      "70: pericardial effusion, f1: 0.124, acc: 0.985\n",
      "71: alveolar hemorrhage, f1: 0.125, acc: 0.967\n",
      "72: calcified nodule, f1: 0.125, acc: 0.965\n",
      "73: scoliosis, f1: 0.129, acc: 0.953\n",
      "74: goiter, f1: 0.094, acc: 0.987\n",
      "75: superior mediastinal mass/enlargement, f1: 0.083, acc: 0.990\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing MIMIC-CXR inputs/outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 217190/217190 [00:23<00:00, 9171.00it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 72/217190 reports without facts\u001b[0m\n",
      "len(mimiccxr_train_input_texts): 217118\n",
      "100%|█████████████████████████████████████| 5568/5568 [00:00<00:00, 9485.54it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 3/5568 reports without facts\u001b[0m\n",
      "len(mimiccxr_val_input_texts): 5565\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "pleural abnormalities:yes 3,yes 3\n",
      "emphysema:yes 2,yes 3\n",
      "tortuous aorta:yes 5,yes 6\n",
      "calcification of the aorta:yes 5,yes 7\n",
      "vascular calcification:no 1,yes 4\n",
      "lung lesion:no 2,yes 3\n",
      "fibrosis:no 4,yes 4\n",
      "calcified nodule:no 2,yes 3\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mclear lungs. hyperinflated lungs. top normal heart size. normal hilar contours. normal mediastinal contours. no pleural abnormality.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "tortuous aorta:yes 7,yes 6\n",
      "calcification of the aorta:yes 7,yes 5\n",
      "vascular calcification:yes 3,yes 3\n",
      "vascular redistribution:no 3,yes 4\n",
      "goiter:yes 4,no 3\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mno acute cardiopulmonary process. no acute fracture detected. concern for rib fractures. suggestion for dedicated rib radiographs. well expanded lungs. clear lungs. no pleural effusion. no pneumothorax. cardiomediastinal silhouette top-normal in size. no acute fracture. surgical clips in the left neck.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing CheXpert inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 136708/182199 reports with empty output\u001b[0m\n",
      "len(chexpert_train_input_texts): 45491\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 3491/4603 reports with empty output\u001b[0m\n",
      "len(chexpert_val_input_texts): 1112\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "pleural abnormalities:yes 5\n",
      "lung opacity:yes 7\n",
      "opacity texture:yes 5\n",
      "airspace opacity:yes 6\n",
      "vascular congestion:yes 6\n",
      "linear/patchy atelectasis:yes 6\n",
      "atelectasis:yes 4\n",
      "enlarged cardiomediastinum:yes 5\n",
      "consolidation:yes 2\n",
      "emphysema:yes 2\n",
      "interstitial texture:yes 6\n",
      "tortuous aorta:yes 7\n",
      "calcification of the aorta:yes 6\n",
      "vascular calcification:yes 5\n",
      "interstitial lung disease:yes 4\n",
      "vascular redistribution:yes 5\n",
      "fibrosis:yes 4\n",
      "increased reticular markings/ild pattern:yes 6\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mA portable supine radiograph of the chest was obtained. No focal pulmonary consolidation, pleural effusion, or pneumothorax is seen. The heart size is normal. The thoracic aorta is mildly ectatic. Otherwise, the mediastinum is grossly unremarkable given the supine technique and low lung volumes. There are mild reticular opacities throughout both lungs with indistinctness of the pulmonary vasculature. While this may be related to low lung volumes, a component of pulmonary edema may be present. No acute osseous abnormalities are seen. There are severe degenerative changes of the right shoulder, with overriding of the right humeral head, compatible with full thickness rotator cuff injury.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "pleural abnormalities:yes 3,yes 5\n",
      "lung opacity:no 3,yes 5\n",
      "opacity texture:no 2,yes 4\n",
      "enlarged cardiac silhouette:no 4,yes 6\n",
      "vascular congestion:yes 3,yes 5\n",
      "enlarged cardiomediastinum:no 4,yes 5\n",
      "emphysema:no 1,yes 4\n",
      "interstitial texture:no 3,yes 5\n",
      "tortuous aorta:yes 4,yes 6\n",
      "prosthetic valve:yes 3,no 2\n",
      "calcification of the aorta:yes 4,yes 6\n",
      "vascular calcification:yes 3,yes 5\n",
      "vascular redistribution:no 3,yes 5\n",
      "pleural/parenchymal scarring:no 3,yes 4\n",
      "lung lesion:no 2,yes 3\n",
      "fibrosis:yes 4,yes 6\n",
      "increased reticular markings/ild pattern:no 2,yes 4\n",
      "pericardial effusion:no 1,yes 3\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThere is mild opacity of the left lung base which could be related to atelectasis or early pneumonia. No pleural effusions are found. The left atrial contour of the heart appears somewhat prominent. There is mild degenerative change of the thoracic spine with mild dextroscoliosis.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing OpenI inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 477/3729 reports with empty output\u001b[0m\n",
      "len(openi_train_input_texts): 3252\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 12/97 reports with empty output\u001b[0m\n",
      "len(openi_val_input_texts): 85\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "lung opacity:no 0,yes 4\n",
      "no abnormalities:yes 8,yes 4\n",
      "linear/patchy atelectasis:no 1,yes 3\n",
      "tortuous aorta:no 1,yes 4\n",
      "calcification of the aorta:no 1,yes 3\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe cardiomediastinal silhouette is normal in size and contour. No focal consolidation, pneumothorax or large pleural effusion. Normal XXXX. XXXX cholecystectomy.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "no abnormalities:yes 8,yes 8\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mThe cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There is no pneumothorax or pleural effusion. There are no focal areas of consolidation.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing Interpret-CXR public test set inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 985/3677 reports without images or empty output\u001b[0m\n",
      "len(public_test_input_texts): 2692\n",
      "Examples:\n",
      "\u001b[1mPublic test example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:yes 4\n",
      "endotracheal tube:yes 7\n",
      "enteric tube:yes 6\n",
      "pleural abnormalities:yes 3\n",
      "lung opacity:yes 6\n",
      "opacity texture:yes 3\n",
      "support devices:yes 8\n",
      "subcutaneous air:yes 3\n",
      "airspace opacity:yes 5\n",
      "vascular congestion:yes 4\n",
      "chest tube:yes 4\n",
      "ij line:yes 8\n",
      "linear/patchy atelectasis:yes 4\n",
      "atelectasis:yes 4\n",
      "enlarged cardiomediastinum:yes 5\n",
      "swan-ganz catheter:yes 7\n",
      "prosthetic valve:yes 5\n",
      "vascular calcification:yes 3\n",
      "mediastinal displacement:yes 5\n",
      "aortic graft/repair:yes 5\n",
      "intra-aortic balloon pump:yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mFollowing left chest tube placement, left tension pneumothorax has substantially resolved. Small residual pneumothorax persists, but no evidence of tension. Small amount of pneumopericardium is likely related to recent surgery. Minimal atelectasis is present in the left lung base. There is no pleural effusion. Patient is status post median sternotomy, and sternal sutures are intact. Postoperative mediastinal widening and mildly enlarged heart size are stable. Endotracheal tube ends approximately 1.7 cm above the carina. Consider retracting the ET tube by 2 cm for appropriate seating. Orogastric tube ends into the stomach, and a Swan-Ganz catheter through the right internal jugular approach terminates approximately in the right main pulmonary artery.\u001b[0m\n",
      "\n",
      "Including public test set in training dataset...\n",
      "bronchiectasis: 16\n",
      "scoliosis: 22\n",
      "sub-diaphragmatic air: 47\n",
      "No labels: 277\n",
      "low lung volumes: 358\n",
      "granulomatous disease: 527\n",
      "cyst/bullae: 1202\n",
      "hyperaeration: 4337\n",
      "nodule: 4369\n",
      "alveolar texture: 4709\n",
      "hydropneumothorax: 6117\n",
      "alveolar hemorrhage: 7558\n",
      "pneumomediastinum: 8745\n",
      "subcutaneous emphysema: 10109\n",
      "copd/emphysema: 10161\n",
      "mass: 11375\n",
      "pneumothorax: 11697\n",
      "hernia: 12233\n",
      "fluid overload/heart failure: 13423\n",
      "subclavian line: 16170\n",
      "cabg grafts: 16623\n",
      "calcified nodule: 18234\n",
      "goiter: 18474\n",
      "mass/nodule (not otherwise specified): 18969\n",
      "tracheostomy tube: 20025\n",
      "cardiomegaly: 20573\n",
      "interstitial lung disease: 21515\n",
      "mediastinal widening: 22931\n",
      "picc: 26525\n",
      "subcutaneous air: 26971\n",
      "pigtail catheter: 27007\n",
      "superior mediastinal mass/enlargement: 29615\n",
      "chest port: 29654\n",
      "intra-aortic balloon pump: 30826\n",
      "swan-ganz catheter: 32952\n",
      "aortic graft/repair: 34120\n",
      "pleural/parenchymal scarring: 34444\n",
      "multiple masses/nodules: 35968\n",
      "emphysema: 36825\n",
      "lung cancer: 36864\n",
      "elevated hemidiaphragm: 37009\n",
      "pericardial effusion: 41989\n",
      "infiltration: 42921\n",
      "cardiac pacer and wires: 46692\n",
      "fibrosis: 49319\n",
      "mediastinal displacement: 52621\n",
      "endotracheal tube: 55494\n",
      "enlarged cardiac silhouette: 56021\n",
      "pulmonary edema/hazy opacity: 56056\n",
      "pneumonia: 56427\n",
      "chest tube: 57499\n",
      "edema: 59465\n",
      "no abnormalities: 61197\n",
      "increased reticular markings/ild pattern: 65106\n",
      "lung lesion: 67627\n",
      "enteric tube: 72907\n",
      "costophrenic angle blunting: 83212\n",
      "pleural effusion: 84966\n",
      "vascular redistribution: 94789\n",
      "interstitial texture: 97080\n",
      "prosthetic valve: 97718\n",
      "support devices: 103679\n",
      "enlarged cardiomediastinum: 108408\n",
      "ij line: 108938\n",
      "lobar/segmental collapse: 114213\n",
      "tortuous aorta: 133867\n",
      "atelectasis: 145522\n",
      "vascular calcification: 147457\n",
      "vascular congestion: 150633\n",
      "consolidation: 154238\n",
      "calcification of the aorta: 155233\n",
      "airspace opacity: 155941\n",
      "opacity texture: 177088\n",
      "lung opacity: 201682\n",
      "linear/patchy atelectasis: 209089\n",
      "pleural abnormalities: 212996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes: [36792, 14067, 13800, 12710, 11741, 10292, 9775, 9712, 8961, 7707, 6475, 5986, 5905, 5903, 5878, 5772, 5650, 5246, 5068, 4919, 4771, 4640, 4532, 4507, 4073, 4010, 3829, 3537, 3443, 3372, 3183, 3031, 3026, 3022, 2792, 2712, 2228, 2113, 2079, 1672, 1634, 1526, 1505, 1350, 1263, 1043, 967, 742, 725, 704, 668, 518, 446, 399, 358, 278, 277, 270, 223, 195, 184, 169, 168, 124, 108, 98, 80, 76, 54, 49, 48, 135]\n",
      "  len(indices) = 36792, weight = 3489.056767678069\n",
      "  len(indices) = 14067, weight = 2616.677569701033\n",
      "  len(indices) = 13800, weight = 2600.9598817636793\n",
      "  len(indices) = 12710, weight = 2534.1886758172827\n",
      "  len(indices) = 11741, weight = 2470.924641019512\n",
      "  len(indices) = 10292, weight = 2368.18565972543\n",
      "  len(indices) = 9775, weight = 2328.774827005463\n",
      "  len(indices) = 9712, weight = 2323.8615770803394\n",
      "  len(indices) = 8961, weight = 2263.2837630583954\n",
      "  len(indices) = 7707, weight = 2152.6621650457887\n",
      "  len(indices) = 6475, weight = 2029.4086113409926\n",
      "  len(indices) = 5986, weight = 1975.417040682102\n",
      "  len(indices) = 5905, weight = 1966.148219171306\n",
      "  len(indices) = 5903, weight = 1965.9181244413182\n",
      "  len(indices) = 5878, weight = 1963.0368655079449\n",
      "  len(indices) = 5772, weight = 1950.7145475320117\n",
      "  len(indices) = 5650, weight = 1936.314936204985\n",
      "  len(indices) = 5246, weight = 1886.858621731186\n",
      "  len(indices) = 5068, weight = 1864.1371449440821\n",
      "  len(indices) = 4919, weight = 1844.6428411996344\n",
      "  len(indices) = 4771, weight = 1824.8270820881846\n",
      "  len(indices) = 4640, weight = 1806.8917721585833\n",
      "  len(indices) = 4532, weight = 1791.8124576759558\n",
      "  len(indices) = 4507, weight = 1788.282879232502\n",
      "  len(indices) = 4073, weight = 1724.4928501529423\n",
      "  len(indices) = 4010, weight = 1714.80868719209\n",
      "  len(indices) = 3829, weight = 1686.3283791147912\n",
      "  len(indices) = 3537, weight = 1638.1538992177043\n",
      "  len(indices) = 3443, weight = 1622.006775353154\n",
      "  len(indices) = 3372, weight = 1609.5886094009054\n",
      "  len(indices) = 3183, weight = 1575.543266272346\n",
      "  len(indices) = 3031, weight = 1547.041774762268\n",
      "  len(indices) = 3026, weight = 1546.0861584176546\n",
      "  len(indices) = 3022, weight = 1545.3208117763515\n",
      "  len(indices) = 2792, weight = 1499.9767282026453\n",
      "  len(indices) = 2712, weight = 1483.5494578483074\n",
      "  len(indices) = 2228, weight = 1375.6058849552123\n",
      "  len(indices) = 2113, weight = 1347.4301154864438\n",
      "  len(indices) = 2079, weight = 1338.8831899556926\n",
      "  len(indices) = 1672, weight = 1227.5723799284503\n",
      "  len(indices) = 1634, weight = 1216.2001810036945\n",
      "  len(indices) = 1526, weight = 1182.7897815319836\n",
      "  len(indices) = 1505, weight = 1176.0947918484187\n",
      "  len(indices) = 1350, weight = 1124.4564024013926\n",
      "  len(indices) = 1263, weight = 1093.5671054773313\n",
      "  len(indices) = 1043, weight = 1007.9781562050789\n",
      "  len(indices) = 967, weight = 975.4158809088976\n",
      "  len(indices) = 742, weight = 866.9613161526532\n",
      "  len(indices) = 725, weight = 857.872514013076\n",
      "  len(indices) = 704, weight = 846.4379490955091\n",
      "  len(indices) = 668, weight = 826.2718180340576\n",
      "  len(indices) = 518, weight = 733.0920466569294\n",
      "  len(indices) = 446, weight = 681.6810861294584\n",
      "  len(indices) = 399, weight = 645.0273987281234\n",
      "  len(indices) = 358, weight = 610.623744674081\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 277, weight = 534.1504621238341\n",
      "  len(indices) = 270, weight = 526.8906631574398\n",
      "  len(indices) = 223, weight = 474.71626868396766\n",
      "  len(indices) = 195, weight = 440.2474222842083\n",
      "  len(indices) = 184, weight = 425.8635843953102\n",
      "  len(indices) = 169, weight = 405.3684909627789\n",
      "  len(indices) = 168, weight = 403.96321604889306\n",
      "  len(indices) = 124, weight = 336.310819069364\n",
      "  len(indices) = 108, weight = 308.2154192941874\n",
      "  len(indices) = 98, weight = 289.4225699262594\n",
      "  len(indices) = 80, weight = 252.66707670360077\n",
      "  len(indices) = 76, weight = 243.89783600777827\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 48, weight = 174.20506759073166\n",
      "  len(indices) = 135, weight = 354.4162593823014\n",
      "seq2seq_trainer.name =  fact_classifier_predictions2report_section(sigmoids2findings)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_97_s2s_loss=0.3982.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/checkpoint_97_s2s_loss=0.3982.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 98/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.81683, s2s_loss 1.27441, 127.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.54028, 20.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_98_s2s_loss=0.3983.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 99/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.49060, s2s_loss 1.29066, 117.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53830, 20.19 secs\n",
      "\u001b[1m---- Epoch 100/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.51337, s2s_loss 1.28959, 117.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53981, 19.87 secs\n",
      "\u001b[1m---- Epoch 101/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.07635, s2s_loss 1.29620, 117.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.56783, 19.92 secs\n",
      "\u001b[1m---- Epoch 102/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.37903, s2s_loss 1.28149, 117.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.55888, 20.50 secs\n",
      "\u001b[1m---- Epoch 103/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.55660, s2s_loss 1.27605, 118.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.54380, 19.59 secs\n",
      "\u001b[1m---- Epoch 104/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.00995, s2s_loss 1.28561, 116.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53831, 20.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_104_s2s_loss=0.3983.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 105/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.36776, s2s_loss 1.27960, 117.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53654, 19.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_105_s2s_loss=0.3987.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 106/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.15442, s2s_loss 1.25731, 117.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53529, 20.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_106_s2s_loss=0.3993.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 107/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.19622, s2s_loss 1.26082, 117.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53569, 19.68 secs\n",
      "\u001b[1m---- Epoch 108/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.10461, s2s_loss 1.27872, 117.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53491, 19.63 secs\n",
      "\u001b[1m---- Epoch 109/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.21797, s2s_loss 1.28007, 118.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.54641, 19.78 secs\n",
      "\u001b[1m---- Epoch 110/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.70562, s2s_loss 1.29173, 116.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.54438, 19.53 secs\n",
      "\u001b[1m---- Epoch 111/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.37285, s2s_loss 1.27458, 116.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53182, 19.71 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_111_s2s_loss=0.3994.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 112/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.15064, s2s_loss 1.26780, 117.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52723, 19.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_112_s2s_loss=0.4002.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 113/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.14812, s2s_loss 1.25474, 116.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52982, 19.73 secs\n",
      "\u001b[1m---- Epoch 114/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.49696, s2s_loss 1.27266, 118.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52708, 19.90 secs\n",
      "\u001b[1m---- Epoch 115/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.05932, s2s_loss 1.26643, 115.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52769, 19.88 secs\n",
      "\u001b[1m---- Epoch 116/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.06221, s2s_loss 1.26511, 117.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52715, 19.85 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_116_s2s_loss=0.4003.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 117/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.88270, s2s_loss 1.27533, 117.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.54446, 20.06 secs\n",
      "\u001b[1m---- Epoch 118/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.18296, s2s_loss 1.27136, 117.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52895, 20.20 secs\n",
      "\u001b[1m---- Epoch 119/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.02293, s2s_loss 1.27314, 117.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52793, 19.53 secs\n",
      "\u001b[1m---- Epoch 120/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.04306, s2s_loss 1.26427, 117.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52514, 19.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_120_s2s_loss=0.4006.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 121/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.37846, s2s_loss 1.26549, 118.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52303, 20.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_121_s2s_loss=0.4009.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 122/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.78320, s2s_loss 1.25606, 117.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52028, 20.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_122_s2s_loss=0.4014.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 123/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.07308, s2s_loss 1.26115, 116.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51901, 19.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_123_s2s_loss=0.4015.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 124/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.41328, s2s_loss 1.25832, 118.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52034, 19.85 secs\n",
      "\u001b[1m---- Epoch 125/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.37106, s2s_loss 1.28230, 117.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.55450, 20.27 secs\n",
      "\u001b[1m---- Epoch 126/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.20307, s2s_loss 1.26627, 118.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.53440, 20.10 secs\n",
      "\u001b[1m---- Epoch 127/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.48058, s2s_loss 1.27081, 118.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51989, 19.75 secs\n",
      "\u001b[1m---- Epoch 128/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.43254, s2s_loss 1.25845, 117.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51789, 19.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_128_s2s_loss=0.4017.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 129/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.39469, s2s_loss 1.26427, 118.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51713, 19.92 secs\n",
      "\u001b[1m---- Epoch 130/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.55727, s2s_loss 1.24878, 118.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51534, 19.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_130_s2s_loss=0.4023.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 131/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.15554, s2s_loss 1.24775, 117.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51417, 19.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_131_s2s_loss=0.4025.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 132/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.90277, s2s_loss 1.25496, 117.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51378, 19.85 secs\n",
      "\u001b[1m---- Epoch 133/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.21124, s2s_loss 1.27229, 117.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52785, 20.23 secs\n",
      "\u001b[1m---- Epoch 134/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.23908, s2s_loss 1.26547, 118.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52765, 20.06 secs\n",
      "\u001b[1m---- Epoch 135/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.87511, s2s_loss 1.26163, 117.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51659, 20.10 secs\n",
      "\u001b[1m---- Epoch 136/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.45769, s2s_loss 1.24195, 118.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50817, 19.56 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_136_s2s_loss=0.4034.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 137/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.24485, s2s_loss 1.23878, 117.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51055, 19.96 secs\n",
      "\u001b[1m---- Epoch 138/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.30744, s2s_loss 1.23707, 118.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50692, 19.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_138_s2s_loss=0.4037.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 139/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.50961, s2s_loss 1.24353, 117.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50568, 19.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_139_s2s_loss=0.4038.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 140/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.13754, s2s_loss 1.24138, 116.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50611, 20.03 secs\n",
      "\u001b[1m---- Epoch 141/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.89686, s2s_loss 1.25695, 116.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52115, 19.93 secs\n",
      "\u001b[1m---- Epoch 142/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.05831, s2s_loss 1.25830, 116.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.51348, 19.80 secs\n",
      "\u001b[1m---- Epoch 143/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.05970, s2s_loss 1.24022, 116.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50759, 20.25 secs\n",
      "\u001b[1m---- Epoch 144/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.96205, s2s_loss 1.23473, 118.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50194, 19.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_144_s2s_loss=0.4045.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 145/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.22186, s2s_loss 1.25400, 118.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50054, 19.70 secs\n",
      "\u001b[1m---- Epoch 146/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.55240, s2s_loss 1.23592, 116.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.49930, 19.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_146_s2s_loss=0.4048.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 147/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.70250, s2s_loss 1.24278, 117.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.49885, 20.21 secs\n",
      "\u001b[1m---- Epoch 148/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.75954, s2s_loss 1.24722, 116.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.49921, 20.12 secs\n",
      "\u001b[1m---- Epoch 149/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.24429, s2s_loss 1.25847, 116.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.52820, 20.16 secs\n",
      "\u001b[1m---- Epoch 150/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.30287, s2s_loss 1.24841, 117.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50612, 19.81 secs\n",
      "\u001b[1m---- Epoch 151/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.05957, s2s_loss 1.24550, 118.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.50195, 19.69 secs\n",
      "\u001b[1m---- Epoch 152/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.15561, s2s_loss 1.23087, 117.22 secs\n",
      "(2) Validation stage ...\n",
      "   iteration 125\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.84296, s2s_loss 1.21347, 117.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46566, 20.01 secs\n",
      "\u001b[1m---- Epoch 208/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.87519, s2s_loss 1.21884, 117.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45743, 20.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_208_s2s_loss=0.4113.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 209/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.53483, s2s_loss 1.20534, 116.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45973, 19.43 secs\n",
      "\u001b[1m---- Epoch 210/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.99230, s2s_loss 1.19769, 118.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45905, 20.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_210_s2s_loss=0.4115.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 211/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.02409, s2s_loss 1.19817, 117.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45798, 19.91 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_211_s2s_loss=0.4116.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 212/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.61311, s2s_loss 1.19320, 117.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45823, 20.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_212_s2s_loss=0.4117.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 213/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.08750, s2s_loss 1.21331, 116.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.47672, 19.73 secs\n",
      "\u001b[1m---- Epoch 214/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.09460, s2s_loss 1.20733, 116.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46790, 20.12 secs\n",
      "\u001b[1m---- Epoch 215/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.24782, s2s_loss 1.20290, 116.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46179, 19.67 secs\n",
      "\u001b[1m---- Epoch 216/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.69900, s2s_loss 1.18226, 117.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46036, 19.63 secs\n",
      "\u001b[1m---- Epoch 217/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.59877, s2s_loss 1.20167, 117.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45744, 20.01 secs\n",
      "\u001b[1m---- Epoch 218/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.90075, s2s_loss 1.18770, 116.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45423, 19.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_218_s2s_loss=0.4124.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 219/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.06593, s2s_loss 1.18552, 117.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45582, 19.93 secs\n",
      "\u001b[1m---- Epoch 220/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.37883, s2s_loss 1.19047, 117.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45596, 19.73 secs\n",
      "\u001b[1m---- Epoch 221/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.03331, s2s_loss 1.21574, 117.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.47604, 19.83 secs\n",
      "\u001b[1m---- Epoch 222/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.20434, s2s_loss 1.20842, 118.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46612, 19.78 secs\n",
      "\u001b[1m---- Epoch 223/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.91137, s2s_loss 1.19986, 117.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45886, 19.93 secs\n",
      "\u001b[1m---- Epoch 224/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.62859, s2s_loss 1.18760, 117.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45335, 19.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_224_s2s_loss=0.4126.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 225/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.46776, s2s_loss 1.18215, 116.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45505, 19.49 secs\n",
      "\u001b[1m---- Epoch 226/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.15855, s2s_loss 1.18902, 116.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45327, 19.91 secs\n",
      "\u001b[1m---- Epoch 227/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.15554, s2s_loss 1.18057, 116.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45301, 19.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_227_s2s_loss=0.4128.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 228/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.21538, s2s_loss 1.19829, 115.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45221, 19.47 secs\n",
      "\u001b[1m---- Epoch 229/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.11643, s2s_loss 1.19990, 117.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.47120, 19.79 secs\n",
      "\u001b[1m---- Epoch 230/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.14580, s2s_loss 1.20835, 116.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45837, 20.05 secs\n",
      "\u001b[1m---- Epoch 231/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.17551, s2s_loss 1.19155, 118.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45486, 19.70 secs\n",
      "\u001b[1m---- Epoch 232/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.16383, s2s_loss 1.18663, 116.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45004, 20.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_232_s2s_loss=0.4131.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 233/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.14752, s2s_loss 1.19374, 118.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44759, 20.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_233_s2s_loss=0.4133.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 234/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.20511, s2s_loss 1.18270, 117.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44741, 20.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_234_s2s_loss=0.4136.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 235/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.14239, s2s_loss 1.18815, 116.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44691, 19.82 secs\n",
      "\u001b[1m---- Epoch 236/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.22718, s2s_loss 1.18869, 117.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44615, 20.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_236_s2s_loss=0.4136.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 237/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.43884, s2s_loss 1.20302, 116.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46606, 19.67 secs\n",
      "\u001b[1m---- Epoch 238/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.59808, s2s_loss 1.19342, 116.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46473, 20.36 secs\n",
      "\u001b[1m---- Epoch 239/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.14334, s2s_loss 1.19501, 117.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45396, 20.03 secs\n",
      "\u001b[1m---- Epoch 240/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.36697, s2s_loss 1.18320, 117.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44495, 19.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_240_s2s_loss=0.4139.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 241/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.99675, s2s_loss 1.17921, 116.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44574, 19.94 secs\n",
      "\u001b[1m---- Epoch 242/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.76529, s2s_loss 1.17901, 118.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44254, 19.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_242_s2s_loss=0.4144.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 243/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.26238, s2s_loss 1.18173, 118.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44392, 20.06 secs\n",
      "\u001b[1m---- Epoch 244/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.58212, s2s_loss 1.18522, 117.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44289, 19.75 secs\n",
      "\u001b[1m---- Epoch 245/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.18345, s2s_loss 1.18291, 117.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.46306, 19.97 secs\n",
      "\u001b[1m---- Epoch 246/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.65668, s2s_loss 1.19194, 116.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44809, 19.89 secs\n",
      "\u001b[1m---- Epoch 247/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.01612, s2s_loss 1.18582, 116.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44034, 19.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_247_s2s_loss=0.4146.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 248/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.65986, s2s_loss 1.18711, 118.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44043, 20.14 secs\n",
      "\u001b[1m---- Epoch 249/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.05842, s2s_loss 1.17596, 118.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43762, 19.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_249_s2s_loss=0.4152.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 250/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.42153, s2s_loss 1.17484, 116.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43701, 19.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_250_s2s_loss=0.4153.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 251/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.03387, s2s_loss 1.17587, 118.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43594, 20.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_251_s2s_loss=0.4154.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 252/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.01109, s2s_loss 1.19213, 117.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43603, 19.65 secs\n",
      "\u001b[1m---- Epoch 253/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.28080, s2s_loss 1.19351, 118.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45663, 19.77 secs\n",
      "\u001b[1m---- Epoch 254/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.39557, s2s_loss 1.18706, 116.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44853, 19.70 secs\n",
      "\u001b[1m---- Epoch 255/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.97025, s2s_loss 1.18589, 117.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44251, 19.89 secs\n",
      "\u001b[1m---- Epoch 256/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.30480, s2s_loss 1.17684, 116.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44070, 20.21 secs\n",
      "\u001b[1m---- Epoch 257/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.39285, s2s_loss 1.17641, 117.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43905, 20.21 secs\n",
      "\u001b[1m---- Epoch 258/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.22686, s2s_loss 1.18185, 116.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43847, 19.76 secs\n",
      "\u001b[1m---- Epoch 259/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.14546, s2s_loss 1.17284, 117.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43724, 20.06 secs\n",
      "\u001b[1m---- Epoch 260/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.15442, s2s_loss 1.16638, 117.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43702, 19.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_260_s2s_loss=0.4155.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 261/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.74284, s2s_loss 1.18923, 119.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.45334, 19.79 secs\n",
      "\u001b[1m---- Epoch 262/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.36595, s2s_loss 1.19748, 118.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44692, 19.96 secs\n",
      "\u001b[1m---- Epoch 263/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.96688, s2s_loss 1.17405, 117.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43856, 19.82 secs\n",
      "\u001b[1m---- Epoch 264/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.05247, s2s_loss 1.17585, 117.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43585, 19.65 secs\n",
      "\u001b[1m---- Epoch 265/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.32079, s2s_loss 1.17542, 116.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43321, 19.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_265_s2s_loss=0.4158.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 266/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.20306, s2s_loss 1.16559, 118.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43123, 20.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_266_s2s_loss=0.4164.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 267/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.27319, s2s_loss 1.16566, 117.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43220, 19.72 secs\n",
      "\u001b[1m---- Epoch 268/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.55295, s2s_loss 1.17146, 117.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43233, 20.30 secs\n",
      "\u001b[1m---- Epoch 269/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.11864, s2s_loss 1.19208, 115.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44231, 19.88 secs\n",
      "\u001b[1m---- Epoch 270/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.85668, s2s_loss 1.19165, 117.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43797, 19.96 secs\n",
      "\u001b[1m---- Epoch 271/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.02353, s2s_loss 1.16978, 118.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43538, 19.87 secs\n",
      "\u001b[1m---- Epoch 272/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.10778, s2s_loss 1.16725, 117.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43126, 19.89 secs\n",
      "\u001b[1m---- Epoch 273/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.85525, s2s_loss 1.17404, 118.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43004, 19.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_273_s2s_loss=0.4164.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 274/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.49443, s2s_loss 1.16873, 117.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42921, 19.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_274_s2s_loss=0.4166.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 275/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.27091, s2s_loss 1.16449, 117.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42806, 20.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_275_s2s_loss=0.4169.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 276/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.08183, s2s_loss 1.16700, 116.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42710, 19.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_276_s2s_loss=0.4170.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 277/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.13848, s2s_loss 1.17265, 118.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44464, 20.11 secs\n",
      "\u001b[1m---- Epoch 278/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.16724, s2s_loss 1.18640, 116.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43376, 19.69 secs\n",
      "\u001b[1m---- Epoch 279/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.66312, s2s_loss 1.15247, 116.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43076, 19.63 secs\n",
      "\u001b[1m---- Epoch 280/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.42233, s2s_loss 1.15905, 116.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42447, 19.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_280_s2s_loss=0.4175.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 281/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.58985, s2s_loss 1.16249, 116.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42435, 19.90 secs\n",
      "\u001b[1m---- Epoch 282/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.64241, s2s_loss 1.16381, 115.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42314, 19.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_282_s2s_loss=0.4176.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 283/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.34250, s2s_loss 1.17198, 118.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42214, 19.85 secs\n",
      "\u001b[1m---- Epoch 284/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.12962, s2s_loss 1.16851, 117.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42286, 19.94 secs\n",
      "\u001b[1m---- Epoch 285/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.76241, s2s_loss 1.18432, 117.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.44208, 19.57 secs\n",
      "\u001b[1m---- Epoch 286/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.44243, s2s_loss 1.18662, 117.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43706, 19.74 secs\n",
      "\u001b[1m---- Epoch 287/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.33087, s2s_loss 1.17032, 117.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.43236, 19.94 secs\n",
      "\u001b[1m---- Epoch 288/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.87247, s2s_loss 1.17270, 118.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42230, 20.01 secs\n",
      "\u001b[1m---- Epoch 289/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.02080, s2s_loss 1.15256, 116.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42542, 19.76 secs\n",
      "\u001b[1m---- Epoch 290/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.04785, s2s_loss 1.16448, 117.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42203, 20.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_290_s2s_loss=0.4178.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 291/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.20692, s2s_loss 1.16874, 117.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42202, 20.03 secs\n",
      "\u001b[1m---- Epoch 292/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.79731, s2s_loss 1.16373, 117.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.42159, 19.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_292_s2s_loss=0.4179.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 293/397\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "   iteration 293750\r"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/seq2seq/20240511_231851_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 1500 \\\n",
    "--batch_size 3 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 30 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"fact_classifier_predictions2report_section\" \\\n",
    "--experiment_name \"sigmoids2findings\" \\\n",
    "--interpret_cxr__label_based_predictions_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\" \\\n",
    "--interpret_cxr_challenge_data_dir \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\" \\\n",
    "--mimiccxr_integrated_report_nli_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--report_section_to_generate \"findings\" \\\n",
    "--best_k_classes 75 \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--bart_model_name \"facebook/bart-base\" \\\n",
    "--include_public_test_in_train \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
