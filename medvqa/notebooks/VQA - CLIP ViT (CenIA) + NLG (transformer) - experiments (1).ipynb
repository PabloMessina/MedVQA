{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-large-huggingface\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/vte-vit-large-patch16-bio-clinical-bert-finetuned-v3\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,4e-4,76,5e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 6\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "Downloading: 100%|█████████████████████████| 4.49k/4.49k [00:00<00:00, 2.57MB/s]\n",
      "Downloading: 100%|███████████████████████████| 789M/789M [00:37<00:00, 22.3MB/s]\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf-v3+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "---- Epoch 1/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 11.91934, a_loss 8.41806, cD 0.00038, wmdcmp 0.00127, oracc 0.40265, orien_loss 1.07992, chxlmicf1 0.20415, chxlmacf1 0.27031, chx_loss 1.11005, chxlacc 0.46717, chxlrocaucmic 0.47398, chxlrocaucmac 0.50517, qlmicf1 0.12142, qlmacf1 0.12663, ql_loss 1.08784, gacc 0.45443, gloss 0.75700, cxr14micf1 0.13354, cxr14macf1 0.17688, cxr14_loss 1.24080, vnbgmicf1 0.12053, vnbgmacf1 0.16221, vnbg_loss 9.46339, ema 0.00000, 169.99 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.00024, wmdcmp 0.00149, oracc 0.51029, chxlmicf1 0.24242, chxlmacf1 0.30248, chxlacc 0.47864, chxlrocaucmic 0.48656, chxlrocaucmac 0.53318, qlmicf1 0.14366, qlmacf1 0.15242, ema 0.00000, 57.20 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "---- Epoch 2/80\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 11.61823, a_loss 7.11320, cD 0.00027, wmdcmp 0.00011, oracc 0.55808, orien_loss 0.95690, chxlmicf1 0.26613, chxlmacf1 0.31096, chx_loss 1.08602, chxlacc 0.50689, chxlrocaucmic 0.54275, chxlrocaucmac 0.56535, qlmicf1 0.15579, qlmacf1 0.14070, ql_loss 1.06130, gacc 0.49682, gloss 0.71514, cxr14micf1 0.14929, cxr14macf1 0.19150, cxr14_loss 1.22710, vnbgmicf1 0.14279, vnbgmacf1 0.18717, vnbg_loss 7.80719, ema 0.01944, 143.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, oracc 0.68744, chxlmicf1 0.35813, chxlmacf1 0.36986, chxlacc 0.54719, chxlrocaucmic 0.58785, chxlrocaucmac 0.61940, qlmicf1 0.20116, qlmacf1 0.17353, ema 0.03636, 54.18 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "---- Epoch 3/80\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 10.50250, a_loss 5.04177, cD 0.04006, wmdcmp 0.00915, oracc 0.80981, orien_loss 0.65105, chxlmicf1 0.44047, chxlmacf1 0.40594, chx_loss 1.01625, chxlacc 0.62346, chxlrocaucmic 0.71065, chxlrocaucmac 0.70100, qlmicf1 0.27454, qlmacf1 0.17017, ql_loss 0.98962, gacc 0.57239, gloss 0.67565, cxr14micf1 0.20583, cxr14macf1 0.23595, cxr14_loss 1.18324, vnbgmicf1 0.31005, vnbgmacf1 0.28751, vnbg_loss 5.45091, ema 0.00509, 143.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.01404, wmdcmp 0.02036, oracc 0.86341, chxlmicf1 0.50047, chxlmacf1 0.45444, chxlacc 0.65579, chxlrocaucmic 0.73947, chxlrocaucmac 0.72657, qlmicf1 0.32754, qlmacf1 0.20570, ema 0.00000, 54.57 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-05.\n",
      "---- Epoch 4/80\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 8.46126, a_loss 2.65676, cD 0.09786, wmdcmp 0.02232, oracc 0.90398, orien_loss 0.31767, chxlmicf1 0.50231, chxlmacf1 0.45709, chx_loss 0.92953, chxlacc 0.68801, chxlrocaucmic 0.78063, chxlrocaucmac 0.75849, qlmicf1 0.36413, qlmacf1 0.20602, ql_loss 0.89454, gacc 0.65545, gloss 0.63020, cxr14micf1 0.30528, cxr14macf1 0.30409, cxr14_loss 1.07046, vnbgmicf1 0.52013, vnbgmacf1 0.38879, vnbg_loss 2.80082, ema 0.24208, 143.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.18388, wmdcmp 0.05305, oracc 0.94527, chxlmicf1 0.52249, chxlmacf1 0.47121, chxlacc 0.68160, chxlrocaucmic 0.77297, chxlrocaucmac 0.75322, qlmicf1 0.38479, qlmacf1 0.24200, ema 0.58000, 54.63 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-04.\n",
      "---- Epoch 5/80\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 7.04052, a_loss 1.54272, cD 0.45114, wmdcmp 0.07054, oracc 0.95269, orien_loss 0.14580, chxlmicf1 0.51792, chxlmacf1 0.47173, chx_loss 0.89112, chxlacc 0.70786, chxlrocaucmic 0.79439, chxlrocaucmac 0.77433, qlmicf1 0.36029, qlmacf1 0.21651, ql_loss 0.83763, gacc 0.72591, gloss 0.55421, cxr14micf1 0.34196, cxr14macf1 0.33267, cxr14_loss 0.98057, vnbgmicf1 0.53443, vnbgmacf1 0.40640, vnbg_loss 1.18034, ema 0.55259, 143.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.72926, wmdcmp 0.11451, oracc 0.97972, chxlmicf1 0.53544, chxlmacf1 0.48253, chxlacc 0.70148, chxlrocaucmic 0.78266, chxlrocaucmac 0.76014, qlmicf1 0.36149, qlmacf1 0.25508, ema 0.55364, 54.84 secs\n",
      "Adjusting learning rate of group 0 to 3.7759e-04.\n",
      "---- Epoch 6/80\n",
      "(1) Training stage (lr = 0.000378) ...\n",
      "loss 5.53360, a_loss 1.23080, cD 0.80785, wmdcmp 0.11552, oracc 0.96679, orien_loss 0.09167, chxlmicf1 0.52174, chxlmacf1 0.47424, chx_loss 0.88195, chxlacc 0.71329, chxlrocaucmic 0.79810, chxlrocaucmac 0.77751, qlmicf1 0.36331, qlmacf1 0.22130, ql_loss 0.82445, gacc 0.77205, gloss 0.49257, cxr14micf1 0.34383, cxr14macf1 0.33919, cxr14_loss 0.95291, vnbgmicf1 0.54943, vnbgmacf1 0.42037, vnbg_loss 0.86623, ema 0.62940, 144.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.92092, wmdcmp 0.14836, oracc 0.97972, chxlmicf1 0.52976, chxlmacf1 0.48406, chxlacc 0.69039, chxlrocaucmic 0.77554, chxlrocaucmac 0.75858, qlmicf1 0.36899, qlmacf1 0.25336, ema 0.61636, 58.58 secs\n",
      "Adjusting learning rate of group 0 to 3.5643e-04.\n",
      "---- Epoch 7/80\n",
      "(1) Training stage (lr = 0.000356) ...\n",
      "loss 5.09802, a_loss 1.13745, cD 0.96182, wmdcmp 0.13425, oracc 0.97234, orien_loss 0.07003, chxlmicf1 0.52402, chxlmacf1 0.47674, chx_loss 0.87740, chxlacc 0.71484, chxlrocaucmic 0.80080, chxlrocaucmac 0.78098, qlmicf1 0.36740, qlmacf1 0.22125, ql_loss 0.81109, gacc 0.80170, gloss 0.45075, cxr14micf1 0.34727, cxr14macf1 0.34103, cxr14_loss 0.95214, vnbgmicf1 0.55206, vnbgmacf1 0.41916, vnbg_loss 0.81165, ema 0.66731, 239.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.83905, wmdcmp 0.14025, oracc 0.98121, chxlmicf1 0.54078, chxlmacf1 0.48612, chxlacc 0.70351, chxlrocaucmic 0.78685, chxlrocaucmac 0.76324, qlmicf1 0.37400, qlmacf1 0.26402, ema 0.63273, 94.38 secs\n",
      "Adjusting learning rate of group 0 to 3.3646e-04.\n",
      "---- Epoch 8/80\n",
      "(1) Training stage (lr = 0.000336) ...\n",
      "loss 4.74668, a_loss 1.08246, cD 1.03481, wmdcmp 0.14266, oracc 0.97512, orien_loss 0.06101, chxlmicf1 0.52581, chxlmacf1 0.47870, chx_loss 0.87611, chxlacc 0.71551, chxlrocaucmic 0.80217, chxlrocaucmac 0.78207, qlmicf1 0.36938, qlmacf1 0.22471, ql_loss 0.81080, gacc 0.81284, gloss 0.43110, cxr14micf1 0.35363, cxr14macf1 0.34474, cxr14_loss 0.94258, vnbgmicf1 0.56360, vnbgmacf1 0.43042, vnbg_loss 0.76901, ema 0.67083, 263.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.97438, wmdcmp 0.14795, oracc 0.98121, chxlmicf1 0.53929, chxlmacf1 0.48724, chxlacc 0.70387, chxlrocaucmic 0.78569, chxlrocaucmac 0.76475, qlmicf1 0.38240, qlmacf1 0.26041, ema 0.63455, 96.84 secs\n",
      "Adjusting learning rate of group 0 to 3.1761e-04.\n",
      "---- Epoch 9/80\n",
      "(1) Training stage (lr = 0.000318) ...\n",
      "loss 5.02264, a_loss 1.04379, cD 1.09006, wmdcmp 0.15020, oracc 0.97599, orien_loss 0.05563, chxlmicf1 0.52857, chxlmacf1 0.48049, chx_loss 0.86715, chxlacc 0.71972, chxlrocaucmic 0.80461, chxlrocaucmac 0.78585, qlmicf1 0.36847, qlmacf1 0.22697, ql_loss 0.80685, gacc 0.82557, gloss 0.41326, cxr14micf1 0.36124, cxr14macf1 0.35345, cxr14_loss 0.92959, vnbgmicf1 0.57800, vnbgmacf1 0.44052, vnbg_loss 0.74699, ema 0.68593, 265.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07472, wmdcmp 0.16122, oracc 0.98121, chxlmicf1 0.52857, chxlmacf1 0.48035, chxlacc 0.69955, chxlrocaucmic 0.77701, chxlrocaucmac 0.76262, qlmicf1 0.39501, qlmacf1 0.25999, ema 0.65727, 96.21 secs\n",
      "Adjusting learning rate of group 0 to 2.9982e-04.\n",
      "---- Epoch 10/80\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 4.68490, a_loss 1.02266, cD 1.12736, wmdcmp 0.15417, oracc 0.97714, orien_loss 0.05063, chxlmicf1 0.52936, chxlmacf1 0.48056, chx_loss 0.86512, chxlacc 0.71781, chxlrocaucmic 0.80555, chxlrocaucmac 0.78575, qlmicf1 0.37601, qlmacf1 0.22983, ql_loss 0.80060, gacc 0.82727, gloss 0.39664, cxr14micf1 0.35553, cxr14macf1 0.34665, cxr14_loss 0.94114, vnbgmicf1 0.57270, vnbgmacf1 0.43528, vnbg_loss 0.74894, ema 0.68690, 261.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.10253, wmdcmp 0.16179, oracc 0.98345, chxlmicf1 0.53679, chxlmacf1 0.48441, chxlacc 0.69874, chxlrocaucmic 0.78485, chxlrocaucmac 0.76619, qlmicf1 0.39790, qlmacf1 0.26347, ema 0.66727, 96.98 secs\n",
      "Adjusting learning rate of group 0 to 2.8302e-04.\n",
      "---- Epoch 11/80\n",
      "(1) Training stage (lr = 0.000283) ...\n",
      "loss 4.56235, a_loss 1.00213, cD 1.15225, wmdcmp 0.15750, oracc 0.97694, orien_loss 0.04502, chxlmicf1 0.53260, chxlmacf1 0.48329, chx_loss 0.86489, chxlacc 0.72123, chxlrocaucmic 0.80662, chxlrocaucmac 0.78723, qlmicf1 0.37467, qlmacf1 0.23352, ql_loss 0.80427, gacc 0.83477, gloss 0.39059, cxr14micf1 0.36151, cxr14macf1 0.35363, cxr14_loss 0.92054, vnbgmicf1 0.58382, vnbgmacf1 0.44836, vnbg_loss 0.72015, ema 0.69727, 264.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09710, wmdcmp 0.15786, oracc 0.98464, chxlmicf1 0.53364, chxlmacf1 0.48488, chxlacc 0.69876, chxlrocaucmic 0.77914, chxlrocaucmac 0.76561, qlmicf1 0.38381, qlmacf1 0.26096, ema 0.66091, 95.95 secs\n",
      "Adjusting learning rate of group 0 to 2.6716e-04.\n",
      "---- Epoch 12/80\n",
      "(1) Training stage (lr = 0.000267) ...\n",
      "loss 4.52858, a_loss 0.99135, cD 1.18615, wmdcmp 0.16100, oracc 0.97752, orien_loss 0.04501, chxlmicf1 0.52922, chxlmacf1 0.48075, chx_loss 0.86563, chxlacc 0.71888, chxlrocaucmic 0.80625, chxlrocaucmac 0.78698, qlmicf1 0.37706, qlmacf1 0.22848, ql_loss 0.79638, gacc 0.84295, gloss 0.37533, cxr14micf1 0.35791, cxr14macf1 0.34887, cxr14_loss 0.93633, vnbgmicf1 0.58046, vnbgmacf1 0.44431, vnbg_loss 0.71861, ema 0.70977, 265.11 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.02141, wmdcmp 0.15224, oracc 0.98464, chxlmicf1 0.54151, chxlmacf1 0.48875, chxlacc 0.70833, chxlrocaucmic 0.78777, chxlrocaucmac 0.76742, qlmicf1 0.39396, qlmacf1 0.26223, ema 0.67545, 96.10 secs\n",
      "Adjusting learning rate of group 0 to 2.5219e-04.\n",
      "---- Epoch 13/80\n",
      "(1) Training stage (lr = 0.000252) ...\n",
      "loss 4.74691, a_loss 0.97672, cD 1.23258, wmdcmp 0.16536, oracc 0.98100, orien_loss 0.03768, chxlmicf1 0.53043, chxlmacf1 0.48126, chx_loss 0.86477, chxlacc 0.72041, chxlrocaucmic 0.80621, chxlrocaucmac 0.78615, qlmicf1 0.37592, qlmacf1 0.23674, ql_loss 0.80100, gacc 0.84500, gloss 0.36773, cxr14micf1 0.36697, cxr14macf1 0.35537, cxr14_loss 0.92124, vnbgmicf1 0.58660, vnbgmacf1 0.45143, vnbg_loss 0.69113, ema 0.71046, 268.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.04749, wmdcmp 0.15755, oracc 0.98345, chxlmicf1 0.53188, chxlmacf1 0.48419, chxlacc 0.69911, chxlrocaucmic 0.78307, chxlrocaucmac 0.76967, qlmicf1 0.39258, qlmacf1 0.26567, ema 0.69273, 101.84 secs\n",
      "Adjusting learning rate of group 0 to 2.3806e-04.\n",
      "---- Epoch 14/80\n",
      "(1) Training stage (lr = 0.000238) ...\n",
      "loss 4.51760, a_loss 0.96642, cD 1.22178, wmdcmp 0.16512, oracc 0.97932, orien_loss 0.04057, chxlmicf1 0.52966, chxlmacf1 0.48115, chx_loss 0.86402, chxlacc 0.72040, chxlrocaucmic 0.80691, chxlrocaucmac 0.78874, qlmicf1 0.37726, qlmacf1 0.22907, ql_loss 0.80119, gacc 0.84614, gloss 0.35915, cxr14micf1 0.36892, cxr14macf1 0.35675, cxr14_loss 0.92018, vnbgmicf1 0.58840, vnbgmacf1 0.45106, vnbg_loss 0.69926, ema 0.71255, 279.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.04433, wmdcmp 0.15776, oracc 0.98732, chxlmicf1 0.53714, chxlmacf1 0.48673, chxlacc 0.69596, chxlrocaucmic 0.78798, chxlrocaucmac 0.76801, qlmicf1 0.37674, qlmacf1 0.26101, ema 0.66091, 142.50 secs\n",
      "Adjusting learning rate of group 0 to 2.2473e-04.\n",
      "---- Epoch 15/80\n",
      "(1) Training stage (lr = 0.000225) ...\n",
      "loss 4.36825, a_loss 0.95809, cD 1.24160, wmdcmp 0.16752, oracc 0.98038, orien_loss 0.03626, chxlmicf1 0.53145, chxlmacf1 0.48233, chx_loss 0.86255, chxlacc 0.71993, chxlrocaucmic 0.80696, chxlrocaucmac 0.78802, qlmicf1 0.38152, qlmacf1 0.23761, ql_loss 0.79093, gacc 0.85409, gloss 0.35453, cxr14micf1 0.38135, cxr14macf1 0.36417, cxr14_loss 0.90172, vnbgmicf1 0.60210, vnbgmacf1 0.46272, vnbg_loss 0.67112, ema 0.71130, 275.84 secs\n",
      "(2) Validation stage ...\n",
      "loss 4.65922, a_loss 0.94729, cD 1.26757, wmdcmp 0.17065, oracc 0.98081, orien_loss 0.03514, chxlmicf1 0.53180, chxlmacf1 0.48365, chx_loss 0.86010, chxlacc 0.72140, chxlrocaucmic 0.80755, chxlrocaucmac 0.78893, qlmicf1 0.37892, qlmacf1 0.23325, ql_loss 0.79312, gacc 0.85148, gloss 0.35386, cxr14micf1 0.37654, cxr14macf1 0.36209, cxr14_loss 0.90405, vnbgmicf1 0.58780, vnbgmacf1 0.45206, vnbg_loss 0.68722, ema 0.71917, 270.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14882, wmdcmp 0.16988, oracc 0.98330, chxlmicf1 0.54083, chxlmacf1 0.48954, chxlacc 0.70234, chxlrocaucmic 0.79030, chxlrocaucmac 0.77023, qlmicf1 0.39482, qlmacf1 0.26421, ema 0.68818, 135.86 secs\n",
      "Adjusting learning rate of group 0 to 2.0025e-04.\n",
      "---- Epoch 17/80\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 4.60159, a_loss 0.93415, cD 1.28962, wmdcmp 0.17190, oracc 0.98084, orien_loss 0.03482, chxlmicf1 0.53369, chxlmacf1 0.48540, chx_loss 0.85595, chxlacc 0.72248, chxlrocaucmic 0.80889, chxlrocaucmac 0.79098, qlmicf1 0.38638, qlmacf1 0.23545, ql_loss 0.78787, gacc 0.85375, gloss 0.35182, cxr14micf1 0.37498, cxr14macf1 0.35927, cxr14_loss 0.91531, vnbgmicf1 0.59801, vnbgmacf1 0.46283, vnbg_loss 0.66781, ema 0.71977, 262.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16961, wmdcmp 0.16864, oracc 0.98106, chxlmicf1 0.54155, chxlmacf1 0.49137, chxlacc 0.70100, chxlrocaucmic 0.78855, chxlrocaucmac 0.76707, qlmicf1 0.39526, qlmacf1 0.26645, ema 0.69727, 149.46 secs\n",
      "Adjusting learning rate of group 0 to 1.8903e-04.\n",
      "---- Epoch 18/80\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 4.47293, a_loss 0.92878, cD 1.29805, wmdcmp 0.17348, oracc 0.98031, orien_loss 0.03248, chxlmicf1 0.53138, chxlmacf1 0.48207, chx_loss 0.86312, chxlacc 0.72015, chxlrocaucmic 0.80592, chxlrocaucmac 0.78655, qlmicf1 0.38438, qlmacf1 0.23554, ql_loss 0.78766, gacc 0.84659, gloss 0.35573, cxr14micf1 0.38481, cxr14macf1 0.36436, cxr14_loss 0.90704, vnbgmicf1 0.59509, vnbgmacf1 0.45707, vnbg_loss 0.67598, ema 0.71472, 262.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23355, wmdcmp 0.17833, oracc 0.98732, chxlmicf1 0.53191, chxlmacf1 0.48457, chxlacc 0.70142, chxlrocaucmic 0.78409, chxlrocaucmac 0.77046, qlmicf1 0.39699, qlmacf1 0.26741, ema 0.70455, 148.24 secs\n",
      "Adjusting learning rate of group 0 to 1.7844e-04.\n",
      "---- Epoch 19/80\n",
      "(1) Training stage (lr = 0.000178) ...\n",
      "loss 4.49543, a_loss 0.92590, cD 1.32179, wmdcmp 0.17610, oracc 0.98204, orien_loss 0.03050, chxlmicf1 0.53379, chxlmacf1 0.48482, chx_loss 0.85838, chxlacc 0.72346, chxlrocaucmic 0.80915, chxlrocaucmac 0.79050, qlmicf1 0.38870, qlmacf1 0.23444, ql_loss 0.78229, gacc 0.86682, gloss 0.33531, cxr14micf1 0.37027, cxr14macf1 0.35661, cxr14_loss 0.90832, vnbgmicf1 0.60088, vnbgmacf1 0.46464, vnbg_loss 0.66109, ema 0.72500, 259.60 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22972, wmdcmp 0.17597, oracc 0.98464, chxlmicf1 0.53582, chxlmacf1 0.48548, chxlacc 0.69854, chxlrocaucmic 0.78826, chxlrocaucmac 0.77040, qlmicf1 0.39431, qlmacf1 0.26682, ema 0.68818, 138.07 secs\n",
      "Adjusting learning rate of group 0 to 1.6844e-04.\n",
      "---- Epoch 20/80\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 4.23136, a_loss 0.91385, cD 1.33574, wmdcmp 0.17786, oracc 0.98070, orien_loss 0.03231, chxlmicf1 0.53221, chxlmacf1 0.48395, chx_loss 0.86065, chxlacc 0.72151, chxlrocaucmic 0.80763, chxlrocaucmac 0.78995, qlmicf1 0.38709, qlmacf1 0.23806, ql_loss 0.78341, gacc 0.85818, gloss 0.34308, cxr14micf1 0.36960, cxr14macf1 0.35714, cxr14_loss 0.91283, vnbgmicf1 0.59937, vnbgmacf1 0.46674, vnbg_loss 0.65772, ema 0.72241, 262.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25904, wmdcmp 0.18129, oracc 0.98464, chxlmicf1 0.53972, chxlmacf1 0.48742, chxlacc 0.69909, chxlrocaucmic 0.78954, chxlrocaucmac 0.77094, qlmicf1 0.38884, qlmacf1 0.26497, ema 0.68909, 132.53 secs\n",
      "Adjusting learning rate of group 0 to 1.5900e-04.\n",
      "---- Epoch 21/80\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 4.20159, a_loss 0.91153, cD 1.35052, wmdcmp 0.17955, oracc 0.98181, orien_loss 0.03368, chxlmicf1 0.53547, chxlmacf1 0.48670, chx_loss 0.85512, chxlacc 0.72361, chxlrocaucmic 0.81015, chxlrocaucmac 0.79241, qlmicf1 0.39000, qlmacf1 0.24033, ql_loss 0.78334, gacc 0.85420, gloss 0.33927, cxr14micf1 0.38355, cxr14macf1 0.36571, cxr14_loss 0.90331, vnbgmicf1 0.60077, vnbgmacf1 0.46430, vnbg_loss 0.66058, ema 0.72477, 268.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16262, wmdcmp 0.16935, oracc 0.98732, chxlmicf1 0.53748, chxlmacf1 0.48422, chxlacc 0.70245, chxlrocaucmic 0.78955, chxlrocaucmac 0.76894, qlmicf1 0.40332, qlmacf1 0.26799, ema 0.71000, 136.35 secs\n",
      "Adjusting learning rate of group 0 to 1.5010e-04.\n",
      "---- Epoch 22/80\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "loss 4.31880, a_loss 0.90895, cD 1.37943, wmdcmp 0.18305, oracc 0.98187, orien_loss 0.03099, chxlmicf1 0.53549, chxlmacf1 0.48604, chx_loss 0.85755, chxlacc 0.72385, chxlrocaucmic 0.81083, chxlrocaucmac 0.79149, qlmicf1 0.38861, qlmacf1 0.23836, ql_loss 0.78046, gacc 0.86523, gloss 0.33178, cxr14micf1 0.38367, cxr14macf1 0.36466, cxr14_loss 0.90352, vnbgmicf1 0.60308, vnbgmacf1 0.46880, vnbg_loss 0.65210, ema 0.72778, 261.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18955, wmdcmp 0.17216, oracc 0.98732, chxlmicf1 0.53845, chxlmacf1 0.48586, chxlacc 0.70231, chxlrocaucmic 0.79007, chxlrocaucmac 0.76944, qlmicf1 0.39421, qlmacf1 0.27072, ema 0.67545, 154.03 secs\n",
      "Adjusting learning rate of group 0 to 1.4169e-04.\n",
      "---- Epoch 23/80\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 4.44622, a_loss 0.90612, cD 1.38440, wmdcmp 0.18327, oracc 0.98065, orien_loss 0.03597, chxlmicf1 0.53431, chxlmacf1 0.48479, chx_loss 0.85651, chxlacc 0.72346, chxlrocaucmic 0.80964, chxlrocaucmac 0.79091, qlmicf1 0.38596, qlmacf1 0.23743, ql_loss 0.78470, gacc 0.86375, gloss 0.32904, cxr14micf1 0.38469, cxr14macf1 0.36736, cxr14_loss 0.89596, vnbgmicf1 0.60781, vnbgmacf1 0.47616, vnbg_loss 0.63470, ema 0.73088, 264.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22905, wmdcmp 0.17734, oracc 0.98330, chxlmicf1 0.53455, chxlmacf1 0.48619, chxlacc 0.69654, chxlrocaucmic 0.78470, chxlrocaucmac 0.77235, qlmicf1 0.40370, qlmacf1 0.26952, ema 0.66818, 151.81 secs\n",
      "Adjusting learning rate of group 0 to 1.3375e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 24/80\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 4.35070, a_loss 0.89967, cD 1.38389, wmdcmp 0.18254, oracc 0.98356, orien_loss 0.02753, chxlmicf1 0.53458, chxlmacf1 0.48543, chx_loss 0.85452, chxlacc 0.72349, chxlrocaucmic 0.81074, chxlrocaucmac 0.79210, qlmicf1 0.38928, qlmacf1 0.23651, ql_loss 0.77998, gacc 0.85886, gloss 0.33331, cxr14micf1 0.37916, cxr14macf1 0.35938, cxr14_loss 0.90076, vnbgmicf1 0.61059, vnbgmacf1 0.47622, vnbg_loss 0.64449, ema 0.72704, 264.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27296, wmdcmp 0.18292, oracc 0.98464, chxlmicf1 0.53614, chxlmacf1 0.48646, chxlacc 0.69674, chxlrocaucmic 0.78664, chxlrocaucmac 0.77022, qlmicf1 0.39528, qlmacf1 0.26560, ema 0.71000, 140.61 secs\n",
      "Adjusting learning rate of group 0 to 1.2625e-04.\n",
      "---- Epoch 25/80\n",
      "(1) Training stage (lr = 0.000126) ...\n",
      "loss 4.38291, a_loss 0.89657, cD 1.39345, wmdcmp 0.18428, oracc 0.98317, orien_loss 0.02645, chxlmicf1 0.53737, chxlmacf1 0.48789, chx_loss 0.84959, chxlacc 0.72485, chxlrocaucmic 0.81236, chxlrocaucmac 0.79337, qlmicf1 0.39325, qlmacf1 0.23846, ql_loss 0.77476, gacc 0.86034, gloss 0.33360, cxr14micf1 0.37732, cxr14macf1 0.36319, cxr14_loss 0.90729, vnbgmicf1 0.60904, vnbgmacf1 0.47178, vnbg_loss 0.64272, ema 0.73056, 258.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37989, wmdcmp 0.19237, oracc 0.98464, chxlmicf1 0.54459, chxlmacf1 0.49321, chxlacc 0.70863, chxlrocaucmic 0.78764, chxlrocaucmac 0.77148, qlmicf1 0.40325, qlmacf1 0.27092, ema 0.69636, 129.20 secs\n",
      "Adjusting learning rate of group 0 to 1.1918e-04.\n",
      "---- Epoch 26/80\n",
      "(1) Training stage (lr = 0.000119) ...\n",
      "loss 4.20022, a_loss 0.89128, cD 1.40584, wmdcmp 0.18461, oracc 0.98360, orien_loss 0.02702, chxlmicf1 0.53665, chxlmacf1 0.48759, chx_loss 0.85143, chxlacc 0.72492, chxlrocaucmic 0.81102, chxlrocaucmac 0.79335, qlmicf1 0.39651, qlmacf1 0.24482, ql_loss 0.77586, gacc 0.86307, gloss 0.32322, cxr14micf1 0.38879, cxr14macf1 0.36998, cxr14_loss 0.89203, vnbgmicf1 0.60882, vnbgmacf1 0.47580, vnbg_loss 0.63253, ema 0.73227, 259.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31249, wmdcmp 0.18626, oracc 0.98732, chxlmicf1 0.54199, chxlmacf1 0.48902, chxlacc 0.70378, chxlrocaucmic 0.78992, chxlrocaucmac 0.77169, qlmicf1 0.39677, qlmacf1 0.26919, ema 0.70455, 137.00 secs\n",
      "Adjusting learning rate of group 0 to 1.1250e-04.\n",
      "---- Epoch 27/80\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 4.52497, a_loss 0.89531, cD 1.41876, wmdcmp 0.18691, oracc 0.98151, orien_loss 0.02969, chxlmicf1 0.53428, chxlmacf1 0.48440, chx_loss 0.85607, chxlacc 0.72360, chxlrocaucmic 0.80991, chxlrocaucmac 0.79090, qlmicf1 0.38970, qlmacf1 0.23808, ql_loss 0.78168, gacc 0.86375, gloss 0.33039, cxr14micf1 0.37061, cxr14macf1 0.35974, cxr14_loss 0.90728, vnbgmicf1 0.60878, vnbgmacf1 0.47677, vnbg_loss 0.63569, ema 0.73153, 259.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22830, wmdcmp 0.17588, oracc 0.98732, chxlmicf1 0.53852, chxlmacf1 0.48930, chxlacc 0.70105, chxlrocaucmic 0.78855, chxlrocaucmac 0.77243, qlmicf1 0.39854, qlmacf1 0.27058, ema 0.69727, 132.95 secs\n",
      "Adjusting learning rate of group 0 to 1.0620e-04.\n",
      "---- Epoch 28/80\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "Current run is terminating due to exception: Caught OSError in DataLoader worker process 3.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2818, in open\n",
      "    prefix = fp.read(16)\n",
      "OSError: [Errno 5] Input/output error\n",
      "\n",
      "Engine run is terminating due to exception: Caught OSError in DataLoader worker process 3.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2818, in open\n",
      "    prefix = fp.read(16)\n",
      "OSError: [Errno 5] Input/output error\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_vqa.py\", line 1449, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_vqa.py\", line 1348, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_vqa.py\", line 890, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 801, in _run_once_on_dataset\n",
      "    self.state.batch = next(self._dataloader_iter)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 169, in balanced_dataloaders_generator\n",
      "    yield next(cyclic_dataloaders[i])\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 135, in cyclic_dataloader_generator\n",
      "    for batch in dataloader:\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "OSError: Caught OSError in DataLoader worker process 3.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2818, in open\n",
      "    prefix = fp.read(16)\n",
      "OSError: [Errno 5] Input/output error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 80 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 6 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,4e-4,76,5e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --raw-image-encoding \"clip-vit-large-huggingface\" \\\n",
    "        --clip-version \"CenIA/vte-vit-large-patch16-bio-clinical-bert-finetuned-v3\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 30\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   iuxray_qa_adapted_reports_filename: None\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: bilstm\n",
      "   answer_decoding: lstm\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adam\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 6\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.05\n",
      "   mimiccxr_weight_chexpert_mode: 0.2\n",
      "   iuxray_weight_chexpert_mode: 0.05\n",
      "   mimiccxr_include_chexpert_mode: False\n",
      "   iuxray_include_chexpert_mode: False\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: False\n",
      "   medical_tokenization: False\n",
      "   medical_terms_frequency_filename: None\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: False\n",
      "   balanced_dataloading: False\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: None\n",
      "   mimiccxr_balanced_metadata_filename: None\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   iuxray_train_with_all: False\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: None\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_questions: False\n",
      "   n_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf-v3+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_25_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_25_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 26/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000119) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.50588, a_loss 0.84004, cD 1.50688, wmdcmp 0.19605, oracc 0.98213, orien_loss 0.03043, chxlmicf1 0.53649, chxlmacf1 0.48758, chx_loss 0.85231, chxlacc 0.72475, chxlrocaucmic 0.81141, chxlrocaucmac 0.79310, qlmicf1 0.39509, qlmacf1 0.24303, ql_loss 0.76976, gacc 0.85705, gloss 0.33487, cxr14micf1 0.38355, cxr14macf1 0.36476, cxr14_loss 0.89594, vnbgmicf1 0.61937, vnbgmacf1 0.48213, vnbg_loss 0.61642, ema 0.73236, 164.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17662, wmdcmp 0.17255, oracc 0.98688, chxlmicf1 0.53632, chxlmacf1 0.48763, chxlacc 0.69466, chxlrocaucmic 0.78580, chxlrocaucmac 0.77022, qlmicf1 0.39433, qlmacf1 0.26816, ema 0.69182, 54.55 secs\n",
      "Adjusting learning rate of group 0 to 1.1250e-04.\n",
      "\u001b[1m---- Epoch 27/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 4.19873, a_loss 0.87325, cD 1.42431, wmdcmp 0.18743, oracc 0.98268, orien_loss 0.02821, chxlmicf1 0.53578, chxlmacf1 0.48600, chx_loss 0.85265, chxlacc 0.72267, chxlrocaucmic 0.80967, chxlrocaucmac 0.79172, qlmicf1 0.39241, qlmacf1 0.24263, ql_loss 0.77387, gacc 0.86682, gloss 0.32451, cxr14micf1 0.38901, cxr14macf1 0.36758, cxr14_loss 0.90122, vnbgmicf1 0.61724, vnbgmacf1 0.49006, vnbg_loss 0.61719, ema 0.73556, 144.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30584, wmdcmp 0.18211, oracc 0.98777, chxlmicf1 0.54266, chxlmacf1 0.49046, chxlacc 0.70666, chxlrocaucmic 0.78815, chxlrocaucmac 0.77042, qlmicf1 0.40431, qlmacf1 0.27045, ema 0.67364, 54.73 secs\n",
      "Adjusting learning rate of group 0 to 1.0620e-04.\n",
      "\u001b[1m---- Epoch 28/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 4.13163, a_loss 0.88253, cD 1.44529, wmdcmp 0.18971, oracc 0.98302, orien_loss 0.02602, chxlmicf1 0.53529, chxlmacf1 0.48607, chx_loss 0.85338, chxlacc 0.72390, chxlrocaucmic 0.81003, chxlrocaucmac 0.79198, qlmicf1 0.39371, qlmacf1 0.23843, ql_loss 0.77931, gacc 0.86261, gloss 0.32779, cxr14micf1 0.39881, cxr14macf1 0.37700, cxr14_loss 0.87524, vnbgmicf1 0.61431, vnbgmacf1 0.47662, vnbg_loss 0.62927, ema 0.72986, 149.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25915, wmdcmp 0.17999, oracc 0.98688, chxlmicf1 0.53843, chxlmacf1 0.48692, chxlacc 0.70130, chxlrocaucmic 0.78787, chxlrocaucmac 0.77123, qlmicf1 0.39689, qlmacf1 0.26756, ema 0.68091, 96.23 secs\n",
      "Adjusting learning rate of group 0 to 1.0025e-04.\n",
      "\u001b[1m---- Epoch 29/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.16562, a_loss 0.87890, cD 1.43923, wmdcmp 0.18863, oracc 0.98263, orien_loss 0.02869, chxlmicf1 0.53690, chxlmacf1 0.48801, chx_loss 0.84953, chxlacc 0.72377, chxlrocaucmic 0.81117, chxlrocaucmac 0.79374, qlmicf1 0.39357, qlmacf1 0.23920, ql_loss 0.77279, gacc 0.86466, gloss 0.33161, cxr14micf1 0.38017, cxr14macf1 0.36456, cxr14_loss 0.89291, vnbgmicf1 0.61131, vnbgmacf1 0.47683, vnbg_loss 0.63037, ema 0.73292, 290.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29478, wmdcmp 0.18227, oracc 0.98807, chxlmicf1 0.53903, chxlmacf1 0.48661, chxlacc 0.70169, chxlrocaucmic 0.79087, chxlrocaucmac 0.77230, qlmicf1 0.40507, qlmacf1 0.27099, ema 0.68364, 98.25 secs\n",
      "Adjusting learning rate of group 0 to 9.4633e-05.\n",
      "\u001b[1m---- Epoch 30/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 4.42239, a_loss 0.87933, cD 1.42835, wmdcmp 0.18822, oracc 0.98249, orien_loss 0.03066, chxlmicf1 0.53930, chxlmacf1 0.48945, chx_loss 0.84686, chxlacc 0.72505, chxlrocaucmic 0.81282, chxlrocaucmac 0.79541, qlmicf1 0.39605, qlmacf1 0.24083, ql_loss 0.76696, gacc 0.86352, gloss 0.32589, cxr14micf1 0.36845, cxr14macf1 0.35932, cxr14_loss 0.90844, vnbgmicf1 0.61431, vnbgmacf1 0.48141, vnbg_loss 0.62514, ema 0.73394, 265.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32252, wmdcmp 0.18640, oracc 0.98807, chxlmicf1 0.54063, chxlmacf1 0.48927, chxlacc 0.70108, chxlrocaucmic 0.78867, chxlrocaucmac 0.77220, qlmicf1 0.40545, qlmacf1 0.27022, ema 0.69636, 125.33 secs\n",
      "Adjusting learning rate of group 0 to 8.9331e-05.\n",
      "\u001b[1m---- Epoch 31/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 4.49195, a_loss 0.87430, cD 1.43762, wmdcmp 0.18853, oracc 0.98421, orien_loss 0.02935, chxlmicf1 0.53417, chxlmacf1 0.48465, chx_loss 0.85602, chxlacc 0.72303, chxlrocaucmic 0.80873, chxlrocaucmac 0.78999, qlmicf1 0.39328, qlmacf1 0.24352, ql_loss 0.77547, gacc 0.87148, gloss 0.32007, cxr14micf1 0.39306, cxr14macf1 0.37057, cxr14_loss 0.89182, vnbgmicf1 0.61384, vnbgmacf1 0.48132, vnbg_loss 0.61773, ema 0.73625, 272.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29905, wmdcmp 0.18378, oracc 0.99016, chxlmicf1 0.53610, chxlmacf1 0.48727, chxlacc 0.70085, chxlrocaucmic 0.78502, chxlrocaucmac 0.77150, qlmicf1 0.40360, qlmacf1 0.26789, ema 0.67636, 145.18 secs\n",
      "Adjusting learning rate of group 0 to 8.4326e-05.\n",
      "\u001b[1m---- Epoch 32/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000084) ...\n",
      "loss 4.29557, a_loss 0.87443, cD 1.43934, wmdcmp 0.19021, oracc 0.98270, orien_loss 0.02671, chxlmicf1 0.53915, chxlmacf1 0.49005, chx_loss 0.84811, chxlacc 0.72594, chxlrocaucmic 0.81212, chxlrocaucmac 0.79584, qlmicf1 0.39426, qlmacf1 0.24411, ql_loss 0.76997, gacc 0.86523, gloss 0.32743, cxr14micf1 0.38211, cxr14macf1 0.36613, cxr14_loss 0.89630, vnbgmicf1 0.62136, vnbgmacf1 0.49115, vnbg_loss 0.61438, ema 0.73713, 264.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36539, wmdcmp 0.18855, oracc 0.99016, chxlmicf1 0.54469, chxlmacf1 0.49117, chxlacc 0.70599, chxlrocaucmic 0.79109, chxlrocaucmac 0.77355, qlmicf1 0.41129, qlmacf1 0.27096, ema 0.68727, 111.39 secs\n",
      "Adjusting learning rate of group 0 to 7.9602e-05.\n",
      "\u001b[1m---- Epoch 33/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 4.03461, a_loss 0.87099, cD 1.45421, wmdcmp 0.19085, oracc 0.98318, orien_loss 0.02403, chxlmicf1 0.53303, chxlmacf1 0.48409, chx_loss 0.85723, chxlacc 0.72160, chxlrocaucmic 0.80893, chxlrocaucmac 0.79155, qlmicf1 0.39505, qlmacf1 0.24007, ql_loss 0.77184, gacc 0.86318, gloss 0.32888, cxr14micf1 0.39832, cxr14macf1 0.37435, cxr14_loss 0.88476, vnbgmicf1 0.62100, vnbgmacf1 0.48216, vnbg_loss 0.60902, ema 0.74000, 270.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24633, wmdcmp 0.17931, oracc 0.99016, chxlmicf1 0.54058, chxlmacf1 0.48802, chxlacc 0.70642, chxlrocaucmic 0.78777, chxlrocaucmac 0.77259, qlmicf1 0.39996, qlmacf1 0.27075, ema 0.69364, 115.37 secs\n",
      "Adjusting learning rate of group 0 to 7.5142e-05.\n",
      "\u001b[1m---- Epoch 34/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000075) ...\n",
      "loss 4.36994, a_loss 0.86635, cD 1.46138, wmdcmp 0.19248, oracc 0.98205, orien_loss 0.02673, chxlmicf1 0.53508, chxlmacf1 0.48598, chx_loss 0.85050, chxlacc 0.72454, chxlrocaucmic 0.81073, chxlrocaucmac 0.79241, qlmicf1 0.39742, qlmacf1 0.25260, ql_loss 0.76893, gacc 0.87239, gloss 0.32035, cxr14micf1 0.39198, cxr14macf1 0.37078, cxr14_loss 0.88898, vnbgmicf1 0.61540, vnbgmacf1 0.47929, vnbg_loss 0.60788, ema 0.74593, 266.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29551, wmdcmp 0.18509, oracc 0.99016, chxlmicf1 0.53774, chxlmacf1 0.48694, chxlacc 0.70033, chxlrocaucmic 0.78668, chxlrocaucmac 0.77203, qlmicf1 0.39815, qlmacf1 0.26878, ema 0.67091, 112.32 secs\n",
      "Adjusting learning rate of group 0 to 7.0932e-05.\n",
      "\u001b[1m---- Epoch 35/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 4.10673, a_loss 0.86370, cD 1.46599, wmdcmp 0.19262, oracc 0.98246, orien_loss 0.03060, chxlmicf1 0.53756, chxlmacf1 0.48806, chx_loss 0.85200, chxlacc 0.72493, chxlrocaucmic 0.81316, chxlrocaucmac 0.79375, qlmicf1 0.39157, qlmacf1 0.23862, ql_loss 0.77405, gacc 0.86830, gloss 0.32234, cxr14micf1 0.38203, cxr14macf1 0.36457, cxr14_loss 0.90094, vnbgmicf1 0.62484, vnbgmacf1 0.49369, vnbg_loss 0.60028, ema 0.74241, 268.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29734, wmdcmp 0.18375, oracc 0.98807, chxlmicf1 0.54036, chxlmacf1 0.48961, chxlacc 0.70318, chxlrocaucmic 0.78623, chxlrocaucmac 0.77129, qlmicf1 0.39718, qlmacf1 0.26947, ema 0.69091, 111.61 secs\n",
      "Adjusting learning rate of group 0 to 6.6958e-05.\n",
      "\u001b[1m---- Epoch 36/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 4.19864, a_loss 0.86660, cD 1.45450, wmdcmp 0.19133, oracc 0.98314, orien_loss 0.02351, chxlmicf1 0.53433, chxlmacf1 0.48425, chx_loss 0.85541, chxlacc 0.72290, chxlrocaucmic 0.80953, chxlrocaucmac 0.79118, qlmicf1 0.39286, qlmacf1 0.24301, ql_loss 0.77385, gacc 0.86239, gloss 0.32329, cxr14micf1 0.37326, cxr14macf1 0.36106, cxr14_loss 0.90659, vnbgmicf1 0.62258, vnbgmacf1 0.49164, vnbg_loss 0.61304, ema 0.74153, 267.90 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.32476, wmdcmp 0.18738, oracc 0.99016, chxlmicf1 0.54098, chxlmacf1 0.48797, chxlacc 0.70537, chxlrocaucmic 0.78925, chxlrocaucmac 0.77265, qlmicf1 0.40323, qlmacf1 0.26826, ema 0.68182, 111.98 secs\n",
      "Adjusting learning rate of group 0 to 6.3206e-05.\n",
      "\u001b[1m---- Epoch 37/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 4.26894, a_loss 0.86165, cD 1.47050, wmdcmp 0.19246, oracc 0.98162, orien_loss 0.02793, chxlmicf1 0.53821, chxlmacf1 0.48774, chx_loss 0.85115, chxlacc 0.72618, chxlrocaucmic 0.81222, chxlrocaucmac 0.79420, qlmicf1 0.39739, qlmacf1 0.24031, ql_loss 0.76864, gacc 0.86693, gloss 0.31835, cxr14micf1 0.37581, cxr14macf1 0.36348, cxr14_loss 0.89953, vnbgmicf1 0.62980, vnbgmacf1 0.49582, vnbg_loss 0.59675, ema 0.74282, 263.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30612, wmdcmp 0.18549, oracc 0.98807, chxlmicf1 0.54004, chxlmacf1 0.48771, chxlacc 0.70181, chxlrocaucmic 0.78920, chxlrocaucmac 0.77191, qlmicf1 0.40727, qlmacf1 0.26979, ema 0.68364, 116.37 secs\n",
      "Adjusting learning rate of group 0 to 5.9665e-05.\n",
      "\u001b[1m---- Epoch 38/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 4.24957, a_loss 0.86042, cD 1.48787, wmdcmp 0.19490, oracc 0.98230, orien_loss 0.02445, chxlmicf1 0.53759, chxlmacf1 0.48935, chx_loss 0.85116, chxlacc 0.72557, chxlrocaucmic 0.81219, chxlrocaucmac 0.79430, qlmicf1 0.39576, qlmacf1 0.23947, ql_loss 0.77125, gacc 0.86670, gloss 0.32142, cxr14micf1 0.39459, cxr14macf1 0.37500, cxr14_loss 0.88533, vnbgmicf1 0.62247, vnbgmacf1 0.49078, vnbg_loss 0.59729, ema 0.74509, 267.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31451, wmdcmp 0.18701, oracc 0.98807, chxlmicf1 0.54091, chxlmacf1 0.48898, chxlacc 0.70323, chxlrocaucmic 0.78786, chxlrocaucmac 0.77247, qlmicf1 0.40154, qlmacf1 0.27193, ema 0.68273, 110.13 secs\n",
      "Adjusting learning rate of group 0 to 5.6322e-05.\n",
      "\u001b[1m---- Epoch 39/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 3.93484, a_loss 0.85994, cD 1.48099, wmdcmp 0.19422, oracc 0.98248, orien_loss 0.02744, chxlmicf1 0.53463, chxlmacf1 0.48592, chx_loss 0.85333, chxlacc 0.72316, chxlrocaucmic 0.81153, chxlrocaucmac 0.79426, qlmicf1 0.39692, qlmacf1 0.24182, ql_loss 0.77102, gacc 0.86977, gloss 0.31484, cxr14micf1 0.38519, cxr14macf1 0.36727, cxr14_loss 0.89369, vnbgmicf1 0.62342, vnbgmacf1 0.49661, vnbg_loss 0.60932, ema 0.74222, 265.60 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32932, wmdcmp 0.18676, oracc 0.99016, chxlmicf1 0.54123, chxlmacf1 0.48779, chxlacc 0.70651, chxlrocaucmic 0.78771, chxlrocaucmac 0.77174, qlmicf1 0.40703, qlmacf1 0.27205, ema 0.69818, 113.50 secs\n",
      "Adjusting learning rate of group 0 to 5.3166e-05.\n",
      "\u001b[1m---- Epoch 40/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 3.97296, a_loss 0.86370, cD 1.51618, wmdcmp 0.19859, oracc 0.98325, orien_loss 0.02587, chxlmicf1 0.53735, chxlmacf1 0.48685, chx_loss 0.85137, chxlacc 0.72479, chxlrocaucmic 0.81120, chxlrocaucmac 0.79292, qlmicf1 0.39578, qlmacf1 0.24424, ql_loss 0.77365, gacc 0.87466, gloss 0.31125, cxr14micf1 0.39732, cxr14macf1 0.37655, cxr14_loss 0.88364, vnbgmicf1 0.62484, vnbgmacf1 0.49110, vnbg_loss 0.59170, ema 0.74120, 267.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32622, wmdcmp 0.18843, oracc 0.99016, chxlmicf1 0.53898, chxlmacf1 0.48614, chxlacc 0.70132, chxlrocaucmic 0.78889, chxlrocaucmac 0.77222, qlmicf1 0.40581, qlmacf1 0.27146, ema 0.69636, 111.33 secs\n",
      "Adjusting learning rate of group 0 to 5.0188e-05.\n",
      "\u001b[1m---- Epoch 41/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n",
      "loss 4.07290, a_loss 0.85921, cD 1.48093, wmdcmp 0.19439, oracc 0.98479, orien_loss 0.02300, chxlmicf1 0.53470, chxlmacf1 0.48381, chx_loss 0.85767, chxlacc 0.72274, chxlrocaucmic 0.80865, chxlrocaucmac 0.79136, qlmicf1 0.39733, qlmacf1 0.24399, ql_loss 0.76878, gacc 0.87386, gloss 0.31083, cxr14micf1 0.39533, cxr14macf1 0.37524, cxr14_loss 0.87928, vnbgmicf1 0.62372, vnbgmacf1 0.48846, vnbg_loss 0.60220, ema 0.74037, 262.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39511, wmdcmp 0.19369, oracc 0.99016, chxlmicf1 0.53940, chxlmacf1 0.48578, chxlacc 0.70505, chxlrocaucmic 0.78780, chxlrocaucmac 0.77173, qlmicf1 0.40969, qlmacf1 0.27452, ema 0.67818, 112.39 secs\n",
      "Adjusting learning rate of group 0 to 4.7376e-05.\n",
      "\u001b[1m---- Epoch 42/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 4.31058, a_loss 0.84810, cD 1.52122, wmdcmp 0.19807, oracc 0.98174, orien_loss 0.02770, chxlmicf1 0.53963, chxlmacf1 0.49073, chx_loss 0.84630, chxlacc 0.72726, chxlrocaucmic 0.81431, chxlrocaucmac 0.79685, qlmicf1 0.39883, qlmacf1 0.24556, ql_loss 0.77030, gacc 0.87148, gloss 0.31251, cxr14micf1 0.39391, cxr14macf1 0.37160, cxr14_loss 0.89030, vnbgmicf1 0.62372, vnbgmacf1 0.49260, vnbg_loss 0.59529, ema 0.74644, 268.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31506, wmdcmp 0.18676, oracc 0.98807, chxlmicf1 0.54070, chxlmacf1 0.48839, chxlacc 0.70406, chxlrocaucmic 0.78894, chxlrocaucmac 0.77255, qlmicf1 0.40745, qlmacf1 0.27412, ema 0.68818, 108.61 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-05.\n",
      "\u001b[1m---- Epoch 43/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.32108, a_loss 0.85557, cD 1.49229, wmdcmp 0.19464, oracc 0.98208, orien_loss 0.02778, chxlmicf1 0.53893, chxlmacf1 0.48955, chx_loss 0.84704, chxlacc 0.72515, chxlrocaucmic 0.81184, chxlrocaucmac 0.79452, qlmicf1 0.39467, qlmacf1 0.25204, ql_loss 0.77204, gacc 0.86557, gloss 0.31689, cxr14micf1 0.39231, cxr14macf1 0.36857, cxr14_loss 0.88514, vnbgmicf1 0.61458, vnbgmacf1 0.48280, vnbg_loss 0.61330, ema 0.74657, 264.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33294, wmdcmp 0.18939, oracc 0.99016, chxlmicf1 0.54115, chxlmacf1 0.48947, chxlacc 0.70441, chxlrocaucmic 0.78882, chxlrocaucmac 0.77206, qlmicf1 0.40556, qlmacf1 0.27325, ema 0.69545, 98.17 secs\n",
      "Adjusting learning rate of group 0 to 4.2216e-05.\n",
      "\u001b[1m---- Epoch 44/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 4.10573, a_loss 0.85998, cD 1.49108, wmdcmp 0.19550, oracc 0.98354, orien_loss 0.02781, chxlmicf1 0.53696, chxlmacf1 0.48778, chx_loss 0.85028, chxlacc 0.72369, chxlrocaucmic 0.81118, chxlrocaucmac 0.79332, qlmicf1 0.39768, qlmacf1 0.24336, ql_loss 0.77351, gacc 0.87125, gloss 0.31440, cxr14micf1 0.39332, cxr14macf1 0.37336, cxr14_loss 0.89379, vnbgmicf1 0.62487, vnbgmacf1 0.49718, vnbg_loss 0.59338, ema 0.74269, 265.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32067, wmdcmp 0.18858, oracc 0.99016, chxlmicf1 0.53964, chxlmacf1 0.48804, chxlacc 0.70319, chxlrocaucmic 0.78900, chxlrocaucmac 0.77248, qlmicf1 0.40164, qlmacf1 0.27045, ema 0.69091, 97.05 secs\n",
      "Adjusting learning rate of group 0 to 3.9850e-05.\n",
      "\u001b[1m---- Epoch 45/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 4.16955, a_loss 0.85251, cD 1.50762, wmdcmp 0.19741, oracc 0.98252, orien_loss 0.02896, chxlmicf1 0.53534, chxlmacf1 0.48641, chx_loss 0.85071, chxlacc 0.72407, chxlrocaucmic 0.81087, chxlrocaucmac 0.79405, qlmicf1 0.39583, qlmacf1 0.24586, ql_loss 0.76960, gacc 0.86807, gloss 0.31808, cxr14micf1 0.39468, cxr14macf1 0.37649, cxr14_loss 0.87511, vnbgmicf1 0.62914, vnbgmacf1 0.49310, vnbg_loss 0.58945, ema 0.74722, 266.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33319, wmdcmp 0.18920, oracc 0.99016, chxlmicf1 0.53950, chxlmacf1 0.48652, chxlacc 0.70363, chxlrocaucmic 0.79084, chxlrocaucmac 0.77251, qlmicf1 0.40582, qlmacf1 0.27213, ema 0.67909, 98.57 secs\n",
      "Adjusting learning rate of group 0 to 3.7618e-05.\n",
      "\u001b[1m---- Epoch 46/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 4.12501, a_loss 0.84757, cD 1.49204, wmdcmp 0.19596, oracc 0.98236, orien_loss 0.02508, chxlmicf1 0.53788, chxlmacf1 0.48745, chx_loss 0.84973, chxlacc 0.72543, chxlrocaucmic 0.81234, chxlrocaucmac 0.79327, qlmicf1 0.39581, qlmacf1 0.25104, ql_loss 0.76981, gacc 0.86295, gloss 0.32408, cxr14micf1 0.40002, cxr14macf1 0.37633, cxr14_loss 0.87333, vnbgmicf1 0.62451, vnbgmacf1 0.49527, vnbg_loss 0.59618, ema 0.74583, 267.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31916, wmdcmp 0.18937, oracc 0.99016, chxlmicf1 0.53986, chxlmacf1 0.48757, chxlacc 0.70373, chxlrocaucmic 0.78823, chxlrocaucmac 0.77208, qlmicf1 0.40560, qlmacf1 0.27243, ema 0.69545, 96.80 secs\n",
      "Adjusting learning rate of group 0 to 3.5510e-05.\n",
      "\u001b[1m---- Epoch 47/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 4.09443, a_loss 0.85220, cD 1.50475, wmdcmp 0.19663, oracc 0.98208, orien_loss 0.03002, chxlmicf1 0.53605, chxlmacf1 0.48685, chx_loss 0.85444, chxlacc 0.72443, chxlrocaucmic 0.81088, chxlrocaucmac 0.79318, qlmicf1 0.39690, qlmacf1 0.24871, ql_loss 0.76976, gacc 0.87568, gloss 0.31047, cxr14micf1 0.40464, cxr14macf1 0.38214, cxr14_loss 0.87104, vnbgmicf1 0.62256, vnbgmacf1 0.48783, vnbg_loss 0.59734, ema 0.74449, 266.15 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.37182, wmdcmp 0.19294, oracc 0.99016, chxlmicf1 0.54054, chxlmacf1 0.48695, chxlacc 0.70123, chxlrocaucmic 0.78954, chxlrocaucmac 0.77224, qlmicf1 0.40812, qlmacf1 0.27200, ema 0.68636, 98.54 secs\n",
      "Adjusting learning rate of group 0 to 3.3521e-05.\n",
      "\u001b[1m---- Epoch 48/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.04078, a_loss 0.85253, cD 1.51953, wmdcmp 0.19763, oracc 0.98291, orien_loss 0.02442, chxlmicf1 0.53591, chxlmacf1 0.48635, chx_loss 0.85078, chxlacc 0.72427, chxlrocaucmic 0.81081, chxlrocaucmac 0.79377, qlmicf1 0.39743, qlmacf1 0.24272, ql_loss 0.76557, gacc 0.87330, gloss 0.31028, cxr14micf1 0.39280, cxr14macf1 0.36987, cxr14_loss 0.89874, vnbgmicf1 0.62843, vnbgmacf1 0.49440, vnbg_loss 0.59486, ema 0.74662, 267.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35252, wmdcmp 0.18948, oracc 0.99016, chxlmicf1 0.54074, chxlmacf1 0.48828, chxlacc 0.70459, chxlrocaucmic 0.78867, chxlrocaucmac 0.77222, qlmicf1 0.40283, qlmacf1 0.27078, ema 0.68818, 98.89 secs\n",
      "Adjusting learning rate of group 0 to 3.1643e-05.\n",
      "\u001b[1m---- Epoch 49/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 4.05420, a_loss 0.84769, cD 1.52039, wmdcmp 0.19767, oracc 0.98295, orien_loss 0.02665, chxlmicf1 0.53638, chxlmacf1 0.48569, chx_loss 0.85233, chxlacc 0.72347, chxlrocaucmic 0.81021, chxlrocaucmac 0.79245, qlmicf1 0.39818, qlmacf1 0.24713, ql_loss 0.77218, gacc 0.87000, gloss 0.31791, cxr14micf1 0.39175, cxr14macf1 0.37079, cxr14_loss 0.89197, vnbgmicf1 0.62935, vnbgmacf1 0.49288, vnbg_loss 0.59392, ema 0.74375, 266.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32047, wmdcmp 0.18858, oracc 0.99016, chxlmicf1 0.53801, chxlmacf1 0.48608, chxlacc 0.70136, chxlrocaucmic 0.78891, chxlrocaucmac 0.77185, qlmicf1 0.40359, qlmacf1 0.27189, ema 0.67909, 99.91 secs\n",
      "Adjusting learning rate of group 0 to 2.9870e-05.\n",
      "\u001b[1m---- Epoch 50/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 4.17250, a_loss 0.84718, cD 1.51094, wmdcmp 0.19701, oracc 0.98340, orien_loss 0.02271, chxlmicf1 0.54074, chxlmacf1 0.49021, chx_loss 0.84793, chxlacc 0.72674, chxlrocaucmic 0.81346, chxlrocaucmac 0.79546, qlmicf1 0.39898, qlmacf1 0.24922, ql_loss 0.76837, gacc 0.86955, gloss 0.31751, cxr14micf1 0.38244, cxr14macf1 0.36481, cxr14_loss 0.88916, vnbgmicf1 0.62466, vnbgmacf1 0.49651, vnbg_loss 0.59632, ema 0.74657, 266.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32979, wmdcmp 0.18826, oracc 0.99016, chxlmicf1 0.54033, chxlmacf1 0.48799, chxlacc 0.70327, chxlrocaucmic 0.78840, chxlrocaucmac 0.77175, qlmicf1 0.40229, qlmacf1 0.27068, ema 0.69909, 98.84 secs\n",
      "Adjusting learning rate of group 0 to 2.8196e-05.\n",
      "\u001b[1m---- Epoch 51/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 3.88899, a_loss 0.84678, cD 1.52986, wmdcmp 0.19977, oracc 0.98339, orien_loss 0.02653, chxlmicf1 0.53762, chxlmacf1 0.48706, chx_loss 0.85017, chxlacc 0.72574, chxlrocaucmic 0.81175, chxlrocaucmac 0.79468, qlmicf1 0.39783, qlmacf1 0.25153, ql_loss 0.76945, gacc 0.87432, gloss 0.31550, cxr14micf1 0.38452, cxr14macf1 0.36977, cxr14_loss 0.88225, vnbgmicf1 0.62912, vnbgmacf1 0.49852, vnbg_loss 0.58117, ema 0.75093, 268.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35743, wmdcmp 0.19188, oracc 0.99016, chxlmicf1 0.54035, chxlmacf1 0.48811, chxlacc 0.70344, chxlrocaucmic 0.78738, chxlrocaucmac 0.77168, qlmicf1 0.40704, qlmacf1 0.27133, ema 0.68909, 97.39 secs\n",
      "Adjusting learning rate of group 0 to 2.6616e-05.\n",
      "\u001b[1m---- Epoch 52/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.25981, a_loss 0.84575, cD 1.51071, wmdcmp 0.19776, oracc 0.98422, orien_loss 0.02513, chxlmicf1 0.53735, chxlmacf1 0.48892, chx_loss 0.85037, chxlacc 0.72424, chxlrocaucmic 0.81129, chxlrocaucmac 0.79356, qlmicf1 0.40123, qlmacf1 0.25726, ql_loss 0.76723, gacc 0.86932, gloss 0.31271, cxr14micf1 0.38129, cxr14macf1 0.36648, cxr14_loss 0.89680, vnbgmicf1 0.62869, vnbgmacf1 0.49825, vnbg_loss 0.58790, ema 0.74259, 265.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33140, wmdcmp 0.18851, oracc 0.99016, chxlmicf1 0.53945, chxlmacf1 0.48765, chxlacc 0.70361, chxlrocaucmic 0.78679, chxlrocaucmac 0.77196, qlmicf1 0.40508, qlmacf1 0.27127, ema 0.69727, 98.33 secs\n",
      "Adjusting learning rate of group 0 to 2.5125e-05.\n",
      "\u001b[1m---- Epoch 53/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 4.01631, a_loss 0.84761, cD 1.50904, wmdcmp 0.19755, oracc 0.98314, orien_loss 0.02392, chxlmicf1 0.53763, chxlmacf1 0.48793, chx_loss 0.84820, chxlacc 0.72605, chxlrocaucmic 0.81184, chxlrocaucmac 0.79466, qlmicf1 0.39847, qlmacf1 0.24146, ql_loss 0.76785, gacc 0.87341, gloss 0.31745, cxr14micf1 0.39578, cxr14macf1 0.37568, cxr14_loss 0.87768, vnbgmicf1 0.62793, vnbgmacf1 0.49397, vnbg_loss 0.59189, ema 0.74546, 270.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32177, wmdcmp 0.18759, oracc 0.99016, chxlmicf1 0.54043, chxlmacf1 0.48777, chxlacc 0.70306, chxlrocaucmic 0.78814, chxlrocaucmac 0.77151, qlmicf1 0.40165, qlmacf1 0.27045, ema 0.68818, 100.09 secs\n",
      "Adjusting learning rate of group 0 to 2.3717e-05.\n",
      "\u001b[1m---- Epoch 54/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 4.19294, a_loss 0.84926, cD 1.50947, wmdcmp 0.19813, oracc 0.98241, orien_loss 0.02580, chxlmicf1 0.53945, chxlmacf1 0.49069, chx_loss 0.84997, chxlacc 0.72681, chxlrocaucmic 0.81279, chxlrocaucmac 0.79548, qlmicf1 0.40217, qlmacf1 0.24878, ql_loss 0.76400, gacc 0.87545, gloss 0.30549, cxr14micf1 0.39788, cxr14macf1 0.37329, cxr14_loss 0.88334, vnbgmicf1 0.62947, vnbgmacf1 0.49888, vnbg_loss 0.59529, ema 0.74829, 266.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34795, wmdcmp 0.19103, oracc 0.99016, chxlmicf1 0.53998, chxlmacf1 0.48800, chxlacc 0.70278, chxlrocaucmic 0.78866, chxlrocaucmac 0.77160, qlmicf1 0.40700, qlmacf1 0.27059, ema 0.68727, 100.57 secs\n",
      "Adjusting learning rate of group 0 to 2.2389e-05.\n",
      "\u001b[1m---- Epoch 55/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 4.05681, a_loss 0.84557, cD 1.52412, wmdcmp 0.19877, oracc 0.98384, orien_loss 0.02563, chxlmicf1 0.53741, chxlmacf1 0.48707, chx_loss 0.85093, chxlacc 0.72482, chxlrocaucmic 0.81047, chxlrocaucmac 0.79268, qlmicf1 0.39548, qlmacf1 0.23765, ql_loss 0.77332, gacc 0.86273, gloss 0.31853, cxr14micf1 0.38172, cxr14macf1 0.36271, cxr14_loss 0.89477, vnbgmicf1 0.62349, vnbgmacf1 0.48937, vnbg_loss 0.59654, ema 0.74620, 267.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35952, wmdcmp 0.19197, oracc 0.99016, chxlmicf1 0.54140, chxlmacf1 0.48879, chxlacc 0.70458, chxlrocaucmic 0.78900, chxlrocaucmac 0.77177, qlmicf1 0.40578, qlmacf1 0.27021, ema 0.69273, 102.35 secs\n",
      "Adjusting learning rate of group 0 to 2.1134e-05.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 30 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 6 \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-large-huggingface\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/vte-vit-large-patch16-bio-clinical-bert-finetuned-v3\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,8e-5,56,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 20\n",
      "   iters_to_accumulate: 8\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf-v3+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,8e-5,56,1e-6\n",
      "1e-06 4 8e-05 56 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 20\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|███████████████████████████████████████████| 97/97 [00:10<00:00,  9.18it/s]\n",
      " *** merging from i=0 to j=1, acc_size = 27\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=20,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 96\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|██████████████████████████████████████████| 91/91 [00:00<00:00, 681.62it/s]\n",
      " *** merging from i=0 to j=11, acc_size = 20\n",
      " *** merging from i=12 to j=17, acc_size = 23\n",
      " *** merging from i=18 to j=20, acc_size = 21\n",
      " *** merging from i=21 to j=23, acc_size = 24\n",
      " *** merging from i=24 to j=25, acc_size = 21\n",
      " *** merging from i=26 to j=27, acc_size = 22\n",
      " *** merging from i=28 to j=29, acc_size = 24\n",
      " *** merging from i=30 to j=31, acc_size = 28\n",
      " *** merging from i=32 to j=33, acc_size = 32\n",
      " *** merging from i=34 to j=35, acc_size = 43\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=20,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 65\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "checkpoint_names = ['checkpoint_25_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt', 'checkpoint_50_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_50_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.57829, a_loss 0.73185, cD 1.93747, wmdcmp 0.23787, oracc 0.98025, orien_loss 0.03170, chxlmicf1 0.54820, chxlmacf1 0.49107, chx_loss 0.80306, chxlacc 0.74098, chxlrocaucmic 0.81949, chxlrocaucmac 0.79806, qlmicf1 0.41065, qlmacf1 0.24284, ql_loss 0.60236, gacc 0.86773, gloss 0.30742, cxr14micf1 0.39920, cxr14macf1 0.37600, cxr14_loss 0.84297, vnbgmicf1 0.63308, vnbgmacf1 0.50062, vnbg_loss 0.52685, ema 0.73870, 105.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34139, wmdcmp 0.18997, oracc 0.98971, chxlmicf1 0.54909, chxlmacf1 0.49015, chxlacc 0.72312, chxlrocaucmic 0.79547, chxlrocaucmac 0.77122, qlmicf1 0.42082, qlmacf1 0.27315, ema 0.71273, 68.95 secs\n",
      "Adjusting learning rate of group 0 to 2.9907e-06.\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.97929, a_loss 0.81655, cD 1.58966, wmdcmp 0.20195, oracc 0.98156, orien_loss 0.03701, chxlmicf1 0.55151, chxlmacf1 0.48920, chx_loss 0.81466, chxlacc 0.74961, chxlrocaucmic 0.81841, chxlrocaucmac 0.78907, qlmicf1 0.43634, qlmacf1 0.25026, ql_loss 0.59471, gacc 0.88591, gloss 0.28302, cxr14micf1 0.38455, cxr14macf1 0.37305, cxr14_loss 0.82703, vnbgmicf1 0.64797, vnbgmacf1 0.52119, vnbg_loss 0.54079, ema 0.73204, 101.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34004, wmdcmp 0.18945, oracc 0.98747, chxlmicf1 0.55425, chxlmacf1 0.49310, chxlacc 0.72957, chxlrocaucmic 0.79770, chxlrocaucmac 0.77281, qlmicf1 0.44658, qlmacf1 0.27679, ema 0.71091, 69.78 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-06.\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.93935, a_loss 0.84190, cD 1.57153, wmdcmp 0.19807, oracc 0.98534, orien_loss 0.02012, chxlmicf1 0.55414, chxlmacf1 0.49637, chx_loss 0.81334, chxlacc 0.74636, chxlrocaucmic 0.82109, chxlrocaucmac 0.79395, qlmicf1 0.47283, qlmacf1 0.26909, ql_loss 0.59642, gacc 0.90864, gloss 0.23715, cxr14micf1 0.40733, cxr14macf1 0.38542, cxr14_loss 0.82012, vnbgmicf1 0.66171, vnbgmacf1 0.54468, vnbg_loss 0.51549, ema 0.74463, 101.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34145, wmdcmp 0.18949, oracc 0.98971, chxlmicf1 0.55638, chxlmacf1 0.49723, chxlacc 0.72374, chxlrocaucmic 0.80238, chxlrocaucmac 0.77274, qlmicf1 0.48031, qlmacf1 0.28500, ema 0.70727, 69.71 secs\n",
      "Adjusting learning rate of group 0 to 2.6750e-05.\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.33172, a_loss 0.84306, cD 1.54264, wmdcmp 0.19723, oracc 0.98173, orien_loss 0.02460, chxlmicf1 0.55332, chxlmacf1 0.49525, chx_loss 0.81448, chxlacc 0.74585, chxlrocaucmic 0.82113, chxlrocaucmac 0.79349, qlmicf1 0.48853, qlmacf1 0.27171, ql_loss 0.58658, gacc 0.90545, gloss 0.23675, cxr14micf1 0.38549, cxr14macf1 0.37978, cxr14_loss 0.82799, vnbgmicf1 0.66154, vnbgmacf1 0.53582, vnbg_loss 0.52210, ema 0.75315, 101.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33379, wmdcmp 0.18884, oracc 0.98971, chxlmicf1 0.54628, chxlmacf1 0.48934, chxlacc 0.71862, chxlrocaucmic 0.78850, chxlrocaucmac 0.76630, qlmicf1 0.48347, qlmacf1 0.28658, ema 0.71273, 69.19 secs\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 4.17355, a_loss 0.85385, cD 1.49256, wmdcmp 0.19242, oracc 0.98198, orien_loss 0.02641, chxlmicf1 0.53597, chxlmacf1 0.48329, chx_loss 0.83626, chxlacc 0.73482, chxlrocaucmic 0.80709, chxlrocaucmac 0.78176, qlmicf1 0.48360, qlmacf1 0.25330, ql_loss 0.59969, gacc 0.89182, gloss 0.32062, cxr14micf1 0.39776, cxr14macf1 0.38697, cxr14_loss 0.84108, vnbgmicf1 0.63446, vnbgmacf1 0.51425, vnbg_loss 0.58956, ema 0.71481, 101.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28369, wmdcmp 0.18391, oracc 0.98807, chxlmicf1 0.53354, chxlmacf1 0.47439, chxlacc 0.71435, chxlrocaucmic 0.77909, chxlrocaucmac 0.75814, qlmicf1 0.44800, qlmacf1 0.26120, ema 0.68636, 69.33 secs\n",
      "Adjusting learning rate of group 0 to 7.3979e-05.\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000074) ...\n",
      "loss 4.31323, a_loss 0.86239, cD 1.50301, wmdcmp 0.19385, oracc 0.98040, orien_loss 0.04014, chxlmicf1 0.53639, chxlmacf1 0.47672, chx_loss 0.83558, chxlacc 0.73068, chxlrocaucmic 0.80949, chxlrocaucmac 0.77783, qlmicf1 0.49143, qlmacf1 0.24851, ql_loss 0.59252, gacc 0.91818, gloss 0.23305, cxr14micf1 0.41643, cxr14macf1 0.38987, cxr14_loss 0.81446, vnbgmicf1 0.62857, vnbgmacf1 0.49158, vnbg_loss 0.57790, ema 0.72056, 101.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26039, wmdcmp 0.17971, oracc 0.98971, chxlmicf1 0.54898, chxlmacf1 0.48581, chxlacc 0.71154, chxlrocaucmic 0.79657, chxlrocaucmac 0.76430, qlmicf1 0.48757, qlmacf1 0.27093, ema 0.69091, 69.90 secs\n",
      "Adjusting learning rate of group 0 to 6.8410e-05.\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 4.01156, a_loss 0.86657, cD 1.46144, wmdcmp 0.18546, oracc 0.98393, orien_loss 0.02683, chxlmicf1 0.54051, chxlmacf1 0.48340, chx_loss 0.82533, chxlacc 0.73551, chxlrocaucmic 0.81168, chxlrocaucmac 0.78480, qlmicf1 0.48794, qlmacf1 0.25640, ql_loss 0.59547, gacc 0.93364, gloss 0.18573, cxr14micf1 0.39972, cxr14macf1 0.38286, cxr14_loss 0.82703, vnbgmicf1 0.66308, vnbgmacf1 0.53779, vnbg_loss 0.52140, ema 0.74500, 101.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35884, wmdcmp 0.18973, oracc 0.98971, chxlmicf1 0.56230, chxlmacf1 0.48998, chxlacc 0.72190, chxlrocaucmic 0.81051, chxlrocaucmac 0.76415, qlmicf1 0.49327, qlmacf1 0.27214, ema 0.68909, 69.51 secs\n",
      "Adjusting learning rate of group 0 to 6.3261e-05.\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 3.83147, a_loss 0.85674, cD 1.47472, wmdcmp 0.19122, oracc 0.98215, orien_loss 0.02303, chxlmicf1 0.54723, chxlmacf1 0.49221, chx_loss 0.81767, chxlacc 0.73548, chxlrocaucmic 0.81777, chxlrocaucmac 0.79230, qlmicf1 0.48822, qlmacf1 0.26078, ql_loss 0.59481, gacc 0.93000, gloss 0.18280, cxr14micf1 0.39156, cxr14macf1 0.38200, cxr14_loss 0.84475, vnbgmicf1 0.66233, vnbgmacf1 0.53835, vnbg_loss 0.51372, ema 0.73815, 101.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28109, wmdcmp 0.18221, oracc 0.98971, chxlmicf1 0.53965, chxlmacf1 0.48575, chxlacc 0.71709, chxlrocaucmic 0.78064, chxlrocaucmac 0.77083, qlmicf1 0.48271, qlmacf1 0.27945, ema 0.70909, 69.80 secs\n",
      "Adjusting learning rate of group 0 to 5.8500e-05.\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000058) ...\n",
      "loss 3.52628, a_loss 0.85835, cD 1.54956, wmdcmp 0.19776, oracc 0.98318, orien_loss 0.01911, chxlmicf1 0.53967, chxlmacf1 0.48288, chx_loss 0.82162, chxlacc 0.73990, chxlrocaucmic 0.81408, chxlrocaucmac 0.78761, qlmicf1 0.48795, qlmacf1 0.25930, ql_loss 0.59318, gacc 0.95500, gloss 0.12851, cxr14micf1 0.42566, cxr14macf1 0.40090, cxr14_loss 0.80909, vnbgmicf1 0.67086, vnbgmacf1 0.53065, vnbg_loss 0.51073, ema 0.73963, 101.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31585, wmdcmp 0.18567, oracc 0.98747, chxlmicf1 0.54644, chxlmacf1 0.48926, chxlacc 0.71922, chxlrocaucmic 0.79639, chxlrocaucmac 0.77095, qlmicf1 0.49241, qlmacf1 0.28002, ema 0.68273, 69.32 secs\n",
      "Adjusting learning rate of group 0 to 5.4097e-05.\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 4.40081, a_loss 0.86363, cD 1.48378, wmdcmp 0.19093, oracc 0.98461, orien_loss 0.01940, chxlmicf1 0.55147, chxlmacf1 0.49679, chx_loss 0.81096, chxlacc 0.74237, chxlrocaucmic 0.82104, chxlrocaucmac 0.79642, qlmicf1 0.49313, qlmacf1 0.26300, ql_loss 0.59236, gacc 0.94591, gloss 0.15364, cxr14micf1 0.40615, cxr14macf1 0.39032, cxr14_loss 0.82210, vnbgmicf1 0.66784, vnbgmacf1 0.54103, vnbg_loss 0.51700, ema 0.73796, 101.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33333, wmdcmp 0.18855, oracc 0.98807, chxlmicf1 0.55590, chxlmacf1 0.49756, chxlacc 0.72117, chxlrocaucmic 0.79803, chxlrocaucmac 0.77182, qlmicf1 0.48964, qlmacf1 0.27916, ema 0.69636, 69.31 secs\n",
      "Adjusting learning rate of group 0 to 5.0025e-05.\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.01845, a_loss 0.84661, cD 1.58272, wmdcmp 0.20179, oracc 0.98242, orien_loss 0.02060, chxlmicf1 0.55521, chxlmacf1 0.50067, chx_loss 0.80835, chxlacc 0.74485, chxlrocaucmic 0.82284, chxlrocaucmac 0.79845, qlmicf1 0.49432, qlmacf1 0.26514, ql_loss 0.58591, gacc 0.95364, gloss 0.10747, cxr14micf1 0.42734, cxr14macf1 0.40207, cxr14_loss 0.79358, vnbgmicf1 0.68163, vnbgmacf1 0.54774, vnbg_loss 0.48775, ema 0.73722, 102.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35740, wmdcmp 0.19185, oracc 0.98747, chxlmicf1 0.55584, chxlmacf1 0.49481, chxlacc 0.72126, chxlrocaucmic 0.80111, chxlrocaucmac 0.76867, qlmicf1 0.49838, qlmacf1 0.28567, ema 0.69909, 69.19 secs\n",
      "Adjusting learning rate of group 0 to 4.6260e-05.\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 3.98638, a_loss 0.85542, cD 1.51430, wmdcmp 0.19316, oracc 0.98378, orien_loss 0.01930, chxlmicf1 0.55345, chxlmacf1 0.49816, chx_loss 0.80811, chxlacc 0.74432, chxlrocaucmic 0.82265, chxlrocaucmac 0.79854, qlmicf1 0.49448, qlmacf1 0.26747, ql_loss 0.58393, gacc 0.95455, gloss 0.12354, cxr14micf1 0.41775, cxr14macf1 0.39868, cxr14_loss 0.79616, vnbgmicf1 0.67872, vnbgmacf1 0.55889, vnbg_loss 0.48585, ema 0.74296, 101.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33498, wmdcmp 0.18940, oracc 0.98628, chxlmicf1 0.55631, chxlmacf1 0.49682, chxlacc 0.73371, chxlrocaucmic 0.79765, chxlrocaucmac 0.77341, qlmicf1 0.50041, qlmacf1 0.28648, ema 0.72091, 70.03 secs\n",
      "Adjusting learning rate of group 0 to 4.2778e-05.\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 3.74599, a_loss 0.85096, cD 1.52288, wmdcmp 0.19500, oracc 0.97987, orien_loss 0.02610, chxlmicf1 0.55922, chxlmacf1 0.50226, chx_loss 0.79979, chxlacc 0.74699, chxlrocaucmic 0.82649, chxlrocaucmac 0.80257, qlmicf1 0.49686, qlmacf1 0.26592, ql_loss 0.57881, gacc 0.95500, gloss 0.11775, cxr14micf1 0.38809, cxr14macf1 0.37998, cxr14_loss 0.83704, vnbgmicf1 0.69089, vnbgmacf1 0.57238, vnbg_loss 0.45145, ema 0.75259, 101.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35796, wmdcmp 0.19151, oracc 0.98598, chxlmicf1 0.54877, chxlmacf1 0.49532, chxlacc 0.72111, chxlrocaucmic 0.79039, chxlrocaucmac 0.77126, qlmicf1 0.48192, qlmacf1 0.27607, ema 0.70636, 69.42 secs\n",
      "Adjusting learning rate of group 0 to 3.9558e-05.\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.94207, a_loss 0.85727, cD 1.52974, wmdcmp 0.19505, oracc 0.98393, orien_loss 0.02310, chxlmicf1 0.55973, chxlmacf1 0.50581, chx_loss 0.79158, chxlacc 0.74736, chxlrocaucmic 0.82813, chxlrocaucmac 0.80558, qlmicf1 0.50093, qlmacf1 0.27054, ql_loss 0.57898, gacc 0.96364, gloss 0.10968, cxr14micf1 0.40765, cxr14macf1 0.39808, cxr14_loss 0.81505, vnbgmicf1 0.69134, vnbgmacf1 0.56850, vnbg_loss 0.48172, ema 0.75667, 101.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36350, wmdcmp 0.19147, oracc 0.98732, chxlmicf1 0.54782, chxlmacf1 0.48986, chxlacc 0.72017, chxlrocaucmic 0.79825, chxlrocaucmac 0.77213, qlmicf1 0.49508, qlmacf1 0.28230, ema 0.71364, 69.43 secs\n",
      "Adjusting learning rate of group 0 to 3.6581e-05.\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 4.48048, a_loss 0.84317, cD 1.55353, wmdcmp 0.19664, oracc 0.98319, orien_loss 0.01219, chxlmicf1 0.55712, chxlmacf1 0.50226, chx_loss 0.79742, chxlacc 0.74683, chxlrocaucmic 0.82569, chxlrocaucmac 0.80141, qlmicf1 0.49198, qlmacf1 0.26848, ql_loss 0.57656, gacc 0.96682, gloss 0.09545, cxr14micf1 0.43517, cxr14macf1 0.41193, cxr14_loss 0.77191, vnbgmicf1 0.69059, vnbgmacf1 0.58678, vnbg_loss 0.48208, ema 0.75259, 101.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34621, wmdcmp 0.18962, oracc 0.98807, chxlmicf1 0.55995, chxlmacf1 0.49870, chxlacc 0.72436, chxlrocaucmic 0.80249, chxlrocaucmac 0.77449, qlmicf1 0.49779, qlmacf1 0.28277, ema 0.72909, 69.24 secs\n",
      "Adjusting learning rate of group 0 to 3.3827e-05.\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 3.73165, a_loss 0.86089, cD 1.54522, wmdcmp 0.19828, oracc 0.98694, orien_loss 0.01675, chxlmicf1 0.56195, chxlmacf1 0.50368, chx_loss 0.79483, chxlacc 0.74961, chxlrocaucmic 0.82759, chxlrocaucmac 0.80227, qlmicf1 0.49854, qlmacf1 0.26703, ql_loss 0.57730, gacc 0.96500, gloss 0.09724, cxr14micf1 0.42926, cxr14macf1 0.41964, cxr14_loss 0.77613, vnbgmicf1 0.69608, vnbgmacf1 0.56884, vnbg_loss 0.45367, ema 0.75019, 101.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33984, wmdcmp 0.18901, oracc 0.98971, chxlmicf1 0.56199, chxlmacf1 0.50069, chxlacc 0.72257, chxlrocaucmic 0.80800, chxlrocaucmac 0.77253, qlmicf1 0.49394, qlmacf1 0.28849, ema 0.70000, 69.74 secs\n",
      "Adjusting learning rate of group 0 to 3.1281e-05.\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 4.09177, a_loss 0.85058, cD 1.53485, wmdcmp 0.19546, oracc 0.98444, orien_loss 0.02118, chxlmicf1 0.56178, chxlmacf1 0.50901, chx_loss 0.79073, chxlacc 0.75198, chxlrocaucmic 0.83043, chxlrocaucmac 0.80786, qlmicf1 0.49698, qlmacf1 0.27221, ql_loss 0.57836, gacc 0.96955, gloss 0.07641, cxr14micf1 0.42103, cxr14macf1 0.40953, cxr14_loss 0.78571, vnbgmicf1 0.69921, vnbgmacf1 0.60439, vnbg_loss 0.44080, ema 0.75667, 101.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30333, wmdcmp 0.18514, oracc 0.98971, chxlmicf1 0.55993, chxlmacf1 0.49604, chxlacc 0.73665, chxlrocaucmic 0.80032, chxlrocaucmac 0.77278, qlmicf1 0.49419, qlmacf1 0.29125, ema 0.71636, 69.25 secs\n",
      "Adjusting learning rate of group 0 to 2.8927e-05.\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 3.52548, a_loss 0.84552, cD 1.48613, wmdcmp 0.19237, oracc 0.98284, orien_loss 0.02099, chxlmicf1 0.56349, chxlmacf1 0.50828, chx_loss 0.78531, chxlacc 0.75117, chxlrocaucmic 0.83037, chxlrocaucmac 0.80787, qlmicf1 0.49829, qlmacf1 0.26937, ql_loss 0.57982, gacc 0.95318, gloss 0.12194, cxr14micf1 0.42330, cxr14macf1 0.41073, cxr14_loss 0.81205, vnbgmicf1 0.72058, vnbgmacf1 0.62980, vnbg_loss 0.41717, ema 0.75944, 101.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32358, wmdcmp 0.18612, oracc 0.98971, chxlmicf1 0.55694, chxlmacf1 0.50187, chxlacc 0.72240, chxlrocaucmic 0.79790, chxlrocaucmac 0.77238, qlmicf1 0.49034, qlmacf1 0.28719, ema 0.70091, 69.60 secs\n",
      "Adjusting learning rate of group 0 to 2.6750e-05.\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.70962, a_loss 0.85261, cD 1.49661, wmdcmp 0.19110, oracc 0.98471, orien_loss 0.01623, chxlmicf1 0.56729, chxlmacf1 0.51099, chx_loss 0.77405, chxlacc 0.75706, chxlrocaucmic 0.83448, chxlrocaucmac 0.81278, qlmicf1 0.50055, qlmacf1 0.27620, ql_loss 0.56758, gacc 0.96318, gloss 0.09815, cxr14micf1 0.41161, cxr14macf1 0.40467, cxr14_loss 0.80274, vnbgmicf1 0.70774, vnbgmacf1 0.60604, vnbg_loss 0.42442, ema 0.75204, 101.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32252, wmdcmp 0.18870, oracc 0.98971, chxlmicf1 0.56571, chxlmacf1 0.50302, chxlacc 0.72896, chxlrocaucmic 0.80863, chxlrocaucmac 0.77636, qlmicf1 0.49853, qlmacf1 0.28786, ema 0.70273, 69.78 secs\n",
      "Adjusting learning rate of group 0 to 2.4736e-05.\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 4.09014, a_loss 0.86106, cD 1.51943, wmdcmp 0.19385, oracc 0.98504, orien_loss 0.02161, chxlmicf1 0.56121, chxlmacf1 0.50671, chx_loss 0.78907, chxlacc 0.75005, chxlrocaucmic 0.83032, chxlrocaucmac 0.80973, qlmicf1 0.49398, qlmacf1 0.27513, ql_loss 0.57823, gacc 0.96727, gloss 0.08294, cxr14micf1 0.43169, cxr14macf1 0.42273, cxr14_loss 0.78860, vnbgmicf1 0.72096, vnbgmacf1 0.63735, vnbg_loss 0.41852, ema 0.75370, 101.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33551, wmdcmp 0.18824, oracc 0.98598, chxlmicf1 0.56435, chxlmacf1 0.49814, chxlacc 0.73307, chxlrocaucmic 0.80887, chxlrocaucmac 0.77815, qlmicf1 0.50070, qlmacf1 0.29131, ema 0.71636, 69.06 secs\n",
      "Adjusting learning rate of group 0 to 2.2874e-05.\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 4.02166, a_loss 0.85394, cD 1.53274, wmdcmp 0.19651, oracc 0.98287, orien_loss 0.02476, chxlmicf1 0.55949, chxlmacf1 0.50558, chx_loss 0.78848, chxlacc 0.74944, chxlrocaucmic 0.82949, chxlrocaucmac 0.80822, qlmicf1 0.49794, qlmacf1 0.27254, ql_loss 0.57780, gacc 0.97500, gloss 0.07844, cxr14micf1 0.43785, cxr14macf1 0.43496, cxr14_loss 0.75098, vnbgmicf1 0.71880, vnbgmacf1 0.62848, vnbg_loss 0.42361, ema 0.76574, 101.80 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.35920, wmdcmp 0.19168, oracc 0.98971, chxlmicf1 0.56296, chxlmacf1 0.50356, chxlacc 0.73498, chxlrocaucmic 0.80193, chxlrocaucmac 0.77734, qlmicf1 0.49897, qlmacf1 0.28946, ema 0.70727, 69.70 secs\n",
      "Adjusting learning rate of group 0 to 2.1153e-05.\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 3.68326, a_loss 0.85557, cD 1.51512, wmdcmp 0.19355, oracc 0.98607, orien_loss 0.01521, chxlmicf1 0.56788, chxlmacf1 0.51478, chx_loss 0.77481, chxlacc 0.75313, chxlrocaucmic 0.83536, chxlrocaucmac 0.81349, qlmicf1 0.50285, qlmacf1 0.27720, ql_loss 0.56943, gacc 0.96591, gloss 0.09061, cxr14micf1 0.41205, cxr14macf1 0.40900, cxr14_loss 0.78647, vnbgmicf1 0.71790, vnbgmacf1 0.64547, vnbg_loss 0.44199, ema 0.74593, 101.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33154, wmdcmp 0.18883, oracc 0.98598, chxlmicf1 0.55950, chxlmacf1 0.49970, chxlacc 0.72705, chxlrocaucmic 0.80222, chxlrocaucmac 0.77597, qlmicf1 0.49668, qlmacf1 0.29121, ema 0.71364, 69.90 secs\n",
      "Adjusting learning rate of group 0 to 1.9561e-05.\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 3.64837, a_loss 0.84347, cD 1.51316, wmdcmp 0.19539, oracc 0.98795, orien_loss 0.01259, chxlmicf1 0.56512, chxlmacf1 0.51275, chx_loss 0.77015, chxlacc 0.75498, chxlrocaucmic 0.83668, chxlrocaucmac 0.81665, qlmicf1 0.50469, qlmacf1 0.28995, ql_loss 0.56182, gacc 0.97045, gloss 0.08374, cxr14micf1 0.44769, cxr14macf1 0.43938, cxr14_loss 0.77682, vnbgmicf1 0.73427, vnbgmacf1 0.65044, vnbg_loss 0.39968, ema 0.75000, 101.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35490, wmdcmp 0.19153, oracc 0.98971, chxlmicf1 0.56625, chxlmacf1 0.50260, chxlacc 0.73815, chxlrocaucmic 0.80673, chxlrocaucmac 0.77731, qlmicf1 0.50461, qlmacf1 0.29235, ema 0.71364, 69.62 secs\n",
      "Adjusting learning rate of group 0 to 1.8088e-05.\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 3.48377, a_loss 0.84796, cD 1.54615, wmdcmp 0.19749, oracc 0.98354, orien_loss 0.01447, chxlmicf1 0.56723, chxlmacf1 0.51334, chx_loss 0.77445, chxlacc 0.75687, chxlrocaucmic 0.83603, chxlrocaucmac 0.81668, qlmicf1 0.50426, qlmacf1 0.28425, ql_loss 0.57112, gacc 0.97364, gloss 0.07098, cxr14micf1 0.43084, cxr14macf1 0.42367, cxr14_loss 0.78019, vnbgmicf1 0.73148, vnbgmacf1 0.62707, vnbg_loss 0.38527, ema 0.75556, 101.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35140, wmdcmp 0.19075, oracc 0.98971, chxlmicf1 0.56141, chxlmacf1 0.49895, chxlacc 0.73761, chxlrocaucmic 0.80499, chxlrocaucmac 0.77707, qlmicf1 0.50433, qlmacf1 0.28838, ema 0.71273, 69.00 secs\n",
      "Adjusting learning rate of group 0 to 1.6727e-05.\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 4.38199, a_loss 0.85912, cD 1.49088, wmdcmp 0.19066, oracc 0.98535, orien_loss 0.01115, chxlmicf1 0.56784, chxlmacf1 0.51181, chx_loss 0.77897, chxlacc 0.75939, chxlrocaucmic 0.83562, chxlrocaucmac 0.81317, qlmicf1 0.50532, qlmacf1 0.27801, ql_loss 0.57007, gacc 0.97182, gloss 0.07315, cxr14micf1 0.43700, cxr14macf1 0.43308, cxr14_loss 0.76791, vnbgmicf1 0.72627, vnbgmacf1 0.63276, vnbg_loss 0.41030, ema 0.75500, 101.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35782, wmdcmp 0.19158, oracc 0.98807, chxlmicf1 0.56468, chxlmacf1 0.50412, chxlacc 0.73240, chxlrocaucmic 0.80259, chxlrocaucmac 0.78043, qlmicf1 0.49797, qlmacf1 0.28881, ema 0.70727, 69.56 secs\n",
      "Adjusting learning rate of group 0 to 1.5468e-05.\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 4.22232, a_loss 0.84303, cD 1.56820, wmdcmp 0.20196, oracc 0.98432, orien_loss 0.01931, chxlmicf1 0.56820, chxlmacf1 0.51514, chx_loss 0.77375, chxlacc 0.75745, chxlrocaucmic 0.83574, chxlrocaucmac 0.81628, qlmicf1 0.50788, qlmacf1 0.28283, ql_loss 0.56634, gacc 0.97545, gloss 0.06711, cxr14micf1 0.42336, cxr14macf1 0.41471, cxr14_loss 0.77804, vnbgmicf1 0.74066, vnbgmacf1 0.66131, vnbg_loss 0.39082, ema 0.75593, 101.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34002, wmdcmp 0.18971, oracc 0.98971, chxlmicf1 0.55888, chxlmacf1 0.50125, chxlacc 0.72685, chxlrocaucmic 0.80026, chxlrocaucmac 0.77729, qlmicf1 0.48910, qlmacf1 0.28343, ema 0.68364, 69.64 secs\n",
      "Adjusting learning rate of group 0 to 1.4304e-05.\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.08670, a_loss 0.84773, cD 1.58199, wmdcmp 0.19933, oracc 0.98681, orien_loss 0.01292, chxlmicf1 0.57216, chxlmacf1 0.51758, chx_loss 0.77425, chxlacc 0.76294, chxlrocaucmic 0.83925, chxlrocaucmac 0.81810, qlmicf1 0.50653, qlmacf1 0.28048, ql_loss 0.56557, gacc 0.97227, gloss 0.06852, cxr14micf1 0.45688, cxr14macf1 0.44980, cxr14_loss 0.74558, vnbgmicf1 0.72805, vnbgmacf1 0.63566, vnbg_loss 0.40485, ema 0.76278, 101.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35077, wmdcmp 0.18996, oracc 0.98807, chxlmicf1 0.56764, chxlmacf1 0.50657, chxlacc 0.74266, chxlrocaucmic 0.80507, chxlrocaucmac 0.78092, qlmicf1 0.50747, qlmacf1 0.28773, ema 0.71364, 69.68 secs\n",
      "Adjusting learning rate of group 0 to 1.3227e-05.\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 3.61423, a_loss 0.84466, cD 1.52124, wmdcmp 0.19420, oracc 0.98466, orien_loss 0.01702, chxlmicf1 0.56849, chxlmacf1 0.51632, chx_loss 0.76744, chxlacc 0.75892, chxlrocaucmic 0.83874, chxlrocaucmac 0.82122, qlmicf1 0.50860, qlmacf1 0.27927, ql_loss 0.56457, gacc 0.97045, gloss 0.07477, cxr14micf1 0.43871, cxr14macf1 0.43071, cxr14_loss 0.76015, vnbgmicf1 0.73490, vnbgmacf1 0.64720, vnbg_loss 0.37768, ema 0.76963, 101.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34032, wmdcmp 0.18970, oracc 0.98971, chxlmicf1 0.56547, chxlmacf1 0.50404, chxlacc 0.73706, chxlrocaucmic 0.80635, chxlrocaucmac 0.78206, qlmicf1 0.50675, qlmacf1 0.29233, ema 0.71818, 69.45 secs\n",
      "Adjusting learning rate of group 0 to 1.2232e-05.\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 4.20279, a_loss 0.85078, cD 1.56045, wmdcmp 0.19758, oracc 0.98432, orien_loss 0.01886, chxlmicf1 0.57601, chxlmacf1 0.52196, chx_loss 0.76473, chxlacc 0.76223, chxlrocaucmic 0.84116, chxlrocaucmac 0.81987, qlmicf1 0.50545, qlmacf1 0.28464, ql_loss 0.56402, gacc 0.97682, gloss 0.07056, cxr14micf1 0.44943, cxr14macf1 0.44519, cxr14_loss 0.74259, vnbgmicf1 0.73158, vnbgmacf1 0.66013, vnbg_loss 0.40761, ema 0.75778, 101.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36199, wmdcmp 0.19238, oracc 0.98971, chxlmicf1 0.57139, chxlmacf1 0.51127, chxlacc 0.73874, chxlrocaucmic 0.80987, chxlrocaucmac 0.78358, qlmicf1 0.50481, qlmacf1 0.28960, ema 0.71091, 69.59 secs\n",
      "Adjusting learning rate of group 0 to 1.1311e-05.\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 3.71233, a_loss 0.84720, cD 1.52950, wmdcmp 0.19699, oracc 0.98260, orien_loss 0.02069, chxlmicf1 0.57845, chxlmacf1 0.52088, chx_loss 0.76160, chxlacc 0.76373, chxlrocaucmic 0.84320, chxlrocaucmac 0.82184, qlmicf1 0.51066, qlmacf1 0.29957, ql_loss 0.55962, gacc 0.97773, gloss 0.05943, cxr14micf1 0.43282, cxr14macf1 0.43414, cxr14_loss 0.79549, vnbgmicf1 0.75125, vnbgmacf1 0.67288, vnbg_loss 0.36668, ema 0.76981, 101.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35161, wmdcmp 0.19024, oracc 0.98807, chxlmicf1 0.56429, chxlmacf1 0.50459, chxlacc 0.74014, chxlrocaucmic 0.80751, chxlrocaucmac 0.78350, qlmicf1 0.49990, qlmacf1 0.28931, ema 0.72636, 69.63 secs\n",
      "Adjusting learning rate of group 0 to 1.0460e-05.\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.48041, a_loss 0.85643, cD 1.49318, wmdcmp 0.19361, oracc 0.98428, orien_loss 0.01158, chxlmicf1 0.57734, chxlmacf1 0.52292, chx_loss 0.76267, chxlacc 0.76300, chxlrocaucmic 0.84111, chxlrocaucmac 0.82116, qlmicf1 0.50564, qlmacf1 0.28419, ql_loss 0.56827, gacc 0.97864, gloss 0.05842, cxr14micf1 0.42676, cxr14macf1 0.42095, cxr14_loss 0.76105, vnbgmicf1 0.74461, vnbgmacf1 0.69016, vnbg_loss 0.38265, ema 0.76481, 101.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36735, wmdcmp 0.19194, oracc 0.98971, chxlmicf1 0.56795, chxlmacf1 0.50605, chxlacc 0.74338, chxlrocaucmic 0.80890, chxlrocaucmac 0.78154, qlmicf1 0.50074, qlmacf1 0.29151, ema 0.72182, 69.12 secs\n",
      "Adjusting learning rate of group 0 to 9.6723e-06.\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.92671, a_loss 0.83895, cD 1.52553, wmdcmp 0.19465, oracc 0.98446, orien_loss 0.01244, chxlmicf1 0.57872, chxlmacf1 0.52218, chx_loss 0.75681, chxlacc 0.76311, chxlrocaucmic 0.84132, chxlrocaucmac 0.82088, qlmicf1 0.50828, qlmacf1 0.28773, ql_loss 0.56982, gacc 0.98000, gloss 0.05485, cxr14micf1 0.43417, cxr14macf1 0.43158, cxr14_loss 0.75205, vnbgmicf1 0.74700, vnbgmacf1 0.69461, vnbg_loss 0.36532, ema 0.76463, 101.48 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.35777, wmdcmp 0.19129, oracc 0.98807, chxlmicf1 0.57154, chxlmacf1 0.50850, chxlacc 0.74197, chxlrocaucmic 0.81307, chxlrocaucmac 0.78190, qlmicf1 0.50598, qlmacf1 0.29355, ema 0.72727, 69.84 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-06.\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.63147, a_loss 0.83469, cD 1.55930, wmdcmp 0.19930, oracc 0.98680, orien_loss 0.01089, chxlmicf1 0.57712, chxlmacf1 0.52262, chx_loss 0.75560, chxlacc 0.76439, chxlrocaucmic 0.84355, chxlrocaucmac 0.82405, qlmicf1 0.50925, qlmacf1 0.29046, ql_loss 0.55902, gacc 0.97591, gloss 0.06059, cxr14micf1 0.45044, cxr14macf1 0.44389, cxr14_loss 0.74904, vnbgmicf1 0.74521, vnbgmacf1 0.69209, vnbg_loss 0.36874, ema 0.76704, 101.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35045, wmdcmp 0.19149, oracc 0.98971, chxlmicf1 0.56648, chxlmacf1 0.50548, chxlacc 0.74499, chxlrocaucmic 0.80754, chxlrocaucmac 0.78109, qlmicf1 0.50398, qlmacf1 0.29575, ema 0.72273, 69.39 secs\n",
      "Adjusting learning rate of group 0 to 8.2711e-06.\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 3.58562, a_loss 0.84397, cD 1.59176, wmdcmp 0.20284, oracc 0.98623, orien_loss 0.01116, chxlmicf1 0.57601, chxlmacf1 0.52434, chx_loss 0.75896, chxlacc 0.76344, chxlrocaucmic 0.84115, chxlrocaucmac 0.82533, qlmicf1 0.50895, qlmacf1 0.29443, ql_loss 0.55817, gacc 0.97591, gloss 0.07379, cxr14micf1 0.44000, cxr14macf1 0.44075, cxr14_loss 0.74680, vnbgmicf1 0.75301, vnbgmacf1 0.67428, vnbg_loss 0.36272, ema 0.75630, 100.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37388, wmdcmp 0.19347, oracc 0.98971, chxlmicf1 0.57234, chxlmacf1 0.50492, chxlacc 0.74856, chxlrocaucmic 0.81008, chxlrocaucmac 0.78340, qlmicf1 0.50914, qlmacf1 0.29419, ema 0.71727, 70.47 secs\n",
      "Adjusting learning rate of group 0 to 7.6485e-06.\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 3.83693, a_loss 0.84813, cD 1.50219, wmdcmp 0.19210, oracc 0.98623, orien_loss 0.02061, chxlmicf1 0.58073, chxlmacf1 0.52771, chx_loss 0.75753, chxlacc 0.76701, chxlrocaucmic 0.84760, chxlrocaucmac 0.82802, qlmicf1 0.50990, qlmacf1 0.28976, ql_loss 0.55660, gacc 0.98227, gloss 0.05449, cxr14micf1 0.45143, cxr14macf1 0.44320, cxr14_loss 0.76457, vnbgmicf1 0.75561, vnbgmacf1 0.69345, vnbg_loss 0.35495, ema 0.76481, 101.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36017, wmdcmp 0.19132, oracc 0.98971, chxlmicf1 0.56780, chxlmacf1 0.50651, chxlacc 0.74021, chxlrocaucmic 0.81021, chxlrocaucmac 0.78425, qlmicf1 0.50327, qlmacf1 0.29583, ema 0.71273, 69.73 secs\n",
      "Adjusting learning rate of group 0 to 7.0728e-06.\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.97014, a_loss 0.85391, cD 1.57770, wmdcmp 0.20210, oracc 0.98798, orien_loss 0.01191, chxlmicf1 0.58134, chxlmacf1 0.52850, chx_loss 0.75829, chxlacc 0.76475, chxlrocaucmic 0.84161, chxlrocaucmac 0.82327, qlmicf1 0.51335, qlmacf1 0.29499, ql_loss 0.55687, gacc 0.97273, gloss 0.06943, cxr14micf1 0.45750, cxr14macf1 0.45704, cxr14_loss 0.73066, vnbgmicf1 0.76464, vnbgmacf1 0.70591, vnbg_loss 0.35986, ema 0.77278, 101.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36042, wmdcmp 0.19115, oracc 0.98971, chxlmicf1 0.56855, chxlmacf1 0.50449, chxlacc 0.74037, chxlrocaucmic 0.81025, chxlrocaucmac 0.78272, qlmicf1 0.50360, qlmacf1 0.29360, ema 0.71818, 69.80 secs\n",
      "Adjusting learning rate of group 0 to 6.5405e-06.\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.75190, a_loss 0.84132, cD 1.59102, wmdcmp 0.20144, oracc 0.98550, orien_loss 0.01113, chxlmicf1 0.57999, chxlmacf1 0.52921, chx_loss 0.75485, chxlacc 0.76301, chxlrocaucmic 0.84351, chxlrocaucmac 0.82435, qlmicf1 0.50807, qlmacf1 0.29725, ql_loss 0.55801, gacc 0.97455, gloss 0.05808, cxr14micf1 0.44054, cxr14macf1 0.43737, cxr14_loss 0.77436, vnbgmicf1 0.76240, vnbgmacf1 0.70390, vnbg_loss 0.35962, ema 0.76074, 101.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34249, wmdcmp 0.19087, oracc 0.98807, chxlmicf1 0.57080, chxlmacf1 0.50548, chxlacc 0.74184, chxlrocaucmic 0.81189, chxlrocaucmac 0.78408, qlmicf1 0.50878, qlmacf1 0.29409, ema 0.71909, 69.40 secs\n",
      "Adjusting learning rate of group 0 to 6.0482e-06.\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.63156, a_loss 0.84786, cD 1.51595, wmdcmp 0.19497, oracc 0.98462, orien_loss 0.01324, chxlmicf1 0.58199, chxlmacf1 0.53155, chx_loss 0.74277, chxlacc 0.76736, chxlrocaucmic 0.84725, chxlrocaucmac 0.83012, qlmicf1 0.51265, qlmacf1 0.29633, ql_loss 0.56061, gacc 0.97773, gloss 0.05455, cxr14micf1 0.43969, cxr14macf1 0.43163, cxr14_loss 0.75325, vnbgmicf1 0.75466, vnbgmacf1 0.66827, vnbg_loss 0.35319, ema 0.76093, 101.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36543, wmdcmp 0.19215, oracc 0.98971, chxlmicf1 0.57195, chxlmacf1 0.50759, chxlacc 0.74568, chxlrocaucmic 0.81276, chxlrocaucmac 0.78415, qlmicf1 0.50503, qlmacf1 0.29800, ema 0.71818, 69.69 secs\n",
      "Adjusting learning rate of group 0 to 5.5930e-06.\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.60046, a_loss 0.83869, cD 1.58179, wmdcmp 0.20129, oracc 0.98475, orien_loss 0.00770, chxlmicf1 0.58172, chxlmacf1 0.52690, chx_loss 0.75084, chxlacc 0.76720, chxlrocaucmic 0.84757, chxlrocaucmac 0.82645, qlmicf1 0.50896, qlmacf1 0.28751, ql_loss 0.55808, gacc 0.97727, gloss 0.05877, cxr14micf1 0.44791, cxr14macf1 0.44998, cxr14_loss 0.75605, vnbgmicf1 0.74626, vnbgmacf1 0.68806, vnbg_loss 0.35930, ema 0.76519, 101.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35939, wmdcmp 0.19162, oracc 0.98971, chxlmicf1 0.57060, chxlmacf1 0.50582, chxlacc 0.74215, chxlrocaucmic 0.81385, chxlrocaucmac 0.78491, qlmicf1 0.50691, qlmacf1 0.29728, ema 0.72273, 69.51 secs\n",
      "Adjusting learning rate of group 0 to 5.1720e-06.\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.75636, a_loss 0.85103, cD 1.50855, wmdcmp 0.19620, oracc 0.98534, orien_loss 0.00978, chxlmicf1 0.57783, chxlmacf1 0.52679, chx_loss 0.75068, chxlacc 0.76608, chxlrocaucmic 0.84366, chxlrocaucmac 0.82421, qlmicf1 0.50943, qlmacf1 0.29029, ql_loss 0.56110, gacc 0.97955, gloss 0.04754, cxr14micf1 0.44222, cxr14macf1 0.43310, cxr14_loss 0.79164, vnbgmicf1 0.76435, vnbgmacf1 0.70408, vnbg_loss 0.34138, ema 0.77333, 101.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35944, wmdcmp 0.19060, oracc 0.98971, chxlmicf1 0.57761, chxlmacf1 0.51231, chxlacc 0.75294, chxlrocaucmic 0.81293, chxlrocaucmac 0.78529, qlmicf1 0.50606, qlmacf1 0.29591, ema 0.72091, 69.60 secs\n",
      "Adjusting learning rate of group 0 to 4.7827e-06.\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.53510, a_loss 0.85651, cD 1.51363, wmdcmp 0.19359, oracc 0.98474, orien_loss 0.01181, chxlmicf1 0.58317, chxlmacf1 0.53142, chx_loss 0.74692, chxlacc 0.76790, chxlrocaucmic 0.84541, chxlrocaucmac 0.82863, qlmicf1 0.50863, qlmacf1 0.30870, ql_loss 0.55548, gacc 0.98045, gloss 0.05542, cxr14micf1 0.43733, cxr14macf1 0.43187, cxr14_loss 0.76756, vnbgmicf1 0.76818, vnbgmacf1 0.71648, vnbg_loss 0.34868, ema 0.76796, 101.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33884, wmdcmp 0.18904, oracc 0.98971, chxlmicf1 0.57215, chxlmacf1 0.50706, chxlacc 0.74569, chxlrocaucmic 0.81198, chxlrocaucmac 0.78569, qlmicf1 0.50729, qlmacf1 0.29586, ema 0.72455, 69.64 secs\n",
      "Adjusting learning rate of group 0 to 4.4227e-06.\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.18938, a_loss 0.83406, cD 1.56113, wmdcmp 0.20063, oracc 0.98681, orien_loss 0.01393, chxlmicf1 0.58518, chxlmacf1 0.53358, chx_loss 0.74297, chxlacc 0.76875, chxlrocaucmic 0.84962, chxlrocaucmac 0.83226, qlmicf1 0.50972, qlmacf1 0.28775, ql_loss 0.55616, gacc 0.98091, gloss 0.04960, cxr14micf1 0.43592, cxr14macf1 0.42853, cxr14_loss 0.76364, vnbgmicf1 0.75657, vnbgmacf1 0.70898, vnbg_loss 0.34453, ema 0.76889, 101.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35931, wmdcmp 0.19128, oracc 0.98971, chxlmicf1 0.57054, chxlmacf1 0.50588, chxlacc 0.74373, chxlrocaucmic 0.81093, chxlrocaucmac 0.78557, qlmicf1 0.50319, qlmacf1 0.29706, ema 0.72455, 69.68 secs\n",
      "Adjusting learning rate of group 0 to 4.0899e-06.\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.97329, a_loss 0.84955, cD 1.55359, wmdcmp 0.19885, oracc 0.98770, orien_loss 0.01420, chxlmicf1 0.57955, chxlmacf1 0.52652, chx_loss 0.75724, chxlacc 0.76711, chxlrocaucmic 0.84374, chxlrocaucmac 0.82467, qlmicf1 0.51183, qlmacf1 0.29434, ql_loss 0.55930, gacc 0.98045, gloss 0.05263, cxr14micf1 0.44918, cxr14macf1 0.44546, cxr14_loss 0.73720, vnbgmicf1 0.76545, vnbgmacf1 0.70514, vnbg_loss 0.33647, ema 0.76407, 101.82 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.36112, wmdcmp 0.19150, oracc 0.98971, chxlmicf1 0.56642, chxlmacf1 0.50318, chxlacc 0.74075, chxlrocaucmic 0.81182, chxlrocaucmac 0.78541, qlmicf1 0.50523, qlmacf1 0.29920, ema 0.72455, 69.10 secs\n",
      "Adjusting learning rate of group 0 to 3.7820e-06.\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.17157, a_loss 0.84173, cD 1.52698, wmdcmp 0.19635, oracc 0.98459, orien_loss 0.01286, chxlmicf1 0.58438, chxlmacf1 0.53055, chx_loss 0.75114, chxlacc 0.76689, chxlrocaucmic 0.84767, chxlrocaucmac 0.82928, qlmicf1 0.50938, qlmacf1 0.30162, ql_loss 0.55814, gacc 0.98591, gloss 0.05529, cxr14micf1 0.44990, cxr14macf1 0.44372, cxr14_loss 0.72974, vnbgmicf1 0.76495, vnbgmacf1 0.68810, vnbg_loss 0.33668, ema 0.76296, 101.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36777, wmdcmp 0.19178, oracc 0.98971, chxlmicf1 0.57045, chxlmacf1 0.50656, chxlacc 0.74343, chxlrocaucmic 0.81110, chxlrocaucmac 0.78619, qlmicf1 0.50213, qlmacf1 0.30046, ema 0.71545, 69.52 secs\n",
      "Adjusting learning rate of group 0 to 3.4974e-06.\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.45650, a_loss 0.84472, cD 1.55460, wmdcmp 0.19848, oracc 0.98489, orien_loss 0.01311, chxlmicf1 0.58040, chxlmacf1 0.52873, chx_loss 0.74804, chxlacc 0.76706, chxlrocaucmic 0.84514, chxlrocaucmac 0.82743, qlmicf1 0.50809, qlmacf1 0.30180, ql_loss 0.55700, gacc 0.97909, gloss 0.04932, cxr14micf1 0.44892, cxr14macf1 0.44069, cxr14_loss 0.75541, vnbgmicf1 0.77480, vnbgmacf1 0.71598, vnbg_loss 0.34578, ema 0.77111, 101.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38738, wmdcmp 0.19386, oracc 0.98971, chxlmicf1 0.56792, chxlmacf1 0.50499, chxlacc 0.74517, chxlrocaucmic 0.81287, chxlrocaucmac 0.78506, qlmicf1 0.50497, qlmacf1 0.29779, ema 0.71818, 69.56 secs\n",
      "Adjusting learning rate of group 0 to 3.2341e-06.\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.76511, a_loss 0.83338, cD 1.56188, wmdcmp 0.19897, oracc 0.98545, orien_loss 0.01026, chxlmicf1 0.58344, chxlmacf1 0.53066, chx_loss 0.74688, chxlacc 0.76590, chxlrocaucmic 0.84593, chxlrocaucmac 0.82951, qlmicf1 0.50957, qlmacf1 0.29759, ql_loss 0.56268, gacc 0.98545, gloss 0.04383, cxr14micf1 0.44330, cxr14macf1 0.44107, cxr14_loss 0.74633, vnbgmicf1 0.76057, vnbgmacf1 0.69896, vnbg_loss 0.34487, ema 0.75963, 101.60 secs\n",
      "(2) Validation stage ...\n",
      "   iteration 330\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\" \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 20 \\\n",
    "        --iters-to-accumulate 8 \\\n",
    "        --num-workers 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,8e-5,56,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --raw-image-encoding \"clip-vit-large-huggingface\" \\\n",
    "        --clip-version \"CenIA/vte-vit-large-patch16-bio-clinical-bert-finetuned-v3\" \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
