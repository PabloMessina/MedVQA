{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 20\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,1e-4,16,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 0\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [256, 256]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(qa_adapted_reports__20220904_095810.json,clamped.pkl...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModel ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,1e-4,16,1e-6\n",
      "1e-06 4 0.0001 16 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "train_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "val_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 488528.81it/s]\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_17_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.4304.pt', 'checkpoint_34_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.5019.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/checkpoint_34_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.5019.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01151, chestimgbbmf1 0.82055, chestimgbb_loss 0.01867, chestimgbbiou 0.90743, chestimgbbmae 0.03177, 420.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.79640, chestimgbbiou 0.90104, chestimgbbmae 0.03452, 17.79 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 2/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01125, chestimgbbmf1 0.82205, chestimgbb_loss 0.01779, chestimgbbiou 0.90779, chestimgbbmae 0.03163, 422.72 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.79975, chestimgbbiou 0.90165, chestimgbbmae 0.03431, 17.51 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 3/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.01504, chestimgbbmf1 0.82323, chestimgbb_loss 0.01836, chestimgbbiou 0.90789, chestimgbbmae 0.03161, 421.57 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.80372, chestimgbbiou 0.90196, chestimgbbmae 0.03419, 17.74 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 4/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.01865, chestimgbbmf1 0.82239, chestimgbb_loss 0.01900, chestimgbbiou 0.90766, chestimgbbmae 0.03172, 419.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.80932, chestimgbbiou 0.90292, chestimgbbmae 0.03383, 17.24 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[1m---- Epoch 5/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 0.01817, chestimgbbmf1 0.79337, chestimgbb_loss 0.01972, chestimgbbiou 0.90323, chestimgbbmae 0.03329, 419.69 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81612, chestimgbbiou 0.90409, chestimgbbmae 0.03336, 17.25 secs\n",
      "Adjusting learning rate of group 0 to 7.4989e-05.\n",
      "\u001b[1m---- Epoch 6/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000075) ...\n",
      "loss 0.01065, chestimgbbmf1 0.85239, chestimgbb_loss 0.01838, chestimgbbiou 0.91300, chestimgbbmae 0.02986, 416.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84492, chestimgbbiou 0.90940, chestimgbbmae 0.03157, 17.20 secs\n",
      "Adjusting learning rate of group 0 to 5.6234e-05.\n",
      "\u001b[1m---- Epoch 7/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 0.01439, chestimgbbmf1 0.86918, chestimgbb_loss 0.01670, chestimgbbiou 0.91667, chestimgbbmae 0.02852, 416.99 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85537, chestimgbbiou 0.91149, chestimgbbmae 0.03082, 17.26 secs\n",
      "Adjusting learning rate of group 0 to 4.2170e-05.\n",
      "\u001b[1m---- Epoch 8/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 0.02045, chestimgbbmf1 0.87749, chestimgbb_loss 0.01629, chestimgbbiou 0.91844, chestimgbbmae 0.02792, 417.81 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86481, chestimgbbiou 0.91361, chestimgbbmae 0.03007, 17.24 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-05.\n",
      "\u001b[1m---- Epoch 9/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.01757, chestimgbbmf1 0.88341, chestimgbb_loss 0.01613, chestimgbbiou 0.92001, chestimgbbmae 0.02739, 418.24 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86994, chestimgbbiou 0.91537, chestimgbbmae 0.02945, 17.35 secs\n",
      "Adjusting learning rate of group 0 to 2.3714e-05.\n",
      "\u001b[1m---- Epoch 10/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.01703, chestimgbbmf1 0.88761, chestimgbb_loss 0.01659, chestimgbbiou 0.92081, chestimgbbmae 0.02714, 423.90 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87564, chestimgbbiou 0.91680, chestimgbbmae 0.02895, 17.57 secs\n",
      "Adjusting learning rate of group 0 to 1.7783e-05.\n",
      "\u001b[1m---- Epoch 11/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.00777, chestimgbbmf1 0.89387, chestimgbb_loss 0.01497, chestimgbbiou 0.92281, chestimgbbmae 0.02637, 422.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87938, chestimgbbiou 0.91733, chestimgbbmae 0.02877, 17.78 secs\n",
      "Adjusting learning rate of group 0 to 1.3335e-05.\n",
      "\u001b[1m---- Epoch 12/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.01509, chestimgbbmf1 0.89908, chestimgbb_loss 0.01294, chestimgbbiou 0.92432, chestimgbbmae 0.02577, 422.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88085, chestimgbbiou 0.91763, chestimgbbmae 0.02866, 17.54 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 13/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.00871, chestimgbbmf1 0.89879, chestimgbb_loss 0.01211, chestimgbbiou 0.92421, chestimgbbmae 0.02578, 419.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88323, chestimgbbiou 0.91844, chestimgbbmae 0.02839, 17.47 secs\n",
      "Adjusting learning rate of group 0 to 7.4989e-06.\n",
      "\u001b[1m---- Epoch 14/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "^C iteration 4000\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"../train_visual_module.py\", line 1295, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_visual_module.py\", line 1192, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_visual_module.py\", line 807, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 698, in step_fn\n",
      "    output = step_fn__mimiccxr_iuxray(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 175, in step_fn__mimiccxr_iuxray\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 362, in forward\n",
      "    padchest_forward=False,\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/models/densenet.py\", line 127, in forward\n",
      "    new_features = layer(features)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/models/densenet.py\", line 94, in forward\n",
      "    new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 446, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 443, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\" \\\n",
    "        --epochs 20 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 0 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,1e-4,16,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 20\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: models/visual_module/20230215_124027_mim_dense121\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   num_regions: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,3,1e-4,17,8e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: False\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: True\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModel ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,3,1e-4,17,8e-6\n",
      "1e-06 3 0.0001 17 8e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "train_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "val_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 455018.01it/s]\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_13_chestimgbbmf1=0.8848.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121/checkpoint_13_chestimgbbmf1=0.8848.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 14/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.00793, chestimgbbmf1 0.90149, chestimgbb_loss 0.01030, chestimgbbiou 0.92572, chestimgbbmae 0.02514, 398.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88381, chestimgbbiou 0.91874, chestimgbbmae 0.02830, 16.86 secs\n",
      "Adjusting learning rate of group 0 to 4.6416e-06.\n",
      "\u001b[1m---- Epoch 15/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01294, chestimgbbmf1 0.89952, chestimgbb_loss 0.01173, chestimgbbiou 0.92440, chestimgbbmae 0.02571, 395.29 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88174, chestimgbbiou 0.91792, chestimgbbmae 0.02859, 16.65 secs\n",
      "Adjusting learning rate of group 0 to 2.1544e-05.\n",
      "\u001b[1m---- Epoch 16/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.01030, chestimgbbmf1 0.89540, chestimgbb_loss 0.01163, chestimgbbiou 0.92341, chestimgbbmae 0.02602, 394.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87205, chestimgbbiou 0.91551, chestimgbbmae 0.02945, 17.04 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[1m---- Epoch 17/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 0.00766, chestimgbbmf1 0.83671, chestimgbb_loss 0.01602, chestimgbbiou 0.91082, chestimgbbmae 0.03058, 397.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84574, chestimgbbiou 0.91115, chestimgbbmae 0.03099, 16.69 secs\n",
      "Adjusting learning rate of group 0 to 8.6194e-05.\n",
      "\u001b[1m---- Epoch 18/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000086) ...\n",
      "loss 0.00686, chestimgbbmf1 0.87595, chestimgbb_loss 0.01623, chestimgbbiou 0.91841, chestimgbbmae 0.02794, 395.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86547, chestimgbbiou 0.91446, chestimgbbmae 0.02977, 16.71 secs\n",
      "Adjusting learning rate of group 0 to 7.4294e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 19/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000074) ...\n",
      "loss 0.01346, chestimgbbmf1 0.88901, chestimgbb_loss 0.01452, chestimgbbiou 0.92182, chestimgbbmae 0.02669, 397.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87360, chestimgbbiou 0.91652, chestimgbbmae 0.02910, 16.99 secs\n",
      "Adjusting learning rate of group 0 to 6.4037e-05.\n",
      "\u001b[1m---- Epoch 20/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000064) ...\n",
      "loss 0.01625, chestimgbbmf1 0.89440, chestimgbb_loss 0.01315, chestimgbbiou 0.92334, chestimgbbmae 0.02611, 394.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87730, chestimgbbiou 0.91729, chestimgbbmae 0.02883, 16.81 secs\n",
      "Adjusting learning rate of group 0 to 5.5195e-05.\n",
      "\u001b[1m---- Epoch 21/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000055) ...\n",
      "loss 0.02296, chestimgbbmf1 0.89747, chestimgbb_loss 0.01326, chestimgbbiou 0.92394, chestimgbbmae 0.02593, 396.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87696, chestimgbbiou 0.91719, chestimgbbmae 0.02886, 16.84 secs\n",
      "Adjusting learning rate of group 0 to 4.7575e-05.\n",
      "\u001b[1m---- Epoch 22/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 0.01060, chestimgbbmf1 0.90195, chestimgbb_loss 0.01201, chestimgbbiou 0.92581, chestimgbbmae 0.02522, 395.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88722, chestimgbbiou 0.92043, chestimgbbmae 0.02772, 16.81 secs\n",
      "Adjusting learning rate of group 0 to 4.1007e-05.\n",
      "\u001b[1m---- Epoch 23/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 0.01654, chestimgbbmf1 0.90485, chestimgbb_loss 0.01244, chestimgbbiou 0.92645, chestimgbbmae 0.02504, 396.75 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88177, chestimgbbiou 0.91816, chestimgbbmae 0.02858, 17.17 secs\n",
      "Adjusting learning rate of group 0 to 3.5345e-05.\n",
      "\u001b[1m---- Epoch 24/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000035) ...\n",
      "loss 0.00742, chestimgbbmf1 0.90696, chestimgbb_loss 0.01147, chestimgbbiou 0.92746, chestimgbbmae 0.02463, 399.01 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89092, chestimgbbiou 0.92123, chestimgbbmae 0.02745, 17.47 secs\n",
      "Adjusting learning rate of group 0 to 3.0465e-05.\n",
      "\u001b[1m---- Epoch 25/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.01584, chestimgbbmf1 0.91196, chestimgbb_loss 0.00917, chestimgbbiou 0.92913, chestimgbbmae 0.02396, 398.42 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89296, chestimgbbiou 0.92191, chestimgbbmae 0.02720, 16.71 secs\n",
      "Adjusting learning rate of group 0 to 2.6259e-05.\n",
      "\u001b[1m---- Epoch 26/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.00561, chestimgbbmf1 0.91378, chestimgbb_loss 0.00800, chestimgbbiou 0.93012, chestimgbbmae 0.02354, 391.71 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89460, chestimgbbiou 0.92264, chestimgbbmae 0.02697, 16.91 secs\n",
      "Adjusting learning rate of group 0 to 2.2634e-05.\n",
      "\u001b[1m---- Epoch 27/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.00364, chestimgbbmf1 0.91394, chestimgbb_loss 0.00810, chestimgbbiou 0.93001, chestimgbbmae 0.02360, 395.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89728, chestimgbbiou 0.92343, chestimgbbmae 0.02666, 17.47 secs\n",
      "Adjusting learning rate of group 0 to 1.9509e-05.\n",
      "\u001b[1m---- Epoch 28/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.00650, chestimgbbmf1 0.91535, chestimgbb_loss 0.00772, chestimgbbiou 0.93061, chestimgbbmae 0.02338, 396.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89562, chestimgbbiou 0.92317, chestimgbbmae 0.02675, 17.17 secs\n",
      "Adjusting learning rate of group 0 to 1.6816e-05.\n",
      "\u001b[1m---- Epoch 29/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.00943, chestimgbbmf1 0.91531, chestimgbb_loss 0.00778, chestimgbbiou 0.93076, chestimgbbmae 0.02333, 405.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89898, chestimgbbiou 0.92389, chestimgbbmae 0.02651, 17.84 secs\n",
      "Adjusting learning rate of group 0 to 1.4494e-05.\n",
      "\u001b[1m---- Epoch 30/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.00483, chestimgbbmf1 0.91558, chestimgbb_loss 0.00767, chestimgbbiou 0.93099, chestimgbbmae 0.02324, 410.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89878, chestimgbbiou 0.92404, chestimgbbmae 0.02647, 17.83 secs\n",
      "Adjusting learning rate of group 0 to 1.2493e-05.\n",
      "\u001b[1m---- Epoch 31/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00288, chestimgbbmf1 0.91849, chestimgbb_loss 0.00632, chestimgbbiou 0.93223, chestimgbbmae 0.02274, 411.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89947, chestimgbbiou 0.92440, chestimgbbmae 0.02635, 17.72 secs\n",
      "Adjusting learning rate of group 0 to 1.0768e-05.\n",
      "\u001b[1m---- Epoch 32/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.00452, chestimgbbmf1 0.91961, chestimgbb_loss 0.00625, chestimgbbiou 0.93253, chestimgbbmae 0.02264, 412.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90017, chestimgbbiou 0.92435, chestimgbbmae 0.02638, 17.83 secs\n",
      "Adjusting learning rate of group 0 to 9.2814e-06.\n",
      "\u001b[1m---- Epoch 33/33\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.00782, chestimgbbmf1 0.91964, chestimgbb_loss 0.00623, chestimgbbiou 0.93259, chestimgbbmae 0.02262, 408.79 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90198, chestimgbbiou 0.92538, chestimgbbmae 0.02600, 17.69 secs\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --checkpoint-folder \"models/visual_module/20230215_124027_mim_dense121\" \\\n",
    "        --epochs 20 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,3,1e-4,17,8e-6\" \\\n",
    "        --override-lr \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 30\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,5,1e-4,25,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [256, 256]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(qa_adapted_reports__20220904_095810.json,clamped.pkl...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModel ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,5,1e-4,25,1e-6\n",
      "1e-06 5 0.0001 25 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 2\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.3\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 480520.04it/s]\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_13_chestimgbbmf1=0.8848.pt', 'checkpoint_33_chestimgbbmf1=0.9038.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121/checkpoint_33_chestimgbbmf1=0.9038.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.13499, chestimgbbmf1 0.75716, chestimgbb_loss 0.08512, chestimgbbiou 0.88972, chestimgbbmae 0.04101, 402.50 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84675, chestimgbbiou 0.91179, chestimgbbmae 0.03107, 16.43 secs\n",
      "Adjusting learning rate of group 0 to 2.5119e-06.\n",
      "\u001b[1m---- Epoch 2/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.07164, chestimgbbmf1 0.78965, chestimgbb_loss 0.06475, chestimgbbiou 0.89463, chestimgbbmae 0.03893, 401.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85136, chestimgbbiou 0.91153, chestimgbbmae 0.03111, 16.47 secs\n",
      "Adjusting learning rate of group 0 to 6.3096e-06.\n",
      "\u001b[1m---- Epoch 3/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.04396, chestimgbbmf1 0.79957, chestimgbb_loss 0.04831, chestimgbbiou 0.89582, chestimgbbmae 0.03829, 398.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85205, chestimgbbiou 0.91119, chestimgbbmae 0.03118, 16.65 secs\n",
      "Adjusting learning rate of group 0 to 1.5849e-05.\n",
      "\u001b[1m---- Epoch 4/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.03553, chestimgbbmf1 0.81352, chestimgbb_loss 0.04149, chestimgbbiou 0.89868, chestimgbbmae 0.03707, 403.91 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85876, chestimgbbiou 0.91258, chestimgbbmae 0.03064, 16.60 secs\n",
      "Adjusting learning rate of group 0 to 3.9811e-05.\n",
      "\u001b[1m---- Epoch 5/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.02794, chestimgbbmf1 0.81961, chestimgbb_loss 0.03786, chestimgbbiou 0.90036, chestimgbbmae 0.03629, 402.29 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.85505, chestimgbbiou 0.91167, chestimgbbmae 0.03091, 16.76 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[1m---- Epoch 6/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 0.03304, chestimgbbmf1 0.79855, chestimgbb_loss 0.03610, chestimgbbiou 0.89677, chestimgbbmae 0.03748, 402.16 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84878, chestimgbbiou 0.91029, chestimgbbmae 0.03138, 16.70 secs\n",
      "Adjusting learning rate of group 0 to 8.3176e-05.\n",
      "\u001b[1m---- Epoch 7/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000083) ...\n",
      "loss 0.03732, chestimgbbmf1 0.83045, chestimgbb_loss 0.03433, chestimgbbiou 0.90329, chestimgbbmae 0.03505, 401.68 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84159, chestimgbbiou 0.90931, chestimgbbmae 0.03175, 16.49 secs\n",
      "Adjusting learning rate of group 0 to 6.9183e-05.\n",
      "\u001b[1m---- Epoch 8/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000069) ...\n",
      "loss 0.03826, chestimgbbmf1 0.84262, chestimgbb_loss 0.03336, chestimgbbiou 0.90584, chestimgbbmae 0.03410, 401.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86179, chestimgbbiou 0.91431, chestimgbbmae 0.02993, 16.65 secs\n",
      "Adjusting learning rate of group 0 to 5.7544e-05.\n",
      "\u001b[1m---- Epoch 9/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000058) ...\n",
      "loss 0.02444, chestimgbbmf1 0.85367, chestimgbb_loss 0.03219, chestimgbbiou 0.90845, chestimgbbmae 0.03313, 404.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87380, chestimgbbiou 0.91639, chestimgbbmae 0.02928, 16.64 secs\n",
      "Adjusting learning rate of group 0 to 4.7863e-05.\n",
      "\u001b[1m---- Epoch 10/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 0.02728, chestimgbbmf1 0.86035, chestimgbb_loss 0.03239, chestimgbbiou 0.91020, chestimgbbmae 0.03248, 402.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87632, chestimgbbiou 0.91727, chestimgbbmae 0.02888, 16.70 secs\n",
      "Adjusting learning rate of group 0 to 3.9811e-05.\n",
      "\u001b[1m---- Epoch 11/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.02307, chestimgbbmf1 0.86577, chestimgbb_loss 0.03206, chestimgbbiou 0.91148, chestimgbbmae 0.03203, 402.24 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87576, chestimgbbiou 0.91729, chestimgbbmae 0.02895, 16.81 secs\n",
      "Adjusting learning rate of group 0 to 3.3113e-05.\n",
      "\u001b[1m---- Epoch 12/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.02712, chestimgbbmf1 0.87089, chestimgbb_loss 0.03044, chestimgbbiou 0.91321, chestimgbbmae 0.03132, 399.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88295, chestimgbbiou 0.91892, chestimgbbmae 0.02840, 16.98 secs\n",
      "Adjusting learning rate of group 0 to 2.7542e-05.\n",
      "\u001b[1m---- Epoch 13/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.03810, chestimgbbmf1 0.87324, chestimgbb_loss 0.02994, chestimgbbiou 0.91388, chestimgbbmae 0.03108, 402.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88601, chestimgbbiou 0.92000, chestimgbbmae 0.02798, 16.73 secs\n",
      "Adjusting learning rate of group 0 to 2.2909e-05.\n",
      "\u001b[1m---- Epoch 14/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.02866, chestimgbbmf1 0.87516, chestimgbb_loss 0.03043, chestimgbbiou 0.91417, chestimgbbmae 0.03101, 402.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88911, chestimgbbiou 0.92120, chestimgbbmae 0.02757, 16.73 secs\n",
      "Adjusting learning rate of group 0 to 1.9055e-05.\n",
      "\u001b[1m---- Epoch 15/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.03108, chestimgbbmf1 0.87705, chestimgbb_loss 0.03048, chestimgbbiou 0.91455, chestimgbbmae 0.03089, 402.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88961, chestimgbbiou 0.92094, chestimgbbmae 0.02766, 16.70 secs\n",
      "Adjusting learning rate of group 0 to 1.5849e-05.\n",
      "\u001b[1m---- Epoch 16/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.03937, chestimgbbmf1 0.87975, chestimgbb_loss 0.03010, chestimgbbiou 0.91533, chestimgbbmae 0.03059, 401.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89148, chestimgbbiou 0.92177, chestimgbbmae 0.02738, 16.69 secs\n",
      "Adjusting learning rate of group 0 to 1.3183e-05.\n",
      "\u001b[1m---- Epoch 17/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.02718, chestimgbbmf1 0.87926, chestimgbb_loss 0.03001, chestimgbbiou 0.91542, chestimgbbmae 0.03057, 401.97 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89085, chestimgbbiou 0.92177, chestimgbbmae 0.02739, 16.74 secs\n",
      "Adjusting learning rate of group 0 to 1.0965e-05.\n",
      "\u001b[1m---- Epoch 18/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.03576, chestimgbbmf1 0.88224, chestimgbb_loss 0.02974, chestimgbbiou 0.91627, chestimgbbmae 0.03023, 402.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89365, chestimgbbiou 0.92218, chestimgbbmae 0.02724, 16.68 secs\n",
      "Adjusting learning rate of group 0 to 9.1201e-06.\n",
      "\u001b[1m---- Epoch 19/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.02362, chestimgbbmf1 0.88354, chestimgbb_loss 0.02949, chestimgbbiou 0.91663, chestimgbbmae 0.03011, 403.91 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89588, chestimgbbiou 0.92304, chestimgbbmae 0.02694, 16.79 secs\n",
      "Adjusting learning rate of group 0 to 7.5858e-06.\n",
      "\u001b[1m---- Epoch 20/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.02067, chestimgbbmf1 0.88454, chestimgbb_loss 0.02982, chestimgbbiou 0.91681, chestimgbbmae 0.03006, 403.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89598, chestimgbbiou 0.92319, chestimgbbmae 0.02686, 16.93 secs\n",
      "Adjusting learning rate of group 0 to 6.3096e-06.\n",
      "\u001b[1m---- Epoch 21/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.02154, chestimgbbmf1 0.88454, chestimgbb_loss 0.03015, chestimgbbiou 0.91666, chestimgbbmae 0.03014, 403.36 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89708, chestimgbbiou 0.92368, chestimgbbmae 0.02670, 17.03 secs\n",
      "Adjusting learning rate of group 0 to 5.2481e-06.\n",
      "\u001b[1m---- Epoch 22/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.02580, chestimgbbmf1 0.88588, chestimgbb_loss 0.02873, chestimgbbiou 0.91758, chestimgbbmae 0.02974, 403.33 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89839, chestimgbbiou 0.92396, chestimgbbmae 0.02661, 16.73 secs\n",
      "Adjusting learning rate of group 0 to 4.3652e-06.\n",
      "\u001b[1m---- Epoch 23/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.02159, chestimgbbmf1 0.88780, chestimgbb_loss 0.02930, chestimgbbiou 0.91782, chestimgbbmae 0.02967, 402.52 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89751, chestimgbbiou 0.92395, chestimgbbmae 0.02661, 16.70 secs\n",
      "Adjusting learning rate of group 0 to 3.6308e-06.\n",
      "\u001b[1m---- Epoch 24/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.03173, chestimgbbmf1 0.88606, chestimgbb_loss 0.02959, chestimgbbiou 0.91725, chestimgbbmae 0.02991, 404.41 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89784, chestimgbbiou 0.92403, chestimgbbmae 0.02658, 16.92 secs\n",
      "Adjusting learning rate of group 0 to 3.0200e-06.\n",
      "\u001b[1m---- Epoch 25/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.03361, chestimgbbmf1 0.88723, chestimgbb_loss 0.02905, chestimgbbiou 0.91787, chestimgbbmae 0.02964, 402.99 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89930, chestimgbbiou 0.92440, chestimgbbmae 0.02644, 16.73 secs\n",
      "Adjusting learning rate of group 0 to 2.5119e-06.\n",
      "\u001b[1m---- Epoch 26/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.03663, chestimgbbmf1 0.88869, chestimgbb_loss 0.02879, chestimgbbiou 0.91811, chestimgbbmae 0.02957, 403.52 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89889, chestimgbbiou 0.92428, chestimgbbmae 0.02649, 16.89 secs\n",
      "Adjusting learning rate of group 0 to 2.0893e-06.\n",
      "\u001b[1m---- Epoch 27/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02658, chestimgbbmf1 0.88692, chestimgbb_loss 0.02879, chestimgbbiou 0.91772, chestimgbbmae 0.02971, 402.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89931, chestimgbbiou 0.92452, chestimgbbmae 0.02641, 16.66 secs\n",
      "Adjusting learning rate of group 0 to 1.7378e-06.\n",
      "\u001b[1m---- Epoch 28/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02691, chestimgbbmf1 0.88813, chestimgbb_loss 0.02886, chestimgbbiou 0.91806, chestimgbbmae 0.02958, 400.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89875, chestimgbbiou 0.92436, chestimgbbmae 0.02646, 16.73 secs\n",
      "Adjusting learning rate of group 0 to 1.4454e-06.\n",
      "\u001b[1m---- Epoch 29/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.04603, chestimgbbmf1 0.88829, chestimgbb_loss 0.02907, chestimgbbiou 0.91814, chestimgbbmae 0.02954, 403.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89844, chestimgbbiou 0.92432, chestimgbbmae 0.02649, 16.69 secs\n",
      "Adjusting learning rate of group 0 to 1.2023e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 30/30\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.03208, chestimgbbmf1 0.88863, chestimgbb_loss 0.02817, chestimgbbiou 0.91850, chestimgbbmae 0.02936, 401.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89851, chestimgbbiou 0.92426, chestimgbbmae 0.02651, 16.70 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230215_124027_mim_dense121\" \\\n",
    "        --epochs 30 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,5,1e-4,25,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 15\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: models/visual_module/20230216_131111_mim_dn121\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,1e-5,10,2e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: False\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: True\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModel ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,1e-5,10,2e-6\n",
      "1e-06 4 1e-05 10 2e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 2\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.5\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 493939.91it/s]\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_25_chestimgbbmf1=0.8981.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121/checkpoint_25_chestimgbbmf1=0.8981.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02363, chestimgbbmf1 0.89579, chestimgbb_loss 0.02416, chestimgbbiou 0.92162, chestimgbbmae 0.02789, 299.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90010, chestimgbbiou 0.92485, chestimgbbmae 0.02629, 12.39 secs\n",
      "Adjusting learning rate of group 0 to 1.7783e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01402, chestimgbbmf1 0.89599, chestimgbb_loss 0.02397, chestimgbbiou 0.92140, chestimgbbmae 0.02801, 296.39 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90011, chestimgbbiou 0.92497, chestimgbbmae 0.02624, 12.58 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02639, chestimgbbmf1 0.89612, chestimgbb_loss 0.02417, chestimgbbiou 0.92157, chestimgbbmae 0.02791, 294.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90050, chestimgbbiou 0.92500, chestimgbbmae 0.02621, 12.52 secs\n",
      "Adjusting learning rate of group 0 to 5.6234e-06.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.01705, chestimgbbmf1 0.89487, chestimgbb_loss 0.02313, chestimgbbiou 0.92122, chestimgbbmae 0.02800, 294.27 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90024, chestimgbbiou 0.92486, chestimgbbmae 0.02628, 12.54 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.03075, chestimgbbmf1 0.89524, chestimgbb_loss 0.02309, chestimgbbiou 0.92149, chestimgbbmae 0.02787, 294.52 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89681, chestimgbbiou 0.92352, chestimgbbmae 0.02676, 12.57 secs\n",
      "Adjusting learning rate of group 0 to 8.5134e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.02168, chestimgbbmf1 0.89316, chestimgbb_loss 0.02379, chestimgbbiou 0.92087, chestimgbbmae 0.02810, 292.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89786, chestimgbbiou 0.92377, chestimgbbmae 0.02669, 12.43 secs\n",
      "Adjusting learning rate of group 0 to 7.2478e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.01526, chestimgbbmf1 0.89450, chestimgbb_loss 0.02384, chestimgbbiou 0.92086, chestimgbbmae 0.02817, 292.71 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89945, chestimgbbiou 0.92442, chestimgbbmae 0.02645, 12.52 secs\n",
      "Adjusting learning rate of group 0 to 6.1703e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.02457, chestimgbbmf1 0.89428, chestimgbb_loss 0.02306, chestimgbbiou 0.92142, chestimgbbmae 0.02790, 293.86 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90079, chestimgbbiou 0.92489, chestimgbbmae 0.02625, 12.54 secs\n",
      "Adjusting learning rate of group 0 to 5.2531e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.03847, chestimgbbmf1 0.89729, chestimgbb_loss 0.02327, chestimgbbiou 0.92213, chestimgbbmae 0.02766, 294.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90025, chestimgbbiou 0.92478, chestimgbbmae 0.02631, 12.49 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01822, chestimgbbmf1 0.89745, chestimgbb_loss 0.02310, chestimgbbiou 0.92227, chestimgbbmae 0.02762, 294.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90101, chestimgbbiou 0.92489, chestimgbbmae 0.02627, 12.54 secs\n",
      "Adjusting learning rate of group 0 to 3.8073e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.02163, chestimgbbmf1 0.89659, chestimgbb_loss 0.02363, chestimgbbiou 0.92193, chestimgbbmae 0.02778, 293.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90195, chestimgbbiou 0.92536, chestimgbbmae 0.02612, 12.58 secs\n",
      "Adjusting learning rate of group 0 to 3.2413e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01674, chestimgbbmf1 0.89698, chestimgbb_loss 0.02277, chestimgbbiou 0.92229, chestimgbbmae 0.02759, 294.35 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90216, chestimgbbiou 0.92533, chestimgbbmae 0.02613, 12.43 secs\n",
      "Adjusting learning rate of group 0 to 2.7595e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02901, chestimgbbmf1 0.89725, chestimgbb_loss 0.02347, chestimgbbiou 0.92219, chestimgbbmae 0.02767, 293.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90271, chestimgbbiou 0.92544, chestimgbbmae 0.02610, 12.50 secs\n",
      "Adjusting learning rate of group 0 to 2.3492e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02234, chestimgbbmf1 0.89750, chestimgbb_loss 0.02331, chestimgbbiou 0.92213, chestimgbbmae 0.02768, 293.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90246, chestimgbbiou 0.92567, chestimgbbmae 0.02600, 12.65 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02420, chestimgbbmf1 0.89756, chestimgbb_loss 0.02287, chestimgbbiou 0.92250, chestimgbbmae 0.02752, 292.62 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90259, chestimgbbiou 0.92557, chestimgbbmae 0.02605, 12.59 secs\n",
      "Adjusting learning rate of group 0 to 1.7027e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --checkpoint-folder \"models/visual_module/20230216_131111_mim_dn121\" \\\n",
    "        --epochs 15 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,1e-5,10,2e-6\" \\\n",
    "        --override-lr \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 20\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,1e-4,16,2e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [256, 256]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(qa_adapted_reports__20220904_095810.json,clamped).pkl...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,1e-4,16,2e-6\n",
      "1e-06 4 0.0001 16 2e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 490001.00it/s]\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_38_chestimgbbmf1=0.9022.pt', 'checkpoint_25_chestimgbbmf1=0.8981.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121/checkpoint_38_chestimgbbmf1=0.9022.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02451, chestimgbbmf1 0.91051, chestimgbb_loss 0.01606, chestimgbbiou 0.92854, chestimgbbmae 0.02466, 292.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90264, chestimgbbiou 0.92588, chestimgbbmae 0.02591, 12.06 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 2/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02830, chestimgbbmf1 0.91281, chestimgbb_loss 0.01594, chestimgbbiou 0.92926, chestimgbbmae 0.02438, 295.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90339, chestimgbbiou 0.92598, chestimgbbmae 0.02586, 12.28 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 3/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.00904, chestimgbbmf1 0.91118, chestimgbb_loss 0.01617, chestimgbbiou 0.92834, chestimgbbmae 0.02472, 296.54 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90214, chestimgbbiou 0.92531, chestimgbbmae 0.02610, 12.36 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-05.\n",
      "\u001b[1m---- Epoch 4/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.02536, chestimgbbmf1 0.90494, chestimgbb_loss 0.01632, chestimgbbiou 0.92575, chestimgbbmae 0.02562, 297.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88848, chestimgbbiou 0.92110, chestimgbbmae 0.02760, 12.50 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[1m---- Epoch 5/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 0.02316, chestimgbbmf1 0.86239, chestimgbb_loss 0.02008, chestimgbbiou 0.91444, chestimgbbmae 0.02967, 297.33 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86969, chestimgbbiou 0.91530, chestimgbbmae 0.02960, 12.60 secs\n",
      "Adjusting learning rate of group 0 to 7.8309e-05.\n",
      "\u001b[1m---- Epoch 6/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000078) ...\n",
      "loss 0.02344, chestimgbbmf1 0.88757, chestimgbb_loss 0.01888, chestimgbbiou 0.92087, chestimgbbmae 0.02741, 298.01 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88859, chestimgbbiou 0.91997, chestimgbbmae 0.02795, 12.34 secs\n",
      "Adjusting learning rate of group 0 to 6.1324e-05.\n",
      "\u001b[1m---- Epoch 7/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 0.01386, chestimgbbmf1 0.89786, chestimgbb_loss 0.01762, chestimgbbiou 0.92364, chestimgbbmae 0.02640, 298.81 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88989, chestimgbbiou 0.92115, chestimgbbmae 0.02750, 12.49 secs\n",
      "Adjusting learning rate of group 0 to 4.8022e-05.\n",
      "\u001b[1m---- Epoch 8/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 0.01978, chestimgbbmf1 0.90104, chestimgbb_loss 0.01729, chestimgbbiou 0.92499, chestimgbbmae 0.02591, 295.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89635, chestimgbbiou 0.92322, chestimgbbmae 0.02684, 12.47 secs\n",
      "Adjusting learning rate of group 0 to 3.7606e-05.\n",
      "\u001b[1m---- Epoch 9/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 0.01049, chestimgbbmf1 0.90699, chestimgbb_loss 0.01744, chestimgbbiou 0.92649, chestimgbbmae 0.02542, 295.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89450, chestimgbbiou 0.92258, chestimgbbmae 0.02703, 12.30 secs\n",
      "Adjusting learning rate of group 0 to 2.9449e-05.\n",
      "\u001b[1m---- Epoch 10/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 0.00956, chestimgbbmf1 0.90874, chestimgbb_loss 0.01707, chestimgbbiou 0.92737, chestimgbbmae 0.02512, 296.38 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90127, chestimgbbiou 0.92504, chestimgbbmae 0.02621, 12.41 secs\n",
      "Adjusting learning rate of group 0 to 2.3061e-05.\n",
      "\u001b[1m---- Epoch 11/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.01611, chestimgbbmf1 0.91155, chestimgbb_loss 0.01631, chestimgbbiou 0.92851, chestimgbbmae 0.02468, 293.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90538, chestimgbbiou 0.92643, chestimgbbmae 0.02569, 12.43 secs\n",
      "Adjusting learning rate of group 0 to 1.8059e-05.\n",
      "\u001b[1m---- Epoch 12/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.01175, chestimgbbmf1 0.91398, chestimgbb_loss 0.01513, chestimgbbiou 0.92966, chestimgbbmae 0.02422, 294.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90724, chestimgbbiou 0.92724, chestimgbbmae 0.02542, 12.16 secs\n",
      "Adjusting learning rate of group 0 to 1.4142e-05.\n",
      "\u001b[1m---- Epoch 13/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.00954, chestimgbbmf1 0.91567, chestimgbb_loss 0.01496, chestimgbbiou 0.93026, chestimgbbmae 0.02401, 293.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90601, chestimgbbiou 0.92696, chestimgbbmae 0.02551, 12.44 secs\n",
      "Adjusting learning rate of group 0 to 1.1075e-05.\n",
      "\u001b[1m---- Epoch 14/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.02136, chestimgbbmf1 0.91585, chestimgbb_loss 0.01458, chestimgbbiou 0.93033, chestimgbbmae 0.02398, 294.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90603, chestimgbbiou 0.92699, chestimgbbmae 0.02552, 12.27 secs\n",
      "Adjusting learning rate of group 0 to 8.6725e-06.\n",
      "\u001b[1m---- Epoch 15/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.01639, chestimgbbmf1 0.91605, chestimgbb_loss 0.01439, chestimgbbiou 0.93055, chestimgbbmae 0.02389, 294.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90783, chestimgbbiou 0.92764, chestimgbbmae 0.02529, 12.26 secs\n",
      "Adjusting learning rate of group 0 to 6.7914e-06.\n",
      "\u001b[1m---- Epoch 16/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.01601, chestimgbbmf1 0.91764, chestimgbb_loss 0.01451, chestimgbbiou 0.93104, chestimgbbmae 0.02375, 293.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90833, chestimgbbiou 0.92782, chestimgbbmae 0.02524, 12.30 secs\n",
      "Adjusting learning rate of group 0 to 5.3183e-06.\n",
      "\u001b[1m---- Epoch 17/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01315, chestimgbbmf1 0.91681, chestimgbb_loss 0.01446, chestimgbbiou 0.93085, chestimgbbmae 0.02380, 296.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90918, chestimgbbiou 0.92803, chestimgbbmae 0.02516, 12.49 secs\n",
      "Adjusting learning rate of group 0 to 4.1647e-06.\n",
      "\u001b[1m---- Epoch 18/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.02026, chestimgbbmf1 0.91707, chestimgbb_loss 0.01432, chestimgbbiou 0.93109, chestimgbbmae 0.02372, 295.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90986, chestimgbbiou 0.92825, chestimgbbmae 0.02509, 12.25 secs\n",
      "Adjusting learning rate of group 0 to 3.2614e-06.\n",
      "\u001b[1m---- Epoch 19/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01044, chestimgbbmf1 0.91908, chestimgbb_loss 0.01374, chestimgbbiou 0.93196, chestimgbbmae 0.02335, 295.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91018, chestimgbbiou 0.92865, chestimgbbmae 0.02493, 12.28 secs\n",
      "Adjusting learning rate of group 0 to 2.5540e-06.\n",
      "\u001b[1m---- Epoch 20/20\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02173, chestimgbbmf1 0.91815, chestimgbb_loss 0.01381, chestimgbbiou 0.93142, chestimgbbmae 0.02357, 294.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91084, chestimgbbiou 0.92890, chestimgbbmae 0.02485, 12.76 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230216_131111_mim_dn121\" \\\n",
    "        --epochs 20 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,1e-4,16,2e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 20\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: models/visual_module/20230221_174959_mim_dn121\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,5,6e-5,15,2e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: False\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: True\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,5,6e-5,15,2e-6\n",
      "1e-06 5 6e-05 15 2e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.4\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 484558.65it/s]\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_50_chestimgbbmf1=0.9053.pt', 'checkpoint_20_chestimgbbmf1=0.9116.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/checkpoint_20_chestimgbbmf1=0.9116.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01410, chestimgbbmf1 0.91695, chestimgbb_loss 0.01532, chestimgbbiou 0.93070, chestimgbbmae 0.02391, 291.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91033, chestimgbbiou 0.92871, chestimgbbmae 0.02491, 12.31 secs\n",
      "Adjusting learning rate of group 0 to 2.2679e-06.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01532, chestimgbbmf1 0.91803, chestimgbb_loss 0.01431, chestimgbbiou 0.93136, chestimgbbmae 0.02363, 291.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90992, chestimgbbiou 0.92868, chestimgbbmae 0.02492, 12.39 secs\n",
      "Adjusting learning rate of group 0 to 5.1435e-06.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01558, chestimgbbmf1 0.91677, chestimgbb_loss 0.01473, chestimgbbiou 0.93066, chestimgbbmae 0.02390, 292.13 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90952, chestimgbbiou 0.92831, chestimgbbmae 0.02506, 12.52 secs\n",
      "Adjusting learning rate of group 0 to 1.1665e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.01544, chestimgbbmf1 0.91502, chestimgbb_loss 0.01447, chestimgbbiou 0.92994, chestimgbbmae 0.02414, 294.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90697, chestimgbbiou 0.92744, chestimgbbmae 0.02538, 12.49 secs\n",
      "Adjusting learning rate of group 0 to 2.6456e-05.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01462, chestimgbbmf1 0.90902, chestimgbb_loss 0.01574, chestimgbbiou 0.92744, chestimgbbmae 0.02505, 293.48 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89714, chestimgbbiou 0.92402, chestimgbbmae 0.02660, 12.35 secs\n",
      "Adjusting learning rate of group 0 to 6.0000e-05.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.01552, chestimgbbmf1 0.89322, chestimgbb_loss 0.01734, chestimgbbiou 0.92192, chestimgbbmae 0.02699, 293.34 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.88109, chestimgbbiou 0.91846, chestimgbbmae 0.02845, 12.35 secs\n",
      "Adjusting learning rate of group 0 to 4.7827e-05.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 0.01894, chestimgbbmf1 0.89845, chestimgbb_loss 0.01691, chestimgbbiou 0.92407, chestimgbbmae 0.02624, 293.35 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88974, chestimgbbiou 0.92028, chestimgbbmae 0.02797, 12.43 secs\n",
      "Adjusting learning rate of group 0 to 3.8124e-05.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 0.02555, chestimgbbmf1 0.90596, chestimgbb_loss 0.01637, chestimgbbiou 0.92622, chestimgbbmae 0.02550, 293.66 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89838, chestimgbbiou 0.92351, chestimgbbmae 0.02685, 12.58 secs\n",
      "Adjusting learning rate of group 0 to 3.0390e-05.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.00952, chestimgbbmf1 0.90819, chestimgbb_loss 0.01611, chestimgbbiou 0.92737, chestimgbbmae 0.02508, 292.39 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90064, chestimgbbiou 0.92491, chestimgbbmae 0.02626, 12.51 secs\n",
      "Adjusting learning rate of group 0 to 2.4224e-05.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.00895, chestimgbbmf1 0.91108, chestimgbb_loss 0.01581, chestimgbbiou 0.92840, chestimgbbmae 0.02473, 294.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90756, chestimgbbiou 0.92697, chestimgbbmae 0.02554, 12.39 secs\n",
      "Adjusting learning rate of group 0 to 1.9310e-05.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.02014, chestimgbbmf1 0.91357, chestimgbb_loss 0.01584, chestimgbbiou 0.92934, chestimgbbmae 0.02439, 295.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90695, chestimgbbiou 0.92705, chestimgbbmae 0.02551, 12.46 secs\n",
      "Adjusting learning rate of group 0 to 1.5392e-05.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.00809, chestimgbbmf1 0.91514, chestimgbb_loss 0.01423, chestimgbbiou 0.93014, chestimgbbmae 0.02405, 292.32 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90676, chestimgbbiou 0.92729, chestimgbbmae 0.02543, 12.37 secs\n",
      "Adjusting learning rate of group 0 to 1.2270e-05.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.01299, chestimgbbmf1 0.91577, chestimgbb_loss 0.01456, chestimgbbiou 0.93045, chestimgbbmae 0.02397, 291.61 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90773, chestimgbbiou 0.92755, chestimgbbmae 0.02537, 12.31 secs\n",
      "Adjusting learning rate of group 0 to 9.7803e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.01288, chestimgbbmf1 0.91663, chestimgbb_loss 0.01455, chestimgbbiou 0.93078, chestimgbbmae 0.02384, 291.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91026, chestimgbbiou 0.92856, chestimgbbmae 0.02499, 12.50 secs\n",
      "Adjusting learning rate of group 0 to 7.7961e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01262, chestimgbbmf1 0.91734, chestimgbb_loss 0.01425, chestimgbbiou 0.93104, chestimgbbmae 0.02375, 294.42 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90939, chestimgbbiou 0.92817, chestimgbbmae 0.02513, 12.34 secs\n",
      "Adjusting learning rate of group 0 to 6.2145e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.00990, chestimgbbmf1 0.91726, chestimgbb_loss 0.01458, chestimgbbiou 0.93084, chestimgbbmae 0.02387, 292.35 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91060, chestimgbbiou 0.92874, chestimgbbmae 0.02494, 12.55 secs\n",
      "Adjusting learning rate of group 0 to 4.9537e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00740, chestimgbbmf1 0.91773, chestimgbb_loss 0.01430, chestimgbbiou 0.93124, chestimgbbmae 0.02368, 292.36 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91044, chestimgbbiou 0.92844, chestimgbbmae 0.02507, 12.52 secs\n",
      "Adjusting learning rate of group 0 to 3.9487e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01119, chestimgbbmf1 0.91877, chestimgbb_loss 0.01367, chestimgbbiou 0.93167, chestimgbbmae 0.02351, 292.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91066, chestimgbbiou 0.92852, chestimgbbmae 0.02504, 12.49 secs\n",
      "Adjusting learning rate of group 0 to 3.1476e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00697, chestimgbbmf1 0.91976, chestimgbb_loss 0.01373, chestimgbbiou 0.93215, chestimgbbmae 0.02332, 293.29 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91000, chestimgbbiou 0.92844, chestimgbbmae 0.02506, 12.55 secs\n",
      "Adjusting learning rate of group 0 to 2.5090e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01626, chestimgbbmf1 0.91808, chestimgbb_loss 0.01390, chestimgbbiou 0.93164, chestimgbbmae 0.02351, 301.57 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91136, chestimgbbiou 0.92900, chestimgbbmae 0.02486, 13.51 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --checkpoint-folder \"models/visual_module/20230221_174959_mim_dn121\" \\\n",
    "        --epochs 20 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,5,6e-5,15,2e-6\" \\\n",
    "        --override-lr \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 45\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 256\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,5e-4,38,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 40\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [512, 512]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped).pkl...\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 256\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,5e-4,38,1e-6\n",
      "1e-06 7 0.0005 38 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "227835it [00:00, 488944.49it/s]\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230223_234613_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230223_234613_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_40_chestimgbbmf1=0.9120.pt', 'checkpoint_50_chestimgbbmf1=0.9053.pt', 'checkpoint_20_chestimgbbmf1=0.9116.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/checkpoint_40_chestimgbbmf1=0.9120.pt\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.0.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.1.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.2.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.3.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.4.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.5.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.6.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.7.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.8.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.9.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.10.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.11.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.12.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.13.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.14.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.15.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.16.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.17.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.18.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.19.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.20.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.21.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.22.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.23.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.24.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.25.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.26.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.27.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.28.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.29.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.30.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.31.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.32.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.33.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.34.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_coords_fc.35.weight, required shape: torch.Size([4, 32896]), loaded shape: torch.Size([4, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.0.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.1.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.2.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.3.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.4.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.5.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.6.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.7.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.8.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.9.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.10.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.11.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.12.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.13.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.14.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.15.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.16.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.17.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.18.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.19.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.20.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.21.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.22.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.23.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.24.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.25.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.26.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.27.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.28.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.29.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.30.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.31.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.32.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.33.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.34.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.bbox_presence_fc.35.weight, required shape: torch.Size([1, 32896]), loaded shape: torch.Size([1, 8320])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230223_234613_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.74867, chestimgbbmf1 0.01409, chestimgbb_loss 0.57877, chestimgbbiou 0.64929, chestimgbbmae 0.14375, 180.72 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.02387, chestimgbbiou 0.67768, chestimgbbmae 0.12801, 19.96 secs\n",
      "Adjusting learning rate of group 0 to 2.4298e-06.\n",
      "\u001b[1m---- Epoch 2/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44938, chestimgbbmf1 0.02892, chestimgbb_loss 0.26517, chestimgbbiou 0.69398, chestimgbbmae 0.11992, 180.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.03492, chestimgbbiou 0.70723, chestimgbbmae 0.11330, 20.30 secs\n",
      "Adjusting learning rate of group 0 to 5.9038e-06.\n",
      "\u001b[1m---- Epoch 3/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.15167, chestimgbbmf1 0.04937, chestimgbb_loss 0.07639, chestimgbbiou 0.73084, chestimgbbmae 0.10243, 181.53 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.06788, chestimgbbiou 0.75302, chestimgbbmae 0.09219, 20.25 secs\n",
      "Adjusting learning rate of group 0 to 1.4345e-05.\n",
      "\u001b[1m---- Epoch 4/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.07361, chestimgbbmf1 0.09126, chestimgbb_loss 0.04881, chestimgbbiou 0.76926, chestimgbbmae 0.08528, 181.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.11960, chestimgbbiou 0.78673, chestimgbbmae 0.07777, 20.27 secs\n",
      "Adjusting learning rate of group 0 to 3.4855e-05.\n",
      "\u001b[1m---- Epoch 5/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000035) ...\n",
      "loss 0.12424, chestimgbbmf1 0.13641, chestimgbb_loss 0.04125, chestimgbbiou 0.79346, chestimgbbmae 0.07494, 181.61 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.17372, chestimgbbiou 0.80783, chestimgbbmae 0.06892, 20.44 secs\n",
      "Adjusting learning rate of group 0 to 8.4691e-05.\n",
      "\u001b[1m---- Epoch 6/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000085) ...\n",
      "loss 0.02389, chestimgbbmf1 0.16443, chestimgbb_loss 0.03805, chestimgbbiou 0.79918, chestimgbbmae 0.07280, 181.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22023, chestimgbbiou 0.81775, chestimgbbmae 0.06512, 20.30 secs\n",
      "Adjusting learning rate of group 0 to 2.0578e-04.\n",
      "\u001b[1m---- Epoch 7/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000206) ...\n",
      "loss 0.03463, chestimgbbmf1 0.31400, chestimgbb_loss 0.05734, chestimgbbiou 0.77916, chestimgbbmae 0.09077, 181.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.35771, chestimgbbiou 0.83196, chestimgbbmae 0.06013, 20.31 secs\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "\u001b[1m---- Epoch 8/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000500) ...\n",
      "loss 0.02485, chestimgbbmf1 0.38531, chestimgbb_loss 0.03744, chestimgbbiou 0.84042, chestimgbbmae 0.05696, 181.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.48683, chestimgbbiou 0.86257, chestimgbbmae 0.04762, 20.36 secs\n",
      "Adjusting learning rate of group 0 to 4.2457e-04.\n",
      "\u001b[1m---- Epoch 9/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000425) ...\n",
      "loss 0.02273, chestimgbbmf1 0.52662, chestimgbb_loss 0.03303, chestimgbbiou 0.87061, chestimgbbmae 0.04457, 181.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.43777, chestimgbbiou 0.85326, chestimgbbmae 0.05137, 20.41 secs\n",
      "Adjusting learning rate of group 0 to 3.6051e-04.\n",
      "\u001b[1m---- Epoch 10/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000361) ...\n",
      "loss 0.01464, chestimgbbmf1 0.59689, chestimgbb_loss 0.03081, chestimgbbiou 0.87965, chestimgbbmae 0.04128, 181.39 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.63438, chestimgbbiou 0.88313, chestimgbbmae 0.03998, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 3.0612e-04.\n",
      "\u001b[1m---- Epoch 11/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000306) ...\n",
      "loss 0.03077, chestimgbbmf1 0.66991, chestimgbb_loss 0.02941, chestimgbbiou 0.88887, chestimgbbmae 0.03795, 181.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.63956, chestimgbbiou 0.88520, chestimgbbmae 0.03925, 20.45 secs\n",
      "Adjusting learning rate of group 0 to 2.5994e-04.\n",
      "\u001b[1m---- Epoch 12/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000260) ...\n",
      "loss 0.00775, chestimgbbmf1 0.69277, chestimgbb_loss 0.02813, chestimgbbiou 0.89184, chestimgbbmae 0.03688, 181.29 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.65089, chestimgbbiou 0.88590, chestimgbbmae 0.03892, 20.51 secs\n",
      "Adjusting learning rate of group 0 to 2.2072e-04.\n",
      "\u001b[1m---- Epoch 13/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000221) ...\n",
      "loss 0.03092, chestimgbbmf1 0.71910, chestimgbb_loss 0.02700, chestimgbbiou 0.89504, chestimgbbmae 0.03574, 181.50 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71325, chestimgbbiou 0.89371, chestimgbbmae 0.03617, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 1.8742e-04.\n",
      "\u001b[1m---- Epoch 14/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000187) ...\n",
      "loss 0.02381, chestimgbbmf1 0.74725, chestimgbb_loss 0.02641, chestimgbbiou 0.89899, chestimgbbmae 0.03434, 181.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75459, chestimgbbiou 0.89845, chestimgbbmae 0.03465, 20.45 secs\n",
      "Adjusting learning rate of group 0 to 1.5914e-04.\n",
      "\u001b[1m---- Epoch 15/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 0.00545, chestimgbbmf1 0.76920, chestimgbb_loss 0.02650, chestimgbbiou 0.90150, chestimgbbmae 0.03350, 181.29 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72985, chestimgbbiou 0.89623, chestimgbbmae 0.03526, 20.45 secs\n",
      "Adjusting learning rate of group 0 to 1.3513e-04.\n",
      "\u001b[1m---- Epoch 16/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000135) ...\n",
      "loss 0.05492, chestimgbbmf1 0.79493, chestimgbb_loss 0.02607, chestimgbbiou 0.90606, chestimgbbmae 0.03181, 181.81 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.79565, chestimgbbiou 0.90559, chestimgbbmae 0.03191, 20.43 secs\n",
      "Adjusting learning rate of group 0 to 1.1475e-04.\n",
      "\u001b[1m---- Epoch 17/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000115) ...\n",
      "loss 0.01365, chestimgbbmf1 0.79387, chestimgbb_loss 0.02678, chestimgbbiou 0.90578, chestimgbbmae 0.03194, 181.57 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.78505, chestimgbbiou 0.90380, chestimgbbmae 0.03269, 20.39 secs\n",
      "Adjusting learning rate of group 0 to 9.7435e-05.\n",
      "\u001b[1m---- Epoch 18/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000097) ...\n",
      "loss 0.06077, chestimgbbmf1 0.81101, chestimgbb_loss 0.02504, chestimgbbiou 0.90845, chestimgbbmae 0.03099, 181.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81844, chestimgbbiou 0.90922, chestimgbbmae 0.03067, 20.43 secs\n",
      "Adjusting learning rate of group 0 to 8.2735e-05.\n",
      "\u001b[1m---- Epoch 19/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000083) ...\n",
      "loss 0.02170, chestimgbbmf1 0.82706, chestimgbb_loss 0.02597, chestimgbbiou 0.91089, chestimgbbmae 0.03015, 181.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83643, chestimgbbiou 0.91240, chestimgbbmae 0.02965, 20.46 secs\n",
      "Adjusting learning rate of group 0 to 7.0253e-05.\n",
      "\u001b[1m---- Epoch 20/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 0.01645, chestimgbbmf1 0.83325, chestimgbb_loss 0.02500, chestimgbbiou 0.91216, chestimgbbmae 0.02973, 182.56 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82531, chestimgbbiou 0.91103, chestimgbbmae 0.03012, 20.39 secs\n",
      "Adjusting learning rate of group 0 to 5.9654e-05.\n",
      "\u001b[1m---- Epoch 21/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.01175, chestimgbbmf1 0.84219, chestimgbb_loss 0.02347, chestimgbbiou 0.91365, chestimgbbmae 0.02921, 180.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82828, chestimgbbiou 0.91138, chestimgbbmae 0.02995, 20.40 secs\n",
      "Adjusting learning rate of group 0 to 5.0654e-05.\n",
      "\u001b[1m---- Epoch 22/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 0.01363, chestimgbbmf1 0.84319, chestimgbb_loss 0.02412, chestimgbbiou 0.91375, chestimgbbmae 0.02918, 181.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84260, chestimgbbiou 0.91381, chestimgbbmae 0.02918, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 4.3012e-05.\n",
      "\u001b[1m---- Epoch 23/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.01007, chestimgbbmf1 0.85151, chestimgbb_loss 0.02316, chestimgbbiou 0.91570, chestimgbbmae 0.02845, 181.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85146, chestimgbbiou 0.91531, chestimgbbmae 0.02861, 20.45 secs\n",
      "Adjusting learning rate of group 0 to 3.6523e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 24/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 0.02286, chestimgbbmf1 0.85352, chestimgbb_loss 0.02429, chestimgbbiou 0.91559, chestimgbbmae 0.02853, 181.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85119, chestimgbbiou 0.91477, chestimgbbmae 0.02886, 20.63 secs\n",
      "Adjusting learning rate of group 0 to 3.1012e-05.\n",
      "\u001b[1m---- Epoch 25/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 0.01222, chestimgbbmf1 0.85659, chestimgbb_loss 0.02329, chestimgbbiou 0.91605, chestimgbbmae 0.02840, 181.12 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86150, chestimgbbiou 0.91747, chestimgbbmae 0.02784, 20.46 secs\n",
      "Adjusting learning rate of group 0 to 2.6334e-05.\n",
      "\u001b[1m---- Epoch 26/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.03534, chestimgbbmf1 0.86306, chestimgbb_loss 0.02295, chestimgbbiou 0.91799, chestimgbbmae 0.02763, 181.24 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84964, chestimgbbiou 0.91488, chestimgbbmae 0.02886, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 2.2361e-05.\n",
      "\u001b[1m---- Epoch 27/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.00820, chestimgbbmf1 0.86342, chestimgbb_loss 0.02257, chestimgbbiou 0.91767, chestimgbbmae 0.02782, 181.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86304, chestimgbbiou 0.91710, chestimgbbmae 0.02810, 20.24 secs\n",
      "Adjusting learning rate of group 0 to 1.8987e-05.\n",
      "\u001b[1m---- Epoch 28/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.01722, chestimgbbmf1 0.86776, chestimgbb_loss 0.02336, chestimgbbiou 0.91822, chestimgbbmae 0.02766, 180.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86642, chestimgbbiou 0.91806, chestimgbbmae 0.02772, 20.82 secs\n",
      "Adjusting learning rate of group 0 to 1.6123e-05.\n",
      "\u001b[1m---- Epoch 29/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01073, chestimgbbmf1 0.86903, chestimgbb_loss 0.02439, chestimgbbiou 0.91839, chestimgbbmae 0.02763, 181.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86780, chestimgbbiou 0.91870, chestimgbbmae 0.02748, 20.50 secs\n",
      "Adjusting learning rate of group 0 to 1.3690e-05.\n",
      "\u001b[1m---- Epoch 30/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.00906, chestimgbbmf1 0.87333, chestimgbb_loss 0.02248, chestimgbbiou 0.92003, chestimgbbmae 0.02694, 180.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86946, chestimgbbiou 0.91891, chestimgbbmae 0.02743, 20.62 secs\n",
      "Adjusting learning rate of group 0 to 1.1625e-05.\n",
      "\u001b[1m---- Epoch 31/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.04621, chestimgbbmf1 0.87322, chestimgbb_loss 0.02187, chestimgbbiou 0.91991, chestimgbbmae 0.02702, 181.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87043, chestimgbbiou 0.91936, chestimgbbmae 0.02724, 20.39 secs\n",
      "Adjusting learning rate of group 0 to 9.8709e-06.\n",
      "\u001b[1m---- Epoch 32/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.01686, chestimgbbmf1 0.87668, chestimgbb_loss 0.02158, chestimgbbiou 0.92092, chestimgbbmae 0.02663, 181.75 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87405, chestimgbbiou 0.91998, chestimgbbmae 0.02706, 20.33 secs\n",
      "Adjusting learning rate of group 0 to 8.3817e-06.\n",
      "\u001b[1m---- Epoch 33/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.00886, chestimgbbmf1 0.87732, chestimgbb_loss 0.02200, chestimgbbiou 0.92051, chestimgbbmae 0.02683, 181.47 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87331, chestimgbbiou 0.91970, chestimgbbmae 0.02716, 20.40 secs\n",
      "Adjusting learning rate of group 0 to 7.1172e-06.\n",
      "\u001b[1m---- Epoch 34/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.01126, chestimgbbmf1 0.87759, chestimgbb_loss 0.02270, chestimgbbiou 0.92059, chestimgbbmae 0.02681, 181.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87447, chestimgbbiou 0.91993, chestimgbbmae 0.02707, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 6.0434e-06.\n",
      "\u001b[1m---- Epoch 35/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.02280, chestimgbbmf1 0.87712, chestimgbb_loss 0.02218, chestimgbbiou 0.92078, chestimgbbmae 0.02670, 181.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87268, chestimgbbiou 0.91961, chestimgbbmae 0.02721, 20.43 secs\n",
      "Adjusting learning rate of group 0 to 5.1316e-06.\n",
      "\u001b[1m---- Epoch 36/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01017, chestimgbbmf1 0.87698, chestimgbb_loss 0.02161, chestimgbbiou 0.92058, chestimgbbmae 0.02680, 181.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87633, chestimgbbiou 0.92050, chestimgbbmae 0.02687, 20.43 secs\n",
      "Adjusting learning rate of group 0 to 4.3574e-06.\n",
      "\u001b[1m---- Epoch 37/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01678, chestimgbbmf1 0.87664, chestimgbb_loss 0.02294, chestimgbbiou 0.92038, chestimgbbmae 0.02691, 180.65 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87454, chestimgbbiou 0.92032, chestimgbbmae 0.02692, 20.48 secs\n",
      "Adjusting learning rate of group 0 to 3.7000e-06.\n",
      "\u001b[1m---- Epoch 38/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00410, chestimgbbmf1 0.87603, chestimgbb_loss 0.02309, chestimgbbiou 0.92032, chestimgbbmae 0.02692, 180.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87565, chestimgbbiou 0.92032, chestimgbbmae 0.02693, 20.46 secs\n",
      "Adjusting learning rate of group 0 to 3.1418e-06.\n",
      "\u001b[1m---- Epoch 39/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00949, chestimgbbmf1 0.87717, chestimgbb_loss 0.02277, chestimgbbiou 0.92069, chestimgbbmae 0.02678, 181.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87534, chestimgbbiou 0.92038, chestimgbbmae 0.02690, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 2.6678e-06.\n",
      "\u001b[1m---- Epoch 40/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01234, chestimgbbmf1 0.87728, chestimgbb_loss 0.02366, chestimgbbiou 0.92053, chestimgbbmae 0.02685, 182.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87427, chestimgbbiou 0.92010, chestimgbbmae 0.02703, 20.40 secs\n",
      "Adjusting learning rate of group 0 to 2.2653e-06.\n",
      "\u001b[1m---- Epoch 41/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.04285, chestimgbbmf1 0.88006, chestimgbb_loss 0.02137, chestimgbbiou 0.92150, chestimgbbmae 0.02648, 181.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87409, chestimgbbiou 0.92032, chestimgbbmae 0.02694, 20.38 secs\n",
      "Adjusting learning rate of group 0 to 1.9235e-06.\n",
      "\u001b[1m---- Epoch 42/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01722, chestimgbbmf1 0.88242, chestimgbb_loss 0.02034, chestimgbbiou 0.92201, chestimgbbmae 0.02627, 181.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87694, chestimgbbiou 0.92092, chestimgbbmae 0.02671, 20.41 secs\n",
      "Adjusting learning rate of group 0 to 1.6333e-06.\n",
      "\u001b[1m---- Epoch 43/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02769, chestimgbbmf1 0.87955, chestimgbb_loss 0.02298, chestimgbbiou 0.92126, chestimgbbmae 0.02657, 180.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87560, chestimgbbiou 0.92048, chestimgbbmae 0.02688, 20.50 secs\n",
      "Adjusting learning rate of group 0 to 1.3869e-06.\n",
      "\u001b[1m---- Epoch 44/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02506, chestimgbbmf1 0.88111, chestimgbb_loss 0.02190, chestimgbbiou 0.92134, chestimgbbmae 0.02656, 181.48 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87508, chestimgbbiou 0.92039, chestimgbbmae 0.02692, 20.50 secs\n",
      "Adjusting learning rate of group 0 to 1.1777e-06.\n",
      "\u001b[1m---- Epoch 45/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02543, chestimgbbmf1 0.87864, chestimgbb_loss 0.02211, chestimgbbiou 0.92096, chestimgbbmae 0.02670, 181.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87639, chestimgbbiou 0.92067, chestimgbbmae 0.02681, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\" \\\n",
    "        --epochs 45 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 40 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,5e-4,38,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 512 512 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 256 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 45\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 256\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,5e-5,38,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 40\n",
      "   iters_to_accumulate: 5\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [512, 512]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230223_234613_mim_dn121\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped).pkl...\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 256\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,5e-5,38,1e-6\n",
      "1e-06 7 5e-05 38 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "227835it [00:00, 490346.97it/s]\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_051558_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_051558_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_42_chestimgbbmf1=0.8775.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230223_234613_mim_dn121/checkpoint_42_chestimgbbmf1=0.8775.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_051558_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.04850, chestimgbbmf1 0.88166, chestimgbb_loss 0.02148, chestimgbbiou 0.92188, chestimgbbmae 0.02635, 180.44 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87631, chestimgbbiou 0.92070, chestimgbbmae 0.02679, 20.12 secs\n",
      "Adjusting learning rate of group 0 to 1.7487e-06.\n",
      "\u001b[1m---- Epoch 2/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01402, chestimgbbmf1 0.87809, chestimgbb_loss 0.02270, chestimgbbiou 0.92087, chestimgbbmae 0.02671, 179.41 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87499, chestimgbbiou 0.92040, chestimgbbmae 0.02692, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 3.0579e-06.\n",
      "\u001b[1m---- Epoch 3/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.04388, chestimgbbmf1 0.87884, chestimgbb_loss 0.02127, chestimgbbiou 0.92118, chestimgbbmae 0.02658, 180.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87351, chestimgbbiou 0.92004, chestimgbbmae 0.02701, 20.49 secs\n",
      "Adjusting learning rate of group 0 to 5.3472e-06.\n",
      "\u001b[1m---- Epoch 4/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00631, chestimgbbmf1 0.87668, chestimgbb_loss 0.02192, chestimgbbiou 0.92052, chestimgbbmae 0.02683, 180.29 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87106, chestimgbbiou 0.91953, chestimgbbmae 0.02718, 20.33 secs\n",
      "Adjusting learning rate of group 0 to 9.3506e-06.\n",
      "\u001b[1m---- Epoch 5/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.02385, chestimgbbmf1 0.87608, chestimgbb_loss 0.02137, chestimgbbiou 0.92022, chestimgbbmae 0.02692, 180.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86590, chestimgbbiou 0.91848, chestimgbbmae 0.02757, 20.49 secs\n",
      "Adjusting learning rate of group 0 to 1.6351e-05.\n",
      "\u001b[1m---- Epoch 6/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.00642, chestimgbbmf1 0.86720, chestimgbb_loss 0.02243, chestimgbbiou 0.91820, chestimgbbmae 0.02765, 180.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86508, chestimgbbiou 0.91834, chestimgbbmae 0.02757, 20.59 secs\n",
      "Adjusting learning rate of group 0 to 2.8593e-05.\n",
      "\u001b[1m---- Epoch 7/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 0.02594, chestimgbbmf1 0.85177, chestimgbb_loss 0.02213, chestimgbbiou 0.91567, chestimgbbmae 0.02847, 180.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.85498, chestimgbbiou 0.91562, chestimgbbmae 0.02855, 20.54 secs\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "\u001b[1m---- Epoch 8/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n",
      "loss 0.05878, chestimgbbmf1 0.81831, chestimgbb_loss 0.02233, chestimgbbiou 0.90984, chestimgbbmae 0.03046, 180.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81128, chestimgbbiou 0.90879, chestimgbbmae 0.03090, 20.56 secs\n",
      "Adjusting learning rate of group 0 to 4.5109e-05.\n",
      "\u001b[1m---- Epoch 9/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 0.01249, chestimgbbmf1 0.83203, chestimgbb_loss 0.02276, chestimgbbiou 0.91240, chestimgbbmae 0.02958, 180.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84097, chestimgbbiou 0.91316, chestimgbbmae 0.02941, 20.62 secs\n",
      "Adjusting learning rate of group 0 to 4.0696e-05.\n",
      "\u001b[1m---- Epoch 10/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 0.01525, chestimgbbmf1 0.85019, chestimgbb_loss 0.02280, chestimgbbiou 0.91557, chestimgbbmae 0.02851, 181.62 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84689, chestimgbbiou 0.91456, chestimgbbmae 0.02886, 20.56 secs\n",
      "Adjusting learning rate of group 0 to 3.6715e-05.\n",
      "\u001b[1m---- Epoch 11/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 0.01237, chestimgbbmf1 0.85864, chestimgbb_loss 0.02181, chestimgbbiou 0.91664, chestimgbbmae 0.02816, 181.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86137, chestimgbbiou 0.91778, chestimgbbmae 0.02777, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 3.3123e-05.\n",
      "\u001b[1m---- Epoch 12/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.03719, chestimgbbmf1 0.86254, chestimgbb_loss 0.02243, chestimgbbiou 0.91784, chestimgbbmae 0.02773, 180.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86173, chestimgbbiou 0.91823, chestimgbbmae 0.02754, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 2.9883e-05.\n",
      "\u001b[1m---- Epoch 13/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.03469, chestimgbbmf1 0.86831, chestimgbb_loss 0.02409, chestimgbbiou 0.91931, chestimgbbmae 0.02722, 180.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86373, chestimgbbiou 0.91815, chestimgbbmae 0.02771, 20.58 secs\n",
      "Adjusting learning rate of group 0 to 2.6959e-05.\n",
      "\u001b[1m---- Epoch 14/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.04003, chestimgbbmf1 0.87292, chestimgbb_loss 0.02353, chestimgbbiou 0.91981, chestimgbbmae 0.02706, 180.50 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.86630, chestimgbbiou 0.91868, chestimgbbmae 0.02747, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 2.4322e-05.\n",
      "\u001b[1m---- Epoch 15/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.03076, chestimgbbmf1 0.87341, chestimgbb_loss 0.02318, chestimgbbiou 0.92016, chestimgbbmae 0.02696, 180.16 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87455, chestimgbbiou 0.92026, chestimgbbmae 0.02694, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 2.1943e-05.\n",
      "\u001b[1m---- Epoch 16/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.03393, chestimgbbmf1 0.88148, chestimgbb_loss 0.02151, chestimgbbiou 0.92201, chestimgbbmae 0.02631, 180.86 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88107, chestimgbbiou 0.92201, chestimgbbmae 0.02634, 20.65 secs\n",
      "Adjusting learning rate of group 0 to 1.9796e-05.\n",
      "\u001b[1m---- Epoch 17/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.05186, chestimgbbmf1 0.88315, chestimgbb_loss 0.02111, chestimgbbiou 0.92243, chestimgbbmae 0.02616, 181.01 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87922, chestimgbbiou 0.92154, chestimgbbmae 0.02653, 20.53 secs\n",
      "Adjusting learning rate of group 0 to 1.7860e-05.\n",
      "\u001b[1m---- Epoch 18/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.00767, chestimgbbmf1 0.88367, chestimgbb_loss 0.02236, chestimgbbiou 0.92250, chestimgbbmae 0.02615, 181.84 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.87886, chestimgbbiou 0.92130, chestimgbbmae 0.02664, 20.71 secs\n",
      "Adjusting learning rate of group 0 to 1.6112e-05.\n",
      "\u001b[1m---- Epoch 19/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.00393, chestimgbbmf1 0.88823, chestimgbb_loss 0.02046, chestimgbbiou 0.92369, chestimgbbmae 0.02571, 181.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88693, chestimgbbiou 0.92346, chestimgbbmae 0.02588, 20.54 secs\n",
      "Adjusting learning rate of group 0 to 1.3114e-05.\n",
      "\u001b[1m---- Epoch 21/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.02859, chestimgbbmf1 0.88906, chestimgbb_loss 0.02052, chestimgbbiou 0.92392, chestimgbbmae 0.02562, 181.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88682, chestimgbbiou 0.92392, chestimgbbmae 0.02567, 20.89 secs\n",
      "Adjusting learning rate of group 0 to 1.1831e-05.\n",
      "\u001b[1m---- Epoch 22/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.02962, chestimgbbmf1 0.88885, chestimgbb_loss 0.02056, chestimgbbiou 0.92399, chestimgbbmae 0.02564, 181.06 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88083, chestimgbbiou 0.92185, chestimgbbmae 0.02646, 20.43 secs\n",
      "Adjusting learning rate of group 0 to 1.0674e-05.\n",
      "\u001b[1m---- Epoch 23/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.04605, chestimgbbmf1 0.88894, chestimgbb_loss 0.02128, chestimgbbiou 0.92385, chestimgbbmae 0.02568, 181.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88255, chestimgbbiou 0.92279, chestimgbbmae 0.02608, 20.73 secs\n",
      "Adjusting learning rate of group 0 to 9.6297e-06.\n",
      "\u001b[1m---- Epoch 24/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.04185, chestimgbbmf1 0.88974, chestimgbb_loss 0.02301, chestimgbbiou 0.92420, chestimgbbmae 0.02555, 181.41 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88807, chestimgbbiou 0.92401, chestimgbbmae 0.02566, 20.48 secs\n",
      "Adjusting learning rate of group 0 to 8.6877e-06.\n",
      "\u001b[1m---- Epoch 25/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.01862, chestimgbbmf1 0.89379, chestimgbb_loss 0.02081, chestimgbbiou 0.92532, chestimgbbmae 0.02514, 180.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89034, chestimgbbiou 0.92418, chestimgbbmae 0.02564, 20.63 secs\n",
      "Adjusting learning rate of group 0 to 7.8378e-06.\n",
      "\u001b[1m---- Epoch 26/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.00684, chestimgbbmf1 0.89360, chestimgbb_loss 0.01965, chestimgbbiou 0.92530, chestimgbbmae 0.02516, 181.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88923, chestimgbbiou 0.92416, chestimgbbmae 0.02563, 20.62 secs\n",
      "Adjusting learning rate of group 0 to 7.0711e-06.\n",
      "\u001b[1m---- Epoch 27/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.02906, chestimgbbmf1 0.89228, chestimgbb_loss 0.02092, chestimgbbiou 0.92489, chestimgbbmae 0.02530, 180.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89030, chestimgbbiou 0.92450, chestimgbbmae 0.02549, 20.62 secs\n",
      "Adjusting learning rate of group 0 to 6.3793e-06.\n",
      "\u001b[1m---- Epoch 28/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.04265, chestimgbbmf1 0.89651, chestimgbb_loss 0.02157, chestimgbbiou 0.92576, chestimgbbmae 0.02501, 181.65 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88945, chestimgbbiou 0.92421, chestimgbbmae 0.02563, 20.53 secs\n",
      "Adjusting learning rate of group 0 to 5.7553e-06.\n",
      "\u001b[1m---- Epoch 29/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.01668, chestimgbbmf1 0.89511, chestimgbb_loss 0.02142, chestimgbbiou 0.92549, chestimgbbmae 0.02515, 184.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.88940, chestimgbbiou 0.92412, chestimgbbmae 0.02565, 20.54 secs\n",
      "Adjusting learning rate of group 0 to 5.1923e-06.\n",
      "\u001b[1m---- Epoch 30/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01321, chestimgbbmf1 0.89411, chestimgbb_loss 0.02139, chestimgbbiou 0.92543, chestimgbbmae 0.02512, 184.25 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89149, chestimgbbiou 0.92477, chestimgbbmae 0.02540, 21.09 secs\n",
      "Adjusting learning rate of group 0 to 4.6843e-06.\n",
      "\u001b[1m---- Epoch 31/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00937, chestimgbbmf1 0.89492, chestimgbb_loss 0.02103, chestimgbbiou 0.92548, chestimgbbmae 0.02512, 184.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89175, chestimgbbiou 0.92514, chestimgbbmae 0.02527, 20.93 secs\n",
      "Adjusting learning rate of group 0 to 4.2261e-06.\n",
      "\u001b[1m---- Epoch 32/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00555, chestimgbbmf1 0.89474, chestimgbb_loss 0.02020, chestimgbbiou 0.92543, chestimgbbmae 0.02512, 185.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89036, chestimgbbiou 0.92466, chestimgbbmae 0.02544, 21.27 secs\n",
      "Adjusting learning rate of group 0 to 3.8126e-06.\n",
      "\u001b[1m---- Epoch 33/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01780, chestimgbbmf1 0.89462, chestimgbb_loss 0.02134, chestimgbbiou 0.92555, chestimgbbmae 0.02507, 185.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89078, chestimgbbiou 0.92455, chestimgbbmae 0.02549, 20.83 secs\n",
      "Adjusting learning rate of group 0 to 3.4397e-06.\n",
      "\u001b[1m---- Epoch 34/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.03734, chestimgbbmf1 0.89382, chestimgbb_loss 0.02175, chestimgbbiou 0.92514, chestimgbbmae 0.02527, 186.52 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89242, chestimgbbiou 0.92538, chestimgbbmae 0.02517, 21.18 secs\n",
      "Adjusting learning rate of group 0 to 3.1032e-06.\n",
      "\u001b[1m---- Epoch 35/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00394, chestimgbbmf1 0.89780, chestimgbb_loss 0.01968, chestimgbbiou 0.92627, chestimgbbmae 0.02483, 186.02 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89250, chestimgbbiou 0.92527, chestimgbbmae 0.02523, 21.28 secs\n",
      "Adjusting learning rate of group 0 to 2.7996e-06.\n",
      "\u001b[1m---- Epoch 36/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00889, chestimgbbmf1 0.89658, chestimgbb_loss 0.02073, chestimgbbiou 0.92610, chestimgbbmae 0.02487, 187.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89100, chestimgbbiou 0.92489, chestimgbbmae 0.02537, 21.41 secs\n",
      "Adjusting learning rate of group 0 to 2.5257e-06.\n",
      "\u001b[1m---- Epoch 37/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01328, chestimgbbmf1 0.89659, chestimgbb_loss 0.02101, chestimgbbiou 0.92619, chestimgbbmae 0.02484, 186.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89271, chestimgbbiou 0.92538, chestimgbbmae 0.02519, 20.98 secs\n",
      "Adjusting learning rate of group 0 to 2.2787e-06.\n",
      "\u001b[1m---- Epoch 38/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01766, chestimgbbmf1 0.89633, chestimgbb_loss 0.02160, chestimgbbiou 0.92590, chestimgbbmae 0.02500, 186.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89252, chestimgbbiou 0.92535, chestimgbbmae 0.02520, 21.30 secs\n",
      "Adjusting learning rate of group 0 to 2.0557e-06.\n",
      "\u001b[1m---- Epoch 39/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01074, chestimgbbmf1 0.89808, chestimgbb_loss 0.02104, chestimgbbiou 0.92645, chestimgbbmae 0.02475, 186.35 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89152, chestimgbbiou 0.92513, chestimgbbmae 0.02528, 21.33 secs\n",
      "Adjusting learning rate of group 0 to 1.8546e-06.\n",
      "\u001b[1m---- Epoch 40/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.03018, chestimgbbmf1 0.89796, chestimgbb_loss 0.02106, chestimgbbiou 0.92657, chestimgbbmae 0.02469, 187.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89209, chestimgbbiou 0.92528, chestimgbbmae 0.02525, 21.16 secs\n",
      "Adjusting learning rate of group 0 to 1.6732e-06.\n",
      "\u001b[1m---- Epoch 41/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02761, chestimgbbmf1 0.89743, chestimgbb_loss 0.02011, chestimgbbiou 0.92634, chestimgbbmae 0.02482, 187.32 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89235, chestimgbbiou 0.92537, chestimgbbmae 0.02521, 21.09 secs\n",
      "Adjusting learning rate of group 0 to 1.5095e-06.\n",
      "\u001b[1m---- Epoch 42/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.05741, chestimgbbmf1 0.89719, chestimgbb_loss 0.02096, chestimgbbiou 0.92627, chestimgbbmae 0.02481, 187.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89177, chestimgbbiou 0.92514, chestimgbbmae 0.02529, 22.27 secs\n",
      "Adjusting learning rate of group 0 to 1.3618e-06.\n",
      "\u001b[1m---- Epoch 43/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.04075, chestimgbbmf1 0.89505, chestimgbb_loss 0.02185, chestimgbbiou 0.92576, chestimgbbmae 0.02502, 186.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89169, chestimgbbiou 0.92511, chestimgbbmae 0.02529, 22.19 secs\n",
      "Adjusting learning rate of group 0 to 1.2286e-06.\n",
      "\u001b[1m---- Epoch 44/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.03053, chestimgbbmf1 0.89891, chestimgbb_loss 0.01936, chestimgbbiou 0.92658, chestimgbbmae 0.02472, 186.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89358, chestimgbbiou 0.92563, chestimgbbmae 0.02511, 21.35 secs\n",
      "Adjusting learning rate of group 0 to 1.1084e-06.\n",
      "\u001b[1m---- Epoch 45/45\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.04059, chestimgbbmf1 0.89721, chestimgbb_loss 0.02167, chestimgbbiou 0.92609, chestimgbbmae 0.02492, 186.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89273, chestimgbbiou 0.92545, chestimgbbmae 0.02518, 21.29 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230223_234613_mim_dn121\" \\\n",
    "        --epochs 45 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 40 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,5e-5,38,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 512 512 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 256 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
