{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 600\n",
      "   batch_size: 20\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: t5\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240116_111115_multitask(s2f+f2m+f2c+s2co+s2cal+nli+mlm)_Seq2Seq(t5-small)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: multitask\n",
      "   experiment_name: nli+mlm\n",
      "   multitask_name_list: ['nli', 'mlm', 'sentence2facts']\n",
      "   task2weight: {'nli': 2.0, 'mlm': 1.0, 'sentence2facts': 0.0}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl']\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl']\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl']\n",
      "   integrated_nli_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\n",
      "   use_sentence2facts_for_nli: True\n",
      "   use_anli: True\n",
      "   use_multinli: True\n",
      "   use_snli: True\n",
      "   use_report_nli: True\n",
      "   only_validate_nli: True\n",
      "   nli1_only_on_train: True\n",
      "   nli1_only_on_val: True\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: t5-small\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9891 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mB\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mbilateral\u001b[0m\n",
      "\u001b[1m\u001b[35mboth sides\u001b[0m\n",
      "\u001b[1m\u001b[35mboth\u001b[0m\n",
      "\u001b[1m\u001b[35mon both sides\u001b[0m\n",
      "\u001b[1m\u001b[35msymmetrical\u001b[0m\n",
      "\u001b[1m\u001b[35mequally on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mpresent on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mseen on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35moccurring on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mappearing on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mfound on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mseen bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mobserved bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mdetected bilaterally\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9890 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilus\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the hilum on the left side\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 8511 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary vasculature\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral lung vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary blood vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mlung periphery vasculature\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature of the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels in the outer regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular network in the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary circulation\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels supplying the outer areas of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature in the peripheral regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular system in the outer regions of the lung\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "\u001b[1mLoaded 1864 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35ma\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mone\u001b[0m\n",
      "\u001b[1m\u001b[35msingle\u001b[0m\n",
      "\u001b[1m\u001b[35msole\u001b[0m\n",
      "\u001b[1m\u001b[35monly\u001b[0m\n",
      "\u001b[1m\u001b[35mindividual\u001b[0m\n",
      "\u001b[1m\u001b[35mlone\u001b[0m\n",
      "\u001b[1m\u001b[35msolitary\u001b[0m\n",
      "\u001b[1m\u001b[35munique\u001b[0m\n",
      "\u001b[1m\u001b[35mdistinct\u001b[0m\n",
      "\u001b[1m\u001b[35msingular\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14993 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14971 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14972 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14965 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 10000 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9999 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9997 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9994 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9996 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome not detected\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome is not observed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant constriction\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of notable narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of substantial narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mlack of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of notable constriction\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19943 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of wheezing\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing detected\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing observed\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing present\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing found\u001b[0m\n",
      "--------\n",
      "\u001b[1mNumber of unique inputs: 190085\u001b[0m\n",
      "\u001b[1mNumber of total paraphrases: 2093173\u001b[0m\n",
      "Number of medical sentences from paraphrases: 2039914\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing sentence2facts dataset\u001b[0m\n",
      "Loaded 9999 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19971 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\n",
      "Loaded 19984 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\n",
      "Loaded 5000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\n",
      "Loaded 14990 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\n",
      "Loaded 14991 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\n",
      "\u001b[1mInput/output example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mS2F: Mild blunting of the left aortopulmonary window is consistent with thymic tissue better assessed on recent CT.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m[\"mild blunting of the left aortopulmonary window\", \"thymic tissue better assessed on recent CT\"]\u001b[0m\n",
      "Number of train examples: 84935\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing nli dataset\u001b[0m\n",
      "----\n",
      "Loading integrated NLI from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl...\n",
      "Number of samples: 169025\n",
      "Number of sources: 7\n",
      "----\n",
      "\u001b[1mLoading sentence2facts input/output pairs for NLI...\u001b[0m\n",
      "Number of entailment samples added: 184483\n",
      "----\n",
      "\u001b[1mLoading general domain datasets...\u001b[0m\n",
      "Loading ANLI...\n",
      "Number of ANLI R1 samples: 18946\n",
      "Number of ANLI R2 samples: 47460\n",
      "Number of ANLI R3 samples: 102859\n",
      "Loading MultiNLI...\n",
      "Number of MultiNLI train samples: 392702\n",
      "Number of MultiNLI dev_matched samples: 10000\n",
      "Number of MultiNLI dev_mismatched samples: 10000\n",
      "Loading SNLI...\n",
      "Number of SNLI train samples: 550152\n",
      "Number of SNLI dev samples: 10000\n",
      "Number of SNLI test samples: 10000\n",
      "----\n",
      "\u001b[1mLoading report NLI datasets...\u001b[0m\n",
      "Loaded 11198 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\n",
      "Loaded 20000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\n",
      "----\n",
      "\u001b[1mBuilding train NLI dataset...\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: contradiction -> 79430 (4312.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiac, mediastinal and hilar contours appear significantly changed. #H: The cardiac, mediastinal and hilar contours appear not significantly changed.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: contradiction -> 10732 (2400.52)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Stable tiny right pneumothorax. #H: There may be tiny residual left pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: contradiction -> 4170 (1739.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is new small right pleural effusion. #H: Slight decrease in the right basal pleural effusion.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: contradiction -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Group beta strep status unknown. #H:  the group b strep status is known\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: contradiction -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Her EKG showed a ventricularly paced rhythm with no significant changes from prior tracings. #H:  Patient has normal cardiac findings\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: contradiction -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Per her son, Mrs. #H:  The patient does not have a son. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: contradiction -> 106 (304.54)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are probable bilateral pleural effusions, right greater left along with right-sided atelectasis. #H: No pleural abnormality is seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: anli | Label: contradiction -> 44089 (3672.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Therefore I am very pleased to indicate to the member that within the next couple of weeks we will make available a service charge calculator free of charge on our website, Strategis, that will enable consumers to compare the charges levied against them by a variety of financial institutions and see in a very transparent and rapid way where the best services charges can be obtained. #H: The service charge calculator will cost five dollars a month. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: contradiction -> 137356 (4971.81)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: absolutely you know it's like it's i i i i don't really quite understand the idea that people think that i mean i i'm all for registration in the sense that uh a a a lawful person can go down and get a gun and and maybe you shouldn't be given one the day that you go down they should be able to do a check i think possibly and #H: I am fully against gun registration requirements.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: snli | Label: contradiction -> 189702 (5390.10)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A little girl running at on the shore of a beach. #H: A girl is on Mars.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: contradiction -> 5426 (1909.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: interval placement of a right apical chest tube. previously noted small right apical pneumothorax not clearly visualized. persistent pneumomediastinum. extensive amount of subcutaneous emphysema within the chest wall bilaterally. subcutaneous emphysema extending into the neck. curvilinear lucency in the right upper quadrant of the abdomen. retroperitoneal subcutaneous emphysema. unchanged cardiac contours. unchanged mediastinal contours. pulmonary vasculature not engorged. hyperinflated lungs. minimal patchy right basilar opacity. small contusion in the right basilar region. right posterior tenth rib fracture. previously noted tiny right apical pneumothorax not visualized on the current radiograph. extensive amounts of pneumomediastinum #H: small effusion in the right lower lung\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: entailment -> 13185 (2563.82)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Persistent left base opacification is likely atelectasis, although superimposed pneumonia cannot be fully excluded. #H: The patient's left lung base shows signs of possible atelectasis.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: entailment -> 5445 (1911.57)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Prior lines and tubes are unchanged position. #H: The lines and tubes are unchanged.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: entailment -> 1770 (1256.05)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No acute osseous abnormalities present. #H: There is no visualized acute osseous abnormality.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: entailment -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Febrile to 100.3 two days prior to admission that resolved without intervention. #H:  the patient has a history of a mild fever\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: entailment -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Mother was treated with magnesium sulfate. #H:  The mother was given magnesium sulfate during pregnancy\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: entailment -> 473 (701.58)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She subsequently had 10 other BMs with marroon-colored stools and bright red blood mixed in. #H:  She had bloody stools\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: entailment -> 93 (279.62)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is no pneumothorax. #H: Specifically, no evidence of appreciable pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSource: s2f | Label: entailment -> 184483 (5353.06)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: 8:19 AM Right lung basilar opacity is likely atelectasis, although pneumonia is not excluded. #H: pneumonia not excluded\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: anli | Label: entailment -> 54251 (3890.16)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: How to make profitable crafts<br>Wrap candles to make them fancy. Starting with tall, plain pillar candles, it's easy to end up with beautiful and desirable home decorating items that are likely to sell well. Choose unscented white candles for the most versatility, or make scent and color substitutions as you see fit depending on the items you intend to wrap the candles with. #H: The title of this article is \"How to make profitable crafts\".\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: entailment -> 137841 (4976.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: I will put down my little case until I need it.\" He did so, on the round table by the window, but it was an illadvised proceeding; for, the top of it being loose, it tilted up, and precipitated the despatch-case on the floor.  #H: The top of the case was loose and fell on the floor.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: snli | Label: entailment -> 190113 (5392.98)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A little Asian girl in a floral dress is standing in the doorway and holding a teddy bear and a snack. #H: a girl is standing\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: entailment -> 18929 (2868.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: frontal view of the chest. lateral view of the chest. low lung volumes. increased interstitial markings at the bases. interstitial markings compatible with patient's known IPF. no significant change in appearance. no definite new consolidation. cardiomediastinal silhouette within normal limits. no acute osseous abnormality. chronic changes compatible with patient's known IPF. no definite superimposed acute cardiopulmonary process. difficult to discern subtle change #H: no gross change\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: neutral -> 19123 (2877.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Linear opacities at the lung bases bilaterally most likely due to atelectasis. #H: There are no signs of pneumonia in the patient's chest X-ray.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: neutral -> 16675 (2758.96)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No focal consolidation is seen and there is no pneumothorax. #H: No acute osseous abnormalities are definitely noted.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: neutral -> 3968 (1708.29)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Heart is enlarged, improved. #H: Right lung is well expanded and is clear.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: neutral -> 3743 (1672.44)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: PAST MEDICAL HISTORY:  The patient's past medical history is significant for ulcerative colitis and bleeding and diarrhea. #H:  Patient has blood in their stool\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: neutral -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Status post tonsillectomy. #H:  History of recurrent acute tonsillitis\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: neutral -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: EKG with sinus tachycardia, no acute ST/TWI. #H:  patient is hypotensive\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: neutral -> 281 (538.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Small area of parenchymal sparing in the left upper lobe is unchanged. #H: No newly appeared parenchymal opacities.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: anli | Label: neutral -> 70925 (4184.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: E.T., I Love You and Other Extra-Terrestrial Songs for Children is an album by the group the Starlight Children's Chorus, released in 1983 under Kid Stuff Records. It featured a song \"E.T., I Love You\" by Buckner & Garcia, which was originally written to accompany the major motion picture \"E.T. the Extra-Terrestrial\". #H: E.T., I Love You and Other Extra-Terrestrial Songs for Children is an album byt a christian rock group.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: neutral -> 137152 (4969.93)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: I wondered how I could have been so unobservant as to overlook this.  #H: I wondered how I over looked this when others didn't.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: snli | Label: neutral -> 189218 (5386.70)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Two football teams are in the middle of a play as white jerseys and the opposing green jerseys are in all positions of motion while scrambling for the football. #H: huge people in jerseys\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: neutral -> 6843 (2068.00)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: ET tube removed. bilateral chest tubes removed. right IJ line tip in the SVC. Sternal wires seen. mediastinal clips seen. improved region of the lungs. improvement in the vascular redistribution. focal areas of atelectasis in the lower lobes. focal areas of atelectasis similar to prior. small bilateral pleural effusions #H: prior CT likely due to vasculature\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "----\n",
      "Number of RadNLI test samples: 480\n",
      "Number of MS_CXR_T samples: 361\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No pleural effusion or pneumothorax is seen. #H: The right atelectasis and pleural effusion has increased.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Small left apical pneumothorax is unchanged. #H: Small left apical pneumothorax not appreciably changed since ___.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: stable moderate - sized loculated left pleural effusion. #H: new moderate - sized loculated left pleural effusion.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: minimal increase in extent of a pre - existing right pleural effusion. #H: minimal improvement in extent of a pre - existing right pleural effusion.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiomediastinal and hilar contours are unchanged. #H: The cardiomediastinal and hilar contours are normal.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "----\n",
      "\u001b[1mBuilding val NLI dataset...\u001b[0m\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing mlm dataset\u001b[0m\n",
      "Number of general sentences: 1377099\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 1377099\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 1377099/1377099 [00:06<00:00, 201063.50it/s]\n",
      "\tlen(valid_tokens): 21522\n",
      "100%|██████████████████████████████| 1377099/1377099 [00:15<00:00, 89697.19it/s]\n",
      "Number of sentences: 1348333\n",
      "Number of bins: 7\n",
      "Bin size: 958219, weight: 7845.006940358202\n",
      "Bin size: 219530, weight: 5586.745498624757\n",
      "Bin size: 110971, weight: 4707.694773844805\n",
      "Bin size: 46036, weight: 3717.013976819967\n",
      "Bin size: 8332, weight: 2209.4180153128023\n",
      "Bin size: 4974, weight: 1851.8906668241702\n",
      "Bin size: 271, weight: 527.9351334797618\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Many sad women [tok1] on a brown dance [tok2]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] dancing [tok2] floor\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The woman is running a [tok1] .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] race\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: [tok1] [tok2] and female pairs of dancers are on the stage at the ballet , with other ballerinas in the background .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] Three [tok2] male\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The boy is not standing [tok1] .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] straight\u001b[0m\n",
      "Number of medical sentences: 2346041\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 2346041\n",
      "Tokenizing sentences...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 2346041/2346041 [00:08<00:00, 275393.93it/s]\n",
      "\tlen(valid_tokens): 8144\n",
      "100%|█████████████████████████████| 2346041/2346041 [00:19<00:00, 118805.18it/s]\n",
      "Number of sentences: 2319907\n",
      "Number of bins: 10\n",
      "Bin size: 1170496, weight: 8191.941208207072\n",
      "Bin size: 429802, weight: 6553.178868066303\n",
      "Bin size: 387846, weight: 6398.727136819865\n",
      "Bin size: 235678, weight: 5684.026200409652\n",
      "Bin size: 78079, weight: 4293.112851395785\n",
      "Bin size: 14414, weight: 2636.7559731722013\n",
      "Bin size: 3064, weight: 1553.3193432179862\n",
      "Bin size: 240, weight: 494.33025182624635\n",
      "Bin size: 162, weight: 395.4226609416602\n",
      "Bin size: 126, weight: 339.6709772657412\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The observed mass is congruent with a past [tok1] of malignancy\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] diagnosis\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The right hemidiaphragm is uninjured and does not display any signs of [tok1] air\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] free\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The knee [tok1] show no significant findings\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] bones\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: subtle opacity at the lateral right [tok1] base\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] lung\u001b[0m\n",
      "----------------------------------------\n",
      "Number of train datasets: 3\n",
      "Number of val datasets: 1\n",
      "\u001b[93m\u001b[1mWARNING: CompositeInfiniteDataset(): Removed 1 datasets with zero weight\u001b[0m\n",
      "----------------------------------------\n",
      "Examples of val datasets:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: there is interval improvement of the right lower lobe atelectasis. #H: there is interval worsening of the right lower lobe atelectasis.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Atherosclerotic calcifications are noted at the aortic arch. #H: Mild aortic calcification noted.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The lungs are hyperinflated but clear without consolidation, effusion, or pneumothorax. #H: No large effusion or pneumothorax is seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is no focal consolidation or pleural effusion. #H: There is no pleural effusion or pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "seq2seq_trainer.name =  multitask(nli+mlm)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_122528_multitask(nli+mlm)_Seq2Seq(t5-small)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_122528_multitask(nli+mlm)_Seq2Seq(t5-small)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_200_exact_match+s2s_loss=0.8991.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240116_111115_multitask(s2f+f2m+f2c+s2co+s2cal+nli+mlm)_Seq2Seq(t5-small)/checkpoint_200_exact_match+s2s_loss=0.8991.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_122528_multitask(nli+mlm)_Seq2Seq(t5-small)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.14714, s2s_loss 1.95014, 61.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 3.23816, exact_match 0.00000, 1.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_exact_match+s2s_loss=0.1401.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.05289, s2s_loss 1.63241, 59.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.96689, exact_match 0.21522, 1.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_exact_match+s2s_loss=0.3636.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
      "loss 1.48565, s2s_loss 0.71453, 60.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13543, exact_match 0.85731, 1.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_exact_match+s2s_loss=0.8404.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.46496, s2s_loss 0.43877, 60.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11825, exact_match 0.88466, 1.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_exact_match+s2s_loss=0.8700.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "loss 0.40741, s2s_loss 0.43445, 59.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11763, exact_match 0.88942, 1.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_exact_match+s2s_loss=0.8726.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.36623, s2s_loss 0.42658, 59.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11362, exact_match 0.89417, 1.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_exact_match+s2s_loss=0.8766.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.65390, s2s_loss 0.43017, 59.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11186, exact_match 0.89417, 1.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_exact_match+s2s_loss=0.8770.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.37918, s2s_loss 0.42341, 60.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11126, exact_match 0.89298, 1.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_exact_match+s2s_loss=0.8770.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.42303, s2s_loss 0.42283, 60.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11177, exact_match 0.89536, 1.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_exact_match+s2s_loss=0.8780.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.37412, s2s_loss 0.42340, 60.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11188, exact_match 0.89536, 1.25 secs\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.34643, s2s_loss 0.41670, 54.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11198, exact_match 0.89536, 1.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_exact_match+s2s_loss=0.8782.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.32563, s2s_loss 0.42009, 56.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11198, exact_match 0.89536, 1.25 secs\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.61373, s2s_loss 0.42040, 59.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10913, exact_match 0.88942, 1.24 secs\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31776, s2s_loss 0.42050, 60.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11155, exact_match 0.89417, 1.26 secs\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.37883, s2s_loss 0.41481, 60.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11347, exact_match 0.88942, 1.24 secs\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.34922, s2s_loss 0.42084, 59.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11437, exact_match 0.88585, 1.28 secs\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.30899, s2s_loss 0.41915, 60.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11387, exact_match 0.88823, 1.25 secs\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21917, s2s_loss 0.41710, 60.25 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.11427, exact_match 0.88704, 1.25 secs\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.31867, s2s_loss 0.41317, 59.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11412, exact_match 0.88823, 1.24 secs\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.46108, s2s_loss 0.42150, 59.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11393, exact_match 0.88823, 1.24 secs\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 12200\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 555, in <module>\n",
      "    args = parsed_args_to_dict(args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 466, in train_from_scratch\n",
      "    training_kwargs = dict(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 315, in train_model\n",
      "    # Start training\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/seq2seq.py\", line 97, in step_fn_wrapper\n",
      "    output = step_fn(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/seq2seq.py\", line 82, in step_fn\n",
      "    gradient_accumulator.step(batch_loss, model)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 29, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 488, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240116_111115_multitask(s2f+f2m+f2c+s2co+s2cal+nli+mlm)_Seq2Seq(t5-small)\" \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--batch_size 20 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"multitask\" \\\n",
    "--experiment_name \"nli+mlm\" \\\n",
    "--multitask_name_list \\\n",
    "\"nli\" \\\n",
    "\"mlm\" \\\n",
    "\"sentence2facts\" \\\n",
    "--task2weight '{\"nli\": 2.0, \"mlm\": 1.0, \"sentence2facts\": 0.0}' \\\n",
    "--sentence_to_facts_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\"\\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\" \\\n",
    "--integrated_nli_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\" \\\n",
    "--use_sentence2facts_for_nli \\\n",
    "--use_anli \\\n",
    "--use_multinli \\\n",
    "--use_snli \\\n",
    "--use_report_nli \\\n",
    "--report_nli_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\" \\\n",
    "--paraphrased_inputs_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\" \\\n",
    "--only_validate_nli \\\n",
    "--nli1_only_on_train \\\n",
    "--nli1_only_on_val \\\n",
    "--seq2seq_model_name \"t5\" \\\n",
    "--t5_model_name \"t5-small\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 600\n",
      "   batch_size: 20\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: t5\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_122528_multitask(nli+mlm)_Seq2Seq(t5-small)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: multitask\n",
      "   experiment_name: nli+mlm\n",
      "   multitask_name_list: ['nli', 'mlm', 'sentence2facts']\n",
      "   task2weight: {'nli': 2.0, 'mlm': 1.0, 'sentence2facts': 0.0}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl']\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl']\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl']\n",
      "   integrated_nli_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\n",
      "   integrated_report_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "   use_sentence2facts_for_nli: True\n",
      "   use_anli: True\n",
      "   use_multinli: True\n",
      "   use_snli: True\n",
      "   use_report_nli: True\n",
      "   use_fact_based_reports_in_mlm: True\n",
      "   only_validate_nli: True\n",
      "   nli1_only_on_train: True\n",
      "   nli1_only_on_val: True\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: t5-small\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9891 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mB\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mbilateral\u001b[0m\n",
      "\u001b[1m\u001b[35mboth sides\u001b[0m\n",
      "\u001b[1m\u001b[35mboth\u001b[0m\n",
      "\u001b[1m\u001b[35mon both sides\u001b[0m\n",
      "\u001b[1m\u001b[35msymmetrical\u001b[0m\n",
      "\u001b[1m\u001b[35mequally on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mpresent on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mseen on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35moccurring on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mappearing on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mfound on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mseen bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mobserved bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mdetected bilaterally\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9890 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilus\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the hilum on the left side\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 8511 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary vasculature\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral lung vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary blood vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mlung periphery vasculature\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature of the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels in the outer regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular network in the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary circulation\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels supplying the outer areas of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature in the peripheral regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular system in the outer regions of the lung\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "\u001b[1mLoaded 1864 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35ma\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mone\u001b[0m\n",
      "\u001b[1m\u001b[35msingle\u001b[0m\n",
      "\u001b[1m\u001b[35msole\u001b[0m\n",
      "\u001b[1m\u001b[35monly\u001b[0m\n",
      "\u001b[1m\u001b[35mindividual\u001b[0m\n",
      "\u001b[1m\u001b[35mlone\u001b[0m\n",
      "\u001b[1m\u001b[35msolitary\u001b[0m\n",
      "\u001b[1m\u001b[35munique\u001b[0m\n",
      "\u001b[1m\u001b[35mdistinct\u001b[0m\n",
      "\u001b[1m\u001b[35msingular\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14993 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14971 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14972 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14965 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 10000 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9999 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9997 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9994 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9996 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome not detected\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome is not observed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant constriction\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of notable narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of substantial narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mlack of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of notable constriction\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19943 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of wheezing\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing detected\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing observed\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing present\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing found\u001b[0m\n",
      "--------\n",
      "\u001b[1mNumber of unique inputs: 190085\u001b[0m\n",
      "\u001b[1mNumber of total paraphrases: 2093173\u001b[0m\n",
      "Number of medical sentences from paraphrases: 2039914\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing sentence2facts dataset\u001b[0m\n",
      "Loaded 9999 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19971 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\n",
      "Loaded 19984 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\n",
      "Loaded 5000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\n",
      "Loaded 14990 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\n",
      "Loaded 14991 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\n",
      "\u001b[1mInput/output example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mS2F: ET tube is in standard placement at the thoracic inlet.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m[\"ET tube in standard placement at the thoracic inlet\"]\u001b[0m\n",
      "Number of train examples: 84935\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing nli dataset\u001b[0m\n",
      "----\n",
      "Loading integrated NLI from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl...\n",
      "Number of samples: 169025\n",
      "Number of sources: 7\n",
      "----\n",
      "\u001b[1mLoading sentence2facts input/output pairs for NLI...\u001b[0m\n",
      "Number of entailment samples added: 184483\n",
      "----\n",
      "\u001b[1mLoading general domain datasets...\u001b[0m\n",
      "Loading ANLI...\n",
      "Number of ANLI R1 samples: 18946\n",
      "Number of ANLI R2 samples: 47460\n",
      "Number of ANLI R3 samples: 102859\n",
      "Loading MultiNLI...\n",
      "Number of MultiNLI train samples: 392702\n",
      "Number of MultiNLI dev_matched samples: 10000\n",
      "Number of MultiNLI dev_mismatched samples: 10000\n",
      "Loading SNLI...\n",
      "Number of SNLI train samples: 550152\n",
      "Number of SNLI dev samples: 10000\n",
      "Number of SNLI test samples: 10000\n",
      "----\n",
      "\u001b[1mLoading report NLI datasets...\u001b[0m\n",
      "Loaded 11198 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\n",
      "Loaded 20000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\n",
      "----\n",
      "\u001b[1mBuilding train NLI dataset...\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: contradiction -> 79430 (4312.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Extensive bronchiectasis is not present again. #H: Extensive bronchiectasis is again seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: contradiction -> 10732 (2400.52)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Minimal amount of right pleural effusion is suspected. #H: There is no appreciable pleural effusion, pneumothorax, or pulmonary edema.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: contradiction -> 4170 (1739.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There has been improvement of the consolidation in both lung bases. #H: Mild consolidation at both lung bases has developed since .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: contradiction -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She has trouble sleeping usually, and when she awoke at 4am, she noted substernal pressure in the lower chest at about [**5-9**]. #H:  The patient slept through the night. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: contradiction -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: 56 yo F with severe asthma presents with difficutly breathing and a prominent wheeze. #H:  Pulmonary exam is normal \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: contradiction -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: - Glioblastoma multiforme (WHO IV) s/p resection ([**3206-7-20**]) and chemoradiation therapy (completed [**3206-9-28**]). - Complex partial seizures - Migraines - Hypertension #H:  Patient has not had surgery\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: contradiction -> 106 (304.54)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is a moderate to large right pleural effusion with overlying atelectasis, underlying consolidation is difficult to exclude. #H: No focal consolidation, pleural effusion or pneumothorax is seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: anli | Label: contradiction -> 44089 (3672.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: They call on parliament to amend the Criminal Code to ensure the right of all Canadians to die with dignity by allowing people with terminal, irreversible or debilitating illness the right to the assistance of a physician in ending their lives at a time of their choice, subject to six strict safeguards to prevent abuse and to ensure that the decision is free, informed, competent and voluntary. #H: the people pushing for the changes want to kill sick people\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: contradiction -> 137356 (4971.81)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: and and that that you know and you i think that's one of those things when we get to Heaven we're going to ask God #H: Science can definitely explain this.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: snli | Label: contradiction -> 189702 (5390.10)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A woman in a red hat, red sundress, and gossamer wings is wading in a fountain next to parked cars. #H: A woman is walking in the surf at the beach.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: contradiction -> 5426 (1909.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: ETT terminates within 3 cm of the carina. neck flexion. Right PICC in the mid SVC. low lung volumes. unchanged linear opacity in the left retrocardiac region. linear opacity representing scarring in the left retrocardiac region. clear lungs. stable heart size. stable mediastinal contours. stable hilar contours. normal pulmonary vasculature. no pleural effusion. no pneumothorax. no evidence of acute cardiopulmonary process #H: persistent streaky atelectasis of the retrocardiac space\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: entailment -> 13185 (2563.82)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A pigtail catheter is projecting over the right upper quadrant. #H: There is a pigtail catheter in the patient's chest.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: entailment -> 5445 (1911.57)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The previously seen right pleural effusion has resolved. #H: Small right pleural effusion has resolved.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: entailment -> 1770 (1256.05)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is a persistent small right apical pneumothorax. #H: Again there is a tiny right apical pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: entailment -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Type 1 diabetes mellitus for the last 33 years. #H:  The patient has a pancreatic dysfunction. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: entailment -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The patient notes that at 11 AM today she developed fevers and chills. #H:  The patient is febrile.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: entailment -> 473 (701.58)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The patient reports that his abdominal pain began at 10 A.M. on the day prior to admission, was constant, and was unable to be reduced. #H:  the patient has abdominal pain\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: entailment -> 93 (279.62)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No pleural effusions or pneumothorax. #H: Previously seen pneumothorax is no longer visualized.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: s2f | Label: entailment -> 184483 (5353.06)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The patient has taken a better inspiration and the bilateral pulmonary opacifications are less prominent and the costophrenic angles sharper. #H: less prominent bilateral pulmonary opacifications\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSource: anli | Label: entailment -> 54251 (3890.16)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: In 1990, there was a vast coalition put together to run Saddam Hussein out of Kuwait. The international community, the international world said this is the right thing to do, but when it came time to authorize the use of force on the Senate floor, my opponent voted against the use of force. #H: The international community wanted to run Saddam Hussein of Kuwait.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: entailment -> 137841 (4976.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Until restoration is complete, the main reason to hit the area is to check out cultural sites, including the museums. #H: Until renovations are finished, there are cultural sites and museums to visit.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: snli | Label: entailment -> 190113 (5392.98)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: a man in white shorts and a black shirt is paragliding on the ocean #H: A man wears white shorts.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: entailment -> 18929 (2868.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: 2 portable views during NG tube insertion. unchanged appearance of the lungs. right-sided PICC line in compressive changes at the bases. mild pulmonary vascular redistribution. mild cardiomegaly. NG tube not visualized in the chest. visualized coiled over the region of the patient's neck. visualized coiled in the oropharynx #H: loop in the neck\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: neutral -> 19123 (2877.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Bibasilar atelectasis have improved. #H: Bibasilar atelectasis is also noted.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: neutral -> 16675 (2758.96)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Currently, the lungs are clear without focal consolidation. #H: Postsurgical changes in the left upper lung are stable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: neutral -> 3968 (1708.29)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is currently no pleural effusion or pneumothorax. #H: There is no pleural effusion, pneumonia, pulmonary edema or pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: neutral -> 3743 (1672.44)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Substance use - 20 year heroin use history, maintained on methadone now. #H:  patient has history of alcohol abuse\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: neutral -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: He stated at that time that he had been unable to move for 2 days [**12-21**] his back pain and was not eating or drinking. #H:  the patient has a history of back trauma\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: neutral -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Currently, she feels fatigued, continues to have some chest discomfort with coughing, not short of breath. . #H:  Patient has normal O2 sats\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: neutral -> 281 (538.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No focal consolidation or superimposed edema is noted. #H: There is no focal consolidation, effusion, or pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: anli | Label: neutral -> 70925 (4184.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: How to deliver oral medication to rabbits<br>Follow the vet's suggestions. Before you give your bunny oral medication, make sure to take her to the vet to get checked out. Give all medication as directed by your veterinarian and for the time period indicated. #H: your bunny needs oral medication\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: neutral -> 137152 (4969.93)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The Church of the Multiplication of the Loaves and Fishes, at Tabgha, marks the site of one of the most famous miracles of all, in which Jesus is said to have fed the 5,000 with five loaves and two fishes (Mark 6:36-45). #H: The church at Tabgha still provides bread to visitors in honor of the miracle.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: snli | Label: neutral -> 189218 (5386.70)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A man is sleeping on a hammock right next to a body of water. #H: A young man and his hammock are the only things on the beach.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: neutral -> 6843 (2068.00)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: left-sided pacemaker device present. leads terminating in right atrium. leads terminating in right ventricle. curvilinear calcification along the left atrial contours. curvilinear calcification along the left ventricular contours. curvilinear calcification likely pericardial in etiology. mildly enlarged heart. accentuated heart size due to low lung volumes. unremarkable mediastinal contours. no pulmonary vascular congestion. patchy opacities within the lung bases. linear opacities within the lung bases. atelectasis within the lung bases. no pleural effusion. no pneumothorax. mild loss of height of a mid/low thoracic vertebral body. mild degenerative changes in the thoracic spine. bibasilar atelectasis. probable pericardial calcifications #H: focal calcification at the first rib costochondral cartilage\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "----\n",
      "Number of RadNLI test samples: 480\n",
      "Number of MS_CXR_T samples: 361\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The lungs are well expanded and clear. #H: The lungs are otherwise clear.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: there is a persistent small right pneumothorax. #H: there is a new small right pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are likely patchy opacities in the lung bases reflective of atelectasis. #H: Widespread pulmonary opacities appear slightly more confluent at the right lung base, though there is slightly improved aeration in the retrocardiac region.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: there is mild pulmonary edema, stable. #H: there is mild pulmonary edema, improved.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: minimal increase in extent of a pre - existing right basal parenchymal opacity. #H: minimal decrease in extent of a pre - existing right basal parenchymal opacity.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "----\n",
      "\u001b[1mBuilding val NLI dataset...\u001b[0m\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing mlm dataset\u001b[0m\n",
      "Number of general sentences: 1377099\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 1377099\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 1377099/1377099 [00:06<00:00, 210065.79it/s]\n",
      "\tlen(valid_tokens): 21522\n",
      "100%|██████████████████████████████| 1377099/1377099 [00:15<00:00, 89402.96it/s]\n",
      "Number of sentences: 1348333\n",
      "Number of bins: 7\n",
      "Bin size: 958219, weight: 7845.006940358202\n",
      "Bin size: 219530, weight: 5586.745498624757\n",
      "Bin size: 110971, weight: 4707.694773844805\n",
      "Bin size: 46036, weight: 3717.013976819967\n",
      "Bin size: 8332, weight: 2209.4180153128023\n",
      "Bin size: 4974, weight: 1851.8906668241702\n",
      "Bin size: 271, weight: 527.9351334797618\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: there are [tok1] friends .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] two\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The market fluctuates quite a [tok1] .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] bit\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: [tok1] Activities and Participant Sports\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] Outdoor\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: There is a [tok1] and a dog .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] man\u001b[0m\n",
      "Loaded 227835 reports from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "Number of medical sentences: 2569945\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 2569945\n",
      "Tokenizing sentences...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 2569945/2569945 [00:12<00:00, 200214.69it/s]\n",
      "\tlen(valid_tokens): 8357\n",
      "100%|██████████████████████████████| 2569945/2569945 [00:25<00:00, 99604.44it/s]\n",
      "Number of sentences: 2544160\n",
      "Number of bins: 10\n",
      "Bin size: 1052298, weight: 8006.1358339205735\n",
      "Bin size: 608709, weight: 7094.925267865978\n",
      "Bin size: 497797, weight: 6778.307960863436\n",
      "Bin size: 277047, weight: 5909.881758997151\n",
      "Bin size: 87878, weight: 4429.701774530018\n",
      "Bin size: 16541, weight: 2752.0981490250133\n",
      "Bin size: 3287, weight: 1594.4598418872663\n",
      "Bin size: 308, weight: 564.9502057601105\n",
      "Bin size: 159, weight: 391.0802349542582\n",
      "Bin size: 136, weight: 356.01835145313845\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Dobbhoff tube inserted 5-7 [tok1]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] cm\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: left lower the right [tok1]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] ventricle\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: opacification resembling the [tok1] of two comparative examinations\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] earlier\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: [tok1] upper and lower lung region\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] right\u001b[0m\n",
      "----------------------------------------\n",
      "Number of train datasets: 3\n",
      "Number of val datasets: 1\n",
      "\u001b[93m\u001b[1mWARNING: CompositeInfiniteDataset(): Removed 1 datasets with zero weight\u001b[0m\n",
      "----------------------------------------\n",
      "Examples of val datasets:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: unchanged tiny left pleural effusion. #H: new tiny left pleural effusion.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is new mild vascular congestion. #H: No overt pulmonary edema is seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The pulmonary vasculature is normal. #H: There is no pulmonary edema.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiomediastinal silhouette, hila contours, and pleural surfaces are normal. #H: The pleural surfaces are unremarkable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "seq2seq_trainer.name =  multitask(nli+mlm)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_125010_multitask(nli+mlm)_Seq2Seq(t5-small)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_125010_multitask(nli+mlm)_Seq2Seq(t5-small)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_11_exact_match+s2s_loss=0.8782.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_122528_multitask(nli+mlm)_Seq2Seq(t5-small)/checkpoint_11_exact_match+s2s_loss=0.8782.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_125010_multitask(nli+mlm)_Seq2Seq(t5-small)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.64595, s2s_loss 0.44663, 61.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11184, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_exact_match+s2s_loss=0.8768.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.42285, s2s_loss 0.43879, 60.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11127, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_exact_match+s2s_loss=0.8784.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.34648, s2s_loss 0.44745, 60.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11130, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.45806, s2s_loss 0.42868, 60.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10437, exact_match 0.89893, 1.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_exact_match+s2s_loss=0.8820.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 0.42465, s2s_loss 0.43487, 60.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10907, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.36596, s2s_loss 0.42804, 60.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11004, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.45308, s2s_loss 0.42940, 60.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10921, exact_match 0.90250, 1.31 secs\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "loss 0.50582, s2s_loss 0.43425, 60.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10684, exact_match 0.90012, 1.31 secs\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.31660, s2s_loss 0.42755, 60.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10830, exact_match 0.90488, 1.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_exact_match+s2s_loss=0.8833.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.43513, s2s_loss 0.43490, 61.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10749, exact_match 0.90250, 1.30 secs\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.28416, s2s_loss 0.41552, 60.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10719, exact_match 0.90131, 1.31 secs\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38636, s2s_loss 0.42413, 60.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10722, exact_match 0.90012, 1.31 secs\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.47637, s2s_loss 0.42587, 59.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11140, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.36394, s2s_loss 0.42826, 60.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11038, exact_match 0.89893, 1.31 secs\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.42485, s2s_loss 0.42461, 60.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10741, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.66770, s2s_loss 0.42410, 60.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11037, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.37256, s2s_loss 0.42818, 60.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10819, exact_match 0.89893, 1.37 secs\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.31838, s2s_loss 0.42572, 60.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10958, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.33610, s2s_loss 0.42184, 60.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10979, exact_match 0.89417, 1.30 secs\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.48172, s2s_loss 0.42365, 60.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10984, exact_match 0.89298, 1.29 secs\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.38753, s2s_loss 0.42605, 59.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11188, exact_match 0.88585, 1.30 secs\n",
      "\u001b[1m---- Epoch 22/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.44111, s2s_loss 0.42495, 60.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11246, exact_match 0.89061, 1.33 secs\n",
      "\u001b[1m---- Epoch 23/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.43180, s2s_loss 0.41770, 60.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10721, exact_match 0.90131, 1.31 secs\n",
      "\u001b[1m---- Epoch 24/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33660, s2s_loss 0.42517, 60.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10861, exact_match 0.90131, 1.31 secs\n",
      "\u001b[1m---- Epoch 25/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.44129, s2s_loss 0.42911, 59.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10853, exact_match 0.90012, 1.33 secs\n",
      "\u001b[1m---- Epoch 26/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.42080, s2s_loss 0.43155, 42.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10852, exact_match 0.90131, 1.32 secs\n",
      "\u001b[1m---- Epoch 27/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.50780, s2s_loss 0.43036, 60.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10842, exact_match 0.90131, 1.30 secs\n",
      "\u001b[1m---- Epoch 28/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.33640, s2s_loss 0.42211, 60.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10860, exact_match 0.90131, 1.31 secs\n",
      "\u001b[1m---- Epoch 29/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.49909, s2s_loss 0.42170, 60.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10410, exact_match 0.90369, 1.30 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_29_exact_match+s2s_loss=0.8846.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 30/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.53033, s2s_loss 0.42679, 60.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10362, exact_match 0.90131, 1.31 secs\n",
      "\u001b[1m---- Epoch 31/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.40902, s2s_loss 0.42218, 60.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10742, exact_match 0.89893, 1.31 secs\n",
      "\u001b[1m---- Epoch 32/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.51611, s2s_loss 0.41582, 51.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10770, exact_match 0.90131, 1.27 secs\n",
      "\u001b[1m---- Epoch 33/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.61630, s2s_loss 0.41919, 60.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10861, exact_match 0.89655, 1.30 secs\n",
      "\u001b[1m---- Epoch 34/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.49435, s2s_loss 0.42306, 60.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10868, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 35/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.49811, s2s_loss 0.42686, 61.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10870, exact_match 0.89298, 1.32 secs\n",
      "\u001b[1m---- Epoch 36/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.60728, s2s_loss 0.42596, 60.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10870, exact_match 0.89298, 1.34 secs\n",
      "\u001b[1m---- Epoch 37/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.44915, s2s_loss 0.42339, 60.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10147, exact_match 0.90250, 1.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_37_exact_match+s2s_loss=0.8849.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 38/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.43716, s2s_loss 0.42446, 60.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10931, exact_match 0.89893, 1.31 secs\n",
      "\u001b[1m---- Epoch 39/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.47410, s2s_loss 0.41777, 60.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11137, exact_match 0.89655, 1.33 secs\n",
      "\u001b[1m---- Epoch 40/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.52418, s2s_loss 0.42518, 60.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10792, exact_match 0.89655, 1.32 secs\n",
      "\u001b[1m---- Epoch 41/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.36095, s2s_loss 0.41871, 59.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10764, exact_match 0.89774, 1.33 secs\n",
      "\u001b[1m---- Epoch 42/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.36232, s2s_loss 0.42170, 60.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10823, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 43/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.35721, s2s_loss 0.42610, 60.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10793, exact_match 0.89774, 1.32 secs\n",
      "\u001b[1m---- Epoch 44/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.59783, s2s_loss 0.42195, 60.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10771, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 45/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.42683, s2s_loss 0.42013, 60.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10687, exact_match 0.88823, 1.36 secs\n",
      "\u001b[1m---- Epoch 46/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.23323, s2s_loss 0.42475, 60.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11018, exact_match 0.89536, 1.32 secs\n",
      "\u001b[1m---- Epoch 47/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.44360, s2s_loss 0.41384, 59.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10924, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 48/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.48211, s2s_loss 0.41662, 60.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10936, exact_match 0.88942, 1.32 secs\n",
      "\u001b[1m---- Epoch 49/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.33363, s2s_loss 0.42169, 60.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10806, exact_match 0.88823, 1.31 secs\n",
      "\u001b[1m---- Epoch 50/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.37955, s2s_loss 0.42646, 60.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10748, exact_match 0.88704, 1.32 secs\n",
      "\u001b[1m---- Epoch 51/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44147, s2s_loss 0.42031, 61.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10784, exact_match 0.88823, 1.32 secs\n",
      "\u001b[1m---- Epoch 52/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38977, s2s_loss 0.41609, 60.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10779, exact_match 0.88942, 1.30 secs\n",
      "\u001b[1m---- Epoch 53/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.31927, s2s_loss 0.42016, 60.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10501, exact_match 0.90131, 1.32 secs\n",
      "\u001b[1m---- Epoch 54/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.35679, s2s_loss 0.42110, 60.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10583, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 55/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.64420, s2s_loss 0.41699, 60.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10611, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 56/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.41896, s2s_loss 0.41534, 60.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10542, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 57/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.61934, s2s_loss 0.41203, 43.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10630, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 58/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.44022, s2s_loss 0.41723, 60.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10647, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 59/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.29449, s2s_loss 0.42085, 60.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10584, exact_match 0.89774, 1.32 secs\n",
      "\u001b[1m---- Epoch 60/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.34787, s2s_loss 0.41277, 59.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10561, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 61/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.53263, s2s_loss 0.41547, 59.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10357, exact_match 0.89893, 1.31 secs\n",
      "\u001b[1m---- Epoch 62/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.50083, s2s_loss 0.41801, 60.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10317, exact_match 0.90012, 1.31 secs\n",
      "\u001b[1m---- Epoch 63/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.57780, s2s_loss 0.41257, 59.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10357, exact_match 0.90250, 1.31 secs\n",
      "\u001b[1m---- Epoch 64/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.32923, s2s_loss 0.41932, 60.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10594, exact_match 0.90012, 1.31 secs\n",
      "\u001b[1m---- Epoch 65/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32903, s2s_loss 0.41746, 60.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10656, exact_match 0.89774, 1.33 secs\n",
      "\u001b[1m---- Epoch 66/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.82668, s2s_loss 0.41274, 60.36 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.10544, exact_match 0.90012, 1.31 secs\n",
      "\u001b[1m---- Epoch 67/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39593, s2s_loss 0.42066, 60.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10527, exact_match 0.90131, 1.31 secs\n",
      "\u001b[1m---- Epoch 68/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.29518, s2s_loss 0.41678, 60.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10558, exact_match 0.89893, 1.32 secs\n",
      "\u001b[1m---- Epoch 69/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.54604, s2s_loss 0.40873, 60.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10591, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 70/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.46301, s2s_loss 0.41825, 52.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10581, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 71/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.39666, s2s_loss 0.40547, 60.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10345, exact_match 0.89893, 1.32 secs\n",
      "\u001b[1m---- Epoch 72/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.34286, s2s_loss 0.41743, 61.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10548, exact_match 0.89774, 1.32 secs\n",
      "\u001b[1m---- Epoch 73/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.60517, s2s_loss 0.41301, 60.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10659, exact_match 0.89298, 1.31 secs\n",
      "\u001b[1m---- Epoch 74/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.62859, s2s_loss 0.41719, 60.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10658, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 75/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.45157, s2s_loss 0.40832, 60.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10636, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 76/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.61592, s2s_loss 0.42434, 60.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10629, exact_match 0.89774, 1.35 secs\n",
      "\u001b[1m---- Epoch 77/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.23090, s2s_loss 0.41099, 60.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10718, exact_match 0.89536, 1.33 secs\n",
      "\u001b[1m---- Epoch 78/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.41622, s2s_loss 0.42200, 60.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10497, exact_match 0.89774, 1.32 secs\n",
      "\u001b[1m---- Epoch 79/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.52637, s2s_loss 0.41152, 60.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10813, exact_match 0.89536, 1.33 secs\n",
      "\u001b[1m---- Epoch 80/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.48836, s2s_loss 0.40483, 60.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10641, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 81/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32856, s2s_loss 0.41308, 60.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10551, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 82/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.49414, s2s_loss 0.41836, 60.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10542, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 83/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.55580, s2s_loss 0.40922, 60.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10558, exact_match 0.89655, 1.32 secs\n",
      "\u001b[1m---- Epoch 84/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.49158, s2s_loss 0.41271, 60.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10578, exact_match 0.89655, 1.32 secs\n",
      "\u001b[1m---- Epoch 85/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.29290, s2s_loss 0.40729, 60.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10564, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 86/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.38126, s2s_loss 0.41205, 60.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10006, exact_match 0.89655, 1.34 secs\n",
      "\u001b[1m---- Epoch 87/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.53280, s2s_loss 0.41237, 60.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10554, exact_match 0.89774, 1.30 secs\n",
      "\u001b[1m---- Epoch 88/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.37138, s2s_loss 0.41660, 59.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10341, exact_match 0.89774, 1.31 secs\n",
      "\u001b[1m---- Epoch 89/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.45300, s2s_loss 0.41626, 53.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10340, exact_match 0.89655, 1.28 secs\n",
      "\u001b[1m---- Epoch 90/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.48769, s2s_loss 0.40856, 60.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10340, exact_match 0.89774, 1.33 secs\n",
      "\u001b[1m---- Epoch 91/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.51248, s2s_loss 0.41434, 60.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10358, exact_match 0.89774, 1.30 secs\n",
      "\u001b[1m---- Epoch 92/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.19826, s2s_loss 0.41383, 60.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10373, exact_match 0.89774, 1.30 secs\n",
      "\u001b[1m---- Epoch 93/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.70473, s2s_loss 0.40589, 60.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10149, exact_match 0.89893, 1.31 secs\n",
      "\u001b[1m---- Epoch 94/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.51120, s2s_loss 0.40983, 60.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10206, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 95/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.44321, s2s_loss 0.41121, 60.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10137, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 96/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.48857, s2s_loss 0.41457, 60.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10180, exact_match 0.89417, 1.34 secs\n",
      "\u001b[1m---- Epoch 97/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.20794, s2s_loss 0.40943, 60.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10071, exact_match 0.89774, 1.28 secs\n",
      "\u001b[1m---- Epoch 98/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.28458, s2s_loss 0.41522, 60.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10096, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 99/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.35819, s2s_loss 0.41286, 59.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10066, exact_match 0.89655, 1.32 secs\n",
      "\u001b[1m---- Epoch 100/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38260, s2s_loss 0.41615, 60.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10067, exact_match 0.89655, 1.31 secs\n",
      "\u001b[1m---- Epoch 101/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.36593, s2s_loss 0.41146, 60.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10364, exact_match 0.88704, 1.32 secs\n",
      "\u001b[1m---- Epoch 102/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.39917, s2s_loss 0.40713, 60.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10134, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 103/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.37316, s2s_loss 0.41504, 60.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10243, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 104/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.35136, s2s_loss 0.40500, 42.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10207, exact_match 0.89180, 1.31 secs\n",
      "\u001b[1m---- Epoch 105/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38119, s2s_loss 0.40918, 60.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10153, exact_match 0.89298, 1.32 secs\n",
      "\u001b[1m---- Epoch 106/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.48950, s2s_loss 0.41046, 60.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10152, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 107/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26109, s2s_loss 0.41402, 60.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10120, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 108/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.36217, s2s_loss 0.40453, 60.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10108, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 109/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.28290, s2s_loss 0.40978, 60.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09654, exact_match 0.89774, 1.32 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_109_exact_match+s2s_loss=0.8853.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 110/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.39176, s2s_loss 0.40466, 60.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10036, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 111/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.42421, s2s_loss 0.39956, 42.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10070, exact_match 0.89061, 1.31 secs\n",
      "\u001b[1m---- Epoch 112/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.50792, s2s_loss 0.41354, 60.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09886, exact_match 0.89536, 1.31 secs\n",
      "\u001b[1m---- Epoch 113/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53098, s2s_loss 0.40608, 59.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09897, exact_match 0.89417, 1.32 secs\n",
      "\u001b[1m---- Epoch 114/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.44211, s2s_loss 0.40997, 60.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09908, exact_match 0.89417, 1.35 secs\n",
      "\u001b[1m---- Epoch 115/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.40431, s2s_loss 0.41062, 60.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09902, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 116/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38326, s2s_loss 0.40716, 60.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09934, exact_match 0.89417, 1.31 secs\n",
      "\u001b[1m---- Epoch 117/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "   iteration 69650\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240305_122528_multitask(nli+mlm)_Seq2Seq(t5-small)\" \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--batch_size 20 \\\n",
    "--num_workers 2 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"multitask\" \\\n",
    "--experiment_name \"nli+mlm\" \\\n",
    "--multitask_name_list \\\n",
    "\"nli\" \\\n",
    "\"mlm\" \\\n",
    "\"sentence2facts\" \\\n",
    "--task2weight '{\"nli\": 2.0, \"mlm\": 1.0, \"sentence2facts\": 0.0}' \\\n",
    "--sentence_to_facts_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\"\\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\" \\\n",
    "--integrated_nli_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\" \\\n",
    "--use_sentence2facts_for_nli \\\n",
    "--use_anli \\\n",
    "--use_multinli \\\n",
    "--use_snli \\\n",
    "--use_report_nli \\\n",
    "--use_fact_based_reports_in_mlm \\\n",
    "--integrated_report_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\" \\\n",
    "--report_nli_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\" \\\n",
    "--paraphrased_inputs_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\" \\\n",
    "--only_validate_nli \\\n",
    "--nli1_only_on_train \\\n",
    "--nli1_only_on_val \\\n",
    "--seq2seq_model_name \"t5\" \\\n",
    "--t5_model_name \"t5-small\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
