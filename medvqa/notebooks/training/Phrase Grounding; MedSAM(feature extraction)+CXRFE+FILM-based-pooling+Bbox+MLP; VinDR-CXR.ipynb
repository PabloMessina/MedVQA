{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8833170a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 700\n",
      "   max_images_per_batch: 8\n",
      "   max_phrases_per_batch: 10000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 1.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_061820_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: True\n",
      "   raw_image_encoding: medsam-feature-extractor-huggingface\n",
      "   huggingface_model_name: wanglab/medsam-vit-base\n",
      "   num_regions: 4096\n",
      "   image_local_feat_size: 256\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 64\n",
      "   regions_height: 64\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 3\n",
      "   num_val_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [1024, 1024]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_061820_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: medsam-feature-extractor-huggingface\n",
      "  self.global_feat_size = 512\n",
      "  self.local_feat_size = 256\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [1024, 1024]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [1024, 1024]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.phrase_grounding_masks.shape = (18000, 22, 4096)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 35\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 917\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Lung Opacity: 1331\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4288\n",
      "No finding: 10601\n",
      "Group sizes: [10478, 771, 323, 312, 286, 278, 258, 243, 241, 218, 215, 167, 159, 156, 122, 119, 112, 102, 84, 83, 79, 47, 45, 32, 70]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 771, weight = 882.1360585110112\n",
      "  len(indices) = 323, weight = 579.1323556126193\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 167, weight = 402.55283205217046\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 112, weight = 315.45337872121524\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 84, weight = 261.20109767987407\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 47, weight = 171.37827001640065\n",
      "  len(indices) = 45, weight = 165.6367630898417\n",
      "  len(indices) = 32, weight = 125.0\n",
      "  len(indices) = 70, weight = 230.2655804515992\n",
      "batch_size = 8\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 8\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(vinbig_trainer.train_dataloader) = 125000000000000000\n",
      "len(vinbig_trainer.val_dataloader) = 375\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_4_vbss+vbou+vbuc+vbss=0.1141.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_061820_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/checkpoint_4_vbss+vbou+vbuc+vbss=0.1141.pt\n",
      "\u001b[93mWarning: model state dict has 193 keys, loaded state dict has 194 keys, intersection has 193 keys, union has 194 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  pos_encoding.penc.inv_freq\u001b[0m\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.47606, vbg_vgbbox_loss 0.77512, vbg_att_sup_loss 1.37053, vbg_phrcls_loss 1.33041, vbg_prc_auc 0.16070, 326.02 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.05219, vbg_prc_auc 0.09297, 296.28 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_vbss+vbou+vbuc+vbss=0.1035.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.44702, vbg_vgbbox_loss 0.74837, vbg_att_sup_loss 1.37024, vbg_phrcls_loss 1.32841, vbg_prc_auc 0.16106, 325.85 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06078, vbg_prc_auc 0.09336, 296.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_vbss+vbou+vbuc+vbss=0.1079.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 3.37697, vbg_vgbbox_loss 0.68339, vbg_att_sup_loss 1.37000, vbg_phrcls_loss 1.32359, vbg_prc_auc 0.16078, 326.16 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07678, vbg_prc_auc 0.09169, 297.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_vbss+vbou+vbuc+vbss=0.1150.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 3.31001, vbg_vgbbox_loss 0.64815, vbg_att_sup_loss 1.36790, vbg_phrcls_loss 1.29396, vbg_prc_auc 0.15916, 327.28 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07692, vbg_prc_auc 0.09556, 297.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_vbss+vbou+vbuc+vbss=0.1172.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 3.23518, vbg_vgbbox_loss 0.62975, vbg_att_sup_loss 1.36185, vbg_phrcls_loss 1.24358, vbg_prc_auc 0.15859, 327.46 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07642, vbg_prc_auc 0.09715, 297.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_vbss+vbou+vbuc+vbss=0.1180.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.20845, vbg_vgbbox_loss 0.62695, vbg_att_sup_loss 1.35655, vbg_phrcls_loss 1.22495, vbg_prc_auc 0.15975, 327.91 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07637, vbg_prc_auc 0.09737, 297.85 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_vbss+vbou+vbuc+vbss=0.1181.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.19346, vbg_vgbbox_loss 0.62007, vbg_att_sup_loss 1.35340, vbg_phrcls_loss 1.21999, vbg_prc_auc 0.15974, 327.87 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07637, vbg_prc_auc 0.09770, 297.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_vbss+vbou+vbuc+vbss=0.1184.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.19426, vbg_vgbbox_loss 0.62093, vbg_att_sup_loss 1.35182, vbg_phrcls_loss 1.22151, vbg_prc_auc 0.16248, 327.07 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07646, vbg_prc_auc 0.09875, 297.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_vbss+vbou+vbuc+vbss=0.1190.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.18982, vbg_vgbbox_loss 0.62250, vbg_att_sup_loss 1.35186, vbg_phrcls_loss 1.21546, vbg_prc_auc 0.16215, 327.59 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07638, vbg_prc_auc 0.09877, 298.18 secs\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 3.16288, vbg_vgbbox_loss 0.61290, vbg_att_sup_loss 1.33580, vbg_phrcls_loss 1.21418, vbg_prc_auc 0.15954, 327.72 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07509, vbg_prc_auc 0.10547, 298.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_vbss+vbou+vbuc+vbss=0.1215.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.12432, vbg_vgbbox_loss 0.60547, vbg_att_sup_loss 1.31165, vbg_phrcls_loss 1.20720, vbg_prc_auc 0.16105, 327.42 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07482, vbg_prc_auc 0.10591, 297.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_vbss+vbou+vbuc+vbss=0.1219.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.11110, vbg_vgbbox_loss 0.60866, vbg_att_sup_loss 1.30155, vbg_phrcls_loss 1.20089, vbg_prc_auc 0.16088, 328.09 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07414, vbg_prc_auc 0.10672, 298.28 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_vbss+vbou+vbuc+vbss=0.1220.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "^C iteration 8525\n",
      "Exception in thread Thread-1 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1534, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1400, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 915, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 142, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 984, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 543, in step_fn__vinbig_bbox_grounding\n",
      "    phrase_classifier_loss = binary_multilabel_classification_criterion(phrase_classifier_logits, phrase_classification_labels)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/__init__.py\", line 31, in forward\n",
      "    tot = (loss1 + loss2 + loss3).detach().item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_061820_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 700 \\\n",
    "--max_images_per_batch 8 \\\n",
    "--max_phrases_per_batch 10000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 1.0 \\\n",
    "--raw_image_encoding \"medsam-feature-extractor-huggingface\" \\\n",
    "--huggingface_model_name \"wanglab/medsam-vit-base\" \\\n",
    "--freeze_image_encoder \\\n",
    "--image_size 1024 1024 \\\n",
    "--image_local_feat_size 256 \\\n",
    "--num_regions 4096 \\\n",
    "--regions_width 64 \\\n",
    "--regions_height 64 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--num_train_workers 3 \\\n",
    "--num_val_workers 3 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1654541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1000\n",
      "   max_images_per_batch: 2\n",
      "   max_phrases_per_batch: 10000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 3.8\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: medsam-feature-extractor-huggingface\n",
      "   huggingface_model_name: wanglab/medsam-vit-base\n",
      "   num_regions: 4096\n",
      "   image_local_feat_size: 256\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 64\n",
      "   regions_height: 64\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,7e-5,5,1e-6,7e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 20\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 3\n",
      "   num_val_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [1024, 1024]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: medsam-feature-extractor-huggingface\n",
      "  self.global_feat_size = 512\n",
      "  self.local_feat_size = 256\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,7e-5,5,1e-6,7e-5,5,1e-6\n",
      "1e-06 3 7e-05 5 1e-06 7e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 7e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [1024, 1024]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [1024, 1024]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.phrase_grounding_masks.shape = (18000, 22, 4096)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 35\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 917\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Lung Opacity: 1331\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4288\n",
      "No finding: 10601\n",
      "Group sizes: [10478, 771, 323, 312, 286, 278, 258, 243, 241, 218, 215, 167, 159, 156, 122, 119, 112, 102, 84, 83, 79, 47, 45, 32, 70]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 771, weight = 882.1360585110112\n",
      "  len(indices) = 323, weight = 579.1323556126193\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 167, weight = 402.55283205217046\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 112, weight = 315.45337872121524\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 84, weight = 261.20109767987407\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 47, weight = 171.37827001640065\n",
      "  len(indices) = 45, weight = 165.6367630898417\n",
      "  len(indices) = 32, weight = 125.0\n",
      "  len(indices) = 70, weight = 230.2655804515992\n",
      "batch_size = 2\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 7\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(vinbig_trainer.train_dataloader) = 500000000000000000\n",
      "len(vinbig_trainer.val_dataloader) = 429\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_12_vbss+vbou+vbuc+vbss=0.1220.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/checkpoint_12_vbss+vbou+vbuc+vbss=0.1220.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.62135, vbg_vgbbox_loss 0.56449, vbg_att_sup_loss 1.27925, vbg_phrcls_loss 0.77761, vbg_prc_auc 0.16111, 352.33 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07386, vbg_prc_auc 0.10745, 298.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_vbss+vbou+vbuc+vbss=0.1229.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.60347, vbg_vgbbox_loss 0.54566, vbg_att_sup_loss 1.27917, vbg_phrcls_loss 0.77864, vbg_prc_auc 0.16068, 337.86 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07356, vbg_prc_auc 0.12125, 297.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_vbss+vbou+vbuc+vbss=0.1292.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.51346, vbg_vgbbox_loss 0.48016, vbg_att_sup_loss 1.26520, vbg_phrcls_loss 0.76810, vbg_prc_auc 0.16691, 353.01 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06780, vbg_prc_auc 0.11490, 297.91 secs\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 2.42128, vbg_vgbbox_loss 0.44518, vbg_att_sup_loss 1.21965, vbg_phrcls_loss 0.75645, vbg_prc_auc 0.16393, 357.97 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.05872, vbg_prc_auc 0.12377, 298.13 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 2.27987, vbg_vgbbox_loss 0.38461, vbg_att_sup_loss 1.15429, vbg_phrcls_loss 0.74097, vbg_prc_auc 0.18469, 358.99 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06380, vbg_prc_auc 0.14231, 298.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_vbss+vbou+vbuc+vbss=0.1384.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 2.23553, vbg_vgbbox_loss 0.37387, vbg_att_sup_loss 1.13028, vbg_phrcls_loss 0.73138, vbg_prc_auc 0.20774, 359.52 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06864, vbg_prc_auc 0.14544, 298.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_vbss+vbou+vbuc+vbss=0.1432.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.19755, vbg_vgbbox_loss 0.36237, vbg_att_sup_loss 1.11147, vbg_phrcls_loss 0.72372, vbg_prc_auc 0.21744, 362.85 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07023, vbg_prc_auc 0.15053, 299.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_vbss+vbou+vbuc+vbss=0.1468.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.18293, vbg_vgbbox_loss 0.35856, vbg_att_sup_loss 1.10711, vbg_phrcls_loss 0.71726, vbg_prc_auc 0.22952, 367.64 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07431, vbg_prc_auc 0.15212, 299.43 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_vbss+vbou+vbuc+vbss=0.1499.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.17594, vbg_vgbbox_loss 0.35816, vbg_att_sup_loss 1.10204, vbg_phrcls_loss 0.71574, vbg_prc_auc 0.24457, 369.01 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06936, vbg_prc_auc 0.15191, 298.47 secs\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 2.16089, vbg_vgbbox_loss 0.34930, vbg_att_sup_loss 1.08459, vbg_phrcls_loss 0.72701, vbg_prc_auc 0.19705, 374.85 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07477, vbg_prc_auc 0.12928, 300.65 secs\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.05996, vbg_vgbbox_loss 0.32117, vbg_att_sup_loss 1.02508, vbg_phrcls_loss 0.71371, vbg_prc_auc 0.21930, 374.16 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.07260, vbg_prc_auc 0.14347, 300.41 secs\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.00122, vbg_vgbbox_loss 0.30944, vbg_att_sup_loss 0.99567, vbg_phrcls_loss 0.69611, vbg_prc_auc 0.23857, 374.24 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.08152, vbg_prc_auc 0.15417, 300.42 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_vbss+vbou+vbuc+vbss=0.1562.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.98933, vbg_vgbbox_loss 0.30514, vbg_att_sup_loss 0.99062, vbg_phrcls_loss 0.69357, vbg_prc_auc 0.24877, 381.12 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.08010, vbg_prc_auc 0.15444, 301.43 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.96439, vbg_vgbbox_loss 0.29510, vbg_att_sup_loss 0.97774, vbg_phrcls_loss 0.69156, vbg_prc_auc 0.25311, 381.81 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.08236, vbg_prc_auc 0.15463, 301.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_vbss+vbou+vbuc+vbss=0.1577.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.97220, vbg_vgbbox_loss 0.29835, vbg_att_sup_loss 0.96440, vbg_phrcls_loss 0.70945, vbg_prc_auc 0.21064, 379.26 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.08096, vbg_prc_auc 0.15090, 299.98 secs\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.89926, vbg_vgbbox_loss 0.28461, vbg_att_sup_loss 0.92251, vbg_phrcls_loss 0.69213, vbg_prc_auc 0.23220, 374.92 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09571, vbg_prc_auc 0.15261, 301.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_vbss+vbou+vbuc+vbss=0.1628.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.83784, vbg_vgbbox_loss 0.27350, vbg_att_sup_loss 0.88896, vbg_phrcls_loss 0.67539, vbg_prc_auc 0.26508, 375.91 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09760, vbg_prc_auc 0.15430, 301.42 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_vbss+vbou+vbuc+vbss=0.1660.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.82174, vbg_vgbbox_loss 0.27204, vbg_att_sup_loss 0.87851, vbg_phrcls_loss 0.67119, vbg_prc_auc 0.27451, 384.22 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09844, vbg_prc_auc 0.15132, 302.94 secs\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.81549, vbg_vgbbox_loss 0.26836, vbg_att_sup_loss 0.87559, vbg_phrcls_loss 0.67153, vbg_prc_auc 0.28133, 376.88 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09863, vbg_prc_auc 0.15467, 303.39 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_vbss+vbou+vbuc+vbss=0.1674.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.84120, vbg_vgbbox_loss 0.27704, vbg_att_sup_loss 0.87598, vbg_phrcls_loss 0.68818, vbg_prc_auc 0.23650, 384.00 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09424, vbg_prc_auc 0.14556, 303.57 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.75796, vbg_vgbbox_loss 0.25974, vbg_att_sup_loss 0.83244, vbg_phrcls_loss 0.66578, vbg_prc_auc 0.26485, 392.81 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.10252, vbg_prc_auc 0.15580, 304.37 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_vbss+vbou+vbuc+vbss=0.1697.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.70632, vbg_vgbbox_loss 0.24784, vbg_att_sup_loss 0.79580, vbg_phrcls_loss 0.66268, vbg_prc_auc 0.28381, 410.96 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.10319, vbg_prc_auc 0.15152, 304.22 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.69528, vbg_vgbbox_loss 0.24669, vbg_att_sup_loss 0.79440, vbg_phrcls_loss 0.65419, vbg_prc_auc 0.28526, 403.03 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.10592, vbg_prc_auc 0.15467, 303.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_vbss+vbou+vbuc+vbss=0.1721.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.68154, vbg_vgbbox_loss 0.24475, vbg_att_sup_loss 0.78705, vbg_phrcls_loss 0.64973, vbg_prc_auc 0.30135, 413.55 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.10642, vbg_prc_auc 0.15486, 305.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_vbss+vbou+vbuc+vbss=0.1731.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.70111, vbg_vgbbox_loss 0.24972, vbg_att_sup_loss 0.78852, vbg_phrcls_loss 0.66287, vbg_prc_auc 0.26413, 414.00 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09523, vbg_prc_auc 0.15826, 305.84 secs\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.65580, vbg_vgbbox_loss 0.24618, vbg_att_sup_loss 0.76240, vbg_phrcls_loss 0.64722, vbg_prc_auc 0.28775, 418.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11092, vbg_prc_auc 0.15885, 305.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_vbss+vbou+vbuc+vbss=0.1766.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.58403, vbg_vgbbox_loss 0.22746, vbg_att_sup_loss 0.72439, vbg_phrcls_loss 0.63218, vbg_prc_auc 0.30967, 414.85 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11307, vbg_prc_auc 0.16533, 304.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_vbss+vbou+vbuc+vbss=0.1821.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.57529, vbg_vgbbox_loss 0.22688, vbg_att_sup_loss 0.71548, vbg_phrcls_loss 0.63293, vbg_prc_auc 0.30836, 411.97 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11024, vbg_prc_auc 0.16428, 305.27 secs\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.57167, vbg_vgbbox_loss 0.22597, vbg_att_sup_loss 0.71487, vbg_phrcls_loss 0.63083, vbg_prc_auc 0.30877, 427.61 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11486, vbg_prc_auc 0.16539, 307.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_29_vbss+vbou+vbuc+vbss=0.1830.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.61528, vbg_vgbbox_loss 0.24147, vbg_att_sup_loss 0.72850, vbg_phrcls_loss 0.64531, vbg_prc_auc 0.27541, 426.19 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.08393, vbg_prc_auc 0.15955, 305.89 secs\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.56215, vbg_vgbbox_loss 0.22750, vbg_att_sup_loss 0.69250, vbg_phrcls_loss 0.64216, vbg_prc_auc 0.27584, 421.91 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.10810, vbg_prc_auc 0.17235, 305.95 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.51568, vbg_vgbbox_loss 0.22122, vbg_att_sup_loss 0.67844, vbg_phrcls_loss 0.61602, vbg_prc_auc 0.32057, 422.49 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11403, vbg_prc_auc 0.17332, 305.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_vbss+vbou+vbuc+vbss=0.1871.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.47415, vbg_vgbbox_loss 0.21239, vbg_att_sup_loss 0.65352, vbg_phrcls_loss 0.60825, vbg_prc_auc 0.32988, 426.55 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11863, vbg_prc_auc 0.17669, 307.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_vbss+vbou+vbuc+vbss=0.1915.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.48975, vbg_vgbbox_loss 0.21727, vbg_att_sup_loss 0.66296, vbg_phrcls_loss 0.60951, vbg_prc_auc 0.32324, 426.47 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11638, vbg_prc_auc 0.17765, 306.57 secs\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.55617, vbg_vgbbox_loss 0.23541, vbg_att_sup_loss 0.68837, vbg_phrcls_loss 0.63239, vbg_prc_auc 0.28314, 438.36 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.11204, vbg_prc_auc 0.17699, 307.39 secs\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.46599, vbg_vgbbox_loss 0.21231, vbg_att_sup_loss 0.64593, vbg_phrcls_loss 0.60776, vbg_prc_auc 0.32337, 446.40 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.12235, vbg_prc_auc 0.18739, 307.96 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_36_vbss+vbou+vbuc+vbss=0.1979.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "Current run is terminating due to exception: 'int' object has no attribute 'detach'\n",
      "Engine run is terminating due to exception: 'int' object has no attribute 'detach'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1534, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1400, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 915, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 142, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1087, in _run_once_on_dataset_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 984, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 644, in step_fn__vinbig_bbox_grounding\n",
      "    output['visual_grounding_bbox_loss'] = visual_grounding_bbox_loss.detach()\n",
      "AttributeError: 'int' object has no attribute 'detach'\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--max_images_per_batch 2 \\\n",
    "--max_phrases_per_batch 10000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 3.8 \\\n",
    "--raw_image_encoding \"medsam-feature-extractor-huggingface\" \\\n",
    "--huggingface_model_name \"wanglab/medsam-vit-base\" \\\n",
    "--image_size 1024 1024 \\\n",
    "--image_local_feat_size 256 \\\n",
    "--num_regions 4096 \\\n",
    "--regions_width 64 \\\n",
    "--regions_height 64 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--num_train_workers 3 \\\n",
    "--num_val_workers 3 \\\n",
    "--gradient_accumulation_steps 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,7e-5,5,1e-6,7e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305d95d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 50\n",
      "   batches_per_epoch: 2000\n",
      "   max_images_per_batch: 2\n",
      "   max_phrases_per_batch: 10000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 3.8\n",
      "   checkpoint_folder: models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: medsam-feature-extractor-huggingface\n",
      "   huggingface_model_name: wanglab/medsam-vit-base\n",
      "   num_regions: 4096\n",
      "   image_local_feat_size: 256\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 64\n",
      "   regions_height: 64\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,7e-5,5,1e-6,7e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 3\n",
      "   num_val_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [1024, 1024]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_075456_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: medsam-feature-extractor-huggingface\n",
      "  self.global_feat_size = 512\n",
      "  self.local_feat_size = 256\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,7e-5,5,1e-6,7e-5,5,1e-6\n",
      "1e-06 3 7e-05 5 1e-06 7e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 7e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [1024, 1024]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [1024, 1024]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.phrase_grounding_masks.shape = (18000, 22, 4096)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 35\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 917\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Lung Opacity: 1331\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4288\n",
      "No finding: 10601\n",
      "Group sizes: [10478, 771, 323, 312, 286, 278, 258, 243, 241, 218, 215, 167, 159, 156, 122, 119, 112, 102, 84, 83, 79, 47, 45, 32, 70]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 771, weight = 882.1360585110112\n",
      "  len(indices) = 323, weight = 579.1323556126193\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 167, weight = 402.55283205217046\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 112, weight = 315.45337872121524\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 84, weight = 261.20109767987407\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 47, weight = 171.37827001640065\n",
      "  len(indices) = 45, weight = 165.6367630898417\n",
      "  len(indices) = 32, weight = 125.0\n",
      "  len(indices) = 70, weight = 230.2655804515992\n",
      "batch_size = 2\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 7\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(vinbig_trainer.train_dataloader) = 500000000000000000\n",
      "len(vinbig_trainer.val_dataloader) = 429\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_36_vbss+vbou+vbuc+vbss=0.1979.pt', 'checkpoint_48_vbss+vbou+vbuc+vbss=0.2299.pt', 'checkpoint_84_vbss+vbou+vbuc+vbss=0.2676.pt', 'checkpoint_38_vbss+vbou+vbuc+vbss=0.2012.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/checkpoint_84_vbss+vbou+vbuc+vbss=0.2676.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 85/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.06834, vbg_vgbbox_loss 0.17046, vbg_att_sup_loss 0.40260, vbg_phrcls_loss 0.49528, vbg_prc_auc 0.38772, 700.08 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15916, vbg_prc_auc 0.25495, 300.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_85_vbss+vbou+vbuc+vbss=0.2515.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 86/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.01286, vbg_vgbbox_loss 0.15707, vbg_att_sup_loss 0.37686, vbg_phrcls_loss 0.47894, vbg_prc_auc 0.40415, 717.63 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17318, vbg_prc_auc 0.28958, 301.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_86_vbss+vbou+vbuc+vbss=0.2747.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 87/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.98356, vbg_vgbbox_loss 0.15357, vbg_att_sup_loss 0.36581, vbg_phrcls_loss 0.46418, vbg_prc_auc 0.42212, 734.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16542, vbg_prc_auc 0.26521, 301.33 secs\n",
      "\u001b[1m---- Epoch 88/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "vbg_bbox_iou 0.16606, vbg_prc_auc 0.28260, 298.09 secs\n",
      "\u001b[1m---- Epoch 89/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.96198, vbg_vgbbox_loss 0.15166, vbg_att_sup_loss 0.35368, vbg_phrcls_loss 0.45664, vbg_prc_auc 0.42696, 727.80 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17097, vbg_prc_auc 0.28293, 300.60 secs\n",
      "\u001b[1m---- Epoch 90/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.03162, vbg_vgbbox_loss 0.16504, vbg_att_sup_loss 0.38302, vbg_phrcls_loss 0.48356, vbg_prc_auc 0.39834, 719.61 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16657, vbg_prc_auc 0.26793, 299.52 secs\n",
      "\u001b[1m---- Epoch 91/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.99067, vbg_vgbbox_loss 0.15711, vbg_att_sup_loss 0.36632, vbg_phrcls_loss 0.46724, vbg_prc_auc 0.41825, 720.67 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16776, vbg_prc_auc 0.27148, 299.77 secs\n",
      "\u001b[1m---- Epoch 92/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.95475, vbg_vgbbox_loss 0.15074, vbg_att_sup_loss 0.34866, vbg_phrcls_loss 0.45535, vbg_prc_auc 0.42685, 719.21 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16396, vbg_prc_auc 0.26760, 300.05 secs\n",
      "\u001b[1m---- Epoch 93/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.93861, vbg_vgbbox_loss 0.14956, vbg_att_sup_loss 0.34087, vbg_phrcls_loss 0.44818, vbg_prc_auc 0.43762, 717.40 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16555, vbg_prc_auc 0.26884, 298.83 secs\n",
      "\u001b[1m---- Epoch 94/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.93587, vbg_vgbbox_loss 0.14876, vbg_att_sup_loss 0.33947, vbg_phrcls_loss 0.44764, vbg_prc_auc 0.43572, 718.82 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16512, vbg_prc_auc 0.27283, 299.17 secs\n",
      "\u001b[1m---- Epoch 95/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.02595, vbg_vgbbox_loss 0.16593, vbg_att_sup_loss 0.38134, vbg_phrcls_loss 0.47868, vbg_prc_auc 0.39995, 713.72 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15819, vbg_prc_auc 0.27350, 299.80 secs\n",
      "\u001b[1m---- Epoch 96/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.96230, vbg_vgbbox_loss 0.15472, vbg_att_sup_loss 0.34877, vbg_phrcls_loss 0.45882, vbg_prc_auc 0.42584, 711.34 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16160, vbg_prc_auc 0.28428, 298.49 secs\n",
      "\u001b[1m---- Epoch 97/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.93599, vbg_vgbbox_loss 0.14974, vbg_att_sup_loss 0.33612, vbg_phrcls_loss 0.45012, vbg_prc_auc 0.43864, 712.63 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16986, vbg_prc_auc 0.30371, 298.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_97_vbss+vbou+vbuc+vbss=0.2817.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 98/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.91910, vbg_vgbbox_loss 0.14605, vbg_att_sup_loss 0.32943, vbg_phrcls_loss 0.44362, vbg_prc_auc 0.44340, 710.90 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16952, vbg_prc_auc 0.30102, 299.07 secs\n",
      "\u001b[1m---- Epoch 99/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.91446, vbg_vgbbox_loss 0.14574, vbg_att_sup_loss 0.32817, vbg_phrcls_loss 0.44055, vbg_prc_auc 0.44411, 711.05 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17227, vbg_prc_auc 0.28592, 299.12 secs\n",
      "\u001b[1m---- Epoch 100/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.00941, vbg_vgbbox_loss 0.16488, vbg_att_sup_loss 0.36436, vbg_phrcls_loss 0.48016, vbg_prc_auc 0.40504, 711.09 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.14776, vbg_prc_auc 0.27620, 298.45 secs\n",
      "\u001b[1m---- Epoch 101/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.94248, vbg_vgbbox_loss 0.15075, vbg_att_sup_loss 0.33858, vbg_phrcls_loss 0.45316, vbg_prc_auc 0.43611, 711.12 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17677, vbg_prc_auc 0.28450, 299.19 secs\n",
      "\u001b[1m---- Epoch 102/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.91098, vbg_vgbbox_loss 0.14595, vbg_att_sup_loss 0.32634, vbg_phrcls_loss 0.43869, vbg_prc_auc 0.44678, 709.76 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17373, vbg_prc_auc 0.28188, 299.21 secs\n",
      "\u001b[1m---- Epoch 103/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.89783, vbg_vgbbox_loss 0.14410, vbg_att_sup_loss 0.31732, vbg_phrcls_loss 0.43642, vbg_prc_auc 0.45208, 710.02 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17432, vbg_prc_auc 0.28332, 298.57 secs\n",
      "\u001b[1m---- Epoch 104/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.89777, vbg_vgbbox_loss 0.14338, vbg_att_sup_loss 0.32083, vbg_phrcls_loss 0.43356, vbg_prc_auc 0.46126, 710.05 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17703, vbg_prc_auc 0.28456, 299.15 secs\n",
      "\u001b[1m---- Epoch 105/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 0.97324, vbg_vgbbox_loss 0.15855, vbg_att_sup_loss 0.35002, vbg_phrcls_loss 0.46467, vbg_prc_auc 0.41577, 706.20 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.14926, vbg_prc_auc 0.26896, 299.56 secs\n",
      "\u001b[1m---- Epoch 106/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.93140, vbg_vgbbox_loss 0.14928, vbg_att_sup_loss 0.33349, vbg_phrcls_loss 0.44863, vbg_prc_auc 0.44290, 717.18 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17451, vbg_prc_auc 0.26892, 300.22 secs\n",
      "\u001b[1m---- Epoch 107/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.89183, vbg_vgbbox_loss 0.14402, vbg_att_sup_loss 0.31732, vbg_phrcls_loss 0.43050, vbg_prc_auc 0.45892, 729.88 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17797, vbg_prc_auc 0.29758, 300.45 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_107_vbss+vbou+vbuc+vbss=0.2837.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 108/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.87173, vbg_vgbbox_loss 0.14124, vbg_att_sup_loss 0.30626, vbg_phrcls_loss 0.42423, vbg_prc_auc 0.46535, 734.38 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17667, vbg_prc_auc 0.29280, 299.84 secs\n",
      "\u001b[1m---- Epoch 109/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.87157, vbg_vgbbox_loss 0.14288, vbg_att_sup_loss 0.30244, vbg_phrcls_loss 0.42625, vbg_prc_auc 0.46675, 731.15 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17747, vbg_prc_auc 0.29495, 301.18 secs\n",
      "\u001b[1m---- Epoch 110/134\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "^C iteration 50550\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1530, in <module>\n",
      "    resume_training(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1486, in resume_training\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 915, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 142, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 984, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 615, in step_fn__vinbig_bbox_grounding\n",
      "    gradient_accumulator.step(batch_loss, model)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 29, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/phrase_grounding/20241220_102157_vinbig_PhraseGrounder(wanglab-medsam-vit-base,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\" \\\n",
    "--epochs 50 \\\n",
    "--batches_per_epoch 2000 \\\n",
    "--max_images_per_batch 2 \\\n",
    "--max_phrases_per_batch 10000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 3.8 \\\n",
    "--raw_image_encoding \"medsam-feature-extractor-huggingface\" \\\n",
    "--huggingface_model_name \"wanglab/medsam-vit-base\" \\\n",
    "--image_size 1024 1024 \\\n",
    "--image_local_feat_size 256 \\\n",
    "--num_regions 4096 \\\n",
    "--regions_width 64 \\\n",
    "--regions_height 64 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--num_train_workers 3 \\\n",
    "--num_val_workers 3 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,7e-5,5,1e-6,7e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=353,2491289492560726319).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
