{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: yolov8\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: yolov8l.pt\n",
      "   yolov8_model_alias: yolov8l\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,3e-4,8,2e-6,3e-4,8,3e-6\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 1.0\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: train\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: True\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: yolov8\n",
      "  num_bbox_classes: 22\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.Detect                [22, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43646802 parameters, 43646786 gradients, 165.5 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "    Initializing VinBig classification task\n",
      "MultilabelClassifier_v3:\n",
      "  local_feat_dim: 512\n",
      "  global_feat_dim: 1024\n",
      "  hidden_dim: 128\n",
      "  num_regions: 169\n",
      "  num_labels: 28\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,3e-4,8,2e-6,3e-4,8,3e-6\n",
      "1e-06 3 0.0003 8 2e-06 0.0003 8 3e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0003\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 2\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    for_vinbig: returning vinbig transform\n",
      "    len(_augmented_bbox_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "  Loaded 18000 bounding boxes\n",
      "  self.bboxes[0]: ([], [])\n",
      "  self.bboxes[-1]: ([], [])\n",
      "  self.bboxes[500]: ([], [])\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=10601, #neg=4399\n",
      "Other disease     , #pos=4288, #neg=10712\n",
      "Aortic enlargement, #pos=3067, #neg=11933\n",
      "Cardiomegaly      , #pos=2300, #neg=12700\n",
      "Pleural thickening, #pos=1981, #neg=13019\n",
      "Pulmonary fibrosis, #pos=1617, #neg=13383\n",
      "Lung Opacity      , #pos=1322, #neg=13678\n",
      "Other lesion      , #pos=1134, #neg=13866\n",
      "Pleural effusion  , #pos=1032, #neg=13968\n",
      "Pneumonia         , #pos=917, #neg=14083\n",
      "Nodule/Mass       , #pos=830, #neg=14170\n",
      "Tuberculosis      , #pos=750, #neg=14250\n",
      "Infiltration      , #pos=613, #neg=14387\n",
      "Calcification     , #pos=452, #neg=14548\n",
      "ILD               , #pos=386, #neg=14614\n",
      "Consolidation     , #pos=353, #neg=14647\n",
      "Lung tumor        , #pos=291, #neg=14709\n",
      "Atelectasis       , #pos=186, #neg=14814\n",
      "Mediastinal shift , #pos=150, #neg=14850\n",
      "Enlarged PA       , #pos=131, #neg=14869\n",
      "Pneumothorax      , #pos=96, #neg=14904\n",
      "Rib fracture      , #pos=90, #neg=14910\n",
      "Emphysema         , #pos=78, #neg=14922\n",
      "Lung cavity       , #pos=50, #neg=14950\n",
      "COPD              , #pos=35, #neg=14965\n",
      "Lung cyst         , #pos=32, #neg=14968\n",
      "Clavicle fracture , #pos=27, #neg=14973\n",
      "Edema             , #pos=13, #neg=14987\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_230714_vinbig_yolov8l\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_230714_vinbig_yolov8l/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_230714_vinbig_yolov8l/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 13.34845, y8_loss 9.76362, y8box_loss 2.68585, y8cls_loss 4.64595, y8dfl_loss 2.43182, vnbgprcaucmic 0.16412, vnbgprcaucmac 0.14537, vnbgl_loss 11.54414, 170.36 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.11275, vnbgbbmf1 0.02365, vnbglaucmic 0.83366, vnbglaucmac 0.57888, vnbgprcaucmic 0.26271, vnbgprcaucmac 0.09651, 17.56 secs\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 9.96769, y8_loss 6.64488, y8box_loss 2.00575, y8cls_loss 2.80401, y8dfl_loss 1.83512, vnbgprcaucmic 0.62974, vnbgprcaucmac 0.30839, vnbgl_loss 8.18624, 167.02 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.24019, vnbgbbmf1 0.10259, vnbglaucmic 0.90151, vnbglaucmac 0.80066, vnbgprcaucmic 0.58267, vnbgprcaucmac 0.19350, 16.73 secs\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 7.10088, y8_loss 5.27929, y8box_loss 1.69874, y8cls_loss 2.01240, y8dfl_loss 1.56816, vnbgprcaucmic 0.81326, vnbgprcaucmac 0.53367, vnbgl_loss 6.41535, 167.91 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.15338, vnbgbbmf1 0.12940, vnbglaucmic 0.82280, vnbglaucmac 0.73240, vnbgprcaucmic 0.43812, vnbgprcaucmac 0.20947, 17.53 secs\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 5.75872, y8_loss 5.37330, y8box_loss 1.70827, y8cls_loss 2.06512, y8dfl_loss 1.59991, vnbgprcaucmic 0.83196, vnbgprcaucmac 0.59467, vnbgl_loss 6.40513, 167.62 secs\n",
      "(2) Validation stage ...\n",
      "WARNING: Bbox IOU defaulting to 0 since self._count is 0\n",
      "vnbgbbiou 0.00000, vnbgbbmf1 0.00000, vnbglaucmic 0.77164, vnbglaucmac 0.53364, vnbgprcaucmic 0.22772, vnbgprcaucmac 0.09108, 15.31 secs\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000160) ...\n",
      "loss 5.65798, y8_loss 4.28440, y8box_loss 1.42415, y8cls_loss 1.46590, y8dfl_loss 1.39435, vnbgprcaucmic 0.92773, vnbgprcaucmac 0.84041, vnbgl_loss 4.89376, 168.73 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.06184, vnbgbbmf1 0.01211, vnbglaucmic 0.77431, vnbglaucmac 0.57904, vnbgprcaucmic 0.36491, vnbgprcaucmac 0.12938, 15.91 secs\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000086) ...\n",
      "loss 4.35249, y8_loss 3.62803, y8box_loss 1.21320, y8cls_loss 1.15831, y8dfl_loss 1.25653, vnbgprcaucmic 0.96615, vnbgprcaucmac 0.93302, vnbgl_loss 4.01602, 176.53 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.09740, vnbgbbmf1 0.01697, vnbglaucmic 0.79886, vnbglaucmac 0.59478, vnbgprcaucmic 0.43935, vnbgprcaucmac 0.12606, 17.40 secs\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 3.77141, y8_loss 3.17511, y8box_loss 1.05079, y8cls_loss 0.96180, y8dfl_loss 1.16252, vnbgprcaucmic 0.98322, vnbgprcaucmac 0.97023, vnbgl_loss 3.43911, 203.93 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31802, vnbgbbmf1 0.19277, vnbglaucmic 0.92192, vnbglaucmac 0.81547, vnbgprcaucmic 0.64738, vnbgprcaucmac 0.30237, 19.73 secs\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 3.16398, y8_loss 2.87376, y8box_loss 0.93319, y8cls_loss 0.84105, y8dfl_loss 1.09952, vnbgprcaucmic 0.99049, vnbgprcaucmac 0.98238, vnbgl_loss 3.07230, 236.31 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33668, vnbgbbmf1 0.21839, vnbglaucmic 0.93740, vnbglaucmac 0.80812, vnbgprcaucmic 0.68424, vnbgprcaucmac 0.33094, 19.74 secs\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 2.96553, y8_loss 2.69442, y8box_loss 0.85772, y8cls_loss 0.77346, y8dfl_loss 1.06325, vnbgprcaucmic 0.99377, vnbgprcaucmac 0.98898, vnbgl_loss 2.85934, 241.10 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30514, vnbgbbmf1 0.24324, vnbglaucmic 0.93729, vnbglaucmac 0.80566, vnbgprcaucmic 0.67800, vnbgprcaucmac 0.33372, 20.44 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.73092, y8_loss 2.57187, y8box_loss 0.80362, y8cls_loss 0.72959, y8dfl_loss 1.03865, vnbgprcaucmic 0.99525, vnbgprcaucmac 0.99160, vnbgl_loss 2.71676, 259.01 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32720, vnbgbbmf1 0.25820, vnbglaucmic 0.93620, vnbglaucmac 0.80341, vnbgprcaucmic 0.68153, vnbgprcaucmac 0.35692, 21.94 secs\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.49994, y8_loss 2.51894, y8box_loss 0.77862, y8cls_loss 0.71169, y8dfl_loss 1.02863, vnbgprcaucmic 0.99592, vnbgprcaucmac 0.99234, vnbgl_loss 2.65540, 251.98 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33936, vnbgbbmf1 0.26434, vnbglaucmic 0.93672, vnbglaucmac 0.81281, vnbgprcaucmic 0.68942, vnbgprcaucmac 0.36071, 23.02 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.78516, y8_loss 2.49928, y8box_loss 0.77003, y8cls_loss 0.70450, y8dfl_loss 1.02475, vnbgprcaucmic 0.99605, vnbgprcaucmac 0.99271, vnbgl_loss 2.63176, 295.10 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33980, vnbgbbmf1 0.26680, vnbglaucmic 0.93817, vnbglaucmac 0.80437, vnbgprcaucmic 0.68656, vnbgprcaucmac 0.36279, 27.89 secs\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 2.60287, y8_loss 4.39612, y8box_loss 1.45646, y8cls_loss 1.51704, y8dfl_loss 1.42262, vnbgprcaucmic 0.91297, vnbgprcaucmac 0.81611, vnbgl_loss 5.04747, 304.20 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.06075, vnbgbbmf1 0.01311, vnbglaucmic 0.75052, vnbglaucmac 0.55417, vnbgprcaucmic 0.37151, vnbgprcaucmac 0.10049, 23.02 secs\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 4.81519, y8_loss 3.46947, y8box_loss 1.17069, y8cls_loss 1.06803, y8dfl_loss 1.23075, vnbgprcaucmic 0.97083, vnbgprcaucmac 0.94833, vnbgl_loss 3.80864, 307.90 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.02085, vnbgbbmf1 0.00112, vnbglaucmic 0.62078, vnbglaucmac 0.51666, vnbgprcaucmic 0.14086, vnbgprcaucmac 0.08763, 24.74 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 3.40356, y8_loss 2.87142, y8box_loss 0.95274, y8cls_loss 0.81459, y8dfl_loss 1.10409, vnbgprcaucmic 0.98883, vnbgprcaucmac 0.98048, vnbgl_loss 3.07430, 308.12 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.20435, vnbgbbmf1 0.08069, vnbglaucmic 0.85632, vnbglaucmac 0.74116, vnbgprcaucmic 0.47217, vnbgprcaucmac 0.19141, 23.84 secs\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 2.85771, y8_loss 2.54021, y8box_loss 0.81593, y8cls_loss 0.68748, y8dfl_loss 1.03681, vnbgprcaucmic 0.99486, vnbgprcaucmac 0.99122, vnbgl_loss 2.67763, 302.57 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.28398, vnbgbbmf1 0.19956, vnbglaucmic 0.91730, vnbglaucmac 0.80834, vnbgprcaucmic 0.63069, vnbgprcaucmac 0.26472, 24.04 secs\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 2.69236, y8_loss 2.35550, y8box_loss 0.73410, y8cls_loss 0.62250, y8dfl_loss 0.99889, vnbgprcaucmic 0.99677, vnbgprcaucmac 0.99479, vnbgl_loss 2.46477, 299.55 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35906, vnbgbbmf1 0.25621, vnbglaucmic 0.93936, vnbglaucmac 0.82548, vnbgprcaucmic 0.68975, vnbgprcaucmac 0.34025, 25.69 secs\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 2.36929, y8_loss 2.24488, y8box_loss 0.68177, y8cls_loss 0.58527, y8dfl_loss 0.97784, vnbgprcaucmic 0.99754, vnbgprcaucmac 0.99513, vnbgl_loss 2.34261, 322.82 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35365, vnbgbbmf1 0.27588, vnbglaucmic 0.94218, vnbglaucmac 0.84124, vnbgprcaucmic 0.69170, vnbgprcaucmac 0.35019, 27.22 secs\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.33771, y8_loss 2.19433, y8box_loss 0.65768, y8cls_loss 0.56687, y8dfl_loss 0.96978, vnbgprcaucmic 0.99802, vnbgprcaucmac 0.99681, vnbgl_loss 2.28191, 304.19 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.34957, vnbgbbmf1 0.27776, vnbglaucmic 0.94554, vnbglaucmac 0.83974, vnbgprcaucmic 0.70152, vnbgprcaucmac 0.35107, 24.39 secs\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.43886, y8_loss 2.15703, y8box_loss 0.64027, y8cls_loss 0.55617, y8dfl_loss 0.96059, vnbgprcaucmic 0.99829, vnbgprcaucmac 0.99719, vnbgl_loss 2.23981, 311.35 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35636, vnbgbbmf1 0.28151, vnbglaucmic 0.94488, vnbglaucmac 0.83632, vnbgprcaucmic 0.69772, vnbgprcaucmac 0.35195, 26.38 secs\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 2.39663, y8_loss 3.75768, y8box_loss 1.25602, y8cls_loss 1.21577, y8dfl_loss 1.28589, vnbgprcaucmic 0.95140, vnbgprcaucmac 0.90990, vnbgl_loss 4.20404, 319.80 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.00000, vnbgbbmf1 0.00000, vnbglaucmic 0.71937, vnbglaucmac 0.42574, vnbgprcaucmic 0.30885, vnbgprcaucmac 0.07480, 24.17 secs\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 3.86697, y8_loss 2.98913, y8box_loss 1.00679, y8cls_loss 0.85178, y8dfl_loss 1.13057, vnbgprcaucmic 0.98525, vnbgprcaucmac 0.97542, vnbgl_loss 3.21745, 315.67 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.05690, vnbgbbmf1 0.01421, vnbglaucmic 0.77019, vnbglaucmac 0.56641, vnbgprcaucmic 0.32553, vnbgprcaucmac 0.10933, 26.27 secs\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.79410, y8_loss 2.47175, y8box_loss 0.80252, y8cls_loss 0.64619, y8dfl_loss 1.02304, vnbgprcaucmic 0.99483, vnbgprcaucmac 0.99196, vnbgl_loss 2.60054, 315.95 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.11246, vnbgbbmf1 0.01741, vnbglaucmic 0.79158, vnbglaucmac 0.58929, vnbgprcaucmic 0.37314, vnbgprcaucmac 0.10682, 22.39 secs\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 2.55648, y8_loss 2.21763, y8box_loss 0.68918, y8cls_loss 0.55770, y8dfl_loss 0.97075, vnbgprcaucmic 0.99766, vnbgprcaucmac 0.99603, vnbgl_loss 2.30723, 307.33 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.25404, vnbgbbmf1 0.17229, vnbglaucmic 0.90095, vnbglaucmac 0.76573, vnbgprcaucmic 0.57379, vnbgprcaucmac 0.25399, 26.25 secs\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 2.15701, y8_loss 2.08705, y8box_loss 0.62607, y8cls_loss 0.51457, y8dfl_loss 0.94641, vnbgprcaucmic 0.99847, vnbgprcaucmac 0.99738, vnbgl_loss 2.15909, 309.43 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35255, vnbgbbmf1 0.26206, vnbglaucmic 0.93713, vnbglaucmac 0.84304, vnbgprcaucmic 0.67364, vnbgprcaucmac 0.33522, 27.47 secs\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.97980, y8_loss 2.01284, y8box_loss 0.58987, y8cls_loss 0.48960, y8dfl_loss 0.93337, vnbgprcaucmic 0.99877, vnbgprcaucmac 0.99818, vnbgl_loss 2.07684, 317.69 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.37508, vnbgbbmf1 0.22646, vnbglaucmic 0.93939, vnbglaucmac 0.84022, vnbgprcaucmic 0.68638, vnbgprcaucmac 0.31342, 25.01 secs\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.15670, y8_loss 1.98189, y8box_loss 0.57477, y8cls_loss 0.47928, y8dfl_loss 0.92783, vnbgprcaucmic 0.99893, vnbgprcaucmac 0.99810, vnbgl_loss 2.04361, 317.41 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.34969, vnbgbbmf1 0.26506, vnbglaucmic 0.94425, vnbglaucmac 0.84153, vnbgprcaucmic 0.69376, vnbgprcaucmac 0.34659, 25.41 secs\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.88917, y8_loss 1.95035, y8box_loss 0.55871, y8cls_loss 0.46982, y8dfl_loss 0.92182, vnbgprcaucmic 0.99900, vnbgprcaucmac 0.99822, vnbgl_loss 2.00914, 308.17 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35826, vnbgbbmf1 0.26577, vnbglaucmic 0.94535, vnbglaucmac 0.84291, vnbgprcaucmic 0.69981, vnbgprcaucmac 0.34992, 26.34 secs\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 2.17618, y8_loss 3.30122, y8box_loss 1.10813, y8cls_loss 1.00247, y8dfl_loss 1.19062, vnbgprcaucmic 0.97135, vnbgprcaucmac 0.95120, vnbgl_loss 3.62249, 315.02 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.00000, vnbgbbmf1 0.00000, vnbglaucmic 0.73480, vnbglaucmac 0.56521, vnbgprcaucmic 0.36402, vnbgprcaucmac 0.09945, 22.99 secs\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 3.51749, y8_loss 2.68889, y8box_loss 0.89688, y8cls_loss 0.72497, y8dfl_loss 1.06704, vnbgprcaucmic 0.99084, vnbgprcaucmac 0.98501, vnbgl_loss 2.86225, 301.29 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.00963, vnbgbbmf1 0.00040, vnbglaucmic 0.75334, vnbglaucmac 0.46982, vnbgprcaucmic 0.30623, vnbgprcaucmac 0.07845, 23.96 secs\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.75712, y8_loss 2.22444, y8box_loss 0.70598, y8cls_loss 0.54823, y8dfl_loss 0.97023, vnbgprcaucmic 0.99731, vnbgprcaucmac 0.99605, vnbgl_loss 2.31314, 298.25 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.25046, vnbgbbmf1 0.06088, vnbglaucmic 0.83876, vnbglaucmac 0.68013, vnbgprcaucmic 0.51300, vnbgprcaucmac 0.16463, 24.09 secs\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 2.17362, y8_loss 2.01084, y8box_loss 0.60350, y8cls_loss 0.47575, y8dfl_loss 0.93159, vnbgprcaucmic 0.99868, vnbgprcaucmac 0.99818, vnbgl_loss 2.07288, 300.33 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30638, vnbgbbmf1 0.20183, vnbglaucmic 0.91975, vnbglaucmac 0.79264, vnbgprcaucmic 0.64720, vnbgprcaucmac 0.28636, 23.35 secs\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 2.06281, y8_loss 1.92194, y8box_loss 0.55909, y8cls_loss 0.44842, y8dfl_loss 0.91444, vnbgprcaucmic 0.99908, vnbgprcaucmac 0.99858, vnbgl_loss 1.97486, 302.09 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35641, vnbgbbmf1 0.24230, vnbglaucmic 0.93552, vnbglaucmac 0.83647, vnbgprcaucmic 0.67828, vnbgprcaucmac 0.32310, 26.21 secs\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.91329, y8_loss 1.85793, y8box_loss 0.52803, y8cls_loss 0.42681, y8dfl_loss 0.90308, vnbgprcaucmic 0.99926, vnbgprcaucmac 0.99891, vnbgl_loss 1.90509, 292.42 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.37348, vnbgbbmf1 0.26475, vnbglaucmic 0.94317, vnbglaucmac 0.83735, vnbgprcaucmic 0.69847, vnbgprcaucmac 0.35158, 22.31 secs\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.79567, y8_loss 1.82876, y8box_loss 0.51246, y8cls_loss 0.41713, y8dfl_loss 0.89917, vnbgprcaucmic 0.99940, vnbgprcaucmac 0.99905, vnbgl_loss 1.87160, 244.90 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.36509, vnbgbbmf1 0.27611, vnbglaucmic 0.94492, vnbglaucmac 0.84167, vnbgprcaucmic 0.70409, vnbgprcaucmac 0.35555, 20.74 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.82205, y8_loss 1.82154, y8box_loss 0.50799, y8cls_loss 0.41416, y8dfl_loss 0.89939, vnbgprcaucmic 0.99940, vnbgprcaucmac 0.99910, vnbgl_loss 1.86523, 228.29 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.36941, vnbgbbmf1 0.26577, vnbglaucmic 0.94480, vnbglaucmac 0.84246, vnbgprcaucmic 0.70418, vnbgprcaucmac 0.35622, 20.41 secs\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.76943, y8_loss 3.00300, y8box_loss 1.00258, y8cls_loss 0.87228, y8dfl_loss 1.12814, vnbgprcaucmic 0.97869, vnbgprcaucmac 0.96098, vnbgl_loss 3.27780, 226.36 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.00000, vnbgbbmf1 0.00000, vnbglaucmic 0.71727, vnbglaucmac 0.55248, vnbgprcaucmic 0.19957, vnbgprcaucmac 0.08643, 17.40 secs\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 3.30414, y8_loss 2.46471, y8box_loss 0.81394, y8cls_loss 0.62969, y8dfl_loss 1.02109, vnbgprcaucmic 0.99396, vnbgprcaucmac 0.99124, vnbgl_loss 2.59949, 226.24 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.16406, vnbgbbmf1 0.03218, vnbglaucmic 0.82563, vnbglaucmac 0.67804, vnbgprcaucmic 0.47980, vnbgprcaucmac 0.15762, 18.12 secs\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.18393, y8_loss 2.05932, y8box_loss 0.63685, y8cls_loss 0.48388, y8dfl_loss 0.93859, vnbgprcaucmic 0.99828, vnbgprcaucmac 0.99730, vnbgl_loss 2.12975, 222.82 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.02183, vnbgbbmf1 0.00460, vnbglaucmic 0.68593, vnbglaucmac 0.55750, vnbgprcaucmic 0.13189, vnbgprcaucmac 0.10854, 19.31 secs\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 2.12656, y8_loss 1.89100, y8box_loss 0.55419, y8cls_loss 0.42952, y8dfl_loss 0.90730, vnbgprcaucmic 0.99912, vnbgprcaucmac 0.99858, vnbgl_loss 1.94168, 227.47 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.28207, vnbgbbmf1 0.20321, vnbglaucmic 0.90565, vnbglaucmac 0.76500, vnbgprcaucmic 0.60329, vnbgprcaucmac 0.28636, 20.36 secs\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.77093, y8_loss 1.79289, y8box_loss 0.50496, y8cls_loss 0.39726, y8dfl_loss 0.89066, vnbgprcaucmic 0.99942, vnbgprcaucmac 0.99911, vnbgl_loss 1.83380, 218.48 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.38484, vnbgbbmf1 0.24071, vnbglaucmic 0.93152, vnbglaucmac 0.81195, vnbgprcaucmic 0.67142, vnbgprcaucmac 0.32213, 19.51 secs\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.83515, y8_loss 1.75172, y8box_loss 0.48357, y8cls_loss 0.38386, y8dfl_loss 0.88429, vnbgprcaucmic 0.99952, vnbgprcaucmac 0.99926, vnbgl_loss 1.78905, 218.58 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.37048, vnbgbbmf1 0.25916, vnbglaucmic 0.93763, vnbglaucmac 0.81627, vnbgprcaucmic 0.68734, vnbgprcaucmac 0.33327, 19.85 secs\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.91424, y8_loss 1.72491, y8box_loss 0.46819, y8cls_loss 0.37518, y8dfl_loss 0.88153, vnbgprcaucmic 0.99967, vnbgprcaucmac 0.99957, vnbgl_loss 1.75703, 218.19 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.38486, vnbgbbmf1 0.26755, vnbglaucmic 0.93520, vnbglaucmac 0.82136, vnbgprcaucmic 0.68233, vnbgprcaucmac 0.34407, 19.59 secs\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.78538, y8_loss 1.70213, y8box_loss 0.45684, y8cls_loss 0.36834, y8dfl_loss 0.87695, vnbgprcaucmic 0.99963, vnbgprcaucmac 0.99951, vnbgl_loss 1.73441, 230.38 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.37983, vnbgbbmf1 0.26203, vnbglaucmic 0.93652, vnbglaucmac 0.82289, vnbgprcaucmic 0.68442, vnbgprcaucmac 0.34566, 19.38 secs\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.63492, y8_loss 2.73104, y8box_loss 0.91025, y8cls_loss 0.74897, y8dfl_loss 1.07183, vnbgprcaucmic 0.98642, vnbgprcaucmac 0.97794, vnbgl_loss 2.93708, 220.78 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.01067, vnbgbbmf1 0.00043, vnbglaucmic 0.50484, vnbglaucmac 0.48488, vnbgprcaucmic 0.08146, vnbgprcaucmac 0.08918, 18.48 secs\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 3.16060, y8_loss 2.32990, y8box_loss 0.76299, y8cls_loss 0.57479, y8dfl_loss 0.99211, vnbgprcaucmic 0.99551, vnbgprcaucmac 0.99258, vnbgl_loss 2.44806, 204.03 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.15677, vnbgbbmf1 0.00383, vnbglaucmic 0.79823, vnbglaucmac 0.60681, vnbgprcaucmic 0.44688, vnbgprcaucmac 0.11518, 16.00 secs\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.30858, y8_loss 1.95496, y8box_loss 0.59632, y8cls_loss 0.43901, y8dfl_loss 0.91963, vnbgprcaucmic 0.99882, vnbgprcaucmac 0.99815, vnbgl_loss 2.01187, 190.28 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.35029, vnbgbbmf1 0.10370, vnbglaucmic 0.85852, vnbglaucmac 0.71866, vnbgprcaucmic 0.53848, vnbgprcaucmac 0.21204, 16.68 secs\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 2.01489, y8_loss 1.79786, y8box_loss 0.51715, y8cls_loss 0.39034, y8dfl_loss 0.89036, vnbgprcaucmic 0.99941, vnbgprcaucmac 0.99889, vnbgl_loss 1.83908, 174.96 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.41700, vnbgbbmf1 0.18141, vnbglaucmic 0.90110, vnbglaucmac 0.78981, vnbgprcaucmic 0.62144, vnbgprcaucmac 0.27878, 16.61 secs\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.86913, y8_loss 1.70648, y8box_loss 0.46906, y8cls_loss 0.36139, y8dfl_loss 0.87602, vnbgprcaucmic 0.99964, vnbgprcaucmac 0.99944, vnbgl_loss 1.73910, 171.77 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.36867, vnbgbbmf1 0.25666, vnbglaucmic 0.91903, vnbglaucmac 0.81136, vnbgprcaucmic 0.65499, vnbgprcaucmac 0.32922, 17.59 secs\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.55625, y8_loss 1.66807, y8box_loss 0.44765, y8cls_loss 0.35046, y8dfl_loss 0.86996, vnbgprcaucmic 0.99968, vnbgprcaucmac 0.99955, vnbgl_loss 1.69699, 170.71 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.37574, vnbgbbmf1 0.26370, vnbglaucmic 0.92489, vnbglaucmac 0.82385, vnbgprcaucmic 0.66762, vnbgprcaucmac 0.33554, 17.01 secs\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.70948, y8_loss 1.64974, y8box_loss 0.43767, y8cls_loss 0.34455, y8dfl_loss 0.86752, vnbgprcaucmic 0.99972, vnbgprcaucmac 0.99961, vnbgl_loss 1.67763, 173.39 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.38332, vnbgbbmf1 0.26614, vnbglaucmic 0.92959, vnbglaucmac 0.83051, vnbgprcaucmic 0.67440, vnbgprcaucmac 0.33976, 16.98 secs\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.68244, y8_loss 1.63641, y8box_loss 0.43116, y8cls_loss 0.33995, y8dfl_loss 0.86530, vnbgprcaucmic 0.99976, vnbgprcaucmac 0.99958, vnbgl_loss 1.66305, 171.96 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.38354, vnbgbbmf1 0.27312, vnbglaucmic 0.93196, vnbglaucmac 0.83682, vnbgprcaucmic 0.67760, vnbgprcaucmac 0.34675, 17.03 secs\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.83454, y8_loss 2.52890, y8box_loss 0.83556, y8cls_loss 0.66239, y8dfl_loss 1.03095, vnbgprcaucmic 0.99047, vnbgprcaucmac 0.98450, vnbgl_loss 2.69643, 172.83 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.02268, vnbgbbmf1 0.00000, vnbglaucmic 0.76574, vnbglaucmac 0.52472, vnbgprcaucmic 0.36289, vnbgprcaucmac 0.09112, 15.90 secs\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 2.96967, y8_loss 2.19803, y8box_loss 0.70883, y8cls_loss 0.52314, y8dfl_loss 0.96606, vnbgprcaucmic 0.99702, vnbgprcaucmac 0.99495, vnbgl_loss 2.29242, 173.71 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.04469, vnbgbbmf1 0.00394, vnbglaucmic 0.76869, vnbglaucmac 0.56270, vnbgprcaucmic 0.35132, vnbgprcaucmac 0.10071, 16.33 secs\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.07692, y8_loss 1.85502, y8box_loss 0.55316, y8cls_loss 0.40290, y8dfl_loss 0.89897, vnbgprcaucmic 0.99921, vnbgprcaucmac 0.99880, vnbgl_loss 1.90074, 170.72 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.26523, vnbgbbmf1 0.07938, vnbglaucmic 0.81478, vnbglaucmac 0.65808, vnbgprcaucmic 0.48490, vnbgprcaucmac 0.16971, 16.72 secs\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.71528, y8_loss 1.70621, y8box_loss 0.47501, y8cls_loss 0.35674, y8dfl_loss 0.87446, vnbgprcaucmic 0.99963, vnbgprcaucmac 0.99949, vnbgl_loss 1.73818, 171.15 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.04410, vnbgbbmf1 0.01132, vnbglaucmic 0.80081, vnbglaucmac 0.64587, vnbgprcaucmic 0.32797, vnbgprcaucmac 0.14673, 15.89 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.57323, y8_loss 1.63851, y8box_loss 0.43910, y8cls_loss 0.33516, y8dfl_loss 0.86425, vnbgprcaucmic 0.99975, vnbgprcaucmac 0.99959, vnbgl_loss 1.66425, 171.47 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.42512, vnbgbbmf1 0.19191, vnbglaucmic 0.91651, vnbglaucmac 0.81074, vnbgprcaucmic 0.64962, vnbgprcaucmac 0.29242, 16.43 secs\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.50617, y8_loss 1.62303, y8box_loss 0.43057, y8cls_loss 0.33010, y8dfl_loss 0.86236, vnbgprcaucmic 0.99977, vnbgprcaucmac 0.99970, vnbgl_loss 1.64721, 170.89 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.36461, vnbgbbmf1 0.25206, vnbglaucmic 0.92529, vnbglaucmac 0.81735, vnbgprcaucmic 0.67519, vnbgprcaucmac 0.33678, 17.41 secs\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.63257, y8_loss 1.58674, y8box_loss 0.41126, y8cls_loss 0.31953, y8dfl_loss 0.85595, vnbgprcaucmic 0.99983, vnbgprcaucmac 0.99974, vnbgl_loss 1.60760, 167.31 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.38704, vnbgbbmf1 0.24420, vnbglaucmic 0.92867, vnbglaucmac 0.82326, vnbgprcaucmic 0.67997, vnbgprcaucmac 0.34028, 16.80 secs\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.42411, y8_loss 1.58003, y8box_loss 0.40716, y8cls_loss 0.31766, y8dfl_loss 0.85522, vnbgprcaucmic 0.99981, vnbgprcaucmac 0.99975, vnbgl_loss 1.60149, 170.44 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.38088, vnbgbbmf1 0.25037, vnbglaucmic 0.92923, vnbglaucmac 0.82070, vnbgprcaucmic 0.68201, vnbgprcaucmac 0.34252, 17.45 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 80 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-decay-and-cyclic-decay-args \"1e-6,3,3e-4,8,2e-6,3e-4,8,3e-6\" \\\n",
    "        --use-vinbig \\\n",
    "        --vinbig-use-validation \\\n",
    "        --vinbig-weight 1.0 \\\n",
    "        --predict-bboxes-vinbig \\\n",
    "        --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "        --raw-image-encoding \"yolov8\" \\\n",
    "        --yolov8-model-name-or-path \"yolov8l.pt\" \\\n",
    "        --yolov8-model-alias \"yolov8l\" \\\n",
    "        --image-size 416 416 \\\n",
    "        --image-local-feat-size 512 \\\n",
    "        --num-regions 169 \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
