{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: yolov8\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: yolov8l.pt\n",
      "   yolov8_model_alias: yolov8l\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   batch_size: 28\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 1.0\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230523_133812_mim_Image2ReportModel(yolov8l->TransfTextDec(posenc(learned),es=512,hs=512,nl=3,nh=4,dff=512))\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: train\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: True\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: yolov8\n",
      "  num_bbox_classes: 22\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.Detect                [22, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43646802 parameters, 43646786 gradients, 165.5 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "    Initializing VinBig classification task\n",
      "MultilabelClassifier_v3:\n",
      "  local_feat_dim: 512\n",
      "  global_feat_dim: 1024\n",
      "  hidden_dim: 128\n",
      "  num_regions: 169\n",
      "  num_labels: 28\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    for_vinbig: returning vinbig transform\n",
      "    len(_augmented_bbox_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "  Loaded 18000 bounding boxes\n",
      "  self.bboxes[0]: ([], [])\n",
      "  self.bboxes[-1]: ([], [])\n",
      "  self.bboxes[500]: ([], [])\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=10601, #neg=4399\n",
      "Other disease     , #pos=4288, #neg=10712\n",
      "Aortic enlargement, #pos=3067, #neg=11933\n",
      "Cardiomegaly      , #pos=2300, #neg=12700\n",
      "Pleural thickening, #pos=1981, #neg=13019\n",
      "Pulmonary fibrosis, #pos=1617, #neg=13383\n",
      "Lung Opacity      , #pos=1322, #neg=13678\n",
      "Other lesion      , #pos=1134, #neg=13866\n",
      "Pleural effusion  , #pos=1032, #neg=13968\n",
      "Pneumonia         , #pos=917, #neg=14083\n",
      "Nodule/Mass       , #pos=830, #neg=14170\n",
      "Tuberculosis      , #pos=750, #neg=14250\n",
      "Infiltration      , #pos=613, #neg=14387\n",
      "Calcification     , #pos=452, #neg=14548\n",
      "ILD               , #pos=386, #neg=14614\n",
      "Consolidation     , #pos=353, #neg=14647\n",
      "Lung tumor        , #pos=291, #neg=14709\n",
      "Atelectasis       , #pos=186, #neg=14814\n",
      "Mediastinal shift , #pos=150, #neg=14850\n",
      "Enlarged PA       , #pos=131, #neg=14869\n",
      "Pneumothorax      , #pos=96, #neg=14904\n",
      "Rib fracture      , #pos=90, #neg=14910\n",
      "Emphysema         , #pos=78, #neg=14922\n",
      "Lung cavity       , #pos=50, #neg=14950\n",
      "COPD              , #pos=35, #neg=14965\n",
      "Lung cyst         , #pos=32, #neg=14968\n",
      "Clavicle fracture , #pos=27, #neg=14973\n",
      "Edema             , #pos=13, #neg=14987\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_232710_vinbig_yolov8l\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_232710_vinbig_yolov8l/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_26_chou+chuc+chuc+chuc+chuc+cD+gacc+lfss+wmmp=0.7107.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230523_133812_mim_Image2ReportModel(yolov8l->TransfTextDec(posenc(learned),es=512,hs=512,nl=3,nh=4,dff=512))/checkpoint_26_chou+chuc+chuc+chuc+chuc+cD+gacc+lfss+wmmp=0.7107.pt\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.0.2.weight, required shape: torch.Size([22, 256, 1, 1]), loaded shape: torch.Size([36, 256, 1, 1])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.0.2.bias, required shape: torch.Size([22]), loaded shape: torch.Size([36])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.1.2.weight, required shape: torch.Size([22, 256, 1, 1]), loaded shape: torch.Size([36, 256, 1, 1])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.1.2.bias, required shape: torch.Size([22]), loaded shape: torch.Size([36])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.2.2.weight, required shape: torch.Size([22, 256, 1, 1]), loaded shape: torch.Size([36, 256, 1, 1])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.2.2.bias, required shape: torch.Size([22]), loaded shape: torch.Size([36])\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_232710_vinbig_yolov8l/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 14.38947, y8_loss 11.74811, y8box_loss 2.93034, y8cls_loss 5.54899, y8dfl_loss 3.26878, vnbgprcaucmic 0.15037, vnbgprcaucmac 0.15824, vnbgl_loss 13.52330, 104.01 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.00849, vnbgbbmf1 0.00069, vnbglaucmic 0.57465, vnbglaucmac 0.56658, vnbgprcaucmic 0.09198, vnbgprcaucmac 0.10269, 26.18 secs\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 12.68537, y8_loss 9.71402, y8box_loss 2.49166, y8cls_loss 4.65153, y8dfl_loss 2.57083, vnbgprcaucmic 0.32278, vnbgprcaucmac 0.19002, vnbgl_loss 11.23779, 100.21 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.08439, vnbgbbmf1 0.01585, vnbglaucmic 0.90628, vnbglaucmac 0.81008, vnbgprcaucmic 0.50824, vnbgprcaucmac 0.18334, 30.27 secs\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 10.26214, y8_loss 6.99229, y8box_loss 2.09096, y8cls_loss 2.99352, y8dfl_loss 1.90782, vnbgprcaucmic 0.70244, vnbgprcaucmac 0.35656, vnbgl_loss 8.22159, 101.49 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.19859, vnbgbbmf1 0.10074, vnbglaucmic 0.94878, vnbglaucmac 0.88653, vnbgprcaucmic 0.67792, vnbgprcaucmac 0.27407, 28.85 secs\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 6.60127, y8_loss 5.69101, y8box_loss 1.82555, y8cls_loss 2.22583, y8dfl_loss 1.63963, vnbgprcaucmic 0.81369, vnbgprcaucmac 0.49026, vnbgl_loss 6.65013, 102.60 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.21933, vnbgbbmf1 0.13781, vnbglaucmic 0.92277, vnbglaucmac 0.83813, vnbgprcaucmic 0.61753, vnbgprcaucmac 0.29065, 27.26 secs\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 6.44913, y8_loss 5.07347, y8box_loss 1.64910, y8cls_loss 1.90565, y8dfl_loss 1.51872, vnbgprcaucmic 0.86912, vnbgprcaucmac 0.62616, vnbgl_loss 5.87889, 102.57 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.17151, vnbgbbmf1 0.09854, vnbglaucmic 0.91318, vnbglaucmac 0.84710, vnbgprcaucmic 0.60138, vnbgprcaucmac 0.24925, 29.36 secs\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 5.63365, y8_loss 4.73856, y8box_loss 1.54520, y8cls_loss 1.74123, y8dfl_loss 1.45213, vnbgprcaucmic 0.89869, vnbgprcaucmac 0.70279, vnbgl_loss 5.43813, 102.97 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32817, vnbgbbmf1 0.22676, vnbglaucmic 0.94541, vnbglaucmac 0.89287, vnbgprcaucmic 0.71602, vnbgprcaucmac 0.32953, 27.58 secs\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 5.14857, y8_loss 4.54247, y8box_loss 1.48023, y8cls_loss 1.65043, y8dfl_loss 1.41181, vnbgprcaucmic 0.91353, vnbgprcaucmac 0.74529, vnbgl_loss 5.18857, 103.63 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31125, vnbgbbmf1 0.22775, vnbglaucmic 0.94361, vnbglaucmac 0.87851, vnbgprcaucmic 0.71812, vnbgprcaucmac 0.34448, 27.76 secs\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 5.20267, y8_loss 4.38324, y8box_loss 1.42416, y8cls_loss 1.58410, y8dfl_loss 1.37499, vnbgprcaucmic 0.92836, vnbgprcaucmac 0.78242, vnbgl_loss 4.98010, 104.22 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.29425, vnbgbbmf1 0.23929, vnbglaucmic 0.94812, vnbglaucmac 0.87708, vnbgprcaucmic 0.72607, vnbgprcaucmac 0.35314, 28.48 secs\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.81330, y8_loss 4.27636, y8box_loss 1.38450, y8cls_loss 1.54239, y8dfl_loss 1.34948, vnbgprcaucmic 0.93149, vnbgprcaucmac 0.78962, vnbgl_loss 4.85854, 106.66 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30440, vnbgbbmf1 0.25564, vnbglaucmic 0.95348, vnbglaucmac 0.89046, vnbgprcaucmic 0.73382, vnbgprcaucmac 0.35801, 30.13 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.63040, y8_loss 4.20871, y8box_loss 1.36104, y8cls_loss 1.51083, y8dfl_loss 1.33683, vnbgprcaucmic 0.93544, vnbgprcaucmac 0.80698, vnbgl_loss 4.76672, 111.32 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31294, vnbgbbmf1 0.25247, vnbglaucmic 0.95121, vnbglaucmac 0.89124, vnbgprcaucmic 0.72963, vnbgprcaucmac 0.35497, 31.47 secs\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.83185, y8_loss 4.17449, y8box_loss 1.34590, y8cls_loss 1.49763, y8dfl_loss 1.33097, vnbgprcaucmic 0.93842, vnbgprcaucmac 0.82226, vnbgl_loss 4.72136, 117.73 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31604, vnbgbbmf1 0.25560, vnbglaucmic 0.95183, vnbglaucmac 0.89217, vnbgprcaucmic 0.73360, vnbgprcaucmac 0.35649, 33.10 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.63054, y8_loss 4.16167, y8box_loss 1.34082, y8cls_loss 1.48976, y8dfl_loss 1.33109, vnbgprcaucmic 0.93927, vnbgprcaucmac 0.81249, vnbgl_loss 4.70482, 113.99 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31702, vnbgbbmf1 0.25528, vnbglaucmic 0.95203, vnbglaucmac 0.89110, vnbgprcaucmic 0.73366, vnbgprcaucmac 0.35721, 31.13 secs\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.86479, y8_loss 4.54670, y8box_loss 1.49714, y8cls_loss 1.62728, y8dfl_loss 1.42229, vnbgprcaucmic 0.91072, vnbgprcaucmac 0.76169, vnbgl_loss 5.16452, 117.43 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.01507, vnbgbbmf1 0.00223, vnbglaucmic 0.82010, vnbglaucmac 0.64758, vnbgprcaucmic 0.45753, vnbgprcaucmac 0.11719, 28.53 secs\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.67724, y8_loss 4.22111, y8box_loss 1.39985, y8cls_loss 1.46601, y8dfl_loss 1.35524, vnbgprcaucmic 0.94017, vnbgprcaucmac 0.85110, vnbgl_loss 4.72324, 117.32 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.03584, vnbgbbmf1 0.00673, vnbglaucmic 0.79970, vnbglaucmac 0.61834, vnbgprcaucmic 0.41008, vnbgprcaucmac 0.11152, 29.87 secs\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.26295, y8_loss 3.89640, y8box_loss 1.29530, y8cls_loss 1.31294, y8dfl_loss 1.28816, vnbgprcaucmic 0.95649, vnbgprcaucmac 0.89520, vnbgl_loss 4.31891, 120.73 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.25022, vnbgbbmf1 0.22422, vnbglaucmic 0.94711, vnbglaucmac 0.87907, vnbgprcaucmic 0.70951, vnbgprcaucmac 0.34083, 32.69 secs\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.82893, y8_loss 3.66612, y8box_loss 1.20529, y8cls_loss 1.22088, y8dfl_loss 1.23995, vnbgprcaucmic 0.96717, vnbgprcaucmac 0.92748, vnbgl_loss 4.03571, 119.02 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32076, vnbgbbmf1 0.26122, vnbglaucmic 0.95054, vnbglaucmac 0.87822, vnbgprcaucmic 0.73249, vnbgprcaucmac 0.39446, 31.86 secs\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.78210, y8_loss 3.56389, y8box_loss 1.16334, y8cls_loss 1.18107, y8dfl_loss 1.21947, vnbgprcaucmic 0.97160, vnbgprcaucmac 0.93891, vnbgl_loss 3.90381, 112.27 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31495, vnbgbbmf1 0.26679, vnbglaucmic 0.95329, vnbglaucmac 0.87874, vnbgprcaucmic 0.72633, vnbgprcaucmac 0.36856, 31.80 secs\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.75056, y8_loss 3.48077, y8box_loss 1.13145, y8cls_loss 1.14655, y8dfl_loss 1.20276, vnbgprcaucmic 0.97272, vnbgprcaucmac 0.94200, vnbgl_loss 3.81269, 110.26 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31197, vnbgbbmf1 0.26747, vnbglaucmic 0.95251, vnbglaucmac 0.87323, vnbgprcaucmic 0.72826, vnbgprcaucmac 0.36795, 31.16 secs\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.63474, y8_loss 3.43023, y8box_loss 1.11191, y8cls_loss 1.12676, y8dfl_loss 1.19157, vnbgprcaucmic 0.97640, vnbgprcaucmac 0.94547, vnbgl_loss 3.74795, 113.59 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30989, vnbgbbmf1 0.26494, vnbglaucmic 0.95258, vnbglaucmac 0.87279, vnbgprcaucmic 0.72595, vnbgprcaucmac 0.36582, 31.23 secs\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.60456, y8_loss 3.43617, y8box_loss 1.11126, y8cls_loss 1.12952, y8dfl_loss 1.19539, vnbgprcaucmic 0.97616, vnbgprcaucmac 0.94698, vnbgl_loss 3.75151, 125.41 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31558, vnbgbbmf1 0.26546, vnbglaucmic 0.95186, vnbglaucmac 0.87015, vnbgprcaucmic 0.72392, vnbgprcaucmac 0.36607, 33.38 secs\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.95236, y8_loss 3.94896, y8box_loss 1.32665, y8cls_loss 1.32175, y8dfl_loss 1.30056, vnbgprcaucmic 0.95074, vnbgprcaucmac 0.88395, vnbgl_loss 4.37222, 124.70 secs\n",
      "(2) Validation stage ...\n",
      "WARNING: Bbox IOU defaulting to 0 since self._count is 0\n",
      "vnbgbbiou 0.00000, vnbgbbmf1 0.00000, vnbglaucmic 0.79689, vnbglaucmac 0.56987, vnbgprcaucmic 0.38662, vnbgprcaucmac 0.08843, 28.84 secs\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.05927, y8_loss 3.72358, y8box_loss 1.25082, y8cls_loss 1.20920, y8dfl_loss 1.26356, vnbgprcaucmic 0.96495, vnbgprcaucmac 0.92941, vnbgl_loss 4.07860, 114.75 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.24775, vnbgbbmf1 0.20651, vnbglaucmic 0.93749, vnbglaucmac 0.85900, vnbgprcaucmic 0.67972, vnbgprcaucmac 0.33427, 31.54 secs\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.73710, y8_loss 3.36111, y8box_loss 1.12051, y8cls_loss 1.05961, y8dfl_loss 1.18099, vnbgprcaucmic 0.97923, vnbgprcaucmac 0.96194, vnbgl_loss 3.63419, 115.86 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.29038, vnbgbbmf1 0.25702, vnbglaucmic 0.95134, vnbglaucmac 0.87362, vnbgprcaucmic 0.70676, vnbgprcaucmac 0.39432, 33.16 secs\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.58167, y8_loss 3.19416, y8box_loss 1.05182, y8cls_loss 0.99730, y8dfl_loss 1.14505, vnbgprcaucmic 0.98442, vnbgprcaucmac 0.97198, vnbgl_loss 3.43199, 116.75 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30204, vnbgbbmf1 0.25216, vnbglaucmic 0.95030, vnbglaucmac 0.84929, vnbgprcaucmic 0.71438, vnbgprcaucmac 0.35683, 30.69 secs\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.36784, y8_loss 3.06543, y8box_loss 0.99977, y8cls_loss 0.94156, y8dfl_loss 1.12411, vnbgprcaucmic 0.98804, vnbgprcaucmac 0.98053, vnbgl_loss 3.28016, 125.22 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31720, vnbgbbmf1 0.27406, vnbglaucmic 0.95251, vnbglaucmac 0.85324, vnbgprcaucmic 0.71336, vnbgprcaucmac 0.36818, 32.15 secs\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.99535, y8_loss 3.00829, y8box_loss 0.97605, y8cls_loss 0.92213, y8dfl_loss 1.11012, vnbgprcaucmic 0.98884, vnbgprcaucmac 0.98197, vnbgl_loss 3.21473, 116.26 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31527, vnbgbbmf1 0.26880, vnbglaucmic 0.95202, vnbglaucmac 0.87172, vnbgprcaucmic 0.71977, vnbgprcaucmac 0.37291, 31.30 secs\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.96021, y8_loss 2.94804, y8box_loss 0.95154, y8cls_loss 0.90062, y8dfl_loss 1.09588, vnbgprcaucmic 0.98974, vnbgprcaucmac 0.98233, vnbgl_loss 3.14739, 111.60 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31220, vnbgbbmf1 0.26341, vnbglaucmic 0.95270, vnbglaucmac 0.86578, vnbgprcaucmic 0.71834, vnbgprcaucmac 0.37256, 31.43 secs\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.15768, y8_loss 2.95101, y8box_loss 0.95083, y8cls_loss 0.89984, y8dfl_loss 1.10033, vnbgprcaucmic 0.98991, vnbgprcaucmac 0.98420, vnbgl_loss 3.14888, 115.63 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31221, vnbgbbmf1 0.26977, vnbglaucmic 0.95246, vnbglaucmac 0.86534, vnbgprcaucmic 0.71490, vnbgprcaucmac 0.37427, 32.12 secs\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.46464, y8_loss 3.47550, y8box_loss 1.17570, y8cls_loss 1.09435, y8dfl_loss 1.20546, vnbgprcaucmic 0.97345, vnbgprcaucmac 0.94857, vnbgl_loss 3.76455, 121.69 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.06876, vnbgbbmf1 0.07512, vnbglaucmic 0.81851, vnbglaucmac 0.64741, vnbgprcaucmic 0.35415, vnbgprcaucmac 0.17336, 37.00 secs\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.81621, y8_loss 3.32570, y8box_loss 1.12862, y8cls_loss 1.01623, y8dfl_loss 1.18085, vnbgprcaucmic 0.97994, vnbgprcaucmac 0.96443, vnbgl_loss 3.57934, 123.34 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30426, vnbgbbmf1 0.22398, vnbglaucmic 0.93932, vnbglaucmac 0.86266, vnbgprcaucmic 0.71635, vnbgprcaucmac 0.37202, 31.90 secs\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.86737, y8_loss 3.00845, y8box_loss 1.00667, y8cls_loss 0.88954, y8dfl_loss 1.11225, vnbgprcaucmic 0.98869, vnbgprcaucmac 0.98111, vnbgl_loss 3.20008, 115.35 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31807, vnbgbbmf1 0.25933, vnbglaucmic 0.95124, vnbglaucmac 0.85438, vnbgprcaucmic 0.72497, vnbgprcaucmac 0.35033, 31.02 secs\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.96866, y8_loss 2.84505, y8box_loss 0.93283, y8cls_loss 0.83368, y8dfl_loss 1.07855, vnbgprcaucmic 0.99268, vnbgprcaucmac 0.98893, vnbgl_loss 3.00338, 114.39 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31711, vnbgbbmf1 0.28763, vnbglaucmic 0.95157, vnbglaucmac 0.86388, vnbgprcaucmic 0.71967, vnbgprcaucmac 0.36891, 31.51 secs\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.57780, y8_loss 2.73056, y8box_loss 0.88655, y8cls_loss 0.78813, y8dfl_loss 1.05587, vnbgprcaucmic 0.99407, vnbgprcaucmac 0.99014, vnbgl_loss 2.87566, 114.96 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31640, vnbgbbmf1 0.28845, vnbglaucmic 0.95073, vnbglaucmac 0.84272, vnbgprcaucmic 0.71346, vnbgprcaucmac 0.36330, 33.86 secs\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.95377, y8_loss 2.69914, y8box_loss 0.86845, y8cls_loss 0.78124, y8dfl_loss 1.04945, vnbgprcaucmic 0.99417, vnbgprcaucmac 0.99054, vnbgl_loss 2.84105, 124.48 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31737, vnbgbbmf1 0.28593, vnbglaucmic 0.94989, vnbglaucmac 0.84276, vnbgprcaucmic 0.70887, vnbgprcaucmac 0.36656, 32.71 secs\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.63032, y8_loss 2.63625, y8box_loss 0.83980, y8cls_loss 0.76015, y8dfl_loss 1.03630, vnbgprcaucmic 0.99532, vnbgprcaucmac 0.99331, vnbgl_loss 2.77058, 120.85 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31679, vnbgbbmf1 0.28348, vnbglaucmic 0.95062, vnbglaucmac 0.84142, vnbgprcaucmic 0.70702, vnbgprcaucmac 0.36679, 31.21 secs\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.04657, y8_loss 2.65094, y8box_loss 0.84254, y8cls_loss 0.76511, y8dfl_loss 1.04329, vnbgprcaucmic 0.99537, vnbgprcaucmac 0.99314, vnbgl_loss 2.78124, 115.75 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31698, vnbgbbmf1 0.28830, vnbglaucmic 0.95052, vnbglaucmac 0.84157, vnbgprcaucmic 0.70822, vnbgprcaucmac 0.36730, 31.31 secs\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 2.89608, y8_loss 3.14202, y8box_loss 1.06361, y8cls_loss 0.94018, y8dfl_loss 1.13823, vnbgprcaucmic 0.98375, vnbgprcaucmac 0.96925, vnbgl_loss 3.35840, 119.11 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.11242, vnbgbbmf1 0.10707, vnbglaucmic 0.87612, vnbglaucmac 0.73959, vnbgprcaucmic 0.51056, vnbgprcaucmac 0.24208, 35.07 secs\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.83816, y8_loss 3.03151, y8box_loss 1.03065, y8cls_loss 0.88207, y8dfl_loss 1.11879, vnbgprcaucmic 0.98847, vnbgprcaucmac 0.98030, vnbgl_loss 3.21788, 121.10 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.10510, vnbgbbmf1 0.10847, vnbglaucmic 0.89024, vnbglaucmac 0.78490, vnbgprcaucmic 0.60476, vnbgprcaucmac 0.23301, 34.71 secs\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.07429, y8_loss 2.77668, y8box_loss 0.92543, y8cls_loss 0.78428, y8dfl_loss 1.06697, vnbgprcaucmic 0.99310, vnbgprcaucmac 0.98839, vnbgl_loss 2.92249, 116.86 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.30760, vnbgbbmf1 0.26518, vnbglaucmic 0.94861, vnbglaucmac 0.84458, vnbgprcaucmic 0.71699, vnbgprcaucmac 0.36333, 31.53 secs\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.98326, y8_loss 2.60276, y8box_loss 0.84936, y8cls_loss 0.72343, y8dfl_loss 1.02998, vnbgprcaucmic 0.99566, vnbgprcaucmac 0.99280, vnbgl_loss 2.72219, 114.41 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31854, vnbgbbmf1 0.26766, vnbglaucmic 0.95149, vnbglaucmac 0.84250, vnbgprcaucmic 0.70321, vnbgprcaucmac 0.36235, 31.87 secs\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.91200, y8_loss 2.52177, y8box_loss 0.80755, y8cls_loss 0.69890, y8dfl_loss 1.01531, vnbgprcaucmic 0.99694, vnbgprcaucmac 0.99413, vnbgl_loss 2.62657, 117.25 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32692, vnbgbbmf1 0.27740, vnbglaucmic 0.95079, vnbglaucmac 0.83710, vnbgprcaucmic 0.70343, vnbgprcaucmac 0.36696, 33.27 secs\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.50695, y8_loss 2.45559, y8box_loss 0.77510, y8cls_loss 0.67688, y8dfl_loss 1.00361, vnbgprcaucmic 0.99738, vnbgprcaucmac 0.99597, vnbgl_loss 2.55104, 123.24 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32151, vnbgbbmf1 0.26949, vnbglaucmic 0.95056, vnbglaucmac 0.83955, vnbgprcaucmic 0.70813, vnbgprcaucmac 0.36562, 30.64 secs\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.80474, y8_loss 2.44281, y8box_loss 0.77133, y8cls_loss 0.67288, y8dfl_loss 0.99860, vnbgprcaucmic 0.99783, vnbgprcaucmac 0.99679, vnbgl_loss 2.53631, 126.00 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32341, vnbgbbmf1 0.27189, vnbglaucmic 0.94955, vnbglaucmac 0.83846, vnbgprcaucmic 0.70903, vnbgprcaucmac 0.36659, 32.68 secs\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.67884, y8_loss 2.43692, y8box_loss 0.76614, y8cls_loss 0.67077, y8dfl_loss 1.00002, vnbgprcaucmic 0.99756, vnbgprcaucmac 0.99643, vnbgl_loss 2.53236, 113.47 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31878, vnbgbbmf1 0.27034, vnbglaucmic 0.94983, vnbglaucmac 0.83749, vnbgprcaucmic 0.70565, vnbgprcaucmac 0.36647, 32.03 secs\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 2.39391, y8_loss 2.88557, y8box_loss 0.97558, y8cls_loss 0.81949, y8dfl_loss 1.09050, vnbgprcaucmic 0.99091, vnbgprcaucmac 0.98292, vnbgl_loss 3.04039, 111.55 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.05948, vnbgbbmf1 0.01896, vnbglaucmic 0.82185, vnbglaucmac 0.70462, vnbgprcaucmic 0.39220, vnbgprcaucmac 0.14642, 30.26 secs\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.49174, y8_loss 2.81351, y8box_loss 0.95026, y8cls_loss 0.78669, y8dfl_loss 1.07657, vnbgprcaucmic 0.99166, vnbgprcaucmac 0.98525, vnbgl_loss 2.96732, 119.99 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31109, vnbgbbmf1 0.22675, vnbglaucmic 0.92975, vnbglaucmac 0.85636, vnbgprcaucmic 0.66941, vnbgprcaucmac 0.32606, 31.42 secs\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.55535, y8_loss 2.58340, y8box_loss 0.85133, y8cls_loss 0.70393, y8dfl_loss 1.02815, vnbgprcaucmic 0.99600, vnbgprcaucmac 0.99381, vnbgl_loss 2.69100, 119.23 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32326, vnbgbbmf1 0.27239, vnbglaucmic 0.94470, vnbglaucmac 0.85149, vnbgprcaucmic 0.70956, vnbgprcaucmac 0.35819, 33.45 secs\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.74556, y8_loss 2.43882, y8box_loss 0.78564, y8cls_loss 0.65276, y8dfl_loss 1.00042, vnbgprcaucmic 0.99731, vnbgprcaucmac 0.99642, vnbgl_loss 2.52810, 116.67 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32673, vnbgbbmf1 0.28506, vnbglaucmic 0.95005, vnbglaucmac 0.85163, vnbgprcaucmic 0.71116, vnbgprcaucmac 0.36887, 30.21 secs\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.39029, y8_loss 2.34881, y8box_loss 0.74545, y8cls_loss 0.62464, y8dfl_loss 0.97873, vnbgprcaucmic 0.99828, vnbgprcaucmac 0.99760, vnbgl_loss 2.42377, 109.90 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32611, vnbgbbmf1 0.28265, vnbglaucmic 0.95172, vnbglaucmac 0.84120, vnbgprcaucmic 0.71177, vnbgprcaucmac 0.37097, 30.75 secs\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.18800, y8_loss 2.30345, y8box_loss 0.71811, y8cls_loss 0.60927, y8dfl_loss 0.97607, vnbgprcaucmic 0.99847, vnbgprcaucmac 0.99756, vnbgl_loss 2.37522, 112.24 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32898, vnbgbbmf1 0.28441, vnbglaucmic 0.95203, vnbglaucmac 0.84887, vnbgprcaucmic 0.71120, vnbgprcaucmac 0.37376, 31.11 secs\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.21960, y8_loss 2.28097, y8box_loss 0.70824, y8cls_loss 0.60263, y8dfl_loss 0.97010, vnbgprcaucmic 0.99856, vnbgprcaucmac 0.99806, vnbgl_loss 2.35089, 115.14 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32393, vnbgbbmf1 0.28519, vnbglaucmic 0.95189, vnbglaucmac 0.84116, vnbgprcaucmic 0.70407, vnbgprcaucmac 0.37179, 31.28 secs\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.99870, y8_loss 2.26545, y8box_loss 0.70147, y8cls_loss 0.59759, y8dfl_loss 0.96639, vnbgprcaucmic 0.99858, vnbgprcaucmac 0.99786, vnbgl_loss 2.33643, 120.06 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32483, vnbgbbmf1 0.28138, vnbglaucmic 0.95181, vnbglaucmac 0.84428, vnbgprcaucmic 0.70462, vnbgprcaucmac 0.37200, 32.64 secs\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.32932, y8_loss 2.73848, y8box_loss 0.92385, y8cls_loss 0.75569, y8dfl_loss 1.05895, vnbgprcaucmic 0.99236, vnbgprcaucmac 0.98644, vnbgl_loss 2.87683, 117.04 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.10329, vnbgbbmf1 0.07804, vnbglaucmic 0.87666, vnbglaucmac 0.76647, vnbgprcaucmic 0.46684, vnbgprcaucmac 0.19462, 30.72 secs\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.41851, y8_loss 2.69057, y8box_loss 0.90839, y8cls_loss 0.73058, y8dfl_loss 1.05161, vnbgprcaucmic 0.99443, vnbgprcaucmac 0.99120, vnbgl_loss 2.81470, 115.04 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32158, vnbgbbmf1 0.25267, vnbglaucmic 0.94789, vnbglaucmac 0.86955, vnbgprcaucmic 0.72322, vnbgprcaucmac 0.35616, 31.43 secs\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.71996, y8_loss 2.40707, y8box_loss 0.78140, y8cls_loss 0.63157, y8dfl_loss 0.99410, vnbgprcaucmic 0.99737, vnbgprcaucmac 0.99629, vnbgl_loss 2.49162, 124.51 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33089, vnbgbbmf1 0.28812, vnbglaucmic 0.95112, vnbglaucmac 0.84950, vnbgprcaucmic 0.70886, vnbgprcaucmac 0.37215, 30.75 secs\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.51642, y8_loss 2.29236, y8box_loss 0.72931, y8cls_loss 0.59126, y8dfl_loss 0.97179, vnbgprcaucmic 0.99813, vnbgprcaucmac 0.99700, vnbgl_loss 2.36382, 117.36 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.34483, vnbgbbmf1 0.28127, vnbglaucmic 0.95522, vnbglaucmac 0.85576, vnbgprcaucmic 0.72247, vnbgprcaucmac 0.36888, 33.11 secs\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.42086, y8_loss 2.21574, y8box_loss 0.69261, y8cls_loss 0.56780, y8dfl_loss 0.95533, vnbgprcaucmic 0.99896, vnbgprcaucmac 0.99834, vnbgl_loss 2.27505, 115.44 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.34021, vnbgbbmf1 0.28986, vnbglaucmic 0.95343, vnbglaucmac 0.85084, vnbgprcaucmic 0.71183, vnbgprcaucmac 0.37238, 32.79 secs\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.38568, y8_loss 2.18245, y8box_loss 0.67309, y8cls_loss 0.55771, y8dfl_loss 0.95165, vnbgprcaucmic 0.99897, vnbgprcaucmac 0.99846, vnbgl_loss 2.24009, 114.43 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33263, vnbgbbmf1 0.29361, vnbglaucmic 0.95448, vnbglaucmac 0.84842, vnbgprcaucmic 0.71037, vnbgprcaucmac 0.36933, 30.53 secs\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.21379, y8_loss 2.17042, y8box_loss 0.66655, y8cls_loss 0.55426, y8dfl_loss 0.94961, vnbgprcaucmic 0.99893, vnbgprcaucmac 0.99832, vnbgl_loss 2.22710, 119.15 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33512, vnbgbbmf1 0.28868, vnbglaucmic 0.95325, vnbglaucmac 0.85010, vnbgprcaucmic 0.70827, vnbgprcaucmac 0.37101, 31.93 secs\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.57866, y8_loss 2.16609, y8box_loss 0.66411, y8cls_loss 0.55369, y8dfl_loss 0.94829, vnbgprcaucmic 0.99904, vnbgprcaucmac 0.99858, vnbgl_loss 2.22181, 119.34 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.33443, vnbgbbmf1 0.28822, vnbglaucmic 0.95335, vnbglaucmac 0.85168, vnbgprcaucmic 0.70798, vnbgprcaucmac 0.37006, 31.04 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230523_133812_mim_Image2ReportModel(yolov8l->TransfTextDec(posenc(learned),es=512,hs=512,nl=3,nh=4,dff=512))\" \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 28 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-decay-and-cyclic-decay-args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "        --use-vinbig \\\n",
    "        --vinbig-use-validation \\\n",
    "        --vinbig-weight 1.0 \\\n",
    "        --predict-bboxes-vinbig \\\n",
    "        --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "        --raw-image-encoding \"yolov8\" \\\n",
    "        --yolov8-model-name-or-path \"yolov8l.pt\" \\\n",
    "        --yolov8-model-alias \"yolov8l\" \\\n",
    "        --image-size 416 416 \\\n",
    "        --image-local-feat-size 512 \\\n",
    "        --num-regions 169 \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
