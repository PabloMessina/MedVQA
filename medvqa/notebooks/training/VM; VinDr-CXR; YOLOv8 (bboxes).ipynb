{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 250\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: yolov11-for-det-mlc\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   classification_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   yolov8_use_one_detector_per_dataset: False\n",
      "   yolov11_model_name_or_path: yolov8l.pt\n",
      "   yolov11_model_alias: yolov8l\n",
      "   query_embed_size: None\n",
      "   local_attention_hidden_size: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,6,1e-6,1e-4,6,1e-6\n",
      "   batch_size: 100\n",
      "   gradient_accumulation_steps: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   mimiccxr_balanced_batch_size: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3\n",
      "   pretrained_checkpoint_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: train\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbcbce\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: True\n",
      "   classify_labels_vinbig: False\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[35mvinbig_class_id_offset: 0\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: yolov11-for-det-mlc\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.head.Detect           [22, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43,646,802 parameters, 43,646,786 gradients, 165.5 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "  Initializing auxiliary tasks\n",
      "    Skipping auxiliary tasks initialization for YOLOV11_FOR_DET_MLC\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,6,1e-6,1e-4,6,1e-6\n",
      "1e-06 3 0.0001 6 1e-06 0.0001 6 1e-06\n",
      "self.steps_to_restart = 6\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 1, max_grad_norm = None\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.0, 0.0, 0.0]\n",
      "  std = [1.0, 1.0, 1.0]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.0, 0.0, 0.0]\n",
      "  std = [1.0, 1.0, 1.0]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=10601, #neg=4399\n",
      "Other disease     , #pos=4288, #neg=10712\n",
      "Aortic enlargement, #pos=3067, #neg=11933\n",
      "Cardiomegaly      , #pos=2300, #neg=12700\n",
      "Pleural thickening, #pos=1981, #neg=13019\n",
      "Pulmonary fibrosis, #pos=1617, #neg=13383\n",
      "Lung Opacity      , #pos=1322, #neg=13678\n",
      "Other lesion      , #pos=1134, #neg=13866\n",
      "Pleural effusion  , #pos=1032, #neg=13968\n",
      "Pneumonia         , #pos=917, #neg=14083\n",
      "Nodule/Mass       , #pos=830, #neg=14170\n",
      "Tuberculosis      , #pos=750, #neg=14250\n",
      "Infiltration      , #pos=613, #neg=14387\n",
      "Calcification     , #pos=452, #neg=14548\n",
      "ILD               , #pos=386, #neg=14614\n",
      "Consolidation     , #pos=353, #neg=14647\n",
      "Lung tumor        , #pos=291, #neg=14709\n",
      "Atelectasis       , #pos=186, #neg=14814\n",
      "Mediastinal shift , #pos=150, #neg=14850\n",
      "Enlarged PA       , #pos=131, #neg=14869\n",
      "Pneumothorax      , #pos=96, #neg=14904\n",
      "Rib fracture      , #pos=90, #neg=14910\n",
      "Emphysema         , #pos=78, #neg=14922\n",
      "Lung cavity       , #pos=50, #neg=14950\n",
      "COPD              , #pos=35, #neg=14965\n",
      "Lung cyst         , #pos=32, #neg=14968\n",
      "Clavicle fracture , #pos=27, #neg=14973\n",
      "Edema             , #pos=13, #neg=14987\n",
      "len(train_indices) = 15000\n",
      "len(self.test_indices) = 3000\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [0.3]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241129_083600_vinbig_yolov8l(d:vinbig)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241129_083600_vinbig_yolov8l(d:vinbig)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_77_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.4192.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3/checkpoint_77_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.4192.pt\n",
      "\u001b[93mWarning: model state dict has 680 keys, loaded state dict has 765 keys, intersection has 680 keys, union has 765 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.1.1.bn.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.2.1.conv.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.1.0.bn.num_batches_tracked\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.2.0.bn.running_var\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.0.1.bn.num_batches_tracked\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.2.2.bias\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.1.1.conv.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.0.1.bn.num_batches_tracked\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.0.2.bias\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.2.0.conv.weight\u001b[0m\n",
      "Checkpoint successfully loaded!\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3/checkpoint_77_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.4192.pt\n",
      "\u001b[93mWarning: model state dict has 680 keys, loaded state dict has 765 keys, intersection has 680 keys, union has 765 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.2.0.bn.num_batches_tracked\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.1.0.bn.running_var\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.1.2.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.0.0.bn.bias\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.2.1.bn.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.2.0.bn.running_mean\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.1.0.bn.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv3.2.1.conv.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.2.0.bn.bias\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.detect.cig.cv2.1.0.conv.weight\u001b[0m\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241129_083600_vinbig_yolov8l(d:vinbig)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.02289, vnb_y11_loss 4.02289, vnb_y11_box_loss 1.33844, vnb_y11_cls_loss 1.28378, vnb_y11_dfl_loss 1.40066, 154.77 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15315, 21.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_vnb_y11_bbox_iou=0.1532.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.00297, vnb_y11_loss 4.00297, vnb_y11_box_loss 1.33918, vnb_y11_cls_loss 1.26878, vnb_y11_dfl_loss 1.39501, 151.84 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15037, 21.70 secs\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.96735, vnb_y11_loss 3.96735, vnb_y11_box_loss 1.32541, vnb_y11_cls_loss 1.25088, vnb_y11_dfl_loss 1.39106, 151.88 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15338, 21.91 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_vnb_y11_bbox_iou=0.1534.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.04715, vnb_y11_loss 4.04715, vnb_y11_box_loss 1.34798, vnb_y11_cls_loss 1.29548, vnb_y11_dfl_loss 1.40369, 149.49 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14034, 21.59 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 3.97241, vnb_y11_loss 3.97241, vnb_y11_box_loss 1.32694, vnb_y11_cls_loss 1.25276, vnb_y11_dfl_loss 1.39272, 150.17 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14742, 21.67 secs\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.90552, vnb_y11_loss 3.90552, vnb_y11_box_loss 1.30575, vnb_y11_cls_loss 1.22046, vnb_y11_dfl_loss 1.37932, 152.26 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.13916, 21.93 secs\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.88687, vnb_y11_loss 3.88687, vnb_y11_box_loss 1.30363, vnb_y11_cls_loss 1.20699, vnb_y11_dfl_loss 1.37625, 153.38 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14763, 22.16 secs\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.91964, vnb_y11_loss 3.91964, vnb_y11_box_loss 1.31676, vnb_y11_cls_loss 1.21760, vnb_y11_dfl_loss 1.38527, 152.87 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14458, 21.75 secs\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.88102, vnb_y11_loss 3.88102, vnb_y11_box_loss 1.30202, vnb_y11_cls_loss 1.20086, vnb_y11_dfl_loss 1.37815, 151.39 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14789, 22.11 secs\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.86731, vnb_y11_loss 3.86731, vnb_y11_box_loss 1.29735, vnb_y11_cls_loss 1.19770, vnb_y11_dfl_loss 1.37226, 157.48 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14646, 22.19 secs\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.99080, vnb_y11_loss 3.99080, vnb_y11_box_loss 1.32970, vnb_y11_cls_loss 1.26873, vnb_y11_dfl_loss 1.39237, 157.34 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14004, 21.70 secs\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.89936, vnb_y11_loss 3.89936, vnb_y11_box_loss 1.30494, vnb_y11_cls_loss 1.21800, vnb_y11_dfl_loss 1.37642, 159.77 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14455, 22.17 secs\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.89927, vnb_y11_loss 3.89927, vnb_y11_box_loss 1.30738, vnb_y11_cls_loss 1.21012, vnb_y11_dfl_loss 1.38177, 159.10 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14806, 22.03 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.83937, vnb_y11_loss 3.83937, vnb_y11_box_loss 1.28919, vnb_y11_cls_loss 1.18025, vnb_y11_dfl_loss 1.36993, 158.22 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14730, 21.74 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.84057, vnb_y11_loss 3.84057, vnb_y11_box_loss 1.29073, vnb_y11_cls_loss 1.17938, vnb_y11_dfl_loss 1.37046, 157.39 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14971, 21.59 secs\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.83385, vnb_y11_loss 3.83385, vnb_y11_box_loss 1.28656, vnb_y11_cls_loss 1.17901, vnb_y11_dfl_loss 1.36827, 155.36 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15175, 21.73 secs\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.92598, vnb_y11_loss 3.92598, vnb_y11_box_loss 1.30851, vnb_y11_cls_loss 1.23750, vnb_y11_dfl_loss 1.37996, 153.97 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15046, 21.68 secs\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.89217, vnb_y11_loss 3.89217, vnb_y11_box_loss 1.30290, vnb_y11_cls_loss 1.21190, vnb_y11_dfl_loss 1.37737, 151.97 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15223, 21.96 secs\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.84325, vnb_y11_loss 3.84325, vnb_y11_box_loss 1.28849, vnb_y11_cls_loss 1.18468, vnb_y11_dfl_loss 1.37009, 152.86 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15134, 21.93 secs\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.82125, vnb_y11_loss 3.82125, vnb_y11_box_loss 1.28248, vnb_y11_cls_loss 1.17312, vnb_y11_dfl_loss 1.36566, 153.48 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.16011, 21.77 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_vnb_y11_bbox_iou=0.1601.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.80053, vnb_y11_loss 3.80053, vnb_y11_box_loss 1.27556, vnb_y11_cls_loss 1.16451, vnb_y11_dfl_loss 1.36046, 157.18 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15234, 21.74 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.81017, vnb_y11_loss 3.81017, vnb_y11_box_loss 1.27915, vnb_y11_cls_loss 1.16624, vnb_y11_dfl_loss 1.36478, 153.50 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15017, 21.81 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.92119, vnb_y11_loss 3.92119, vnb_y11_box_loss 1.30929, vnb_y11_cls_loss 1.23200, vnb_y11_dfl_loss 1.37990, 155.22 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15551, 21.75 secs\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.82557, vnb_y11_loss 3.82557, vnb_y11_box_loss 1.28307, vnb_y11_cls_loss 1.17918, vnb_y11_dfl_loss 1.36332, 155.84 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15438, 21.51 secs\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.79825, vnb_y11_loss 3.79825, vnb_y11_box_loss 1.27443, vnb_y11_cls_loss 1.16445, vnb_y11_dfl_loss 1.35936, 151.77 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14649, 22.15 secs\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.77514, vnb_y11_loss 3.77514, vnb_y11_box_loss 1.26600, vnb_y11_cls_loss 1.15238, vnb_y11_dfl_loss 1.35676, 154.97 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15551, 22.10 secs\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.78496, vnb_y11_loss 3.78496, vnb_y11_box_loss 1.26921, vnb_y11_cls_loss 1.15466, vnb_y11_dfl_loss 1.36110, 157.84 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15202, 21.95 secs\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.77177, vnb_y11_loss 3.77177, vnb_y11_box_loss 1.26651, vnb_y11_cls_loss 1.14793, vnb_y11_dfl_loss 1.35733, 152.25 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15529, 21.78 secs\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.87973, vnb_y11_loss 3.87973, vnb_y11_box_loss 1.29731, vnb_y11_cls_loss 1.21010, vnb_y11_dfl_loss 1.37232, 153.44 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14619, 21.68 secs\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.83543, vnb_y11_loss 3.83543, vnb_y11_box_loss 1.28639, vnb_y11_cls_loss 1.18169, vnb_y11_dfl_loss 1.36735, 155.01 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15373, 21.60 secs\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.81126, vnb_y11_loss 3.81126, vnb_y11_box_loss 1.27937, vnb_y11_cls_loss 1.16482, vnb_y11_dfl_loss 1.36707, 152.99 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15309, 21.84 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.75612, vnb_y11_loss 3.75612, vnb_y11_box_loss 1.25901, vnb_y11_cls_loss 1.14411, vnb_y11_dfl_loss 1.35301, 151.12 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15469, 21.87 secs\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.72607, vnb_y11_loss 3.72607, vnb_y11_box_loss 1.24900, vnb_y11_cls_loss 1.13050, vnb_y11_dfl_loss 1.34657, 152.82 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.13884, 21.74 secs\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.76693, vnb_y11_loss 3.76693, vnb_y11_box_loss 1.26506, vnb_y11_cls_loss 1.14420, vnb_y11_dfl_loss 1.35767, 151.93 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15015, 21.92 secs\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.85315, vnb_y11_loss 3.85315, vnb_y11_box_loss 1.28775, vnb_y11_cls_loss 1.19716, vnb_y11_dfl_loss 1.36824, 156.62 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15880, 22.06 secs\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.82030, vnb_y11_loss 3.82030, vnb_y11_box_loss 1.28129, vnb_y11_cls_loss 1.17298, vnb_y11_dfl_loss 1.36603, 152.35 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15236, 21.63 secs\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.74855, vnb_y11_loss 3.74855, vnb_y11_box_loss 1.25821, vnb_y11_cls_loss 1.13937, vnb_y11_dfl_loss 1.35098, 153.70 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15315, 21.63 secs\n",
      "\u001b[1m---- Epoch 38/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.74324, vnb_y11_loss 3.74324, vnb_y11_box_loss 1.25706, vnb_y11_cls_loss 1.13333, vnb_y11_dfl_loss 1.35286, 153.83 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15961, 21.78 secs\n",
      "\u001b[1m---- Epoch 39/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.72782, vnb_y11_loss 3.72782, vnb_y11_box_loss 1.25280, vnb_y11_cls_loss 1.12619, vnb_y11_dfl_loss 1.34883, 154.14 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15754, 21.66 secs\n",
      "\u001b[1m---- Epoch 40/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.70944, vnb_y11_loss 3.70944, vnb_y11_box_loss 1.24390, vnb_y11_cls_loss 1.11966, vnb_y11_dfl_loss 1.34588, 151.92 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14133, 21.41 secs\n",
      "\u001b[1m---- Epoch 41/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.83732, vnb_y11_loss 3.83732, vnb_y11_box_loss 1.28472, vnb_y11_cls_loss 1.18683, vnb_y11_dfl_loss 1.36577, 151.53 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15935, 21.76 secs\n",
      "\u001b[1m---- Epoch 42/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.80096, vnb_y11_loss 3.80096, vnb_y11_box_loss 1.27471, vnb_y11_cls_loss 1.16205, vnb_y11_dfl_loss 1.36420, 152.34 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15407, 21.63 secs\n",
      "\u001b[1m---- Epoch 43/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.74274, vnb_y11_loss 3.74274, vnb_y11_box_loss 1.25631, vnb_y11_cls_loss 1.13403, vnb_y11_dfl_loss 1.35240, 153.53 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15421, 21.48 secs\n",
      "\u001b[1m---- Epoch 44/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.73816, vnb_y11_loss 3.73816, vnb_y11_box_loss 1.25505, vnb_y11_cls_loss 1.13069, vnb_y11_dfl_loss 1.35242, 153.33 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vnb_y11_bbox_iou 0.14949, 21.66 secs\n",
      "\u001b[1m---- Epoch 45/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.71803, vnb_y11_loss 3.71803, vnb_y11_box_loss 1.24637, vnb_y11_cls_loss 1.12367, vnb_y11_dfl_loss 1.34799, 154.16 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15297, 21.59 secs\n",
      "\u001b[1m---- Epoch 46/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.69246, vnb_y11_loss 3.69246, vnb_y11_box_loss 1.24063, vnb_y11_cls_loss 1.11042, vnb_y11_dfl_loss 1.34141, 152.00 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.13820, 21.82 secs\n",
      "\u001b[1m---- Epoch 47/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.80753, vnb_y11_loss 3.80753, vnb_y11_box_loss 1.27282, vnb_y11_cls_loss 1.17384, vnb_y11_dfl_loss 1.36087, 152.93 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14898, 21.80 secs\n",
      "\u001b[1m---- Epoch 48/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.75116, vnb_y11_loss 3.75116, vnb_y11_box_loss 1.25801, vnb_y11_cls_loss 1.14339, vnb_y11_dfl_loss 1.34975, 153.18 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14216, 21.51 secs\n",
      "\u001b[1m---- Epoch 49/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.71264, vnb_y11_loss 3.71264, vnb_y11_box_loss 1.24372, vnb_y11_cls_loss 1.12409, vnb_y11_dfl_loss 1.34484, 154.92 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14284, 21.56 secs\n",
      "\u001b[1m---- Epoch 50/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.69732, vnb_y11_loss 3.69732, vnb_y11_box_loss 1.24303, vnb_y11_cls_loss 1.11013, vnb_y11_dfl_loss 1.34416, 154.62 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14519, 21.65 secs\n",
      "\u001b[1m---- Epoch 51/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.72021, vnb_y11_loss 3.72021, vnb_y11_box_loss 1.25090, vnb_y11_cls_loss 1.11939, vnb_y11_dfl_loss 1.34992, 155.21 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14310, 21.52 secs\n",
      "\u001b[1m---- Epoch 52/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.68413, vnb_y11_loss 3.68413, vnb_y11_box_loss 1.23629, vnb_y11_cls_loss 1.10731, vnb_y11_dfl_loss 1.34053, 155.24 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15405, 21.56 secs\n",
      "\u001b[1m---- Epoch 53/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.80461, vnb_y11_loss 3.80461, vnb_y11_box_loss 1.27504, vnb_y11_cls_loss 1.16968, vnb_y11_dfl_loss 1.35990, 153.75 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14522, 21.65 secs\n",
      "\u001b[1m---- Epoch 54/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.75761, vnb_y11_loss 3.75761, vnb_y11_box_loss 1.25948, vnb_y11_cls_loss 1.14487, vnb_y11_dfl_loss 1.35327, 153.45 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15582, 21.63 secs\n",
      "\u001b[1m---- Epoch 55/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.69850, vnb_y11_loss 3.69850, vnb_y11_box_loss 1.24015, vnb_y11_cls_loss 1.11445, vnb_y11_dfl_loss 1.34390, 152.76 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15274, 21.73 secs\n",
      "\u001b[1m---- Epoch 56/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.68214, vnb_y11_loss 3.68214, vnb_y11_box_loss 1.23542, vnb_y11_cls_loss 1.10545, vnb_y11_dfl_loss 1.34126, 152.78 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15214, 21.73 secs\n",
      "\u001b[1m---- Epoch 57/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.67441, vnb_y11_loss 3.67441, vnb_y11_box_loss 1.23379, vnb_y11_cls_loss 1.10122, vnb_y11_dfl_loss 1.33940, 152.53 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15375, 21.61 secs\n",
      "\u001b[1m---- Epoch 58/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.66986, vnb_y11_loss 3.66986, vnb_y11_box_loss 1.23230, vnb_y11_cls_loss 1.09845, vnb_y11_dfl_loss 1.33911, 153.10 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14880, 21.58 secs\n",
      "\u001b[1m---- Epoch 59/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.77482, vnb_y11_loss 3.77482, vnb_y11_box_loss 1.26577, vnb_y11_cls_loss 1.15699, vnb_y11_dfl_loss 1.35206, 153.55 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15174, 21.76 secs\n",
      "\u001b[1m---- Epoch 60/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.71593, vnb_y11_loss 3.71593, vnb_y11_box_loss 1.24770, vnb_y11_cls_loss 1.12436, vnb_y11_dfl_loss 1.34386, 155.98 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15603, 21.59 secs\n",
      "\u001b[1m---- Epoch 61/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.71394, vnb_y11_loss 3.71394, vnb_y11_box_loss 1.24688, vnb_y11_cls_loss 1.11652, vnb_y11_dfl_loss 1.35055, 152.43 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14585, 21.62 secs\n",
      "\u001b[1m---- Epoch 62/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.65513, vnb_y11_loss 3.65513, vnb_y11_box_loss 1.22755, vnb_y11_cls_loss 1.09272, vnb_y11_dfl_loss 1.33486, 154.77 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15717, 21.62 secs\n",
      "\u001b[1m---- Epoch 63/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.64531, vnb_y11_loss 3.64531, vnb_y11_box_loss 1.22548, vnb_y11_cls_loss 1.08738, vnb_y11_dfl_loss 1.33245, 151.34 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15538, 21.60 secs\n",
      "\u001b[1m---- Epoch 64/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.64716, vnb_y11_loss 3.64716, vnb_y11_box_loss 1.22299, vnb_y11_cls_loss 1.08936, vnb_y11_dfl_loss 1.33481, 152.65 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15567, 21.70 secs\n",
      "\u001b[1m---- Epoch 65/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.74758, vnb_y11_loss 3.74758, vnb_y11_box_loss 1.25305, vnb_y11_cls_loss 1.14646, vnb_y11_dfl_loss 1.34807, 153.16 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15426, 21.74 secs\n",
      "\u001b[1m---- Epoch 66/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.72404, vnb_y11_loss 3.72404, vnb_y11_box_loss 1.24644, vnb_y11_cls_loss 1.12861, vnb_y11_dfl_loss 1.34899, 152.75 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15198, 21.48 secs\n",
      "\u001b[1m---- Epoch 67/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.66265, vnb_y11_loss 3.66265, vnb_y11_box_loss 1.22807, vnb_y11_cls_loss 1.09998, vnb_y11_dfl_loss 1.33459, 151.65 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15226, 21.57 secs\n",
      "\u001b[1m---- Epoch 68/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.63574, vnb_y11_loss 3.63574, vnb_y11_box_loss 1.21660, vnb_y11_cls_loss 1.08807, vnb_y11_dfl_loss 1.33107, 154.28 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15502, 21.63 secs\n",
      "\u001b[1m---- Epoch 69/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.64776, vnb_y11_loss 3.64776, vnb_y11_box_loss 1.22417, vnb_y11_cls_loss 1.08897, vnb_y11_dfl_loss 1.33462, 153.57 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15599, 21.74 secs\n",
      "\u001b[1m---- Epoch 70/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.62552, vnb_y11_loss 3.62552, vnb_y11_box_loss 1.21823, vnb_y11_cls_loss 1.07701, vnb_y11_dfl_loss 1.33028, 155.35 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15335, 21.53 secs\n",
      "\u001b[1m---- Epoch 71/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.76317, vnb_y11_loss 3.76317, vnb_y11_box_loss 1.25835, vnb_y11_cls_loss 1.15263, vnb_y11_dfl_loss 1.35218, 152.80 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.13910, 21.64 secs\n",
      "\u001b[1m---- Epoch 72/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.71231, vnb_y11_loss 3.71231, vnb_y11_box_loss 1.24424, vnb_y11_cls_loss 1.12126, vnb_y11_dfl_loss 1.34681, 155.53 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.14883, 21.71 secs\n",
      "\u001b[1m---- Epoch 73/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.66102, vnb_y11_loss 3.66102, vnb_y11_box_loss 1.22799, vnb_y11_cls_loss 1.09726, vnb_y11_dfl_loss 1.33577, 153.94 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15457, 21.87 secs\n",
      "\u001b[1m---- Epoch 74/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.64878, vnb_y11_loss 3.64878, vnb_y11_box_loss 1.22472, vnb_y11_cls_loss 1.08993, vnb_y11_dfl_loss 1.33414, 154.18 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.15402, 21.83 secs\n",
      "\u001b[1m---- Epoch 75/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "^C iteration 18525\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_visual_module.py\", line 1496, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_visual_module.py\", line 1370, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_visual_module.py\", line 764, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 142, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 952, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 701, in step_fn__vinbig\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 801, in forward\n",
      "    return self.raw_image_encoder(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/yolov11_modified.py\", line 333, in forward\n",
      "    preds = self.detect[task_name](features_)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ultralytics/nn/modules/head.py\", line 77, in forward\n",
      "    x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py\", line 50, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py\", line 175, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/functional.py\", line 2509, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 250 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 3 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,6,1e-6,1e-4,6,1e-6\" \\\n",
    "--use_vinbig \\\n",
    "--vinbig_training_data_mode \"train\" \\\n",
    "--vinbig_use_validation \\\n",
    "--predict_bboxes_vinbig \\\n",
    "--binary_loss_name \"focal+bce+wbcbce\" \\\n",
    "--raw_image_encoding \"yolov11-for-det-mlc\" \\\n",
    "--yolov11_model_name_or_path \"yolov8l.pt\" \\\n",
    "--yolov11_model_alias \"yolov8l\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 169 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
