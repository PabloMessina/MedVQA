{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1200\n",
      "   batch_size: 4\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: fact_classifier_predictions2report_section\n",
      "   experiment_name: sigmoids2findings\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\n",
      "   interpret_cxr_challenge_data_dir: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\n",
      "   mimiccxr_integrated_report_nli_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   report_section_to_generate: impression\n",
      "   include_public_test_in_train: True\n",
      "   best_k_classes: 60\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl...\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_probs(hash=234,1770274675398037115).pkl...\n",
      "thresholds.shape: (93,)\n",
      "f1s.shape: (93,)\n",
      "accs.shape: (93,)\n",
      "probs.shape: (607342, 93)\n",
      "len(image_paths): 607342\n",
      "len(class_names): 93\n",
      "Class names:\n",
      "1: cardiac pacer and wires, f1: 0.726, acc: 0.968\n",
      "2: endotracheal tube, f1: 0.688, acc: 0.942\n",
      "3: enteric tube, f1: 0.694, acc: 0.935\n",
      "4: pleural effusion, f1: 0.735, acc: 0.862\n",
      "5: pleural abnormalities, f1: 0.754, acc: 0.820\n",
      "6: pigtail catheter, f1: 0.569, acc: 0.990\n",
      "7: lung opacity, f1: 0.778, acc: 0.778\n",
      "8: opacity texture, f1: 0.780, acc: 0.769\n",
      "9: tracheostomy tube, f1: 0.555, acc: 0.988\n",
      "10: no abnormalities, f1: 0.651, acc: 0.860\n",
      "11: support devices, f1: 0.686, acc: 0.811\n",
      "12: fluid overload/heart failure, f1: 0.675, acc: 0.799\n",
      "13: edema, f1: 0.624, acc: 0.835\n",
      "14: subcutaneous air, f1: 0.475, acc: 0.983\n",
      "15: enlarged cardiac silhouette, f1: 0.630, acc: 0.812\n",
      "16: pulmonary edema/hazy opacity, f1: 0.578, acc: 0.863\n",
      "17: cardiomegaly, f1: 0.626, acc: 0.808\n",
      "18: subcutaneous emphysema, f1: 0.448, acc: 0.982\n",
      "19: airspace opacity, f1: 0.673, acc: 0.750\n",
      "20: vascular congestion, f1: 0.573, acc: 0.829\n",
      "21: chest tube, f1: 0.449, acc: 0.949\n",
      "22: costophrenic angle blunting, f1: 0.566, acc: 0.828\n",
      "23: ij line, f1: 0.450, acc: 0.942\n",
      "24: pneumothorax, f1: 0.420, acc: 0.957\n",
      "25: linear/patchy atelectasis, f1: 0.657, acc: 0.711\n",
      "26: chest port, f1: 0.405, acc: 0.961\n",
      "27: atelectasis, f1: 0.633, acc: 0.724\n",
      "28: hyperaeration, f1: 0.405, acc: 0.934\n",
      "29: enlarged cardiomediastinum, f1: 0.542, acc: 0.796\n",
      "30: cabg grafts, f1: 0.365, acc: 0.967\n",
      "31: swan-ganz catheter, f1: 0.340, acc: 0.986\n",
      "32: lobar/segmental collapse, f1: 0.600, acc: 0.722\n",
      "33: pneumonia, f1: 0.534, acc: 0.778\n",
      "34: consolidation, f1: 0.563, acc: 0.749\n",
      "35: emphysema, f1: 0.340, acc: 0.953\n",
      "36: interstitial texture, f1: 0.634, acc: 0.659\n",
      "37: copd/emphysema, f1: 0.367, acc: 0.924\n",
      "38: hydropneumothorax, f1: 0.305, acc: 0.979\n",
      "39: infiltration, f1: 0.519, acc: 0.762\n",
      "40: tortuous aorta, f1: 0.388, acc: 0.890\n",
      "41: low lung volumes, f1: 0.464, acc: 0.799\n",
      "42: picc, f1: 0.348, acc: 0.910\n",
      "43: prosthetic valve, f1: 0.273, acc: 0.975\n",
      "44: elevated hemidiaphragm, f1: 0.285, acc: 0.955\n",
      "45: lung cancer, f1: 0.310, acc: 0.928\n",
      "46: alveolar texture, f1: 0.588, acc: 0.631\n",
      "47: hernia, f1: 0.215, acc: 0.983\n",
      "48: pneumomediastinum, f1: 0.206, acc: 0.987\n",
      "49: calcification of the aorta, f1: 0.300, acc: 0.889\n",
      "50: vascular calcification, f1: 0.257, acc: 0.932\n",
      "51: multiple masses/nodules, f1: 0.223, acc: 0.962\n",
      "52: interstitial lung disease, f1: 0.253, acc: 0.929\n",
      "53: subclavian line, f1: 0.207, acc: 0.974\n",
      "54: vascular redistribution, f1: 0.273, acc: 0.900\n",
      "55: nodule, f1: 0.241, acc: 0.929\n",
      "56: mediastinal displacement, f1: 0.214, acc: 0.950\n",
      "57: aortic graft/repair, f1: 0.194, acc: 0.963\n",
      "58: mass, f1: 0.247, acc: 0.899\n",
      "59: cyst/bullae, f1: 0.186, acc: 0.959\n",
      "60: pleural/parenchymal scarring, f1: 0.295, acc: 0.849\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing MIMIC-CXR inputs/outputs...\n",
      "100%|█████████████████████████████████| 217190/217190 [00:28<00:00, 7616.88it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 91320/217190 reports without facts\u001b[0m\n",
      "len(mimiccxr_train_input_texts): 125870\n",
      "100%|█████████████████████████████████████| 5568/5568 [00:00<00:00, 7709.99it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 2328/5568 reports without facts\u001b[0m\n",
      "len(mimiccxr_val_input_texts): 3240\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 3\n",
      "cardiac pacer and wires:3 3 10\n",
      "endotracheal tube:1 1 2\n",
      "enteric tube:2 2 2\n",
      "pleural effusion:18 16 21\n",
      "pleural abnormalities:59 56 61\n",
      "pigtail catheter:6 5 7\n",
      "lung opacity:32 44 36\n",
      "opacity texture:25 30 25\n",
      "tracheostomy tube:6 6 13\n",
      "no abnormalities:27 26 16\n",
      "support devices:8 8 22\n",
      "fluid overload/heart failure:3 5 9\n",
      "edema:8 10 10\n",
      "subcutaneous air:15 13 24\n",
      "enlarged cardiac silhouette:2 4 8\n",
      "pulmonary edema/hazy opacity:6 7 7\n",
      "cardiomegaly:2 3 6\n",
      "subcutaneous emphysema:12 11 20\n",
      "airspace opacity:18 25 16\n",
      "vascular congestion:4 6 9\n",
      "chest tube:2 2 3\n",
      "costophrenic angle blunting:37 34 36\n",
      "ij line:2 2 7\n",
      "pneumothorax:4 4 5\n",
      "linear/patchy atelectasis:44 58 43\n",
      "chest port:4 3 7\n",
      "atelectasis:30 41 25\n",
      "hyperaeration:35 50 43\n",
      "enlarged cardiomediastinum:2 3 9\n",
      "cabg grafts:5 5 13\n",
      "swan-ganz catheter:2 2 3\n",
      "lobar/segmental collapse:23 34 21\n",
      "pneumonia:9 9 13\n",
      "consolidation:22 21 26\n",
      "emphysema:26 43 56\n",
      "interstitial texture:33 38 37\n",
      "copd/emphysema:20 33 45\n",
      "hydropneumothorax:8 7 7\n",
      "infiltration:13 14 19\n",
      "tortuous aorta:19 20 56\n",
      "low lung volumes:20 20 23\n",
      "picc:4 5 10\n",
      "prosthetic valve:8 11 26\n",
      "elevated hemidiaphragm:20 31 29\n",
      "lung cancer:9 11 20\n",
      "alveolar texture:31 33 31\n",
      "hernia:15 17 22\n",
      "pneumomediastinum:8 10 11\n",
      "calcification of the aorta:16 19 71\n",
      "vascular calcification:7 9 53\n",
      "multiple masses/nodules:13 9 13\n",
      "interstitial lung disease:7 9 14\n",
      "subclavian line:6 7 7\n",
      "vascular redistribution:9 10 22\n",
      "nodule:27 20 32\n",
      "mediastinal displacement:2 3 6\n",
      "aortic graft/repair:6 6 18\n",
      "mass:12 11 15\n",
      "cyst/bullae:24 22 32\n",
      "pleural/parenchymal scarring:49 48 52\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mno acute cardiopulmonary process.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "cardiac pacer and wires:11 7\n",
      "endotracheal tube:2 1\n",
      "enteric tube:2 2\n",
      "pleural effusion:17 37\n",
      "pleural abnormalities:42 66\n",
      "pigtail catheter:8 3\n",
      "lung opacity:23 38\n",
      "opacity texture:15 26\n",
      "tracheostomy tube:10 7\n",
      "no abnormalities:20 10\n",
      "support devices:10 7\n",
      "fluid overload/heart failure:12 9\n",
      "edema:7 11\n",
      "subcutaneous air:11 12\n",
      "enlarged cardiac silhouette:46 40\n",
      "pulmonary edema/hazy opacity:4 6\n",
      "cardiomegaly:45 39\n",
      "subcutaneous emphysema:9 11\n",
      "airspace opacity:4 10\n",
      "vascular congestion:12 14\n",
      "chest tube:3 2\n",
      "costophrenic angle blunting:34 43\n",
      "ij line:3 3\n",
      "pneumothorax:5 6\n",
      "linear/patchy atelectasis:15 41\n",
      "chest port:9 3\n",
      "atelectasis:6 26\n",
      "hyperaeration:42 43\n",
      "enlarged cardiomediastinum:32 30\n",
      "cabg grafts:9 13\n",
      "swan-ganz catheter:2 2\n",
      "lobar/segmental collapse:6 18\n",
      "pneumonia:4 6\n",
      "consolidation:11 21\n",
      "emphysema:39 49\n",
      "interstitial texture:24 28\n",
      "copd/emphysema:30 35\n",
      "hydropneumothorax:9 3\n",
      "infiltration:10 15\n",
      "tortuous aorta:85 75\n",
      "low lung volumes:10 18\n",
      "picc:12 5\n",
      "prosthetic valve:25 26\n",
      "elevated hemidiaphragm:31 32\n",
      "lung cancer:14 15\n",
      "alveolar texture:21 24\n",
      "hernia:31 29\n",
      "pneumomediastinum:12 11\n",
      "calcification of the aorta:73 75\n",
      "vascular calcification:29 37\n",
      "multiple masses/nodules:13 9\n",
      "interstitial lung disease:6 7\n",
      "subclavian line:7 5\n",
      "vascular redistribution:36 36\n",
      "nodule:31 25\n",
      "mediastinal displacement:11 11\n",
      "aortic graft/repair:12 15\n",
      "mass:13 14\n",
      "cyst/bullae:21 14\n",
      "pleural/parenchymal scarring:48 51\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mno consolidation. mild cardiomegaly. moderate cardiomegaly.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing CheXpert inputs/outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWARNING: Skipped 580/182199 reports with empty output\u001b[0m\n",
      "len(chexpert_train_input_texts): 181619\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 14/4603 reports with empty output\u001b[0m\n",
      "len(chexpert_val_input_texts): 4589\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:26\n",
      "endotracheal tube:68\n",
      "enteric tube:55\n",
      "pleural effusion:60\n",
      "pleural abnormalities:79\n",
      "pigtail catheter:17\n",
      "lung opacity:84\n",
      "opacity texture:65\n",
      "tracheostomy tube:31\n",
      "no abnormalities:4\n",
      "support devices:84\n",
      "fluid overload/heart failure:66\n",
      "edema:54\n",
      "subcutaneous air:15\n",
      "enlarged cardiac silhouette:54\n",
      "pulmonary edema/hazy opacity:61\n",
      "cardiomegaly:54\n",
      "subcutaneous emphysema:12\n",
      "airspace opacity:70\n",
      "vascular congestion:77\n",
      "chest tube:25\n",
      "costophrenic angle blunting:50\n",
      "ij line:85\n",
      "pneumothorax:6\n",
      "linear/patchy atelectasis:78\n",
      "chest port:27\n",
      "atelectasis:74\n",
      "hyperaeration:15\n",
      "enlarged cardiomediastinum:62\n",
      "cabg grafts:18\n",
      "swan-ganz catheter:53\n",
      "lobar/segmental collapse:72\n",
      "pneumonia:18\n",
      "consolidation:48\n",
      "emphysema:5\n",
      "interstitial texture:46\n",
      "copd/emphysema:6\n",
      "hydropneumothorax:5\n",
      "infiltration:52\n",
      "tortuous aorta:26\n",
      "low lung volumes:52\n",
      "picc:24\n",
      "prosthetic valve:46\n",
      "elevated hemidiaphragm:29\n",
      "lung cancer:13\n",
      "alveolar texture:34\n",
      "hernia:3\n",
      "pneumomediastinum:12\n",
      "calcification of the aorta:26\n",
      "vascular calcification:59\n",
      "multiple masses/nodules:16\n",
      "interstitial lung disease:23\n",
      "subclavian line:25\n",
      "vascular redistribution:36\n",
      "nodule:10\n",
      "mediastinal displacement:52\n",
      "aortic graft/repair:38\n",
      "mass:17\n",
      "cyst/bullae:4\n",
      "pleural/parenchymal scarring:5\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1. SINGLE PORTABLE VIEW OF THE CHEST DEMONSTRATES NO INTERVAL CHANGE IN SUPPORTIVE EQUIPMENT. 2. REDEMONSTRATION OF INTERSTITIAL PROMINENCE, WHICH MOST LIKELY REPRESENTS PULMONARY EDEMA. ELEVATION OF THE RIGHT HEMIDIAPHRAGM, WHICH IS LIKELY SECONDARY TO A COMBINATION OF PLEURAL EFFUSION AND RIGHT LOWER LOBE ATELECTASIS. OVERALL, NO INTERVAL CHANGE IN CARDIOPULMONARY STATUS.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:40\n",
      "endotracheal tube:74\n",
      "enteric tube:64\n",
      "pleural effusion:80\n",
      "pleural abnormalities:85\n",
      "pigtail catheter:11\n",
      "lung opacity:87\n",
      "opacity texture:73\n",
      "tracheostomy tube:27\n",
      "no abnormalities:6\n",
      "support devices:83\n",
      "fluid overload/heart failure:62\n",
      "edema:65\n",
      "subcutaneous air:13\n",
      "enlarged cardiac silhouette:76\n",
      "pulmonary edema/hazy opacity:56\n",
      "cardiomegaly:76\n",
      "subcutaneous emphysema:11\n",
      "airspace opacity:75\n",
      "vascular congestion:78\n",
      "chest tube:25\n",
      "costophrenic angle blunting:54\n",
      "ij line:80\n",
      "pneumothorax:7\n",
      "linear/patchy atelectasis:67\n",
      "chest port:30\n",
      "atelectasis:75\n",
      "hyperaeration:14\n",
      "enlarged cardiomediastinum:78\n",
      "cabg grafts:32\n",
      "swan-ganz catheter:46\n",
      "lobar/segmental collapse:76\n",
      "pneumonia:31\n",
      "consolidation:66\n",
      "emphysema:4\n",
      "interstitial texture:33\n",
      "copd/emphysema:5\n",
      "hydropneumothorax:4\n",
      "infiltration:58\n",
      "tortuous aorta:26\n",
      "low lung volumes:38\n",
      "picc:25\n",
      "prosthetic valve:55\n",
      "elevated hemidiaphragm:24\n",
      "lung cancer:15\n",
      "alveolar texture:44\n",
      "hernia:4\n",
      "pneumomediastinum:18\n",
      "calcification of the aorta:33\n",
      "vascular calcification:60\n",
      "multiple masses/nodules:17\n",
      "interstitial lung disease:21\n",
      "subclavian line:16\n",
      "vascular redistribution:34\n",
      "nodule:9\n",
      "mediastinal displacement:76\n",
      "aortic graft/repair:39\n",
      "mass:21\n",
      "cyst/bullae:4\n",
      "pleural/parenchymal scarring:4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1. I, the attending signed below, have personally reviewed the images and agree with the report transcribed above. Interpreted by Attending Radiologist: Kaylee, Bell Authored By : MD Kaylee Bell Approval Date : 2-27-2008\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing OpenI inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 101/3729 reports with empty output\u001b[0m\n",
      "len(openi_train_input_texts): 3628\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 5/97 reports with empty output\u001b[0m\n",
      "len(openi_val_input_texts): 92\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "cardiac pacer and wires:8 6\n",
      "endotracheal tube:41 2\n",
      "enteric tube:33 2\n",
      "pleural effusion:3 6\n",
      "pleural abnormalities:14 24\n",
      "pigtail catheter:26 6\n",
      "lung opacity:14 23\n",
      "opacity texture:14 22\n",
      "tracheostomy tube:83 11\n",
      "no abnormalities:69 50\n",
      "support devices:65 10\n",
      "fluid overload/heart failure:3 5\n",
      "edema:2 4\n",
      "subcutaneous air:7 12\n",
      "enlarged cardiac silhouette:2 7\n",
      "pulmonary edema/hazy opacity:3 3\n",
      "cardiomegaly:1 7\n",
      "subcutaneous emphysema:5 10\n",
      "airspace opacity:9 14\n",
      "vascular congestion:3 10\n",
      "chest tube:29 3\n",
      "costophrenic angle blunting:11 15\n",
      "ij line:31 4\n",
      "pneumothorax:2 6\n",
      "linear/patchy atelectasis:13 14\n",
      "chest port:58 5\n",
      "atelectasis:5 10\n",
      "hyperaeration:5 17\n",
      "enlarged cardiomediastinum:4 15\n",
      "cabg grafts:5 6\n",
      "swan-ganz catheter:16 3\n",
      "lobar/segmental collapse:7 9\n",
      "pneumonia:6 13\n",
      "consolidation:5 14\n",
      "emphysema:4 12\n",
      "interstitial texture:15 29\n",
      "copd/emphysema:4 10\n",
      "hydropneumothorax:3 9\n",
      "infiltration:7 13\n",
      "tortuous aorta:15 47\n",
      "low lung volumes:8 15\n",
      "picc:49 13\n",
      "prosthetic valve:22 13\n",
      "elevated hemidiaphragm:9 11\n",
      "lung cancer:10 16\n",
      "alveolar texture:15 23\n",
      "hernia:15 19\n",
      "pneumomediastinum:9 18\n",
      "calcification of the aorta:13 55\n",
      "vascular calcification:8 24\n",
      "multiple masses/nodules:8 20\n",
      "interstitial lung disease:5 10\n",
      "subclavian line:32 8\n",
      "vascular redistribution:8 19\n",
      "nodule:13 33\n",
      "mediastinal displacement:8 12\n",
      "aortic graft/repair:24 9\n",
      "mass:6 20\n",
      "cyst/bullae:9 16\n",
      "pleural/parenchymal scarring:9 22\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mNo acute cardiopulmonary abnormality.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:4\n",
      "endotracheal tube:2\n",
      "enteric tube:2\n",
      "pleural effusion:3\n",
      "pleural abnormalities:11\n",
      "pigtail catheter:4\n",
      "lung opacity:9\n",
      "opacity texture:11\n",
      "tracheostomy tube:7\n",
      "no abnormalities:79\n",
      "support devices:12\n",
      "fluid overload/heart failure:3\n",
      "edema:3\n",
      "subcutaneous air:7\n",
      "enlarged cardiac silhouette:5\n",
      "pulmonary edema/hazy opacity:2\n",
      "cardiomegaly:4\n",
      "subcutaneous emphysema:6\n",
      "airspace opacity:7\n",
      "vascular congestion:3\n",
      "chest tube:2\n",
      "costophrenic angle blunting:12\n",
      "ij line:3\n",
      "pneumothorax:3\n",
      "linear/patchy atelectasis:7\n",
      "chest port:4\n",
      "atelectasis:4\n",
      "hyperaeration:8\n",
      "enlarged cardiomediastinum:8\n",
      "cabg grafts:7\n",
      "swan-ganz catheter:3\n",
      "lobar/segmental collapse:4\n",
      "pneumonia:5\n",
      "consolidation:6\n",
      "emphysema:6\n",
      "interstitial texture:13\n",
      "copd/emphysema:5\n",
      "hydropneumothorax:5\n",
      "infiltration:6\n",
      "tortuous aorta:27\n",
      "low lung volumes:9\n",
      "picc:5\n",
      "prosthetic valve:10\n",
      "elevated hemidiaphragm:10\n",
      "lung cancer:8\n",
      "alveolar texture:15\n",
      "hernia:10\n",
      "pneumomediastinum:13\n",
      "calcification of the aorta:22\n",
      "vascular calcification:10\n",
      "multiple masses/nodules:7\n",
      "interstitial lung disease:5\n",
      "subclavian line:4\n",
      "vascular redistribution:10\n",
      "nodule:10\n",
      "mediastinal displacement:6\n",
      "aortic graft/repair:7\n",
      "mass:6\n",
      "cyst/bullae:7\n",
      "pleural/parenchymal scarring:9\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mRight apical cavitary lesion consistent with history of tuberculosis without active infectious process identified.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing Interpret-CXR public test set inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 710/3677 reports without images or empty output\u001b[0m\n",
      "len(public_test_input_texts): 2967\n",
      "Examples:\n",
      "\u001b[1mPublic test example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:3\n",
      "endotracheal tube:4\n",
      "enteric tube:6\n",
      "pleural effusion:86\n",
      "pleural abnormalities:86\n",
      "pigtail catheter:11\n",
      "lung opacity:85\n",
      "opacity texture:60\n",
      "tracheostomy tube:6\n",
      "no abnormalities:3\n",
      "support devices:29\n",
      "fluid overload/heart failure:17\n",
      "edema:25\n",
      "subcutaneous air:13\n",
      "enlarged cardiac silhouette:23\n",
      "pulmonary edema/hazy opacity:18\n",
      "cardiomegaly:18\n",
      "subcutaneous emphysema:12\n",
      "airspace opacity:76\n",
      "vascular congestion:25\n",
      "chest tube:20\n",
      "costophrenic angle blunting:50\n",
      "ij line:4\n",
      "pneumothorax:23\n",
      "linear/patchy atelectasis:69\n",
      "chest port:7\n",
      "atelectasis:82\n",
      "hyperaeration:8\n",
      "enlarged cardiomediastinum:19\n",
      "cabg grafts:3\n",
      "swan-ganz catheter:9\n",
      "lobar/segmental collapse:76\n",
      "pneumonia:62\n",
      "consolidation:63\n",
      "emphysema:9\n",
      "interstitial texture:21\n",
      "copd/emphysema:8\n",
      "hydropneumothorax:15\n",
      "infiltration:45\n",
      "tortuous aorta:12\n",
      "low lung volumes:15\n",
      "picc:15\n",
      "prosthetic valve:16\n",
      "elevated hemidiaphragm:25\n",
      "lung cancer:27\n",
      "alveolar texture:25\n",
      "hernia:14\n",
      "pneumomediastinum:15\n",
      "calcification of the aorta:13\n",
      "vascular calcification:11\n",
      "multiple masses/nodules:16\n",
      "interstitial lung disease:13\n",
      "subclavian line:5\n",
      "vascular redistribution:16\n",
      "nodule:14\n",
      "mediastinal displacement:29\n",
      "aortic graft/repair:5\n",
      "mass:21\n",
      "cyst/bullae:5\n",
      "pleural/parenchymal scarring:6\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mModerate pneumothorax with moderate pleural effusion, inflated right upper lobe and collapsed right lower lobe. No significant shift of the mediastinum. Findings discussed with Dr. ___ at 13:52 on ___ via telephone.\u001b[0m\n",
      "\n",
      "Including public test set in training dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low lung volumes: 273\n",
      "No labels: 606\n",
      "cyst/bullae: 1024\n",
      "nodule: 3915\n",
      "hyperaeration: 5609\n",
      "hydropneumothorax: 6561\n",
      "alveolar texture: 7265\n",
      "hernia: 9795\n",
      "subclavian line: 11394\n",
      "mass: 11622\n",
      "copd/emphysema: 12864\n",
      "pneumomediastinum: 13029\n",
      "pneumothorax: 13881\n",
      "subcutaneous emphysema: 14710\n",
      "cabg grafts: 19218\n",
      "fluid overload/heart failure: 21082\n",
      "tracheostomy tube: 22061\n",
      "cardiomegaly: 22966\n",
      "picc: 23001\n",
      "interstitial lung disease: 30008\n",
      "pigtail catheter: 32919\n",
      "chest port: 34012\n",
      "elevated hemidiaphragm: 35133\n",
      "pleural/parenchymal scarring: 36044\n",
      "subcutaneous air: 37935\n",
      "swan-ganz catheter: 38255\n",
      "multiple masses/nodules: 39452\n",
      "lung cancer: 39623\n",
      "emphysema: 43610\n",
      "aortic graft/repair: 45170\n",
      "infiltration: 57785\n",
      "pneumonia: 59549\n",
      "cardiac pacer and wires: 60312\n",
      "no abnormalities: 61234\n",
      "endotracheal tube: 66828\n",
      "chest tube: 69260\n",
      "enlarged cardiac silhouette: 69673\n",
      "pulmonary edema/hazy opacity: 81874\n",
      "mediastinal displacement: 83106\n",
      "edema: 89462\n",
      "enteric tube: 90093\n",
      "costophrenic angle blunting: 90528\n",
      "pleural effusion: 98275\n",
      "prosthetic valve: 123350\n",
      "interstitial texture: 130184\n",
      "vascular redistribution: 130713\n",
      "support devices: 134942\n",
      "lobar/segmental collapse: 135955\n",
      "enlarged cardiomediastinum: 143816\n",
      "ij line: 144242\n",
      "tortuous aorta: 155018\n",
      "calcification of the aorta: 170311\n",
      "atelectasis: 171625\n",
      "vascular calcification: 186815\n",
      "consolidation: 189474\n",
      "vascular congestion: 194423\n",
      "airspace opacity: 195112\n",
      "opacity texture: 218227\n",
      "lung opacity: 248532\n",
      "linear/patchy atelectasis: 249019\n",
      "pleural abnormalities: 256459\n",
      "Group sizes: [43905, 19941, 17672, 16119, 12984, 12385, 11694, 10688, 9943, 9509, 9128, 8588, 8578, 7543, 7198, 7071, 7032, 6969, 6387, 6286, 6033, 5952, 5772, 5405, 5256, 5183, 5114, 5065, 3640, 3479, 3151, 3138, 3052, 2891, 2585, 2509, 2282, 1824, 1706, 1510, 1024, 778, 710, 606, 495, 473, 379, 360, 273, 253, 224, 201, 195, 172, 142, 131, 130, 122, 170]\n",
      "  len(indices) = 43905, weight = 3668.0085894436424\n",
      "  len(indices) = 19941, weight = 2914.0659026298995\n",
      "  len(indices) = 17672, weight = 2808.6984213243313\n",
      "  len(indices) = 16119, weight = 2730.1903101762614\n",
      "  len(indices) = 12984, weight = 2551.3862377901255\n",
      "  len(indices) = 12385, weight = 2513.406967581201\n",
      "  len(indices) = 11694, weight = 2467.753031619173\n",
      "  len(indices) = 10688, weight = 2397.3364990559635\n",
      "  len(indices) = 9943, weight = 2341.756768346086\n",
      "  len(indices) = 9509, weight = 2307.8585338672647\n",
      "  len(indices) = 9128, weight = 2277.0880373042714\n",
      "  len(indices) = 8588, weight = 2231.711200361847\n",
      "  len(indices) = 8578, weight = 2230.85015467229\n",
      "  len(indices) = 7543, weight = 2137.179122456066\n",
      "  len(indices) = 7198, weight = 2103.7356051113597\n",
      "  len(indices) = 7071, weight = 2091.1113973827614\n",
      "  len(indices) = 7032, weight = 2087.1994431935072\n",
      "  len(indices) = 6969, weight = 2080.8445017035688\n",
      "  len(indices) = 6387, weight = 2019.9300513761025\n",
      "  len(indices) = 6286, weight = 2008.9262136953948\n",
      "  len(indices) = 6033, weight = 1980.7510512660886\n",
      "  len(indices) = 5952, weight = 1971.5382557217767\n",
      "  len(indices) = 5772, weight = 1950.7145475320117\n",
      "  len(indices) = 5405, weight = 1906.660396433076\n",
      "  len(indices) = 5256, weight = 1888.1174796174976\n",
      "  len(indices) = 5183, weight = 1878.8852419986997\n",
      "  len(indices) = 5114, weight = 1870.0668347450503\n",
      "  len(indices) = 5065, weight = 1863.7489968638745\n",
      "  len(indices) = 3640, weight = 1655.4790809691576\n",
      "  len(indices) = 3479, weight = 1628.2296390247218\n",
      "  len(indices) = 3151, weight = 1569.629319067689\n",
      "  len(indices) = 3138, weight = 1567.2138768065774\n",
      "  len(indices) = 3052, weight = 1551.0424903564997\n",
      "  len(indices) = 2891, weight = 1519.8250022159373\n",
      "  len(indices) = 2585, weight = 1456.7116722759806\n",
      "  len(indices) = 2509, weight = 1440.1776701974277\n",
      "  len(indices) = 2282, weight = 1388.4659027584787\n",
      "  len(indices) = 1824, weight = 1271.2559581336277\n",
      "  len(indices) = 1706, weight = 1237.5885553154933\n",
      "  len(indices) = 1510, weight = 1177.694966133201\n",
      "  len(indices) = 1024, weight = 1000.0\n",
      "  len(indices) = 778, weight = 885.7389906403556\n",
      "  len(indices) = 710, weight = 849.7289069360278\n",
      "  len(indices) = 606, weight = 789.7022645620785\n",
      "  len(indices) = 495, weight = 717.226145959771\n",
      "  len(indices) = 473, weight = 701.5754889229496\n",
      "  len(indices) = 379, weight = 628.5537609432805\n",
      "  len(indices) = 360, weight = 612.3608505757353\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 253, weight = 508.74170266677504\n",
      "  len(indices) = 224, weight = 475.89568659197374\n",
      "  len(indices) = 201, weight = 447.8817931761667\n",
      "  len(indices) = 195, weight = 440.2474222842083\n",
      "  len(indices) = 172, weight = 409.5541064098074\n",
      "  len(indices) = 142, weight = 365.48709272231446\n",
      "  len(indices) = 131, weight = 347.9366776004082\n",
      "  len(indices) = 130, weight = 346.29858640647916\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "seq2seq_trainer.name =  fact_classifier_predictions2report_section(sigmoids2findings)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_205809_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_205809_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_205809_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 7.22712, s2s_loss 5.52883, 110.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 4.28140, 21.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_s2s_loss=0.1857.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.60690, s2s_loss 3.99555, 110.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 3.57223, 21.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_s2s_loss=0.2169.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 3.49599, s2s_loss 3.04159, 110.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 3.04787, 21.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_s2s_loss=0.2471.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.77543, s2s_loss 2.38349, 111.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.60895, 20.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_s2s_loss=0.2789.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 2.17280, s2s_loss 2.13129, 111.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.51999, 20.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_s2s_loss=0.2876.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.99105, s2s_loss 2.02131, 111.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.46297, 21.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_s2s_loss=0.2930.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 2.42462, s2s_loss 1.99950, 111.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.44226, 21.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_s2s_loss=0.2948.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.68107, s2s_loss 1.96773, 111.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.43192, 21.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_s2s_loss=0.2959.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.10832, s2s_loss 1.95132, 111.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.41864, 21.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_s2s_loss=0.2971.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.11707, s2s_loss 1.94592, 110.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.41022, 21.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_s2s_loss=0.2979.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.74687, s2s_loss 1.93495, 110.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.41256, 21.03 secs\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.16636, s2s_loss 1.93219, 111.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.40991, 21.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_s2s_loss=0.2980.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.62121, s2s_loss 1.93658, 111.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.37227, 20.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_s2s_loss=0.3009.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 2.18842, s2s_loss 1.84962, 113.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.29847, 21.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_s2s_loss=0.3079.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.60277, s2s_loss 1.83371, 110.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.29022, 21.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_s2s_loss=0.3088.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.96998, s2s_loss 1.82009, 109.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.26236, 21.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_s2s_loss=0.3113.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.07824, s2s_loss 1.78944, 110.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.25292, 21.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_s2s_loss=0.3125.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.69307, s2s_loss 1.80494, 111.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.25112, 21.05 secs\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.14052, s2s_loss 1.78119, 111.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.24939, 21.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_s2s_loss=0.3129.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.64887, s2s_loss 1.79683, 111.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.24750, 20.99 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.71245, s2s_loss 1.78101, 111.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.25036, 21.15 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.58099, s2s_loss 1.75154, 112.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.20573, 20.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_s2s_loss=0.3171.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.20352, s2s_loss 1.72123, 111.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.18205, 21.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_s2s_loss=0.3196.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.85676, s2s_loss 1.70975, 111.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.17261, 21.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_s2s_loss=0.3206.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.50480, s2s_loss 1.70364, 111.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.16388, 21.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_s2s_loss=0.3214.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.99628, s2s_loss 1.69853, 110.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.16099, 21.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_s2s_loss=0.3218.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.69456, s2s_loss 1.70470, 111.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.15760, 21.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_s2s_loss=0.3220.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "^C iteration 32675\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 588, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 499, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 326, in train_model\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1069, in _run_once_on_dataset_as_gen\n",
      "    self._fire_event(Events.ITERATION_COMPLETED)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 425, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/metrics/metric.py\", line 339, in completed\n",
      "    result = result.item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1200 \\\n",
    "--batch_size 4 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"fact_classifier_predictions2report_section\" \\\n",
    "--experiment_name \"sigmoids2findings\" \\\n",
    "--interpret_cxr__label_based_predictions_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\" \\\n",
    "--interpret_cxr_challenge_data_dir \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\" \\\n",
    "--mimiccxr_integrated_report_nli_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--report_section_to_generate \"impression\" \\\n",
    "--best_k_classes 60 \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--bart_model_name \"facebook/bart-base\" \\\n",
    "--include_public_test_in_train \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1200\n",
      "   batch_size: 4\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_205809_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: fact_classifier_predictions2report_section\n",
      "   experiment_name: sigmoids2impression\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\n",
      "   interpret_cxr_challenge_data_dir: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\n",
      "   mimiccxr_integrated_report_nli_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   report_section_to_generate: impression\n",
      "   include_public_test_in_train: True\n",
      "   best_k_classes: 75\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl...\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_probs(hash=234,1770274675398037115).pkl...\n",
      "thresholds.shape: (93,)\n",
      "f1s.shape: (93,)\n",
      "accs.shape: (93,)\n",
      "probs.shape: (607342, 93)\n",
      "len(image_paths): 607342\n",
      "len(class_names): 93\n",
      "Class names:\n",
      "1: cardiac pacer and wires, f1: 0.726, acc: 0.968\n",
      "2: endotracheal tube, f1: 0.688, acc: 0.942\n",
      "3: enteric tube, f1: 0.694, acc: 0.935\n",
      "4: pleural effusion, f1: 0.735, acc: 0.862\n",
      "5: pleural abnormalities, f1: 0.754, acc: 0.820\n",
      "6: pigtail catheter, f1: 0.569, acc: 0.990\n",
      "7: lung opacity, f1: 0.778, acc: 0.778\n",
      "8: opacity texture, f1: 0.780, acc: 0.769\n",
      "9: tracheostomy tube, f1: 0.555, acc: 0.988\n",
      "10: no abnormalities, f1: 0.651, acc: 0.860\n",
      "11: support devices, f1: 0.686, acc: 0.811\n",
      "12: fluid overload/heart failure, f1: 0.675, acc: 0.799\n",
      "13: edema, f1: 0.624, acc: 0.835\n",
      "14: subcutaneous air, f1: 0.475, acc: 0.983\n",
      "15: enlarged cardiac silhouette, f1: 0.630, acc: 0.812\n",
      "16: pulmonary edema/hazy opacity, f1: 0.578, acc: 0.863\n",
      "17: cardiomegaly, f1: 0.626, acc: 0.808\n",
      "18: subcutaneous emphysema, f1: 0.448, acc: 0.982\n",
      "19: airspace opacity, f1: 0.673, acc: 0.750\n",
      "20: vascular congestion, f1: 0.573, acc: 0.829\n",
      "21: chest tube, f1: 0.449, acc: 0.949\n",
      "22: costophrenic angle blunting, f1: 0.566, acc: 0.828\n",
      "23: ij line, f1: 0.450, acc: 0.942\n",
      "24: pneumothorax, f1: 0.420, acc: 0.957\n",
      "25: linear/patchy atelectasis, f1: 0.657, acc: 0.711\n",
      "26: chest port, f1: 0.405, acc: 0.961\n",
      "27: atelectasis, f1: 0.633, acc: 0.724\n",
      "28: hyperaeration, f1: 0.405, acc: 0.934\n",
      "29: enlarged cardiomediastinum, f1: 0.542, acc: 0.796\n",
      "30: cabg grafts, f1: 0.365, acc: 0.967\n",
      "31: swan-ganz catheter, f1: 0.340, acc: 0.986\n",
      "32: lobar/segmental collapse, f1: 0.600, acc: 0.722\n",
      "33: pneumonia, f1: 0.534, acc: 0.778\n",
      "34: consolidation, f1: 0.563, acc: 0.749\n",
      "35: emphysema, f1: 0.340, acc: 0.953\n",
      "36: interstitial texture, f1: 0.634, acc: 0.659\n",
      "37: copd/emphysema, f1: 0.367, acc: 0.924\n",
      "38: hydropneumothorax, f1: 0.305, acc: 0.979\n",
      "39: infiltration, f1: 0.519, acc: 0.762\n",
      "40: tortuous aorta, f1: 0.388, acc: 0.890\n",
      "41: low lung volumes, f1: 0.464, acc: 0.799\n",
      "42: picc, f1: 0.348, acc: 0.910\n",
      "43: prosthetic valve, f1: 0.273, acc: 0.975\n",
      "44: elevated hemidiaphragm, f1: 0.285, acc: 0.955\n",
      "45: lung cancer, f1: 0.310, acc: 0.928\n",
      "46: alveolar texture, f1: 0.588, acc: 0.631\n",
      "47: hernia, f1: 0.215, acc: 0.983\n",
      "48: pneumomediastinum, f1: 0.206, acc: 0.987\n",
      "49: calcification of the aorta, f1: 0.300, acc: 0.889\n",
      "50: vascular calcification, f1: 0.257, acc: 0.932\n",
      "51: multiple masses/nodules, f1: 0.223, acc: 0.962\n",
      "52: interstitial lung disease, f1: 0.253, acc: 0.929\n",
      "53: subclavian line, f1: 0.207, acc: 0.974\n",
      "54: vascular redistribution, f1: 0.273, acc: 0.900\n",
      "55: nodule, f1: 0.241, acc: 0.929\n",
      "56: mediastinal displacement, f1: 0.214, acc: 0.950\n",
      "57: aortic graft/repair, f1: 0.194, acc: 0.963\n",
      "58: mass, f1: 0.247, acc: 0.899\n",
      "59: cyst/bullae, f1: 0.186, acc: 0.959\n",
      "60: pleural/parenchymal scarring, f1: 0.295, acc: 0.849\n",
      "61: lung lesion, f1: 0.295, acc: 0.846\n",
      "62: fibrosis, f1: 0.277, acc: 0.862\n",
      "63: intra-aortic balloon pump, f1: 0.149, acc: 0.989\n",
      "64: granulomatous disease, f1: 0.167, acc: 0.967\n",
      "65: bronchiectasis, f1: 0.147, acc: 0.987\n",
      "66: mediastinal widening, f1: 0.218, acc: 0.914\n",
      "67: sub-diaphragmatic air, f1: 0.140, acc: 0.991\n",
      "68: mass/nodule (not otherwise specified), f1: 0.231, acc: 0.889\n",
      "69: increased reticular markings/ild pattern, f1: 0.281, acc: 0.830\n",
      "70: pericardial effusion, f1: 0.124, acc: 0.985\n",
      "71: alveolar hemorrhage, f1: 0.125, acc: 0.967\n",
      "72: calcified nodule, f1: 0.125, acc: 0.965\n",
      "73: scoliosis, f1: 0.129, acc: 0.953\n",
      "74: goiter, f1: 0.094, acc: 0.987\n",
      "75: superior mediastinal mass/enlargement, f1: 0.083, acc: 0.990\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing MIMIC-CXR inputs/outputs...\n",
      "100%|████████████████████████████████| 217190/217190 [00:13<00:00, 15696.39it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 91320/217190 reports without facts\u001b[0m\n",
      "len(mimiccxr_train_input_texts): 125870\n",
      "100%|████████████████████████████████████| 5568/5568 [00:00<00:00, 15756.20it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 2328/5568 reports without facts\u001b[0m\n",
      "len(mimiccxr_val_input_texts): 3240\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "pleural abnormalities:yes 4,yes 7\n",
      "lung opacity:no 3,yes 4\n",
      "opacity texture:no 2,yes 3\n",
      "costophrenic angle blunting:no 2,yes 5\n",
      "linear/patchy atelectasis:yes 5,yes 6\n",
      "atelectasis:no 3,yes 4\n",
      "tortuous aorta:yes 7,yes 7\n",
      "elevated hemidiaphragm:yes 4,yes 4\n",
      "calcification of the aorta:yes 7,yes 7\n",
      "vascular calcification:yes 4,yes 5\n",
      "vascular redistribution:yes 3,yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mmild increase in interstitial markings bilaterally. slight prominence of the hila. mild edema.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "pleural abnormalities:yes 7,yes 6\n",
      "lung opacity:yes 6,yes 7\n",
      "opacity texture:yes 4,yes 5\n",
      "enlarged cardiac silhouette:yes 6,no 3\n",
      "airspace opacity:no 2,yes 4\n",
      "vascular congestion:yes 6,yes 5\n",
      "linear/patchy atelectasis:yes 6,yes 6\n",
      "enlarged cardiomediastinum:yes 6,no 3\n",
      "consolidation:yes 2,yes 2\n",
      "interstitial texture:yes 5,yes 6\n",
      "tortuous aorta:yes 6,yes 6\n",
      "calcification of the aorta:yes 6,yes 6\n",
      "vascular calcification:yes 5,yes 4\n",
      "vascular redistribution:yes 5,yes 4\n",
      "increased reticular markings/ild pattern:yes 4,yes 5\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mmild pulmonary edema. low lung volumes.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing CheXpert inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 580/182199 reports with empty output\u001b[0m\n",
      "len(chexpert_train_input_texts): 181619\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 14/4603 reports with empty output\u001b[0m\n",
      "len(chexpert_val_input_texts): 4589\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "endotracheal tube:yes 5\n",
      "enteric tube:yes 5\n",
      "pleural abnormalities:yes 6\n",
      "lung opacity:yes 8\n",
      "opacity texture:yes 6\n",
      "tracheostomy tube:yes 6\n",
      "support devices:yes 8\n",
      "edema:yes 5\n",
      "pulmonary edema/hazy opacity:yes 4\n",
      "airspace opacity:yes 7\n",
      "vascular congestion:yes 5\n",
      "ij line:yes 7\n",
      "linear/patchy atelectasis:yes 7\n",
      "atelectasis:yes 6\n",
      "enlarged cardiomediastinum:yes 5\n",
      "lobar/segmental collapse:yes 6\n",
      "consolidation:yes 5\n",
      "interstitial texture:yes 5\n",
      "prosthetic valve:yes 6\n",
      "lung cancer:yes 2\n",
      "calcification of the aorta:yes 4\n",
      "vascular calcification:yes 4\n",
      "vascular redistribution:yes 4\n",
      "mediastinal displacement:yes 4\n",
      "aortic graft/repair:yes 5\n",
      "lung lesion:yes 2\n",
      "intra-aortic balloon pump:yes 4\n",
      "increased reticular markings/ild pattern:yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1. 2. Increased focal airspace opacities in the left upper lung zone, which may represent developing infection. Persistent mild pulmonary edema. I have personally reviewed the images for this examination and agreed with the report transcribed above.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1. THERE HAS BEEN INTERVAL PLACEMENT OF A LEFT SUBCLAVIAN CENTRAL VENOUS CATHETER, WITH ITS TIP IN THE SUPERIOR VENA CAVA. NO PNEUMOTHORAX IS IDENTIFIED. 2. THE CARDIOMEDIASTINAL SILHOUETTE IS WITHIN NORMAL LIMITS AND THE LUNGS ARE CLEAR BILATERALLY.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing OpenI inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 101/3729 reports with empty output\u001b[0m\n",
      "len(openi_train_input_texts): 3628\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 5/97 reports with empty output\u001b[0m\n",
      "len(openi_val_input_texts): 92\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "no abnormalities:yes 8,yes 6\n",
      "tortuous aorta:yes 4,yes 5\n",
      "calcification of the aorta:yes 3,yes 6\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mNo acute cardiopulmonary abnormality.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "no abnormalities:yes 5,yes 5\n",
      "calcification of the aorta:yes 3,yes 3\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mNo acute findings\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing Interpret-CXR public test set inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 710/3677 reports without images or empty output\u001b[0m\n",
      "len(public_test_input_texts): 2967\n",
      "Examples:\n",
      "\u001b[1mPublic test example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "endotracheal tube:yes 5\n",
      "enteric tube:yes 4\n",
      "pleural abnormalities:yes 6\n",
      "lung opacity:yes 8\n",
      "opacity texture:yes 6\n",
      "tracheostomy tube:yes 4\n",
      "fluid overload/heart failure:yes 7\n",
      "edema:yes 6\n",
      "enlarged cardiac silhouette:yes 6\n",
      "pulmonary edema/hazy opacity:yes 6\n",
      "airspace opacity:yes 7\n",
      "vascular congestion:yes 7\n",
      "ij line:yes 6\n",
      "linear/patchy atelectasis:yes 7\n",
      "atelectasis:yes 7\n",
      "enlarged cardiomediastinum:yes 6\n",
      "lobar/segmental collapse:yes 7\n",
      "consolidation:yes 4\n",
      "interstitial texture:yes 5\n",
      "prosthetic valve:yes 3\n",
      "vascular calcification:yes 5\n",
      "vascular redistribution:yes 5\n",
      "increased reticular markings/ild pattern:yes 5\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mET tube tip positioned 4 cm above the carina. NG tube extends inferiorly, tip not seen. Persistent pulmonary edema.\u001b[0m\n",
      "\n",
      "Including public test set in training dataset...\n",
      "bronchiectasis: 12\n",
      "scoliosis: 20\n",
      "sub-diaphragmatic air: 31\n",
      "low lung volumes: 273\n",
      "No labels: 519\n",
      "granulomatous disease: 567\n",
      "cyst/bullae: 1024\n",
      "nodule: 3915\n",
      "hyperaeration: 5609\n",
      "hydropneumothorax: 6561\n",
      "alveolar texture: 7265\n",
      "alveolar hemorrhage: 9753\n",
      "hernia: 9795\n",
      "subclavian line: 11394\n",
      "mass: 11622\n",
      "copd/emphysema: 12864\n",
      "pneumomediastinum: 13029\n",
      "pneumothorax: 13881\n",
      "subcutaneous emphysema: 14710\n",
      "calcified nodule: 17681\n",
      "goiter: 17735\n",
      "mass/nodule (not otherwise specified): 18355\n",
      "cabg grafts: 19218\n",
      "fluid overload/heart failure: 21082\n",
      "tracheostomy tube: 22061\n",
      "cardiomegaly: 22966\n",
      "picc: 23001\n",
      "interstitial lung disease: 30008\n",
      "pigtail catheter: 32919\n",
      "chest port: 34012\n",
      "elevated hemidiaphragm: 35133\n",
      "pleural/parenchymal scarring: 36044\n",
      "intra-aortic balloon pump: 36109\n",
      "subcutaneous air: 37935\n",
      "swan-ganz catheter: 38255\n",
      "multiple masses/nodules: 39452\n",
      "lung cancer: 39623\n",
      "mediastinal widening: 43255\n",
      "emphysema: 43610\n",
      "aortic graft/repair: 45170\n",
      "pericardial effusion: 48591\n",
      "superior mediastinal mass/enlargement: 48606\n",
      "fibrosis: 55454\n",
      "infiltration: 57785\n",
      "pneumonia: 59549\n",
      "cardiac pacer and wires: 60312\n",
      "no abnormalities: 61234\n",
      "endotracheal tube: 66828\n",
      "chest tube: 69260\n",
      "enlarged cardiac silhouette: 69673\n",
      "lung lesion: 81305\n",
      "pulmonary edema/hazy opacity: 81874\n",
      "mediastinal displacement: 83106\n",
      "edema: 89462\n",
      "enteric tube: 90093\n",
      "costophrenic angle blunting: 90528\n",
      "increased reticular markings/ild pattern: 96082\n",
      "pleural effusion: 98275\n",
      "prosthetic valve: 123350\n",
      "interstitial texture: 130184\n",
      "vascular redistribution: 130713\n",
      "support devices: 134942\n",
      "lobar/segmental collapse: 135955\n",
      "enlarged cardiomediastinum: 143816\n",
      "ij line: 144242\n",
      "tortuous aorta: 155018\n",
      "calcification of the aorta: 170311\n",
      "atelectasis: 171625\n",
      "vascular calcification: 186815\n",
      "consolidation: 189474\n",
      "vascular congestion: 194423\n",
      "airspace opacity: 195112\n",
      "opacity texture: 218227\n",
      "lung opacity: 248532\n",
      "linear/patchy atelectasis: 249019\n",
      "pleural abnormalities: 256459\n",
      "Group sizes: [37198, 17593, 17220, 15350, 12614, 11764, 10608, 9691, 8671, 8495, 8120, 8004, 7997, 7143, 6926, 6868, 6847, 6380, 5850, 5742, 5588, 5345, 5176, 4936, 4888, 4872, 4832, 4782, 4502, 4334, 4161, 3754, 3598, 3468, 3324, 3004, 2494, 2344, 2308, 2282, 2221, 2044, 1987, 1956, 1723, 1388, 1352, 1146, 1137, 1136, 943, 832, 560, 519, 487, 474, 378, 354, 326, 306, 273, 206, 170, 169, 166, 130, 115, 111, 94, 58, 57, 114]\n",
      "  len(indices) = 37198, weight = 3499.994865246517\n",
      "  len(indices) = 17593, weight = 2804.839960029521\n",
      "  len(indices) = 17220, weight = 2786.4338183476857\n",
      "  len(indices) = 15350, weight = 2689.06987550976\n",
      "  len(indices) = 12614, weight = 2528.094088771922\n",
      "  len(indices) = 11764, weight = 2472.473067315428\n",
      "  len(indices) = 10608, weight = 2391.516530061358\n",
      "  len(indices) = 9691, weight = 2322.2182873415286\n",
      "  len(indices) = 8671, weight = 2238.8278895313188\n",
      "  len(indices) = 8495, weight = 2223.6731249377995\n",
      "  len(indices) = 8120, weight = 2190.549178065082\n",
      "  len(indices) = 8004, weight = 2180.0619800445174\n",
      "  len(indices) = 7997, weight = 2179.4253599439116\n",
      "  len(indices) = 7143, weight = 2098.289782533978\n",
      "  len(indices) = 6926, weight = 2076.4814230359593\n",
      "  len(indices) = 6868, weight = 2070.563012519687\n",
      "  len(indices) = 6847, weight = 2068.41060402167\n",
      "  len(indices) = 6380, weight = 2019.1717563374636\n",
      "  len(indices) = 5850, weight = 1959.79863792244\n",
      "  len(indices) = 5742, weight = 1947.1955176977044\n",
      "  len(indices) = 5588, weight = 1928.9053254102107\n",
      "  len(indices) = 5345, weight = 1899.2411837997322\n",
      "  len(indices) = 5176, weight = 1877.994734444764\n",
      "  len(indices) = 4936, weight = 1846.8896681138704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  len(indices) = 4888, weight = 1840.5303536818296\n",
      "  len(indices) = 4872, weight = 1838.3999722839405\n",
      "  len(indices) = 4832, weight = 1833.0505230660021\n",
      "  len(indices) = 4782, weight = 1826.3159109280195\n",
      "  len(indices) = 4502, weight = 1787.5751734161904\n",
      "  len(indices) = 4334, weight = 1763.4404100944926\n",
      "  len(indices) = 4161, weight = 1737.8312815407912\n",
      "  len(indices) = 3754, weight = 1674.2276034829674\n",
      "  len(indices) = 3598, weight = 1648.4597506380362\n",
      "  len(indices) = 3468, weight = 1626.333384464924\n",
      "  len(indices) = 3324, weight = 1601.081104394279\n",
      "  len(indices) = 3004, weight = 1541.8673147118832\n",
      "  len(indices) = 2494, weight = 1436.8704293350106\n",
      "  len(indices) = 2344, weight = 1402.9558229953818\n",
      "  len(indices) = 2308, weight = 1394.577443232285\n",
      "  len(indices) = 2282, weight = 1388.4659027584787\n",
      "  len(indices) = 2221, weight = 1373.921994482261\n",
      "  len(indices) = 2044, weight = 1329.976414083735\n",
      "  len(indices) = 1987, weight = 1315.2272623723854\n",
      "  len(indices) = 1956, weight = 1307.0745148551043\n",
      "  len(indices) = 1723, weight = 1242.541994406717\n",
      "  len(indices) = 1388, weight = 1137.4981887030626\n",
      "  len(indices) = 1352, weight = 1125.1493836158581\n",
      "  len(indices) = 1146, weight = 1049.5128093493154\n",
      "  len(indices) = 1137, weight = 1045.992585600678\n",
      "  len(indices) = 1136, weight = 1045.6002198047302\n",
      "  len(indices) = 943, weight = 964.7565245906761\n",
      "  len(indices) = 832, weight = 912.7971248663157\n",
      "  len(indices) = 560, weight = 760.8692146254034\n",
      "  len(indices) = 519, weight = 733.7709170190359\n",
      "  len(indices) = 487, weight = 711.5905006887618\n",
      "  len(indices) = 474, weight = 702.2974400849914\n",
      "  len(indices) = 378, weight = 627.7150766285082\n",
      "  len(indices) = 354, weight = 607.1302286955697\n",
      "  len(indices) = 326, weight = 581.9168867187426\n",
      "  len(indices) = 306, weight = 563.0254813934722\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 169, weight = 405.3684909627789\n",
      "  len(indices) = 166, weight = 401.1372934962121\n",
      "  len(indices) = 130, weight = 346.29858640647916\n",
      "  len(indices) = 115, weight = 320.7846886341935\n",
      "  len(indices) = 111, weight = 313.65800492995106\n",
      "  len(indices) = 94, weight = 281.60240850497803\n",
      "  len(indices) = 58, weight = 201.02213219539033\n",
      "  len(indices) = 57, weight = 198.4501183111308\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "seq2seq_trainer.name =  fact_classifier_predictions2report_section(sigmoids2impression)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_58_s2s_loss=0.3413.pt', 'checkpoint_27_s2s_loss=0.3220.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_205809_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)/checkpoint_58_s2s_loss=0.3413.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.27405, s2s_loss 1.58478, 96.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.98620, 16.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_s2s_loss=0.3401.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.63900, s2s_loss 1.54672, 95.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.98267, 17.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_s2s_loss=0.3410.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.61263, s2s_loss 1.55286, 93.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.97854, 17.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_s2s_loss=0.3413.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.45110, s2s_loss 1.57594, 94.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.00936, 16.84 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 1.34067, s2s_loss 1.56126, 94.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.98693, 16.90 secs\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.50910, s2s_loss 1.54679, 94.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.96681, 16.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_s2s_loss=0.3426.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.77711, s2s_loss 1.52996, 95.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.95975, 16.81 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_s2s_loss=0.3436.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.15502, s2s_loss 1.52272, 92.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.95045, 17.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_s2s_loss=0.3447.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.43476, s2s_loss 1.51415, 94.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.95128, 17.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_s2s_loss=0.3447.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.78552, s2s_loss 1.51616, 93.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.94979, 16.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_s2s_loss=0.3448.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.83047, s2s_loss 1.51844, 92.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.94906, 17.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_s2s_loss=0.3449.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.66432, s2s_loss 1.50790, 94.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.94929, 16.51 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_s2s_loss=0.3450.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.82082, s2s_loss 1.53496, 95.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.99291, 17.19 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.30124, s2s_loss 1.51890, 93.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.96673, 17.03 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.40529, s2s_loss 1.50868, 93.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.93854, 17.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_s2s_loss=0.3461.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.76914, s2s_loss 1.49101, 93.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.93630, 16.96 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_s2s_loss=0.3467.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.34387, s2s_loss 1.49262, 95.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.92844, 17.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_s2s_loss=0.3474.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.07677, s2s_loss 1.50988, 95.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.92682, 16.93 secs\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.47790, s2s_loss 1.48749, 94.28 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 1.92505, 16.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_s2s_loss=0.3479.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.33326, s2s_loss 1.49574, 93.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.92751, 16.87 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.41522, s2s_loss 1.52249, 93.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.95948, 16.89 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.35964, s2s_loss 1.51649, 93.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.94679, 17.10 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.48286, s2s_loss 1.48685, 96.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.91941, 16.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_s2s_loss=0.3485.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.63056, s2s_loss 1.50110, 93.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.91501, 17.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_s2s_loss=0.3487.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.51478, s2s_loss 1.47472, 93.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.90719, 17.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_s2s_loss=0.3500.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.36836, s2s_loss 1.48989, 93.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.90355, 17.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_s2s_loss=0.3501.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.55959, s2s_loss 1.48719, 92.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.90435, 17.14 secs\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.62872, s2s_loss 1.47243, 95.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.90329, 16.71 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_s2s_loss=0.3504.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.16776, s2s_loss 1.50161, 95.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.93783, 16.78 secs\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.49147, s2s_loss 1.49283, 93.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.91645, 17.04 secs\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.36249, s2s_loss 1.48657, 93.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.90675, 17.15 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.14225, s2s_loss 1.46160, 94.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.89835, 16.90 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_s2s_loss=0.3511.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.25733, s2s_loss 1.46454, 95.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.89403, 16.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_s2s_loss=0.3516.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.76085, s2s_loss 1.46687, 94.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.89137, 17.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_34_s2s_loss=0.3518.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.70551, s2s_loss 1.45798, 93.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.89093, 17.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_s2s_loss=0.3520.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "   iteration 43000\r"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_205809_fact_classifier_predictions2report_section(sigmoids2findings)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1200 \\\n",
    "--batch_size 4 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"fact_classifier_predictions2report_section\" \\\n",
    "--experiment_name \"sigmoids2impression\" \\\n",
    "--interpret_cxr__label_based_predictions_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\" \\\n",
    "--interpret_cxr_challenge_data_dir \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\" \\\n",
    "--mimiccxr_integrated_report_nli_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--report_section_to_generate \"impression\" \\\n",
    "--best_k_classes 75 \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--bart_model_name \"facebook/bart-base\" \\\n",
    "--include_public_test_in_train \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 1200\n",
      "   batch_size: 4\n",
      "   checkpoint_folder: models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: fact_classifier_predictions2report_section\n",
      "   experiment_name: sigmoids2impression\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\n",
      "   interpret_cxr_challenge_data_dir: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\n",
      "   mimiccxr_integrated_report_nli_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   report_section_to_generate: impression\n",
      "   include_public_test_in_train: True\n",
      "   best_k_classes: 75\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl...\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_probs(hash=234,1770274675398037115).pkl...\n",
      "thresholds.shape: (93,)\n",
      "f1s.shape: (93,)\n",
      "accs.shape: (93,)\n",
      "probs.shape: (607342, 93)\n",
      "len(image_paths): 607342\n",
      "len(class_names): 93\n",
      "Class names:\n",
      "1: cardiac pacer and wires, f1: 0.726, acc: 0.968\n",
      "2: endotracheal tube, f1: 0.688, acc: 0.942\n",
      "3: enteric tube, f1: 0.694, acc: 0.935\n",
      "4: pleural effusion, f1: 0.735, acc: 0.862\n",
      "5: pleural abnormalities, f1: 0.754, acc: 0.820\n",
      "6: pigtail catheter, f1: 0.569, acc: 0.990\n",
      "7: lung opacity, f1: 0.778, acc: 0.778\n",
      "8: opacity texture, f1: 0.780, acc: 0.769\n",
      "9: tracheostomy tube, f1: 0.555, acc: 0.988\n",
      "10: no abnormalities, f1: 0.651, acc: 0.860\n",
      "11: support devices, f1: 0.686, acc: 0.811\n",
      "12: fluid overload/heart failure, f1: 0.675, acc: 0.799\n",
      "13: edema, f1: 0.624, acc: 0.835\n",
      "14: subcutaneous air, f1: 0.475, acc: 0.983\n",
      "15: enlarged cardiac silhouette, f1: 0.630, acc: 0.812\n",
      "16: pulmonary edema/hazy opacity, f1: 0.578, acc: 0.863\n",
      "17: cardiomegaly, f1: 0.626, acc: 0.808\n",
      "18: subcutaneous emphysema, f1: 0.448, acc: 0.982\n",
      "19: airspace opacity, f1: 0.673, acc: 0.750\n",
      "20: vascular congestion, f1: 0.573, acc: 0.829\n",
      "21: chest tube, f1: 0.449, acc: 0.949\n",
      "22: costophrenic angle blunting, f1: 0.566, acc: 0.828\n",
      "23: ij line, f1: 0.450, acc: 0.942\n",
      "24: pneumothorax, f1: 0.420, acc: 0.957\n",
      "25: linear/patchy atelectasis, f1: 0.657, acc: 0.711\n",
      "26: chest port, f1: 0.405, acc: 0.961\n",
      "27: atelectasis, f1: 0.633, acc: 0.724\n",
      "28: hyperaeration, f1: 0.405, acc: 0.934\n",
      "29: enlarged cardiomediastinum, f1: 0.542, acc: 0.796\n",
      "30: cabg grafts, f1: 0.365, acc: 0.967\n",
      "31: swan-ganz catheter, f1: 0.340, acc: 0.986\n",
      "32: lobar/segmental collapse, f1: 0.600, acc: 0.722\n",
      "33: pneumonia, f1: 0.534, acc: 0.778\n",
      "34: consolidation, f1: 0.563, acc: 0.749\n",
      "35: emphysema, f1: 0.340, acc: 0.953\n",
      "36: interstitial texture, f1: 0.634, acc: 0.659\n",
      "37: copd/emphysema, f1: 0.367, acc: 0.924\n",
      "38: hydropneumothorax, f1: 0.305, acc: 0.979\n",
      "39: infiltration, f1: 0.519, acc: 0.762\n",
      "40: tortuous aorta, f1: 0.388, acc: 0.890\n",
      "41: low lung volumes, f1: 0.464, acc: 0.799\n",
      "42: picc, f1: 0.348, acc: 0.910\n",
      "43: prosthetic valve, f1: 0.273, acc: 0.975\n",
      "44: elevated hemidiaphragm, f1: 0.285, acc: 0.955\n",
      "45: lung cancer, f1: 0.310, acc: 0.928\n",
      "46: alveolar texture, f1: 0.588, acc: 0.631\n",
      "47: hernia, f1: 0.215, acc: 0.983\n",
      "48: pneumomediastinum, f1: 0.206, acc: 0.987\n",
      "49: calcification of the aorta, f1: 0.300, acc: 0.889\n",
      "50: vascular calcification, f1: 0.257, acc: 0.932\n",
      "51: multiple masses/nodules, f1: 0.223, acc: 0.962\n",
      "52: interstitial lung disease, f1: 0.253, acc: 0.929\n",
      "53: subclavian line, f1: 0.207, acc: 0.974\n",
      "54: vascular redistribution, f1: 0.273, acc: 0.900\n",
      "55: nodule, f1: 0.241, acc: 0.929\n",
      "56: mediastinal displacement, f1: 0.214, acc: 0.950\n",
      "57: aortic graft/repair, f1: 0.194, acc: 0.963\n",
      "58: mass, f1: 0.247, acc: 0.899\n",
      "59: cyst/bullae, f1: 0.186, acc: 0.959\n",
      "60: pleural/parenchymal scarring, f1: 0.295, acc: 0.849\n",
      "61: lung lesion, f1: 0.295, acc: 0.846\n",
      "62: fibrosis, f1: 0.277, acc: 0.862\n",
      "63: intra-aortic balloon pump, f1: 0.149, acc: 0.989\n",
      "64: granulomatous disease, f1: 0.167, acc: 0.967\n",
      "65: bronchiectasis, f1: 0.147, acc: 0.987\n",
      "66: mediastinal widening, f1: 0.218, acc: 0.914\n",
      "67: sub-diaphragmatic air, f1: 0.140, acc: 0.991\n",
      "68: mass/nodule (not otherwise specified), f1: 0.231, acc: 0.889\n",
      "69: increased reticular markings/ild pattern, f1: 0.281, acc: 0.830\n",
      "70: pericardial effusion, f1: 0.124, acc: 0.985\n",
      "71: alveolar hemorrhage, f1: 0.125, acc: 0.967\n",
      "72: calcified nodule, f1: 0.125, acc: 0.965\n",
      "73: scoliosis, f1: 0.129, acc: 0.953\n",
      "74: goiter, f1: 0.094, acc: 0.987\n",
      "75: superior mediastinal mass/enlargement, f1: 0.083, acc: 0.990\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing MIMIC-CXR inputs/outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 217190/217190 [00:13<00:00, 16633.68it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 91320/217190 reports without facts\u001b[0m\n",
      "len(mimiccxr_train_input_texts): 125870\n",
      "100%|████████████████████████████████████| 5568/5568 [00:00<00:00, 16797.66it/s]\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 2328/5568 reports without facts\u001b[0m\n",
      "len(mimiccxr_val_input_texts): 3240\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 3\n",
      "cardiac pacer and wires:yes 6,yes 5,yes 3\n",
      "enteric tube:no 0,yes 2,no 1\n",
      "pleural effusion:no 2,yes 6,yes 7\n",
      "pleural abnormalities:yes 5,yes 7,yes 8\n",
      "lung opacity:yes 5,yes 6,yes 8\n",
      "opacity texture:yes 4,yes 4,yes 5\n",
      "support devices:yes 8,yes 8,yes 8\n",
      "airspace opacity:yes 3,yes 4,yes 4\n",
      "vascular congestion:yes 3,no 2,yes 5\n",
      "costophrenic angle blunting:no 3,yes 5,yes 6\n",
      "ij line:yes 7,yes 7,yes 7\n",
      "linear/patchy atelectasis:yes 4,yes 7,yes 8\n",
      "chest port:yes 7,yes 7,yes 6\n",
      "atelectasis:yes 4,yes 7,yes 7\n",
      "enlarged cardiomediastinum:yes 4,yes 4,no 3\n",
      "cabg grafts:no 4,no 4,yes 4\n",
      "swan-ganz catheter:yes 6,yes 6,yes 5\n",
      "lobar/segmental collapse:no 3,yes 6,yes 7\n",
      "consolidation:no 2,yes 3,yes 5\n",
      "prosthetic valve:yes 7,yes 7,yes 7\n",
      "calcification of the aorta:no 2,no 2,yes 3\n",
      "vascular calcification:yes 4,yes 4,yes 6\n",
      "aortic graft/repair:yes 4,yes 5,yes 4\n",
      "intra-aortic balloon pump:yes 3,yes 4,yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mno focal consolidation concerning for pneumonia. small chronic left pleural effusion. chronic atelectasis. aspiration.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "endotracheal tube:yes 7\n",
      "enteric tube:yes 7\n",
      "pleural abnormalities:yes 4\n",
      "lung opacity:yes 6\n",
      "opacity texture:yes 3\n",
      "support devices:yes 7\n",
      "subcutaneous air:yes 3\n",
      "airspace opacity:yes 4\n",
      "chest tube:yes 5\n",
      "ij line:yes 6\n",
      "linear/patchy atelectasis:yes 4\n",
      "consolidation:yes 3\n",
      "lung lesion:yes 2\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mno change in appearance of left pigtail catheter. no pneumothorax. no reaccumulation of pleural fluid.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing CheXpert inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 580/182199 reports with empty output\u001b[0m\n",
      "len(chexpert_train_input_texts): 181619\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 14/4603 reports with empty output\u001b[0m\n",
      "len(chexpert_val_input_texts): 4589\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 3\n",
      "cardiac pacer and wires:yes 3,yes 4,yes 3\n",
      "pleural effusion:yes 7,no 3,yes 8\n",
      "pleural abnormalities:yes 8,yes 5,yes 8\n",
      "lung opacity:yes 5,yes 5,yes 8\n",
      "opacity texture:no 3,yes 3,yes 4\n",
      "support devices:no 4,no 4,yes 5\n",
      "enlarged cardiac silhouette:yes 5,yes 7,yes 6\n",
      "cardiomegaly:no 5,yes 7,no 6\n",
      "airspace opacity:no 2,no 3,yes 5\n",
      "vascular congestion:no 1,yes 3,yes 4\n",
      "costophrenic angle blunting:yes 6,no 4,yes 6\n",
      "ij line:no 2,no 2,yes 3\n",
      "linear/patchy atelectasis:yes 6,yes 5,yes 7\n",
      "atelectasis:yes 5,no 4,yes 7\n",
      "enlarged cardiomediastinum:yes 5,yes 6,yes 6\n",
      "cabg grafts:no 3,yes 5,yes 4\n",
      "lobar/segmental collapse:no 3,no 3,yes 7\n",
      "consolidation:yes 3,no 2,yes 5\n",
      "tortuous aorta:no 2,no 3,yes 4\n",
      "prosthetic valve:yes 6,yes 8,yes 7\n",
      "elevated hemidiaphragm:no 3,no 3,yes 4\n",
      "calcification of the aorta:no 2,yes 4,yes 5\n",
      "vascular calcification:no 2,yes 3,yes 4\n",
      "aortic graft/repair:no 3,yes 4,yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1. No pneumothorax. 2. Unchanged small bilateral pleural effusions, left greater than right. I have personally reviewed the images for this examination and agreed with the report transcribed above.\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "endotracheal tube:yes 6\n",
      "enteric tube:yes 5\n",
      "pleural abnormalities:yes 7\n",
      "lung opacity:yes 6\n",
      "opacity texture:yes 4\n",
      "support devices:yes 8\n",
      "subcutaneous air:yes 3\n",
      "airspace opacity:yes 6\n",
      "vascular congestion:yes 3\n",
      "chest tube:yes 2\n",
      "ij line:yes 7\n",
      "linear/patchy atelectasis:yes 4\n",
      "consolidation:yes 5\n",
      "vascular calcification:yes 3\n",
      "multiple masses/nodules:yes 3\n",
      "lung lesion:yes 3\n",
      "increased reticular markings/ild pattern:yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1. THE SWAN- GANZ CATHETER TIP REMAINS AT THE REGION OF THE PULMONARY OUTFLOW TRACT. 2. NO PNEUMOTHORAX. INTERVAL IMPROVEMENT IN LEFT UPPER LOBE AERATION. SLIGHT INTERVAL INCREASE IN OPACITY OVER THE RIGHT MID AND UPPER LUNG ZONE. LAYERING APICAL LEFT PLEURAL EFFUSION PERSISTS.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing OpenI inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 101/3729 reports with empty output\u001b[0m\n",
      "len(openi_train_input_texts): 3628\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 5/97 reports with empty output\u001b[0m\n",
      "len(openi_val_input_texts): 92\n",
      "Examples:\n",
      "\u001b[1mTrain example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "pleural abnormalities:yes 3,yes 4\n",
      "lung opacity:yes 6,yes 5\n",
      "opacity texture:yes 4,yes 3\n",
      "airspace opacity:yes 4,no 3\n",
      "vascular congestion:yes 5,yes 5\n",
      "linear/patchy atelectasis:yes 4,yes 6\n",
      "atelectasis:no 4,yes 5\n",
      "enlarged cardiomediastinum:yes 5,no 4\n",
      "interstitial texture:yes 4,yes 4\n",
      "tortuous aorta:yes 4,no 3\n",
      "calcification of the aorta:yes 4,no 2\n",
      "vascular calcification:yes 3,no 2\n",
      "vascular redistribution:yes 4,yes 3\n",
      "superior mediastinal mass/enlargement:yes 3,no 2\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mLow lung volume exam. Otherwise, no acute findings. .\u001b[0m\n",
      "\n",
      "\u001b[1mVal example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 2\n",
      "cardiac pacer and wires:yes 3,no 1\n",
      "lung opacity:yes 4,no 3\n",
      "enlarged cardiac silhouette:yes 5,no 4\n",
      "vascular congestion:yes 3,no 3\n",
      "enlarged cardiomediastinum:yes 6,no 4\n",
      "tortuous aorta:yes 4,yes 5\n",
      "prosthetic valve:yes 5,yes 4\n",
      "calcification of the aorta:yes 5,yes 5\n",
      "vascular calcification:yes 3,yes 3\n",
      "aortic graft/repair:yes 3,no 2\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35mStable cardiomegaly without heart failure.\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Preparing Interpret-CXR public test set inputs/outputs...\n",
      "\u001b[93m\u001b[1mWARNING: Skipped 710/3677 reports without images or empty output\u001b[0m\n",
      "len(public_test_input_texts): 2967\n",
      "Examples:\n",
      "\u001b[1mPublic test example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mviews: 1\n",
      "cardiac pacer and wires:yes 7\n",
      "pleural abnormalities:yes 6\n",
      "lung opacity:yes 8\n",
      "opacity texture:yes 5\n",
      "support devices:yes 6\n",
      "airspace opacity:yes 5\n",
      "vascular congestion:yes 4\n",
      "linear/patchy atelectasis:yes 5\n",
      "atelectasis:yes 5\n",
      "enlarged cardiomediastinum:yes 5\n",
      "consolidation:yes 4\n",
      "prosthetic valve:yes 4\n",
      "intra-aortic balloon pump:yes 4\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m1.SINGLE UPRIGHT AP VIEW OF THE CHEST DEMONSTRATES A LEFT ANTERIOR CHEST WALL AICD DEVICE WITH 3 LEADS. 2.CARDIOMEGALY WITH NO EVIDENCE OF PULMONARY EDEMA. 3.SMALL LEFT PLEURAL EFFUSION AND RETROCARDIAC OPACITY. RECOMMEND CORRELATION WITH SUBSEQUENT CT OF THE SAME DAY.\u001b[0m\n",
      "\n",
      "Including public test set in training dataset...\n",
      "bronchiectasis: 12\n",
      "scoliosis: 20\n",
      "sub-diaphragmatic air: 31\n",
      "low lung volumes: 273\n",
      "No labels: 519\n",
      "granulomatous disease: 567\n",
      "cyst/bullae: 1024\n",
      "nodule: 3915\n",
      "hyperaeration: 5609\n",
      "hydropneumothorax: 6561\n",
      "alveolar texture: 7265\n",
      "alveolar hemorrhage: 9753\n",
      "hernia: 9795\n",
      "subclavian line: 11394\n",
      "mass: 11622\n",
      "copd/emphysema: 12864\n",
      "pneumomediastinum: 13029\n",
      "pneumothorax: 13881\n",
      "subcutaneous emphysema: 14710\n",
      "calcified nodule: 17681\n",
      "goiter: 17735\n",
      "mass/nodule (not otherwise specified): 18355\n",
      "cabg grafts: 19218\n",
      "fluid overload/heart failure: 21082\n",
      "tracheostomy tube: 22061\n",
      "cardiomegaly: 22966\n",
      "picc: 23001\n",
      "interstitial lung disease: 30008\n",
      "pigtail catheter: 32919\n",
      "chest port: 34012\n",
      "elevated hemidiaphragm: 35133\n",
      "pleural/parenchymal scarring: 36044\n",
      "intra-aortic balloon pump: 36109\n",
      "subcutaneous air: 37935\n",
      "swan-ganz catheter: 38255\n",
      "multiple masses/nodules: 39452\n",
      "lung cancer: 39623\n",
      "mediastinal widening: 43255\n",
      "emphysema: 43610\n",
      "aortic graft/repair: 45170\n",
      "pericardial effusion: 48591\n",
      "superior mediastinal mass/enlargement: 48606\n",
      "fibrosis: 55454\n",
      "infiltration: 57785\n",
      "pneumonia: 59549\n",
      "cardiac pacer and wires: 60312\n",
      "no abnormalities: 61234\n",
      "endotracheal tube: 66828\n",
      "chest tube: 69260\n",
      "enlarged cardiac silhouette: 69673\n",
      "lung lesion: 81305\n",
      "pulmonary edema/hazy opacity: 81874\n",
      "mediastinal displacement: 83106\n",
      "edema: 89462\n",
      "enteric tube: 90093\n",
      "costophrenic angle blunting: 90528\n",
      "increased reticular markings/ild pattern: 96082\n",
      "pleural effusion: 98275\n",
      "prosthetic valve: 123350\n",
      "interstitial texture: 130184\n",
      "vascular redistribution: 130713\n",
      "support devices: 134942\n",
      "lobar/segmental collapse: 135955\n",
      "enlarged cardiomediastinum: 143816\n",
      "ij line: 144242\n",
      "tortuous aorta: 155018\n",
      "calcification of the aorta: 170311\n",
      "atelectasis: 171625\n",
      "vascular calcification: 186815\n",
      "consolidation: 189474\n",
      "vascular congestion: 194423\n",
      "airspace opacity: 195112\n",
      "opacity texture: 218227\n",
      "lung opacity: 248532\n",
      "linear/patchy atelectasis: 249019\n",
      "pleural abnormalities: 256459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes: [37198, 17593, 17220, 15350, 12614, 11764, 10608, 9691, 8671, 8495, 8120, 8004, 7997, 7143, 6926, 6868, 6847, 6380, 5850, 5742, 5588, 5345, 5176, 4936, 4888, 4872, 4832, 4782, 4502, 4334, 4161, 3754, 3598, 3468, 3324, 3004, 2494, 2344, 2308, 2282, 2221, 2044, 1987, 1956, 1723, 1388, 1352, 1146, 1137, 1136, 943, 832, 560, 519, 487, 474, 378, 354, 326, 306, 273, 206, 170, 169, 166, 130, 115, 111, 94, 58, 57, 114]\n",
      "  len(indices) = 37198, weight = 3499.994865246517\n",
      "  len(indices) = 17593, weight = 2804.839960029521\n",
      "  len(indices) = 17220, weight = 2786.4338183476857\n",
      "  len(indices) = 15350, weight = 2689.06987550976\n",
      "  len(indices) = 12614, weight = 2528.094088771922\n",
      "  len(indices) = 11764, weight = 2472.473067315428\n",
      "  len(indices) = 10608, weight = 2391.516530061358\n",
      "  len(indices) = 9691, weight = 2322.2182873415286\n",
      "  len(indices) = 8671, weight = 2238.8278895313188\n",
      "  len(indices) = 8495, weight = 2223.6731249377995\n",
      "  len(indices) = 8120, weight = 2190.549178065082\n",
      "  len(indices) = 8004, weight = 2180.0619800445174\n",
      "  len(indices) = 7997, weight = 2179.4253599439116\n",
      "  len(indices) = 7143, weight = 2098.289782533978\n",
      "  len(indices) = 6926, weight = 2076.4814230359593\n",
      "  len(indices) = 6868, weight = 2070.563012519687\n",
      "  len(indices) = 6847, weight = 2068.41060402167\n",
      "  len(indices) = 6380, weight = 2019.1717563374636\n",
      "  len(indices) = 5850, weight = 1959.79863792244\n",
      "  len(indices) = 5742, weight = 1947.1955176977044\n",
      "  len(indices) = 5588, weight = 1928.9053254102107\n",
      "  len(indices) = 5345, weight = 1899.2411837997322\n",
      "  len(indices) = 5176, weight = 1877.994734444764\n",
      "  len(indices) = 4936, weight = 1846.8896681138704\n",
      "  len(indices) = 4888, weight = 1840.5303536818296\n",
      "  len(indices) = 4872, weight = 1838.3999722839405\n",
      "  len(indices) = 4832, weight = 1833.0505230660021\n",
      "  len(indices) = 4782, weight = 1826.3159109280195\n",
      "  len(indices) = 4502, weight = 1787.5751734161904\n",
      "  len(indices) = 4334, weight = 1763.4404100944926\n",
      "  len(indices) = 4161, weight = 1737.8312815407912\n",
      "  len(indices) = 3754, weight = 1674.2276034829674\n",
      "  len(indices) = 3598, weight = 1648.4597506380362\n",
      "  len(indices) = 3468, weight = 1626.333384464924\n",
      "  len(indices) = 3324, weight = 1601.081104394279\n",
      "  len(indices) = 3004, weight = 1541.8673147118832\n",
      "  len(indices) = 2494, weight = 1436.8704293350106\n",
      "  len(indices) = 2344, weight = 1402.9558229953818\n",
      "  len(indices) = 2308, weight = 1394.577443232285\n",
      "  len(indices) = 2282, weight = 1388.4659027584787\n",
      "  len(indices) = 2221, weight = 1373.921994482261\n",
      "  len(indices) = 2044, weight = 1329.976414083735\n",
      "  len(indices) = 1987, weight = 1315.2272623723854\n",
      "  len(indices) = 1956, weight = 1307.0745148551043\n",
      "  len(indices) = 1723, weight = 1242.541994406717\n",
      "  len(indices) = 1388, weight = 1137.4981887030626\n",
      "  len(indices) = 1352, weight = 1125.1493836158581\n",
      "  len(indices) = 1146, weight = 1049.5128093493154\n",
      "  len(indices) = 1137, weight = 1045.992585600678\n",
      "  len(indices) = 1136, weight = 1045.6002198047302\n",
      "  len(indices) = 943, weight = 964.7565245906761\n",
      "  len(indices) = 832, weight = 912.7971248663157\n",
      "  len(indices) = 560, weight = 760.8692146254034\n",
      "  len(indices) = 519, weight = 733.7709170190359\n",
      "  len(indices) = 487, weight = 711.5905006887618\n",
      "  len(indices) = 474, weight = 702.2974400849914\n",
      "  len(indices) = 378, weight = 627.7150766285082\n",
      "  len(indices) = 354, weight = 607.1302286955697\n",
      "  len(indices) = 326, weight = 581.9168867187426\n",
      "  len(indices) = 306, weight = 563.0254813934722\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 169, weight = 405.3684909627789\n",
      "  len(indices) = 166, weight = 401.1372934962121\n",
      "  len(indices) = 130, weight = 346.29858640647916\n",
      "  len(indices) = 115, weight = 320.7846886341935\n",
      "  len(indices) = 111, weight = 313.65800492995106\n",
      "  len(indices) = 94, weight = 281.60240850497803\n",
      "  len(indices) = 58, weight = 201.02213219539033\n",
      "  len(indices) = 57, weight = 198.4501183111308\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "seq2seq_trainer.name =  fact_classifier_predictions2report_section(sigmoids2impression)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_100_s2s_loss=0.3649.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)/checkpoint_100_s2s_loss=0.3649.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 101/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.03099, s2s_loss 1.40264, 95.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.80721, 16.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_101_s2s_loss=0.3622.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 102/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.73187, s2s_loss 1.39362, 95.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.79995, 17.13 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_102_s2s_loss=0.3632.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 103/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.26543, s2s_loss 1.39425, 95.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.79012, 16.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_103_s2s_loss=0.3643.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 104/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.09694, s2s_loss 1.37582, 96.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78614, 16.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_104_s2s_loss=0.3651.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 105/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.78681, s2s_loss 1.36701, 95.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78177, 17.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_105_s2s_loss=0.3658.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 106/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.21237, s2s_loss 1.38884, 94.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77872, 16.89 secs\n",
      "\u001b[1m---- Epoch 107/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.34817, s2s_loss 1.39399, 94.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77769, 16.91 secs\n",
      "\u001b[1m---- Epoch 108/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.54258, s2s_loss 1.38215, 94.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77837, 17.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_108_s2s_loss=0.3659.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 109/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.31808, s2s_loss 1.39639, 95.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.81165, 16.60 secs\n",
      "\u001b[1m---- Epoch 110/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.65093, s2s_loss 1.38390, 97.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78732, 16.99 secs\n",
      "\u001b[1m---- Epoch 111/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.54531, s2s_loss 1.38446, 96.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77632, 16.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_111_s2s_loss=0.3661.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 112/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.28410, s2s_loss 1.36867, 94.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77727, 16.96 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_112_s2s_loss=0.3663.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 113/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.86909, s2s_loss 1.36683, 94.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77276, 16.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_113_s2s_loss=0.3668.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 114/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.52243, s2s_loss 1.37167, 94.20 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 1.77283, 17.03 secs\n",
      "\u001b[1m---- Epoch 115/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.62913, s2s_loss 1.37090, 96.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77102, 16.47 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_115_s2s_loss=0.3670.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 116/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.12676, s2s_loss 1.36966, 96.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77123, 17.23 secs\n",
      "\u001b[1m---- Epoch 117/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.99871, s2s_loss 1.39021, 94.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.79867, 16.95 secs\n",
      "\u001b[1m---- Epoch 118/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.07851, s2s_loss 1.38064, 94.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78088, 17.18 secs\n",
      "\u001b[1m---- Epoch 119/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.50574, s2s_loss 1.37299, 94.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76823, 16.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_119_s2s_loss=0.3673.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 120/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.23144, s2s_loss 1.36938, 96.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77160, 16.85 secs\n",
      "\u001b[1m---- Epoch 121/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.50176, s2s_loss 1.37434, 94.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76463, 17.13 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_121_s2s_loss=0.3677.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 122/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.50574, s2s_loss 1.36127, 94.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76191, 17.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_122_s2s_loss=0.3682.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 123/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.42597, s2s_loss 1.36836, 95.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76014, 17.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_123_s2s_loss=0.3683.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 124/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.17236, s2s_loss 1.35194, 94.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76174, 16.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_124_s2s_loss=0.3684.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 125/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.39473, s2s_loss 1.37851, 94.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78764, 17.02 secs\n",
      "\u001b[1m---- Epoch 126/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.46278, s2s_loss 1.37779, 94.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77428, 16.38 secs\n",
      "\u001b[1m---- Epoch 127/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.57330, s2s_loss 1.37167, 95.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76361, 17.10 secs\n",
      "\u001b[1m---- Epoch 128/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.57225, s2s_loss 1.37211, 95.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75537, 17.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_128_s2s_loss=0.3688.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 129/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.40627, s2s_loss 1.35786, 94.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75579, 16.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_129_s2s_loss=0.3690.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 130/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.71587, s2s_loss 1.37057, 95.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75425, 16.99 secs\n",
      "\u001b[1m---- Epoch 131/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.61107, s2s_loss 1.36096, 95.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75323, 16.84 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_131_s2s_loss=0.3692.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 132/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.95282, s2s_loss 1.36269, 97.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75229, 16.90 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_132_s2s_loss=0.3693.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 133/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.53351, s2s_loss 1.37548, 94.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78497, 16.92 secs\n",
      "\u001b[1m---- Epoch 134/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.43552, s2s_loss 1.38560, 94.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77086, 17.02 secs\n",
      "\u001b[1m---- Epoch 135/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.75802, s2s_loss 1.36144, 94.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75847, 17.19 secs\n",
      "\u001b[1m---- Epoch 136/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.76704, s2s_loss 1.37257, 94.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75210, 16.95 secs\n",
      "\u001b[1m---- Epoch 137/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.14124, s2s_loss 1.37105, 96.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75251, 16.52 secs\n",
      "\u001b[1m---- Epoch 138/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.72501, s2s_loss 1.35821, 96.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75031, 16.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_138_s2s_loss=0.3696.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 139/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.22694, s2s_loss 1.35761, 96.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75098, 17.07 secs\n",
      "\u001b[1m---- Epoch 140/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.38105, s2s_loss 1.34719, 94.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75064, 17.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_140_s2s_loss=0.3698.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 141/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.53768, s2s_loss 1.38306, 95.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.78085, 16.87 secs\n",
      "\u001b[1m---- Epoch 142/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.17792, s2s_loss 1.37059, 96.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76597, 16.64 secs\n",
      "\u001b[1m---- Epoch 143/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.18630, s2s_loss 1.35968, 95.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75184, 17.13 secs\n",
      "\u001b[1m---- Epoch 144/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.33538, s2s_loss 1.36266, 94.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75044, 17.15 secs\n",
      "\u001b[1m---- Epoch 145/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.36288, s2s_loss 1.35342, 92.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74681, 16.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_145_s2s_loss=0.3701.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 146/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.38491, s2s_loss 1.36093, 93.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74563, 17.13 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_146_s2s_loss=0.3701.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 147/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.64465, s2s_loss 1.35554, 94.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74228, 17.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_147_s2s_loss=0.3706.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 148/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.07762, s2s_loss 1.33542, 96.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74361, 16.81 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_148_s2s_loss=0.3709.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 149/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.31242, s2s_loss 1.37978, 97.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.77588, 17.06 secs\n",
      "\u001b[1m---- Epoch 150/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.98075, s2s_loss 1.35788, 95.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74990, 17.06 secs\n",
      "\u001b[1m---- Epoch 151/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.48304, s2s_loss 1.35590, 95.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74740, 17.18 secs\n",
      "\u001b[1m---- Epoch 152/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.87759, s2s_loss 1.34710, 94.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74480, 17.20 secs\n",
      "\u001b[1m---- Epoch 153/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.85233, s2s_loss 1.34179, 94.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73936, 16.81 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_153_s2s_loss=0.3712.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 154/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.90306, s2s_loss 1.34388, 95.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73817, 17.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_154_s2s_loss=0.3714.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 155/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.19338, s2s_loss 1.33708, 94.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73846, 16.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_155_s2s_loss=0.3714.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 156/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.41816, s2s_loss 1.34287, 94.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73701, 17.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_156_s2s_loss=0.3715.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 157/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.47704, s2s_loss 1.36462, 95.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.76432, 17.22 secs\n",
      "\u001b[1m---- Epoch 158/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.36981, s2s_loss 1.36330, 95.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.74526, 17.03 secs\n",
      "\u001b[1m---- Epoch 159/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.19078, s2s_loss 1.34776, 97.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73709, 16.58 secs\n",
      "\u001b[1m---- Epoch 160/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.47023, s2s_loss 1.34832, 95.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.73348, 16.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_160_s2s_loss=0.3718.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 161/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.38217, s2s_loss 1.34639, 93.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.72959, 16.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_161_s2s_loss=0.3723.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 162/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.07245, s2s_loss 1.33702, 95.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.72957, 17.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_162_s2s_loss=0.3725.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 163/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.93209, s2s_loss 1.33890, 94.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.72944, 16.88 secs\n",
      "\u001b[1m---- Epoch 164/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.91189, s2s_loss 1.33789, 94.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.72966, 16.83 secs\n",
      "\u001b[1m---- Epoch 165/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.90943, s2s_loss 1.35523, 97.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.75004, 17.10 secs\n",
      "\u001b[1m---- Epoch 166/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.79128, s2s_loss 1.36358, 94.68 secs\n",
      "(2) Validation stage ...\n",
      "   iteration 475\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.43069, s2s_loss 1.30221, 96.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68516, 17.05 secs\n",
      "\u001b[1m---- Epoch 235/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.83431, s2s_loss 1.30560, 94.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68370, 17.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_235_s2s_loss=0.3787.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 236/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.69456, s2s_loss 1.31015, 96.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68298, 16.80 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_236_s2s_loss=0.3787.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 237/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.28198, s2s_loss 1.31716, 95.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.70838, 17.18 secs\n",
      "\u001b[1m---- Epoch 238/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.29358, s2s_loss 1.31316, 94.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69080, 17.21 secs\n",
      "\u001b[1m---- Epoch 239/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.35615, s2s_loss 1.32211, 94.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68326, 17.33 secs\n",
      "\u001b[1m---- Epoch 240/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.50248, s2s_loss 1.30973, 94.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67795, 17.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_240_s2s_loss=0.3794.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 241/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.47766, s2s_loss 1.29451, 96.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67775, 16.71 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_241_s2s_loss=0.3797.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 242/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.90511, s2s_loss 1.30621, 96.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67411, 17.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_242_s2s_loss=0.3799.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 243/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.61748, s2s_loss 1.29618, 94.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67657, 17.10 secs\n",
      "\u001b[1m---- Epoch 244/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.44883, s2s_loss 1.29370, 93.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67586, 17.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_244_s2s_loss=0.3799.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 245/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.12787, s2s_loss 1.31020, 94.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.70778, 17.06 secs\n",
      "\u001b[1m---- Epoch 246/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.33363, s2s_loss 1.30936, 94.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69203, 17.04 secs\n",
      "\u001b[1m---- Epoch 247/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.54219, s2s_loss 1.29926, 96.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68294, 16.97 secs\n",
      "\u001b[1m---- Epoch 248/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.18325, s2s_loss 1.31248, 96.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67616, 17.13 secs\n",
      "\u001b[1m---- Epoch 249/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.75276, s2s_loss 1.29353, 95.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67642, 16.98 secs\n",
      "\u001b[1m---- Epoch 250/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.42877, s2s_loss 1.29483, 95.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67362, 17.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_250_s2s_loss=0.3802.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 251/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.08549, s2s_loss 1.30063, 93.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67270, 16.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_251_s2s_loss=0.3802.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 252/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.15129, s2s_loss 1.28527, 94.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67333, 16.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_252_s2s_loss=0.3804.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 253/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.03344, s2s_loss 1.31043, 95.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69156, 16.60 secs\n",
      "\u001b[1m---- Epoch 254/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.39178, s2s_loss 1.32815, 94.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68417, 16.88 secs\n",
      "\u001b[1m---- Epoch 255/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.07212, s2s_loss 1.29595, 94.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67700, 17.02 secs\n",
      "\u001b[1m---- Epoch 256/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.27353, s2s_loss 1.29737, 93.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67194, 16.89 secs\n",
      "\u001b[1m---- Epoch 257/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.64225, s2s_loss 1.29802, 93.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67235, 17.14 secs\n",
      "\u001b[1m---- Epoch 258/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.02367, s2s_loss 1.29478, 95.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66832, 16.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_258_s2s_loss=0.3809.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 259/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.38328, s2s_loss 1.30451, 93.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66810, 17.05 secs\n",
      "\u001b[1m---- Epoch 260/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.49186, s2s_loss 1.28498, 93.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66879, 17.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_260_s2s_loss=0.3810.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 261/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.88812, s2s_loss 1.31094, 93.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69589, 17.05 secs\n",
      "\u001b[1m---- Epoch 262/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.56975, s2s_loss 1.32009, 94.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68420, 17.09 secs\n",
      "\u001b[1m---- Epoch 263/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.31096, s2s_loss 1.29054, 95.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67952, 16.89 secs\n",
      "\u001b[1m---- Epoch 264/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.57025, s2s_loss 1.29301, 97.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67169, 16.77 secs\n",
      "\u001b[1m---- Epoch 265/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.35017, s2s_loss 1.29302, 94.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66726, 17.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_265_s2s_loss=0.3810.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 266/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.22616, s2s_loss 1.28805, 95.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66697, 17.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_266_s2s_loss=0.3812.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 267/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.94154, s2s_loss 1.30469, 94.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66583, 17.14 secs\n",
      "\u001b[1m---- Epoch 268/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.27800, s2s_loss 1.28396, 95.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66627, 16.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_268_s2s_loss=0.3813.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 269/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.04126, s2s_loss 1.31081, 96.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68836, 16.77 secs\n",
      "\u001b[1m---- Epoch 270/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.45744, s2s_loss 1.29251, 95.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67543, 16.86 secs\n",
      "\u001b[1m---- Epoch 271/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.32622, s2s_loss 1.28839, 93.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67577, 17.14 secs\n",
      "\u001b[1m---- Epoch 272/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.13135, s2s_loss 1.29007, 96.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66551, 16.91 secs\n",
      "\u001b[1m---- Epoch 273/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.47471, s2s_loss 1.29757, 92.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66590, 17.13 secs\n",
      "\u001b[1m---- Epoch 274/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.54258, s2s_loss 1.28483, 96.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66293, 16.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_274_s2s_loss=0.3817.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 275/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.26340, s2s_loss 1.29312, 95.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66114, 17.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_275_s2s_loss=0.3818.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 276/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.24047, s2s_loss 1.28789, 94.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66113, 17.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_276_s2s_loss=0.3819.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 277/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.29048, s2s_loss 1.29740, 94.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68783, 17.05 secs\n",
      "\u001b[1m---- Epoch 278/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.84702, s2s_loss 1.29459, 94.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67367, 17.12 secs\n",
      "\u001b[1m---- Epoch 279/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.18015, s2s_loss 1.28730, 94.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67002, 16.79 secs\n",
      "\u001b[1m---- Epoch 280/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.47186, s2s_loss 1.28847, 94.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66689, 16.82 secs\n",
      "\u001b[1m---- Epoch 281/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.31209, s2s_loss 1.28650, 95.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66291, 17.08 secs\n",
      "\u001b[1m---- Epoch 282/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.13314, s2s_loss 1.28662, 94.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66017, 17.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_282_s2s_loss=0.3821.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 283/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.14264, s2s_loss 1.28648, 94.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66028, 17.00 secs\n",
      "\u001b[1m---- Epoch 284/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.34103, s2s_loss 1.27563, 95.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66081, 17.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_284_s2s_loss=0.3822.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 285/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.93558, s2s_loss 1.28816, 96.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.68940, 16.65 secs\n",
      "\u001b[1m---- Epoch 286/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.17597, s2s_loss 1.29358, 97.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.67024, 17.15 secs\n",
      "\u001b[1m---- Epoch 287/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.19679, s2s_loss 1.29277, 94.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65762, 16.98 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_287_s2s_loss=0.3823.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 288/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.94031, s2s_loss 1.29598, 95.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65950, 17.00 secs\n",
      "\u001b[1m---- Epoch 289/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.27956, s2s_loss 1.27278, 95.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65870, 16.98 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_289_s2s_loss=0.3825.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 290/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.75965, s2s_loss 1.26973, 94.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65494, 16.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_290_s2s_loss=0.3830.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 291/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.40967, s2s_loss 1.29134, 96.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65468, 16.68 secs\n",
      "\u001b[1m---- Epoch 292/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.22488, s2s_loss 1.28101, 95.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65482, 17.16 secs\n",
      "\u001b[1m---- Epoch 293/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.47694, s2s_loss 1.28570, 94.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.69087, 17.18 secs\n",
      "\u001b[1m---- Epoch 294/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.46019, s2s_loss 1.28558, 93.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66574, 17.09 secs\n",
      "\u001b[1m---- Epoch 295/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.33940, s2s_loss 1.29744, 94.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65760, 16.95 secs\n",
      "\u001b[1m---- Epoch 296/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.32671, s2s_loss 1.28697, 95.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65652, 16.59 secs\n",
      "\u001b[1m---- Epoch 297/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.33920, s2s_loss 1.28862, 96.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65295, 16.97 secs\n",
      "\u001b[1m---- Epoch 298/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.25698, s2s_loss 1.27896, 94.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65041, 16.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_298_s2s_loss=0.3834.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 299/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.16322, s2s_loss 1.29318, 95.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64977, 16.98 secs\n",
      "\u001b[1m---- Epoch 300/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.47946, s2s_loss 1.27334, 95.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64915, 17.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_300_s2s_loss=0.3837.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 301/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.25395, s2s_loss 1.28577, 96.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66950, 16.91 secs\n",
      "\u001b[1m---- Epoch 302/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.34787, s2s_loss 1.28982, 96.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65949, 16.70 secs\n",
      "\u001b[1m---- Epoch 303/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.99366, s2s_loss 1.28918, 97.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64887, 17.10 secs\n",
      "\u001b[1m---- Epoch 304/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.06642, s2s_loss 1.27566, 94.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65007, 17.03 secs\n",
      "\u001b[1m---- Epoch 305/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.08718, s2s_loss 1.26592, 94.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64791, 17.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_305_s2s_loss=0.3840.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 306/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.28496, s2s_loss 1.27887, 93.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64480, 16.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_306_s2s_loss=0.3842.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 307/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.21636, s2s_loss 1.27125, 96.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64502, 16.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_307_s2s_loss=0.3843.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 308/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.26869, s2s_loss 1.26946, 96.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64493, 17.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_308_s2s_loss=0.3843.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 309/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.12375, s2s_loss 1.29415, 94.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66686, 17.05 secs\n",
      "\u001b[1m---- Epoch 310/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.15186, s2s_loss 1.28296, 94.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65531, 16.99 secs\n",
      "\u001b[1m---- Epoch 311/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.62417, s2s_loss 1.29856, 94.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64779, 16.92 secs\n",
      "\u001b[1m---- Epoch 312/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.02996, s2s_loss 1.28283, 95.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64034, 16.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_312_s2s_loss=0.3847.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 313/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.21816, s2s_loss 1.27978, 96.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63944, 16.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_313_s2s_loss=0.3848.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 314/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.43688, s2s_loss 1.26853, 95.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64131, 16.90 secs\n",
      "\u001b[1m---- Epoch 315/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.34634, s2s_loss 1.26456, 94.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63898, 17.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_315_s2s_loss=0.3852.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 316/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.85980, s2s_loss 1.26731, 94.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63979, 16.91 secs\n",
      "\u001b[1m---- Epoch 317/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.94625, s2s_loss 1.28036, 94.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66361, 17.03 secs\n",
      "\u001b[1m---- Epoch 318/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.26038, s2s_loss 1.29181, 95.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65599, 16.54 secs\n",
      "\u001b[1m---- Epoch 319/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.12839, s2s_loss 1.28607, 97.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65556, 16.84 secs\n",
      "\u001b[1m---- Epoch 320/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.61024, s2s_loss 1.28478, 94.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64523, 17.01 secs\n",
      "\u001b[1m---- Epoch 321/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.07075, s2s_loss 1.26039, 94.60 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 1.64695, 17.08 secs\n",
      "\u001b[1m---- Epoch 322/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.02473, s2s_loss 1.27587, 93.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64105, 16.92 secs\n",
      "\u001b[1m---- Epoch 323/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.29355, s2s_loss 1.27085, 93.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64189, 16.97 secs\n",
      "\u001b[1m---- Epoch 324/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.26400, s2s_loss 1.26459, 95.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64107, 16.88 secs\n",
      "\u001b[1m---- Epoch 325/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.94240, s2s_loss 1.28910, 94.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.66140, 17.07 secs\n",
      "\u001b[1m---- Epoch 326/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.10092, s2s_loss 1.28705, 94.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65164, 16.73 secs\n",
      "\u001b[1m---- Epoch 327/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.19955, s2s_loss 1.29101, 94.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63850, 17.01 secs\n",
      "\u001b[1m---- Epoch 328/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.43909, s2s_loss 1.27005, 94.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63557, 16.98 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_328_s2s_loss=0.3855.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 329/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.27205, s2s_loss 1.25311, 96.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63528, 16.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_329_s2s_loss=0.3859.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 330/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.38031, s2s_loss 1.28133, 96.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63199, 17.09 secs\n",
      "\u001b[1m---- Epoch 331/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.07944, s2s_loss 1.27625, 95.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63333, 17.06 secs\n",
      "\u001b[1m---- Epoch 332/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.27070, s2s_loss 1.26526, 94.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63341, 17.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_332_s2s_loss=0.3859.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 333/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.47112, s2s_loss 1.27641, 94.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.65437, 17.10 secs\n",
      "\u001b[1m---- Epoch 334/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 1.51005, s2s_loss 1.27851, 95.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.64699, 16.72 secs\n",
      "\u001b[1m---- Epoch 335/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.41284, s2s_loss 1.27429, 97.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63698, 16.99 secs\n",
      "\u001b[1m---- Epoch 336/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.37191, s2s_loss 1.26955, 95.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63568, 17.07 secs\n",
      "\u001b[1m---- Epoch 337/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.32422, s2s_loss 1.28273, 93.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63113, 17.04 secs\n",
      "\u001b[1m---- Epoch 338/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.04701, s2s_loss 1.26363, 95.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 1.63284, 16.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_338_s2s_loss=0.3860.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 339/400\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "   iteration 286275\r"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/seq2seq/20240511_232138_fact_classifier_predictions2report_section(sigmoids2impression)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 1200 \\\n",
    "--batch_size 4 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"fact_classifier_predictions2report_section\" \\\n",
    "--experiment_name \"sigmoids2impression\" \\\n",
    "--interpret_cxr__label_based_predictions_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/results/phrase_grounding/20240511_045927_mim-facts+vinbig+chxp+iuxray_PhraseGrounder(dn121,128,256)/interpret_cxr__label_based_predictions(hash=368,3828061853141051818).pkl\" \\\n",
    "--interpret_cxr_challenge_data_dir \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/interpret-cxr-challenge/\" \\\n",
    "--mimiccxr_integrated_report_nli_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--report_section_to_generate \"impression\" \\\n",
    "--best_k_classes 75 \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--bart_model_name \"facebook/bart-base\" \\\n",
    "--include_public_test_in_train \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
