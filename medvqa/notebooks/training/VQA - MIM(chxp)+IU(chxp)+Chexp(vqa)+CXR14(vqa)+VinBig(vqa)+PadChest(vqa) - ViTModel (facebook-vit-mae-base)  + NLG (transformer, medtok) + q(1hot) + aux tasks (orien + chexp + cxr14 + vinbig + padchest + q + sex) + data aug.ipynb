{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: facebook/vit-mae-base\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,2e-4,93,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 55\n",
      "   iters_to_accumulate: 5\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.mask_token', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.0.layernorm_after.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,2e-4,93,1e-6\n",
      "1e-06 7 0.0002 93 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 55\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|███████████████████████████████████████████| 97/97 [00:11<00:00,  8.69it/s]\n",
      " *** merging from i=0 to j=2, acc_size = 70\n",
      "Balanced train data saved to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,1651436623822174339).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 55\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|██████████████████████████████████████████| 91/91 [00:00<00:00, 535.29it/s]\n",
      " *** merging from i=0 to j=19, acc_size = 57\n",
      " *** merging from i=20 to j=26, acc_size = 63\n",
      " *** merging from i=27 to j=31, acc_size = 63\n",
      " *** merging from i=32 to j=35, acc_size = 75\n",
      " *** merging from i=36 to j=37, acc_size = 55\n",
      " *** merging from i=38 to j=39, acc_size = 83\n",
      " *** merging from i=40 to j=41, acc_size = 91\n",
      " *** merging from i=42 to j=43, acc_size = 98\n",
      " *** merging from i=44 to j=45, acc_size = 112\n",
      "Balanced train data saved to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,4034709835837782143).pkl\n",
      "\tlen(question_datasets) = 54\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1447: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 113853.49it/s]\n",
      "Done. Example answer: <s> suboptimal study , metal , suture material , scoliosis </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 118625.92it/s]\n",
      "Done. Example answer: <s> loc hemithorax , loc right , loc left </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 62562.15it/s]\n",
      "Done. Example answer: <s> loc hemithorax loc mediastinum loc left alveolar pattern consolidation interstitial pattern pneumonia loc lobar loc right lower lobe exclude exclude dual chamber device pacemaker </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc rib , loc left </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:34,  5.54it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 12.00959, a_loss 8.77577, cD 0.00024, wmdcmp 0.00120, ema 0.00000, oracc 0.42470, orien_loss 1.12455, qlmicf1 0.09218, qlmacf1 0.07741, ql_loss 1.03393, chxlmicf1 0.15710, chxlmacf1 0.13753, chx_loss 1.09676, chxlacc 0.54682, chxlrocaucmic 0.45093, chxlrocaucmac 0.51426, gacc 0.48759, gloss 0.69385, cxr14micf1 0.11143, cxr14macf1 0.11829, cxr14_loss 1.23994, vnbgmicf1 0.18003, vnbgmacf1 0.14747, vnbg_loss 9.95773, b1 0.00155, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01017, padchxlmicf1 0.00610, padchxlzmacf1 0.02110, padchxlzmicf1 0.01377, padchxl_loss 0.84293, padchxlz_loss 0.90894, 118.62 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.00061, wmdcmp 0.00202, ema 0.00000, oracc 0.63892, qlmicf1 0.09783, qlmacf1 0.07984, chxlmicf1 0.14775, chxlmacf1 0.14162, chxlacc 0.53282, chxlrocaucmic 0.42312, chxlrocaucmac 0.51523, 30.68 secs\n",
      "Adjusting learning rate of group 0 to 2.1317e-06.\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 11.79753, a_loss 8.59613, cD 0.00037, wmdcmp 0.00136, ema 0.00000, oracc 0.64896, orien_loss 0.99105, qlmicf1 0.09826, qlmacf1 0.08073, ql_loss 1.03618, chxlmicf1 0.12991, chxlmacf1 0.13627, chx_loss 1.09604, chxlacc 0.60808, chxlrocaucmic 0.45130, chxlrocaucmac 0.50953, gacc 0.54755, gloss 0.68974, cxr14micf1 0.11096, cxr14macf1 0.11235, cxr14_loss 1.24439, vnbgmicf1 0.15320, vnbgmacf1 0.13268, vnbg_loss 9.73615, b1 0.00157, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01370, padchxlmicf1 0.00817, padchxlzmacf1 0.02285, padchxlzmicf1 0.01696, padchxl_loss 0.83050, padchxlz_loss 0.90141, 104.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00050, wmdcmp 0.00144, ema 0.00000, oracc 0.63892, qlmicf1 0.13317, qlmacf1 0.09628, chxlmicf1 0.07484, chxlmacf1 0.08893, chxlacc 0.61832, chxlrocaucmic 0.42700, chxlrocaucmac 0.51174, 30.31 secs\n",
      "Adjusting learning rate of group 0 to 4.5440e-06.\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 11.09689, a_loss 8.01115, cD 0.00017, wmdcmp 0.00018, ema 0.03706, oracc 0.67176, orien_loss 0.77208, qlmicf1 0.15674, qlmacf1 0.10020, ql_loss 1.03042, chxlmicf1 0.08830, chxlmacf1 0.13677, chx_loss 1.09733, chxlacc 0.62889, chxlrocaucmic 0.47537, chxlrocaucmac 0.51459, gacc 0.55861, gloss 0.68606, cxr14micf1 0.10068, cxr14macf1 0.09887, cxr14_loss 1.24175, vnbgmicf1 0.17257, vnbgmacf1 0.15961, vnbg_loss 8.97035, b1 0.00017, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01432, padchxlmicf1 0.01315, padchxlzmacf1 0.01944, padchxlzmicf1 0.01936, padchxl_loss 0.83245, padchxlz_loss 0.88881, 101.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.68208, qlmicf1 0.15348, qlmacf1 0.09653, chxlmicf1 0.14832, chxlmacf1 0.19030, chxlacc 0.63729, chxlrocaucmic 0.53410, chxlrocaucmac 0.55830, 29.01 secs\n",
      "Adjusting learning rate of group 0 to 9.6863e-06.\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 10.77703, a_loss 7.20542, cD 0.00000, wmdcmp 0.00000, ema 0.04397, oracc 0.80179, orien_loss 0.53456, qlmicf1 0.19458, qlmacf1 0.10764, ql_loss 1.00557, chxlmicf1 0.29747, chxlmacf1 0.30655, chx_loss 1.08530, chxlacc 0.63061, chxlrocaucmic 0.62713, chxlrocaucmac 0.57405, gacc 0.55594, gloss 0.68656, cxr14micf1 0.10696, cxr14macf1 0.13822, cxr14_loss 1.24204, vnbgmicf1 0.11548, vnbgmacf1 0.14820, vnbg_loss 7.87937, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01249, padchxlmicf1 0.01313, padchxlzmacf1 0.02170, padchxlzmicf1 0.02970, padchxl_loss 0.78445, padchxlz_loss 0.85039, 100.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.89458, qlmicf1 0.22115, qlmacf1 0.11566, chxlmicf1 0.45601, chxlmacf1 0.37030, chxlacc 0.60599, chxlrocaucmic 0.69301, chxlrocaucmac 0.61320, 29.05 secs\n",
      "Adjusting learning rate of group 0 to 2.0648e-05.\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 10.09414, a_loss 6.50760, cD 0.00000, wmdcmp 0.00000, ema 0.04463, oracc 0.84574, orien_loss 0.40295, qlmicf1 0.24832, qlmacf1 0.12412, ql_loss 0.96426, chxlmicf1 0.35203, chxlmacf1 0.34850, chx_loss 1.07693, chxlacc 0.56838, chxlrocaucmic 0.63456, chxlrocaucmac 0.60194, gacc 0.56485, gloss 0.68178, cxr14micf1 0.12503, cxr14macf1 0.18651, cxr14_loss 1.23185, vnbgmicf1 0.20271, vnbgmacf1 0.18542, vnbg_loss 7.02498, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01498, padchxlmicf1 0.02601, padchxlzmacf1 0.02405, padchxlzmicf1 0.04807, padchxl_loss 0.70716, padchxlz_loss 0.78530, 101.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.90283, qlmicf1 0.33149, qlmacf1 0.13992, chxlmicf1 0.34262, chxlmacf1 0.35401, chxlacc 0.56821, chxlrocaucmic 0.61353, chxlrocaucmac 0.60897, 28.91 secs\n",
      "Adjusting learning rate of group 0 to 4.4014e-05.\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 7.79423, a_loss 5.65972, cD 0.03346, wmdcmp 0.00589, ema 0.03410, oracc 0.91947, orien_loss 0.21010, qlmicf1 0.28250, qlmacf1 0.13736, ql_loss 0.93522, chxlmicf1 0.37451, chxlmacf1 0.35752, chx_loss 1.06884, chxlacc 0.55619, chxlrocaucmic 0.64927, chxlrocaucmac 0.61354, gacc 0.61329, gloss 0.65942, cxr14micf1 0.14338, cxr14macf1 0.19713, cxr14_loss 1.21228, vnbgmicf1 0.20327, vnbgmacf1 0.18087, vnbg_loss 6.07372, b1 0.00003, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01873, padchxlmicf1 0.08810, padchxlzmacf1 0.03281, padchxlzmicf1 0.08092, padchxl_loss 0.56884, padchxlz_loss 0.67471, 101.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.09188, wmdcmp 0.01466, ema 0.00000, oracc 0.96486, qlmicf1 0.28730, qlmacf1 0.14397, chxlmicf1 0.42120, chxlmacf1 0.37137, chxlacc 0.55718, chxlrocaucmic 0.65240, chxlrocaucmac 0.61104, 29.13 secs\n",
      "Adjusting learning rate of group 0 to 9.3823e-05.\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 6.18561, a_loss 4.50188, cD 0.04802, wmdcmp 0.01197, ema 0.01462, oracc 0.94636, orien_loss 0.13929, qlmicf1 0.27248, qlmacf1 0.14330, ql_loss 0.91589, chxlmicf1 0.38108, chxlmacf1 0.35968, chx_loss 1.06526, chxlacc 0.56440, chxlrocaucmic 0.65323, chxlrocaucmac 0.61721, gacc 0.68675, gloss 0.56823, cxr14micf1 0.15324, cxr14macf1 0.20459, cxr14_loss 1.20124, vnbgmicf1 0.21701, vnbgmacf1 0.18676, vnbg_loss 4.79614, b1 0.00777, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02285, padchxlmicf1 0.09355, padchxlzmacf1 0.03872, padchxlzmicf1 0.09075, padchxl_loss 0.50220, padchxlz_loss 0.60791, 102.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.06917, wmdcmp 0.01466, ema 0.00000, oracc 0.94552, qlmicf1 0.28310, qlmacf1 0.15109, chxlmicf1 0.40497, chxlmacf1 0.36879, chxlacc 0.55660, chxlrocaucmic 0.65530, chxlrocaucmac 0.60993, 29.58 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 8.04449, a_loss 3.30313, cD 0.06865, wmdcmp 0.01546, ema 0.14135, oracc 0.96381, orien_loss 0.08719, qlmicf1 0.27027, qlmacf1 0.14657, ql_loss 0.91323, chxlmicf1 0.38020, chxlmacf1 0.36159, chx_loss 1.05633, chxlacc 0.58291, chxlrocaucmic 0.66130, chxlrocaucmac 0.63192, gacc 0.84266, gloss 0.35726, cxr14micf1 0.15616, cxr14macf1 0.20561, cxr14_loss 1.20483, vnbgmicf1 0.23157, vnbgmacf1 0.20053, vnbg_loss 3.51967, b1 0.01581, b2 0.00531, b3 0.00000, b4 0.00000, padchxlmacf1 0.02853, padchxlmicf1 0.10818, padchxlzmacf1 0.04583, padchxlzmicf1 0.09794, padchxl_loss 0.44670, padchxlz_loss 0.56257, 102.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.14633, wmdcmp 0.02468, ema 0.44315, oracc 0.97736, qlmicf1 0.25622, qlmacf1 0.15029, chxlmicf1 0.44351, chxlmacf1 0.38635, chxlacc 0.57541, chxlrocaucmic 0.71276, chxlrocaucmac 0.64805, 29.53 secs\n",
      "Adjusting learning rate of group 0 to 1.8892e-04.\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 2.96305, a_loss 2.46774, cD 0.11447, wmdcmp 0.02223, ema 0.38704, oracc 0.96901, orien_loss 0.06862, qlmicf1 0.27819, qlmacf1 0.15262, ql_loss 0.90399, chxlmicf1 0.40829, chxlmacf1 0.37918, chx_loss 1.03446, chxlacc 0.60882, chxlrocaucmic 0.69122, chxlrocaucmac 0.66187, gacc 0.88794, gloss 0.26052, cxr14micf1 0.17253, cxr14macf1 0.21458, cxr14_loss 1.19127, vnbgmicf1 0.35325, vnbgmacf1 0.25864, vnbg_loss 2.43482, b1 0.02767, b2 0.00899, b3 0.00495, b4 0.00330, padchxlmacf1 0.03169, padchxlmicf1 0.10562, padchxlzmacf1 0.05178, padchxlzmicf1 0.11231, padchxl_loss 0.44968, padchxlz_loss 0.57649, 101.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.15513, wmdcmp 0.02385, ema 0.52641, oracc 0.96061, qlmicf1 0.28834, qlmacf1 0.16508, chxlmicf1 0.46112, chxlmacf1 0.41262, chxlacc 0.55120, chxlrocaucmic 0.74478, chxlrocaucmac 0.67792, 29.02 secs\n",
      "Adjusting learning rate of group 0 to 1.7846e-04.\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000178) ...\n",
      "loss 2.39809, a_loss 2.12693, cD 0.16816, wmdcmp 0.03052, ema 0.46194, oracc 0.97183, orien_loss 0.06628, qlmicf1 0.28811, qlmacf1 0.15903, ql_loss 0.89358, chxlmicf1 0.43357, chxlmacf1 0.39651, chx_loss 1.01707, chxlacc 0.61926, chxlrocaucmic 0.70753, chxlrocaucmac 0.67970, gacc 0.91626, gloss 0.20579, cxr14micf1 0.20025, cxr14macf1 0.23423, cxr14_loss 1.16137, vnbgmicf1 0.41710, vnbgmacf1 0.28762, vnbg_loss 1.78981, b1 0.13783, b2 0.07278, b3 0.04479, b4 0.02756, padchxlmacf1 0.03244, padchxlmicf1 0.11555, padchxlzmacf1 0.05452, padchxlzmicf1 0.13911, padchxl_loss 0.42644, padchxlz_loss 0.54237, 102.19 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.22711, wmdcmp 0.03483, ema 0.60609, oracc 0.97288, qlmicf1 0.28397, qlmacf1 0.16896, chxlmicf1 0.48790, chxlmacf1 0.41777, chxlacc 0.64456, chxlrocaucmic 0.74591, chxlrocaucmac 0.69204, 29.04 secs\n",
      "Adjusting learning rate of group 0 to 1.6858e-04.\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000169) ...\n",
      "loss 1.50356, a_loss 1.96177, cD 0.26697, wmdcmp 0.04253, ema 0.50639, oracc 0.97250, orien_loss 0.05846, qlmicf1 0.29978, qlmacf1 0.16731, ql_loss 0.88167, chxlmicf1 0.44274, chxlmacf1 0.40297, chx_loss 1.00182, chxlacc 0.62814, chxlrocaucmic 0.72124, chxlrocaucmac 0.69381, gacc 0.91100, gloss 0.21554, cxr14micf1 0.22098, cxr14macf1 0.24795, cxr14_loss 1.14962, vnbgmicf1 0.45563, vnbgmacf1 0.33148, vnbg_loss 1.45557, b1 0.19379, b2 0.11394, b3 0.07185, b4 0.04801, padchxlmacf1 0.03589, padchxlmicf1 0.12699, padchxlzmacf1 0.05686, padchxlzmicf1 0.13219, padchxl_loss 0.42646, padchxlz_loss 0.55925, 102.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.24368, wmdcmp 0.03787, ema 0.61773, oracc 0.98325, qlmicf1 0.29941, qlmacf1 0.17528, chxlmicf1 0.48039, chxlmacf1 0.42852, chxlacc 0.60873, chxlrocaucmic 0.75030, chxlrocaucmac 0.70213, 29.51 secs\n",
      "Adjusting learning rate of group 0 to 1.5924e-04.\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 6.43474, a_loss 1.87045, cD 0.34502, wmdcmp 0.05218, ema 0.53112, oracc 0.97342, orien_loss 0.05440, qlmicf1 0.30565, qlmacf1 0.16871, ql_loss 0.87359, chxlmicf1 0.44932, chxlmacf1 0.41078, chx_loss 0.98522, chxlacc 0.63526, chxlrocaucmic 0.72669, chxlrocaucmac 0.70391, gacc 0.92273, gloss 0.19103, cxr14micf1 0.20468, cxr14macf1 0.23938, cxr14_loss 1.14695, vnbgmicf1 0.45916, vnbgmacf1 0.32780, vnbg_loss 1.30828, b1 0.27296, b2 0.16807, b3 0.10981, b4 0.07487, padchxlmacf1 0.03958, padchxlmicf1 0.12279, padchxlzmacf1 0.06301, padchxlzmicf1 0.13572, padchxl_loss 0.41524, padchxlz_loss 0.56364, 102.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.26917, wmdcmp 0.04271, ema 0.60251, oracc 0.97972, qlmicf1 0.31384, qlmacf1 0.17997, chxlmicf1 0.49123, chxlmacf1 0.42788, chxlacc 0.64994, chxlrocaucmic 0.75164, chxlrocaucmac 0.70549, 28.98 secs\n",
      "Adjusting learning rate of group 0 to 1.5042e-04.\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "loss 3.61945, a_loss 1.75347, cD 0.41355, wmdcmp 0.06109, ema 0.54624, oracc 0.97820, orien_loss 0.04639, qlmicf1 0.30714, qlmacf1 0.17404, ql_loss 0.85965, chxlmicf1 0.45997, chxlmacf1 0.41948, chx_loss 0.97272, chxlacc 0.64514, chxlrocaucmic 0.73974, chxlrocaucmac 0.71610, gacc 0.93714, gloss 0.15753, cxr14micf1 0.23049, cxr14macf1 0.25488, cxr14_loss 1.12237, vnbgmicf1 0.45541, vnbgmacf1 0.33058, vnbg_loss 1.23363, b1 0.32599, b2 0.22122, b3 0.15207, b4 0.11110, padchxlmacf1 0.03934, padchxlmicf1 0.13083, padchxlzmacf1 0.06419, padchxlzmicf1 0.14533, padchxl_loss 0.40459, padchxlz_loss 0.54704, 102.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.29342, wmdcmp 0.04867, ema 0.61146, oracc 0.97995, qlmicf1 0.31999, qlmacf1 0.18346, chxlmicf1 0.49199, chxlmacf1 0.43015, chxlacc 0.65347, chxlrocaucmic 0.75329, chxlrocaucmac 0.71078, 29.33 secs\n",
      "Adjusting learning rate of group 0 to 1.4209e-04.\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 5.74874, a_loss 1.70698, cD 0.45900, wmdcmp 0.06810, ema 0.55096, oracc 0.97575, orien_loss 0.04460, qlmicf1 0.31154, qlmacf1 0.17588, ql_loss 0.86797, chxlmicf1 0.46161, chxlmacf1 0.42158, chx_loss 0.96564, chxlacc 0.64974, chxlrocaucmic 0.74362, chxlrocaucmac 0.72341, gacc 0.94091, gloss 0.15949, cxr14micf1 0.26298, cxr14macf1 0.27517, cxr14_loss 1.09077, vnbgmicf1 0.47637, vnbgmacf1 0.35716, vnbg_loss 1.14222, b1 0.33779, b2 0.23046, b3 0.15608, b4 0.10969, padchxlmacf1 0.04095, padchxlmicf1 0.12948, padchxlzmacf1 0.06927, padchxlzmicf1 0.15269, padchxl_loss 0.39741, padchxlz_loss 0.52942, 104.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33122, wmdcmp 0.05136, ema 0.62310, oracc 0.98443, qlmicf1 0.33431, qlmacf1 0.18450, chxlmicf1 0.50482, chxlmacf1 0.43888, chxlacc 0.67318, chxlrocaucmic 0.76350, chxlrocaucmac 0.72107, 29.38 secs\n",
      "Adjusting learning rate of group 0 to 1.3423e-04.\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 1.94006, a_loss 1.64135, cD 0.51666, wmdcmp 0.07602, ema 0.55450, oracc 0.97834, orien_loss 0.04280, qlmicf1 0.32083, qlmacf1 0.17980, ql_loss 0.85659, chxlmicf1 0.46206, chxlmacf1 0.42335, chx_loss 0.95905, chxlacc 0.65154, chxlrocaucmic 0.74470, chxlrocaucmac 0.72260, gacc 0.94458, gloss 0.13881, cxr14micf1 0.26568, cxr14macf1 0.27283, cxr14_loss 1.07934, vnbgmicf1 0.48713, vnbgmacf1 0.35942, vnbg_loss 1.08098, b1 0.37342, b2 0.25826, b3 0.17790, b4 0.12587, padchxlmacf1 0.04439, padchxlmicf1 0.13770, padchxlzmacf1 0.06978, padchxlzmicf1 0.15223, padchxl_loss 0.38798, padchxlz_loss 0.51675, 103.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.31945, wmdcmp 0.05246, ema 0.63653, oracc 0.97594, qlmicf1 0.31325, qlmacf1 0.18462, chxlmicf1 0.48320, chxlmacf1 0.43521, chxlacc 0.65100, chxlrocaucmic 0.74398, chxlrocaucmac 0.71720, 29.50 secs\n",
      "Adjusting learning rate of group 0 to 1.2679e-04.\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000127) ...\n",
      "loss 5.76346, a_loss 1.61657, cD 0.55521, wmdcmp 0.08225, ema 0.56547, oracc 0.97887, orien_loss 0.04120, qlmicf1 0.31855, qlmacf1 0.18322, ql_loss 0.85739, chxlmicf1 0.46418, chxlmacf1 0.42547, chx_loss 0.95353, chxlacc 0.65541, chxlrocaucmic 0.74796, chxlrocaucmac 0.72662, gacc 0.94458, gloss 0.14256, cxr14micf1 0.27198, cxr14macf1 0.28025, cxr14_loss 1.07294, vnbgmicf1 0.50872, vnbgmacf1 0.37423, vnbg_loss 1.00825, b1 0.38031, b2 0.27070, b3 0.18773, b4 0.13346, padchxlmacf1 0.04694, padchxlmicf1 0.13286, padchxlzmacf1 0.06855, padchxlzmicf1 0.14375, padchxl_loss 0.40461, padchxlz_loss 0.55206, 102.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.51314, wmdcmp 0.07792, ema 0.63742, oracc 0.98066, qlmicf1 0.32491, qlmacf1 0.19137, chxlmicf1 0.49858, chxlmacf1 0.44587, chxlacc 0.65207, chxlrocaucmic 0.76422, chxlrocaucmac 0.73154, 29.65 secs\n",
      "Adjusting learning rate of group 0 to 1.1977e-04.\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000120) ...\n",
      "loss 1.35334, a_loss 1.56900, cD 0.56737, wmdcmp 0.08312, ema 0.57025, oracc 0.97662, orien_loss 0.04559, qlmicf1 0.32069, qlmacf1 0.18446, ql_loss 0.85102, chxlmicf1 0.47157, chxlmacf1 0.43263, chx_loss 0.94251, chxlacc 0.66384, chxlrocaucmic 0.75587, chxlrocaucmac 0.73435, gacc 0.94303, gloss 0.14501, cxr14micf1 0.27884, cxr14macf1 0.28730, cxr14_loss 1.04726, vnbgmicf1 0.50509, vnbgmacf1 0.37865, vnbg_loss 0.99950, b1 0.38699, b2 0.27263, b3 0.19000, b4 0.13530, padchxlmacf1 0.05047, padchxlmicf1 0.14554, padchxlzmacf1 0.06994, padchxlzmicf1 0.14886, padchxl_loss 0.38238, padchxlz_loss 0.54518, 102.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.48572, wmdcmp 0.07416, ema 0.65354, oracc 0.98420, qlmicf1 0.35851, qlmacf1 0.19542, chxlmicf1 0.49546, chxlmacf1 0.44415, chxlacc 0.67144, chxlrocaucmic 0.75559, chxlrocaucmac 0.72377, 29.71 secs\n",
      "Adjusting learning rate of group 0 to 1.1314e-04.\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 1.28014, a_loss 1.54439, cD 0.61692, wmdcmp 0.08917, ema 0.56729, oracc 0.97856, orien_loss 0.03747, qlmicf1 0.32783, qlmacf1 0.18603, ql_loss 0.84680, chxlmicf1 0.47390, chxlmacf1 0.43393, chx_loss 0.94272, chxlacc 0.67002, chxlrocaucmic 0.75810, chxlrocaucmac 0.73788, gacc 0.94961, gloss 0.13492, cxr14micf1 0.26707, cxr14macf1 0.28410, cxr14_loss 1.07142, vnbgmicf1 0.49848, vnbgmacf1 0.37133, vnbg_loss 0.97443, b1 0.38134, b2 0.27378, b3 0.19460, b4 0.14024, padchxlmacf1 0.05238, padchxlmicf1 0.13741, padchxlzmacf1 0.07274, padchxlzmicf1 0.14698, padchxl_loss 0.39688, padchxlz_loss 0.52224, 102.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.58776, wmdcmp 0.08883, ema 0.64906, oracc 0.98373, qlmicf1 0.35149, qlmacf1 0.19694, chxlmicf1 0.49022, chxlmacf1 0.43957, chxlacc 0.68669, chxlrocaucmic 0.74703, chxlrocaucmac 0.72825, 29.65 secs\n",
      "Adjusting learning rate of group 0 to 1.0687e-04.\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000107) ...\n",
      "loss 2.02299, a_loss 1.49369, cD 0.64758, wmdcmp 0.09422, ema 0.58251, oracc 0.98044, orien_loss 0.03712, qlmicf1 0.32615, qlmacf1 0.18773, ql_loss 0.84011, chxlmicf1 0.47611, chxlmacf1 0.43591, chx_loss 0.93262, chxlacc 0.67042, chxlrocaucmic 0.76090, chxlrocaucmac 0.74196, gacc 0.95420, gloss 0.11798, cxr14micf1 0.28359, cxr14macf1 0.28932, cxr14_loss 1.04677, vnbgmicf1 0.52287, vnbgmacf1 0.39222, vnbg_loss 0.91829, b1 0.42395, b2 0.30529, b3 0.21226, b4 0.14769, padchxlmacf1 0.04881, padchxlmicf1 0.14368, padchxlzmacf1 0.07288, padchxlzmicf1 0.15558, padchxl_loss 0.37893, padchxlz_loss 0.51104, 102.39 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.62645, wmdcmp 0.09531, ema 0.64727, oracc 0.98373, qlmicf1 0.33809, qlmacf1 0.19683, chxlmicf1 0.51089, chxlmacf1 0.44894, chxlacc 0.68408, chxlrocaucmic 0.77213, chxlrocaucmac 0.73478, 29.94 secs\n",
      "Adjusting learning rate of group 0 to 1.0095e-04.\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000101) ...\n",
      "loss 5.96715, a_loss 1.49971, cD 0.65610, wmdcmp 0.09585, ema 0.58593, oracc 0.98037, orien_loss 0.03914, qlmicf1 0.33319, qlmacf1 0.19257, ql_loss 0.82853, chxlmicf1 0.48084, chxlmacf1 0.43898, chx_loss 0.92374, chxlacc 0.67574, chxlrocaucmic 0.76521, chxlrocaucmac 0.74710, gacc 0.95262, gloss 0.11743, cxr14micf1 0.28192, cxr14macf1 0.28888, cxr14_loss 1.04358, vnbgmicf1 0.53345, vnbgmacf1 0.40399, vnbg_loss 0.88314, b1 0.39941, b2 0.28870, b3 0.20135, b4 0.14239, padchxlmacf1 0.05134, padchxlmicf1 0.14397, padchxlzmacf1 0.07364, padchxlzmicf1 0.15275, padchxl_loss 0.39797, padchxlz_loss 0.51978, 102.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.61203, wmdcmp 0.09491, ema 0.65712, oracc 0.98514, qlmicf1 0.32826, qlmacf1 0.19771, chxlmicf1 0.48742, chxlmacf1 0.44647, chxlacc 0.65053, chxlrocaucmic 0.75082, chxlrocaucmac 0.73264, 29.56 secs\n",
      "Adjusting learning rate of group 0 to 9.5363e-05.\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 3.02902, a_loss 1.47056, cD 0.69933, wmdcmp 0.10087, ema 0.58599, oracc 0.98186, orien_loss 0.03698, qlmicf1 0.33759, qlmacf1 0.19320, ql_loss 0.83274, chxlmicf1 0.48134, chxlmacf1 0.44108, chx_loss 0.92351, chxlacc 0.67707, chxlrocaucmic 0.76750, chxlrocaucmac 0.75084, gacc 0.94892, gloss 0.12323, cxr14micf1 0.28902, cxr14macf1 0.29824, cxr14_loss 1.03856, vnbgmicf1 0.52677, vnbgmacf1 0.39158, vnbg_loss 0.90391, b1 0.42383, b2 0.30468, b3 0.21555, b4 0.15329, padchxlmacf1 0.05526, padchxlmicf1 0.14453, padchxlzmacf1 0.07399, padchxlzmicf1 0.15919, padchxl_loss 0.38004, padchxlz_loss 0.51168, 102.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.68585, wmdcmp 0.10348, ema 0.64906, oracc 0.98491, qlmicf1 0.32810, qlmacf1 0.19743, chxlmicf1 0.51598, chxlmacf1 0.45400, chxlacc 0.67951, chxlrocaucmic 0.78237, chxlrocaucmac 0.74355, 29.74 secs\n",
      "Adjusting learning rate of group 0 to 9.0082e-05.\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.78296, a_loss 1.44898, cD 0.71007, wmdcmp 0.10180, ema 0.59522, oracc 0.97979, orien_loss 0.03400, qlmicf1 0.33939, qlmacf1 0.19573, ql_loss 0.82649, chxlmicf1 0.48566, chxlmacf1 0.44579, chx_loss 0.92053, chxlacc 0.68116, chxlrocaucmic 0.76906, chxlrocaucmac 0.75152, gacc 0.94598, gloss 0.13199, cxr14micf1 0.31011, cxr14macf1 0.30790, cxr14_loss 0.99308, vnbgmicf1 0.52733, vnbgmacf1 0.38849, vnbg_loss 0.86406, b1 0.39562, b2 0.28233, b3 0.19281, b4 0.13085, padchxlmacf1 0.05618, padchxlmicf1 0.14492, padchxlzmacf1 0.07043, padchxlzmicf1 0.15116, padchxl_loss 0.39069, padchxlz_loss 0.51975, 102.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.73958, wmdcmp 0.10852, ema 0.65443, oracc 0.98632, qlmicf1 0.33160, qlmacf1 0.19893, chxlmicf1 0.48342, chxlmacf1 0.44418, chxlacc 0.66046, chxlrocaucmic 0.74610, chxlrocaucmac 0.73529, 29.53 secs\n",
      "Adjusting learning rate of group 0 to 8.5093e-05.\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000085) ...\n",
      "loss 1.83842, a_loss 1.42900, cD 0.70731, wmdcmp 0.10187, ema 0.59765, oracc 0.98220, orien_loss 0.03264, qlmicf1 0.34261, qlmacf1 0.20031, ql_loss 0.81843, chxlmicf1 0.48612, chxlmacf1 0.44438, chx_loss 0.92158, chxlacc 0.68234, chxlrocaucmic 0.77012, chxlrocaucmac 0.75105, gacc 0.95682, gloss 0.10759, cxr14micf1 0.31171, cxr14macf1 0.31052, cxr14_loss 1.00776, vnbgmicf1 0.54220, vnbgmacf1 0.39943, vnbg_loss 0.83544, b1 0.42842, b2 0.31354, b3 0.22446, b4 0.16227, padchxlmacf1 0.05794, padchxlmicf1 0.15300, padchxlzmacf1 0.07464, padchxlzmicf1 0.15746, padchxl_loss 0.37550, padchxlz_loss 0.52051, 102.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.74662, wmdcmp 0.11215, ema 0.65801, oracc 0.98491, qlmicf1 0.34615, qlmacf1 0.20354, chxlmicf1 0.50595, chxlmacf1 0.45179, chxlacc 0.66511, chxlrocaucmic 0.77279, chxlrocaucmac 0.74064, 29.38 secs\n",
      "Adjusting learning rate of group 0 to 8.0381e-05.\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 5.34349, a_loss 1.43906, cD 0.73536, wmdcmp 0.10423, ema 0.59519, oracc 0.98321, orien_loss 0.03309, qlmicf1 0.34212, qlmacf1 0.19855, ql_loss 0.82372, chxlmicf1 0.48848, chxlmacf1 0.44841, chx_loss 0.91022, chxlacc 0.68618, chxlrocaucmic 0.77267, chxlrocaucmac 0.75784, gacc 0.95874, gloss 0.10874, cxr14micf1 0.31105, cxr14macf1 0.31006, cxr14_loss 1.01143, vnbgmicf1 0.54444, vnbgmacf1 0.40779, vnbg_loss 0.82473, b1 0.42215, b2 0.30913, b3 0.22060, b4 0.15882, padchxlmacf1 0.05922, padchxlmicf1 0.15530, padchxlzmacf1 0.07760, padchxlzmicf1 0.15867, padchxl_loss 0.37410, padchxlz_loss 0.50355, 102.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.83600, wmdcmp 0.12096, ema 0.65980, oracc 0.98538, qlmicf1 0.36654, qlmacf1 0.20468, chxlmicf1 0.50658, chxlmacf1 0.45029, chxlacc 0.68599, chxlrocaucmic 0.77165, chxlrocaucmac 0.73917, 29.38 secs\n",
      "Adjusting learning rate of group 0 to 7.5930e-05.\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000076) ...\n",
      "loss 1.69703, a_loss 1.40476, cD 0.74025, wmdcmp 0.10529, ema 0.61105, oracc 0.97890, orien_loss 0.04021, qlmicf1 0.34306, qlmacf1 0.20191, ql_loss 0.81737, chxlmicf1 0.49046, chxlmacf1 0.44915, chx_loss 0.90707, chxlacc 0.68839, chxlrocaucmic 0.77454, chxlrocaucmac 0.75816, gacc 0.94930, gloss 0.11679, cxr14micf1 0.31115, cxr14macf1 0.31214, cxr14_loss 0.99774, vnbgmicf1 0.53568, vnbgmacf1 0.40569, vnbg_loss 0.85407, b1 0.40812, b2 0.29571, b3 0.20921, b4 0.14732, padchxlmacf1 0.05727, padchxlmicf1 0.15398, padchxlzmacf1 0.07215, padchxlzmicf1 0.15501, padchxl_loss 0.36569, padchxlz_loss 0.51125, 102.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.80559, wmdcmp 0.11897, ema 0.66786, oracc 0.98491, qlmicf1 0.33907, qlmacf1 0.19951, chxlmicf1 0.52249, chxlmacf1 0.44914, chxlacc 0.69138, chxlrocaucmic 0.78977, chxlrocaucmac 0.73652, 29.80 secs\n",
      "Adjusting learning rate of group 0 to 7.1725e-05.\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000072) ...\n",
      "loss 1.31640, a_loss 1.38712, cD 0.76809, wmdcmp 0.10828, ema 0.60113, oracc 0.98162, orien_loss 0.03237, qlmicf1 0.34506, qlmacf1 0.19927, ql_loss 0.81326, chxlmicf1 0.49198, chxlmacf1 0.44993, chx_loss 0.90835, chxlacc 0.68628, chxlrocaucmic 0.77668, chxlrocaucmac 0.75864, gacc 0.95758, gloss 0.10525, cxr14micf1 0.33122, cxr14macf1 0.31964, cxr14_loss 0.99361, vnbgmicf1 0.54006, vnbgmacf1 0.40887, vnbg_loss 0.81756, b1 0.43963, b2 0.31968, b3 0.22484, b4 0.15902, padchxlmacf1 0.06021, padchxlmicf1 0.15882, padchxlzmacf1 0.08143, padchxlzmicf1 0.16519, padchxl_loss 0.38139, padchxlz_loss 0.51545, 102.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.80692, wmdcmp 0.11845, ema 0.65354, oracc 0.98561, qlmicf1 0.35732, qlmacf1 0.20467, chxlmicf1 0.50279, chxlmacf1 0.45297, chxlacc 0.68284, chxlrocaucmic 0.76393, chxlrocaucmac 0.74686, 29.75 secs\n",
      "Adjusting learning rate of group 0 to 6.7753e-05.\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 5.58955, a_loss 1.41025, cD 0.75292, wmdcmp 0.10703, ema 0.60813, oracc 0.98185, orien_loss 0.02938, qlmicf1 0.34710, qlmacf1 0.20354, ql_loss 0.81439, chxlmicf1 0.49336, chxlmacf1 0.45046, chx_loss 0.90416, chxlacc 0.69150, chxlrocaucmic 0.77778, chxlrocaucmac 0.76078, gacc 0.96224, gloss 0.10816, cxr14micf1 0.30658, cxr14macf1 0.30880, cxr14_loss 0.99033, vnbgmicf1 0.54370, vnbgmacf1 0.40576, vnbg_loss 0.81310, b1 0.42642, b2 0.30990, b3 0.21959, b4 0.15679, padchxlmacf1 0.06077, padchxlmicf1 0.15705, padchxlzmacf1 0.07778, padchxlzmicf1 0.16429, padchxl_loss 0.37190, padchxlz_loss 0.50007, 102.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.89188, wmdcmp 0.12752, ema 0.67681, oracc 0.98538, qlmicf1 0.36039, qlmacf1 0.20636, chxlmicf1 0.50415, chxlmacf1 0.45614, chxlacc 0.67631, chxlrocaucmic 0.76924, chxlrocaucmac 0.74702, 29.48 secs\n",
      "Adjusting learning rate of group 0 to 6.4001e-05.\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000064) ...\n",
      "loss 3.03685, a_loss 1.36986, cD 0.80805, wmdcmp 0.11442, ema 0.59913, oracc 0.98244, orien_loss 0.03531, qlmicf1 0.35142, qlmacf1 0.20367, ql_loss 0.81233, chxlmicf1 0.49460, chxlmacf1 0.45265, chx_loss 0.90353, chxlacc 0.68836, chxlrocaucmic 0.77923, chxlrocaucmac 0.76124, gacc 0.95584, gloss 0.11403, cxr14micf1 0.32455, cxr14macf1 0.31726, cxr14_loss 1.00017, vnbgmicf1 0.54368, vnbgmacf1 0.40768, vnbg_loss 0.79559, b1 0.44338, b2 0.32393, b3 0.23009, b4 0.16451, padchxlmacf1 0.06037, padchxlmicf1 0.16522, padchxlzmacf1 0.08220, padchxlzmicf1 0.16438, padchxl_loss 0.36934, padchxlz_loss 0.50558, 102.28 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.91316, wmdcmp 0.12973, ema 0.66428, oracc 0.98420, qlmicf1 0.35617, qlmacf1 0.20474, chxlmicf1 0.52435, chxlmacf1 0.45768, chxlacc 0.70792, chxlrocaucmic 0.78493, chxlrocaucmac 0.74695, 29.75 secs\n",
      "Adjusting learning rate of group 0 to 6.0456e-05.\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 1.66321, a_loss 1.35724, cD 0.81741, wmdcmp 0.11514, ema 0.60539, oracc 0.98111, orien_loss 0.03517, qlmicf1 0.35292, qlmacf1 0.20410, ql_loss 0.80642, chxlmicf1 0.50255, chxlmacf1 0.45929, chx_loss 0.89426, chxlacc 0.69549, chxlrocaucmic 0.78521, chxlrocaucmac 0.76734, gacc 0.95874, gloss 0.10397, cxr14micf1 0.30304, cxr14macf1 0.30824, cxr14_loss 1.01939, vnbgmicf1 0.54935, vnbgmacf1 0.41341, vnbg_loss 0.79025, b1 0.44165, b2 0.32559, b3 0.23555, b4 0.16839, padchxlmacf1 0.05984, padchxlmicf1 0.16261, padchxlzmacf1 0.07543, padchxlzmicf1 0.15823, padchxl_loss 0.35462, padchxlz_loss 0.50322, 102.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.93786, wmdcmp 0.13388, ema 0.67502, oracc 0.98656, qlmicf1 0.35231, qlmacf1 0.20810, chxlmicf1 0.51027, chxlmacf1 0.45819, chxlacc 0.67884, chxlrocaucmic 0.77848, chxlrocaucmac 0.74747, 29.54 secs\n",
      "Adjusting learning rate of group 0 to 5.7108e-05.\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000057) ...\n",
      "loss 1.22404, a_loss 1.35537, cD 0.84067, wmdcmp 0.11730, ema 0.60531, oracc 0.98382, orien_loss 0.02910, qlmicf1 0.35437, qlmacf1 0.20792, ql_loss 0.80412, chxlmicf1 0.50484, chxlmacf1 0.46243, chx_loss 0.89043, chxlacc 0.69848, chxlrocaucmic 0.78496, chxlrocaucmac 0.76850, gacc 0.95602, gloss 0.10887, cxr14micf1 0.31955, cxr14macf1 0.31932, cxr14_loss 0.98044, vnbgmicf1 0.55532, vnbgmacf1 0.41435, vnbg_loss 0.79520, b1 0.45403, b2 0.33807, b3 0.24497, b4 0.17897, padchxlmacf1 0.06210, padchxlmicf1 0.15785, padchxlzmacf1 0.07967, padchxlzmicf1 0.16454, padchxl_loss 0.36704, padchxlz_loss 0.50988, 102.39 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.92209, wmdcmp 0.13334, ema 0.67592, oracc 0.98561, qlmicf1 0.36540, qlmacf1 0.20819, chxlmicf1 0.52002, chxlmacf1 0.45733, chxlacc 0.69907, chxlrocaucmic 0.78248, chxlrocaucmac 0.74749, 29.44 secs\n",
      "Adjusting learning rate of group 0 to 5.3946e-05.\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 5.56488, a_loss 1.36009, cD 0.86500, wmdcmp 0.12001, ema 0.61652, oracc 0.98173, orien_loss 0.02776, qlmicf1 0.35522, qlmacf1 0.20908, ql_loss 0.80147, chxlmicf1 0.50347, chxlmacf1 0.45821, chx_loss 0.88875, chxlacc 0.69792, chxlrocaucmic 0.78806, chxlrocaucmac 0.77043, gacc 0.96608, gloss 0.08743, cxr14micf1 0.33307, cxr14macf1 0.32502, cxr14_loss 0.97221, vnbgmicf1 0.55673, vnbgmacf1 0.42298, vnbg_loss 0.79238, b1 0.44562, b2 0.32871, b3 0.23921, b4 0.17591, padchxlmacf1 0.06345, padchxlmicf1 0.15930, padchxlzmacf1 0.08233, padchxlzmicf1 0.16135, padchxl_loss 0.36492, padchxlz_loss 0.51481, 102.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.96760, wmdcmp 0.13810, ema 0.66876, oracc 0.98561, qlmicf1 0.33762, qlmacf1 0.20585, chxlmicf1 0.51122, chxlmacf1 0.45792, chxlacc 0.67822, chxlrocaucmic 0.77752, chxlrocaucmac 0.75079, 29.46 secs\n",
      "Adjusting learning rate of group 0 to 5.0958e-05.\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 0.81818, a_loss 1.33673, cD 0.85290, wmdcmp 0.11942, ema 0.61592, oracc 0.98125, orien_loss 0.03268, qlmicf1 0.35465, qlmacf1 0.20657, ql_loss 0.79979, chxlmicf1 0.50376, chxlmacf1 0.46095, chx_loss 0.88953, chxlacc 0.70078, chxlrocaucmic 0.78605, chxlrocaucmac 0.77036, gacc 0.96486, gloss 0.09607, cxr14micf1 0.32300, cxr14macf1 0.32013, cxr14_loss 0.97053, vnbgmicf1 0.57009, vnbgmacf1 0.42633, vnbg_loss 0.75103, b1 0.45117, b2 0.33298, b3 0.24155, b4 0.17458, padchxlmacf1 0.06315, padchxlmicf1 0.16841, padchxlzmacf1 0.07793, padchxlzmicf1 0.16183, padchxl_loss 0.35050, padchxlz_loss 0.48908, 102.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.95643, wmdcmp 0.13536, ema 0.67860, oracc 0.98608, qlmicf1 0.36212, qlmacf1 0.21142, chxlmicf1 0.51662, chxlmacf1 0.45737, chxlacc 0.69375, chxlrocaucmic 0.78130, chxlrocaucmac 0.75426, 29.91 secs\n",
      "Adjusting learning rate of group 0 to 4.8136e-05.\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 1.64421, a_loss 1.33978, cD 0.83124, wmdcmp 0.11732, ema 0.60687, oracc 0.98288, orien_loss 0.02875, qlmicf1 0.35392, qlmacf1 0.20757, ql_loss 0.79920, chxlmicf1 0.50191, chxlmacf1 0.45886, chx_loss 0.88611, chxlacc 0.69791, chxlrocaucmic 0.78513, chxlrocaucmac 0.77010, gacc 0.96923, gloss 0.08619, cxr14micf1 0.33580, cxr14macf1 0.32503, cxr14_loss 0.97483, vnbgmicf1 0.56747, vnbgmacf1 0.42677, vnbg_loss 0.75132, b1 0.43451, b2 0.32057, b3 0.23412, b4 0.16924, padchxlmacf1 0.06750, padchxlmicf1 0.16865, padchxlzmacf1 0.08009, padchxlzmicf1 0.16640, padchxl_loss 0.36363, padchxlz_loss 0.50018, 102.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.02613, wmdcmp 0.14667, ema 0.65891, oracc 0.98632, qlmicf1 0.35883, qlmacf1 0.21183, chxlmicf1 0.52565, chxlmacf1 0.46342, chxlacc 0.70586, chxlrocaucmic 0.78719, chxlrocaucmac 0.75364, 29.67 secs\n",
      "Adjusting learning rate of group 0 to 4.5471e-05.\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 1.22303, a_loss 1.32259, cD 0.85812, wmdcmp 0.11963, ema 0.61427, oracc 0.98373, orien_loss 0.02486, qlmicf1 0.35775, qlmacf1 0.20832, ql_loss 0.79802, chxlmicf1 0.50737, chxlmacf1 0.46370, chx_loss 0.88426, chxlacc 0.70324, chxlrocaucmic 0.78944, chxlrocaucmac 0.77285, gacc 0.96277, gloss 0.08885, cxr14micf1 0.31904, cxr14macf1 0.31946, cxr14_loss 0.97337, vnbgmicf1 0.55803, vnbgmacf1 0.43406, vnbg_loss 0.77064, b1 0.45221, b2 0.33689, b3 0.24494, b4 0.17822, padchxlmacf1 0.06799, padchxlmicf1 0.18341, padchxlzmacf1 0.08098, padchxlzmicf1 0.17878, padchxl_loss 0.34368, padchxlz_loss 0.46461, 102.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.03169, wmdcmp 0.14537, ema 0.66965, oracc 0.98585, qlmicf1 0.36800, qlmacf1 0.21018, chxlmicf1 0.52159, chxlmacf1 0.46344, chxlacc 0.69487, chxlrocaucmic 0.78744, chxlrocaucmac 0.75034, 29.18 secs\n",
      "Adjusting learning rate of group 0 to 4.2953e-05.\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 5.22995, a_loss 1.32702, cD 0.85308, wmdcmp 0.11961, ema 0.62045, oracc 0.98365, orien_loss 0.02758, qlmicf1 0.36064, qlmacf1 0.21168, ql_loss 0.79138, chxlmicf1 0.50685, chxlmacf1 0.46403, chx_loss 0.87869, chxlacc 0.70283, chxlrocaucmic 0.79053, chxlrocaucmac 0.77447, gacc 0.96416, gloss 0.08631, cxr14micf1 0.33650, cxr14macf1 0.32916, cxr14_loss 0.95973, vnbgmicf1 0.57163, vnbgmacf1 0.43778, vnbg_loss 0.73072, b1 0.45270, b2 0.33835, b3 0.24449, b4 0.17628, padchxlmacf1 0.06115, padchxlmicf1 0.15880, padchxlzmacf1 0.08140, padchxlzmicf1 0.16210, padchxl_loss 0.37668, padchxlz_loss 0.49851, 101.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00920, wmdcmp 0.14648, ema 0.66070, oracc 0.98585, qlmicf1 0.36824, qlmacf1 0.21533, chxlmicf1 0.52284, chxlmacf1 0.46164, chxlacc 0.69223, chxlrocaucmic 0.78848, chxlrocaucmac 0.74863, 29.76 secs\n",
      "Adjusting learning rate of group 0 to 4.0574e-05.\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 3.09196, a_loss 1.32510, cD 0.88795, wmdcmp 0.12300, ema 0.60992, oracc 0.98193, orien_loss 0.03158, qlmicf1 0.36078, qlmacf1 0.21462, ql_loss 0.79540, chxlmicf1 0.50802, chxlmacf1 0.46467, chx_loss 0.87921, chxlacc 0.70326, chxlrocaucmic 0.79151, chxlrocaucmac 0.77664, gacc 0.96727, gloss 0.08700, cxr14micf1 0.34037, cxr14macf1 0.32946, cxr14_loss 0.95922, vnbgmicf1 0.56675, vnbgmacf1 0.42557, vnbg_loss 0.76565, b1 0.45928, b2 0.34008, b3 0.24555, b4 0.17919, padchxlmacf1 0.06833, padchxlmicf1 0.17266, padchxlzmacf1 0.08246, padchxlzmicf1 0.17433, padchxl_loss 0.34917, padchxlz_loss 0.48752, 102.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07419, wmdcmp 0.15274, ema 0.67771, oracc 0.98278, qlmicf1 0.36553, qlmacf1 0.21481, chxlmicf1 0.52458, chxlmacf1 0.46057, chxlacc 0.69587, chxlrocaucmic 0.79200, chxlrocaucmac 0.74858, 29.74 secs\n",
      "Adjusting learning rate of group 0 to 3.8327e-05.\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 4.42918, a_loss 1.32621, cD 0.88900, wmdcmp 0.12380, ema 0.61801, oracc 0.98245, orien_loss 0.02813, qlmicf1 0.36602, qlmacf1 0.21700, ql_loss 0.78863, chxlmicf1 0.50985, chxlmacf1 0.46621, chx_loss 0.87195, chxlacc 0.70725, chxlrocaucmic 0.79525, chxlrocaucmac 0.78090, gacc 0.96451, gloss 0.09481, cxr14micf1 0.33048, cxr14macf1 0.32586, cxr14_loss 0.97781, vnbgmicf1 0.55632, vnbgmacf1 0.42162, vnbg_loss 0.74794, b1 0.45346, b2 0.33777, b3 0.24439, b4 0.17478, padchxlmacf1 0.06643, padchxlmicf1 0.16559, padchxlzmacf1 0.08429, padchxlzmicf1 0.17724, padchxl_loss 0.36188, padchxlz_loss 0.50269, 102.99 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.03010, wmdcmp 0.14718, ema 0.67234, oracc 0.98538, qlmicf1 0.37315, qlmacf1 0.21530, chxlmicf1 0.52534, chxlmacf1 0.46511, chxlacc 0.69812, chxlrocaucmic 0.78933, chxlrocaucmac 0.75845, 29.17 secs\n",
      "Adjusting learning rate of group 0 to 3.6204e-05.\n",
      "\u001b[1m---- Epoch 38/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 1.86982, a_loss 1.31175, cD 0.89315, wmdcmp 0.12485, ema 0.61896, oracc 0.98407, orien_loss 0.02630, qlmicf1 0.36123, qlmacf1 0.21255, ql_loss 0.79053, chxlmicf1 0.51123, chxlmacf1 0.46833, chx_loss 0.87540, chxlacc 0.70528, chxlrocaucmic 0.79148, chxlrocaucmac 0.77774, gacc 0.96399, gloss 0.08815, cxr14micf1 0.32308, cxr14macf1 0.32313, cxr14_loss 0.96226, vnbgmicf1 0.57189, vnbgmacf1 0.43967, vnbg_loss 0.72992, b1 0.44929, b2 0.33270, b3 0.23606, b4 0.16690, padchxlmacf1 0.06733, padchxlmicf1 0.17675, padchxlzmacf1 0.08800, padchxlzmicf1 0.16555, padchxl_loss 0.34302, padchxlz_loss 0.49252, 102.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05267, wmdcmp 0.14961, ema 0.68129, oracc 0.98656, qlmicf1 0.36515, qlmacf1 0.21589, chxlmicf1 0.52394, chxlmacf1 0.46226, chxlacc 0.69628, chxlrocaucmic 0.79102, chxlrocaucmac 0.75526, 29.51 secs\n",
      "Adjusting learning rate of group 0 to 3.4200e-05.\n",
      "\u001b[1m---- Epoch 39/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 5.08316, a_loss 1.32591, cD 0.90469, wmdcmp 0.12484, ema 0.61547, oracc 0.98198, orien_loss 0.02852, qlmicf1 0.36151, qlmacf1 0.21370, ql_loss 0.78961, chxlmicf1 0.51567, chxlmacf1 0.47156, chx_loss 0.86767, chxlacc 0.71192, chxlrocaucmic 0.79863, chxlrocaucmac 0.78384, gacc 0.96469, gloss 0.08271, cxr14micf1 0.34086, cxr14macf1 0.32960, cxr14_loss 0.96770, vnbgmicf1 0.57178, vnbgmacf1 0.42898, vnbg_loss 0.74258, b1 0.44239, b2 0.32281, b3 0.22988, b4 0.16223, padchxlmacf1 0.06761, padchxlmicf1 0.16751, padchxlzmacf1 0.08098, padchxlzmicf1 0.16130, padchxl_loss 0.35972, padchxlz_loss 0.52088, 102.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09517, wmdcmp 0.15440, ema 0.68039, oracc 0.98656, qlmicf1 0.35856, qlmacf1 0.21368, chxlmicf1 0.52181, chxlmacf1 0.46550, chxlacc 0.69308, chxlrocaucmic 0.78679, chxlrocaucmac 0.75741, 29.35 secs\n",
      "Adjusting learning rate of group 0 to 3.2306e-05.\n",
      "\u001b[1m---- Epoch 40/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.34222, a_loss 1.30539, cD 0.89638, wmdcmp 0.12427, ema 0.62375, oracc 0.98335, orien_loss 0.02760, qlmicf1 0.36386, qlmacf1 0.21613, ql_loss 0.78595, chxlmicf1 0.51427, chxlmacf1 0.46894, chx_loss 0.86963, chxlacc 0.70903, chxlrocaucmic 0.79752, chxlrocaucmac 0.78236, gacc 0.96693, gloss 0.08757, cxr14micf1 0.33532, cxr14macf1 0.33133, cxr14_loss 0.95753, vnbgmicf1 0.58212, vnbgmacf1 0.44387, vnbg_loss 0.70322, b1 0.45610, b2 0.33374, b3 0.23650, b4 0.16680, padchxlmacf1 0.06837, padchxlmicf1 0.17184, padchxlzmacf1 0.08059, padchxlzmicf1 0.16747, padchxl_loss 0.35357, padchxlz_loss 0.48441, 102.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07850, wmdcmp 0.15257, ema 0.67860, oracc 0.98726, qlmicf1 0.37678, qlmacf1 0.21663, chxlmicf1 0.51997, chxlmacf1 0.46303, chxlacc 0.68212, chxlrocaucmic 0.79039, chxlrocaucmac 0.75526, 29.39 secs\n",
      "Adjusting learning rate of group 0 to 3.0517e-05.\n",
      "\u001b[1m---- Epoch 41/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 1.25976, a_loss 1.29883, cD 0.90831, wmdcmp 0.12760, ema 0.62784, oracc 0.98346, orien_loss 0.03086, qlmicf1 0.37172, qlmacf1 0.22079, ql_loss 0.78843, chxlmicf1 0.52064, chxlmacf1 0.47653, chx_loss 0.86103, chxlacc 0.71240, chxlrocaucmic 0.80020, chxlrocaucmac 0.78562, gacc 0.96952, gloss 0.08822, cxr14micf1 0.32209, cxr14macf1 0.32578, cxr14_loss 0.95982, vnbgmicf1 0.57043, vnbgmacf1 0.44054, vnbg_loss 0.71011, b1 0.45320, b2 0.33626, b3 0.24280, b4 0.17538, padchxlmacf1 0.07090, padchxlmicf1 0.16892, padchxlzmacf1 0.09053, padchxlzmicf1 0.17530, padchxl_loss 0.35892, padchxlz_loss 0.48862, 102.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.10542, wmdcmp 0.15449, ema 0.67860, oracc 0.98561, qlmicf1 0.38036, qlmacf1 0.21828, chxlmicf1 0.52341, chxlmacf1 0.46742, chxlacc 0.69319, chxlrocaucmic 0.78935, chxlrocaucmac 0.75836, 29.40 secs\n",
      "Adjusting learning rate of group 0 to 2.8827e-05.\n",
      "\u001b[1m---- Epoch 42/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.75995, a_loss 1.28840, cD 0.90966, wmdcmp 0.12711, ema 0.62488, oracc 0.98048, orien_loss 0.03135, qlmicf1 0.36603, qlmacf1 0.21853, ql_loss 0.79100, chxlmicf1 0.51253, chxlmacf1 0.46922, chx_loss 0.86758, chxlacc 0.71020, chxlrocaucmic 0.79666, chxlrocaucmac 0.78366, gacc 0.96731, gloss 0.08295, cxr14micf1 0.33525, cxr14macf1 0.32758, cxr14_loss 0.95849, vnbgmicf1 0.57702, vnbgmacf1 0.43678, vnbg_loss 0.70521, b1 0.45459, b2 0.33916, b3 0.24724, b4 0.18015, padchxlmacf1 0.06891, padchxlmicf1 0.15967, padchxlzmacf1 0.07898, padchxlzmicf1 0.16337, padchxl_loss 0.35262, padchxlz_loss 0.51120, 102.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.06793, wmdcmp 0.15167, ema 0.68218, oracc 0.98703, qlmicf1 0.35337, qlmacf1 0.21749, chxlmicf1 0.52003, chxlmacf1 0.46444, chxlacc 0.68684, chxlrocaucmic 0.79040, chxlrocaucmac 0.75539, 29.89 secs\n",
      "Adjusting learning rate of group 0 to 2.7230e-05.\n",
      "\u001b[1m---- Epoch 43/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.14821, a_loss 1.31363, cD 0.88856, wmdcmp 0.12466, ema 0.62308, oracc 0.98461, orien_loss 0.02423, qlmicf1 0.36881, qlmacf1 0.21743, ql_loss 0.78244, chxlmicf1 0.52210, chxlmacf1 0.47821, chx_loss 0.85344, chxlacc 0.71535, chxlrocaucmic 0.80275, chxlrocaucmac 0.78977, gacc 0.96976, gloss 0.08139, cxr14micf1 0.33219, cxr14macf1 0.32782, cxr14_loss 0.95090, vnbgmicf1 0.56608, vnbgmacf1 0.42929, vnbg_loss 0.73038, b1 0.45718, b2 0.33868, b3 0.24359, b4 0.17255, padchxlmacf1 0.06752, padchxlmicf1 0.17214, padchxlzmacf1 0.07984, padchxlzmicf1 0.16297, padchxl_loss 0.35261, padchxlz_loss 0.49152, 102.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.06420, wmdcmp 0.15281, ema 0.67413, oracc 0.98656, qlmicf1 0.36723, qlmacf1 0.21693, chxlmicf1 0.52867, chxlmacf1 0.46644, chxlacc 0.69535, chxlrocaucmic 0.79649, chxlrocaucmac 0.75591, 29.77 secs\n",
      "Adjusting learning rate of group 0 to 2.5722e-05.\n",
      "\u001b[1m---- Epoch 44/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 2.52977, a_loss 1.28868, cD 0.92901, wmdcmp 0.12869, ema 0.62697, oracc 0.98265, orien_loss 0.02774, qlmicf1 0.36311, qlmacf1 0.21847, ql_loss 0.78774, chxlmicf1 0.51843, chxlmacf1 0.47357, chx_loss 0.85942, chxlacc 0.71186, chxlrocaucmic 0.80083, chxlrocaucmac 0.78621, gacc 0.96918, gloss 0.07788, cxr14micf1 0.35074, cxr14macf1 0.33504, cxr14_loss 0.95471, vnbgmicf1 0.57597, vnbgmacf1 0.44805, vnbg_loss 0.70508, b1 0.44917, b2 0.33304, b3 0.24127, b4 0.17373, padchxlmacf1 0.07196, padchxlmicf1 0.16685, padchxlzmacf1 0.07785, padchxlzmicf1 0.16811, padchxl_loss 0.34979, padchxlz_loss 0.48989, 103.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.10446, wmdcmp 0.15693, ema 0.68129, oracc 0.98797, qlmicf1 0.37143, qlmacf1 0.21623, chxlmicf1 0.53003, chxlmacf1 0.46849, chxlacc 0.70338, chxlrocaucmic 0.79356, chxlrocaucmac 0.75771, 29.77 secs\n",
      "Adjusting learning rate of group 0 to 2.4298e-05.\n",
      "\u001b[1m---- Epoch 45/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.68372, a_loss 1.29202, cD 0.90765, wmdcmp 0.12743, ema 0.62671, oracc 0.98455, orien_loss 0.02812, qlmicf1 0.37050, qlmacf1 0.22027, ql_loss 0.78025, chxlmicf1 0.52089, chxlmacf1 0.47587, chx_loss 0.85715, chxlacc 0.71507, chxlrocaucmic 0.80513, chxlrocaucmac 0.78894, gacc 0.97080, gloss 0.07575, cxr14micf1 0.34646, cxr14macf1 0.33398, cxr14_loss 0.95261, vnbgmicf1 0.57518, vnbgmacf1 0.43365, vnbg_loss 0.71430, b1 0.46428, b2 0.34508, b3 0.25076, b4 0.18185, padchxlmacf1 0.07461, padchxlmicf1 0.17876, padchxlzmacf1 0.09107, padchxlzmicf1 0.17781, padchxl_loss 0.34120, padchxlz_loss 0.48240, 102.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.11651, wmdcmp 0.15916, ema 0.69651, oracc 0.98679, qlmicf1 0.36613, qlmacf1 0.21751, chxlmicf1 0.52842, chxlmacf1 0.46619, chxlacc 0.69647, chxlrocaucmic 0.79568, chxlrocaucmac 0.75900, 29.61 secs\n",
      "Adjusting learning rate of group 0 to 2.2952e-05.\n",
      "\u001b[1m---- Epoch 46/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.56273, a_loss 1.28262, cD 0.92550, wmdcmp 0.12916, ema 0.62819, oracc 0.98455, orien_loss 0.02291, qlmicf1 0.36849, qlmacf1 0.22201, ql_loss 0.77950, chxlmicf1 0.52257, chxlmacf1 0.47851, chx_loss 0.85530, chxlacc 0.71450, chxlrocaucmic 0.80052, chxlrocaucmac 0.78755, gacc 0.96713, gloss 0.08777, cxr14micf1 0.34133, cxr14macf1 0.33099, cxr14_loss 0.96774, vnbgmicf1 0.58981, vnbgmacf1 0.45680, vnbg_loss 0.69349, b1 0.48532, b2 0.36064, b3 0.26033, b4 0.18583, padchxlmacf1 0.07282, padchxlmicf1 0.17794, padchxlzmacf1 0.08320, padchxlzmicf1 0.17360, padchxl_loss 0.34958, padchxlz_loss 0.47943, 103.01 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.16666, wmdcmp 0.16317, ema 0.68129, oracc 0.98703, qlmicf1 0.37780, qlmacf1 0.22088, chxlmicf1 0.53043, chxlmacf1 0.46555, chxlacc 0.70052, chxlrocaucmic 0.79757, chxlrocaucmac 0.75748, 29.82 secs\n",
      "Adjusting learning rate of group 0 to 2.1681e-05.\n",
      "\u001b[1m---- Epoch 47/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 4.94869, a_loss 1.28297, cD 0.93127, wmdcmp 0.12804, ema 0.63260, oracc 0.98499, orien_loss 0.02326, qlmicf1 0.37206, qlmacf1 0.21742, ql_loss 0.78017, chxlmicf1 0.52299, chxlmacf1 0.47596, chx_loss 0.85514, chxlacc 0.71560, chxlrocaucmic 0.80067, chxlrocaucmac 0.78612, gacc 0.97150, gloss 0.07509, cxr14micf1 0.33587, cxr14macf1 0.33232, cxr14_loss 0.95528, vnbgmicf1 0.58427, vnbgmacf1 0.45030, vnbg_loss 0.69175, b1 0.48312, b2 0.36145, b3 0.26444, b4 0.19100, padchxlmacf1 0.07152, padchxlmicf1 0.16699, padchxlzmacf1 0.08418, padchxlzmicf1 0.15832, padchxl_loss 0.35309, padchxlz_loss 0.50132, 102.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.11986, wmdcmp 0.15846, ema 0.66428, oracc 0.98726, qlmicf1 0.37699, qlmacf1 0.22008, chxlmicf1 0.53363, chxlmacf1 0.46587, chxlacc 0.70167, chxlrocaucmic 0.80051, chxlrocaucmac 0.75511, 29.92 secs\n",
      "Adjusting learning rate of group 0 to 2.0480e-05.\n",
      "\u001b[1m---- Epoch 48/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 1.80871, a_loss 1.28960, cD 0.91723, wmdcmp 0.12719, ema 0.62279, oracc 0.98442, orien_loss 0.02674, qlmicf1 0.37542, qlmacf1 0.22179, ql_loss 0.77982, chxlmicf1 0.51993, chxlmacf1 0.47606, chx_loss 0.85750, chxlacc 0.71278, chxlrocaucmic 0.80056, chxlrocaucmac 0.78674, gacc 0.97098, gloss 0.07703, cxr14micf1 0.33036, cxr14macf1 0.32413, cxr14_loss 0.95134, vnbgmicf1 0.58423, vnbgmacf1 0.44901, vnbg_loss 0.70351, b1 0.48459, b2 0.36319, b3 0.26887, b4 0.19807, padchxlmacf1 0.06753, padchxlmicf1 0.16620, padchxlzmacf1 0.08534, padchxlzmicf1 0.17214, padchxl_loss 0.35918, padchxlz_loss 0.49062, 103.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14624, wmdcmp 0.16001, ema 0.67681, oracc 0.98726, qlmicf1 0.38095, qlmacf1 0.21982, chxlmicf1 0.53062, chxlmacf1 0.46548, chxlacc 0.71104, chxlrocaucmic 0.79370, chxlrocaucmac 0.75833, 29.54 secs\n",
      "Adjusting learning rate of group 0 to 1.9346e-05.\n",
      "\u001b[1m---- Epoch 49/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.34230, a_loss 1.28259, cD 0.94363, wmdcmp 0.13221, ema 0.63193, oracc 0.98528, orien_loss 0.02291, qlmicf1 0.37230, qlmacf1 0.22177, ql_loss 0.78148, chxlmicf1 0.52121, chxlmacf1 0.47668, chx_loss 0.85242, chxlacc 0.71639, chxlrocaucmic 0.80191, chxlrocaucmac 0.78956, gacc 0.97229, gloss 0.08054, cxr14micf1 0.35414, cxr14macf1 0.33804, cxr14_loss 0.93913, vnbgmicf1 0.58562, vnbgmacf1 0.45365, vnbg_loss 0.69520, b1 0.48251, b2 0.35948, b3 0.26186, b4 0.19042, padchxlmacf1 0.06861, padchxlmicf1 0.18292, padchxlzmacf1 0.08836, padchxlzmicf1 0.17519, padchxl_loss 0.33038, padchxlz_loss 0.46784, 102.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13880, wmdcmp 0.15921, ema 0.68756, oracc 0.98774, qlmicf1 0.37241, qlmacf1 0.21918, chxlmicf1 0.52389, chxlmacf1 0.46387, chxlacc 0.70034, chxlrocaucmic 0.78913, chxlrocaucmac 0.75798, 29.75 secs\n",
      "Adjusting learning rate of group 0 to 1.8275e-05.\n",
      "\u001b[1m---- Epoch 50/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 4.92974, a_loss 1.28707, cD 0.94913, wmdcmp 0.13194, ema 0.62395, oracc 0.98509, orien_loss 0.02862, qlmicf1 0.37007, qlmacf1 0.21845, ql_loss 0.77834, chxlmicf1 0.52618, chxlmacf1 0.48102, chx_loss 0.84290, chxlacc 0.71786, chxlrocaucmic 0.80683, chxlrocaucmac 0.79423, gacc 0.96801, gloss 0.08393, cxr14micf1 0.34854, cxr14macf1 0.33741, cxr14_loss 0.93084, vnbgmicf1 0.58595, vnbgmacf1 0.45256, vnbg_loss 0.68757, b1 0.44979, b2 0.33771, b3 0.24768, b4 0.18032, padchxlmacf1 0.07104, padchxlmicf1 0.17120, padchxlzmacf1 0.08770, padchxlzmicf1 0.18000, padchxl_loss 0.36064, padchxlz_loss 0.49700, 103.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15343, wmdcmp 0.16148, ema 0.67950, oracc 0.98750, qlmicf1 0.37605, qlmacf1 0.22125, chxlmicf1 0.53527, chxlmacf1 0.46793, chxlacc 0.70758, chxlrocaucmic 0.80032, chxlrocaucmac 0.75597, 29.90 secs\n",
      "Adjusting learning rate of group 0 to 1.7263e-05.\n",
      "\u001b[1m---- Epoch 51/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.78746, a_loss 1.27308, cD 0.93496, wmdcmp 0.12934, ema 0.63193, oracc 0.98426, orien_loss 0.02165, qlmicf1 0.37251, qlmacf1 0.22012, ql_loss 0.77782, chxlmicf1 0.52250, chxlmacf1 0.47771, chx_loss 0.84848, chxlacc 0.71758, chxlrocaucmic 0.80527, chxlrocaucmac 0.79087, gacc 0.97212, gloss 0.07380, cxr14micf1 0.32509, cxr14macf1 0.32741, cxr14_loss 0.93444, vnbgmicf1 0.57377, vnbgmacf1 0.43587, vnbg_loss 0.70437, b1 0.44378, b2 0.32966, b3 0.23818, b4 0.17133, padchxlmacf1 0.07561, padchxlmicf1 0.16441, padchxlzmacf1 0.07737, padchxlzmicf1 0.15921, padchxl_loss 0.34111, padchxlz_loss 0.48320, 104.16 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16410, wmdcmp 0.16267, ema 0.67860, oracc 0.98679, qlmicf1 0.37719, qlmacf1 0.21930, chxlmicf1 0.52625, chxlmacf1 0.46780, chxlacc 0.69719, chxlrocaucmic 0.79167, chxlrocaucmac 0.75894, 30.01 secs\n",
      "Adjusting learning rate of group 0 to 1.6307e-05.\n",
      "\u001b[1m---- Epoch 52/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 1.75687, a_loss 1.27120, cD 0.95433, wmdcmp 0.13251, ema 0.62192, oracc 0.98480, orien_loss 0.02584, qlmicf1 0.37284, qlmacf1 0.21983, ql_loss 0.77569, chxlmicf1 0.52070, chxlmacf1 0.47663, chx_loss 0.84869, chxlacc 0.71640, chxlrocaucmic 0.80533, chxlrocaucmac 0.79200, gacc 0.97185, gloss 0.07142, cxr14micf1 0.35725, cxr14macf1 0.34322, cxr14_loss 0.92680, vnbgmicf1 0.58838, vnbgmacf1 0.46449, vnbg_loss 0.68345, b1 0.48551, b2 0.36403, b3 0.26759, b4 0.19978, padchxlmacf1 0.07719, padchxlmicf1 0.17767, padchxlzmacf1 0.08417, padchxlzmicf1 0.18603, padchxl_loss 0.36112, padchxlz_loss 0.48495, 102.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16282, wmdcmp 0.16240, ema 0.68308, oracc 0.98750, qlmicf1 0.37797, qlmacf1 0.22211, chxlmicf1 0.53341, chxlmacf1 0.46964, chxlacc 0.70529, chxlrocaucmic 0.79615, chxlrocaucmac 0.75847, 29.41 secs\n",
      "Adjusting learning rate of group 0 to 1.5404e-05.\n",
      "\u001b[1m---- Epoch 53/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.22315, a_loss 1.26820, cD 0.94123, wmdcmp 0.13079, ema 0.64176, oracc 0.98434, orien_loss 0.02652, qlmicf1 0.37515, qlmacf1 0.22196, ql_loss 0.77329, chxlmicf1 0.52643, chxlmacf1 0.48105, chx_loss 0.84328, chxlacc 0.72031, chxlrocaucmic 0.80638, chxlrocaucmac 0.79266, gacc 0.97316, gloss 0.07369, cxr14micf1 0.32854, cxr14macf1 0.32570, cxr14_loss 0.96958, vnbgmicf1 0.58745, vnbgmacf1 0.46289, vnbg_loss 0.67120, b1 0.47235, b2 0.35309, b3 0.25724, b4 0.18574, padchxlmacf1 0.07747, padchxlmicf1 0.17305, padchxlzmacf1 0.09206, padchxlzmicf1 0.17551, padchxl_loss 0.35451, padchxlz_loss 0.49965, 102.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16167, wmdcmp 0.16303, ema 0.68218, oracc 0.98703, qlmicf1 0.37575, qlmacf1 0.22452, chxlmicf1 0.53049, chxlmacf1 0.46973, chxlacc 0.70016, chxlrocaucmic 0.79609, chxlrocaucmac 0.76031, 29.83 secs\n",
      "Adjusting learning rate of group 0 to 1.4551e-05.\n",
      "\u001b[1m---- Epoch 54/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 4.98032, a_loss 1.27906, cD 0.96153, wmdcmp 0.13249, ema 0.62990, oracc 0.98184, orien_loss 0.02632, qlmicf1 0.37402, qlmacf1 0.22244, ql_loss 0.77499, chxlmicf1 0.52593, chxlmacf1 0.48095, chx_loss 0.84355, chxlacc 0.71844, chxlrocaucmic 0.80778, chxlrocaucmac 0.79510, gacc 0.97203, gloss 0.07590, cxr14micf1 0.33192, cxr14macf1 0.33027, cxr14_loss 0.95504, vnbgmicf1 0.58203, vnbgmacf1 0.44541, vnbg_loss 0.66946, b1 0.48058, b2 0.36215, b3 0.26447, b4 0.19112, padchxlmacf1 0.07238, padchxlmicf1 0.17168, padchxlzmacf1 0.08779, padchxlzmicf1 0.17689, padchxl_loss 0.36373, padchxlz_loss 0.49270, 103.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16081, wmdcmp 0.16308, ema 0.67592, oracc 0.98774, qlmicf1 0.38268, qlmacf1 0.22470, chxlmicf1 0.53560, chxlmacf1 0.47099, chxlacc 0.70436, chxlrocaucmic 0.80083, chxlrocaucmac 0.76145, 29.78 secs\n",
      "Adjusting learning rate of group 0 to 1.3745e-05.\n",
      "\u001b[1m---- Epoch 55/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.61106, a_loss 1.26707, cD 0.93900, wmdcmp 0.13046, ema 0.63088, oracc 0.98448, orien_loss 0.02511, qlmicf1 0.37929, qlmacf1 0.22405, ql_loss 0.77173, chxlmicf1 0.52861, chxlmacf1 0.48393, chx_loss 0.83822, chxlacc 0.72186, chxlrocaucmic 0.80982, chxlrocaucmac 0.79678, gacc 0.97150, gloss 0.07069, cxr14micf1 0.33987, cxr14macf1 0.32980, cxr14_loss 0.94501, vnbgmicf1 0.59382, vnbgmacf1 0.46389, vnbg_loss 0.66560, b1 0.48831, b2 0.36604, b3 0.26851, b4 0.19523, padchxlmacf1 0.07722, padchxlmicf1 0.18064, padchxlzmacf1 0.08526, padchxlzmicf1 0.18020, padchxl_loss 0.33518, padchxlz_loss 0.48184, 102.43 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.14549, wmdcmp 0.16112, ema 0.68039, oracc 0.98703, qlmicf1 0.38418, qlmacf1 0.22418, chxlmicf1 0.53325, chxlmacf1 0.46981, chxlacc 0.71076, chxlrocaucmic 0.79654, chxlrocaucmac 0.76308, 29.85 secs\n",
      "Adjusting learning rate of group 0 to 1.2984e-05.\n",
      "\u001b[1m---- Epoch 56/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.75985, a_loss 1.26418, cD 0.96580, wmdcmp 0.13345, ema 0.63288, oracc 0.98467, orien_loss 0.02466, qlmicf1 0.37568, qlmacf1 0.22230, ql_loss 0.77477, chxlmicf1 0.52734, chxlmacf1 0.48120, chx_loss 0.83987, chxlacc 0.72197, chxlrocaucmic 0.80925, chxlrocaucmac 0.79590, gacc 0.97622, gloss 0.06897, cxr14micf1 0.33552, cxr14macf1 0.32768, cxr14_loss 0.94190, vnbgmicf1 0.59029, vnbgmacf1 0.45230, vnbg_loss 0.67068, b1 0.47549, b2 0.35915, b3 0.26353, b4 0.19336, padchxlmacf1 0.07790, padchxlmicf1 0.18061, padchxlzmacf1 0.08624, padchxlzmicf1 0.17988, padchxl_loss 0.34868, padchxlz_loss 0.48148, 102.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14273, wmdcmp 0.16134, ema 0.67771, oracc 0.98774, qlmicf1 0.38189, qlmacf1 0.22348, chxlmicf1 0.53715, chxlmacf1 0.47204, chxlacc 0.70710, chxlrocaucmic 0.80040, chxlrocaucmac 0.76051, 29.74 secs\n",
      "Adjusting learning rate of group 0 to 1.2265e-05.\n",
      "\u001b[1m---- Epoch 57/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.12537, a_loss 1.25783, cD 0.95944, wmdcmp 0.13185, ema 0.63245, oracc 0.98522, orien_loss 0.02080, qlmicf1 0.37848, qlmacf1 0.22656, ql_loss 0.76691, chxlmicf1 0.52974, chxlmacf1 0.48510, chx_loss 0.83611, chxlacc 0.72331, chxlrocaucmic 0.80895, chxlrocaucmac 0.79764, gacc 0.97610, gloss 0.06545, cxr14micf1 0.34507, cxr14macf1 0.33935, cxr14_loss 0.93920, vnbgmicf1 0.58457, vnbgmacf1 0.45041, vnbg_loss 0.68950, b1 0.49151, b2 0.36669, b3 0.26929, b4 0.19825, padchxlmacf1 0.06852, padchxlmicf1 0.18686, padchxlzmacf1 0.08113, padchxlzmicf1 0.16624, padchxl_loss 0.32466, padchxlz_loss 0.48503, 102.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15097, wmdcmp 0.16197, ema 0.67502, oracc 0.98774, qlmicf1 0.37816, qlmacf1 0.22281, chxlmicf1 0.52846, chxlmacf1 0.46767, chxlacc 0.70666, chxlrocaucmic 0.79212, chxlrocaucmac 0.76174, 29.88 secs\n",
      "Adjusting learning rate of group 0 to 1.1586e-05.\n",
      "\u001b[1m---- Epoch 58/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 5.19570, a_loss 1.26953, cD 0.94127, wmdcmp 0.13025, ema 0.63365, oracc 0.98642, orien_loss 0.02268, qlmicf1 0.37842, qlmacf1 0.22349, ql_loss 0.77370, chxlmicf1 0.52624, chxlmacf1 0.48129, chx_loss 0.83930, chxlacc 0.72093, chxlrocaucmic 0.80759, chxlrocaucmac 0.79361, gacc 0.97325, gloss 0.07868, cxr14micf1 0.34535, cxr14macf1 0.33552, cxr14_loss 0.93724, vnbgmicf1 0.59085, vnbgmacf1 0.45565, vnbg_loss 0.67036, b1 0.47537, b2 0.36258, b3 0.27182, b4 0.20426, padchxlmacf1 0.07279, padchxlmicf1 0.16483, padchxlzmacf1 0.08114, padchxlzmicf1 0.16855, padchxl_loss 0.35187, padchxlz_loss 0.48853, 103.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18071, wmdcmp 0.16399, ema 0.69740, oracc 0.98726, qlmicf1 0.38707, qlmacf1 0.22251, chxlmicf1 0.53423, chxlmacf1 0.47062, chxlacc 0.71301, chxlrocaucmic 0.79744, chxlrocaucmac 0.76007, 29.88 secs\n",
      "Adjusting learning rate of group 0 to 1.0944e-05.\n",
      "\u001b[1m---- Epoch 59/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 2.34009, a_loss 1.26165, cD 0.97658, wmdcmp 0.13545, ema 0.63697, oracc 0.98607, orien_loss 0.01807, qlmicf1 0.37467, qlmacf1 0.22198, ql_loss 0.77511, chxlmicf1 0.52921, chxlmacf1 0.48376, chx_loss 0.83860, chxlacc 0.72149, chxlrocaucmic 0.80858, chxlrocaucmac 0.79569, gacc 0.97143, gloss 0.07527, cxr14micf1 0.37453, cxr14macf1 0.35642, cxr14_loss 0.91592, vnbgmicf1 0.58991, vnbgmacf1 0.45715, vnbg_loss 0.67113, b1 0.47570, b2 0.35604, b3 0.25821, b4 0.18674, padchxlmacf1 0.07359, padchxlmicf1 0.17873, padchxlzmacf1 0.08627, padchxlzmicf1 0.16919, padchxl_loss 0.33500, padchxlz_loss 0.48564, 102.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17760, wmdcmp 0.16464, ema 0.68129, oracc 0.98750, qlmicf1 0.37767, qlmacf1 0.22241, chxlmicf1 0.53543, chxlmacf1 0.46662, chxlacc 0.71673, chxlrocaucmic 0.79851, chxlrocaucmac 0.75824, 29.52 secs\n",
      "Adjusting learning rate of group 0 to 1.0338e-05.\n",
      "\u001b[1m---- Epoch 60/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 4.17865, a_loss 1.26681, cD 0.95709, wmdcmp 0.13284, ema 0.63855, oracc 0.98509, orien_loss 0.02213, qlmicf1 0.37635, qlmacf1 0.22548, ql_loss 0.77132, chxlmicf1 0.52780, chxlmacf1 0.48243, chx_loss 0.83575, chxlacc 0.72409, chxlrocaucmic 0.81054, chxlrocaucmac 0.79774, gacc 0.97465, gloss 0.06933, cxr14micf1 0.33955, cxr14macf1 0.33770, cxr14_loss 0.92990, vnbgmicf1 0.59195, vnbgmacf1 0.45659, vnbg_loss 0.66696, b1 0.47270, b2 0.35727, b3 0.26424, b4 0.19598, padchxlmacf1 0.07015, padchxlmicf1 0.16802, padchxlzmacf1 0.08105, padchxlzmicf1 0.16211, padchxl_loss 0.35614, padchxlz_loss 0.49018, 103.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17297, wmdcmp 0.16426, ema 0.68935, oracc 0.98726, qlmicf1 0.38216, qlmacf1 0.22352, chxlmicf1 0.53403, chxlmacf1 0.46961, chxlacc 0.70839, chxlrocaucmic 0.79914, chxlrocaucmac 0.76249, 29.96 secs\n",
      "Adjusting learning rate of group 0 to 9.7654e-06.\n",
      "\u001b[1m---- Epoch 61/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.83185, a_loss 1.25797, cD 0.93834, wmdcmp 0.13167, ema 0.63784, oracc 0.98600, orien_loss 0.02089, qlmicf1 0.37614, qlmacf1 0.22447, ql_loss 0.77396, chxlmicf1 0.52806, chxlmacf1 0.48169, chx_loss 0.84034, chxlacc 0.72230, chxlrocaucmic 0.80979, chxlrocaucmac 0.79513, gacc 0.97815, gloss 0.05969, cxr14micf1 0.34992, cxr14macf1 0.34189, cxr14_loss 0.93986, vnbgmicf1 0.58746, vnbgmacf1 0.45444, vnbg_loss 0.67105, b1 0.46718, b2 0.35338, b3 0.26107, b4 0.19342, padchxlmacf1 0.06945, padchxlmicf1 0.16563, padchxlzmacf1 0.08271, padchxlzmicf1 0.16451, padchxl_loss 0.34255, padchxlz_loss 0.49502, 103.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13819, wmdcmp 0.16019, ema 0.68666, oracc 0.98797, qlmicf1 0.37178, qlmacf1 0.22204, chxlmicf1 0.53100, chxlmacf1 0.46896, chxlacc 0.69962, chxlrocaucmic 0.79846, chxlrocaucmac 0.76112, 29.64 secs\n",
      "Adjusting learning rate of group 0 to 9.2246e-06.\n",
      "\u001b[1m---- Epoch 62/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.71355, a_loss 1.26865, cD 0.96507, wmdcmp 0.13313, ema 0.65166, oracc 0.98501, orien_loss 0.02332, qlmicf1 0.37644, qlmacf1 0.23073, ql_loss 0.77131, chxlmicf1 0.53166, chxlmacf1 0.48552, chx_loss 0.83196, chxlacc 0.72477, chxlrocaucmic 0.81262, chxlrocaucmac 0.80089, gacc 0.97290, gloss 0.07233, cxr14micf1 0.34177, cxr14macf1 0.33752, cxr14_loss 0.94666, vnbgmicf1 0.58801, vnbgmacf1 0.45130, vnbg_loss 0.65727, b1 0.47057, b2 0.35359, b3 0.26022, b4 0.19234, padchxlmacf1 0.07291, padchxlmicf1 0.18494, padchxlzmacf1 0.08313, padchxlzmicf1 0.18061, padchxl_loss 0.33835, padchxlz_loss 0.49738, 103.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17416, wmdcmp 0.16424, ema 0.68129, oracc 0.98774, qlmicf1 0.38504, qlmacf1 0.22407, chxlmicf1 0.53471, chxlmacf1 0.47149, chxlacc 0.70728, chxlrocaucmic 0.79812, chxlrocaucmac 0.75934, 29.61 secs\n",
      "Adjusting learning rate of group 0 to 8.7138e-06.\n",
      "\u001b[1m---- Epoch 63/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.16427, a_loss 1.26275, cD 0.95078, wmdcmp 0.13221, ema 0.62958, oracc 0.98462, orien_loss 0.02979, qlmicf1 0.37731, qlmacf1 0.22689, ql_loss 0.76981, chxlmicf1 0.52871, chxlmacf1 0.48409, chx_loss 0.83661, chxlacc 0.72240, chxlrocaucmic 0.81005, chxlrocaucmac 0.79747, gacc 0.97385, gloss 0.06594, cxr14micf1 0.35177, cxr14macf1 0.33958, cxr14_loss 0.91909, vnbgmicf1 0.58467, vnbgmacf1 0.45626, vnbg_loss 0.67592, b1 0.46314, b2 0.34579, b3 0.25123, b4 0.18301, padchxlmacf1 0.07254, padchxlmicf1 0.17314, padchxlzmacf1 0.08598, padchxlzmicf1 0.17956, padchxl_loss 0.35654, padchxlz_loss 0.51029, 102.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16947, wmdcmp 0.16359, ema 0.67592, oracc 0.98821, qlmicf1 0.37359, qlmacf1 0.22238, chxlmicf1 0.53280, chxlmacf1 0.46864, chxlacc 0.70568, chxlrocaucmic 0.79883, chxlrocaucmac 0.76124, 29.40 secs\n",
      "Adjusting learning rate of group 0 to 8.2312e-06.\n",
      "\u001b[1m---- Epoch 64/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.14847, a_loss 1.25493, cD 0.95275, wmdcmp 0.13225, ema 0.63549, oracc 0.98629, orien_loss 0.02019, qlmicf1 0.37691, qlmacf1 0.22259, ql_loss 0.76974, chxlmicf1 0.52868, chxlmacf1 0.48297, chx_loss 0.83606, chxlacc 0.72264, chxlrocaucmic 0.81095, chxlrocaucmac 0.79804, gacc 0.96831, gloss 0.08469, cxr14micf1 0.35250, cxr14macf1 0.34388, cxr14_loss 0.92446, vnbgmicf1 0.59220, vnbgmacf1 0.45708, vnbg_loss 0.65223, b1 0.46664, b2 0.35180, b3 0.25917, b4 0.18983, padchxlmacf1 0.07654, padchxlmicf1 0.17605, padchxlzmacf1 0.08399, padchxlzmicf1 0.17702, padchxl_loss 0.34002, padchxlz_loss 0.48122, 102.84 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.15281, wmdcmp 0.16194, ema 0.68756, oracc 0.98797, qlmicf1 0.38321, qlmacf1 0.22449, chxlmicf1 0.53738, chxlmacf1 0.47094, chxlacc 0.70918, chxlrocaucmic 0.80268, chxlrocaucmac 0.76166, 29.80 secs\n",
      "Adjusting learning rate of group 0 to 7.7754e-06.\n",
      "\u001b[1m---- Epoch 65/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.71299, a_loss 1.25886, cD 0.96474, wmdcmp 0.13415, ema 0.63575, oracc 0.98495, orien_loss 0.02210, qlmicf1 0.37654, qlmacf1 0.22645, ql_loss 0.77389, chxlmicf1 0.52907, chxlmacf1 0.48365, chx_loss 0.83963, chxlacc 0.72154, chxlrocaucmic 0.81109, chxlrocaucmac 0.79637, gacc 0.97797, gloss 0.06103, cxr14micf1 0.33989, cxr14macf1 0.34048, cxr14_loss 0.93475, vnbgmicf1 0.59722, vnbgmacf1 0.45725, vnbg_loss 0.66081, b1 0.48550, b2 0.37259, b3 0.28218, b4 0.21386, padchxlmacf1 0.07161, padchxlmicf1 0.17489, padchxlzmacf1 0.08767, padchxlzmicf1 0.18122, padchxl_loss 0.34650, padchxlz_loss 0.48844, 102.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16363, wmdcmp 0.16303, ema 0.69293, oracc 0.98679, qlmicf1 0.37785, qlmacf1 0.22412, chxlmicf1 0.53202, chxlmacf1 0.46981, chxlacc 0.70493, chxlrocaucmic 0.79628, chxlrocaucmac 0.76002, 29.80 secs\n",
      "Adjusting learning rate of group 0 to 7.3448e-06.\n",
      "\u001b[1m---- Epoch 66/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.83079, a_loss 1.25935, cD 0.98205, wmdcmp 0.13562, ema 0.64108, oracc 0.98608, orien_loss 0.02095, qlmicf1 0.38043, qlmacf1 0.22728, ql_loss 0.76549, chxlmicf1 0.52761, chxlmacf1 0.48262, chx_loss 0.83690, chxlacc 0.72375, chxlrocaucmic 0.81064, chxlrocaucmac 0.79831, gacc 0.97290, gloss 0.07056, cxr14micf1 0.38257, cxr14macf1 0.35671, cxr14_loss 0.91244, vnbgmicf1 0.59394, vnbgmacf1 0.45216, vnbg_loss 0.65983, b1 0.46552, b2 0.35068, b3 0.26181, b4 0.19575, padchxlmacf1 0.07878, padchxlmicf1 0.18619, padchxlzmacf1 0.09180, padchxlzmicf1 0.18656, padchxl_loss 0.33087, padchxlz_loss 0.46739, 103.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17210, wmdcmp 0.16370, ema 0.68218, oracc 0.98726, qlmicf1 0.38906, qlmacf1 0.22476, chxlmicf1 0.53339, chxlmacf1 0.46789, chxlacc 0.71061, chxlrocaucmic 0.79826, chxlrocaucmac 0.76039, 29.37 secs\n",
      "Adjusting learning rate of group 0 to 6.9380e-06.\n",
      "\u001b[1m---- Epoch 67/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.55004, a_loss 1.26226, cD 0.96753, wmdcmp 0.13410, ema 0.63819, oracc 0.98480, orien_loss 0.02208, qlmicf1 0.37720, qlmacf1 0.22295, ql_loss 0.77079, chxlmicf1 0.53010, chxlmacf1 0.48504, chx_loss 0.83888, chxlacc 0.72370, chxlrocaucmic 0.81241, chxlrocaucmac 0.79837, gacc 0.97333, gloss 0.07259, cxr14micf1 0.33076, cxr14macf1 0.33120, cxr14_loss 0.94249, vnbgmicf1 0.59489, vnbgmacf1 0.46505, vnbg_loss 0.65071, b1 0.47158, b2 0.35109, b3 0.25871, b4 0.19054, padchxlmacf1 0.07539, padchxlmicf1 0.18352, padchxlzmacf1 0.08585, padchxlzmicf1 0.17997, padchxl_loss 0.34839, padchxlz_loss 0.49709, 103.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16282, wmdcmp 0.16409, ema 0.69024, oracc 0.98750, qlmicf1 0.38591, qlmacf1 0.22624, chxlmicf1 0.53316, chxlmacf1 0.46915, chxlacc 0.70705, chxlrocaucmic 0.79865, chxlrocaucmac 0.75803, 28.11 secs\n",
      "Adjusting learning rate of group 0 to 6.5538e-06.\n",
      "\u001b[1m---- Epoch 68/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.64845, a_loss 1.25368, cD 0.97811, wmdcmp 0.13647, ema 0.64428, oracc 0.98424, orien_loss 0.02659, qlmicf1 0.38216, qlmacf1 0.22688, ql_loss 0.76486, chxlmicf1 0.52917, chxlmacf1 0.48518, chx_loss 0.83153, chxlacc 0.72327, chxlrocaucmic 0.81110, chxlrocaucmac 0.79944, gacc 0.97675, gloss 0.06541, cxr14micf1 0.33105, cxr14macf1 0.33151, cxr14_loss 0.95124, vnbgmicf1 0.58860, vnbgmacf1 0.45523, vnbg_loss 0.66620, b1 0.47844, b2 0.35981, b3 0.26470, b4 0.19170, padchxlmacf1 0.07198, padchxlmicf1 0.17171, padchxlzmacf1 0.08285, padchxlzmicf1 0.17031, padchxl_loss 0.34393, padchxlz_loss 0.49684, 99.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16101, wmdcmp 0.16397, ema 0.68129, oracc 0.98703, qlmicf1 0.38379, qlmacf1 0.22395, chxlmicf1 0.53340, chxlmacf1 0.47017, chxlacc 0.70328, chxlrocaucmic 0.80188, chxlrocaucmac 0.76304, 27.95 secs\n",
      "Adjusting learning rate of group 0 to 6.1909e-06.\n",
      "\u001b[1m---- Epoch 69/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.36525, a_loss 1.25302, cD 0.95389, wmdcmp 0.13345, ema 0.63349, oracc 0.98468, orien_loss 0.02348, qlmicf1 0.37648, qlmacf1 0.22684, ql_loss 0.76584, chxlmicf1 0.53077, chxlmacf1 0.48508, chx_loss 0.83417, chxlacc 0.72575, chxlrocaucmic 0.81131, chxlrocaucmac 0.79937, gacc 0.97395, gloss 0.06351, cxr14micf1 0.34688, cxr14macf1 0.33687, cxr14_loss 0.92417, vnbgmicf1 0.59580, vnbgmacf1 0.45470, vnbg_loss 0.65399, b1 0.47374, b2 0.35822, b3 0.26573, b4 0.19560, padchxlmacf1 0.07577, padchxlmicf1 0.17980, padchxlzmacf1 0.09112, padchxlzmicf1 0.17869, padchxl_loss 0.35614, padchxlz_loss 0.48426, 98.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16331, wmdcmp 0.16388, ema 0.68308, oracc 0.98726, qlmicf1 0.38165, qlmacf1 0.22427, chxlmicf1 0.53664, chxlmacf1 0.47325, chxlacc 0.70709, chxlrocaucmic 0.80015, chxlrocaucmac 0.76237, 27.94 secs\n",
      "Adjusting learning rate of group 0 to 5.8480e-06.\n",
      "\u001b[1m---- Epoch 70/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.95460, a_loss 1.26762, cD 0.98736, wmdcmp 0.13578, ema 0.63497, oracc 0.98371, orien_loss 0.02721, qlmicf1 0.37939, qlmacf1 0.22439, ql_loss 0.76834, chxlmicf1 0.52828, chxlmacf1 0.48408, chx_loss 0.83676, chxlacc 0.72437, chxlrocaucmic 0.81108, chxlrocaucmac 0.79831, gacc 0.97465, gloss 0.06329, cxr14micf1 0.35001, cxr14macf1 0.34660, cxr14_loss 0.91861, vnbgmicf1 0.60013, vnbgmacf1 0.46357, vnbg_loss 0.64241, b1 0.47863, b2 0.36071, b3 0.26774, b4 0.19826, padchxlmacf1 0.08353, padchxlmicf1 0.18090, padchxlzmacf1 0.09474, padchxlzmicf1 0.17719, padchxl_loss 0.33324, padchxlz_loss 0.48436, 98.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16730, wmdcmp 0.16385, ema 0.68577, oracc 0.98726, qlmicf1 0.37850, qlmacf1 0.22495, chxlmicf1 0.53169, chxlmacf1 0.46853, chxlacc 0.70276, chxlrocaucmic 0.79770, chxlrocaucmac 0.76151, 27.94 secs\n",
      "Adjusting learning rate of group 0 to 5.5242e-06.\n",
      "\u001b[1m---- Epoch 71/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.62466, a_loss 1.25217, cD 0.98653, wmdcmp 0.13652, ema 0.63593, oracc 0.98583, orien_loss 0.02236, qlmicf1 0.38466, qlmacf1 0.22797, ql_loss 0.76370, chxlmicf1 0.53559, chxlmacf1 0.48957, chx_loss 0.82415, chxlacc 0.72688, chxlrocaucmic 0.81539, chxlrocaucmac 0.80262, gacc 0.97780, gloss 0.05834, cxr14micf1 0.35521, cxr14macf1 0.34441, cxr14_loss 0.92444, vnbgmicf1 0.60430, vnbgmacf1 0.46587, vnbg_loss 0.63914, b1 0.47281, b2 0.35317, b3 0.25517, b4 0.18229, padchxlmacf1 0.07750, padchxlmicf1 0.18222, padchxlzmacf1 0.08623, padchxlzmicf1 0.17453, padchxl_loss 0.35124, padchxlz_loss 0.49664, 99.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16112, wmdcmp 0.16369, ema 0.69114, oracc 0.98703, qlmicf1 0.38057, qlmacf1 0.22475, chxlmicf1 0.53257, chxlmacf1 0.47093, chxlacc 0.70240, chxlrocaucmic 0.79752, chxlrocaucmac 0.76312, 27.87 secs\n",
      "Adjusting learning rate of group 0 to 5.2183e-06.\n",
      "\u001b[1m---- Epoch 72/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.30490, a_loss 1.24381, cD 0.97432, wmdcmp 0.13581, ema 0.63384, oracc 0.98548, orien_loss 0.01928, qlmicf1 0.38306, qlmacf1 0.22570, ql_loss 0.76243, chxlmicf1 0.53297, chxlmacf1 0.48674, chx_loss 0.82912, chxlacc 0.72578, chxlrocaucmic 0.81483, chxlrocaucmac 0.80099, gacc 0.97004, gloss 0.07690, cxr14micf1 0.34750, cxr14macf1 0.33957, cxr14_loss 0.94941, vnbgmicf1 0.59432, vnbgmacf1 0.46377, vnbg_loss 0.65366, b1 0.49108, b2 0.37080, b3 0.27277, b4 0.19869, padchxlmacf1 0.08486, padchxlmicf1 0.18875, padchxlzmacf1 0.08679, padchxlzmicf1 0.18384, padchxl_loss 0.33165, padchxlz_loss 0.48410, 98.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16296, wmdcmp 0.16370, ema 0.68397, oracc 0.98797, qlmicf1 0.37660, qlmacf1 0.22390, chxlmicf1 0.52926, chxlmacf1 0.46817, chxlacc 0.70113, chxlrocaucmic 0.79616, chxlrocaucmac 0.76231, 27.87 secs\n",
      "Adjusting learning rate of group 0 to 4.9293e-06.\n",
      "\u001b[1m---- Epoch 73/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.77725, a_loss 1.26307, cD 0.97378, wmdcmp 0.13405, ema 0.64537, oracc 0.98567, orien_loss 0.02108, qlmicf1 0.38357, qlmacf1 0.22508, ql_loss 0.76852, chxlmicf1 0.53086, chxlmacf1 0.48489, chx_loss 0.83034, chxlacc 0.72631, chxlrocaucmic 0.81322, chxlrocaucmac 0.80109, gacc 0.97343, gloss 0.06478, cxr14micf1 0.35400, cxr14macf1 0.34101, cxr14_loss 0.93354, vnbgmicf1 0.59135, vnbgmacf1 0.46494, vnbg_loss 0.64203, b1 0.47864, b2 0.35955, b3 0.26704, b4 0.19837, padchxlmacf1 0.07417, padchxlmicf1 0.17421, padchxlzmacf1 0.08870, padchxlzmicf1 0.17350, padchxl_loss 0.34330, padchxlz_loss 0.48249, 98.94 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.16351, wmdcmp 0.16321, ema 0.68577, oracc 0.98797, qlmicf1 0.38226, qlmacf1 0.22671, chxlmicf1 0.53374, chxlmacf1 0.46915, chxlacc 0.70514, chxlrocaucmic 0.80101, chxlrocaucmac 0.76252, 27.84 secs\n",
      "Adjusting learning rate of group 0 to 4.6563e-06.\n",
      "\u001b[1m---- Epoch 74/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.72415, a_loss 1.25330, cD 0.97775, wmdcmp 0.13710, ema 0.64158, oracc 0.98615, orien_loss 0.01885, qlmicf1 0.38281, qlmacf1 0.22822, ql_loss 0.76285, chxlmicf1 0.52766, chxlmacf1 0.48302, chx_loss 0.83228, chxlacc 0.72320, chxlrocaucmic 0.81081, chxlrocaucmac 0.79934, gacc 0.97472, gloss 0.06284, cxr14micf1 0.37001, cxr14macf1 0.35273, cxr14_loss 0.91875, vnbgmicf1 0.59631, vnbgmacf1 0.46235, vnbg_loss 0.62850, b1 0.47894, b2 0.36155, b3 0.26946, b4 0.20006, padchxlmacf1 0.07295, padchxlmicf1 0.18577, padchxlzmacf1 0.08557, padchxlzmicf1 0.16948, padchxl_loss 0.33669, padchxlz_loss 0.50356, 99.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17813, wmdcmp 0.16546, ema 0.69740, oracc 0.98821, qlmicf1 0.38016, qlmacf1 0.22652, chxlmicf1 0.53321, chxlmacf1 0.46819, chxlacc 0.70815, chxlrocaucmic 0.79890, chxlrocaucmac 0.76048, 27.80 secs\n",
      "Adjusting learning rate of group 0 to 4.3984e-06.\n",
      "\u001b[1m---- Epoch 75/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.65985, a_loss 1.24518, cD 0.97221, wmdcmp 0.13518, ema 0.63236, oracc 0.98488, orien_loss 0.02577, qlmicf1 0.37872, qlmacf1 0.22618, ql_loss 0.76608, chxlmicf1 0.53042, chxlmacf1 0.48446, chx_loss 0.83398, chxlacc 0.72446, chxlrocaucmic 0.81100, chxlrocaucmac 0.79754, gacc 0.97552, gloss 0.06596, cxr14micf1 0.36553, cxr14macf1 0.34875, cxr14_loss 0.92083, vnbgmicf1 0.59232, vnbgmacf1 0.45415, vnbg_loss 0.65509, b1 0.48010, b2 0.36213, b3 0.26668, b4 0.19630, padchxlmacf1 0.07872, padchxlmicf1 0.18221, padchxlzmacf1 0.09068, padchxlzmicf1 0.17977, padchxl_loss 0.34738, padchxlz_loss 0.47885, 98.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17679, wmdcmp 0.16461, ema 0.68397, oracc 0.98750, qlmicf1 0.37826, qlmacf1 0.22428, chxlmicf1 0.53144, chxlmacf1 0.47075, chxlacc 0.70289, chxlrocaucmic 0.79688, chxlrocaucmac 0.76373, 27.92 secs\n",
      "Adjusting learning rate of group 0 to 4.1549e-06.\n",
      "\u001b[1m---- Epoch 76/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.19685, a_loss 1.24791, cD 0.95991, wmdcmp 0.13340, ema 0.64367, oracc 0.98331, orien_loss 0.02373, qlmicf1 0.38183, qlmacf1 0.22534, ql_loss 0.76710, chxlmicf1 0.53039, chxlmacf1 0.48592, chx_loss 0.82959, chxlacc 0.72426, chxlrocaucmic 0.81105, chxlrocaucmac 0.79876, gacc 0.97835, gloss 0.06063, cxr14micf1 0.35877, cxr14macf1 0.34596, cxr14_loss 0.91742, vnbgmicf1 0.60683, vnbgmacf1 0.47198, vnbg_loss 0.64265, b1 0.49077, b2 0.37369, b3 0.28056, b4 0.21034, padchxlmacf1 0.07742, padchxlmicf1 0.18130, padchxlzmacf1 0.08740, padchxlzmicf1 0.18129, padchxl_loss 0.34116, padchxlz_loss 0.47702, 98.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19403, wmdcmp 0.16656, ema 0.68756, oracc 0.98774, qlmicf1 0.38544, qlmacf1 0.22439, chxlmicf1 0.53563, chxlmacf1 0.46880, chxlacc 0.71287, chxlrocaucmic 0.80147, chxlrocaucmac 0.76359, 27.89 secs\n",
      "Adjusting learning rate of group 0 to 3.9248e-06.\n",
      "\u001b[1m---- Epoch 77/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.89236, a_loss 1.26048, cD 0.97821, wmdcmp 0.13588, ema 0.64152, oracc 0.98628, orien_loss 0.02077, qlmicf1 0.38069, qlmacf1 0.23114, ql_loss 0.76244, chxlmicf1 0.53053, chxlmacf1 0.48527, chx_loss 0.83246, chxlacc 0.72405, chxlrocaucmic 0.81251, chxlrocaucmac 0.79958, gacc 0.97552, gloss 0.06710, cxr14micf1 0.35318, cxr14macf1 0.34027, cxr14_loss 0.92468, vnbgmicf1 0.60689, vnbgmacf1 0.46748, vnbg_loss 0.63745, b1 0.47909, b2 0.36121, b3 0.26727, b4 0.19589, padchxlmacf1 0.07777, padchxlmicf1 0.17542, padchxlzmacf1 0.08528, padchxlzmicf1 0.16698, padchxl_loss 0.34674, padchxlz_loss 0.48240, 98.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16976, wmdcmp 0.16420, ema 0.69203, oracc 0.98726, qlmicf1 0.38279, qlmacf1 0.22504, chxlmicf1 0.53403, chxlmacf1 0.46934, chxlacc 0.70472, chxlrocaucmic 0.80167, chxlrocaucmac 0.76308, 27.81 secs\n",
      "Adjusting learning rate of group 0 to 3.7074e-06.\n",
      "\u001b[1m---- Epoch 78/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.60931, a_loss 1.24548, cD 0.97506, wmdcmp 0.13492, ema 0.64124, oracc 0.98417, orien_loss 0.02388, qlmicf1 0.38236, qlmacf1 0.22811, ql_loss 0.76361, chxlmicf1 0.53517, chxlmacf1 0.49076, chx_loss 0.82125, chxlacc 0.72900, chxlrocaucmic 0.81616, chxlrocaucmac 0.80464, gacc 0.97605, gloss 0.06156, cxr14micf1 0.35686, cxr14macf1 0.34417, cxr14_loss 0.92191, vnbgmicf1 0.60468, vnbgmacf1 0.47273, vnbg_loss 0.63692, b1 0.49350, b2 0.37254, b3 0.27544, b4 0.20505, padchxlmacf1 0.06865, padchxlmicf1 0.18187, padchxlzmacf1 0.08311, padchxlzmicf1 0.17751, padchxl_loss 0.34240, padchxlz_loss 0.49094, 98.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17274, wmdcmp 0.16497, ema 0.68577, oracc 0.98679, qlmicf1 0.38262, qlmacf1 0.22662, chxlmicf1 0.53873, chxlmacf1 0.47269, chxlacc 0.70898, chxlrocaucmic 0.80343, chxlrocaucmac 0.76350, 27.86 secs\n",
      "Adjusting learning rate of group 0 to 3.5021e-06.\n",
      "\u001b[1m---- Epoch 79/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.62385, a_loss 1.24067, cD 0.96946, wmdcmp 0.13393, ema 0.64367, oracc 0.98292, orien_loss 0.02278, qlmicf1 0.38162, qlmacf1 0.22823, ql_loss 0.76938, chxlmicf1 0.53243, chxlmacf1 0.48658, chx_loss 0.83184, chxlacc 0.72713, chxlrocaucmic 0.81335, chxlrocaucmac 0.80017, gacc 0.97395, gloss 0.06890, cxr14micf1 0.35066, cxr14macf1 0.34550, cxr14_loss 0.92528, vnbgmicf1 0.60205, vnbgmacf1 0.47098, vnbg_loss 0.62806, b1 0.49082, b2 0.37216, b3 0.27487, b4 0.20283, padchxlmacf1 0.07658, padchxlmicf1 0.18318, padchxlzmacf1 0.09084, padchxlzmicf1 0.18292, padchxl_loss 0.33753, padchxlz_loss 0.47699, 98.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18572, wmdcmp 0.16633, ema 0.69293, oracc 0.98797, qlmicf1 0.38286, qlmacf1 0.22425, chxlmicf1 0.53258, chxlmacf1 0.47099, chxlacc 0.70571, chxlrocaucmic 0.79721, chxlrocaucmac 0.76396, 27.89 secs\n",
      "Adjusting learning rate of group 0 to 3.3082e-06.\n",
      "\u001b[1m---- Epoch 80/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.14911, a_loss 1.24447, cD 0.98897, wmdcmp 0.13655, ema 0.64889, oracc 0.98535, orien_loss 0.02084, qlmicf1 0.38135, qlmacf1 0.22760, ql_loss 0.75960, chxlmicf1 0.53022, chxlmacf1 0.48572, chx_loss 0.82865, chxlacc 0.72753, chxlrocaucmic 0.81215, chxlrocaucmac 0.80122, gacc 0.97662, gloss 0.05980, cxr14micf1 0.36989, cxr14macf1 0.35468, cxr14_loss 0.90087, vnbgmicf1 0.60375, vnbgmacf1 0.46923, vnbg_loss 0.63689, b1 0.50899, b2 0.38675, b3 0.28912, b4 0.21620, padchxlmacf1 0.08174, padchxlmicf1 0.18412, padchxlzmacf1 0.08727, padchxlzmicf1 0.18420, padchxl_loss 0.33499, padchxlz_loss 0.47523, 98.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16480, wmdcmp 0.16336, ema 0.70009, oracc 0.98750, qlmicf1 0.38351, qlmacf1 0.22408, chxlmicf1 0.53821, chxlmacf1 0.47305, chxlacc 0.70885, chxlrocaucmic 0.80291, chxlrocaucmac 0.76642, 27.93 secs\n",
      "Adjusting learning rate of group 0 to 3.1250e-06.\n",
      "\u001b[1m---- Epoch 81/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.83625, a_loss 1.25009, cD 0.96721, wmdcmp 0.13601, ema 0.64344, oracc 0.98468, orien_loss 0.02060, qlmicf1 0.37994, qlmacf1 0.22459, ql_loss 0.76256, chxlmicf1 0.53441, chxlmacf1 0.48952, chx_loss 0.82495, chxlacc 0.72802, chxlrocaucmic 0.81523, chxlrocaucmac 0.80303, gacc 0.97815, gloss 0.06438, cxr14micf1 0.36569, cxr14macf1 0.34789, cxr14_loss 0.92120, vnbgmicf1 0.59850, vnbgmacf1 0.46900, vnbg_loss 0.63267, b1 0.46852, b2 0.35210, b3 0.25715, b4 0.18939, padchxlmacf1 0.07445, padchxlmicf1 0.18403, padchxlzmacf1 0.08304, padchxlzmicf1 0.16829, padchxl_loss 0.33633, padchxlz_loss 0.45973, 98.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16590, wmdcmp 0.16310, ema 0.69472, oracc 0.98774, qlmicf1 0.38524, qlmacf1 0.22738, chxlmicf1 0.53651, chxlmacf1 0.47078, chxlacc 0.71097, chxlrocaucmic 0.80358, chxlrocaucmac 0.76531, 27.86 secs\n",
      "Adjusting learning rate of group 0 to 2.9519e-06.\n",
      "\u001b[1m---- Epoch 82/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.48384, a_loss 1.25818, cD 0.97207, wmdcmp 0.13618, ema 0.63923, oracc 0.98387, orien_loss 0.02583, qlmicf1 0.38620, qlmacf1 0.22792, ql_loss 0.75912, chxlmicf1 0.53351, chxlmacf1 0.48756, chx_loss 0.82634, chxlacc 0.72774, chxlrocaucmic 0.81580, chxlrocaucmac 0.80308, gacc 0.97801, gloss 0.06294, cxr14micf1 0.35652, cxr14macf1 0.34643, cxr14_loss 0.93442, vnbgmicf1 0.60471, vnbgmacf1 0.46542, vnbg_loss 0.64087, b1 0.47322, b2 0.35801, b3 0.26330, b4 0.19239, padchxlmacf1 0.07953, padchxlmicf1 0.18183, padchxlzmacf1 0.08948, padchxlzmicf1 0.18550, padchxl_loss 0.34855, padchxlz_loss 0.49786, 98.71 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.17541, wmdcmp 0.16446, ema 0.68666, oracc 0.98774, qlmicf1 0.38497, qlmacf1 0.22549, chxlmicf1 0.53568, chxlmacf1 0.47039, chxlacc 0.70913, chxlrocaucmic 0.80158, chxlrocaucmac 0.76426, 27.96 secs\n",
      "Adjusting learning rate of group 0 to 2.7884e-06.\n",
      "\u001b[1m---- Epoch 83/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.18536, a_loss 1.25953, cD 0.95929, wmdcmp 0.13252, ema 0.64449, oracc 0.98305, orien_loss 0.02180, qlmicf1 0.39146, qlmacf1 0.23184, ql_loss 0.75777, chxlmicf1 0.53617, chxlmacf1 0.49001, chx_loss 0.82102, chxlacc 0.72993, chxlrocaucmic 0.81675, chxlrocaucmac 0.80469, gacc 0.97465, gloss 0.06768, cxr14micf1 0.35252, cxr14macf1 0.34263, cxr14_loss 0.93096, vnbgmicf1 0.60004, vnbgmacf1 0.47152, vnbg_loss 0.63596, b1 0.47637, b2 0.35724, b3 0.26319, b4 0.19578, padchxlmacf1 0.07074, padchxlmicf1 0.18225, padchxlzmacf1 0.08243, padchxlzmicf1 0.16035, padchxl_loss 0.32963, padchxlz_loss 0.47379, 98.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16323, wmdcmp 0.16393, ema 0.70457, oracc 0.98774, qlmicf1 0.39137, qlmacf1 0.22785, chxlmicf1 0.53412, chxlmacf1 0.46907, chxlacc 0.70787, chxlrocaucmic 0.80186, chxlrocaucmac 0.76435, 27.88 secs\n",
      "Adjusting learning rate of group 0 to 2.6340e-06.\n",
      "\u001b[1m---- Epoch 84/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.75248, a_loss 1.24715, cD 0.97139, wmdcmp 0.13551, ema 0.63810, oracc 0.98482, orien_loss 0.02205, qlmicf1 0.38460, qlmacf1 0.22688, ql_loss 0.76079, chxlmicf1 0.53405, chxlmacf1 0.48821, chx_loss 0.82720, chxlacc 0.72756, chxlrocaucmic 0.81456, chxlrocaucmac 0.80190, gacc 0.97308, gloss 0.07230, cxr14micf1 0.35913, cxr14macf1 0.34872, cxr14_loss 0.90770, vnbgmicf1 0.59510, vnbgmacf1 0.45929, vnbg_loss 0.64386, b1 0.49802, b2 0.37677, b3 0.27925, b4 0.20689, padchxlmacf1 0.07557, padchxlmicf1 0.18001, padchxlzmacf1 0.09285, padchxlzmicf1 0.19016, padchxl_loss 0.34682, padchxlz_loss 0.48839, 98.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17699, wmdcmp 0.16537, ema 0.69114, oracc 0.98726, qlmicf1 0.37905, qlmacf1 0.22391, chxlmicf1 0.53517, chxlmacf1 0.47061, chxlacc 0.70743, chxlrocaucmic 0.80020, chxlrocaucmac 0.76403, 27.83 secs\n",
      "Adjusting learning rate of group 0 to 2.4881e-06.\n",
      "\u001b[1m---- Epoch 85/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.10952, a_loss 1.23958, cD 0.98882, wmdcmp 0.13578, ema 0.63986, oracc 0.98581, orien_loss 0.02038, qlmicf1 0.38136, qlmacf1 0.22683, ql_loss 0.76927, chxlmicf1 0.53327, chxlmacf1 0.48825, chx_loss 0.82517, chxlacc 0.72620, chxlrocaucmic 0.81481, chxlrocaucmac 0.80286, gacc 0.97413, gloss 0.06568, cxr14micf1 0.36491, cxr14macf1 0.34544, cxr14_loss 0.91810, vnbgmicf1 0.60124, vnbgmacf1 0.46854, vnbg_loss 0.65555, b1 0.47613, b2 0.36510, b3 0.27156, b4 0.20038, padchxlmacf1 0.08196, padchxlmicf1 0.18389, padchxlzmacf1 0.08984, padchxlzmicf1 0.18771, padchxl_loss 0.33983, padchxlz_loss 0.47799, 98.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16800, wmdcmp 0.16404, ema 0.68308, oracc 0.98774, qlmicf1 0.37719, qlmacf1 0.22485, chxlmicf1 0.53542, chxlmacf1 0.47204, chxlacc 0.70741, chxlrocaucmic 0.80088, chxlrocaucmac 0.76426, 27.85 secs\n",
      "Adjusting learning rate of group 0 to 2.3504e-06.\n",
      "\u001b[1m---- Epoch 86/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.19606, a_loss 1.25477, cD 0.96098, wmdcmp 0.13362, ema 0.64193, oracc 0.98501, orien_loss 0.02530, qlmicf1 0.37975, qlmacf1 0.22722, ql_loss 0.76702, chxlmicf1 0.53309, chxlmacf1 0.48815, chx_loss 0.82341, chxlacc 0.72823, chxlrocaucmic 0.81591, chxlrocaucmac 0.80339, gacc 0.97922, gloss 0.06232, cxr14micf1 0.36155, cxr14macf1 0.35136, cxr14_loss 0.91363, vnbgmicf1 0.60829, vnbgmacf1 0.46877, vnbg_loss 0.63608, b1 0.44790, b2 0.33502, b3 0.24456, b4 0.17976, padchxlmacf1 0.08124, padchxlmicf1 0.18650, padchxlzmacf1 0.08803, padchxlzmicf1 0.16732, padchxl_loss 0.33666, padchxlz_loss 0.48154, 99.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19800, wmdcmp 0.16787, ema 0.69382, oracc 0.98774, qlmicf1 0.38011, qlmacf1 0.22440, chxlmicf1 0.53495, chxlmacf1 0.46998, chxlacc 0.70859, chxlrocaucmic 0.80060, chxlrocaucmac 0.76306, 27.90 secs\n",
      "Adjusting learning rate of group 0 to 2.2202e-06.\n",
      "\u001b[1m---- Epoch 87/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.12902, a_loss 1.22998, cD 0.99484, wmdcmp 0.13765, ema 0.63967, oracc 0.98395, orien_loss 0.02230, qlmicf1 0.38232, qlmacf1 0.22628, ql_loss 0.76422, chxlmicf1 0.53526, chxlmacf1 0.48938, chx_loss 0.82501, chxlacc 0.72739, chxlrocaucmic 0.81466, chxlrocaucmac 0.80158, gacc 0.97870, gloss 0.05958, cxr14micf1 0.36971, cxr14macf1 0.35188, cxr14_loss 0.91298, vnbgmicf1 0.61255, vnbgmacf1 0.47238, vnbg_loss 0.63874, b1 0.49789, b2 0.37615, b3 0.27786, b4 0.20694, padchxlmacf1 0.07736, padchxlmicf1 0.19427, padchxlzmacf1 0.08904, padchxlzmicf1 0.18412, padchxl_loss 0.32824, padchxlz_loss 0.46413, 98.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17181, wmdcmp 0.16363, ema 0.69114, oracc 0.98821, qlmicf1 0.38388, qlmacf1 0.22562, chxlmicf1 0.53799, chxlmacf1 0.47101, chxlacc 0.71179, chxlrocaucmic 0.80286, chxlrocaucmac 0.76429, 29.04 secs\n",
      "Adjusting learning rate of group 0 to 2.0972e-06.\n",
      "\u001b[1m---- Epoch 88/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.68538, a_loss 1.25155, cD 0.98022, wmdcmp 0.13556, ema 0.64350, oracc 0.98543, orien_loss 0.02175, qlmicf1 0.38271, qlmacf1 0.22952, ql_loss 0.76302, chxlmicf1 0.53364, chxlmacf1 0.48898, chx_loss 0.82200, chxlacc 0.72688, chxlrocaucmic 0.81507, chxlrocaucmac 0.80304, gacc 0.97448, gloss 0.06353, cxr14micf1 0.35144, cxr14macf1 0.34299, cxr14_loss 0.92339, vnbgmicf1 0.61067, vnbgmacf1 0.48109, vnbg_loss 0.64494, b1 0.47965, b2 0.36439, b3 0.26950, b4 0.19927, padchxlmacf1 0.07711, padchxlmicf1 0.17336, padchxlzmacf1 0.08210, padchxlzmicf1 0.17693, padchxl_loss 0.34954, padchxlz_loss 0.48993, 98.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17248, wmdcmp 0.16404, ema 0.69382, oracc 0.98750, qlmicf1 0.38316, qlmacf1 0.22578, chxlmicf1 0.53395, chxlmacf1 0.47105, chxlacc 0.70584, chxlrocaucmic 0.79969, chxlrocaucmac 0.76423, 27.86 secs\n",
      "Adjusting learning rate of group 0 to 1.9811e-06.\n",
      "\u001b[1m---- Epoch 89/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.80738, a_loss 1.24805, cD 0.96530, wmdcmp 0.13340, ema 0.65533, oracc 0.98448, orien_loss 0.02060, qlmicf1 0.38454, qlmacf1 0.22911, ql_loss 0.76066, chxlmicf1 0.53660, chxlmacf1 0.49078, chx_loss 0.82141, chxlacc 0.72954, chxlrocaucmic 0.81779, chxlrocaucmac 0.80614, gacc 0.97535, gloss 0.06479, cxr14micf1 0.38027, cxr14macf1 0.35823, cxr14_loss 0.91345, vnbgmicf1 0.60430, vnbgmacf1 0.46445, vnbg_loss 0.62033, b1 0.50267, b2 0.38056, b3 0.28101, b4 0.20476, padchxlmacf1 0.06786, padchxlmicf1 0.17886, padchxlzmacf1 0.08224, padchxlzmicf1 0.17153, padchxl_loss 0.32814, padchxlz_loss 0.48726, 98.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16506, wmdcmp 0.16356, ema 0.69651, oracc 0.98821, qlmicf1 0.37973, qlmacf1 0.22400, chxlmicf1 0.53180, chxlmacf1 0.46988, chxlacc 0.70407, chxlrocaucmic 0.79803, chxlrocaucmac 0.76439, 27.80 secs\n",
      "Adjusting learning rate of group 0 to 1.8714e-06.\n",
      "\u001b[1m---- Epoch 90/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.38183, a_loss 1.25675, cD 0.96600, wmdcmp 0.13407, ema 0.63288, oracc 0.98555, orien_loss 0.01770, qlmicf1 0.38115, qlmacf1 0.22631, ql_loss 0.76573, chxlmicf1 0.53240, chxlmacf1 0.48599, chx_loss 0.82551, chxlacc 0.72870, chxlrocaucmic 0.81457, chxlrocaucmac 0.80265, gacc 0.97558, gloss 0.06408, cxr14micf1 0.35850, cxr14macf1 0.34836, cxr14_loss 0.92943, vnbgmicf1 0.59687, vnbgmacf1 0.46159, vnbg_loss 0.65004, b1 0.48747, b2 0.37341, b3 0.28167, b4 0.21357, padchxlmacf1 0.07786, padchxlmicf1 0.18540, padchxlzmacf1 0.09256, padchxlzmicf1 0.19078, padchxl_loss 0.33884, padchxlz_loss 0.47434, 98.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17249, wmdcmp 0.16490, ema 0.68666, oracc 0.98726, qlmicf1 0.38127, qlmacf1 0.22486, chxlmicf1 0.53820, chxlmacf1 0.47212, chxlacc 0.71125, chxlrocaucmic 0.80131, chxlrocaucmac 0.76487, 27.80 secs\n",
      "Adjusting learning rate of group 0 to 1.7678e-06.\n",
      "\u001b[1m---- Epoch 91/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.67684, a_loss 1.23821, cD 0.97509, wmdcmp 0.13535, ema 0.64002, oracc 0.98381, orien_loss 0.02232, qlmicf1 0.38414, qlmacf1 0.22872, ql_loss 0.76491, chxlmicf1 0.53766, chxlmacf1 0.49246, chx_loss 0.82128, chxlacc 0.73048, chxlrocaucmic 0.81675, chxlrocaucmac 0.80506, gacc 0.97535, gloss 0.06501, cxr14micf1 0.34986, cxr14macf1 0.34123, cxr14_loss 0.92828, vnbgmicf1 0.59750, vnbgmacf1 0.46956, vnbg_loss 0.65328, b1 0.47231, b2 0.35774, b3 0.26495, b4 0.19730, padchxlmacf1 0.08072, padchxlmicf1 0.18765, padchxlzmacf1 0.09067, padchxlzmicf1 0.19380, padchxl_loss 0.33573, padchxlz_loss 0.47105, 98.87 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.18473, wmdcmp 0.16541, ema 0.69293, oracc 0.98750, qlmicf1 0.38369, qlmacf1 0.22539, chxlmicf1 0.53547, chxlmacf1 0.47192, chxlacc 0.70438, chxlrocaucmic 0.80171, chxlrocaucmac 0.76396, 27.87 secs\n",
      "Adjusting learning rate of group 0 to 1.6699e-06.\n",
      "\u001b[1m---- Epoch 92/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.42149, a_loss 1.25302, cD 0.97493, wmdcmp 0.13518, ema 0.63515, oracc 0.98614, orien_loss 0.02427, qlmicf1 0.38502, qlmacf1 0.22699, ql_loss 0.76184, chxlmicf1 0.53776, chxlmacf1 0.49249, chx_loss 0.81763, chxlacc 0.72909, chxlrocaucmic 0.81782, chxlrocaucmac 0.80672, gacc 0.97045, gloss 0.07221, cxr14micf1 0.35855, cxr14macf1 0.34303, cxr14_loss 0.93050, vnbgmicf1 0.59578, vnbgmacf1 0.46203, vnbg_loss 0.63183, b1 0.48479, b2 0.36567, b3 0.26983, b4 0.19893, padchxlmacf1 0.07845, padchxlmicf1 0.17369, padchxlzmacf1 0.08992, padchxlzmicf1 0.17614, padchxl_loss 0.34823, padchxlz_loss 0.48336, 98.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16997, wmdcmp 0.16423, ema 0.69293, oracc 0.98679, qlmicf1 0.38148, qlmacf1 0.22547, chxlmicf1 0.53380, chxlmacf1 0.47013, chxlacc 0.70563, chxlrocaucmic 0.79928, chxlrocaucmac 0.76304, 27.94 secs\n",
      "Adjusting learning rate of group 0 to 1.5774e-06.\n",
      "\u001b[1m---- Epoch 93/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.01628, a_loss 1.25557, cD 0.99366, wmdcmp 0.13736, ema 0.64528, oracc 0.98628, orien_loss 0.01771, qlmicf1 0.38176, qlmacf1 0.22870, ql_loss 0.75983, chxlmicf1 0.53499, chxlmacf1 0.48824, chx_loss 0.82097, chxlacc 0.72791, chxlrocaucmic 0.81650, chxlrocaucmac 0.80435, gacc 0.97850, gloss 0.05776, cxr14micf1 0.37057, cxr14macf1 0.35393, cxr14_loss 0.91232, vnbgmicf1 0.59771, vnbgmacf1 0.46318, vnbg_loss 0.64506, b1 0.47286, b2 0.35665, b3 0.26469, b4 0.19696, padchxlmacf1 0.07544, padchxlmicf1 0.17812, padchxlzmacf1 0.09104, padchxlzmicf1 0.18254, padchxl_loss 0.34719, padchxlz_loss 0.47890, 98.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17195, wmdcmp 0.16386, ema 0.68218, oracc 0.98750, qlmicf1 0.38242, qlmacf1 0.22552, chxlmicf1 0.53477, chxlmacf1 0.47030, chxlacc 0.70769, chxlrocaucmic 0.80027, chxlrocaucmac 0.76354, 27.91 secs\n",
      "Adjusting learning rate of group 0 to 1.4900e-06.\n",
      "\u001b[1m---- Epoch 94/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.66657, a_loss 1.23490, cD 0.98495, wmdcmp 0.13558, ema 0.64341, oracc 0.98571, orien_loss 0.02299, qlmicf1 0.38458, qlmacf1 0.22984, ql_loss 0.76286, chxlmicf1 0.53717, chxlmacf1 0.49225, chx_loss 0.81794, chxlacc 0.72961, chxlrocaucmic 0.81645, chxlrocaucmac 0.80438, gacc 0.97535, gloss 0.06194, cxr14micf1 0.35447, cxr14macf1 0.34462, cxr14_loss 0.93336, vnbgmicf1 0.59391, vnbgmacf1 0.46019, vnbg_loss 0.62727, b1 0.51274, b2 0.38860, b3 0.28704, b4 0.21175, padchxlmacf1 0.07429, padchxlmicf1 0.17717, padchxlzmacf1 0.08776, padchxlzmicf1 0.17445, padchxl_loss 0.34119, padchxlz_loss 0.49201, 98.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17707, wmdcmp 0.16528, ema 0.68397, oracc 0.98821, qlmicf1 0.38389, qlmacf1 0.22536, chxlmicf1 0.53713, chxlmacf1 0.47095, chxlacc 0.71118, chxlrocaucmic 0.80251, chxlrocaucmac 0.76321, 27.83 secs\n",
      "Adjusting learning rate of group 0 to 1.4075e-06.\n",
      "\u001b[1m---- Epoch 95/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.17413, a_loss 1.24217, cD 0.97503, wmdcmp 0.13448, ema 0.64993, oracc 0.98642, orien_loss 0.02137, qlmicf1 0.38450, qlmacf1 0.22615, ql_loss 0.76070, chxlmicf1 0.53966, chxlmacf1 0.49375, chx_loss 0.81439, chxlacc 0.73092, chxlrocaucmic 0.81931, chxlrocaucmac 0.80602, gacc 0.97593, gloss 0.05868, cxr14micf1 0.36912, cxr14macf1 0.34598, cxr14_loss 0.91266, vnbgmicf1 0.60848, vnbgmacf1 0.46292, vnbg_loss 0.62921, b1 0.48333, b2 0.36444, b3 0.26639, b4 0.19423, padchxlmacf1 0.07304, padchxlmicf1 0.17127, padchxlzmacf1 0.09209, padchxlzmicf1 0.17555, padchxl_loss 0.33431, padchxlz_loss 0.46724, 98.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19335, wmdcmp 0.16669, ema 0.69203, oracc 0.98774, qlmicf1 0.38319, qlmacf1 0.22579, chxlmicf1 0.53613, chxlmacf1 0.46949, chxlacc 0.70971, chxlrocaucmic 0.80132, chxlrocaucmac 0.76177, 27.91 secs\n",
      "Adjusting learning rate of group 0 to 1.3296e-06.\n",
      "\u001b[1m---- Epoch 96/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.79535, a_loss 1.25050, cD 1.00143, wmdcmp 0.13646, ema 0.63969, oracc 0.98439, orien_loss 0.02133, qlmicf1 0.38135, qlmacf1 0.23201, ql_loss 0.76062, chxlmicf1 0.53712, chxlmacf1 0.49044, chx_loss 0.82419, chxlacc 0.73155, chxlrocaucmic 0.81611, chxlrocaucmac 0.80253, gacc 0.97745, gloss 0.05925, cxr14micf1 0.36877, cxr14macf1 0.34975, cxr14_loss 0.92447, vnbgmicf1 0.61623, vnbgmacf1 0.47642, vnbg_loss 0.61180, b1 0.47668, b2 0.36203, b3 0.26922, b4 0.19971, padchxlmacf1 0.07822, padchxlmicf1 0.17995, padchxlzmacf1 0.09005, padchxlzmicf1 0.18582, padchxl_loss 0.34361, padchxlz_loss 0.47348, 98.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16527, wmdcmp 0.16363, ema 0.70904, oracc 0.98774, qlmicf1 0.38324, qlmacf1 0.22485, chxlmicf1 0.53683, chxlmacf1 0.47191, chxlacc 0.71252, chxlrocaucmic 0.80019, chxlrocaucmac 0.76382, 27.84 secs\n",
      "Adjusting learning rate of group 0 to 1.2559e-06.\n",
      "\u001b[1m---- Epoch 97/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.72901, a_loss 1.24680, cD 0.98549, wmdcmp 0.13648, ema 0.64445, oracc 0.98440, orien_loss 0.02179, qlmicf1 0.37794, qlmacf1 0.22933, ql_loss 0.76246, chxlmicf1 0.53865, chxlmacf1 0.49493, chx_loss 0.81674, chxlacc 0.72960, chxlrocaucmic 0.81691, chxlrocaucmac 0.80601, gacc 0.97680, gloss 0.06230, cxr14micf1 0.37288, cxr14macf1 0.35399, cxr14_loss 0.90710, vnbgmicf1 0.60649, vnbgmacf1 0.48248, vnbg_loss 0.62396, b1 0.49536, b2 0.37885, b3 0.28145, b4 0.20923, padchxlmacf1 0.07695, padchxlmicf1 0.18136, padchxlzmacf1 0.08548, padchxlzmicf1 0.17147, padchxl_loss 0.33394, padchxlz_loss 0.47965, 98.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17082, wmdcmp 0.16443, ema 0.69293, oracc 0.98703, qlmicf1 0.38400, qlmacf1 0.22676, chxlmicf1 0.53749, chxlmacf1 0.47210, chxlacc 0.71220, chxlrocaucmic 0.80097, chxlrocaucmac 0.76417, 27.82 secs\n",
      "Adjusting learning rate of group 0 to 1.1864e-06.\n",
      "\u001b[1m---- Epoch 98/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.78223, a_loss 1.23828, cD 0.99393, wmdcmp 0.13668, ema 0.64498, oracc 0.98433, orien_loss 0.02451, qlmicf1 0.38471, qlmacf1 0.22933, ql_loss 0.75878, chxlmicf1 0.53699, chxlmacf1 0.49082, chx_loss 0.81657, chxlacc 0.73009, chxlrocaucmic 0.81827, chxlrocaucmac 0.80627, gacc 0.97832, gloss 0.06510, cxr14micf1 0.35955, cxr14macf1 0.35275, cxr14_loss 0.91116, vnbgmicf1 0.60133, vnbgmacf1 0.49037, vnbg_loss 0.63707, b1 0.47436, b2 0.35638, b3 0.26196, b4 0.19032, padchxlmacf1 0.07327, padchxlmicf1 0.16865, padchxlzmacf1 0.08701, padchxlzmicf1 0.17888, padchxl_loss 0.33668, padchxlz_loss 0.47650, 99.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17365, wmdcmp 0.16482, ema 0.68666, oracc 0.98726, qlmicf1 0.38615, qlmacf1 0.22623, chxlmicf1 0.53615, chxlmacf1 0.46999, chxlacc 0.71120, chxlrocaucmic 0.80149, chxlrocaucmac 0.76174, 27.84 secs\n",
      "Adjusting learning rate of group 0 to 1.1207e-06.\n",
      "\u001b[1m---- Epoch 99/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.24718, a_loss 1.24285, cD 0.97854, wmdcmp 0.13494, ema 0.64854, oracc 0.98226, orien_loss 0.02896, qlmicf1 0.39019, qlmacf1 0.22847, ql_loss 0.75608, chxlmicf1 0.53405, chxlmacf1 0.48758, chx_loss 0.82434, chxlacc 0.73044, chxlrocaucmic 0.81610, chxlrocaucmac 0.80359, gacc 0.97801, gloss 0.05616, cxr14micf1 0.33865, cxr14macf1 0.33613, cxr14_loss 0.93400, vnbgmicf1 0.60161, vnbgmacf1 0.47406, vnbg_loss 0.63097, b1 0.48190, b2 0.36759, b3 0.27437, b4 0.20272, padchxlmacf1 0.07678, padchxlmicf1 0.17272, padchxlzmacf1 0.08602, padchxlzmicf1 0.17589, padchxl_loss 0.35589, padchxlz_loss 0.49180, 98.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18261, wmdcmp 0.16559, ema 0.69472, oracc 0.98774, qlmicf1 0.38385, qlmacf1 0.22463, chxlmicf1 0.53534, chxlmacf1 0.47082, chxlacc 0.70859, chxlrocaucmic 0.80021, chxlrocaucmac 0.76122, 27.86 secs\n",
      "Adjusting learning rate of group 0 to 1.0586e-06.\n",
      "\u001b[1m---- Epoch 100/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.82604, a_loss 1.24903, cD 0.96632, wmdcmp 0.13330, ema 0.63855, oracc 0.98460, orien_loss 0.02470, qlmicf1 0.38579, qlmacf1 0.22749, ql_loss 0.76227, chxlmicf1 0.53324, chxlmacf1 0.48637, chx_loss 0.82767, chxlacc 0.72882, chxlrocaucmic 0.81535, chxlrocaucmac 0.80168, gacc 0.97535, gloss 0.06351, cxr14micf1 0.35762, cxr14macf1 0.34644, cxr14_loss 0.93003, vnbgmicf1 0.61211, vnbgmacf1 0.47834, vnbg_loss 0.61736, b1 0.46567, b2 0.35357, b3 0.26258, b4 0.19657, padchxlmacf1 0.07501, padchxlmicf1 0.17732, padchxlzmacf1 0.09026, padchxlzmicf1 0.17910, padchxl_loss 0.33458, padchxlz_loss 0.48667, 98.88 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.18895, wmdcmp 0.16547, ema 0.69203, oracc 0.98750, qlmicf1 0.38266, qlmacf1 0.22509, chxlmicf1 0.53363, chxlmacf1 0.46983, chxlacc 0.70712, chxlrocaucmic 0.80068, chxlrocaucmac 0.76313, 27.90 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 100 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 55 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,2e-4,93,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"facebook/vit-mae-base\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: facebook/vit-mae-base\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,2e-4,53,3e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 55\n",
      "   iters_to_accumulate: 5\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.6\n",
      "   cxr14_weight: 0.0\n",
      "   vinbig_weight: 0.0\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.0\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.mask_token', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.3.attention.attention.key.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,2e-4,53,3e-6\n",
      "1e-06 7 0.0002 53 3e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 55\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,1651436623822174339).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 55\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,4034709835837782143).pkl\n",
      "\tlen(question_datasets) = 54\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 5\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.6]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230108_144019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230108_144019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp/metadata.json\n",
      "checkpoint_names = ['checkpoint_96_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5551.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_96_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5551.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230108_144019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.58049, a_loss 1.36499, cD 1.06348, wmdcmp 0.14576, ema 0.67587, oracc 0.98281, orien_loss 0.01720, qlmicf1 0.38957, qlmacf1 0.22815, ql_loss 0.75687, chxlmicf1 0.54052, chxlmacf1 0.49398, chx_loss 0.81799, chxlacc 0.73278, chxlrocaucmic 0.81863, chxlrocaucmac 0.80649, gacc 0.97955, gloss 0.05978, 81.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18682, wmdcmp 0.16426, ema 0.66965, oracc 0.98514, qlmicf1 0.37953, qlmacf1 0.22521, chxlmicf1 0.52918, chxlmacf1 0.46585, chxlacc 0.70460, chxlrocaucmic 0.79647, chxlrocaucmac 0.75904, 19.03 secs\n",
      "Adjusting learning rate of group 0 to 2.1317e-06.\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.02706, a_loss 1.43205, cD 0.97032, wmdcmp 0.13443, ema 0.67979, oracc 0.98468, orien_loss 0.01180, qlmicf1 0.38258, qlmacf1 0.23018, ql_loss 0.75915, chxlmicf1 0.53478, chxlmacf1 0.48950, chx_loss 0.82174, chxlacc 0.72735, chxlrocaucmic 0.81423, chxlrocaucmac 0.80305, gacc 0.97671, gloss 0.06595, 77.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17860, wmdcmp 0.16426, ema 0.66159, oracc 0.98561, qlmicf1 0.38503, qlmacf1 0.22626, chxlmicf1 0.52938, chxlmacf1 0.46679, chxlacc 0.70400, chxlrocaucmic 0.79741, chxlrocaucmac 0.75986, 19.10 secs\n",
      "Adjusting learning rate of group 0 to 4.5440e-06.\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 5.06949, a_loss 1.45701, cD 0.99037, wmdcmp 0.13711, ema 0.68193, oracc 0.98577, orien_loss 0.01484, qlmicf1 0.38511, qlmacf1 0.22966, ql_loss 0.76035, chxlmicf1 0.54081, chxlmacf1 0.49393, chx_loss 0.81722, chxlacc 0.73311, chxlrocaucmic 0.81992, chxlrocaucmac 0.80684, gacc 0.97338, gloss 0.07135, 76.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17470, wmdcmp 0.16373, ema 0.67144, oracc 0.98514, qlmicf1 0.38600, qlmacf1 0.22693, chxlmicf1 0.53390, chxlmacf1 0.46809, chxlacc 0.71143, chxlrocaucmic 0.79846, chxlrocaucmac 0.75980, 18.99 secs\n",
      "Adjusting learning rate of group 0 to 9.6863e-06.\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.76742, a_loss 1.45364, cD 0.97322, wmdcmp 0.13562, ema 0.67283, oracc 0.98433, orien_loss 0.01506, qlmicf1 0.38785, qlmacf1 0.23421, ql_loss 0.75618, chxlmicf1 0.53673, chxlmacf1 0.49119, chx_loss 0.82249, chxlacc 0.72919, chxlrocaucmic 0.81626, chxlrocaucmac 0.80444, gacc 0.97468, gloss 0.07258, 76.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18113, wmdcmp 0.16431, ema 0.68487, oracc 0.98561, qlmicf1 0.37647, qlmacf1 0.22548, chxlmicf1 0.52674, chxlmacf1 0.46482, chxlacc 0.70251, chxlrocaucmic 0.79336, chxlrocaucmac 0.76008, 19.25 secs\n",
      "Adjusting learning rate of group 0 to 2.0648e-05.\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 4.95342, a_loss 1.45572, cD 0.97698, wmdcmp 0.13604, ema 0.67933, oracc 0.98495, orien_loss 0.01483, qlmicf1 0.37712, qlmacf1 0.22413, ql_loss 0.76304, chxlmicf1 0.53210, chxlmacf1 0.48604, chx_loss 0.82798, chxlacc 0.72624, chxlrocaucmic 0.81259, chxlrocaucmac 0.80148, gacc 0.97045, gloss 0.07482, 77.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15555, wmdcmp 0.16162, ema 0.65622, oracc 0.98443, qlmicf1 0.37050, qlmacf1 0.22340, chxlmicf1 0.51994, chxlmacf1 0.46665, chxlacc 0.69303, chxlrocaucmic 0.78780, chxlrocaucmac 0.76382, 19.14 secs\n",
      "Adjusting learning rate of group 0 to 4.4014e-05.\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 1.10042, a_loss 1.44234, cD 0.98167, wmdcmp 0.13659, ema 0.68738, oracc 0.98305, orien_loss 0.01515, qlmicf1 0.37865, qlmacf1 0.22601, ql_loss 0.76312, chxlmicf1 0.53260, chxlmacf1 0.48633, chx_loss 0.82969, chxlacc 0.72651, chxlrocaucmic 0.81223, chxlrocaucmac 0.80012, gacc 0.97129, gloss 0.08291, 78.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15812, wmdcmp 0.16189, ema 0.67144, oracc 0.98419, qlmicf1 0.38288, qlmacf1 0.22563, chxlmicf1 0.52561, chxlmacf1 0.46608, chxlacc 0.69724, chxlrocaucmic 0.79134, chxlrocaucmac 0.75879, 19.99 secs\n",
      "Adjusting learning rate of group 0 to 9.3823e-05.\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 4.67978, a_loss 1.44184, cD 0.99749, wmdcmp 0.13794, ema 0.65758, oracc 0.98150, orien_loss 0.02247, qlmicf1 0.36368, qlmacf1 0.22014, ql_loss 0.77756, chxlmicf1 0.51811, chxlmacf1 0.47325, chx_loss 0.85621, chxlacc 0.71255, chxlrocaucmic 0.80008, chxlrocaucmac 0.78588, gacc 0.96266, gloss 0.10389, 78.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13479, wmdcmp 0.15732, ema 0.67681, oracc 0.97806, qlmicf1 0.36594, qlmacf1 0.22037, chxlmicf1 0.50122, chxlmacf1 0.45638, chxlacc 0.68598, chxlrocaucmic 0.76100, chxlrocaucmac 0.75553, 19.78 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.66552, a_loss 1.43923, cD 1.00446, wmdcmp 0.13954, ema 0.65347, oracc 0.97975, orien_loss 0.02670, qlmicf1 0.34651, qlmacf1 0.20936, ql_loss 0.79509, chxlmicf1 0.49808, chxlmacf1 0.45404, chx_loss 0.89449, chxlacc 0.69516, chxlrocaucmic 0.78274, chxlrocaucmac 0.76634, gacc 0.93831, gloss 0.15368, 78.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16742, wmdcmp 0.16323, ema 0.65354, oracc 0.98160, qlmicf1 0.36312, qlmacf1 0.21709, chxlmicf1 0.53203, chxlmacf1 0.45171, chxlacc 0.71494, chxlrocaucmic 0.79306, chxlrocaucmac 0.75002, 20.29 secs\n",
      "Adjusting learning rate of group 0 to 1.8476e-04.\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000185) ...\n",
      "loss 4.55711, a_loss 1.42051, cD 1.04012, wmdcmp 0.14282, ema 0.65097, oracc 0.98052, orien_loss 0.02439, qlmicf1 0.35486, qlmacf1 0.20916, ql_loss 0.79497, chxlmicf1 0.50299, chxlmacf1 0.45950, chx_loss 0.88587, chxlacc 0.70109, chxlrocaucmic 0.78565, chxlrocaucmac 0.77245, gacc 0.89578, gloss 0.25731, 78.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18930, wmdcmp 0.16671, ema 0.67234, oracc 0.98443, qlmicf1 0.38062, qlmacf1 0.21960, chxlmicf1 0.52384, chxlmacf1 0.45325, chxlacc 0.70173, chxlrocaucmic 0.78715, chxlrocaucmac 0.74342, 19.84 secs\n",
      "Adjusting learning rate of group 0 to 1.7069e-04.\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000171) ...\n",
      "loss 1.30811, a_loss 1.38168, cD 1.05582, wmdcmp 0.14538, ema 0.65786, oracc 0.98202, orien_loss 0.02098, qlmicf1 0.35825, qlmacf1 0.21743, ql_loss 0.78593, chxlmicf1 0.51271, chxlmacf1 0.46658, chx_loss 0.86832, chxlacc 0.70771, chxlrocaucmic 0.79617, chxlrocaucmac 0.77984, gacc 0.94992, gloss 0.13788, 78.99 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.25409, wmdcmp 0.17130, ema 0.65980, oracc 0.98467, qlmicf1 0.36157, qlmacf1 0.21695, chxlmicf1 0.51751, chxlmacf1 0.45485, chxlacc 0.69843, chxlrocaucmic 0.78268, chxlrocaucmac 0.74259, 20.15 secs\n",
      "Adjusting learning rate of group 0 to 1.5768e-04.\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000158) ...\n",
      "loss 4.71516, a_loss 1.39032, cD 1.07499, wmdcmp 0.14689, ema 0.66504, oracc 0.98120, orien_loss 0.02253, qlmicf1 0.36301, qlmacf1 0.22263, ql_loss 0.78667, chxlmicf1 0.51311, chxlmacf1 0.46852, chx_loss 0.86243, chxlacc 0.70842, chxlrocaucmic 0.79553, chxlrocaucmac 0.78196, gacc 0.96104, gloss 0.10738, 78.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21871, wmdcmp 0.17008, ema 0.66428, oracc 0.98301, qlmicf1 0.38463, qlmacf1 0.21801, chxlmicf1 0.52380, chxlmacf1 0.45627, chxlacc 0.69887, chxlrocaucmic 0.78977, chxlrocaucmac 0.74635, 19.88 secs\n",
      "Adjusting learning rate of group 0 to 1.4567e-04.\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000146) ...\n",
      "loss 1.71278, a_loss 1.37214, cD 1.07032, wmdcmp 0.14659, ema 0.66649, oracc 0.98358, orien_loss 0.02069, qlmicf1 0.37118, qlmacf1 0.22172, ql_loss 0.77085, chxlmicf1 0.51939, chxlmacf1 0.47396, chx_loss 0.85396, chxlacc 0.71558, chxlrocaucmic 0.80201, chxlrocaucmac 0.78765, gacc 0.95455, gloss 0.10779, 79.16 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27682, wmdcmp 0.17322, ema 0.66338, oracc 0.98207, qlmicf1 0.37329, qlmacf1 0.21761, chxlmicf1 0.53577, chxlmacf1 0.46038, chxlacc 0.71022, chxlrocaucmic 0.80281, chxlrocaucmac 0.75191, 19.84 secs\n",
      "Adjusting learning rate of group 0 to 1.3457e-04.\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000135) ...\n",
      "loss 4.65488, a_loss 1.37019, cD 1.09850, wmdcmp 0.15033, ema 0.67511, oracc 0.98230, orien_loss 0.01991, qlmicf1 0.36943, qlmacf1 0.22613, ql_loss 0.77040, chxlmicf1 0.52253, chxlmacf1 0.47782, chx_loss 0.84503, chxlacc 0.71832, chxlrocaucmic 0.80453, chxlrocaucmac 0.79170, gacc 0.95455, gloss 0.11558, 78.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25008, wmdcmp 0.17101, ema 0.67950, oracc 0.98443, qlmicf1 0.38452, qlmacf1 0.22428, chxlmicf1 0.52817, chxlmacf1 0.46292, chxlacc 0.70602, chxlrocaucmic 0.79743, chxlrocaucmac 0.75581, 20.65 secs\n",
      "Adjusting learning rate of group 0 to 1.2432e-04.\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000124) ...\n",
      "loss 1.17324, a_loss 1.33898, cD 1.12921, wmdcmp 0.15460, ema 0.67743, oracc 0.98267, orien_loss 0.01606, qlmicf1 0.37241, qlmacf1 0.22504, ql_loss 0.77375, chxlmicf1 0.52243, chxlmacf1 0.47744, chx_loss 0.84394, chxlacc 0.71737, chxlrocaucmic 0.80399, chxlrocaucmac 0.79116, gacc 0.95981, gloss 0.10414, 79.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26272, wmdcmp 0.17235, ema 0.67234, oracc 0.98301, qlmicf1 0.39236, qlmacf1 0.22997, chxlmicf1 0.53302, chxlmacf1 0.45779, chxlacc 0.70591, chxlrocaucmic 0.80022, chxlrocaucmac 0.74866, 20.08 secs\n",
      "Adjusting learning rate of group 0 to 1.1485e-04.\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000115) ...\n",
      "loss 4.65536, a_loss 1.35322, cD 1.10110, wmdcmp 0.15081, ema 0.68193, oracc 0.98152, orien_loss 0.01811, qlmicf1 0.37666, qlmacf1 0.22793, ql_loss 0.76301, chxlmicf1 0.52238, chxlmacf1 0.47813, chx_loss 0.84235, chxlacc 0.71848, chxlrocaucmic 0.80634, chxlrocaucmac 0.79408, gacc 0.95552, gloss 0.10915, 79.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27494, wmdcmp 0.17437, ema 0.68039, oracc 0.98396, qlmicf1 0.35974, qlmacf1 0.22037, chxlmicf1 0.52994, chxlmacf1 0.46671, chxlacc 0.70550, chxlrocaucmic 0.79266, chxlrocaucmac 0.75934, 20.01 secs\n",
      "Adjusting learning rate of group 0 to 1.0610e-04.\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 1.66490, a_loss 1.33817, cD 1.14778, wmdcmp 0.15679, ema 0.67725, oracc 0.98528, orien_loss 0.01500, qlmicf1 0.37613, qlmacf1 0.22920, ql_loss 0.75964, chxlmicf1 0.52599, chxlmacf1 0.48066, chx_loss 0.83754, chxlacc 0.72066, chxlrocaucmic 0.80880, chxlrocaucmac 0.79660, gacc 0.96753, gloss 0.09350, 79.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27787, wmdcmp 0.17524, ema 0.68308, oracc 0.98443, qlmicf1 0.37767, qlmacf1 0.22738, chxlmicf1 0.52837, chxlmacf1 0.46274, chxlacc 0.71579, chxlrocaucmic 0.79142, chxlrocaucmac 0.75774, 19.76 secs\n",
      "Adjusting learning rate of group 0 to 9.8019e-05.\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000098) ...\n",
      "loss 4.69359, a_loss 1.33997, cD 1.15715, wmdcmp 0.15640, ema 0.69535, oracc 0.98434, orien_loss 0.01370, qlmicf1 0.38270, qlmacf1 0.23939, ql_loss 0.75604, chxlmicf1 0.52893, chxlmacf1 0.48451, chx_loss 0.82692, chxlacc 0.72470, chxlrocaucmic 0.81217, chxlrocaucmac 0.80080, gacc 0.96104, gloss 0.10303, 79.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29656, wmdcmp 0.17757, ema 0.65801, oracc 0.98490, qlmicf1 0.36775, qlmacf1 0.23005, chxlmicf1 0.52887, chxlmacf1 0.46489, chxlacc 0.69644, chxlrocaucmic 0.79589, chxlrocaucmac 0.75616, 19.88 secs\n",
      "Adjusting learning rate of group 0 to 9.0552e-05.\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000091) ...\n",
      "loss 1.08188, a_loss 1.29118, cD 1.17472, wmdcmp 0.15849, ema 0.68898, oracc 0.98452, orien_loss 0.01581, qlmicf1 0.37725, qlmacf1 0.23623, ql_loss 0.75108, chxlmicf1 0.53426, chxlmacf1 0.48736, chx_loss 0.82078, chxlacc 0.72826, chxlrocaucmic 0.81545, chxlrocaucmac 0.80344, gacc 0.97097, gloss 0.08485, 79.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26165, wmdcmp 0.17396, ema 0.68577, oracc 0.98419, qlmicf1 0.40154, qlmacf1 0.23469, chxlmicf1 0.52746, chxlmacf1 0.46468, chxlacc 0.71425, chxlrocaucmic 0.78939, chxlrocaucmac 0.75814, 20.81 secs\n",
      "Adjusting learning rate of group 0 to 8.3653e-05.\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000084) ...\n",
      "loss 4.57791, a_loss 1.33693, cD 1.14841, wmdcmp 0.15600, ema 0.69632, oracc 0.98372, orien_loss 0.01608, qlmicf1 0.37846, qlmacf1 0.23065, ql_loss 0.75639, chxlmicf1 0.53080, chxlmacf1 0.48631, chx_loss 0.82359, chxlacc 0.72487, chxlrocaucmic 0.81327, chxlrocaucmac 0.80211, gacc 0.96948, gloss 0.08912, 79.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31076, wmdcmp 0.17838, ema 0.69203, oracc 0.98443, qlmicf1 0.38279, qlmacf1 0.22777, chxlmicf1 0.52658, chxlmacf1 0.46114, chxlacc 0.70904, chxlrocaucmic 0.79463, chxlrocaucmac 0.76052, 20.25 secs\n",
      "Adjusting learning rate of group 0 to 7.7280e-05.\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000077) ...\n",
      "loss 1.67648, a_loss 1.30022, cD 1.16322, wmdcmp 0.15880, ema 0.69489, oracc 0.98370, orien_loss 0.01682, qlmicf1 0.38691, qlmacf1 0.24086, ql_loss 0.74495, chxlmicf1 0.53768, chxlmacf1 0.49115, chx_loss 0.81444, chxlacc 0.73050, chxlrocaucmic 0.81727, chxlrocaucmac 0.80586, gacc 0.96331, gloss 0.10389, 79.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31520, wmdcmp 0.17907, ema 0.69651, oracc 0.98443, qlmicf1 0.36265, qlmacf1 0.22893, chxlmicf1 0.52825, chxlmacf1 0.46592, chxlacc 0.70346, chxlrocaucmic 0.79354, chxlrocaucmac 0.75940, 20.17 secs\n",
      "Adjusting learning rate of group 0 to 7.1393e-05.\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 4.30566, a_loss 1.31259, cD 1.19191, wmdcmp 0.16051, ema 0.69600, oracc 0.98440, orien_loss 0.01041, qlmicf1 0.38451, qlmacf1 0.24185, ql_loss 0.74839, chxlmicf1 0.54118, chxlmacf1 0.49484, chx_loss 0.80660, chxlacc 0.73448, chxlrocaucmic 0.82078, chxlrocaucmac 0.80992, gacc 0.97532, gloss 0.07288, 79.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28418, wmdcmp 0.17795, ema 0.68218, oracc 0.98537, qlmicf1 0.36843, qlmacf1 0.22827, chxlmicf1 0.52806, chxlmacf1 0.46832, chxlacc 0.70256, chxlrocaucmic 0.79419, chxlrocaucmac 0.75944, 20.12 secs\n",
      "Adjusting learning rate of group 0 to 6.5954e-05.\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000066) ...\n",
      "loss 1.08353, a_loss 1.29167, cD 1.18501, wmdcmp 0.16078, ema 0.69829, oracc 0.98310, orien_loss 0.01586, qlmicf1 0.38473, qlmacf1 0.24130, ql_loss 0.74453, chxlmicf1 0.53751, chxlmacf1 0.49150, chx_loss 0.80904, chxlacc 0.73358, chxlrocaucmic 0.82005, chxlrocaucmac 0.80959, gacc 0.97257, gloss 0.07177, 80.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25909, wmdcmp 0.17230, ema 0.70009, oracc 0.98490, qlmicf1 0.39042, qlmacf1 0.23006, chxlmicf1 0.53279, chxlmacf1 0.46165, chxlacc 0.71701, chxlrocaucmic 0.79994, chxlrocaucmac 0.75688, 20.30 secs\n",
      "Adjusting learning rate of group 0 to 6.0930e-05.\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.51625, a_loss 1.30409, cD 1.18385, wmdcmp 0.16042, ema 0.69784, oracc 0.98457, orien_loss 0.01445, qlmicf1 0.39523, qlmacf1 0.23699, ql_loss 0.73824, chxlmicf1 0.54344, chxlmacf1 0.49765, chx_loss 0.79957, chxlacc 0.73551, chxlrocaucmic 0.82304, chxlrocaucmac 0.81332, gacc 0.96721, gloss 0.08870, 79.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29117, wmdcmp 0.17593, ema 0.70367, oracc 0.98372, qlmicf1 0.37151, qlmacf1 0.22967, chxlmicf1 0.52644, chxlmacf1 0.46489, chxlacc 0.70947, chxlrocaucmic 0.79064, chxlrocaucmac 0.76472, 20.57 secs\n",
      "Adjusting learning rate of group 0 to 5.6288e-05.\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 1.69786, a_loss 1.29177, cD 1.17918, wmdcmp 0.16100, ema 0.70156, oracc 0.98440, orien_loss 0.01362, qlmicf1 0.39085, qlmacf1 0.24223, ql_loss 0.73828, chxlmicf1 0.54608, chxlmacf1 0.50000, chx_loss 0.79244, chxlacc 0.73825, chxlrocaucmic 0.82680, chxlrocaucmac 0.81642, gacc 0.96299, gloss 0.09272, 79.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27117, wmdcmp 0.17623, ema 0.68218, oracc 0.98419, qlmicf1 0.38011, qlmacf1 0.23488, chxlmicf1 0.53167, chxlmacf1 0.46492, chxlacc 0.71242, chxlrocaucmic 0.79723, chxlrocaucmac 0.75920, 20.38 secs\n",
      "Adjusting learning rate of group 0 to 5.2000e-05.\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.58085, a_loss 1.30759, cD 1.17029, wmdcmp 0.15914, ema 0.70054, oracc 0.98570, orien_loss 0.01020, qlmicf1 0.39140, qlmacf1 0.24755, ql_loss 0.73245, chxlmicf1 0.54291, chxlmacf1 0.49644, chx_loss 0.79780, chxlacc 0.73684, chxlrocaucmic 0.82396, chxlrocaucmac 0.81342, gacc 0.97695, gloss 0.05988, 79.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27189, wmdcmp 0.17618, ema 0.68935, oracc 0.98396, qlmicf1 0.38151, qlmacf1 0.23178, chxlmicf1 0.53907, chxlmacf1 0.46890, chxlacc 0.72072, chxlrocaucmic 0.80349, chxlrocaucmac 0.76173, 20.14 secs\n",
      "Adjusting learning rate of group 0 to 4.8038e-05.\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 1.14617, a_loss 1.27739, cD 1.21010, wmdcmp 0.16364, ema 0.70246, oracc 0.98331, orien_loss 0.01349, qlmicf1 0.39372, qlmacf1 0.24552, ql_loss 0.73642, chxlmicf1 0.54647, chxlmacf1 0.50066, chx_loss 0.79417, chxlacc 0.73895, chxlrocaucmic 0.82661, chxlrocaucmac 0.81654, gacc 0.97671, gloss 0.06485, 79.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34548, wmdcmp 0.18275, ema 0.69114, oracc 0.98467, qlmicf1 0.39182, qlmacf1 0.23607, chxlmicf1 0.53288, chxlmacf1 0.47138, chxlacc 0.70536, chxlrocaucmic 0.79897, chxlrocaucmac 0.76831, 19.98 secs\n",
      "Adjusting learning rate of group 0 to 4.4379e-05.\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 4.81624, a_loss 1.29187, cD 1.20580, wmdcmp 0.16389, ema 0.70455, oracc 0.98352, orien_loss 0.01607, qlmicf1 0.40195, qlmacf1 0.25153, ql_loss 0.72643, chxlmicf1 0.54864, chxlmacf1 0.50183, chx_loss 0.79126, chxlacc 0.74043, chxlrocaucmic 0.82784, chxlrocaucmac 0.81722, gacc 0.97175, gloss 0.07172, 79.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33948, wmdcmp 0.18284, ema 0.69919, oracc 0.98561, qlmicf1 0.39387, qlmacf1 0.23489, chxlmicf1 0.53091, chxlmacf1 0.46694, chxlacc 0.70371, chxlrocaucmic 0.79838, chxlrocaucmac 0.76201, 20.05 secs\n",
      "Adjusting learning rate of group 0 to 4.0998e-05.\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 1.51768, a_loss 1.28338, cD 1.21618, wmdcmp 0.16382, ema 0.71124, oracc 0.98571, orien_loss 0.01120, qlmicf1 0.39954, qlmacf1 0.25937, ql_loss 0.72661, chxlmicf1 0.54521, chxlmacf1 0.49911, chx_loss 0.78817, chxlacc 0.74006, chxlrocaucmic 0.82901, chxlrocaucmac 0.81922, gacc 0.97305, gloss 0.08498, 79.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33488, wmdcmp 0.18147, ema 0.70546, oracc 0.98514, qlmicf1 0.37927, qlmacf1 0.23362, chxlmicf1 0.54434, chxlmacf1 0.47662, chxlacc 0.72536, chxlrocaucmic 0.80418, chxlrocaucmac 0.76921, 20.77 secs\n",
      "Adjusting learning rate of group 0 to 3.7875e-05.\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 4.58750, a_loss 1.28854, cD 1.21854, wmdcmp 0.16531, ema 0.71071, oracc 0.98568, orien_loss 0.01094, qlmicf1 0.39557, qlmacf1 0.24684, ql_loss 0.72671, chxlmicf1 0.55543, chxlmacf1 0.50984, chx_loss 0.77785, chxlacc 0.74643, chxlrocaucmic 0.83282, chxlrocaucmac 0.82353, gacc 0.97305, gloss 0.07657, 79.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33710, wmdcmp 0.18324, ema 0.70009, oracc 0.98490, qlmicf1 0.39371, qlmacf1 0.23560, chxlmicf1 0.54170, chxlmacf1 0.47262, chxlacc 0.72238, chxlrocaucmic 0.80404, chxlrocaucmac 0.76439, 20.17 secs\n",
      "Adjusting learning rate of group 0 to 3.4989e-05.\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000035) ...\n",
      "loss 1.24280, a_loss 1.27350, cD 1.19679, wmdcmp 0.16281, ema 0.71476, oracc 0.98471, orien_loss 0.01257, qlmicf1 0.40578, qlmacf1 0.25118, ql_loss 0.72567, chxlmicf1 0.55163, chxlmacf1 0.50550, chx_loss 0.78018, chxlacc 0.74329, chxlrocaucmic 0.83264, chxlrocaucmac 0.82273, gacc 0.97257, gloss 0.07147, 79.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32766, wmdcmp 0.18145, ema 0.70009, oracc 0.98537, qlmicf1 0.39737, qlmacf1 0.23682, chxlmicf1 0.54605, chxlmacf1 0.47306, chxlacc 0.73185, chxlrocaucmic 0.80676, chxlrocaucmac 0.76598, 20.35 secs\n",
      "Adjusting learning rate of group 0 to 3.2324e-05.\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 4.38015, a_loss 1.28025, cD 1.22695, wmdcmp 0.16473, ema 0.71136, oracc 0.98631, orien_loss 0.01075, qlmicf1 0.40069, qlmacf1 0.25478, ql_loss 0.72488, chxlmicf1 0.55167, chxlmacf1 0.50518, chx_loss 0.77832, chxlacc 0.74476, chxlrocaucmic 0.83123, chxlrocaucmac 0.82180, gacc 0.96753, gloss 0.08115, 80.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29735, wmdcmp 0.17865, ema 0.69561, oracc 0.98561, qlmicf1 0.38904, qlmacf1 0.23596, chxlmicf1 0.54671, chxlmacf1 0.47472, chxlacc 0.72374, chxlrocaucmic 0.80815, chxlrocaucmac 0.76422, 20.02 secs\n",
      "Adjusting learning rate of group 0 to 2.9861e-05.\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 1.54537, a_loss 1.27395, cD 1.22691, wmdcmp 0.16572, ema 0.70672, oracc 0.98119, orien_loss 0.01392, qlmicf1 0.40600, qlmacf1 0.24590, ql_loss 0.72063, chxlmicf1 0.55430, chxlmacf1 0.50853, chx_loss 0.77440, chxlacc 0.74755, chxlrocaucmic 0.83384, chxlrocaucmac 0.82442, gacc 0.97695, gloss 0.06571, 79.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31414, wmdcmp 0.17983, ema 0.69561, oracc 0.98514, qlmicf1 0.37829, qlmacf1 0.23265, chxlmicf1 0.54086, chxlmacf1 0.47580, chxlacc 0.71693, chxlrocaucmic 0.80596, chxlrocaucmac 0.76849, 20.39 secs\n",
      "Adjusting learning rate of group 0 to 2.7586e-05.\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 4.43522, a_loss 1.28361, cD 1.21660, wmdcmp 0.16398, ema 0.71223, oracc 0.98353, orien_loss 0.01365, qlmicf1 0.40445, qlmacf1 0.24934, ql_loss 0.72377, chxlmicf1 0.55349, chxlmacf1 0.50768, chx_loss 0.77418, chxlacc 0.74556, chxlrocaucmic 0.83268, chxlrocaucmac 0.82350, gacc 0.97532, gloss 0.07315, 79.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34416, wmdcmp 0.18396, ema 0.69919, oracc 0.98514, qlmicf1 0.38711, qlmacf1 0.23706, chxlmicf1 0.54295, chxlmacf1 0.47313, chxlacc 0.72593, chxlrocaucmic 0.80678, chxlrocaucmac 0.76891, 20.34 secs\n",
      "Adjusting learning rate of group 0 to 2.5485e-05.\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 1.00327, a_loss 1.26866, cD 1.19826, wmdcmp 0.16337, ema 0.72128, oracc 0.98386, orien_loss 0.01417, qlmicf1 0.40766, qlmacf1 0.25189, ql_loss 0.71866, chxlmicf1 0.55820, chxlmacf1 0.51220, chx_loss 0.76780, chxlacc 0.74860, chxlrocaucmic 0.83582, chxlrocaucmac 0.82733, gacc 0.97735, gloss 0.06261, 79.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32753, wmdcmp 0.18191, ema 0.69651, oracc 0.98467, qlmicf1 0.38523, qlmacf1 0.23789, chxlmicf1 0.53799, chxlmacf1 0.47587, chxlacc 0.71690, chxlrocaucmic 0.80049, chxlrocaucmac 0.77107, 20.16 secs\n",
      "Adjusting learning rate of group 0 to 2.3543e-05.\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 4.37165, a_loss 1.26197, cD 1.25687, wmdcmp 0.17085, ema 0.71580, oracc 0.98594, orien_loss 0.01107, qlmicf1 0.40819, qlmacf1 0.25969, ql_loss 0.71741, chxlmicf1 0.55662, chxlmacf1 0.50999, chx_loss 0.76910, chxlacc 0.74687, chxlrocaucmic 0.83587, chxlrocaucmac 0.82696, gacc 0.98084, gloss 0.06203, 79.99 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.34600, wmdcmp 0.18442, ema 0.69382, oracc 0.98585, qlmicf1 0.38293, qlmacf1 0.23573, chxlmicf1 0.53433, chxlmacf1 0.47703, chxlacc 0.70575, chxlrocaucmic 0.79862, chxlrocaucmac 0.77318, 20.28 secs\n",
      "Adjusting learning rate of group 0 to 2.1750e-05.\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.63954, a_loss 1.26770, cD 1.22408, wmdcmp 0.16659, ema 0.71791, oracc 0.98544, orien_loss 0.01075, qlmicf1 0.40798, qlmacf1 0.25545, ql_loss 0.72016, chxlmicf1 0.55982, chxlmacf1 0.51307, chx_loss 0.76593, chxlacc 0.75021, chxlrocaucmic 0.83771, chxlrocaucmac 0.82938, gacc 0.97565, gloss 0.07268, 79.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29821, wmdcmp 0.17932, ema 0.68577, oracc 0.98537, qlmicf1 0.38302, qlmacf1 0.23389, chxlmicf1 0.54172, chxlmacf1 0.47659, chxlacc 0.71479, chxlrocaucmic 0.80605, chxlrocaucmac 0.76995, 20.23 secs\n",
      "Adjusting learning rate of group 0 to 2.0093e-05.\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 4.33828, a_loss 1.26716, cD 1.25599, wmdcmp 0.17054, ema 0.72543, oracc 0.98156, orien_loss 0.01519, qlmicf1 0.40746, qlmacf1 0.26213, ql_loss 0.71935, chxlmicf1 0.56024, chxlmacf1 0.51516, chx_loss 0.76197, chxlacc 0.75106, chxlrocaucmic 0.83818, chxlrocaucmac 0.83060, gacc 0.98312, gloss 0.05322, 79.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32653, wmdcmp 0.18198, ema 0.69024, oracc 0.98514, qlmicf1 0.38782, qlmacf1 0.23441, chxlmicf1 0.54518, chxlmacf1 0.47393, chxlacc 0.72369, chxlrocaucmic 0.80598, chxlrocaucmac 0.76669, 20.81 secs\n",
      "Adjusting learning rate of group 0 to 1.8562e-05.\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.21169, a_loss 1.25395, cD 1.24753, wmdcmp 0.16926, ema 0.71465, oracc 0.98458, orien_loss 0.01352, qlmicf1 0.40654, qlmacf1 0.26102, ql_loss 0.71419, chxlmicf1 0.55728, chxlmacf1 0.51043, chx_loss 0.76944, chxlacc 0.75073, chxlrocaucmic 0.83617, chxlrocaucmac 0.82692, gacc 0.97703, gloss 0.06753, 79.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34130, wmdcmp 0.18333, ema 0.69472, oracc 0.98490, qlmicf1 0.38535, qlmacf1 0.23926, chxlmicf1 0.53939, chxlmacf1 0.47407, chxlacc 0.71706, chxlrocaucmic 0.80333, chxlrocaucmac 0.76879, 20.00 secs\n",
      "Adjusting learning rate of group 0 to 1.7148e-05.\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 4.37058, a_loss 1.27354, cD 1.21981, wmdcmp 0.16520, ema 0.71948, oracc 0.98502, orien_loss 0.01301, qlmicf1 0.40829, qlmacf1 0.25554, ql_loss 0.71343, chxlmicf1 0.56371, chxlmacf1 0.51777, chx_loss 0.75643, chxlacc 0.75339, chxlrocaucmic 0.84062, chxlrocaucmac 0.83262, gacc 0.97792, gloss 0.06017, 79.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31735, wmdcmp 0.18118, ema 0.69293, oracc 0.98467, qlmicf1 0.39881, qlmacf1 0.23918, chxlmicf1 0.54376, chxlmacf1 0.47420, chxlacc 0.72598, chxlrocaucmic 0.80463, chxlrocaucmac 0.76867, 20.22 secs\n",
      "Adjusting learning rate of group 0 to 1.5842e-05.\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 1.67808, a_loss 1.26606, cD 1.23827, wmdcmp 0.16753, ema 0.71824, oracc 0.98325, orien_loss 0.01354, qlmicf1 0.41375, qlmacf1 0.26529, ql_loss 0.70888, chxlmicf1 0.56061, chxlmacf1 0.51476, chx_loss 0.75974, chxlacc 0.75349, chxlrocaucmic 0.83938, chxlrocaucmac 0.83143, gacc 0.97305, gloss 0.07218, 79.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30145, wmdcmp 0.17890, ema 0.68577, oracc 0.98467, qlmicf1 0.39308, qlmacf1 0.23781, chxlmicf1 0.54201, chxlmacf1 0.47511, chxlacc 0.71520, chxlrocaucmic 0.80605, chxlrocaucmac 0.76762, 19.90 secs\n",
      "Adjusting learning rate of group 0 to 1.4635e-05.\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 4.14233, a_loss 1.26657, cD 1.24215, wmdcmp 0.16836, ema 0.72738, oracc 0.98555, orien_loss 0.01015, qlmicf1 0.41104, qlmacf1 0.25830, ql_loss 0.71285, chxlmicf1 0.56526, chxlmacf1 0.51997, chx_loss 0.75428, chxlacc 0.75315, chxlrocaucmic 0.83894, chxlrocaucmac 0.83198, gacc 0.97630, gloss 0.05965, 80.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32970, wmdcmp 0.18063, ema 0.69472, oracc 0.98467, qlmicf1 0.39625, qlmacf1 0.23700, chxlmicf1 0.54392, chxlmacf1 0.47683, chxlacc 0.72100, chxlrocaucmic 0.80709, chxlrocaucmac 0.76982, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 1.3520e-05.\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.01129, a_loss 1.25984, cD 1.23867, wmdcmp 0.16716, ema 0.71786, oracc 0.98340, orien_loss 0.01128, qlmicf1 0.40843, qlmacf1 0.25942, ql_loss 0.71369, chxlmicf1 0.56361, chxlmacf1 0.51676, chx_loss 0.75706, chxlacc 0.75311, chxlrocaucmic 0.83942, chxlrocaucmac 0.83074, gacc 0.97735, gloss 0.06486, 79.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38337, wmdcmp 0.18708, ema 0.70636, oracc 0.98514, qlmicf1 0.39755, qlmacf1 0.23767, chxlmicf1 0.54626, chxlmacf1 0.47355, chxlacc 0.72921, chxlrocaucmic 0.80795, chxlrocaucmac 0.76803, 20.64 secs\n",
      "Adjusting learning rate of group 0 to 1.2490e-05.\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 4.51764, a_loss 1.26718, cD 1.23649, wmdcmp 0.16841, ema 0.72002, oracc 0.98481, orien_loss 0.01344, qlmicf1 0.40772, qlmacf1 0.25862, ql_loss 0.71203, chxlmicf1 0.56138, chxlmacf1 0.51543, chx_loss 0.76075, chxlacc 0.75342, chxlrocaucmic 0.84017, chxlrocaucmac 0.83205, gacc 0.98506, gloss 0.04394, 79.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33649, wmdcmp 0.18206, ema 0.70098, oracc 0.98443, qlmicf1 0.39275, qlmacf1 0.23947, chxlmicf1 0.54401, chxlmacf1 0.47829, chxlacc 0.72294, chxlrocaucmic 0.80668, chxlrocaucmac 0.77274, 20.58 secs\n",
      "Adjusting learning rate of group 0 to 1.1538e-05.\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.64783, a_loss 1.25634, cD 1.25942, wmdcmp 0.16909, ema 0.72082, oracc 0.98380, orien_loss 0.01269, qlmicf1 0.41338, qlmacf1 0.26155, ql_loss 0.71116, chxlmicf1 0.56291, chxlmacf1 0.51706, chx_loss 0.75324, chxlacc 0.75437, chxlrocaucmic 0.84126, chxlrocaucmac 0.83260, gacc 0.97500, gloss 0.06888, 80.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35510, wmdcmp 0.18476, ema 0.69561, oracc 0.98514, qlmicf1 0.39798, qlmacf1 0.23840, chxlmicf1 0.54598, chxlmacf1 0.47785, chxlacc 0.72558, chxlrocaucmic 0.80799, chxlrocaucmac 0.77145, 20.35 secs\n",
      "Adjusting learning rate of group 0 to 1.0659e-05.\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 4.20901, a_loss 1.26889, cD 1.23723, wmdcmp 0.16733, ema 0.72338, oracc 0.98482, orien_loss 0.00859, qlmicf1 0.41513, qlmacf1 0.25483, ql_loss 0.70517, chxlmicf1 0.56476, chxlmacf1 0.51824, chx_loss 0.75462, chxlacc 0.75614, chxlrocaucmic 0.84156, chxlrocaucmac 0.83298, gacc 0.97987, gloss 0.05587, 80.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31401, wmdcmp 0.18033, ema 0.69024, oracc 0.98514, qlmicf1 0.40373, qlmacf1 0.23997, chxlmicf1 0.54433, chxlmacf1 0.47399, chxlacc 0.72379, chxlrocaucmic 0.80844, chxlrocaucmac 0.77149, 20.13 secs\n",
      "Adjusting learning rate of group 0 to 9.8474e-06.\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.94824, a_loss 1.25394, cD 1.24381, wmdcmp 0.16878, ema 0.72118, oracc 0.98483, orien_loss 0.01221, qlmicf1 0.41220, qlmacf1 0.25972, ql_loss 0.70545, chxlmicf1 0.56269, chxlmacf1 0.51753, chx_loss 0.75413, chxlacc 0.75416, chxlrocaucmic 0.84066, chxlrocaucmac 0.83289, gacc 0.97927, gloss 0.06212, 80.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33475, wmdcmp 0.18288, ema 0.69561, oracc 0.98514, qlmicf1 0.39615, qlmacf1 0.23895, chxlmicf1 0.54380, chxlmacf1 0.47347, chxlacc 0.72256, chxlrocaucmic 0.80838, chxlrocaucmac 0.76862, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 9.0972e-06.\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.31086, a_loss 1.26349, cD 1.23493, wmdcmp 0.16719, ema 0.72327, oracc 0.98434, orien_loss 0.01095, qlmicf1 0.41599, qlmacf1 0.26626, ql_loss 0.70368, chxlmicf1 0.56879, chxlmacf1 0.52141, chx_loss 0.74689, chxlacc 0.75754, chxlrocaucmic 0.84483, chxlrocaucmac 0.83657, gacc 0.98474, gloss 0.04722, 80.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31425, wmdcmp 0.18054, ema 0.69382, oracc 0.98490, qlmicf1 0.39588, qlmacf1 0.23888, chxlmicf1 0.54650, chxlmacf1 0.47850, chxlacc 0.72129, chxlrocaucmic 0.80904, chxlrocaucmac 0.76983, 20.32 secs\n",
      "Adjusting learning rate of group 0 to 8.4042e-06.\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.58870, a_loss 1.25315, cD 1.22828, wmdcmp 0.16755, ema 0.72512, oracc 0.98472, orien_loss 0.01115, qlmicf1 0.41162, qlmacf1 0.26155, ql_loss 0.70736, chxlmicf1 0.56930, chxlmacf1 0.52204, chx_loss 0.74516, chxlacc 0.75666, chxlrocaucmic 0.84459, chxlrocaucmac 0.83633, gacc 0.98084, gloss 0.05469, 80.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31938, wmdcmp 0.18088, ema 0.70457, oracc 0.98490, qlmicf1 0.40411, qlmacf1 0.24052, chxlmicf1 0.54827, chxlmacf1 0.47915, chxlacc 0.72591, chxlrocaucmic 0.80951, chxlrocaucmac 0.77122, 20.20 secs\n",
      "Adjusting learning rate of group 0 to 7.7639e-06.\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 4.24787, a_loss 1.26663, cD 1.23701, wmdcmp 0.16711, ema 0.73041, oracc 0.98421, orien_loss 0.01219, qlmicf1 0.41441, qlmacf1 0.26496, ql_loss 0.70623, chxlmicf1 0.56651, chxlmacf1 0.52054, chx_loss 0.74749, chxlacc 0.75650, chxlrocaucmic 0.84306, chxlrocaucmac 0.83435, gacc 0.98182, gloss 0.05217, 80.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33997, wmdcmp 0.18424, ema 0.70367, oracc 0.98537, qlmicf1 0.39144, qlmacf1 0.23898, chxlmicf1 0.54590, chxlmacf1 0.47710, chxlacc 0.72522, chxlrocaucmic 0.80759, chxlrocaucmac 0.76993, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 7.1725e-06.\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.04743, a_loss 1.24121, cD 1.22535, wmdcmp 0.16713, ema 0.71936, oracc 0.98473, orien_loss 0.01078, qlmicf1 0.41150, qlmacf1 0.26166, ql_loss 0.70562, chxlmicf1 0.56781, chxlmacf1 0.52103, chx_loss 0.74632, chxlacc 0.75630, chxlrocaucmic 0.84450, chxlrocaucmac 0.83661, gacc 0.97895, gloss 0.05679, 79.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33055, wmdcmp 0.18157, ema 0.69114, oracc 0.98561, qlmicf1 0.39563, qlmacf1 0.23884, chxlmicf1 0.54224, chxlmacf1 0.47557, chxlacc 0.71842, chxlrocaucmic 0.80642, chxlrocaucmac 0.77074, 20.20 secs\n",
      "Adjusting learning rate of group 0 to 6.6261e-06.\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.40924, a_loss 1.26687, cD 1.23835, wmdcmp 0.16827, ema 0.72305, oracc 0.98388, orien_loss 0.01239, qlmicf1 0.41269, qlmacf1 0.26188, ql_loss 0.70769, chxlmicf1 0.56659, chxlmacf1 0.52208, chx_loss 0.74465, chxlacc 0.75610, chxlrocaucmic 0.84332, chxlrocaucmac 0.83676, gacc 0.98312, gloss 0.05333, 80.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33281, wmdcmp 0.18223, ema 0.69651, oracc 0.98467, qlmicf1 0.40199, qlmacf1 0.24009, chxlmicf1 0.54741, chxlmacf1 0.47569, chxlacc 0.72490, chxlrocaucmic 0.81164, chxlrocaucmac 0.76846, 20.86 secs\n",
      "Adjusting learning rate of group 0 to 6.1213e-06.\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.51153, a_loss 1.25284, cD 1.24584, wmdcmp 0.16831, ema 0.71996, oracc 0.98180, orien_loss 0.01110, qlmicf1 0.41724, qlmacf1 0.26048, ql_loss 0.70034, chxlmicf1 0.56675, chxlmacf1 0.51901, chx_loss 0.74759, chxlacc 0.75617, chxlrocaucmic 0.84497, chxlrocaucmac 0.83624, gacc 0.98117, gloss 0.05086, 80.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32354, wmdcmp 0.18162, ema 0.70994, oracc 0.98537, qlmicf1 0.39683, qlmacf1 0.23768, chxlmicf1 0.54374, chxlmacf1 0.47513, chxlacc 0.72101, chxlrocaucmic 0.80895, chxlrocaucmac 0.76901, 20.33 secs\n",
      "Adjusting learning rate of group 0 to 5.6549e-06.\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.19105, a_loss 1.26631, cD 1.24978, wmdcmp 0.16801, ema 0.72273, oracc 0.98481, orien_loss 0.01091, qlmicf1 0.42332, qlmacf1 0.26694, ql_loss 0.70375, chxlmicf1 0.56457, chxlmacf1 0.51832, chx_loss 0.75698, chxlacc 0.75497, chxlrocaucmic 0.84102, chxlrocaucmac 0.83443, gacc 0.97597, gloss 0.06286, 80.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35316, wmdcmp 0.18517, ema 0.70457, oracc 0.98514, qlmicf1 0.40244, qlmacf1 0.23911, chxlmicf1 0.54675, chxlmacf1 0.47666, chxlacc 0.72514, chxlrocaucmic 0.81036, chxlrocaucmac 0.77121, 20.26 secs\n",
      "Adjusting learning rate of group 0 to 5.2241e-06.\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.18961, a_loss 1.24340, cD 1.23511, wmdcmp 0.16641, ema 0.72599, oracc 0.98448, orien_loss 0.01094, qlmicf1 0.41808, qlmacf1 0.26380, ql_loss 0.69806, chxlmicf1 0.56675, chxlmacf1 0.52100, chx_loss 0.74810, chxlacc 0.75763, chxlrocaucmic 0.84473, chxlrocaucmac 0.83634, gacc 0.97512, gloss 0.06394, 79.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33598, wmdcmp 0.18240, ema 0.69561, oracc 0.98561, qlmicf1 0.40217, qlmacf1 0.24079, chxlmicf1 0.54520, chxlmacf1 0.47395, chxlacc 0.72495, chxlrocaucmic 0.80841, chxlrocaucmac 0.76628, 20.28 secs\n",
      "Adjusting learning rate of group 0 to 4.8262e-06.\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.60152, a_loss 1.25928, cD 1.24950, wmdcmp 0.16837, ema 0.72446, oracc 0.98558, orien_loss 0.00820, qlmicf1 0.41542, qlmacf1 0.25913, ql_loss 0.70629, chxlmicf1 0.56971, chxlmacf1 0.52181, chx_loss 0.74580, chxlacc 0.75789, chxlrocaucmic 0.84563, chxlrocaucmac 0.83639, gacc 0.97630, gloss 0.06871, 80.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32117, wmdcmp 0.18134, ema 0.69561, oracc 0.98537, qlmicf1 0.39606, qlmacf1 0.23983, chxlmicf1 0.54454, chxlmacf1 0.47610, chxlacc 0.72426, chxlrocaucmic 0.80786, chxlrocaucmac 0.77039, 20.47 secs\n",
      "Adjusting learning rate of group 0 to 4.4585e-06.\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.59853, a_loss 1.25773, cD 1.24513, wmdcmp 0.16931, ema 0.71770, oracc 0.98435, orien_loss 0.01384, qlmicf1 0.41127, qlmacf1 0.26378, ql_loss 0.70501, chxlmicf1 0.56554, chxlmacf1 0.51938, chx_loss 0.74916, chxlacc 0.75722, chxlrocaucmic 0.84323, chxlrocaucmac 0.83568, gacc 0.98019, gloss 0.05252, 79.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33299, wmdcmp 0.18350, ema 0.69203, oracc 0.98514, qlmicf1 0.40564, qlmacf1 0.24026, chxlmicf1 0.54466, chxlmacf1 0.47461, chxlacc 0.72459, chxlrocaucmic 0.80816, chxlrocaucmac 0.76962, 20.16 secs\n",
      "Adjusting learning rate of group 0 to 4.1188e-06.\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.07980, a_loss 1.26055, cD 1.24386, wmdcmp 0.16810, ema 0.71331, oracc 0.98582, orien_loss 0.01096, qlmicf1 0.42237, qlmacf1 0.25927, ql_loss 0.70095, chxlmicf1 0.56468, chxlmacf1 0.51871, chx_loss 0.75040, chxlacc 0.75613, chxlrocaucmic 0.84325, chxlrocaucmac 0.83494, gacc 0.98409, gloss 0.05162, 79.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34682, wmdcmp 0.18383, ema 0.71083, oracc 0.98490, qlmicf1 0.39858, qlmacf1 0.23869, chxlmicf1 0.54284, chxlmacf1 0.47517, chxlacc 0.72180, chxlrocaucmic 0.80724, chxlrocaucmac 0.77091, 20.12 secs\n",
      "Adjusting learning rate of group 0 to 3.8051e-06.\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.07645, a_loss 1.24090, cD 1.25512, wmdcmp 0.16860, ema 0.72481, oracc 0.98521, orien_loss 0.00954, qlmicf1 0.41709, qlmacf1 0.25804, ql_loss 0.69967, chxlmicf1 0.56947, chxlmacf1 0.52376, chx_loss 0.74508, chxlacc 0.75830, chxlrocaucmic 0.84502, chxlrocaucmac 0.83742, gacc 0.97959, gloss 0.05109, 79.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34525, wmdcmp 0.18396, ema 0.70904, oracc 0.98561, qlmicf1 0.39803, qlmacf1 0.23991, chxlmicf1 0.54964, chxlmacf1 0.47706, chxlacc 0.72932, chxlrocaucmic 0.81078, chxlrocaucmac 0.77039, 20.19 secs\n",
      "Adjusting learning rate of group 0 to 3.5152e-06.\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.42296, a_loss 1.26777, cD 1.26481, wmdcmp 0.17129, ema 0.72792, oracc 0.98347, orien_loss 0.01184, qlmicf1 0.41614, qlmacf1 0.26935, ql_loss 0.70381, chxlmicf1 0.56885, chxlmacf1 0.52275, chx_loss 0.74434, chxlacc 0.75803, chxlrocaucmic 0.84454, chxlrocaucmac 0.83699, gacc 0.98149, gloss 0.04936, 79.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34300, wmdcmp 0.18299, ema 0.69651, oracc 0.98537, qlmicf1 0.39715, qlmacf1 0.23942, chxlmicf1 0.54376, chxlmacf1 0.47495, chxlacc 0.72323, chxlrocaucmic 0.80846, chxlrocaucmac 0.77015, 20.33 secs\n",
      "Adjusting learning rate of group 0 to 3.2474e-06.\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.60990, a_loss 1.26346, cD 1.23528, wmdcmp 0.16673, ema 0.72770, oracc 0.98233, orien_loss 0.01184, qlmicf1 0.41729, qlmacf1 0.26731, ql_loss 0.70066, chxlmicf1 0.56493, chxlmacf1 0.51983, chx_loss 0.74730, chxlacc 0.75652, chxlrocaucmic 0.84346, chxlrocaucmac 0.83578, gacc 0.98149, gloss 0.05396, 79.63 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.33214, wmdcmp 0.18285, ema 0.70367, oracc 0.98561, qlmicf1 0.39879, qlmacf1 0.23821, chxlmicf1 0.54856, chxlmacf1 0.47871, chxlacc 0.72709, chxlrocaucmic 0.81053, chxlrocaucmac 0.77151, 20.83 secs\n",
      "Adjusting learning rate of group 0 to 3.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 55 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,2e-4,53,3e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.6 \\\n",
    "        --cxr14-weight 0 \\\n",
    "        --vinbig-weight 0 \\\n",
    "        --padchest-weight 0 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"facebook/vit-mae-base\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
