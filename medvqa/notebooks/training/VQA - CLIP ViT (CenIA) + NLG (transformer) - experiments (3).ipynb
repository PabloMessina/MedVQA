{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/vte-vit-base-patch16-bio-clinical-bert-finetuned-v3\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,4e-4,76,5e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 6\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-bp16bcbf-v3+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 11.78733, a_loss 8.24992, cD 0.00106, wmdcmp 0.00249, oracc 0.58420, orien_loss 0.99865, chxlmicf1 0.15288, chxlmacf1 0.23574, chx_loss 1.09987, chxlacc 0.46648, chxlrocaucmic 0.43868, chxlrocaucmac 0.50414, qlmicf1 0.12614, qlmacf1 0.11721, ql_loss 1.07764, gacc 0.56750, gloss 0.68183, cxr14micf1 0.06921, cxr14macf1 0.13049, cxr14_loss 1.24712, vnbgmicf1 0.13501, vnbgmacf1 0.18059, vnbg_loss 9.25303, ema 0.00000, 162.86 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.00893, wmdcmp 0.00941, oracc 0.65911, chxlmicf1 0.17342, chxlmacf1 0.25149, chxlacc 0.46663, chxlrocaucmic 0.43648, chxlrocaucmac 0.49663, qlmicf1 0.15156, qlmacf1 0.13984, ema 0.00000, 81.25 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 11.56918, a_loss 7.06418, cD 0.01521, wmdcmp 0.00395, oracc 0.64856, orien_loss 0.93060, chxlmicf1 0.21642, chxlmacf1 0.28752, chx_loss 1.08867, chxlacc 0.50325, chxlrocaucmic 0.50338, chxlrocaucmac 0.55547, qlmicf1 0.15748, qlmacf1 0.12995, ql_loss 1.06232, gacc 0.57830, gloss 0.67841, cxr14micf1 0.07306, cxr14macf1 0.14312, cxr14_loss 1.24293, vnbgmicf1 0.14004, vnbgmacf1 0.18961, vnbg_loss 7.75344, ema 0.01333, 137.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, oracc 0.70713, chxlmicf1 0.26933, chxlmacf1 0.32331, chxlacc 0.52676, chxlrocaucmic 0.52998, chxlrocaucmac 0.56974, qlmicf1 0.20508, qlmacf1 0.15813, ema 0.03636, 142.81 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 10.49356, a_loss 4.84404, cD 0.04837, wmdcmp 0.01035, oracc 0.75002, orien_loss 0.72993, chxlmicf1 0.41432, chxlmacf1 0.38964, chx_loss 1.04605, chxlacc 0.60229, chxlrocaucmic 0.68373, chxlrocaucmac 0.67538, qlmicf1 0.27869, qlmacf1 0.16243, ql_loss 1.01364, gacc 0.58341, gloss 0.67233, cxr14micf1 0.13908, cxr14macf1 0.20565, cxr14_loss 1.21537, vnbgmicf1 0.24549, vnbgmacf1 0.26043, vnbg_loss 5.18259, ema 0.00407, 172.39 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.28379, wmdcmp 0.04475, oracc 0.80301, chxlmicf1 0.46727, chxlmacf1 0.42590, chxlacc 0.62572, chxlrocaucmic 0.70775, chxlrocaucmac 0.68870, qlmicf1 0.34231, qlmacf1 0.18998, ema 0.03455, 116.99 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-05.\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 8.55122, a_loss 2.73463, cD 0.10826, wmdcmp 0.02268, oracc 0.86385, orien_loss 0.43396, chxlmicf1 0.48757, chxlmacf1 0.44577, chx_loss 0.96725, chxlacc 0.66724, chxlrocaucmic 0.76928, chxlrocaucmac 0.74464, qlmicf1 0.35743, qlmacf1 0.18840, ql_loss 0.93632, gacc 0.63500, gloss 0.63844, cxr14micf1 0.27199, cxr14macf1 0.28212, cxr14_loss 1.13934, vnbgmicf1 0.50786, vnbgmacf1 0.35795, vnbg_loss 2.99500, ema 0.18560, 216.78 secs\n",
      "(2) Validation stage ...\n",
      "loss 7.27701, a_loss 1.57763, cD 0.40198, wmdcmp 0.06257, oracc 0.91957, orien_loss 0.22270, chxlmicf1 0.50814, chxlmacf1 0.46266, chx_loss 0.91069, chxlacc 0.69420, chxlrocaucmic 0.78631, chxlrocaucmac 0.76394, qlmicf1 0.36065, qlmacf1 0.20895, ql_loss 0.87175, gacc 0.71773, gloss 0.58130, cxr14micf1 0.31386, cxr14macf1 0.31150, cxr14_loss 1.03945, vnbgmicf1 0.53393, vnbgmacf1 0.39469, vnbg_loss 1.26512, ema 0.54880, 197.76 secs\n",
      "(2) Validation stage ...\n",
      "loss 5.82769, a_loss 1.25885, cD 0.73098, wmdcmp 0.10533, oracc 0.94785, orien_loss 0.14474, chxlmicf1 0.50905, chxlmacf1 0.46347, chx_loss 0.90235, chxlacc 0.69865, chxlrocaucmic 0.78772, chxlrocaucmac 0.76554, qlmicf1 0.35683, qlmacf1 0.21205, ql_loss 0.85325, gacc 0.76852, gloss 0.51900, cxr14micf1 0.32612, cxr14macf1 0.32155, cxr14_loss 1.00053, vnbgmicf1 0.53428, vnbgmacf1 0.40128, vnbg_loss 0.95308, ema 0.63620, 181.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.94247, wmdcmp 0.14232, oracc 0.95407, chxlmicf1 0.51527, chxlmacf1 0.46597, chxlacc 0.68511, chxlrocaucmic 0.76176, chxlrocaucmac 0.74054, qlmicf1 0.36122, qlmacf1 0.24201, ema 0.60455, 126.36 secs\n",
      "Adjusting learning rate of group 0 to 3.5643e-04.\n",
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000356) ...\n",
      "loss 5.22928, a_loss 1.15811, cD 0.89841, wmdcmp 0.12592, oracc 0.95674, orien_loss 0.11761, chxlmicf1 0.51359, chxlmacf1 0.46698, chx_loss 0.89378, chxlacc 0.70261, chxlrocaucmic 0.79225, chxlrocaucmac 0.77076, qlmicf1 0.35986, qlmacf1 0.21353, ql_loss 0.83913, gacc 0.78341, gloss 0.49039, cxr14micf1 0.33356, cxr14macf1 0.32964, cxr14_loss 0.97769, vnbgmicf1 0.54633, vnbgmacf1 0.40796, vnbg_loss 0.87696, ema 0.65310, 246.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00142, wmdcmp 0.14872, oracc 0.95571, chxlmicf1 0.51285, chxlmacf1 0.46109, chxlacc 0.68894, chxlrocaucmic 0.76262, chxlrocaucmac 0.74042, qlmicf1 0.36151, qlmacf1 0.24375, ema 0.62727, 144.29 secs\n",
      "Adjusting learning rate of group 0 to 3.3646e-04.\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000336) ...\n",
      "loss 4.96118, a_loss 1.09888, cD 1.00257, wmdcmp 0.13870, oracc 0.96114, orien_loss 0.09831, chxlmicf1 0.51495, chxlmacf1 0.46866, chx_loss 0.88969, chxlacc 0.70488, chxlrocaucmic 0.79324, chxlrocaucmac 0.77321, qlmicf1 0.36319, qlmacf1 0.21595, ql_loss 0.83599, gacc 0.79898, gloss 0.47130, cxr14micf1 0.32928, cxr14macf1 0.32957, cxr14_loss 0.97251, vnbgmicf1 0.54454, vnbgmacf1 0.41271, vnbg_loss 0.84175, ema 0.66685, 261.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.94746, wmdcmp 0.14865, oracc 0.95840, chxlmicf1 0.52016, chxlmacf1 0.46735, chxlacc 0.69028, chxlrocaucmic 0.76823, chxlrocaucmac 0.74298, qlmicf1 0.36565, qlmacf1 0.24881, ema 0.66727, 144.05 secs\n",
      "Adjusting learning rate of group 0 to 3.1761e-04.\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000318) ...\n",
      "loss 5.43594, a_loss 1.05453, cD 1.09060, wmdcmp 0.15009, oracc 0.96433, orien_loss 0.09022, chxlmicf1 0.51843, chxlmacf1 0.47080, chx_loss 0.88846, chxlacc 0.70624, chxlrocaucmic 0.79497, chxlrocaucmac 0.77489, qlmicf1 0.36419, qlmacf1 0.21887, ql_loss 0.82749, gacc 0.80557, gloss 0.45193, cxr14micf1 0.33891, cxr14macf1 0.33085, cxr14_loss 0.96705, vnbgmicf1 0.54997, vnbgmacf1 0.42205, vnbg_loss 0.80957, ema 0.68190, 360.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.02591, wmdcmp 0.15192, oracc 0.96525, chxlmicf1 0.51126, chxlmacf1 0.46431, chxlacc 0.68214, chxlrocaucmic 0.75966, chxlrocaucmac 0.74469, qlmicf1 0.36480, qlmacf1 0.24591, ema 0.63273, 188.72 secs\n",
      "Adjusting learning rate of group 0 to 2.9982e-04.\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 4.61274, a_loss 1.02797, cD 1.15117, wmdcmp 0.15618, oracc 0.96706, orien_loss 0.08018, chxlmicf1 0.51720, chxlmacf1 0.47042, chx_loss 0.88511, chxlacc 0.70479, chxlrocaucmic 0.79404, chxlrocaucmac 0.77359, qlmicf1 0.36120, qlmacf1 0.21752, ql_loss 0.82596, gacc 0.81841, gloss 0.43593, cxr14micf1 0.33656, cxr14macf1 0.33164, cxr14_loss 0.96383, vnbgmicf1 0.55634, vnbgmacf1 0.41901, vnbg_loss 0.79041, ema 0.68806, 342.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.06436, wmdcmp 0.15529, oracc 0.96660, chxlmicf1 0.51642, chxlmacf1 0.46845, chxlacc 0.68198, chxlrocaucmic 0.76807, chxlrocaucmac 0.74772, qlmicf1 0.37358, qlmacf1 0.24982, ema 0.65455, 250.58 secs\n",
      "Adjusting learning rate of group 0 to 2.8302e-04.\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000283) ...\n",
      "loss 4.58966, a_loss 1.00424, cD 1.18041, wmdcmp 0.16025, oracc 0.97019, orien_loss 0.07253, chxlmicf1 0.51890, chxlmacf1 0.47229, chx_loss 0.88611, chxlacc 0.70634, chxlrocaucmic 0.79542, chxlrocaucmac 0.77482, qlmicf1 0.36194, qlmacf1 0.21826, ql_loss 0.82657, gacc 0.81023, gloss 0.43925, cxr14micf1 0.35033, cxr14macf1 0.34023, cxr14_loss 0.95314, vnbgmicf1 0.56174, vnbgmacf1 0.42369, vnbg_loss 0.78158, ema 0.68935, 388.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05203, wmdcmp 0.15676, oracc 0.96660, chxlmicf1 0.51959, chxlmacf1 0.47059, chxlacc 0.69012, chxlrocaucmic 0.76933, chxlrocaucmac 0.74737, qlmicf1 0.36541, qlmacf1 0.24696, ema 0.64727, 286.15 secs\n",
      "Adjusting learning rate of group 0 to 2.6716e-04.\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000267) ...\n",
      "loss 4.68516, a_loss 0.99724, cD 1.19639, wmdcmp 0.16181, oracc 0.97152, orien_loss 0.06543, chxlmicf1 0.51779, chxlmacf1 0.47050, chx_loss 0.88677, chxlacc 0.70710, chxlrocaucmic 0.79611, chxlrocaucmac 0.77530, qlmicf1 0.36799, qlmacf1 0.21924, ql_loss 0.82164, gacc 0.81295, gloss 0.43284, cxr14micf1 0.33915, cxr14macf1 0.33324, cxr14_loss 0.95199, vnbgmicf1 0.56220, vnbgmacf1 0.42920, vnbg_loss 0.77033, ema 0.69329, 440.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.02344, wmdcmp 0.15130, oracc 0.96660, chxlmicf1 0.51690, chxlmacf1 0.46787, chxlacc 0.68727, chxlrocaucmic 0.76640, chxlrocaucmac 0.74797, qlmicf1 0.38252, qlmacf1 0.25138, ema 0.68273, 255.70 secs\n",
      "Adjusting learning rate of group 0 to 2.5219e-04.\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000252) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.77120, a_loss 0.97601, cD 1.22416, wmdcmp 0.16550, oracc 0.97157, orien_loss 0.06182, chxlmicf1 0.51777, chxlmacf1 0.47119, chx_loss 0.88398, chxlacc 0.70771, chxlrocaucmic 0.79619, chxlrocaucmac 0.77572, qlmicf1 0.36385, qlmacf1 0.21940, ql_loss 0.82112, gacc 0.82580, gloss 0.41497, cxr14micf1 0.34765, cxr14macf1 0.33878, cxr14_loss 0.96054, vnbgmicf1 0.56118, vnbgmacf1 0.42845, vnbg_loss 0.76742, ema 0.70144, 466.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31629, wmdcmp 0.18276, oracc 0.96779, chxlmicf1 0.51726, chxlmacf1 0.46839, chxlacc 0.68879, chxlrocaucmic 0.76462, chxlrocaucmac 0.74921, qlmicf1 0.37338, qlmacf1 0.24906, ema 0.67636, 300.58 secs\n",
      "Adjusting learning rate of group 0 to 2.3806e-04.\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000238) ...\n",
      "Current run is terminating due to exception: Caught OSError in DataLoader worker process 2.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2818, in open\n",
      "    prefix = fp.read(16)\n",
      "OSError: [Errno 5] Input/output error\n",
      "\n",
      "Engine run is terminating due to exception: Caught OSError in DataLoader worker process 2.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2818, in open\n",
      "    prefix = fp.read(16)\n",
      "OSError: [Errno 5] Input/output error\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_vqa.py\", line 1449, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_vqa.py\", line 1348, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_vqa.py\", line 890, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 801, in _run_once_on_dataset\n",
      "    self.state.batch = next(self._dataloader_iter)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 169, in balanced_dataloaders_generator\n",
      "    yield next(cyclic_dataloaders[i])\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 135, in cyclic_dataloader_generator\n",
      "    for batch in dataloader:\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "OSError: Caught OSError in DataLoader worker process 2.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2818, in open\n",
      "    prefix = fp.read(16)\n",
      "OSError: [Errno 5] Input/output error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 80 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 6 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,4e-4,76,5e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --raw-image-encoding \"clip-vit-huggingface\" \\\n",
    "        --clip-version \"CenIA/vte-vit-base-patch16-bio-clinical-bert-finetuned-v3\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 30\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   iuxray_qa_adapted_reports_filename: None\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: bilstm\n",
      "   answer_decoding: lstm\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adam\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.05\n",
      "   mimiccxr_weight_chexpert_mode: 0.2\n",
      "   iuxray_weight_chexpert_mode: 0.05\n",
      "   mimiccxr_include_chexpert_mode: False\n",
      "   iuxray_include_chexpert_mode: False\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: False\n",
      "   medical_tokenization: False\n",
      "   medical_terms_frequency_filename: None\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: False\n",
      "   balanced_dataloading: False\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: None\n",
      "   mimiccxr_balanced_metadata_filename: None\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   iuxray_train_with_all: False\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: None\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_questions: False\n",
      "   n_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-bp16bcbf-v3+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_13_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5539.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_13_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5539.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 14/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000238) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.53364, a_loss 0.91472, cD 1.34674, wmdcmp 0.17798, oracc 0.97394, orien_loss 0.05840, chxlmicf1 0.51614, chxlmacf1 0.46897, chx_loss 0.88242, chxlacc 0.70674, chxlrocaucmic 0.79606, chxlrocaucmac 0.77612, qlmicf1 0.36502, qlmacf1 0.21797, ql_loss 0.81765, gacc 0.81966, gloss 0.41513, cxr14micf1 0.35719, cxr14macf1 0.34486, cxr14_loss 0.94393, vnbgmicf1 0.56581, vnbgmacf1 0.43238, vnbg_loss 0.74358, ema 0.70648, 185.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.10962, wmdcmp 0.16237, oracc 0.96824, chxlmicf1 0.51915, chxlmacf1 0.47009, chxlacc 0.68994, chxlrocaucmic 0.76785, chxlrocaucmac 0.74993, qlmicf1 0.37327, qlmacf1 0.25293, ema 0.67182, 92.46 secs\n",
      "Adjusting learning rate of group 0 to 2.2473e-04.\n",
      "\u001b[1m---- Epoch 15/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000225) ...\n",
      "loss 4.63615, a_loss 0.95126, cD 1.29328, wmdcmp 0.17334, oracc 0.97332, orien_loss 0.05638, chxlmicf1 0.51921, chxlmacf1 0.47281, chx_loss 0.87984, chxlacc 0.70782, chxlrocaucmic 0.79885, chxlrocaucmac 0.77838, qlmicf1 0.36760, qlmacf1 0.22202, ql_loss 0.81796, gacc 0.83170, gloss 0.40396, cxr14micf1 0.34805, cxr14macf1 0.33612, cxr14_loss 0.95112, vnbgmicf1 0.56242, vnbgmacf1 0.42910, vnbg_loss 0.76007, ema 0.70074, 217.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.03834, wmdcmp 0.15400, oracc 0.96824, chxlmicf1 0.51962, chxlmacf1 0.46882, chxlacc 0.68953, chxlrocaucmic 0.76792, chxlrocaucmac 0.74815, qlmicf1 0.37301, qlmacf1 0.24925, ema 0.66091, 136.16 secs\n",
      "Adjusting learning rate of group 0 to 2.1214e-04.\n",
      "\u001b[1m---- Epoch 16/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000212) ...\n",
      "loss 4.61803, a_loss 0.94714, cD 1.28978, wmdcmp 0.17177, oracc 0.97395, orien_loss 0.05740, chxlmicf1 0.51666, chxlmacf1 0.47041, chx_loss 0.88735, chxlacc 0.70700, chxlrocaucmic 0.79584, chxlrocaucmac 0.77617, qlmicf1 0.36737, qlmacf1 0.22244, ql_loss 0.81291, gacc 0.82670, gloss 0.40677, cxr14micf1 0.34377, cxr14macf1 0.33646, cxr14_loss 0.95420, vnbgmicf1 0.56702, vnbgmacf1 0.42875, vnbg_loss 0.74154, ema 0.70778, 283.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08007, wmdcmp 0.15732, oracc 0.97301, chxlmicf1 0.51581, chxlmacf1 0.46778, chxlacc 0.68280, chxlrocaucmic 0.76567, chxlrocaucmac 0.74963, qlmicf1 0.38556, qlmacf1 0.25661, ema 0.69000, 274.64 secs\n",
      "Adjusting learning rate of group 0 to 2.0025e-04.\n",
      "\u001b[1m---- Epoch 17/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 4.33710, a_loss 0.93915, cD 1.29123, wmdcmp 0.17349, oracc 0.97530, orien_loss 0.05193, chxlmicf1 0.51922, chxlmacf1 0.47196, chx_loss 0.88338, chxlacc 0.70799, chxlrocaucmic 0.79683, chxlrocaucmac 0.77749, qlmicf1 0.36610, qlmacf1 0.22120, ql_loss 0.81826, gacc 0.83591, gloss 0.39630, cxr14micf1 0.34394, cxr14macf1 0.33555, cxr14_loss 0.95285, vnbgmicf1 0.56523, vnbgmacf1 0.43172, vnbg_loss 0.75181, ema 0.70625, 458.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17216, wmdcmp 0.16777, oracc 0.97003, chxlmicf1 0.52133, chxlmacf1 0.46981, chxlacc 0.69280, chxlrocaucmic 0.77125, chxlrocaucmac 0.74959, qlmicf1 0.37780, qlmacf1 0.25526, ema 0.65636, 280.65 secs\n",
      "Adjusting learning rate of group 0 to 1.8903e-04.\n",
      "\u001b[1m---- Epoch 18/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 4.56916, a_loss 0.93032, cD 1.31655, wmdcmp 0.17604, oracc 0.97635, orien_loss 0.04911, chxlmicf1 0.51845, chxlmacf1 0.47181, chx_loss 0.88078, chxlacc 0.70781, chxlrocaucmic 0.79669, chxlrocaucmac 0.77683, qlmicf1 0.36938, qlmacf1 0.22220, ql_loss 0.81343, gacc 0.82875, gloss 0.39443, cxr14micf1 0.34984, cxr14macf1 0.34060, cxr14_loss 0.94769, vnbgmicf1 0.56682, vnbgmacf1 0.43770, vnbg_loss 0.74124, ema 0.71366, 457.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20586, wmdcmp 0.17413, oracc 0.97003, chxlmicf1 0.52124, chxlmacf1 0.47010, chxlacc 0.68792, chxlrocaucmic 0.77001, chxlrocaucmac 0.75069, qlmicf1 0.37272, qlmacf1 0.25318, ema 0.66182, 282.30 secs\n",
      "Adjusting learning rate of group 0 to 1.7844e-04.\n",
      "\u001b[1m---- Epoch 19/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000178) ...\n",
      "loss 4.51178, a_loss 0.92318, cD 1.33269, wmdcmp 0.17766, oracc 0.97687, orien_loss 0.04795, chxlmicf1 0.51881, chxlmacf1 0.47187, chx_loss 0.87743, chxlacc 0.70818, chxlrocaucmic 0.79810, chxlrocaucmac 0.78014, qlmicf1 0.36727, qlmacf1 0.22135, ql_loss 0.81626, gacc 0.82784, gloss 0.40114, cxr14micf1 0.36164, cxr14macf1 0.34529, cxr14_loss 0.93718, vnbgmicf1 0.57161, vnbgmacf1 0.43445, vnbg_loss 0.73831, ema 0.71222, 458.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16600, wmdcmp 0.16955, oracc 0.97003, chxlmicf1 0.52595, chxlmacf1 0.47272, chxlacc 0.69648, chxlrocaucmic 0.77066, chxlrocaucmac 0.74921, qlmicf1 0.36791, qlmacf1 0.25131, ema 0.68182, 282.41 secs\n",
      "Adjusting learning rate of group 0 to 1.6844e-04.\n",
      "\u001b[1m---- Epoch 20/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 4.58227, a_loss 0.92483, cD 1.34089, wmdcmp 0.17745, oracc 0.97655, orien_loss 0.04713, chxlmicf1 0.52078, chxlmacf1 0.47358, chx_loss 0.88193, chxlacc 0.70844, chxlrocaucmic 0.79698, chxlrocaucmac 0.77739, qlmicf1 0.36885, qlmacf1 0.22312, ql_loss 0.81146, gacc 0.83841, gloss 0.38739, cxr14micf1 0.35203, cxr14macf1 0.34202, cxr14_loss 0.93744, vnbgmicf1 0.56827, vnbgmacf1 0.43612, vnbg_loss 0.72852, ema 0.71130, 457.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21557, wmdcmp 0.17625, oracc 0.97301, chxlmicf1 0.52273, chxlmacf1 0.47194, chxlacc 0.69491, chxlrocaucmic 0.76761, chxlrocaucmac 0.74941, qlmicf1 0.38205, qlmacf1 0.25540, ema 0.66636, 282.49 secs\n",
      "Adjusting learning rate of group 0 to 1.5900e-04.\n",
      "\u001b[1m---- Epoch 21/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 4.29914, a_loss 0.91770, cD 1.36459, wmdcmp 0.18230, oracc 0.97574, orien_loss 0.04834, chxlmicf1 0.51986, chxlmacf1 0.47382, chx_loss 0.87742, chxlacc 0.70796, chxlrocaucmic 0.79894, chxlrocaucmac 0.77982, qlmicf1 0.37023, qlmacf1 0.22401, ql_loss 0.81280, gacc 0.83659, gloss 0.38540, cxr14micf1 0.34831, cxr14macf1 0.33999, cxr14_loss 0.94086, vnbgmicf1 0.57405, vnbgmacf1 0.44107, vnbg_loss 0.72476, ema 0.71120, 456.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25872, wmdcmp 0.17741, oracc 0.97301, chxlmicf1 0.52340, chxlmacf1 0.47159, chxlacc 0.69260, chxlrocaucmic 0.77146, chxlrocaucmac 0.74892, qlmicf1 0.37143, qlmacf1 0.25358, ema 0.68636, 282.47 secs\n",
      "Adjusting learning rate of group 0 to 1.5010e-04.\n",
      "\u001b[1m---- Epoch 22/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "loss 4.67321, a_loss 0.90775, cD 1.38662, wmdcmp 0.18412, oracc 0.97831, orien_loss 0.04375, chxlmicf1 0.52091, chxlmacf1 0.47491, chx_loss 0.87844, chxlacc 0.70926, chxlrocaucmic 0.79920, chxlrocaucmac 0.77967, qlmicf1 0.37137, qlmacf1 0.22327, ql_loss 0.80964, gacc 0.83909, gloss 0.38239, cxr14micf1 0.36111, cxr14macf1 0.34698, cxr14_loss 0.93829, vnbgmicf1 0.58172, vnbgmacf1 0.44673, vnbg_loss 0.70306, ema 0.71968, 453.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17237, wmdcmp 0.17046, oracc 0.97599, chxlmicf1 0.52012, chxlmacf1 0.47125, chxlacc 0.68529, chxlrocaucmic 0.76599, chxlrocaucmac 0.74965, qlmicf1 0.38046, qlmacf1 0.25389, ema 0.67273, 263.26 secs\n",
      "Adjusting learning rate of group 0 to 1.4169e-04.\n",
      "\u001b[1m---- Epoch 23/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 4.38758, a_loss 0.90902, cD 1.36038, wmdcmp 0.18051, oracc 0.97734, orien_loss 0.04366, chxlmicf1 0.52489, chxlmacf1 0.47757, chx_loss 0.87348, chxlacc 0.71001, chxlrocaucmic 0.79929, chxlrocaucmac 0.77979, qlmicf1 0.36967, qlmacf1 0.22572, ql_loss 0.80941, gacc 0.84034, gloss 0.38286, cxr14micf1 0.36719, cxr14macf1 0.34925, cxr14_loss 0.93341, vnbgmicf1 0.56730, vnbgmacf1 0.42959, vnbg_loss 0.73721, ema 0.71704, 206.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16314, wmdcmp 0.16813, oracc 0.97599, chxlmicf1 0.51904, chxlmacf1 0.46841, chxlacc 0.68741, chxlrocaucmic 0.76970, chxlrocaucmac 0.74851, qlmicf1 0.37886, qlmacf1 0.25584, ema 0.69273, 91.20 secs\n",
      "Adjusting learning rate of group 0 to 1.3375e-04.\n",
      "\u001b[1m---- Epoch 24/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 4.43364, a_loss 0.90359, cD 1.38329, wmdcmp 0.18376, oracc 0.97713, orien_loss 0.04101, chxlmicf1 0.51792, chxlmacf1 0.47111, chx_loss 0.88006, chxlacc 0.70801, chxlrocaucmic 0.79732, chxlrocaucmac 0.77718, qlmicf1 0.36541, qlmacf1 0.22148, ql_loss 0.81330, gacc 0.83614, gloss 0.38064, cxr14micf1 0.34892, cxr14macf1 0.34104, cxr14_loss 0.94308, vnbgmicf1 0.57640, vnbgmacf1 0.43841, vnbg_loss 0.70261, ema 0.71954, 144.21 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.21154, wmdcmp 0.17621, oracc 0.97599, chxlmicf1 0.51856, chxlmacf1 0.46966, chxlacc 0.68279, chxlrocaucmic 0.76762, chxlrocaucmac 0.75079, qlmicf1 0.37894, qlmacf1 0.25502, ema 0.66364, 86.86 secs\n",
      "Adjusting learning rate of group 0 to 1.2625e-04.\n",
      "\u001b[1m---- Epoch 25/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000126) ...\n",
      "loss 4.43223, a_loss 0.90610, cD 1.38581, wmdcmp 0.18354, oracc 0.97939, orien_loss 0.04076, chxlmicf1 0.52047, chxlmacf1 0.47354, chx_loss 0.87605, chxlacc 0.70821, chxlrocaucmic 0.79865, chxlrocaucmac 0.77984, qlmicf1 0.36767, qlmacf1 0.22430, ql_loss 0.81485, gacc 0.83000, gloss 0.39428, cxr14micf1 0.36647, cxr14macf1 0.34667, cxr14_loss 0.93837, vnbgmicf1 0.57858, vnbgmacf1 0.44400, vnbg_loss 0.71057, ema 0.71616, 160.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23690, wmdcmp 0.17835, oracc 0.97599, chxlmicf1 0.52126, chxlmacf1 0.47015, chxlacc 0.69250, chxlrocaucmic 0.76880, chxlrocaucmac 0.74992, qlmicf1 0.38001, qlmacf1 0.25640, ema 0.68000, 82.40 secs\n",
      "Adjusting learning rate of group 0 to 1.1918e-04.\n",
      "\u001b[1m---- Epoch 26/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000119) ...\n",
      "loss 4.46145, a_loss 0.89535, cD 1.41769, wmdcmp 0.18696, oracc 0.97655, orien_loss 0.04026, chxlmicf1 0.51969, chxlmacf1 0.47352, chx_loss 0.87777, chxlacc 0.70943, chxlrocaucmic 0.79770, chxlrocaucmac 0.77875, qlmicf1 0.37046, qlmacf1 0.22597, ql_loss 0.81074, gacc 0.83977, gloss 0.37994, cxr14micf1 0.35558, cxr14macf1 0.34235, cxr14_loss 0.93385, vnbgmicf1 0.57236, vnbgmacf1 0.44017, vnbg_loss 0.71064, ema 0.72111, 163.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26309, wmdcmp 0.18169, oracc 0.97868, chxlmicf1 0.51732, chxlmacf1 0.46799, chxlacc 0.68637, chxlrocaucmic 0.76756, chxlrocaucmac 0.75108, qlmicf1 0.37554, qlmacf1 0.25449, ema 0.68636, 85.56 secs\n",
      "Adjusting learning rate of group 0 to 1.1250e-04.\n",
      "\u001b[1m---- Epoch 27/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 4.15664, a_loss 0.89331, cD 1.40693, wmdcmp 0.18641, oracc 0.97797, orien_loss 0.04253, chxlmicf1 0.52051, chxlmacf1 0.47358, chx_loss 0.88008, chxlacc 0.71096, chxlrocaucmic 0.80016, chxlrocaucmac 0.78011, qlmicf1 0.37223, qlmacf1 0.22442, ql_loss 0.80785, gacc 0.83591, gloss 0.38126, cxr14micf1 0.35602, cxr14macf1 0.34116, cxr14_loss 0.93767, vnbgmicf1 0.57441, vnbgmacf1 0.43887, vnbg_loss 0.71052, ema 0.72264, 141.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23561, wmdcmp 0.17738, oracc 0.97599, chxlmicf1 0.51723, chxlmacf1 0.46743, chxlacc 0.68644, chxlrocaucmic 0.76669, chxlrocaucmac 0.74998, qlmicf1 0.38806, qlmacf1 0.25721, ema 0.68545, 85.87 secs\n",
      "Adjusting learning rate of group 0 to 1.0620e-04.\n",
      "\u001b[1m---- Epoch 28/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 4.34637, a_loss 0.89550, cD 1.43629, wmdcmp 0.18910, oracc 0.97902, orien_loss 0.03999, chxlmicf1 0.52199, chxlmacf1 0.47543, chx_loss 0.87469, chxlacc 0.71118, chxlrocaucmic 0.80096, chxlrocaucmac 0.78207, qlmicf1 0.37405, qlmacf1 0.22788, ql_loss 0.80405, gacc 0.83534, gloss 0.38099, cxr14micf1 0.34190, cxr14macf1 0.33705, cxr14_loss 0.94186, vnbgmicf1 0.57550, vnbgmacf1 0.44486, vnbg_loss 0.70749, ema 0.72014, 163.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23835, wmdcmp 0.17730, oracc 0.97599, chxlmicf1 0.51847, chxlmacf1 0.46860, chxlacc 0.68752, chxlrocaucmic 0.76781, chxlrocaucmac 0.75084, qlmicf1 0.38018, qlmacf1 0.25567, ema 0.68909, 82.68 secs\n",
      "Adjusting learning rate of group 0 to 1.0025e-04.\n",
      "\u001b[1m---- Epoch 29/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.22281, a_loss 0.88796, cD 1.43756, wmdcmp 0.18941, oracc 0.97833, orien_loss 0.04222, chxlmicf1 0.52084, chxlmacf1 0.47446, chx_loss 0.87607, chxlacc 0.70982, chxlrocaucmic 0.80042, chxlrocaucmac 0.78154, qlmicf1 0.37315, qlmacf1 0.22411, ql_loss 0.80820, gacc 0.84170, gloss 0.37670, cxr14micf1 0.36655, cxr14macf1 0.35102, cxr14_loss 0.92909, vnbgmicf1 0.58189, vnbgmacf1 0.44743, vnbg_loss 0.70640, ema 0.71671, 163.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17396, wmdcmp 0.17087, oracc 0.97748, chxlmicf1 0.51964, chxlmacf1 0.46714, chxlacc 0.68722, chxlrocaucmic 0.77024, chxlrocaucmac 0.75101, qlmicf1 0.38446, qlmacf1 0.25746, ema 0.67727, 90.37 secs\n",
      "Adjusting learning rate of group 0 to 9.4633e-05.\n",
      "\u001b[1m---- Epoch 30/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 4.65070, a_loss 0.87919, cD 1.43612, wmdcmp 0.18882, oracc 0.97894, orien_loss 0.04153, chxlmicf1 0.52281, chxlmacf1 0.47588, chx_loss 0.87703, chxlacc 0.71046, chxlrocaucmic 0.79911, chxlrocaucmac 0.78046, qlmicf1 0.37224, qlmacf1 0.22483, ql_loss 0.80996, gacc 0.83409, gloss 0.38768, cxr14micf1 0.35752, cxr14macf1 0.34532, cxr14_loss 0.93890, vnbgmicf1 0.57600, vnbgmacf1 0.44466, vnbg_loss 0.69674, ema 0.72069, 144.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23578, wmdcmp 0.17721, oracc 0.98017, chxlmicf1 0.52110, chxlmacf1 0.46830, chxlacc 0.69191, chxlrocaucmic 0.76988, chxlrocaucmac 0.74976, qlmicf1 0.38020, qlmacf1 0.25658, ema 0.68818, 87.50 secs\n",
      "Adjusting learning rate of group 0 to 8.9331e-05.\n",
      "\u001b[1m---- Epoch 31/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 4.41967, a_loss 0.88267, cD 1.45433, wmdcmp 0.19062, oracc 0.97899, orien_loss 0.03878, chxlmicf1 0.52177, chxlmacf1 0.47501, chx_loss 0.87499, chxlacc 0.70964, chxlrocaucmic 0.79753, chxlrocaucmac 0.77953, qlmicf1 0.36981, qlmacf1 0.22437, ql_loss 0.80984, gacc 0.84352, gloss 0.37259, cxr14micf1 0.35596, cxr14macf1 0.34394, cxr14_loss 0.94333, vnbgmicf1 0.58976, vnbgmacf1 0.45212, vnbg_loss 0.67809, ema 0.72296, 163.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25082, wmdcmp 0.17873, oracc 0.97748, chxlmicf1 0.52373, chxlmacf1 0.47282, chxlacc 0.69032, chxlrocaucmic 0.77098, chxlrocaucmac 0.75142, qlmicf1 0.38384, qlmacf1 0.25578, ema 0.69273, 84.44 secs\n",
      "Adjusting learning rate of group 0 to 8.4326e-05.\n",
      "\u001b[1m---- Epoch 32/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000084) ...\n",
      "loss 4.36817, a_loss 0.88733, cD 1.45246, wmdcmp 0.19151, oracc 0.97750, orien_loss 0.04176, chxlmicf1 0.52092, chxlmacf1 0.47410, chx_loss 0.87703, chxlacc 0.70926, chxlrocaucmic 0.79801, chxlrocaucmac 0.77901, qlmicf1 0.36992, qlmacf1 0.22798, ql_loss 0.80578, gacc 0.84295, gloss 0.37569, cxr14micf1 0.36268, cxr14macf1 0.34839, cxr14_loss 0.93547, vnbgmicf1 0.57595, vnbgmacf1 0.44317, vnbg_loss 0.70628, ema 0.72458, 163.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31368, wmdcmp 0.18548, oracc 0.98017, chxlmicf1 0.52099, chxlmacf1 0.46970, chxlacc 0.69022, chxlrocaucmic 0.77127, chxlrocaucmac 0.75266, qlmicf1 0.38489, qlmacf1 0.25782, ema 0.68091, 84.48 secs\n",
      "Adjusting learning rate of group 0 to 7.9602e-05.\n",
      "\u001b[1m---- Epoch 33/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 4.26705, a_loss 0.87646, cD 1.45240, wmdcmp 0.19090, oracc 0.97877, orien_loss 0.03827, chxlmicf1 0.52123, chxlmacf1 0.47478, chx_loss 0.87449, chxlacc 0.70991, chxlrocaucmic 0.80102, chxlrocaucmac 0.78175, qlmicf1 0.36911, qlmacf1 0.22393, ql_loss 0.81284, gacc 0.83966, gloss 0.37798, cxr14micf1 0.35933, cxr14macf1 0.34715, cxr14_loss 0.93241, vnbgmicf1 0.58571, vnbgmacf1 0.45045, vnbg_loss 0.69044, ema 0.73245, 143.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29156, wmdcmp 0.18284, oracc 0.97868, chxlmicf1 0.51973, chxlmacf1 0.46971, chxlacc 0.69060, chxlrocaucmic 0.76972, chxlrocaucmac 0.75233, qlmicf1 0.38419, qlmacf1 0.25873, ema 0.67909, 85.56 secs\n",
      "Adjusting learning rate of group 0 to 7.5142e-05.\n",
      "\u001b[1m---- Epoch 34/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000075) ...\n",
      "loss 4.25195, a_loss 0.87369, cD 1.46599, wmdcmp 0.19190, oracc 0.97870, orien_loss 0.03964, chxlmicf1 0.52108, chxlmacf1 0.47580, chx_loss 0.87516, chxlacc 0.71062, chxlrocaucmic 0.79952, chxlrocaucmac 0.78016, qlmicf1 0.37155, qlmacf1 0.22416, ql_loss 0.80511, gacc 0.84739, gloss 0.36589, cxr14micf1 0.35346, cxr14macf1 0.34251, cxr14_loss 0.93459, vnbgmicf1 0.58637, vnbgmacf1 0.45022, vnbg_loss 0.69115, ema 0.72986, 164.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27111, wmdcmp 0.18202, oracc 0.98017, chxlmicf1 0.51914, chxlmacf1 0.46926, chxlacc 0.68822, chxlrocaucmic 0.77108, chxlrocaucmac 0.75214, qlmicf1 0.38522, qlmacf1 0.25791, ema 0.69091, 82.52 secs\n",
      "Adjusting learning rate of group 0 to 7.0932e-05.\n",
      "\u001b[1m---- Epoch 35/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 4.21228, a_loss 0.87658, cD 1.46351, wmdcmp 0.19209, oracc 0.97845, orien_loss 0.03723, chxlmicf1 0.52076, chxlmacf1 0.47329, chx_loss 0.87792, chxlacc 0.70950, chxlrocaucmic 0.79839, chxlrocaucmac 0.77914, qlmicf1 0.37289, qlmacf1 0.22527, ql_loss 0.80453, gacc 0.84182, gloss 0.37308, cxr14micf1 0.36248, cxr14macf1 0.34961, cxr14_loss 0.93062, vnbgmicf1 0.58514, vnbgmacf1 0.45210, vnbg_loss 0.68922, ema 0.72278, 161.67 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.25447, wmdcmp 0.17826, oracc 0.98017, chxlmicf1 0.52237, chxlmacf1 0.47108, chxlacc 0.69068, chxlrocaucmic 0.76982, chxlrocaucmac 0.75115, qlmicf1 0.38325, qlmacf1 0.25797, ema 0.68727, 82.21 secs\n",
      "Adjusting learning rate of group 0 to 6.6958e-05.\n",
      "\u001b[1m---- Epoch 36/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 4.40070, a_loss 0.86971, cD 1.48336, wmdcmp 0.19549, oracc 0.97917, orien_loss 0.03817, chxlmicf1 0.52194, chxlmacf1 0.47463, chx_loss 0.87325, chxlacc 0.71021, chxlrocaucmic 0.79928, chxlrocaucmac 0.78059, qlmicf1 0.37530, qlmacf1 0.22610, ql_loss 0.80543, gacc 0.84170, gloss 0.37570, cxr14micf1 0.35672, cxr14macf1 0.34342, cxr14_loss 0.94039, vnbgmicf1 0.58456, vnbgmacf1 0.45325, vnbg_loss 0.67827, ema 0.72366, 142.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30553, wmdcmp 0.18439, oracc 0.98017, chxlmicf1 0.52301, chxlmacf1 0.47274, chxlacc 0.68922, chxlrocaucmic 0.77044, chxlrocaucmac 0.75165, qlmicf1 0.38257, qlmacf1 0.25710, ema 0.68000, 85.51 secs\n",
      "Adjusting learning rate of group 0 to 6.3206e-05.\n",
      "\u001b[1m---- Epoch 37/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 4.33552, a_loss 0.87033, cD 1.47146, wmdcmp 0.19245, oracc 0.98007, orien_loss 0.03748, chxlmicf1 0.52056, chxlmacf1 0.47410, chx_loss 0.87616, chxlacc 0.70915, chxlrocaucmic 0.79920, chxlrocaucmac 0.78086, qlmicf1 0.37471, qlmacf1 0.22408, ql_loss 0.80417, gacc 0.84614, gloss 0.37277, cxr14micf1 0.37732, cxr14macf1 0.35531, cxr14_loss 0.92725, vnbgmicf1 0.58186, vnbgmacf1 0.44464, vnbg_loss 0.70246, ema 0.72648, 168.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26217, wmdcmp 0.18054, oracc 0.97868, chxlmicf1 0.52142, chxlmacf1 0.46860, chxlacc 0.69301, chxlrocaucmic 0.77054, chxlrocaucmac 0.75118, qlmicf1 0.38637, qlmacf1 0.25804, ema 0.67636, 81.56 secs\n",
      "Adjusting learning rate of group 0 to 5.9665e-05.\n",
      "\u001b[1m---- Epoch 38/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 4.04417, a_loss 0.87005, cD 1.49230, wmdcmp 0.19665, oracc 0.98009, orien_loss 0.03996, chxlmicf1 0.52125, chxlmacf1 0.47380, chx_loss 0.87662, chxlacc 0.71119, chxlrocaucmic 0.79957, chxlrocaucmac 0.77997, qlmicf1 0.37424, qlmacf1 0.22763, ql_loss 0.80412, gacc 0.83750, gloss 0.37288, cxr14micf1 0.36535, cxr14macf1 0.35086, cxr14_loss 0.92394, vnbgmicf1 0.58168, vnbgmacf1 0.44880, vnbg_loss 0.69204, ema 0.72810, 157.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31839, wmdcmp 0.18616, oracc 0.98017, chxlmicf1 0.52033, chxlmacf1 0.46833, chxlacc 0.69050, chxlrocaucmic 0.77121, chxlrocaucmac 0.75204, qlmicf1 0.38080, qlmacf1 0.25715, ema 0.69364, 83.12 secs\n",
      "Adjusting learning rate of group 0 to 5.6322e-05.\n",
      "\u001b[1m---- Epoch 39/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 4.16795, a_loss 0.86651, cD 1.50372, wmdcmp 0.19641, oracc 0.97932, orien_loss 0.03672, chxlmicf1 0.52150, chxlmacf1 0.47520, chx_loss 0.87384, chxlacc 0.71083, chxlrocaucmic 0.80044, chxlrocaucmac 0.78105, qlmicf1 0.37484, qlmacf1 0.22625, ql_loss 0.80759, gacc 0.84500, gloss 0.36675, cxr14micf1 0.36884, cxr14macf1 0.35395, cxr14_loss 0.92368, vnbgmicf1 0.58834, vnbgmacf1 0.45444, vnbg_loss 0.67676, ema 0.72963, 148.34 secs\n",
      "(2) Validation stage ...\n",
      "^C iteration 20\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221106_125335_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 30 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 3 \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pamessina/venv/lib/python3.6/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
