{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 20\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: t5\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   task_name: report2negative_facts\n",
      "   experiment_name: r2nf\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_v2_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   report_to_negative_facts_input_output_jsonl_filepaths: ['/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_to_negative_facts.jsonl', '/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_fact_based_report_to_negative_facts.jsonl', '/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_sentence_to_negative_facts.jsonl', '/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o-mini_sentence_to_negative_facts.jsonl']\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: None\n",
      "   interpret_cxr_challenge_data_dir: None\n",
      "   mimiccxr_integrated_report_nli_data_filepath: None\n",
      "   report_section_to_generate: None\n",
      "   include_public_test_in_train: False\n",
      "   best_k_classes: None\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   use_numeric_templates: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: t5-small\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "1e-06 3 0.0002 8 1e-06 0.0002 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loaded 10000 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_to_negative_facts.jsonl\n",
      "100%|███████████████████████████████████| 10000/10000 [00:04<00:00, 2338.65it/s]\n",
      "Loaded 139995 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_fact_based_report_to_negative_facts.jsonl\n",
      "100%|█████████████████████████████████| 139995/139995 [00:47<00:00, 2938.58it/s]\n",
      "Loaded 50436 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_sentence_to_negative_facts.jsonl\n",
      "100%|██████████████████████████████████| 50436/50436 [00:01<00:00, 34135.97it/s]\n",
      "Loaded 348733 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o-mini_sentence_to_negative_facts.jsonl\n",
      "100%|████████████████████████████████| 348733/348733 [00:10<00:00, 32174.28it/s]\n",
      "Number of abnormal sentences: 463962\n",
      "Number of normal sentences: 50588\n",
      "Skipped 34 reports with estimated token count > 512\n",
      "len(train_dataset_1): 1000000000000000000\n",
      "len(train_dataset_2): 1000000000000000000\n",
      "len(train_dataset_3): 1000000000000000000\n",
      "len(val_dataset_1): 500\n",
      "len(val_dataset_2): 500\n",
      "len(val_dataset_3): 500\n",
      "len(merged_train_dataset): 1000000000000000000\n",
      "len(merged_val_dataset): 1500\n",
      "\u001b[1m----- Input/output examples from train_dataset_1:\u001b[0m\n",
      "mode: 1\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mPacemaker leads are identified in the right atrium and the right and left ventricles as well as additional pacer external to the heart. regression of pleural densities blunting the posterior pleural sinus. In addition to vague opacity probably localizing to the left lower lobe there is an extensive right perihilar consolidation primarily involving the right upper lobe, most consistent with pneumonia.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35munchanged linear opacity in the left mid lung zone. remainder of the lungs cleared. presumably hematoma at the base of the left lung\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"unchanged linear opacity in the left mid lung zone\": [\"acute lung consolidation\", \"acute pulmonary edema\"], \"remainder of the lungs cleared\": [\"lung consolidation\", \"lung mass\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno lytic lesion identified. no associated pneumothorax identified. possible very subtle increase in opacity in the remaining aerated left upper lung. intact continuous right atrium lead. no evidence of pleural effusion on lateral radiograph\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no lytic lesion identified\": [\"lytic bone lesion\", \"bone lytic lesion\"], \"no associated pneumothorax identified\": [\"pneumothorax\"], \"intact continuous right atrium lead\": [\"right atrium lead dislodgement\", \"right atrium lead damage\"], \"no evidence of pleural effusion on lateral radiograph\": [\"pleural effusion\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mheart is at the upper limits of normal size. Widening mediastinum has improved .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"heart is at the upper limits of normal size\": [\"cardiomegaly\", \"left ventricular hypertrophy\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno other opacities concerning for aspiration. opacities in the lower lungs have generally otherwise resolved. left lung without evidence of new parenchymal infiltrates. unremarkable soft tissues of the chest wall\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no other opacities concerning for aspiration\": [\"aspiration\", \"aspiration pneumonia\"], \"opacities in the lower lungs have generally otherwise resolved\": [\"lower lung opacity\", \"lower lung consolidation\"], \"left lung without evidence of new parenchymal infiltrates\": [\"left lung parenchymal infiltrates\"], \"unremarkable soft tissues of the chest wall\": [\"chest wall mass\", \"chest wall edema\"]}\u001b[0m\n",
      "\u001b[1m----- Input/output examples from train_dataset_2:\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of pneumothorax on limited frontal supine views. Minimal opacity at the right heart border likely represents crowding of normal bronchovascular structures.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no evidence of pneumothorax on limited frontal supine views\": [\"pneumothorax\"]}\u001b[0m\n",
      "mode: 1\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlarge pulmonary nodules\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "mode: 1\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mAs compared to the previous image, there is unchanged presence of subtle any ill-defined bilateral parenchymal opacities, combines to a minimal locally increase in vascularity.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mtrach tube is in appropriate position\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"trach tube is in appropriate position\": [\"malpositioned tracheostomy tube\", \"tracheal injury due to improper tube placement\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno other large confluent consolidation. no radiographic signs suggestive of aspiration\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no other large confluent consolidation\": [\"large confluent consolidation\"], \"no radiographic signs suggestive of aspiration\": [\"aspiration pneumonia\", \"aspiration pneumonitis\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mmild upper lobe volume loss and hilar retraction. largely cleared\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"mild upper lobe volume loss and hilar retraction\": [\"upper lobe collapse\", \"hilar mass\"], \"largely cleared\": [\"pulmonary edema\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mupper portions of left lung grossly clear. normal cardiac border\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"upper portions of left lung grossly clear\": [\"left upper lung zone collapse\", \"left upper lung zone consolidation\"], \"normal cardiac border\": [\"cardiomegaly\", \"pericardial effusion\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mETT positioned appropriately. no evidence of pulmonary infarct\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"ETT positioned appropriately\": [\"endotracheal tube malposition\", \"endotracheal tube dislodgement\"], \"no evidence of pulmonary infarct\": [\"pulmonary infarct\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35msubtotal collapse of the right lung. upper abdomen within normal limits\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"upper abdomen within normal limits\": [\"abdominal mass\", \"abdominal organomegaly\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mmediastinal structures do not show evidence of significant shift\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"mediastinal structures do not show evidence of significant shift\": [\"mediastinal shift\", \"mediastinal displacement\"]}\u001b[0m\n",
      "\u001b[1m----- Input/output example from train_dataset_3:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mright PICC tip can be follow to the cavoatrial junction\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mA left-sided PICC line is present, tip overlies the mid/ distal SVC.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1m----- Input/output example from val_dataset_1:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mIn this patient with known squamous cell lung cancer, there is a similar pattern of right perihilar opacity with associated fibrosis. suggestive of small bilateral effusions. Right subclavian infusion port ends in the SVC.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1m----- Input/output example from val_dataset_2:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft base opacity due to pathology. new lobulation since [previous study]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1m----- Input/output example from val_dataset_3:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mtip overlies the lateral right chest wall at the level of the right mid chest\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq2seq_trainer.name =  report2negative_facts(r2nf)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_142005_report2negative_facts(r2nf)_Seq2Seq(t5-small)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_142005_report2negative_facts(r2nf)_Seq2Seq(t5-small)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_142005_report2negative_facts(r2nf)_Seq2Seq(t5-small)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.71199, s2s_loss 3.58438, 101.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 2.83059, 2.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_s2s_loss=0.2568.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.86892, s2s_loss 1.25162, 101.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.70312, 2.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_s2s_loss=0.5729.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.19462, s2s_loss 0.63596, 102.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.41717, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_s2s_loss=0.6962.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000103) ...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "loss 0.45431, s2s_loss 0.47834, 100.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.38601, 2.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_s2s_loss=0.7170.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 0.34564, s2s_loss 0.44999, 102.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.35695, 2.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_s2s_loss=0.7322.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.53958, s2s_loss 0.42747, 101.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.34654, 2.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_s2s_loss=0.7384.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.40389, s2s_loss 0.41683, 102.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.34425, 2.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_s2s_loss=0.7401.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53146, s2s_loss 0.41533, 101.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.34494, 2.18 secs\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.55851, s2s_loss 0.41835, 101.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.33228, 2.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_s2s_loss=0.7460.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.45363, s2s_loss 0.41043, 101.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.33648, 2.14 secs\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28530, s2s_loss 0.41159, 93.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.34394, 2.16 secs\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.36329, s2s_loss 0.39044, 101.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.30552, 2.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_s2s_loss=0.7613.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.54940, s2s_loss 0.35381, 101.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.27827, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_s2s_loss=0.7779.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.38996, s2s_loss 0.33367, 101.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.28061, 2.18 secs\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.43034, s2s_loss 0.33054, 101.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.27839, 2.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_s2s_loss=0.7792.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.55217, s2s_loss 0.32687, 101.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.27442, 2.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_s2s_loss=0.7816.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.30476, s2s_loss 0.32503, 101.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.27394, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_s2s_loss=0.7819.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.29246, s2s_loss 0.31972, 101.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.27670, 2.15 secs\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.44555, s2s_loss 0.32013, 101.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.27397, 2.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_s2s_loss=0.7822.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.30533, s2s_loss 0.32260, 101.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.26555, 2.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_s2s_loss=0.7868.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.15902, s2s_loss 0.29815, 101.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.25693, 2.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_s2s_loss=0.7931.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.25620, s2s_loss 0.28893, 102.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24572, 2.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_s2s_loss=0.8001.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.35588, s2s_loss 0.28132, 101.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24798, 2.15 secs\n",
      "\u001b[1m---- Epoch 25/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.28270, s2s_loss 0.27853, 72.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24041, 2.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_s2s_loss=0.8038.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.32588, s2s_loss 0.27558, 102.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.23904, 2.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_s2s_loss=0.8048.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.30766, s2s_loss 0.27517, 101.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24257, 2.20 secs\n",
      "\u001b[1m---- Epoch 28/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.33222, s2s_loss 0.27811, 90.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24666, 2.18 secs\n",
      "\u001b[1m---- Epoch 29/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.40423, s2s_loss 0.28251, 101.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.23746, 2.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_29_s2s_loss=0.8053.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 30/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.27169, s2s_loss 0.26696, 101.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21620, 2.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_30_s2s_loss=0.8189.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 31/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.22973, s2s_loss 0.25535, 101.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.22182, 2.20 secs\n",
      "\u001b[1m---- Epoch 32/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.31589, s2s_loss 0.24935, 101.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21985, 2.16 secs\n",
      "\u001b[1m---- Epoch 33/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.34255, s2s_loss 0.24880, 102.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21548, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_s2s_loss=0.8205.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.22267, s2s_loss 0.25299, 102.55 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.22052, 2.12 secs\n",
      "\u001b[1m---- Epoch 35/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.25456, s2s_loss 0.25074, 102.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21281, 2.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_s2s_loss=0.8220.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17855, s2s_loss 0.24980, 89.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21814, 2.24 secs\n",
      "\u001b[1m---- Epoch 37/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.16875, s2s_loss 0.25179, 102.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21750, 2.16 secs\n",
      "\u001b[1m---- Epoch 38/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.20835, s2s_loss 0.23728, 101.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21201, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_38_s2s_loss=0.8234.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 39/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.23455, s2s_loss 0.23328, 101.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21201, 2.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_s2s_loss=0.8237.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.27684, s2s_loss 0.23390, 101.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20850, 2.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_40_s2s_loss=0.8258.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 41/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.30001, s2s_loss 0.23288, 101.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21213, 2.12 secs\n",
      "\u001b[1m---- Epoch 42/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.16655, s2s_loss 0.22782, 101.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18984, 2.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_s2s_loss=0.8378.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20181, s2s_loss 0.22778, 102.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21092, 2.15 secs\n",
      "\u001b[1m---- Epoch 44/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21189, s2s_loss 0.22804, 102.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20867, 2.12 secs\n",
      "\u001b[1m---- Epoch 45/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.23696, s2s_loss 0.23359, 101.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20670, 2.24 secs\n",
      "\u001b[1m---- Epoch 46/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.29384, s2s_loss 0.22716, 101.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19272, 2.21 secs\n",
      "\u001b[1m---- Epoch 47/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.31816, s2s_loss 0.21921, 101.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20235, 2.22 secs\n",
      "\u001b[1m---- Epoch 48/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.22361, s2s_loss 0.21896, 102.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19289, 2.13 secs\n",
      "\u001b[1m---- Epoch 49/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.25256, s2s_loss 0.21917, 102.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19130, 2.18 secs\n",
      "\u001b[1m---- Epoch 50/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.25690, s2s_loss 0.21404, 101.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19742, 2.15 secs\n",
      "\u001b[1m---- Epoch 51/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20569, s2s_loss 0.21248, 102.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18938, 2.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_51_s2s_loss=0.8392.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 52/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17918, s2s_loss 0.21581, 101.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19448, 2.13 secs\n",
      "\u001b[1m---- Epoch 53/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.17398, s2s_loss 0.21860, 101.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19481, 2.10 secs\n",
      "\u001b[1m---- Epoch 54/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.20126, s2s_loss 0.21234, 102.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18987, 2.18 secs\n",
      "\u001b[1m---- Epoch 55/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.11773, s2s_loss 0.20683, 102.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18856, 2.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_55_s2s_loss=0.8401.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 56/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.41286, s2s_loss 0.21059, 101.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19512, 2.12 secs\n",
      "\u001b[1m---- Epoch 57/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.15488, s2s_loss 0.20365, 101.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18908, 2.18 secs\n",
      "\u001b[1m---- Epoch 58/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.15368, s2s_loss 0.20650, 102.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17360, 2.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_58_s2s_loss=0.8498.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 59/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.19550, s2s_loss 0.20425, 99.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18730, 2.13 secs\n",
      "\u001b[1m---- Epoch 60/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.27362, s2s_loss 0.20437, 101.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18111, 2.17 secs\n",
      "\u001b[1m---- Epoch 61/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.08824, s2s_loss 0.21133, 102.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19376, 2.16 secs\n",
      "\u001b[1m---- Epoch 62/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.22173, s2s_loss 0.20544, 102.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18496, 2.18 secs\n",
      "\u001b[1m---- Epoch 63/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.15594, s2s_loss 0.19763, 102.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17315, 2.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_63_s2s_loss=0.8507.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 64/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.19803, s2s_loss 0.19490, 102.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18205, 2.21 secs\n",
      "\u001b[1m---- Epoch 65/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.27782, s2s_loss 0.19447, 101.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17994, 2.19 secs\n",
      "\u001b[1m---- Epoch 66/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.20790, s2s_loss 0.19564, 101.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17414, 2.21 secs\n",
      "\u001b[1m---- Epoch 67/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.19931, s2s_loss 0.19516, 101.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18037, 2.23 secs\n",
      "\u001b[1m---- Epoch 68/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.14770, s2s_loss 0.19418, 101.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18043, 2.25 secs\n",
      "\u001b[1m---- Epoch 69/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.15202, s2s_loss 0.20208, 102.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18029, 2.17 secs\n",
      "\u001b[1m---- Epoch 70/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.20854, s2s_loss 0.19181, 102.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17328, 2.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_70_s2s_loss=0.8510.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 71/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.19863, s2s_loss 0.19251, 101.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17581, 2.16 secs\n",
      "\u001b[1m---- Epoch 72/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.28375, s2s_loss 0.19050, 97.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16833, 2.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_72_s2s_loss=0.8543.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 73/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.24931, s2s_loss 0.19081, 102.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16667, 2.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_73_s2s_loss=0.8554.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 74/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.21325, s2s_loss 0.19097, 97.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16160, 2.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_74_s2s_loss=0.8588.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 75/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.14536, s2s_loss 0.18797, 101.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16878, 2.27 secs\n",
      "\u001b[1m---- Epoch 76/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17518, s2s_loss 0.18886, 102.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16601, 2.16 secs\n",
      "\u001b[1m---- Epoch 77/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.18056, s2s_loss 0.18992, 101.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17257, 2.26 secs\n",
      "\u001b[1m---- Epoch 78/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.17187, s2s_loss 0.18837, 77.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16081, 2.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_78_s2s_loss=0.8595.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 79/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.19728, s2s_loss 0.17953, 102.79 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.16560, 2.22 secs\n",
      "\u001b[1m---- Epoch 80/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.33048, s2s_loss 0.18517, 102.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17582, 2.25 secs\n",
      "\u001b[1m---- Epoch 81/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.19047, s2s_loss 0.18221, 101.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17037, 2.29 secs\n",
      "\u001b[1m---- Epoch 82/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.20982, s2s_loss 0.18235, 102.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16055, 2.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_82_s2s_loss=0.8601.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 83/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.08047, s2s_loss 0.18044, 103.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16597, 2.34 secs\n",
      "\u001b[1m---- Epoch 84/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.14427, s2s_loss 0.18252, 101.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16748, 2.20 secs\n",
      "\u001b[1m---- Epoch 85/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.16860, s2s_loss 0.18611, 102.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16733, 2.27 secs\n",
      "\u001b[1m---- Epoch 86/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.19652, s2s_loss 0.18150, 101.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16681, 2.19 secs\n",
      "\u001b[1m---- Epoch 87/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.15654, s2s_loss 0.17978, 102.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15356, 2.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_87_s2s_loss=0.8650.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 88/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.25241, s2s_loss 0.18029, 89.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15942, 2.30 secs\n",
      "\u001b[1m---- Epoch 89/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.15760, s2s_loss 0.17632, 102.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16895, 2.35 secs\n",
      "\u001b[1m---- Epoch 90/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.22711, s2s_loss 0.17444, 101.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15728, 2.28 secs\n",
      "\u001b[1m---- Epoch 91/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.15566, s2s_loss 0.17604, 102.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16013, 2.21 secs\n",
      "\u001b[1m---- Epoch 92/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.25140, s2s_loss 0.17685, 101.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17860, 2.24 secs\n",
      "\u001b[1m---- Epoch 93/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.16312, s2s_loss 0.17972, 102.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16183, 2.22 secs\n",
      "\u001b[1m---- Epoch 94/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.09348, s2s_loss 0.17637, 87.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15282, 2.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_94_s2s_loss=0.8657.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 95/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.21543, s2s_loss 0.17880, 101.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15614, 2.19 secs\n",
      "\u001b[1m---- Epoch 96/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.16998, s2s_loss 0.16966, 98.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15094, 2.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_96_s2s_loss=0.8675.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 97/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.11125, s2s_loss 0.17339, 102.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15648, 2.20 secs\n",
      "\u001b[1m---- Epoch 98/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.12871, s2s_loss 0.17013, 102.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15935, 2.19 secs\n",
      "\u001b[1m---- Epoch 99/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.09583, s2s_loss 0.17229, 91.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16048, 2.49 secs\n",
      "\u001b[1m---- Epoch 101/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.12367, s2s_loss 0.17701, 102.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15027, 2.16 secs\n",
      "\u001b[1m---- Epoch 102/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.17113, s2s_loss 0.17491, 102.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15708, 2.19 secs\n",
      "\u001b[1m---- Epoch 103/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.17120, s2s_loss 0.17142, 100.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15352, 2.22 secs\n",
      "\u001b[1m---- Epoch 104/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.12434, s2s_loss 0.16824, 101.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15504, 2.27 secs\n",
      "\u001b[1m---- Epoch 105/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.22813, s2s_loss 0.16950, 101.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15101, 2.16 secs\n",
      "\u001b[1m---- Epoch 106/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.16320, s2s_loss 0.16747, 101.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15456, 2.17 secs\n",
      "\u001b[1m---- Epoch 107/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21610, s2s_loss 0.16826, 101.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14915, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_107_s2s_loss=0.8688.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 108/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10347, s2s_loss 0.16953, 102.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14654, 2.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_108_s2s_loss=0.8705.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 109/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.18004, s2s_loss 0.17146, 98.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15726, 2.17 secs\n",
      "\u001b[1m---- Epoch 110/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.13137, s2s_loss 0.16910, 101.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15195, 2.21 secs\n",
      "\u001b[1m---- Epoch 111/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.13620, s2s_loss 0.16386, 101.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15290, 2.18 secs\n",
      "\u001b[1m---- Epoch 112/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.13242, s2s_loss 0.16441, 101.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15276, 2.19 secs\n",
      "\u001b[1m---- Epoch 113/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.06973, s2s_loss 0.16395, 101.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15072, 2.12 secs\n",
      "\u001b[1m---- Epoch 114/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.15893, s2s_loss 0.16336, 101.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15440, 2.19 secs\n",
      "\u001b[1m---- Epoch 115/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.07589, s2s_loss 0.16173, 102.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15025, 2.21 secs\n",
      "\u001b[1m---- Epoch 116/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15706, s2s_loss 0.16048, 102.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15286, 2.10 secs\n",
      "\u001b[1m---- Epoch 117/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.08262, s2s_loss 0.16526, 102.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14850, 2.16 secs\n",
      "\u001b[1m---- Epoch 118/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.18495, s2s_loss 0.16682, 102.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15367, 2.16 secs\n",
      "\u001b[1m---- Epoch 119/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.11830, s2s_loss 0.16158, 101.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14257, 2.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_119_s2s_loss=0.8738.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 120/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.13036, s2s_loss 0.16034, 102.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14773, 2.20 secs\n",
      "\u001b[1m---- Epoch 121/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.10022, s2s_loss 0.16125, 101.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13690, 2.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_121_s2s_loss=0.8777.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 122/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.20540, s2s_loss 0.16102, 101.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15042, 2.14 secs\n",
      "\u001b[1m---- Epoch 123/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.15808, s2s_loss 0.16146, 101.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14680, 2.19 secs\n",
      "\u001b[1m---- Epoch 124/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16174, s2s_loss 0.15948, 99.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14154, 2.11 secs\n",
      "\u001b[1m---- Epoch 125/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.18564, s2s_loss 0.16398, 102.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15180, 2.21 secs\n",
      "\u001b[1m---- Epoch 126/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.18587, s2s_loss 0.15934, 101.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14988, 2.18 secs\n",
      "\u001b[1m---- Epoch 127/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.27083, s2s_loss 0.15995, 101.91 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.13755, 2.20 secs\n",
      "\u001b[1m---- Epoch 128/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.10831, s2s_loss 0.15879, 101.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15474, 2.12 secs\n",
      "\u001b[1m---- Epoch 129/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.14155, s2s_loss 0.15386, 101.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14769, 2.17 secs\n",
      "\u001b[1m---- Epoch 130/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.20119, s2s_loss 0.15457, 101.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14166, 2.18 secs\n",
      "\u001b[1m---- Epoch 131/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.25143, s2s_loss 0.15655, 94.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13703, 2.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_131_s2s_loss=0.8780.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 132/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10019, s2s_loss 0.15336, 102.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14224, 2.14 secs\n",
      "\u001b[1m---- Epoch 133/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.16376, s2s_loss 0.16243, 101.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15065, 2.17 secs\n",
      "\u001b[1m---- Epoch 134/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.19261, s2s_loss 0.16020, 101.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15359, 2.15 secs\n",
      "\u001b[1m---- Epoch 135/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.16563, s2s_loss 0.15583, 101.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14495, 2.18 secs\n",
      "\u001b[1m---- Epoch 136/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.14102, s2s_loss 0.15582, 101.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14264, 2.24 secs\n",
      "\u001b[1m---- Epoch 137/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.16300, s2s_loss 0.15704, 102.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14236, 2.19 secs\n",
      "\u001b[1m---- Epoch 138/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.18357, s2s_loss 0.15480, 102.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13645, 2.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_138_s2s_loss=0.8785.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 139/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11921, s2s_loss 0.15497, 102.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14457, 2.13 secs\n",
      "\u001b[1m---- Epoch 140/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.12637, s2s_loss 0.15327, 101.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14196, 2.16 secs\n",
      "\u001b[1m---- Epoch 141/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.22854, s2s_loss 0.15496, 101.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14364, 2.21 secs\n",
      "\u001b[1m---- Epoch 142/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.27956, s2s_loss 0.15528, 91.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13936, 2.20 secs\n",
      "\u001b[1m---- Epoch 143/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.06670, s2s_loss 0.15230, 101.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14566, 2.14 secs\n",
      "\u001b[1m---- Epoch 144/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.11383, s2s_loss 0.14589, 102.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14038, 2.20 secs\n",
      "\u001b[1m---- Epoch 145/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.14908, s2s_loss 0.15238, 101.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13677, 2.18 secs\n",
      "\u001b[1m---- Epoch 146/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.09110, s2s_loss 0.15521, 101.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13789, 2.11 secs\n",
      "\u001b[1m---- Epoch 147/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.13616, s2s_loss 0.15092, 101.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13386, 2.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_147_s2s_loss=0.8806.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 148/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17727, s2s_loss 0.15305, 102.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14027, 2.13 secs\n",
      "\u001b[1m---- Epoch 149/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.12628, s2s_loss 0.15255, 101.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14205, 2.19 secs\n",
      "\u001b[1m---- Epoch 150/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.07656, s2s_loss 0.15483, 101.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14062, 2.21 secs\n",
      "\u001b[1m---- Epoch 151/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.11011, s2s_loss 0.15252, 102.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13983, 2.18 secs\n",
      "\u001b[1m---- Epoch 152/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.17054, s2s_loss 0.15472, 102.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13676, 2.23 secs\n",
      "\u001b[1m---- Epoch 153/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.19035, s2s_loss 0.14867, 101.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13670, 2.26 secs\n",
      "\u001b[1m---- Epoch 154/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.23715, s2s_loss 0.15222, 101.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13574, 2.15 secs\n",
      "\u001b[1m---- Epoch 155/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "^C iteration 154025\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 598, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 509, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_seq2seq.py\", line 329, in train_model\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/seq2seq.py\", line 97, in step_fn_wrapper\n",
      "    output = step_fn(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/seq2seq.py\", line 82, in step_fn\n",
      "    gradient_accumulator.step(batch_loss, model)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 29, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 20 \\\n",
    "--num_workers 4 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\" \\\n",
    "--task_name \"report2negative_facts\" \\\n",
    "--report_to_negative_facts_input_output_jsonl_filepaths \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_to_negative_facts.jsonl\" \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_fact_based_report_to_negative_facts.jsonl\" \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_sentence_to_negative_facts.jsonl\" \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o-mini_sentence_to_negative_facts.jsonl\" \\\n",
    "--seq2seq_model_name \"t5\" \\\n",
    "--t5_model_name \"t5-small\" \\\n",
    "--experiment_name \"r2nf\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 43\n",
      "   batches_per_epoch: 1000\n",
      "   batch_size: 20\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: t5\n",
      "   t5_model_name: t5-small\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_142005_report2negative_facts(r2nf)_Seq2Seq(t5-small)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "   iters_to_accumulate: 4\n",
      "   override_lr: False\n",
      "   task_name: report2negative_facts\n",
      "   experiment_name: r2nf\n",
      "   multitask_name_list: None\n",
      "   task2weight: {}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: None\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_metadata_v2_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_train_jsonl_filepaths: None\n",
      "   report_nli_input_output_val_jsonl_filepaths: None\n",
      "   report_to_negative_facts_input_output_jsonl_filepaths: ['/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_to_negative_facts.jsonl', '/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_fact_based_report_to_negative_facts.jsonl', '/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_sentence_to_negative_facts.jsonl', '/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o-mini_sentence_to_negative_facts.jsonl']\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_report_facts_jsonl_filepath: None\n",
      "   interpret_cxr__label_based_predictions_filepath: None\n",
      "   interpret_cxr_challenge_data_dir: None\n",
      "   mimiccxr_integrated_report_nli_data_filepath: None\n",
      "   report_section_to_generate: None\n",
      "   include_public_test_in_train: False\n",
      "   best_k_classes: None\n",
      "   use_sentence2facts_for_nli: False\n",
      "   use_anli: False\n",
      "   use_multinli: False\n",
      "   use_snli: False\n",
      "   use_report_nli: False\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   use_report_nli_entailment_dataset: False\n",
      "   use_report_nli_paraphrases_dataset: False\n",
      "   use_numeric_templates: False\n",
      "   only_validate_nli: False\n",
      "   nli1_only_on_train: False\n",
      "   nli1_only_on_val: False\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: t5-small\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\n",
      "1e-06 3 0.0002 8 1e-06 0.0002 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "Loaded 10000 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_to_negative_facts.jsonl\n",
      "100%|███████████████████████████████████| 10000/10000 [00:04<00:00, 2355.07it/s]\n",
      "Loaded 139995 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_fact_based_report_to_negative_facts.jsonl\n",
      "100%|█████████████████████████████████| 139995/139995 [00:48<00:00, 2861.39it/s]\n",
      "Loaded 50436 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_sentence_to_negative_facts.jsonl\n",
      "100%|██████████████████████████████████| 50436/50436 [00:01<00:00, 34131.56it/s]\n",
      "Loaded 398547 input/output pairs from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o-mini_sentence_to_negative_facts.jsonl\n",
      "100%|████████████████████████████████| 398547/398547 [00:12<00:00, 32641.59it/s]\n",
      "Number of abnormal sentences: 508295\n",
      "Number of normal sentences: 53037\n",
      "Skipped 34 reports with estimated token count > 512\n",
      "len(train_dataset_1): 1000000000000000000\n",
      "len(train_dataset_2): 1000000000000000000\n",
      "len(train_dataset_3): 1000000000000000000\n",
      "len(val_dataset_1): 500\n",
      "len(val_dataset_2): 500\n",
      "len(val_dataset_3): 500\n",
      "len(merged_train_dataset): 1000000000000000000\n",
      "len(merged_val_dataset): 1500\n",
      "\u001b[1m----- Input/output examples from train_dataset_1:\u001b[0m\n",
      "mode: 1\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mloculated fluid collection along the fissures on the right. opacities representative of atypical infection. PA. pleural fluid with volume loss in the lower lung.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno increase in intra-abdominal air. IABP in similar position\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no increase in intra-abdominal air\": [\"free air in the abdomen\", \"pneumoperitoneum\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno relevant short-interval changes in the right mid lung region. Short-term followup radiographs may be helpful to re-evaluate if needed clinically.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no relevant short-interval changes in the right mid lung region\": [\"new right mid lung abnormality\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno acute cardiopulmonary abnormality appreciated\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no acute cardiopulmonary abnormality appreciated\": [\"acute cardiopulmonary disease\", \"acute heart failure\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mstablely widened cardiomediastinal silhouette. previous mild edema in the left lung has cleared. mild prominence of pulmonary interstitial markings. complete resolution of the pre-existing parenchymal opacities at the right lung base\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"previous mild edema in the left lung has cleared\": [\"left lung edema\"], \"complete resolution of the pre-existing parenchymal opacities at the right lung base\": [\"parenchymal opacity at the right lung base\"]}\u001b[0m\n",
      "\u001b[1m----- Input/output examples from train_dataset_2:\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno abnormality along the left upper extremity. subcentimeter nodules in the lungs\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no abnormality along the left upper extremity\": [\"left upper extremity fracture\", \"left upper extremity lesion\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno consolidative opacity is seen on the lateral view. no progression into total atelectasis in this area\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no consolidative opacity is seen on the lateral view\": [\"lung consolidation\"], \"no progression into total atelectasis in this area\": [\"total atelectasis in the right middle lobe medial segment\", \"total atelectasis\"]}\u001b[0m\n",
      "mode: 1\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mmild prominence of the perihilar vessels.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mstable appearance of the right hemithorax. mild degree of underlying pulmonary edema is unchanged\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"stable appearance of the right hemithorax\": [\"right hemithorax abnormality\", \"right hemithorax mass\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno engorgement of pulmonary vessels. central pulmonary vessels not engorged\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no engorgement of pulmonary vessels\": [\"pulmonary vessel engorgement\"], \"central pulmonary vessels not engorged\": [\"pulmonary vascular congestion\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno sign indicative of pneumothorax\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no sign indicative of pneumothorax\": [\"pneumothorax\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mMinimal if any interval improvement of interstitial markings. no definite evidence of residual pneumonia\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"no definite evidence of residual pneumonia\": [\"residual pneumonia\"]}\u001b[0m\n",
      "mode: 3\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mheart upper limits normal in size. worrisome infectious process.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"heart upper limits normal in size\": [\"cardiomegaly\"]}\u001b[0m\n",
      "mode: 2\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mendotracheal tube terminates well above the clavicles. upper lobes do not show pulmonary edema\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"endotracheal tube terminates well above the clavicles\": [\"endotracheal tube malposition\"], \"upper lobes do not show pulmonary edema\": [\"pulmonary edema in upper lobes\", \"upper lobe pulmonary edema\"]}\u001b[0m\n",
      "mode: 1\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft lateral costophrenic angle effusion\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1m----- Input/output example from train_dataset_3:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnormal lungs. unchanged since previous study. normal heart. no pleural effusion. no intrathoracic hematoma. normal hila. normal mediastinum. no edema. normal pleural surfaces. right subclavian infusion port ends low in the SVC. no pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"normal heart\": [\"cardiomegaly\", \"heart failure\"], \"normal lungs\": [\"lung mass\", \"lung consolidation\"], \"normal hila\": [\"hilar lymphadenopathy\", \"hilar mass\"], \"normal mediastinum\": [\"mediastinal mass\", \"mediastinal widening\"], \"normal pleural surfaces\": [\"pleural thickening\", \"pleural plaques\"], \"no edema\": [\"pulmonary edema\"], \"no pleural effusion\": [\"pleural effusion\"], \"no intrathoracic hematoma\": [\"intrathoracic hematoma\"], \"no pneumothorax\": [\"pneumothorax\"]}\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe pre-existing right basal parenchymal opacity with air bronchograms, likely reflecting aspiration or pneumonia, is smaller and better defined as on the previous image.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1m----- Input/output example from val_dataset_1:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mdual intracavitary electrode system is unchanged. Pulmonary vascular congestion and mild pulmonary edema having improved. 9:14 PM Stable small right apical pneumothorax status post chest tube removal. unable to assess for consolidation\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{}\u001b[0m\n",
      "\u001b[1m----- Input/output example from val_dataset_2:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of other change. bilateral pulmonary opacifications cleared\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"bilateral pulmonary opacifications cleared\": [\"bilateral pulmonary opacifications\"]}\u001b[0m\n",
      "\u001b[1m----- Input/output example from val_dataset_3:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno pneumothorax. unremarkable mediastinal contours. leads terminating in the right ventricle. left-sided AICD device noted. pulmonary vasculature not engorged. leads terminating in the right atrium. normal heart size. hyperinflated lungs. leads terminating in the region of the coronary sinus. unremarkable hilar contours. no acute cardiopulmonary abnormality. calcification in the aortic knob. no acute osseous abnormalities detected. no pleural effusion. lungs without focal consolidation.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m{\"normal heart size\": [\"cardiomegaly\"], \"unremarkable mediastinal contours\": [\"mediastinal mass\", \"mediastinal widening\"], \"unremarkable hilar contours\": [\"hilar lymphadenopathy\", \"hilar mass\"], \"pulmonary vasculature not engorged\": [\"pulmonary edema\"], \"lungs without focal consolidation\": [\"lung consolidation\"], \"no pleural effusion\": [\"pleural effusion\"], \"no pneumothorax\": [\"pneumothorax\"], \"no acute osseous abnormalities detected\": [\"bone fracture\", \"bone lesion\"], \"no acute cardiopulmonary abnormality\": [\"acute heart failure\", \"acute respiratory distress\"]}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq2seq_trainer.name =  report2negative_facts(r2nf)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_184937_report2negative_facts(r2nf)_Seq2Seq(t5-small)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_184937_report2negative_facts(r2nf)_Seq2Seq(t5-small)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_147_s2s_loss=0.8806.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_142005_report2negative_facts(r2nf)_Seq2Seq(t5-small)/checkpoint_147_s2s_loss=0.8806.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_184937_report2negative_facts(r2nf)_Seq2Seq(t5-small)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10834, s2s_loss 0.15660, 102.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14689, 2.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_s2s_loss=0.8712.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.25885, s2s_loss 0.15371, 102.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14630, 2.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_s2s_loss=0.8718.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 0.17163, s2s_loss 0.15312, 102.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13633, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_s2s_loss=0.8787.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.29922, s2s_loss 0.16141, 101.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15079, 2.24 secs\n",
      "\u001b[1m---- Epoch 5/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000103) ...\n",
      "loss 0.16521, s2s_loss 0.15989, 102.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14196, 2.16 secs\n",
      "\u001b[1m---- Epoch 6/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 0.12950, s2s_loss 0.15457, 102.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14179, 2.20 secs\n",
      "\u001b[1m---- Epoch 7/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.15026, s2s_loss 0.15199, 102.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13909, 2.13 secs\n",
      "\u001b[1m---- Epoch 8/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.13368, s2s_loss 0.15165, 102.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13991, 2.18 secs\n",
      "\u001b[1m---- Epoch 9/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.11094, s2s_loss 0.14881, 102.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13828, 2.16 secs\n",
      "\u001b[1m---- Epoch 10/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.12820, s2s_loss 0.15026, 103.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13567, 2.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_s2s_loss=0.8794.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.05653, s2s_loss 0.15196, 102.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14064, 2.21 secs\n",
      "\u001b[1m---- Epoch 12/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.13014, s2s_loss 0.15136, 93.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13667, 2.26 secs\n",
      "\u001b[1m---- Epoch 13/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.25170, s2s_loss 0.15225, 102.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13740, 2.23 secs\n",
      "\u001b[1m---- Epoch 14/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.15864, s2s_loss 0.15330, 102.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13615, 2.23 secs\n",
      "\u001b[1m---- Epoch 15/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.19156, s2s_loss 0.15256, 102.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14232, 2.17 secs\n",
      "\u001b[1m---- Epoch 16/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.10516, s2s_loss 0.14978, 101.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13387, 2.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_s2s_loss=0.8807.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.06882, s2s_loss 0.14911, 102.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14161, 2.22 secs\n",
      "\u001b[1m---- Epoch 18/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.19751, s2s_loss 0.14961, 102.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14031, 2.22 secs\n",
      "\u001b[1m---- Epoch 19/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.09018, s2s_loss 0.14514, 102.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13598, 2.19 secs\n",
      "\u001b[1m---- Epoch 20/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16946, s2s_loss 0.14931, 102.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13492, 2.17 secs\n",
      "\u001b[1m---- Epoch 21/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.15468, s2s_loss 0.15210, 102.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14114, 2.23 secs\n",
      "\u001b[1m---- Epoch 22/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.16594, s2s_loss 0.15077, 96.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13414, 2.20 secs\n",
      "\u001b[1m---- Epoch 23/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "loss 0.15234, s2s_loss 0.15220, 103.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13231, 2.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_s2s_loss=0.8816.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.21447, s2s_loss 0.14796, 103.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13641, 2.25 secs\n",
      "\u001b[1m---- Epoch 25/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.15103, s2s_loss 0.14944, 102.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13674, 2.21 secs\n",
      "\u001b[1m---- Epoch 26/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "loss 0.07685, s2s_loss 0.14922, 102.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13633, 2.20 secs\n",
      "\u001b[1m---- Epoch 27/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.19631, s2s_loss 0.14735, 102.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12799, 2.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_s2s_loss=0.8850.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10240, s2s_loss 0.14916, 85.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13193, 2.23 secs\n",
      "\u001b[1m---- Epoch 29/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.14467, s2s_loss 0.15055, 102.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13684, 2.22 secs\n",
      "\u001b[1m---- Epoch 30/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.19973, s2s_loss 0.14707, 86.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13936, 2.19 secs\n",
      "\u001b[1m---- Epoch 31/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.11728, s2s_loss 0.14510, 102.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13179, 2.22 secs\n",
      "\u001b[1m---- Epoch 32/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.27131, s2s_loss 0.14452, 102.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13146, 2.20 secs\n",
      "\u001b[1m---- Epoch 33/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.14259, s2s_loss 0.14529, 90.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13365, 2.23 secs\n",
      "\u001b[1m---- Epoch 34/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.15604, s2s_loss 0.14727, 102.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13800, 2.19 secs\n",
      "\u001b[1m---- Epoch 35/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.14833, s2s_loss 0.14426, 102.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13265, 2.20 secs\n",
      "\u001b[1m---- Epoch 36/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20376, s2s_loss 0.14807, 102.08 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.13571, 2.24 secs\n",
      "\u001b[1m---- Epoch 37/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.16962, s2s_loss 0.14621, 102.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13105, 2.24 secs\n",
      "\u001b[1m---- Epoch 38/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.17555, s2s_loss 0.14617, 101.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13222, 2.23 secs\n",
      "\u001b[1m---- Epoch 39/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.05698, s2s_loss 0.14422, 102.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13038, 2.21 secs\n",
      "\u001b[1m---- Epoch 40/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.07519, s2s_loss 0.14025, 102.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13298, 2.28 secs\n",
      "\u001b[1m---- Epoch 41/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.16417, s2s_loss 0.14469, 102.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13151, 2.27 secs\n",
      "\u001b[1m---- Epoch 42/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.13116, s2s_loss 0.14355, 101.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13012, 2.24 secs\n",
      "\u001b[1m---- Epoch 43/43\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.15457, s2s_loss 0.14360, 102.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13561, 2.26 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20250114_142005_report2negative_facts(r2nf)_Seq2Seq(t5-small)\" \\\n",
    "--epochs 43 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--batch_size 20 \\\n",
    "--num_workers 4 \\\n",
    "--iters_to_accumulate 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,8,1e-6,2e-4,8,1e-6\" \\\n",
    "--task_name \"report2negative_facts\" \\\n",
    "--report_to_negative_facts_input_output_jsonl_filepaths \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_to_negative_facts.jsonl\" \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_fact_based_report_to_negative_facts.jsonl\" \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o_sentence_to_negative_facts.jsonl\" \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4o-mini_sentence_to_negative_facts.jsonl\" \\\n",
    "--seq2seq_model_name \"t5\" \\\n",
    "--t5_model_name \"t5-small\" \\\n",
    "--experiment_name \"r2nf\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
