{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: None\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: facebook/vit-mae-base\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,5,2e-4,55,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 55\n",
      "   iters_to_accumulate: 5\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   mimiccxr_weight_chexpert_mode: 0.2\n",
      "   iuxray_weight_chexpert_mode: 0.05\n",
      "   padchest_weight: 1.0\n",
      "   mimiccxr_include_chexpert_mode: False\n",
      "   iuxray_include_chexpert_mode: False\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: False\n",
      "   medical_terms_frequency_filename: None\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: False\n",
      "   balanced_dataloading: False\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: None\n",
      "   mimiccxr_balanced_metadata_filename: None\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   iuxray_train_with_all: False\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: None\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: True\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_questions: False\n",
      "   n_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.mask_token', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.3.attention.attention.query.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  self.global_feat_size = 768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  n_questions = 196\n",
      "  n_questions_aux_task = None\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,5,2e-4,55,1e-6\n",
      "1e-06 5 0.0002 55 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1497: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 112507.05it/s]\n",
      "Done. Example answer: <s> aortic elongation </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 116089.25it/s]\n",
      "Done. Example answer: <s> loc paracardiac , loc left , loc cardiac , loc pleural , loc subsegmental </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 65471.01it/s]\n",
      "Done. Example answer: <s> normal </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc pectoral , loc lung field , loc left , loc lower lung field </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:26,  7.40it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc subsegmental , loc right , loc basal </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:00, 234.16it/s]\n",
      "Done!\n",
      "len(self.val_dataset) = 4398\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221228_093550_padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_orien_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221228_093550_padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_orien_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221228_093550_padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_orien_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 12.54593, a_loss 8.24504, ema 0.00000, oracc 0.16339, orien_loss 1.63645, gacc 0.51061, gloss 0.69082, b1 0.00059, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01415, padchxlmicf1 0.01394, padchxlzmacf1 0.02252, padchxlzmicf1 0.01951, padchxl_loss 0.84168, padchxlz_loss 0.90657, 124.54 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.00000, oracc 0.79559, gacc 0.50455, b1 0.00168, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01833, padchxlmicf1 0.01928, padchxlzmacf1 0.02847, padchxlzmicf1 0.02866, 33.63 secs\n",
      "Adjusting learning rate of group 0 to 2.8854e-06.\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 12.17782, a_loss 7.95425, ema 0.00000, oracc 0.81588, orien_loss 0.98066, gacc 0.59867, gloss 0.68822, b1 0.00082, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01571, padchxlmicf1 0.01139, padchxlzmacf1 0.02587, padchxlzmicf1 0.02262, padchxl_loss 0.83704, padchxlz_loss 0.89766, 124.15 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.00000, oracc 0.79695, gacc 0.65462, b1 0.00365, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01491, padchxlmicf1 0.01510, padchxlzmacf1 0.03578, padchxlzmicf1 0.03742, 33.26 secs\n",
      "Adjusting learning rate of group 0 to 8.3255e-06.\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 10.50981, a_loss 6.90024, ema 0.10588, oracc 0.89970, orien_loss 0.37926, gacc 0.66739, gloss 0.65260, b1 0.00006, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01639, padchxlmicf1 0.01450, padchxlzmacf1 0.03192, padchxlzmicf1 0.03101, padchxl_loss 0.79506, padchxlz_loss 0.84712, 121.13 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.07276, oracc 0.92906, gacc 0.79104, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02197, padchxlmicf1 0.02070, padchxlzmacf1 0.04136, padchxlzmicf1 0.05913, 33.03 secs\n",
      "Adjusting learning rate of group 0 to 2.4022e-05.\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 8.44670, a_loss 5.64101, ema 0.12558, oracc 0.93430, orien_loss 0.24918, gacc 0.76521, gloss 0.47897, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02135, padchxlmicf1 0.05336, padchxlzmacf1 0.04121, padchxlzmicf1 0.06953, padchxl_loss 0.66603, padchxlz_loss 0.73033, 121.03 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.07276, oracc 0.93633, gacc 0.89245, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02331, padchxlmicf1 0.09723, padchxlzmacf1 0.04298, padchxlzmicf1 0.08666, 33.55 secs\n",
      "Adjusting learning rate of group 0 to 6.9314e-05.\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000069) ...\n",
      "loss 7.08865, a_loss 4.54018, ema 0.12491, oracc 0.95291, orien_loss 0.16604, gacc 0.91473, gloss 0.20286, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02555, padchxlmicf1 0.11336, padchxlzmacf1 0.04381, padchxlzmicf1 0.09560, padchxl_loss 0.50867, padchxlz_loss 0.61217, 120.63 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.07094, oracc 0.95884, gacc 0.93429, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.03068, padchxlmicf1 0.10235, padchxlzmacf1 0.04829, padchxlzmicf1 0.11424, 33.24 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 5.44726, a_loss 3.29824, ema 0.13709, oracc 0.91564, orien_loss 0.26994, gacc 0.87267, gloss 0.29470, b1 0.06142, b2 0.04310, b3 0.02855, b4 0.02029, padchxlmacf1 0.02698, padchxlmicf1 0.09043, padchxlzmacf1 0.04377, padchxlzmicf1 0.10077, padchxl_loss 0.45579, padchxlz_loss 0.57384, 120.65 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ema 0.13574, oracc 0.95862, gacc 0.91996, b1 0.11605, b2 0.06767, b3 0.03733, b4 0.02476, padchxlmacf1 0.03230, padchxlmicf1 0.09321, padchxlzmacf1 0.04977, padchxlzmicf1 0.10713, 33.30 secs\n",
      "Adjusting learning rate of group 0 to 1.8163e-04.\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000182) ...\n",
      "loss 4.71170, a_loss 2.50128, ema 0.24212, oracc 0.96339, orien_loss 0.12858, gacc 0.93388, gloss 0.15769, b1 0.20032, b2 0.13933, b3 0.09271, b4 0.06494, padchxlmacf1 0.03027, padchxlmicf1 0.10839, padchxlzmacf1 0.04845, padchxlzmicf1 0.10579, padchxl_loss 0.43548, padchxlz_loss 0.56795, 121.11 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.19782, oracc 0.96794, gacc 0.95543, b1 0.17995, b2 0.12809, b3 0.07497, b4 0.04927, padchxlmacf1 0.03571, padchxlmicf1 0.10581, padchxlzmacf1 0.05913, padchxlzmicf1 0.13849, 33.76 secs\n",
      "Adjusting learning rate of group 0 to 1.6495e-04.\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000165) ...\n",
      "loss 4.41343, a_loss 2.10395, ema 0.25891, oracc 0.97091, orien_loss 0.09928, gacc 0.95006, gloss 0.12413, b1 0.32281, b2 0.23325, b3 0.15846, b4 0.11160, padchxlmacf1 0.03574, padchxlmicf1 0.12402, padchxlzmacf1 0.05443, padchxlzmicf1 0.12394, padchxl_loss 0.42037, padchxlz_loss 0.55020, 122.12 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.24079, oracc 0.97203, gacc 0.95521, b1 0.14670, b2 0.10620, b3 0.06472, b4 0.04348, padchxlmacf1 0.04226, padchxlmicf1 0.13179, padchxlzmacf1 0.06714, padchxlzmicf1 0.16851, 33.49 secs\n",
      "Adjusting learning rate of group 0 to 1.4980e-04.\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "ema 0.23374, oracc 0.97271, gacc 0.96066, b1 0.17200, b2 0.12872, b3 0.08741, b4 0.06297, padchxlmacf1 0.04975, padchxlmicf1 0.13774, padchxlzmacf1 0.07059, padchxlzmicf1 0.17693, 33.42 secs\n",
      "Adjusting learning rate of group 0 to 1.3604e-04.\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000136) ...\n",
      "loss 2.84366, a_loss 1.82781, ema 0.27364, oracc 0.97733, orien_loss 0.08272, gacc 0.96412, gloss 0.09201, b1 0.40032, b2 0.29976, b3 0.21412, b4 0.15506, padchxlmacf1 0.04515, padchxlmicf1 0.13096, padchxlzmacf1 0.06213, padchxlzmicf1 0.14116, padchxl_loss 0.39914, padchxlz_loss 0.53001, 121.23 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.24238, oracc 0.97499, gacc 0.96430, b1 0.15151, b2 0.11428, b3 0.08145, b4 0.06175, padchxlmacf1 0.05364, padchxlmicf1 0.13985, padchxlzmacf1 0.07399, padchxlzmicf1 0.16572, 33.69 secs\n",
      "Adjusting learning rate of group 0 to 1.2355e-04.\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000124) ...\n",
      "loss 2.71032, a_loss 1.76798, ema 0.26697, oracc 0.97679, orien_loss 0.07974, gacc 0.96242, gloss 0.09262, b1 0.40920, b2 0.30763, b3 0.22120, b4 0.16168, padchxlmacf1 0.04726, padchxlmicf1 0.13118, padchxlzmacf1 0.06258, padchxlzmicf1 0.14302, padchxl_loss 0.39001, padchxlz_loss 0.52728, 124.03 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.22988, oracc 0.97908, gacc 0.96885, b1 0.23068, b2 0.17122, b3 0.12551, b4 0.09626, padchxlmacf1 0.05609, padchxlmicf1 0.13870, padchxlzmacf1 0.07556, padchxlzmicf1 0.17346, 33.87 secs\n",
      "Adjusting learning rate of group 0 to 1.1220e-04.\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000112) ...\n",
      "loss 2.98280, a_loss 1.70896, ema 0.31158, oracc 0.98291, orien_loss 0.06602, gacc 0.96624, gloss 0.08842, b1 0.44113, b2 0.32992, b3 0.23803, b4 0.17390, padchxlmacf1 0.04700, padchxlmicf1 0.13058, padchxlzmacf1 0.06464, padchxlzmicf1 0.13951, padchxl_loss 0.39018, padchxlz_loss 0.52944, 121.46 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34425, oracc 0.98090, gacc 0.96794, b1 0.29449, b2 0.20973, b3 0.15407, b4 0.11779, padchxlmacf1 0.05362, padchxlmicf1 0.14154, padchxlzmacf1 0.07504, padchxlzmicf1 0.17129, 33.99 secs\n",
      "Adjusting learning rate of group 0 to 1.0190e-04.\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000102) ...\n",
      "loss 2.79017, a_loss 1.64413, ema 0.36085, oracc 0.98055, orien_loss 0.06996, gacc 0.96964, gloss 0.07971, b1 0.46994, b2 0.35079, b3 0.25528, b4 0.18743, padchxlmacf1 0.05084, padchxlmicf1 0.13641, padchxlzmacf1 0.06597, padchxlzmicf1 0.14371, padchxl_loss 0.38480, padchxlz_loss 0.52068, 124.05 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34948, oracc 0.98022, gacc 0.97431, b1 0.27026, b2 0.18136, b3 0.12774, b4 0.09434, padchxlmacf1 0.05751, padchxlmicf1 0.14268, padchxlzmacf1 0.07665, padchxlzmicf1 0.17340, 35.65 secs\n",
      "Adjusting learning rate of group 0 to 9.2541e-05.\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000093) ...\n",
      "loss 2.51864, a_loss 1.61770, ema 0.36485, oracc 0.98194, orien_loss 0.06136, gacc 0.97061, gloss 0.08109, b1 0.48511, b2 0.36244, b3 0.26487, b4 0.19508, padchxlmacf1 0.05104, padchxlmicf1 0.13738, padchxlzmacf1 0.06678, padchxlzmicf1 0.14341, padchxl_loss 0.37904, padchxlz_loss 0.51571, 125.11 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34357, oracc 0.98272, gacc 0.96680, b1 0.29401, b2 0.20856, b3 0.15129, b4 0.11324, padchxlmacf1 0.05934, padchxlmicf1 0.14677, padchxlzmacf1 0.08006, padchxlzmicf1 0.17645, 35.49 secs\n",
      "Adjusting learning rate of group 0 to 8.4042e-05.\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000084) ...\n",
      "loss 2.72045, a_loss 1.59122, ema 0.36594, oracc 0.98345, orien_loss 0.05906, gacc 0.97139, gloss 0.07406, b1 0.48463, b2 0.36534, b3 0.27040, b4 0.20132, padchxlmacf1 0.05058, padchxlmicf1 0.13903, padchxlzmacf1 0.06703, padchxlzmicf1 0.14539, padchxl_loss 0.37897, padchxlz_loss 0.51346, 125.35 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35539, oracc 0.98408, gacc 0.97840, b1 0.30651, b2 0.21391, b3 0.15477, b4 0.11486, padchxlmacf1 0.06213, padchxlmicf1 0.15128, padchxlzmacf1 0.07855, padchxlzmicf1 0.17698, 35.73 secs\n",
      "Adjusting learning rate of group 0 to 7.6324e-05.\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000076) ...\n",
      "loss 2.76121, a_loss 1.58252, ema 0.35867, oracc 0.98691, orien_loss 0.04929, gacc 0.97382, gloss 0.06628, b1 0.48187, b2 0.36383, b3 0.27003, b4 0.20106, padchxlmacf1 0.05233, padchxlmicf1 0.13662, padchxlzmacf1 0.07010, padchxlzmicf1 0.15079, padchxl_loss 0.38162, padchxlz_loss 0.51458, 125.68 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34970, oracc 0.98704, gacc 0.97226, b1 0.31171, b2 0.21854, b3 0.15845, b4 0.11818, padchxlmacf1 0.06361, padchxlmicf1 0.14746, padchxlzmacf1 0.07908, padchxlzmicf1 0.16877, 35.06 secs\n",
      "Adjusting learning rate of group 0 to 6.9314e-05.\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000069) ...\n",
      "loss 2.55059, a_loss 1.55215, ema 0.36061, oracc 0.98624, orien_loss 0.05552, gacc 0.97467, gloss 0.06985, b1 0.49527, b2 0.37701, b3 0.28153, b4 0.21096, padchxlmacf1 0.05646, padchxlmicf1 0.14628, padchxlzmacf1 0.07274, padchxlzmicf1 0.15584, padchxl_loss 0.37368, padchxlz_loss 0.50614, 127.73 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.33697, oracc 0.98340, gacc 0.97863, b1 0.31134, b2 0.22292, b3 0.16493, b4 0.12443, padchxlmacf1 0.06667, padchxlmicf1 0.14649, padchxlzmacf1 0.08164, padchxlzmicf1 0.17731, 35.43 secs\n",
      "Adjusting learning rate of group 0 to 6.2949e-05.\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 2.56262, a_loss 1.52758, ema 0.36267, oracc 0.98394, orien_loss 0.05900, gacc 0.97527, gloss 0.06479, b1 0.49301, b2 0.37566, b3 0.28206, b4 0.21386, padchxlmacf1 0.05501, padchxlmicf1 0.14381, padchxlzmacf1 0.07028, padchxlzmicf1 0.14873, padchxl_loss 0.37182, padchxlz_loss 0.50870, 127.51 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.32106, oracc 0.98772, gacc 0.98067, b1 0.33030, b2 0.24307, b3 0.18216, b4 0.13890, padchxlmacf1 0.06073, padchxlmicf1 0.13758, padchxlzmacf1 0.07857, padchxlzmicf1 0.18088, 34.69 secs\n",
      "Adjusting learning rate of group 0 to 5.7168e-05.\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000057) ...\n",
      "loss 2.41682, a_loss 1.51043, ema 0.36394, oracc 0.98582, orien_loss 0.05526, gacc 0.97648, gloss 0.06507, b1 0.49766, b2 0.38003, b3 0.28646, b4 0.21737, padchxlmacf1 0.05856, padchxlmicf1 0.14758, padchxlzmacf1 0.07359, padchxlzmicf1 0.15157, padchxl_loss 0.36703, padchxlz_loss 0.50605, 127.66 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.33970, oracc 0.99068, gacc 0.98204, b1 0.33534, b2 0.24116, b3 0.17730, b4 0.13206, padchxlmacf1 0.06731, padchxlmicf1 0.15176, padchxlzmacf1 0.08393, padchxlzmicf1 0.18348, 34.78 secs\n",
      "Adjusting learning rate of group 0 to 5.1917e-05.\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.66668, a_loss 1.51476, ema 0.36685, oracc 0.98733, orien_loss 0.05024, gacc 0.97824, gloss 0.05830, b1 0.49735, b2 0.37912, b3 0.28579, b4 0.21648, padchxlmacf1 0.06014, padchxlmicf1 0.14942, padchxlzmacf1 0.07438, padchxlzmicf1 0.15841, padchxl_loss 0.36632, padchxlz_loss 0.49999, 125.00 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34561, oracc 0.98954, gacc 0.98272, b1 0.33333, b2 0.24465, b3 0.18331, b4 0.13994, padchxlmacf1 0.07287, padchxlmicf1 0.15471, padchxlzmacf1 0.08663, padchxlzmicf1 0.17537, 34.17 secs\n",
      "Adjusting learning rate of group 0 to 4.7149e-05.\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 2.29425, a_loss 1.48780, ema 0.36842, oracc 0.98788, orien_loss 0.04850, gacc 0.97952, gloss 0.05576, b1 0.50151, b2 0.38650, b3 0.29523, b4 0.22677, padchxlmacf1 0.05922, padchxlmicf1 0.15075, padchxlzmacf1 0.07618, padchxlzmicf1 0.15637, padchxl_loss 0.36153, padchxlz_loss 0.49981, 124.41 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.33834, oracc 0.98863, gacc 0.98590, b1 0.34793, b2 0.26172, b3 0.19957, b4 0.15486, padchxlmacf1 0.07050, padchxlmicf1 0.15047, padchxlzmacf1 0.08769, padchxlzmicf1 0.17718, 34.48 secs\n",
      "Adjusting learning rate of group 0 to 4.2819e-05.\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 2.66438, a_loss 1.47982, ema 0.36370, oracc 0.98794, orien_loss 0.04584, gacc 0.97776, gloss 0.05980, b1 0.50446, b2 0.38882, b3 0.29643, b4 0.22736, padchxlmacf1 0.06192, padchxlmicf1 0.15366, padchxlzmacf1 0.07596, padchxlzmicf1 0.15755, padchxl_loss 0.35857, padchxlz_loss 0.49340, 124.14 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34129, oracc 0.98977, gacc 0.98863, b1 0.33499, b2 0.24906, b3 0.18944, b4 0.14624, padchxlmacf1 0.07367, padchxlmicf1 0.15595, padchxlzmacf1 0.09155, padchxlzmicf1 0.18613, 34.40 secs\n",
      "Adjusting learning rate of group 0 to 3.8887e-05.\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 2.64374, a_loss 1.49179, ema 0.36285, oracc 0.99061, orien_loss 0.03987, gacc 0.98158, gloss 0.04989, b1 0.50655, b2 0.38916, b3 0.29495, b4 0.22365, padchxlmacf1 0.06198, padchxlmicf1 0.15164, padchxlzmacf1 0.07803, padchxlzmicf1 0.15866, padchxl_loss 0.36159, padchxlz_loss 0.50160, 125.09 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34015, oracc 0.99045, gacc 0.98795, b1 0.32595, b2 0.24583, b3 0.18726, b4 0.14337, padchxlmacf1 0.07388, padchxlmicf1 0.16484, padchxlzmacf1 0.09050, padchxlzmicf1 0.19111, 35.18 secs\n",
      "Adjusting learning rate of group 0 to 3.5316e-05.\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000035) ...\n",
      "loss 2.01839, a_loss 1.47119, ema 0.36200, oracc 0.98885, orien_loss 0.04529, gacc 0.98400, gloss 0.04773, b1 0.50877, b2 0.39198, b3 0.29894, b4 0.22897, padchxlmacf1 0.06548, padchxlmicf1 0.15683, padchxlzmacf1 0.07936, padchxlzmicf1 0.16362, padchxl_loss 0.35765, padchxlz_loss 0.49536, 128.41 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34789, oracc 0.99000, gacc 0.98772, b1 0.33933, b2 0.25291, b3 0.19300, b4 0.14822, padchxlmacf1 0.07533, padchxlmicf1 0.15936, padchxlzmacf1 0.09025, padchxlzmicf1 0.18749, 34.49 secs\n",
      "Adjusting learning rate of group 0 to 3.2072e-05.\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 2.34209, a_loss 1.47025, ema 0.36424, oracc 0.98818, orien_loss 0.04773, gacc 0.98279, gloss 0.05175, b1 0.51073, b2 0.39385, b3 0.30013, b4 0.23015, padchxlmacf1 0.06405, padchxlmicf1 0.15723, padchxlzmacf1 0.08045, padchxlzmicf1 0.16119, padchxl_loss 0.35847, padchxlz_loss 0.49790, 123.85 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34357, oracc 0.98977, gacc 0.98954, b1 0.35255, b2 0.26230, b3 0.19800, b4 0.15117, padchxlmacf1 0.07290, padchxlmicf1 0.15752, padchxlzmacf1 0.09339, padchxlzmicf1 0.18519, 34.33 secs\n",
      "Adjusting learning rate of group 0 to 2.9127e-05.\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 2.23093, a_loss 1.46370, ema 0.36715, oracc 0.98982, orien_loss 0.04297, gacc 0.98564, gloss 0.04259, b1 0.51132, b2 0.39461, b3 0.30213, b4 0.23267, padchxlmacf1 0.06483, padchxlmicf1 0.15765, padchxlzmacf1 0.08203, padchxlzmicf1 0.16296, padchxl_loss 0.35249, padchxlz_loss 0.49071, 124.92 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.33925, oracc 0.99227, gacc 0.98795, b1 0.34085, b2 0.25238, b3 0.18907, b4 0.14268, padchxlmacf1 0.07460, padchxlmicf1 0.16099, padchxlzmacf1 0.09280, padchxlzmicf1 0.19062, 35.15 secs\n",
      "Adjusting learning rate of group 0 to 2.6452e-05.\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 2.32457, a_loss 1.44896, ema 0.37527, oracc 0.99109, orien_loss 0.04041, gacc 0.98261, gloss 0.04553, b1 0.51870, b2 0.39976, b3 0.30493, b4 0.23300, padchxlmacf1 0.06578, padchxlmicf1 0.16620, padchxlzmacf1 0.08118, padchxlzmicf1 0.16685, padchxl_loss 0.34955, padchxlz_loss 0.48341, 128.71 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34766, oracc 0.99068, gacc 0.98795, b1 0.34146, b2 0.25656, b3 0.19595, b4 0.15126, padchxlmacf1 0.07774, padchxlmicf1 0.16644, padchxlzmacf1 0.09625, padchxlzmicf1 0.19525, 36.08 secs\n",
      "Adjusting learning rate of group 0 to 2.4022e-05.\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.43445, a_loss 1.43510, ema 0.37448, oracc 0.99091, orien_loss 0.03679, gacc 0.98685, gloss 0.04098, b1 0.52212, b2 0.40451, b3 0.31050, b4 0.23989, padchxlmacf1 0.06798, padchxlmicf1 0.16805, padchxlzmacf1 0.08349, padchxlzmicf1 0.16909, padchxl_loss 0.34601, padchxlz_loss 0.48807, 131.77 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34629, oracc 0.99068, gacc 0.99295, b1 0.34297, b2 0.25611, b3 0.19607, b4 0.15163, padchxlmacf1 0.07540, padchxlmicf1 0.16401, padchxlzmacf1 0.09634, padchxlzmicf1 0.19298, 36.61 secs\n",
      "Adjusting learning rate of group 0 to 2.1816e-05.\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 2.29035, a_loss 1.44621, ema 0.36703, oracc 0.99194, orien_loss 0.03275, gacc 0.98897, gloss 0.03555, b1 0.51556, b2 0.39976, b3 0.30702, b4 0.23625, padchxlmacf1 0.06579, padchxlmicf1 0.15915, padchxlzmacf1 0.08335, padchxlzmicf1 0.16318, padchxl_loss 0.34962, padchxlz_loss 0.48639, 134.44 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.33606, oracc 0.99272, gacc 0.99113, b1 0.35344, b2 0.26100, b3 0.19631, b4 0.14862, padchxlmacf1 0.07627, padchxlmicf1 0.16136, padchxlzmacf1 0.09897, padchxlzmicf1 0.19378, 37.86 secs\n",
      "Adjusting learning rate of group 0 to 1.9813e-05.\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 2.26251, a_loss 1.45448, ema 0.36473, oracc 0.99164, orien_loss 0.03729, gacc 0.98836, gloss 0.03622, b1 0.51769, b2 0.39904, b3 0.30328, b4 0.23099, padchxlmacf1 0.07112, padchxlmicf1 0.16124, padchxlzmacf1 0.08223, padchxlzmicf1 0.16690, padchxl_loss 0.34950, padchxlz_loss 0.48207, 129.74 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35198, oracc 0.99454, gacc 0.99272, b1 0.33850, b2 0.25639, b3 0.19829, b4 0.15462, padchxlmacf1 0.08168, padchxlmicf1 0.17466, padchxlzmacf1 0.09708, padchxlzmicf1 0.19892, 34.71 secs\n",
      "Adjusting learning rate of group 0 to 1.7993e-05.\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 2.20040, a_loss 1.43466, ema 0.37267, oracc 0.99236, orien_loss 0.03732, gacc 0.98976, gloss 0.03611, b1 0.51536, b2 0.39947, b3 0.30707, b4 0.23730, padchxlmacf1 0.07013, padchxlmicf1 0.16448, padchxlzmacf1 0.08357, padchxlzmicf1 0.17237, padchxl_loss 0.35001, padchxlz_loss 0.48244, 125.94 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34993, oracc 0.99454, gacc 0.99386, b1 0.34176, b2 0.25858, b3 0.19934, b4 0.15483, padchxlmacf1 0.08364, padchxlmicf1 0.17218, padchxlzmacf1 0.10054, padchxlzmicf1 0.20056, 35.98 secs\n",
      "Adjusting learning rate of group 0 to 1.6341e-05.\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 2.55611, a_loss 1.43290, ema 0.37030, oracc 0.99145, orien_loss 0.03579, gacc 0.98970, gloss 0.03268, b1 0.51855, b2 0.40243, b3 0.30936, b4 0.23824, padchxlmacf1 0.07031, padchxlmicf1 0.16314, padchxlzmacf1 0.08296, padchxlzmicf1 0.17043, padchxl_loss 0.34827, padchxlz_loss 0.48111, 130.03 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34811, oracc 0.99386, gacc 0.99363, b1 0.34846, b2 0.26359, b3 0.20260, b4 0.15606, padchxlmacf1 0.08193, padchxlmicf1 0.17299, padchxlzmacf1 0.10401, padchxlzmicf1 0.19985, 37.15 secs\n",
      "Adjusting learning rate of group 0 to 1.4840e-05.\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.22831, a_loss 1.42472, ema 0.36285, oracc 0.99412, orien_loss 0.02802, gacc 0.99127, gloss 0.03280, b1 0.52076, b2 0.40485, b3 0.31073, b4 0.23901, padchxlmacf1 0.07193, padchxlmicf1 0.16932, padchxlzmacf1 0.08704, padchxlzmicf1 0.17599, padchxl_loss 0.34353, padchxlz_loss 0.48410, 132.46 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34970, oracc 0.99432, gacc 0.99250, b1 0.35114, b2 0.26554, b3 0.20524, b4 0.15969, padchxlmacf1 0.08748, padchxlmicf1 0.17233, padchxlzmacf1 0.10050, padchxlzmicf1 0.20000, 36.72 secs\n",
      "Adjusting learning rate of group 0 to 1.3477e-05.\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 2.83478, a_loss 1.43374, ema 0.35855, oracc 0.99248, orien_loss 0.03243, gacc 0.99242, gloss 0.02883, b1 0.51771, b2 0.40146, b3 0.30787, b4 0.23588, padchxlmacf1 0.07098, padchxlmicf1 0.16574, padchxlzmacf1 0.08517, padchxlzmicf1 0.17326, padchxl_loss 0.34439, padchxlz_loss 0.48679, 134.47 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34607, oracc 0.99432, gacc 0.99363, b1 0.34549, b2 0.26198, b3 0.20212, b4 0.15638, padchxlmacf1 0.08591, padchxlmicf1 0.17346, padchxlzmacf1 0.10113, padchxlzmicf1 0.20232, 37.98 secs\n",
      "Adjusting learning rate of group 0 to 1.2239e-05.\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 2.52046, a_loss 1.41330, ema 0.37018, oracc 0.99430, orien_loss 0.02811, gacc 0.99321, gloss 0.02740, b1 0.52391, b2 0.40906, b3 0.31602, b4 0.24413, padchxlmacf1 0.07436, padchxlmicf1 0.16928, padchxlzmacf1 0.08689, padchxlzmicf1 0.17326, padchxl_loss 0.34108, padchxlz_loss 0.47756, 135.78 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34357, oracc 0.99500, gacc 0.99545, b1 0.36226, b2 0.27145, b3 0.20752, b4 0.15907, padchxlmacf1 0.08621, padchxlmicf1 0.17326, padchxlzmacf1 0.10429, padchxlzmicf1 0.20275, 37.31 secs\n",
      "Adjusting learning rate of group 0 to 1.1115e-05.\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 2.29392, a_loss 1.41097, ema 0.36745, oracc 0.99473, orien_loss 0.02846, gacc 0.99455, gloss 0.02292, b1 0.52546, b2 0.40827, b3 0.31429, b4 0.24251, padchxlmacf1 0.07216, padchxlmicf1 0.16709, padchxlzmacf1 0.08586, padchxlzmicf1 0.17056, padchxl_loss 0.33927, padchxlz_loss 0.47572, 134.30 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34720, oracc 0.99477, gacc 0.99500, b1 0.34672, b2 0.26409, b3 0.20359, b4 0.15722, padchxlmacf1 0.08819, padchxlmicf1 0.17841, padchxlzmacf1 0.10498, padchxlzmicf1 0.20153, 37.26 secs\n",
      "Adjusting learning rate of group 0 to 1.0095e-05.\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.13607, a_loss 1.41794, ema 0.36558, oracc 0.99376, orien_loss 0.02805, gacc 0.99467, gloss 0.02264, b1 0.52539, b2 0.40974, b3 0.31672, b4 0.24501, padchxlmacf1 0.07588, padchxlmicf1 0.17065, padchxlzmacf1 0.08698, padchxlzmicf1 0.17473, padchxl_loss 0.34453, padchxlz_loss 0.47628, 137.02 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34834, oracc 0.99500, gacc 0.99432, b1 0.34143, b2 0.25893, b3 0.20022, b4 0.15523, padchxlmacf1 0.09078, padchxlmicf1 0.17814, padchxlzmacf1 0.11069, padchxlzmicf1 0.20417, 37.67 secs\n",
      "Adjusting learning rate of group 0 to 9.1675e-06.\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.94363, a_loss 1.42000, ema 0.36612, oracc 0.99515, orien_loss 0.02569, gacc 0.99424, gloss 0.02407, b1 0.52525, b2 0.40884, b3 0.31529, b4 0.24385, padchxlmacf1 0.07400, padchxlmicf1 0.16901, padchxlzmacf1 0.08817, padchxlzmicf1 0.17520, padchxl_loss 0.33693, padchxlz_loss 0.47640, 137.54 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34857, oracc 0.99523, gacc 0.99477, b1 0.33969, b2 0.25905, b3 0.19975, b4 0.15429, padchxlmacf1 0.09121, padchxlmicf1 0.18212, padchxlzmacf1 0.10895, padchxlzmicf1 0.20990, 38.36 secs\n",
      "Adjusting learning rate of group 0 to 8.3255e-06.\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.43296, a_loss 1.41208, ema 0.36873, oracc 0.99497, orien_loss 0.02325, gacc 0.99424, gloss 0.02411, b1 0.52545, b2 0.40866, b3 0.31463, b4 0.24238, padchxlmacf1 0.07426, padchxlmicf1 0.16892, padchxlzmacf1 0.08734, padchxlzmicf1 0.17381, padchxl_loss 0.33878, padchxlz_loss 0.47461, 137.43 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34993, oracc 0.99500, gacc 0.99568, b1 0.35360, b2 0.26900, b3 0.20653, b4 0.16003, padchxlmacf1 0.08861, padchxlmicf1 0.17899, padchxlzmacf1 0.11198, padchxlzmicf1 0.20631, 38.57 secs\n",
      "Adjusting learning rate of group 0 to 7.5609e-06.\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.24759, a_loss 1.40789, ema 0.37036, oracc 0.99594, orien_loss 0.02166, gacc 0.99509, gloss 0.02369, b1 0.53057, b2 0.41345, b3 0.31878, b4 0.24632, padchxlmacf1 0.07713, padchxlmicf1 0.17652, padchxlzmacf1 0.08882, padchxlzmicf1 0.18038, padchxl_loss 0.33948, padchxlz_loss 0.47304, 136.49 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35152, oracc 0.99568, gacc 0.99659, b1 0.35160, b2 0.26720, b3 0.20621, b4 0.15986, padchxlmacf1 0.08974, padchxlmicf1 0.17659, padchxlzmacf1 0.11140, padchxlzmicf1 0.20479, 39.39 secs\n",
      "Adjusting learning rate of group 0 to 6.8665e-06.\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.26891, a_loss 1.39894, ema 0.37436, oracc 0.99552, orien_loss 0.02432, gacc 0.99424, gloss 0.02597, b1 0.53009, b2 0.41392, b3 0.32093, b4 0.24840, padchxlmacf1 0.07969, padchxlmicf1 0.17519, padchxlzmacf1 0.08935, padchxlzmicf1 0.17665, padchxl_loss 0.33340, padchxlz_loss 0.46917, 136.54 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35039, oracc 0.99545, gacc 0.99636, b1 0.33992, b2 0.26061, b3 0.20174, b4 0.15669, padchxlmacf1 0.08953, padchxlmicf1 0.18006, padchxlzmacf1 0.10854, padchxlzmicf1 0.21148, 39.25 secs\n",
      "Adjusting learning rate of group 0 to 6.2359e-06.\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.31869, a_loss 1.40421, ema 0.37103, oracc 0.99685, orien_loss 0.01866, gacc 0.99545, gloss 0.02140, b1 0.53417, b2 0.41537, b3 0.31991, b4 0.24619, padchxlmacf1 0.07754, padchxlmicf1 0.17523, padchxlzmacf1 0.09068, padchxlzmicf1 0.18024, padchxl_loss 0.33086, padchxlz_loss 0.46848, 138.44 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34834, oracc 0.99568, gacc 0.99727, b1 0.35119, b2 0.26653, b3 0.20484, b4 0.15777, padchxlmacf1 0.08959, padchxlmicf1 0.17788, padchxlzmacf1 0.11287, padchxlzmicf1 0.20806, 40.47 secs\n",
      "Adjusting learning rate of group 0 to 5.6632e-06.\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.97497, a_loss 1.41382, ema 0.36691, oracc 0.99697, orien_loss 0.01691, gacc 0.99618, gloss 0.01852, b1 0.52241, b2 0.40697, b3 0.31394, b4 0.24111, padchxlmacf1 0.07614, padchxlmicf1 0.17592, padchxlzmacf1 0.09280, padchxlzmicf1 0.18237, padchxl_loss 0.33862, padchxlz_loss 0.46684, 138.26 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.34948, oracc 0.99568, gacc 0.99591, b1 0.35280, b2 0.26795, b3 0.20652, b4 0.15966, padchxlmacf1 0.09015, padchxlmicf1 0.17986, padchxlzmacf1 0.11189, padchxlzmicf1 0.20808, 39.25 secs\n",
      "Adjusting learning rate of group 0 to 5.1431e-06.\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.26300, a_loss 1.39923, ema 0.37115, oracc 0.99606, orien_loss 0.02102, gacc 0.99655, gloss 0.01691, b1 0.53045, b2 0.41553, b3 0.32223, b4 0.25057, padchxlmacf1 0.07796, padchxlmicf1 0.17568, padchxlzmacf1 0.09314, padchxlzmicf1 0.17961, padchxl_loss 0.33553, padchxlz_loss 0.46747, 137.96 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35130, oracc 0.99636, gacc 0.99659, b1 0.34070, b2 0.25974, b3 0.20046, b4 0.15517, padchxlmacf1 0.09165, padchxlmicf1 0.18046, padchxlzmacf1 0.11267, padchxlzmicf1 0.20899, 38.87 secs\n",
      "Adjusting learning rate of group 0 to 4.6708e-06.\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.10603, a_loss 1.40043, ema 0.37091, oracc 0.99642, orien_loss 0.01855, gacc 0.99509, gloss 0.01954, b1 0.53489, b2 0.41759, b3 0.32318, b4 0.25013, padchxlmacf1 0.07631, padchxlmicf1 0.17760, padchxlzmacf1 0.09040, padchxlzmicf1 0.18211, padchxl_loss 0.33119, padchxlz_loss 0.46424, 138.31 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35152, oracc 0.99636, gacc 0.99750, b1 0.34474, b2 0.26267, b3 0.20275, b4 0.15736, padchxlmacf1 0.09158, padchxlmicf1 0.18445, padchxlzmacf1 0.11406, padchxlzmicf1 0.21324, 38.28 secs\n",
      "Adjusting learning rate of group 0 to 4.2418e-06.\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.38000, a_loss 1.40052, ema 0.37206, oracc 0.99612, orien_loss 0.02298, gacc 0.99648, gloss 0.01738, b1 0.52727, b2 0.40835, b3 0.31241, b4 0.23908, padchxlmacf1 0.07813, padchxlmicf1 0.17447, padchxlzmacf1 0.09297, padchxlzmicf1 0.18074, padchxl_loss 0.33089, padchxlz_loss 0.46340, 135.61 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35175, oracc 0.99636, gacc 0.99659, b1 0.33586, b2 0.25765, b3 0.19950, b4 0.15488, padchxlmacf1 0.09211, padchxlmicf1 0.18152, padchxlzmacf1 0.11286, padchxlzmicf1 0.21078, 38.41 secs\n",
      "Adjusting learning rate of group 0 to 3.8523e-06.\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.98567, a_loss 1.39605, ema 0.37552, oracc 0.99697, orien_loss 0.01789, gacc 0.99655, gloss 0.01657, b1 0.52724, b2 0.41095, b3 0.31841, b4 0.24695, padchxlmacf1 0.08077, padchxlmicf1 0.17789, padchxlzmacf1 0.09405, padchxlzmicf1 0.18298, padchxl_loss 0.32869, padchxlz_loss 0.46725, 138.15 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35039, oracc 0.99636, gacc 0.99659, b1 0.34376, b2 0.26335, b3 0.20374, b4 0.15815, padchxlmacf1 0.09188, padchxlmicf1 0.18247, padchxlzmacf1 0.11323, padchxlzmicf1 0.20950, 38.14 secs\n",
      "Adjusting learning rate of group 0 to 3.4985e-06.\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.79918, a_loss 1.39265, ema 0.37073, oracc 0.99655, orien_loss 0.01959, gacc 0.99570, gloss 0.02213, b1 0.53260, b2 0.41739, b3 0.32476, b4 0.25250, padchxlmacf1 0.07754, padchxlmicf1 0.17560, padchxlzmacf1 0.09120, padchxlzmicf1 0.18236, padchxl_loss 0.33421, padchxlz_loss 0.46234, 138.82 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35221, oracc 0.99613, gacc 0.99750, b1 0.34908, b2 0.26621, b3 0.20554, b4 0.15956, padchxlmacf1 0.09120, padchxlmicf1 0.18183, padchxlzmacf1 0.11338, padchxlzmicf1 0.21116, 38.45 secs\n",
      "Adjusting learning rate of group 0 to 3.1772e-06.\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.59458, a_loss 1.40208, ema 0.36758, oracc 0.99642, orien_loss 0.01917, gacc 0.99782, gloss 0.01328, b1 0.52999, b2 0.41406, b3 0.32024, b4 0.24766, padchxlmacf1 0.08295, padchxlmicf1 0.17781, padchxlzmacf1 0.09562, padchxlzmicf1 0.18307, padchxl_loss 0.33233, padchxlz_loss 0.46866, 138.87 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35107, oracc 0.99636, gacc 0.99750, b1 0.34594, b2 0.26444, b3 0.20441, b4 0.15849, padchxlmacf1 0.09364, padchxlmicf1 0.18156, padchxlzmacf1 0.11425, padchxlzmicf1 0.21107, 38.33 secs\n",
      "Adjusting learning rate of group 0 to 2.8854e-06.\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.46049, a_loss 1.40269, ema 0.37133, oracc 0.99679, orien_loss 0.01833, gacc 0.99648, gloss 0.01572, b1 0.53287, b2 0.41653, b3 0.32237, b4 0.24923, padchxlmacf1 0.07839, padchxlmicf1 0.17670, padchxlzmacf1 0.09696, padchxlzmicf1 0.18471, padchxl_loss 0.33438, padchxlz_loss 0.46456, 139.74 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35243, oracc 0.99659, gacc 0.99682, b1 0.34361, b2 0.26335, b3 0.20383, b4 0.15804, padchxlmacf1 0.09484, padchxlmicf1 0.18322, padchxlzmacf1 0.11502, padchxlzmicf1 0.21201, 37.88 secs\n",
      "Adjusting learning rate of group 0 to 2.6204e-06.\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.27748, a_loss 1.39658, ema 0.37006, oracc 0.99606, orien_loss 0.02116, gacc 0.99721, gloss 0.01559, b1 0.53616, b2 0.41846, b3 0.32403, b4 0.25250, padchxlmacf1 0.07977, padchxlmicf1 0.18030, padchxlzmacf1 0.09256, padchxlzmicf1 0.18482, padchxl_loss 0.32951, padchxlz_loss 0.46101, 138.40 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35198, oracc 0.99659, gacc 0.99659, b1 0.34842, b2 0.26615, b3 0.20568, b4 0.15964, padchxlmacf1 0.09340, padchxlmicf1 0.18424, padchxlzmacf1 0.11437, padchxlzmicf1 0.21157, 37.62 secs\n",
      "Adjusting learning rate of group 0 to 2.3798e-06.\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.33204, a_loss 1.40477, ema 0.37048, oracc 0.99636, orien_loss 0.02121, gacc 0.99648, gloss 0.01710, b1 0.53132, b2 0.41313, b3 0.31784, b4 0.24459, padchxlmacf1 0.08024, padchxlmicf1 0.17853, padchxlzmacf1 0.09129, padchxlzmicf1 0.17967, padchxl_loss 0.33391, padchxlz_loss 0.46115, 137.67 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35289, oracc 0.99659, gacc 0.99659, b1 0.34280, b2 0.26203, b3 0.20246, b4 0.15726, padchxlmacf1 0.09564, padchxlmicf1 0.18503, padchxlzmacf1 0.11408, padchxlzmicf1 0.21079, 38.19 secs\n",
      "Adjusting learning rate of group 0 to 2.1612e-06.\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.11573, a_loss 1.39498, ema 0.37891, oracc 0.99600, orien_loss 0.02029, gacc 0.99655, gloss 0.01763, b1 0.53636, b2 0.41876, b3 0.32454, b4 0.25194, padchxlmacf1 0.08255, padchxlmicf1 0.18537, padchxlzmacf1 0.10250, padchxlzmicf1 0.19003, padchxl_loss 0.32770, padchxlz_loss 0.45731, 136.81 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35243, oracc 0.99659, gacc 0.99659, b1 0.35106, b2 0.26781, b3 0.20659, b4 0.16007, padchxlmacf1 0.09386, padchxlmicf1 0.18339, padchxlzmacf1 0.11458, padchxlzmicf1 0.21323, 37.77 secs\n",
      "Adjusting learning rate of group 0 to 1.9627e-06.\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.59628, a_loss 1.38751, ema 0.37418, oracc 0.99697, orien_loss 0.02029, gacc 0.99709, gloss 0.01507, b1 0.53685, b2 0.41843, b3 0.32275, b4 0.24901, padchxlmacf1 0.08046, padchxlmicf1 0.18280, padchxlzmacf1 0.09302, padchxlzmicf1 0.18434, padchxl_loss 0.32867, padchxlz_loss 0.46010, 135.93 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35175, oracc 0.99659, gacc 0.99727, b1 0.34415, b2 0.26428, b3 0.20525, b4 0.15972, padchxlmacf1 0.09511, padchxlmicf1 0.18416, padchxlzmacf1 0.11384, padchxlzmicf1 0.21361, 35.85 secs\n",
      "Adjusting learning rate of group 0 to 1.7825e-06.\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.27934, a_loss 1.39972, ema 0.37327, oracc 0.99745, orien_loss 0.01686, gacc 0.99636, gloss 0.01646, b1 0.53364, b2 0.41633, b3 0.32108, b4 0.24818, padchxlmacf1 0.08464, padchxlmicf1 0.18128, padchxlzmacf1 0.09550, padchxlzmicf1 0.18809, padchxl_loss 0.32730, padchxlz_loss 0.45963, 127.03 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35016, oracc 0.99659, gacc 0.99750, b1 0.35783, b2 0.27296, b3 0.21089, b4 0.16332, padchxlmacf1 0.09748, padchxlmicf1 0.18160, padchxlzmacf1 0.11213, padchxlzmicf1 0.21198, 34.57 secs\n",
      "Adjusting learning rate of group 0 to 1.6188e-06.\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.13790, a_loss 1.40181, ema 0.36958, oracc 0.99848, orien_loss 0.01321, gacc 0.99745, gloss 0.01534, b1 0.52727, b2 0.41158, b3 0.31883, b4 0.24700, padchxlmacf1 0.08303, padchxlmicf1 0.17763, padchxlzmacf1 0.10103, padchxlzmicf1 0.18115, padchxl_loss 0.33155, padchxlz_loss 0.45834, 124.81 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35175, oracc 0.99659, gacc 0.99750, b1 0.35367, b2 0.26970, b3 0.20811, b4 0.16123, padchxlmacf1 0.09783, padchxlmicf1 0.18248, padchxlzmacf1 0.11255, padchxlzmicf1 0.21159, 34.09 secs\n",
      "Adjusting learning rate of group 0 to 1.4701e-06.\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.16854, a_loss 1.40212, ema 0.37515, oracc 0.99594, orien_loss 0.02639, gacc 0.99758, gloss 0.01438, b1 0.53658, b2 0.41860, b3 0.32325, b4 0.24946, padchxlmacf1 0.08278, padchxlmicf1 0.17746, padchxlzmacf1 0.09976, padchxlzmicf1 0.18215, padchxl_loss 0.33160, padchxlz_loss 0.46088, 125.20 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35221, oracc 0.99659, gacc 0.99818, b1 0.34529, b2 0.26419, b3 0.20480, b4 0.15901, padchxlmacf1 0.09481, padchxlmicf1 0.18399, padchxlzmacf1 0.11465, padchxlzmicf1 0.21423, 34.37 secs\n",
      "Adjusting learning rate of group 0 to 1.3351e-06.\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.99268, a_loss 1.39394, ema 0.38042, oracc 0.99733, orien_loss 0.01722, gacc 0.99739, gloss 0.01615, b1 0.52648, b2 0.41074, b3 0.31803, b4 0.24728, padchxlmacf1 0.08412, padchxlmicf1 0.18240, padchxlzmacf1 0.09966, padchxlzmicf1 0.19113, padchxl_loss 0.32687, padchxlz_loss 0.45460, 124.27 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35312, oracc 0.99659, gacc 0.99864, b1 0.33954, b2 0.26025, b3 0.20180, b4 0.15674, padchxlmacf1 0.09546, padchxlmicf1 0.18576, padchxlzmacf1 0.11863, padchxlzmicf1 0.21247, 34.29 secs\n",
      "Adjusting learning rate of group 0 to 1.2125e-06.\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.23486, a_loss 1.39359, ema 0.36836, oracc 0.99691, orien_loss 0.01697, gacc 0.99739, gloss 0.01589, b1 0.53331, b2 0.41716, b3 0.32388, b4 0.25118, padchxlmacf1 0.08016, padchxlmicf1 0.17888, padchxlzmacf1 0.09813, padchxlzmicf1 0.18712, padchxl_loss 0.32921, padchxlz_loss 0.46099, 124.22 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35198, oracc 0.99659, gacc 0.99864, b1 0.34818, b2 0.26596, b3 0.20578, b4 0.15980, padchxlmacf1 0.09489, padchxlmicf1 0.18453, padchxlzmacf1 0.11824, padchxlzmicf1 0.21362, 34.37 secs\n",
      "Adjusting learning rate of group 0 to 1.1011e-06.\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.14742, a_loss 1.39154, ema 0.36770, oracc 0.99673, orien_loss 0.01793, gacc 0.99721, gloss 0.01641, b1 0.53210, b2 0.41491, b3 0.31919, b4 0.24552, padchxlmacf1 0.08236, padchxlmicf1 0.18158, padchxlzmacf1 0.09843, padchxlzmicf1 0.18874, padchxl_loss 0.32911, padchxlz_loss 0.46079, 124.58 secs\n",
      "(2) Validation stage ...\n",
      "ema 0.35175, oracc 0.99659, gacc 0.99864, b1 0.35309, b2 0.26917, b3 0.20805, b4 0.16135, padchxlmacf1 0.09428, padchxlmicf1 0.18360, padchxlzmacf1 0.11455, padchxlzmicf1 0.21371, 34.37 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 55 \\\n",
    "        --iters-to-accumulate 5 \\\n",
    "        --num-workers 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,5,2e-4,55,1e-6\" \\\n",
    "        --use-padchest \\\n",
    "        --padchest-use-validation \\\n",
    "        --padchest-weight 1 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --classify-orientation \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"facebook/vit-mae-base\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
