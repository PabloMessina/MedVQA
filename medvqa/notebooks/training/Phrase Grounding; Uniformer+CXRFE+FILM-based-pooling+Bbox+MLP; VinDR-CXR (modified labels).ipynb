{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e56399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_196_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9189.pt']\n",
      "Loading facts_relevant_to_anchor_facts from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_find_facts_relevant_to_anchor_facts(af=25,rf=404064)(hash=411,1888951042299108423).pkl...\n",
      "\u001b[1mExtracting embeddings...\u001b[0m\n",
      "  0%|                                                | 0/404064 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=469,680486110513564934).pkl\n",
      "len(self.cache[\"hashes\"]) = 1778187\n",
      "self.cache[\"embeddings\"].shape = (1778187, 128)\n",
      "100%|███████████████████████████████| 404064/404064 [00:02<00:00, 190009.24it/s]\n",
      "100%|███████████████████████████████████████| 28/28 [00:00<00:00, 194437.93it/s]\n",
      "Computing embeddings for 1 new texts\n",
      "checkpoint_names = ['checkpoint_196_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9189.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240629_084405_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_196_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9189.pt\n",
      "\u001b[93mWarning: model state dict has 210 keys, loaded state dict has 257 keys, intersection has 210 keys, union has 257 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.in_proj_weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.in_proj_bias\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.bias\u001b[0m\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.90it/s]\n",
      "Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=469,680486110513564934).pkl\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 7825.19it/s]\n",
      "Aortic enlargement: len(anchor_fact_idxs)=2754\n",
      "Atelectasis: len(anchor_fact_idxs)=40553\n",
      "Calcification: len(anchor_fact_idxs)=12673\n",
      "Cardiomegaly: len(anchor_fact_idxs)=9865\n",
      "Clavicle fracture: len(anchor_fact_idxs)=1366\n",
      "Consolidation: len(anchor_fact_idxs)=36095\n",
      "Edema: len(anchor_fact_idxs)=21285\n",
      "Emphysema: len(anchor_fact_idxs)=5403\n",
      "Enlarged PA: len(anchor_fact_idxs)=3108\n",
      "ILD: len(anchor_fact_idxs)=10232\n",
      "Infiltration: len(anchor_fact_idxs)=6239\n",
      "Lung Opacity: len(anchor_fact_idxs)=143698\n",
      "Lung cavity: len(anchor_fact_idxs)=2671\n",
      "Lung cyst: len(anchor_fact_idxs)=1305\n",
      "Mediastinal shift: len(anchor_fact_idxs)=1887\n",
      "Nodule/Mass: len(anchor_fact_idxs)=30361\n",
      "Pleural effusion: len(anchor_fact_idxs)=54765\n",
      "Pleural thickening: len(anchor_fact_idxs)=4117\n",
      "Pneumothorax: len(anchor_fact_idxs)=20049\n",
      "Pulmonary fibrosis: len(anchor_fact_idxs)=3398\n",
      "Rib fracture: len(anchor_fact_idxs)=10976\n",
      "COPD: len(anchor_fact_idxs)=1844\n",
      "Lung tumor: len(anchor_fact_idxs)=2399\n",
      "Pneumonia: len(anchor_fact_idxs)=25849\n",
      "Tuberculosis: len(anchor_fact_idxs)=420\n",
      "\u001b[1m\u001b[34mSaving output to:\u001b[0m \u001b[1m\u001b[34m/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\u001b[0m\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/vinbig/precompute_phrase_embeddings.py \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240629_084405_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--average_top_k_most_similar \\\n",
    "--top_k 100 \\\n",
    "--facts_relevant_to_anchor_facts_pickle_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_find_facts_relevant_to_anchor_facts(af=25,rf=404064)(hash=411,1888951042299108423).pkl\" \\\n",
    "--use_modified_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61e3aa28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 150\n",
      "   batches_per_epoch: 600\n",
      "   max_images_per_batch: 12\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 2.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: cxrmate-rrg24-uniformer-huggingface\n",
      "   huggingface_model_name: aehrc/cxrmate-rrg24\n",
      "   num_regions: 144\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 12\n",
      "   regions_height: 12\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 3\n",
      "   num_val_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [384, 384]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: cxrmate-rrg24-uniformer-huggingface\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR classification labels ...\u001b[0m\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "phrase_embeddings.dtype = float32\n",
      "len(phrases) = 28\n",
      "Compute phrase grounding masks and labels\n",
      "vinbig_bbox_names = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Abnormal finding']\n",
      "vinbig_labels = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'Abnormal finding']\n",
      "num_bbox_classes = 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.phrase_grounding_masks.shape = (18000, 23, 144)\n",
      "self.phrase_classification_labels.shape = (18000, 23)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 5\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(sorted_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\taortic enlargement seen (Aortic enlargement)\n",
      "\tatelectasis seen (Atelectasis)\n",
      "\tcalcification seen (Calcification)\n",
      "\tcardiomegaly seen (Cardiomegaly)\n",
      "\tclavicle fracture seen (Clavicle fracture)\n",
      "\tconsolidation seen (Consolidation)\n",
      "\tedema seen (Edema)\n",
      "\temphysema seen (Emphysema)\n",
      "\tenlarged pulmonary artery seen (Enlarged PA)\n",
      "\tinterstitial lung disease seen (ILD)\n",
      "\tinfiltration seen (Infiltration)\n",
      "\tlung opacity seen (Lung Opacity)\n",
      "\tlung cavity seen (Lung cavity)\n",
      "\tlung cyst seen (Lung cyst)\n",
      "\tmediastinal shift seen (Mediastinal shift)\n",
      "\tnodule/mass seen (Nodule/Mass)\n",
      "\tother lesion seen (Other lesion)\n",
      "\tpleural effusion seen (Pleural effusion)\n",
      "\tpleural thickening seen (Pleural thickening)\n",
      "\tpneumothorax seen (Pneumothorax)\n",
      "\tpulmonary fibrosis seen (Pulmonary fibrosis)\n",
      "\trib fracture seen (Rib fracture)\n",
      "\tabnormal findings seen (Abnormal finding)\n",
      "\tcopd seen (COPD)\n",
      "\tlung tumor seen (Lung tumor)\n",
      "\tpneumonia seen (Pneumonia)\n",
      "\ttuberculosis seen (Tuberculosis)\n",
      "\tother disease seen (Other disease)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 36\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 919\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Lung Opacity: 2709\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4377\n",
      "Abnormal finding: 4522\n",
      "No labels: 10478\n",
      "Group sizes: [10478, 794, 341, 312, 286, 278, 258, 243, 241, 218, 215, 198, 159, 156, 122, 119, 114, 102, 91, 83, 79, 63, 50]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 794, weight = 893.8899020987899\n",
      "  len(indices) = 341, weight = 595.5934427021492\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 198, weight = 444.08258972130596\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 91, weight = 275.6141558688678\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 63, weight = 213.55551164361594\n",
      "  len(indices) = 50, weight = 179.7743872238934\n",
      "batch_size = 12\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 24\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(vinbig_trainer.train_dataloader) = 83333333333333334\n",
      "len(vinbig_trainer.val_dataloader) = 125\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.81829, vbg_vgbbox_loss 1.74718, vbg_att_sup_loss 1.35248, vbg_phrcls_loss 1.71864, vbg_prc_auc 0.18617, 213.46 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.00000, vbg_prc_auc 0.06430, 61.44 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mvbg_vgbbox_loss: 0.3640, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_att_sup_loss: 0.4251, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.1862, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 2.6508, den = 12.0000, score = 0.2209\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mvbg_bbox_iou: 0.0000, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.0643, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 0.6430, den = 11.0000, score = 0.0585\u001b[0m\n",
      "\u001b[93mTrain score = 0.2209, Val score = 0.0585, Final score = 0.0666\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_vbss+vbou+vbuc+vbss=0.0666.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.67726, vbg_vgbbox_loss 1.64072, vbg_att_sup_loss 1.34849, vbg_phrcls_loss 1.68804, vbg_prc_auc 0.18914, 211.19 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.00009, vbg_prc_auc 0.06611, 42.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_vbss+vbou+vbuc+vbss=0.0683.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 3.85069, vbg_vgbbox_loss 0.99744, vbg_att_sup_loss 1.30726, vbg_phrcls_loss 1.54599, vbg_prc_auc 0.18664, 212.24 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06282, vbg_prc_auc 0.05081, 41.65 secs\n",
      "\u001b[1m---- Epoch 4/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.87717, vbg_vgbbox_loss 0.41929, vbg_att_sup_loss 1.09822, vbg_phrcls_loss 1.35965, vbg_prc_auc 0.27141, 211.41 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.13708, vbg_prc_auc 0.24518, 45.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_vbss+vbou+vbuc+vbss=0.2398.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 2.21775, vbg_vgbbox_loss 0.31201, vbg_att_sup_loss 0.73683, vbg_phrcls_loss 1.16891, vbg_prc_auc 0.31616, 211.05 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.14450, vbg_prc_auc 0.28195, 44.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_vbss+vbou+vbuc+vbss=0.2747.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.07435, vbg_vgbbox_loss 0.29348, vbg_att_sup_loss 0.66210, vbg_phrcls_loss 1.11877, vbg_prc_auc 0.33933, 211.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.14826, vbg_prc_auc 0.29187, 44.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_vbss+vbou+vbuc+vbss=0.2847.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.01762, vbg_vgbbox_loss 0.28890, vbg_att_sup_loss 0.63701, vbg_phrcls_loss 1.09171, vbg_prc_auc 0.34851, 212.52 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15207, vbg_prc_auc 0.29424, 43.90 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_vbss+vbou+vbuc+vbss=0.2875.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.00225, vbg_vgbbox_loss 0.28356, vbg_att_sup_loss 0.63023, vbg_phrcls_loss 1.08846, vbg_prc_auc 0.35173, 211.95 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.15170, vbg_prc_auc 0.29714, 43.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_vbss+vbou+vbuc+vbss=0.2902.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.99087, vbg_vgbbox_loss 0.28403, vbg_att_sup_loss 0.62538, vbg_phrcls_loss 1.08146, vbg_prc_auc 0.35149, 211.82 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15142, vbg_prc_auc 0.29715, 43.47 secs\n",
      "\u001b[1m---- Epoch 10/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.91647, vbg_vgbbox_loss 0.28477, vbg_att_sup_loss 0.58824, vbg_phrcls_loss 1.04346, vbg_prc_auc 0.36049, 211.93 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15053, vbg_prc_auc 0.32147, 43.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_vbss+vbou+vbuc+vbss=0.3115.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.77355, vbg_vgbbox_loss 0.27173, vbg_att_sup_loss 0.52575, vbg_phrcls_loss 0.97606, vbg_prc_auc 0.39562, 212.71 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15067, vbg_prc_auc 0.33862, 42.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_vbss+vbou+vbuc+vbss=0.3280.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.72121, vbg_vgbbox_loss 0.26412, vbg_att_sup_loss 0.50133, vbg_phrcls_loss 0.95576, vbg_prc_auc 0.40682, 206.48 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15342, vbg_prc_auc 0.33517, 42.56 secs\n",
      "\u001b[1m---- Epoch 13/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.70598, vbg_vgbbox_loss 0.26191, vbg_att_sup_loss 0.49639, vbg_phrcls_loss 0.94768, vbg_prc_auc 0.41031, 212.31 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15233, vbg_prc_auc 0.33502, 42.53 secs\n",
      "\u001b[1m---- Epoch 14/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.70167, vbg_vgbbox_loss 0.26254, vbg_att_sup_loss 0.49366, vbg_phrcls_loss 0.94547, vbg_prc_auc 0.41306, 207.24 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15494, vbg_prc_auc 0.33710, 42.43 secs\n",
      "\u001b[1m---- Epoch 15/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.67187, vbg_vgbbox_loss 0.26344, vbg_att_sup_loss 0.47739, vbg_phrcls_loss 0.93104, vbg_prc_auc 0.41597, 212.93 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17209, vbg_prc_auc 0.36777, 43.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_vbss+vbou+vbuc+vbss=0.3559.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.58955, vbg_vgbbox_loss 0.25673, vbg_att_sup_loss 0.44145, vbg_phrcls_loss 0.89137, vbg_prc_auc 0.45217, 212.01 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16552, vbg_prc_auc 0.38031, 42.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_vbss+vbou+vbuc+vbss=0.3678.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.54084, vbg_vgbbox_loss 0.24931, vbg_att_sup_loss 0.42428, vbg_phrcls_loss 0.86724, vbg_prc_auc 0.46636, 212.22 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16733, vbg_prc_auc 0.37937, 42.35 secs\n",
      "\u001b[1m---- Epoch 18/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.53510, vbg_vgbbox_loss 0.24926, vbg_att_sup_loss 0.42375, vbg_phrcls_loss 0.86209, vbg_prc_auc 0.47200, 211.43 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17034, vbg_prc_auc 0.38088, 42.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_vbss+vbou+vbuc+vbss=0.3696.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.51803, vbg_vgbbox_loss 0.24664, vbg_att_sup_loss 0.41678, vbg_phrcls_loss 0.85461, vbg_prc_auc 0.47543, 210.95 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16925, vbg_prc_auc 0.38071, 42.58 secs\n",
      "\u001b[1m---- Epoch 20/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.52123, vbg_vgbbox_loss 0.25109, vbg_att_sup_loss 0.41478, vbg_phrcls_loss 0.85536, vbg_prc_auc 0.47586, 212.28 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.16822, vbg_prc_auc 0.38216, 42.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_vbss+vbou+vbuc+vbss=0.3707.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.44255, vbg_vgbbox_loss 0.24173, vbg_att_sup_loss 0.38636, vbg_phrcls_loss 0.81446, vbg_prc_auc 0.51291, 212.12 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17691, vbg_prc_auc 0.40290, 42.47 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_vbss+vbou+vbuc+vbss=0.3910.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.41170, vbg_vgbbox_loss 0.24097, vbg_att_sup_loss 0.38036, vbg_phrcls_loss 0.79036, vbg_prc_auc 0.54028, 212.81 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17629, vbg_prc_auc 0.40735, 42.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_vbss+vbou+vbuc+vbss=0.3959.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.39814, vbg_vgbbox_loss 0.23841, vbg_att_sup_loss 0.37574, vbg_phrcls_loss 0.78399, vbg_prc_auc 0.53989, 212.69 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17601, vbg_prc_auc 0.41196, 42.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_vbss+vbou+vbuc+vbss=0.3999.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.39401, vbg_vgbbox_loss 0.23937, vbg_att_sup_loss 0.37623, vbg_phrcls_loss 0.77842, vbg_prc_auc 0.54366, 212.25 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.17450, vbg_prc_auc 0.40901, 41.86 secs\n",
      "\u001b[1m---- Epoch 25/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.40788, vbg_vgbbox_loss 0.24238, vbg_att_sup_loss 0.37713, vbg_phrcls_loss 0.78837, vbg_prc_auc 0.53592, 200.95 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18526, vbg_prc_auc 0.42779, 41.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_vbss+vbou+vbuc+vbss=0.4142.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.33923, vbg_vgbbox_loss 0.23539, vbg_att_sup_loss 0.35587, vbg_phrcls_loss 0.74797, vbg_prc_auc 0.57613, 201.66 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18569, vbg_prc_auc 0.43468, 42.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_vbss+vbou+vbuc+vbss=0.4219.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.30864, vbg_vgbbox_loss 0.23307, vbg_att_sup_loss 0.34689, vbg_phrcls_loss 0.72869, vbg_prc_auc 0.59116, 200.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18215, vbg_prc_auc 0.42734, 41.73 secs\n",
      "\u001b[1m---- Epoch 28/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.30550, vbg_vgbbox_loss 0.23239, vbg_att_sup_loss 0.34736, vbg_phrcls_loss 0.72575, vbg_prc_auc 0.60034, 211.48 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18510, vbg_prc_auc 0.42896, 41.84 secs\n",
      "\u001b[1m---- Epoch 29/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.29695, vbg_vgbbox_loss 0.23019, vbg_att_sup_loss 0.34312, vbg_phrcls_loss 0.72364, vbg_prc_auc 0.60200, 211.54 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18309, vbg_prc_auc 0.43141, 41.50 secs\n",
      "\u001b[1m---- Epoch 30/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.31374, vbg_vgbbox_loss 0.23646, vbg_att_sup_loss 0.34669, vbg_phrcls_loss 0.73060, vbg_prc_auc 0.59001, 208.62 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18993, vbg_prc_auc 0.44600, 41.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_30_vbss+vbou+vbuc+vbss=0.4326.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 31/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.26546, vbg_vgbbox_loss 0.22954, vbg_att_sup_loss 0.33197, vbg_phrcls_loss 0.70394, vbg_prc_auc 0.61736, 210.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19243, vbg_prc_auc 0.44276, 42.39 secs\n",
      "\u001b[1m---- Epoch 32/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.23482, vbg_vgbbox_loss 0.22700, vbg_att_sup_loss 0.32857, vbg_phrcls_loss 0.67925, vbg_prc_auc 0.64031, 206.03 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19187, vbg_prc_auc 0.45000, 41.74 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_vbss+vbou+vbuc+vbss=0.4384.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.22060, vbg_vgbbox_loss 0.22596, vbg_att_sup_loss 0.32319, vbg_phrcls_loss 0.67146, vbg_prc_auc 0.64506, 211.58 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18929, vbg_prc_auc 0.44389, 42.13 secs\n",
      "\u001b[1m---- Epoch 34/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.21722, vbg_vgbbox_loss 0.22436, vbg_att_sup_loss 0.32330, vbg_phrcls_loss 0.66956, vbg_prc_auc 0.65130, 212.55 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19058, vbg_prc_auc 0.44070, 41.99 secs\n",
      "\u001b[1m---- Epoch 35/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.24249, vbg_vgbbox_loss 0.22979, vbg_att_sup_loss 0.32787, vbg_phrcls_loss 0.68483, vbg_prc_auc 0.63421, 212.50 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.19554, vbg_prc_auc 0.46713, 42.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_vbss+vbou+vbuc+vbss=0.4533.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.19304, vbg_vgbbox_loss 0.22405, vbg_att_sup_loss 0.31671, vbg_phrcls_loss 0.65228, vbg_prc_auc 0.66251, 210.54 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19565, vbg_prc_auc 0.45783, 42.32 secs\n",
      "\u001b[1m---- Epoch 37/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.16511, vbg_vgbbox_loss 0.22043, vbg_att_sup_loss 0.30762, vbg_phrcls_loss 0.63707, vbg_prc_auc 0.68566, 212.77 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19330, vbg_prc_auc 0.45700, 42.12 secs\n",
      "\u001b[1m---- Epoch 38/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.15903, vbg_vgbbox_loss 0.21989, vbg_att_sup_loss 0.30829, vbg_phrcls_loss 0.63085, vbg_prc_auc 0.68319, 212.00 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19555, vbg_prc_auc 0.45621, 42.37 secs\n",
      "\u001b[1m---- Epoch 39/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.15491, vbg_vgbbox_loss 0.22077, vbg_att_sup_loss 0.30637, vbg_phrcls_loss 0.62777, vbg_prc_auc 0.69053, 212.21 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19376, vbg_prc_auc 0.45901, 41.95 secs\n",
      "\u001b[1m---- Epoch 40/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.17129, vbg_vgbbox_loss 0.22348, vbg_att_sup_loss 0.30993, vbg_phrcls_loss 0.63789, vbg_prc_auc 0.67014, 211.18 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18685, vbg_prc_auc 0.41992, 41.60 secs\n",
      "\u001b[1m---- Epoch 41/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.14577, vbg_vgbbox_loss 0.21999, vbg_att_sup_loss 0.30393, vbg_phrcls_loss 0.62185, vbg_prc_auc 0.69132, 212.80 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19462, vbg_prc_auc 0.43858, 41.75 secs\n",
      "\u001b[1m---- Epoch 42/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.10584, vbg_vgbbox_loss 0.21423, vbg_att_sup_loss 0.29261, vbg_phrcls_loss 0.59899, vbg_prc_auc 0.70363, 211.95 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19527, vbg_prc_auc 0.44421, 42.02 secs\n",
      "\u001b[1m---- Epoch 43/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.10233, vbg_vgbbox_loss 0.21542, vbg_att_sup_loss 0.29319, vbg_phrcls_loss 0.59371, vbg_prc_auc 0.70842, 212.30 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19483, vbg_prc_auc 0.44551, 41.68 secs\n",
      "\u001b[1m---- Epoch 44/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.09718, vbg_vgbbox_loss 0.21487, vbg_att_sup_loss 0.29139, vbg_phrcls_loss 0.59093, vbg_prc_auc 0.71444, 211.68 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19283, vbg_prc_auc 0.44650, 42.03 secs\n",
      "\u001b[1m---- Epoch 45/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.12238, vbg_vgbbox_loss 0.21978, vbg_att_sup_loss 0.29773, vbg_phrcls_loss 0.60486, vbg_prc_auc 0.69456, 211.08 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19619, vbg_prc_auc 0.45150, 42.14 secs\n",
      "\u001b[1m---- Epoch 46/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.09095, vbg_vgbbox_loss 0.21626, vbg_att_sup_loss 0.28936, vbg_phrcls_loss 0.58532, vbg_prc_auc 0.71645, 212.87 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19191, vbg_prc_auc 0.44962, 41.89 secs\n",
      "\u001b[1m---- Epoch 47/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.05431, vbg_vgbbox_loss 0.21054, vbg_att_sup_loss 0.28198, vbg_phrcls_loss 0.56179, vbg_prc_auc 0.73504, 212.16 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19923, vbg_prc_auc 0.45497, 41.99 secs\n",
      "\u001b[1m---- Epoch 48/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.04971, vbg_vgbbox_loss 0.21228, vbg_att_sup_loss 0.27982, vbg_phrcls_loss 0.55762, vbg_prc_auc 0.74038, 211.94 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19687, vbg_prc_auc 0.45400, 42.06 secs\n",
      "\u001b[1m---- Epoch 49/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.05213, vbg_vgbbox_loss 0.21252, vbg_att_sup_loss 0.28040, vbg_phrcls_loss 0.55921, vbg_prc_auc 0.73944, 212.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19551, vbg_prc_auc 0.45677, 41.66 secs\n",
      "\u001b[1m---- Epoch 50/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.08596, vbg_vgbbox_loss 0.21785, vbg_att_sup_loss 0.28608, vbg_phrcls_loss 0.58203, vbg_prc_auc 0.72551, 212.18 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19347, vbg_prc_auc 0.44629, 42.20 secs\n",
      "\u001b[1m---- Epoch 51/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.03816, vbg_vgbbox_loss 0.20933, vbg_att_sup_loss 0.27547, vbg_phrcls_loss 0.55335, vbg_prc_auc 0.74288, 210.85 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20095, vbg_prc_auc 0.45841, 42.28 secs\n",
      "\u001b[1m---- Epoch 52/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.01956, vbg_vgbbox_loss 0.21063, vbg_att_sup_loss 0.27137, vbg_phrcls_loss 0.53756, vbg_prc_auc 0.76051, 211.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20543, vbg_prc_auc 0.45846, 42.14 secs\n",
      "\u001b[1m---- Epoch 53/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.01139, vbg_vgbbox_loss 0.20916, vbg_att_sup_loss 0.27046, vbg_phrcls_loss 0.53178, vbg_prc_auc 0.76469, 211.36 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20531, vbg_prc_auc 0.45106, 41.92 secs\n",
      "\u001b[1m---- Epoch 54/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.99739, vbg_vgbbox_loss 0.20673, vbg_att_sup_loss 0.26699, vbg_phrcls_loss 0.52368, vbg_prc_auc 0.77045, 207.14 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20294, vbg_prc_auc 0.45367, 42.27 secs\n",
      "\u001b[1m---- Epoch 55/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.02595, vbg_vgbbox_loss 0.21084, vbg_att_sup_loss 0.27347, vbg_phrcls_loss 0.54164, vbg_prc_auc 0.74632, 204.78 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20210, vbg_prc_auc 0.45372, 42.06 secs\n",
      "\u001b[1m---- Epoch 56/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.98983, vbg_vgbbox_loss 0.21026, vbg_att_sup_loss 0.26490, vbg_phrcls_loss 0.51467, vbg_prc_auc 0.77014, 213.38 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19856, vbg_prc_auc 0.44548, 42.18 secs\n",
      "\u001b[1m---- Epoch 57/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.96894, vbg_vgbbox_loss 0.20660, vbg_att_sup_loss 0.26131, vbg_phrcls_loss 0.50103, vbg_prc_auc 0.77997, 209.49 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20177, vbg_prc_auc 0.44713, 42.20 secs\n",
      "\u001b[1m---- Epoch 58/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.95816, vbg_vgbbox_loss 0.20516, vbg_att_sup_loss 0.25772, vbg_phrcls_loss 0.49528, vbg_prc_auc 0.79412, 203.58 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20125, vbg_prc_auc 0.44757, 42.24 secs\n",
      "\u001b[1m---- Epoch 59/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.95912, vbg_vgbbox_loss 0.20410, vbg_att_sup_loss 0.25808, vbg_phrcls_loss 0.49694, vbg_prc_auc 0.79360, 211.95 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20161, vbg_prc_auc 0.45026, 41.73 secs\n",
      "\u001b[1m---- Epoch 60/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.99797, vbg_vgbbox_loss 0.21067, vbg_att_sup_loss 0.26584, vbg_phrcls_loss 0.52146, vbg_prc_auc 0.76992, 212.07 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20005, vbg_prc_auc 0.44279, 42.22 secs\n",
      "\u001b[1m---- Epoch 61/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.95432, vbg_vgbbox_loss 0.20618, vbg_att_sup_loss 0.25578, vbg_phrcls_loss 0.49236, vbg_prc_auc 0.78960, 211.59 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20643, vbg_prc_auc 0.46053, 42.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_61_vbss+vbou+vbuc+vbss=0.4552.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 62/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.93909, vbg_vgbbox_loss 0.20561, vbg_att_sup_loss 0.25150, vbg_phrcls_loss 0.48198, vbg_prc_auc 0.79192, 212.34 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20222, vbg_prc_auc 0.45834, 42.52 secs\n",
      "\u001b[1m---- Epoch 63/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.92262, vbg_vgbbox_loss 0.20384, vbg_att_sup_loss 0.24816, vbg_phrcls_loss 0.47062, vbg_prc_auc 0.80359, 212.77 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20192, vbg_prc_auc 0.45443, 42.25 secs\n",
      "\u001b[1m---- Epoch 64/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.91913, vbg_vgbbox_loss 0.20295, vbg_att_sup_loss 0.24858, vbg_phrcls_loss 0.46760, vbg_prc_auc 0.80684, 210.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20366, vbg_prc_auc 0.45605, 42.34 secs\n",
      "\u001b[1m---- Epoch 65/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.96029, vbg_vgbbox_loss 0.20963, vbg_att_sup_loss 0.25618, vbg_phrcls_loss 0.49447, vbg_prc_auc 0.78458, 203.06 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20437, vbg_prc_auc 0.44434, 41.74 secs\n",
      "\u001b[1m---- Epoch 66/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.92911, vbg_vgbbox_loss 0.20382, vbg_att_sup_loss 0.25057, vbg_phrcls_loss 0.47471, vbg_prc_auc 0.79854, 212.29 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19803, vbg_prc_auc 0.44466, 42.20 secs\n",
      "\u001b[1m---- Epoch 67/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.89372, vbg_vgbbox_loss 0.20185, vbg_att_sup_loss 0.24217, vbg_phrcls_loss 0.44970, vbg_prc_auc 0.82560, 212.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19908, vbg_prc_auc 0.45073, 42.55 secs\n",
      "\u001b[1m---- Epoch 68/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.88817, vbg_vgbbox_loss 0.20016, vbg_att_sup_loss 0.24265, vbg_phrcls_loss 0.44535, vbg_prc_auc 0.82204, 212.50 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19651, vbg_prc_auc 0.44524, 42.43 secs\n",
      "\u001b[1m---- Epoch 69/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.88596, vbg_vgbbox_loss 0.20012, vbg_att_sup_loss 0.24264, vbg_phrcls_loss 0.44320, vbg_prc_auc 0.82538, 213.18 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20404, vbg_prc_auc 0.44780, 42.72 secs\n",
      "\u001b[1m---- Epoch 70/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.92044, vbg_vgbbox_loss 0.20550, vbg_att_sup_loss 0.24702, vbg_phrcls_loss 0.46792, vbg_prc_auc 0.80035, 211.95 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20223, vbg_prc_auc 0.45691, 42.73 secs\n",
      "\u001b[1m---- Epoch 71/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.88297, vbg_vgbbox_loss 0.20196, vbg_att_sup_loss 0.23954, vbg_phrcls_loss 0.44147, vbg_prc_auc 0.82936, 213.27 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20349, vbg_prc_auc 0.45324, 42.87 secs\n",
      "\u001b[1m---- Epoch 72/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.85989, vbg_vgbbox_loss 0.19908, vbg_att_sup_loss 0.23737, vbg_phrcls_loss 0.42345, vbg_prc_auc 0.84174, 212.46 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20552, vbg_prc_auc 0.44996, 42.89 secs\n",
      "\u001b[1m---- Epoch 73/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.85233, vbg_vgbbox_loss 0.19722, vbg_att_sup_loss 0.23169, vbg_phrcls_loss 0.42341, vbg_prc_auc 0.83757, 212.83 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20127, vbg_prc_auc 0.45022, 42.95 secs\n",
      "\u001b[1m---- Epoch 74/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.85281, vbg_vgbbox_loss 0.19834, vbg_att_sup_loss 0.23412, vbg_phrcls_loss 0.42035, vbg_prc_auc 0.84356, 211.69 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20255, vbg_prc_auc 0.45133, 42.93 secs\n",
      "\u001b[1m---- Epoch 75/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.90548, vbg_vgbbox_loss 0.20508, vbg_att_sup_loss 0.24541, vbg_phrcls_loss 0.45499, vbg_prc_auc 0.81083, 202.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20378, vbg_prc_auc 0.44183, 43.09 secs\n",
      "\u001b[1m---- Epoch 76/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.85358, vbg_vgbbox_loss 0.20021, vbg_att_sup_loss 0.23164, vbg_phrcls_loss 0.42173, vbg_prc_auc 0.83825, 212.53 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20489, vbg_prc_auc 0.45039, 42.87 secs\n",
      "\u001b[1m---- Epoch 77/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.83264, vbg_vgbbox_loss 0.19712, vbg_att_sup_loss 0.22953, vbg_phrcls_loss 0.40599, vbg_prc_auc 0.85424, 214.00 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20596, vbg_prc_auc 0.45407, 43.09 secs\n",
      "\u001b[1m---- Epoch 78/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.82686, vbg_vgbbox_loss 0.19815, vbg_att_sup_loss 0.22824, vbg_phrcls_loss 0.40047, vbg_prc_auc 0.85645, 211.67 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20515, vbg_prc_auc 0.45262, 43.12 secs\n",
      "\u001b[1m---- Epoch 79/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.81670, vbg_vgbbox_loss 0.19565, vbg_att_sup_loss 0.22699, vbg_phrcls_loss 0.39407, vbg_prc_auc 0.86478, 208.26 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20649, vbg_prc_auc 0.45439, 43.25 secs\n",
      "\u001b[1m---- Epoch 80/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.85438, vbg_vgbbox_loss 0.20218, vbg_att_sup_loss 0.23274, vbg_phrcls_loss 0.41946, vbg_prc_auc 0.83807, 212.00 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19921, vbg_prc_auc 0.45961, 43.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_80_vbss+vbou+vbuc+vbss=0.4559.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 81/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.82177, vbg_vgbbox_loss 0.19756, vbg_att_sup_loss 0.22737, vbg_phrcls_loss 0.39684, vbg_prc_auc 0.86043, 213.15 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20536, vbg_prc_auc 0.45531, 43.48 secs\n",
      "\u001b[1m---- Epoch 82/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.80171, vbg_vgbbox_loss 0.19624, vbg_att_sup_loss 0.22376, vbg_phrcls_loss 0.38171, vbg_prc_auc 0.87102, 212.37 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20399, vbg_prc_auc 0.45204, 43.65 secs\n",
      "\u001b[1m---- Epoch 83/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.78331, vbg_vgbbox_loss 0.19562, vbg_att_sup_loss 0.21783, vbg_phrcls_loss 0.36986, vbg_prc_auc 0.88205, 213.63 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20141, vbg_prc_auc 0.45218, 43.66 secs\n",
      "\u001b[1m---- Epoch 84/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.78628, vbg_vgbbox_loss 0.19357, vbg_att_sup_loss 0.22049, vbg_phrcls_loss 0.37221, vbg_prc_auc 0.87932, 212.36 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20232, vbg_prc_auc 0.45013, 43.94 secs\n",
      "\u001b[1m---- Epoch 85/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.82471, vbg_vgbbox_loss 0.19794, vbg_att_sup_loss 0.22707, vbg_phrcls_loss 0.39970, vbg_prc_auc 0.85316, 212.69 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19836, vbg_prc_auc 0.44614, 44.19 secs\n",
      "\u001b[1m---- Epoch 86/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.79963, vbg_vgbbox_loss 0.19596, vbg_att_sup_loss 0.22195, vbg_phrcls_loss 0.38172, vbg_prc_auc 0.87734, 214.43 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20652, vbg_prc_auc 0.45353, 44.18 secs\n",
      "\u001b[1m---- Epoch 87/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.76779, vbg_vgbbox_loss 0.19435, vbg_att_sup_loss 0.21557, vbg_phrcls_loss 0.35786, vbg_prc_auc 0.88982, 212.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20601, vbg_prc_auc 0.45706, 44.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_87_vbss+vbou+vbuc+vbss=0.4565.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 88/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.76274, vbg_vgbbox_loss 0.19111, vbg_att_sup_loss 0.21478, vbg_phrcls_loss 0.35686, vbg_prc_auc 0.88965, 204.02 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20604, vbg_prc_auc 0.45510, 45.06 secs\n",
      "\u001b[1m---- Epoch 89/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.76411, vbg_vgbbox_loss 0.19203, vbg_att_sup_loss 0.21590, vbg_phrcls_loss 0.35618, vbg_prc_auc 0.89139, 203.13 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20533, vbg_prc_auc 0.45085, 45.09 secs\n",
      "\u001b[1m---- Epoch 90/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.79889, vbg_vgbbox_loss 0.19834, vbg_att_sup_loss 0.22168, vbg_phrcls_loss 0.37888, vbg_prc_auc 0.86367, 213.58 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20260, vbg_prc_auc 0.44861, 45.54 secs\n",
      "\u001b[1m---- Epoch 91/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.76974, vbg_vgbbox_loss 0.19537, vbg_att_sup_loss 0.21817, vbg_phrcls_loss 0.35621, vbg_prc_auc 0.89527, 204.49 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20208, vbg_prc_auc 0.44920, 45.90 secs\n",
      "\u001b[1m---- Epoch 92/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.74678, vbg_vgbbox_loss 0.19178, vbg_att_sup_loss 0.21224, vbg_phrcls_loss 0.34276, vbg_prc_auc 0.89695, 205.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20162, vbg_prc_auc 0.45038, 45.83 secs\n",
      "\u001b[1m---- Epoch 93/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.73803, vbg_vgbbox_loss 0.19199, vbg_att_sup_loss 0.21025, vbg_phrcls_loss 0.33580, vbg_prc_auc 0.90241, 206.03 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20286, vbg_prc_auc 0.45348, 46.04 secs\n",
      "\u001b[1m---- Epoch 94/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.77582, vbg_vgbbox_loss 0.19602, vbg_att_sup_loss 0.21657, vbg_phrcls_loss 0.36322, vbg_prc_auc 0.88265, 214.99 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18913, vbg_prc_auc 0.43821, 46.19 secs\n",
      "\u001b[1m---- Epoch 96/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.74561, vbg_vgbbox_loss 0.19229, vbg_att_sup_loss 0.20989, vbg_phrcls_loss 0.34342, vbg_prc_auc 0.90211, 213.30 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19209, vbg_prc_auc 0.43976, 46.18 secs\n",
      "\u001b[1m---- Epoch 97/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.71413, vbg_vgbbox_loss 0.18962, vbg_att_sup_loss 0.20305, vbg_phrcls_loss 0.32145, vbg_prc_auc 0.90689, 215.49 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.19179, vbg_prc_auc 0.44466, 46.13 secs\n",
      "\u001b[1m---- Epoch 98/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.70859, vbg_vgbbox_loss 0.18818, vbg_att_sup_loss 0.20235, vbg_phrcls_loss 0.31807, vbg_prc_auc 0.91656, 214.97 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19616, vbg_prc_auc 0.44067, 46.03 secs\n",
      "\u001b[1m---- Epoch 99/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.71466, vbg_vgbbox_loss 0.19111, vbg_att_sup_loss 0.20555, vbg_phrcls_loss 0.31799, vbg_prc_auc 0.91536, 215.62 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19628, vbg_prc_auc 0.44100, 45.96 secs\n",
      "\u001b[1m---- Epoch 100/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.75409, vbg_vgbbox_loss 0.19504, vbg_att_sup_loss 0.21352, vbg_phrcls_loss 0.34553, vbg_prc_auc 0.89660, 216.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20206, vbg_prc_auc 0.45517, 46.20 secs\n",
      "\u001b[1m---- Epoch 101/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.72543, vbg_vgbbox_loss 0.19027, vbg_att_sup_loss 0.20620, vbg_phrcls_loss 0.32897, vbg_prc_auc 0.90555, 217.08 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21065, vbg_prc_auc 0.45726, 46.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_101_vbss+vbou+vbuc+vbss=0.4578.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 102/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.69932, vbg_vgbbox_loss 0.18858, vbg_att_sup_loss 0.20098, vbg_phrcls_loss 0.30977, vbg_prc_auc 0.91552, 216.42 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20640, vbg_prc_auc 0.45672, 46.41 secs\n",
      "\u001b[1m---- Epoch 103/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68164, vbg_vgbbox_loss 0.18878, vbg_att_sup_loss 0.19818, vbg_phrcls_loss 0.29468, vbg_prc_auc 0.92866, 213.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20222, vbg_prc_auc 0.46285, 46.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_103_vbss+vbou+vbuc+vbss=0.4629.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 104/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68744, vbg_vgbbox_loss 0.18858, vbg_att_sup_loss 0.20117, vbg_phrcls_loss 0.29769, vbg_prc_auc 0.92215, 215.02 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20260, vbg_prc_auc 0.45274, 46.26 secs\n",
      "\u001b[1m---- Epoch 105/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 62825\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1551, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1417, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 926, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 142, in run_common_boilerplate_code_and_start_training\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 991, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 516, in step_fn__vinbig_bbox_grounding\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/phrase_grounding/phrase_grounder.py\", line 371, in forward\n",
      "    output = super().forward(\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 954, in forward\n",
      "    local_feat_NxCxHxW = self.raw_image_encoder(raw_images)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/.cache/huggingface/modules/transformers_modules/aehrc/cxrmate-rrg24/df24aadfdbf77b20b8e847d09eb6b96745a0ac85/modelling_uniformer.py\", line 286, in forward\n",
      "    x = self.forward_features(x)\n",
      "  File \"/home/pamessina/.cache/huggingface/modules/transformers_modules/aehrc/cxrmate-rrg24/df24aadfdbf77b20b8e847d09eb6b96745a0ac85/modelling_uniformer.py\", line 277, in forward_features\n",
      "    x = blk(x)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/.cache/huggingface/modules/transformers_modules/aehrc/cxrmate-rrg24/df24aadfdbf77b20b8e847d09eb6b96745a0ac85/modelling_uniformer.py\", line 150, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/.cache/huggingface/modules/transformers_modules/aehrc/cxrmate-rrg24/df24aadfdbf77b20b8e847d09eb6b96745a0ac85/modelling_uniformer.py\", line 36, in forward\n",
      "    x = self.drop(x)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/dropout.py\", line 59, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/functional.py\", line 1295, in dropout\n",
      "    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--epochs 150 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--max_images_per_batch 12 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 2.0 \\\n",
    "--raw_image_encoding \"cxrmate-rrg24-uniformer-huggingface\" \\\n",
    "--huggingface_model_name \"aehrc/cxrmate-rrg24\" \\\n",
    "--image_size 384 384 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 144 \\\n",
    "--regions_width 12 \\\n",
    "--regions_height 12 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--num_train_workers 3 \\\n",
    "--num_val_workers 3 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\" \\\n",
    "--use_vinbig_with_modified_labels \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef82b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 30\n",
      "   batches_per_epoch: 600\n",
      "   max_images_per_batch: 12\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 2.0\n",
      "   checkpoint_folder: models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: cxrmate-rrg24-uniformer-huggingface\n",
      "   huggingface_model_name: aehrc/cxrmate-rrg24\n",
      "   num_regions: 144\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 12\n",
      "   regions_height: 12\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 3\n",
      "   num_val_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [384, 384]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: cxrmate-rrg24-uniformer-huggingface\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR classification labels ...\u001b[0m\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "phrase_embeddings.dtype = float32\n",
      "len(phrases) = 28\n",
      "Compute phrase grounding masks and labels\n",
      "vinbig_bbox_names = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Abnormal finding']\n",
      "vinbig_labels = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'Abnormal finding']\n",
      "num_bbox_classes = 23\n",
      "self.phrase_grounding_masks.shape = (18000, 23, 144)\n",
      "self.phrase_classification_labels.shape = (18000, 23)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 5\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(sorted_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\taortic enlargement seen (Aortic enlargement)\n",
      "\tatelectasis seen (Atelectasis)\n",
      "\tcalcification seen (Calcification)\n",
      "\tcardiomegaly seen (Cardiomegaly)\n",
      "\tclavicle fracture seen (Clavicle fracture)\n",
      "\tconsolidation seen (Consolidation)\n",
      "\tedema seen (Edema)\n",
      "\temphysema seen (Emphysema)\n",
      "\tenlarged pulmonary artery seen (Enlarged PA)\n",
      "\tinterstitial lung disease seen (ILD)\n",
      "\tinfiltration seen (Infiltration)\n",
      "\tlung opacity seen (Lung Opacity)\n",
      "\tlung cavity seen (Lung cavity)\n",
      "\tlung cyst seen (Lung cyst)\n",
      "\tmediastinal shift seen (Mediastinal shift)\n",
      "\tnodule/mass seen (Nodule/Mass)\n",
      "\tother lesion seen (Other lesion)\n",
      "\tpleural effusion seen (Pleural effusion)\n",
      "\tpleural thickening seen (Pleural thickening)\n",
      "\tpneumothorax seen (Pneumothorax)\n",
      "\tpulmonary fibrosis seen (Pulmonary fibrosis)\n",
      "\trib fracture seen (Rib fracture)\n",
      "\tabnormal findings seen (Abnormal finding)\n",
      "\tcopd seen (COPD)\n",
      "\tlung tumor seen (Lung tumor)\n",
      "\tpneumonia seen (Pneumonia)\n",
      "\ttuberculosis seen (Tuberculosis)\n",
      "\tother disease seen (Other disease)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 36\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 919\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Lung Opacity: 2709\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4377\n",
      "Abnormal finding: 4522\n",
      "No labels: 10478\n",
      "Group sizes: [10478, 794, 341, 312, 286, 278, 258, 243, 241, 218, 215, 198, 159, 156, 122, 119, 114, 102, 91, 83, 79, 63, 50]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 794, weight = 893.8899020987899\n",
      "  len(indices) = 341, weight = 595.5934427021492\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 198, weight = 444.08258972130596\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 91, weight = 275.6141558688678\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 63, weight = 213.55551164361594\n",
      "  len(indices) = 50, weight = 179.7743872238934\n",
      "batch_size = 12\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 24\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(vinbig_trainer.train_dataloader) = 83333333333333334\n",
      "len(vinbig_trainer.val_dataloader) = 125\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_103_vbss+vbou+vbuc+vbss=0.4629.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/checkpoint_103_vbss+vbou+vbuc+vbss=0.4629.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 104/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.89174, vbg_vgbbox_loss 0.19456, vbg_att_sup_loss 0.24420, vbg_phrcls_loss 0.45298, vbg_prc_auc 0.85911, 207.19 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22173, vbg_prc_auc 0.48619, 27.89 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mvbg_vgbbox_loss: 0.8371, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_att_sup_loss: 0.8037, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.8591, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 10.2319, den = 12.0000, score = 0.8527\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mvbg_bbox_iou: 0.2217, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.4862, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 5.0836, den = 11.0000, score = 0.4621\u001b[0m\n",
      "\u001b[93mTrain score = 0.8527, Val score = 0.4621, Final score = 0.4817\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_104_vbss+vbou+vbuc+vbss=0.4817.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 105/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.84600, vbg_vgbbox_loss 0.19734, vbg_att_sup_loss 0.22959, vbg_phrcls_loss 0.41908, vbg_prc_auc 0.85743, 204.44 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21703, vbg_prc_auc 0.49069, 27.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_105_vbss+vbou+vbuc+vbss=0.4851.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 106/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.78384, vbg_vgbbox_loss 0.19255, vbg_att_sup_loss 0.21256, vbg_phrcls_loss 0.37874, vbg_prc_auc 0.88399, 203.87 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21905, vbg_prc_auc 0.48897, 27.56 secs\n",
      "\u001b[1m---- Epoch 107/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.76834, vbg_vgbbox_loss 0.19107, vbg_att_sup_loss 0.21062, vbg_phrcls_loss 0.36665, vbg_prc_auc 0.89323, 210.72 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22174, vbg_prc_auc 0.48763, 27.96 secs\n",
      "\u001b[1m---- Epoch 108/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.75150, vbg_vgbbox_loss 0.18777, vbg_att_sup_loss 0.20740, vbg_phrcls_loss 0.35632, vbg_prc_auc 0.90095, 214.75 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22413, vbg_prc_auc 0.48937, 28.71 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_108_vbss+vbou+vbuc+vbss=0.4865.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 109/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.74974, vbg_vgbbox_loss 0.18888, vbg_att_sup_loss 0.20782, vbg_phrcls_loss 0.35303, vbg_prc_auc 0.90167, 215.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22014, vbg_prc_auc 0.48759, 28.83 secs\n",
      "\u001b[1m---- Epoch 110/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.78598, vbg_vgbbox_loss 0.19200, vbg_att_sup_loss 0.21437, vbg_phrcls_loss 0.37960, vbg_prc_auc 0.88532, 223.97 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22687, vbg_prc_auc 0.48066, 28.80 secs\n",
      "\u001b[1m---- Epoch 111/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.74561, vbg_vgbbox_loss 0.18976, vbg_att_sup_loss 0.20591, vbg_phrcls_loss 0.34994, vbg_prc_auc 0.90027, 211.34 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21669, vbg_prc_auc 0.47689, 27.73 secs\n",
      "\u001b[1m---- Epoch 112/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72033, vbg_vgbbox_loss 0.18830, vbg_att_sup_loss 0.20293, vbg_phrcls_loss 0.32911, vbg_prc_auc 0.91390, 217.43 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22086, vbg_prc_auc 0.48154, 28.69 secs\n",
      "\u001b[1m---- Epoch 113/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.71439, vbg_vgbbox_loss 0.18834, vbg_att_sup_loss 0.20089, vbg_phrcls_loss 0.32517, vbg_prc_auc 0.92213, 227.59 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21983, vbg_prc_auc 0.47939, 28.87 secs\n",
      "\u001b[1m---- Epoch 114/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70611, vbg_vgbbox_loss 0.18591, vbg_att_sup_loss 0.19857, vbg_phrcls_loss 0.32162, vbg_prc_auc 0.92406, 229.88 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21633, vbg_prc_auc 0.48006, 29.14 secs\n",
      "\u001b[1m---- Epoch 115/133\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 6975\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1549, in <module>\n",
      "    resume_training(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1505, in resume_training\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 926, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 137, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 991, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 622, in step_fn__vinbig_bbox_grounding\n",
      "    gradient_accumulator.step(batch_loss, model)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 29, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \"models/phrase_grounding/20250203_061403_vinbig_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\" \\\n",
    "--epochs 30 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--max_images_per_batch 12 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 2.0 \\\n",
    "--raw_image_encoding \"cxrmate-rrg24-uniformer-huggingface\" \\\n",
    "--huggingface_model_name \"aehrc/cxrmate-rrg24\" \\\n",
    "--image_size 384 384 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 144 \\\n",
    "--regions_width 12 \\\n",
    "--regions_height 12 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--num_train_workers 3 \\\n",
    "--num_val_workers 3 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\" \\\n",
    "--use_vinbig_with_modified_labels \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
