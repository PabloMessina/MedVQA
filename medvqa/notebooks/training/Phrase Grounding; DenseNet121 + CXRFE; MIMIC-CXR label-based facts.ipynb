{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8288f907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 150\n",
      "   batches_per_epoch: 600\n",
      "   max_images_per_batch: 35\n",
      "   max_phrases_per_batch: 600\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 3.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: densenet-121\n",
      "   num_regions: 169\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 13\n",
      "   regions_height: 13\n",
      "   qkv_size: 256\n",
      "   phrase_classifier_hidden_size: 256\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   iters_to_accumulate: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_all_pos_neg_facts(hash=1013,1477415609053716381).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_bbox_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   img_aug_mode: None\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   vinbig_training_data_mode: train\n",
      "   mask_exponent: 1.0\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: densenet-121\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "mask_exponent = 1.0\n",
      "len(forbidden_train_dicom_ids) = 1030\n",
      "\u001b[1mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596394, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 177946.48it/s]\n",
      "Total number of images: 376105\n",
      "len(train_indices) = 367955\n",
      "len(test_indices) = 8150\n",
      "\u001b[1mBuilding train fact dataloaders...\u001b[0m\n",
      "Number of facts: 30, # images: 361407\n",
      "Number of facts: 27, # images: 751\n",
      "Number of facts: 19, # images: 270\n",
      "Number of facts: 23, # images: 379\n",
      "Number of facts: 24, # images: 423\n",
      "Number of facts: 28, # images: 778\n",
      "Number of facts: 25, # images: 586\n",
      "Number of facts: 29, # images: 724\n",
      "Number of facts: 17, # images: 172\n",
      "Number of facts: 12, # images: 70\n",
      "Number of facts: 22, # images: 334\n",
      "Number of facts: 26, # images: 753\n",
      "Number of facts: 21, # images: 296\n",
      "Number of facts: 20, # images: 282\n",
      "Number of facts: 7, # images: 7\n",
      "Number of facts: 11, # images: 47\n",
      "Number of facts: 16, # images: 119\n",
      "Number of facts: 18, # images: 231\n",
      "Number of facts: 15, # images: 104\n",
      "Number of facts: 10, # images: 26\n",
      "Number of facts: 14, # images: 100\n",
      "Number of facts: 13, # images: 71\n",
      "Number of facts: 9, # images: 11\n",
      "Number of facts: 5, # images: 1\n",
      "Number of facts: 8, # images: 4\n",
      "Number of facts: 6, # images: 5\n",
      "Number of facts: 4, # images: 4\n",
      "len(self.train_fact_dataloader) = 18350\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "Number of facts: 30, # images: 8011\n",
      "Number of facts: 27, # images: 15\n",
      "Number of facts: 28, # images: 13\n",
      "Number of facts: 15, # images: 5\n",
      "Number of facts: 23, # images: 13\n",
      "Number of facts: 29, # images: 26\n",
      "Number of facts: 26, # images: 16\n",
      "Number of facts: 25, # images: 17\n",
      "Number of facts: 18, # images: 3\n",
      "Number of facts: 22, # images: 4\n",
      "Number of facts: 17, # images: 7\n",
      "Number of facts: 14, # images: 2\n",
      "Number of facts: 21, # images: 4\n",
      "Number of facts: 20, # images: 8\n",
      "Number of facts: 24, # images: 2\n",
      "Number of facts: 16, # images: 4\n",
      "len(self.test_fact_dataloader) = 149\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 18350\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 149\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 8.32917, fg_cpg_loss 6.35840, fg_att_reg_loss 0.58452, fg_phrcls_loss 1.38624, 201.12 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 7.15680, fg_att_reg_loss 0.58024, fg_phrcls_loss 1.38550, 47.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.3919.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 7.52266, fg_cpg_loss 5.57951, fg_att_reg_loss 0.56112, fg_phrcls_loss 1.38203, 205.68 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 6.49888, fg_att_reg_loss 0.54122, fg_phrcls_loss 1.38032, 47.35 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4011.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 6.63944, fg_cpg_loss 4.82059, fg_att_reg_loss 0.45215, fg_phrcls_loss 1.36671, 207.43 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 6.10042, fg_att_reg_loss 0.39618, fg_phrcls_loss 1.36329, 47.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4268.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 6.09191, fg_cpg_loss 4.52276, fg_att_reg_loss 0.33561, fg_phrcls_loss 1.23355, 204.83 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.91452, fg_att_reg_loss 0.30155, fg_phrcls_loss 1.13555, 46.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4603.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 5.53019, fg_cpg_loss 4.28314, fg_att_reg_loss 0.26648, fg_phrcls_loss 0.98057, 199.71 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.74511, fg_att_reg_loss 0.28741, fg_phrcls_loss 1.07141, 46.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4718.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 5.36638, fg_cpg_loss 4.18029, fg_att_reg_loss 0.25935, fg_phrcls_loss 0.92673, 202.62 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.69337, fg_att_reg_loss 0.28448, fg_phrcls_loss 1.05303, 47.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4747.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 5.31612, fg_cpg_loss 4.14610, fg_att_reg_loss 0.25664, fg_phrcls_loss 0.91338, 204.06 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.66027, fg_att_reg_loss 0.28163, fg_phrcls_loss 1.04249, 47.39 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4764.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 5.25454, fg_cpg_loss 4.09712, fg_att_reg_loss 0.25477, fg_phrcls_loss 0.90265, 205.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.64748, fg_att_reg_loss 0.28148, fg_phrcls_loss 1.04077, 47.47 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4769.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 5.25120, fg_cpg_loss 4.09521, fg_att_reg_loss 0.25406, fg_phrcls_loss 0.90193, 207.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.61800, fg_att_reg_loss 0.28097, fg_phrcls_loss 1.03785, 47.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4774.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 5.20213, fg_cpg_loss 4.05428, fg_att_reg_loss 0.25283, fg_phrcls_loss 0.89502, 208.25 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.60496, fg_att_reg_loss 0.28052, fg_phrcls_loss 1.03680, 47.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4778.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.20398, fg_cpg_loss 4.05794, fg_att_reg_loss 0.25233, fg_phrcls_loss 0.89370, 200.20 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.60382, fg_att_reg_loss 0.28035, fg_phrcls_loss 1.03882, 47.06 secs\n",
      "\u001b[1m---- Epoch 12/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.21423, fg_cpg_loss 4.06680, fg_att_reg_loss 0.25230, fg_phrcls_loss 0.89514, 203.07 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.60067, fg_att_reg_loss 0.27997, fg_phrcls_loss 1.03502, 47.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4780.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.18219, fg_cpg_loss 4.04795, fg_att_reg_loss 0.24979, fg_phrcls_loss 0.88446, 205.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.54759, fg_att_reg_loss 0.27614, fg_phrcls_loss 1.01190, 47.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4810.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.98926, fg_cpg_loss 3.88877, fg_att_reg_loss 0.24514, fg_phrcls_loss 0.85536, 206.08 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.50139, fg_att_reg_loss 0.27584, fg_phrcls_loss 0.99838, 47.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4830.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.91680, fg_cpg_loss 3.82078, fg_att_reg_loss 0.24745, fg_phrcls_loss 0.84857, 201.04 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.37975, fg_att_reg_loss 0.27797, fg_phrcls_loss 0.98795, 46.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4843.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.87943, fg_cpg_loss 3.78507, fg_att_reg_loss 0.24865, fg_phrcls_loss 0.84572, 201.10 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.36007, fg_att_reg_loss 0.27886, fg_phrcls_loss 0.98285, 47.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4848.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.82714, fg_cpg_loss 3.73885, fg_att_reg_loss 0.24892, fg_phrcls_loss 0.83937, 203.96 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.32345, fg_att_reg_loss 0.27975, fg_phrcls_loss 0.97744, 47.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4854.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.78592, fg_cpg_loss 3.70648, fg_att_reg_loss 0.24804, fg_phrcls_loss 0.83140, 206.02 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.32414, fg_att_reg_loss 0.28026, fg_phrcls_loss 0.98085, 47.48 secs\n",
      "\u001b[1m---- Epoch 19/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.79218, fg_cpg_loss 3.70839, fg_att_reg_loss 0.24950, fg_phrcls_loss 0.83429, 204.64 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.30760, fg_att_reg_loss 0.28033, fg_phrcls_loss 0.97720, 47.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4855.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.82960, fg_cpg_loss 3.74041, fg_att_reg_loss 0.25026, fg_phrcls_loss 0.83894, 200.98 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.30983, fg_att_reg_loss 0.28046, fg_phrcls_loss 0.97841, 47.03 secs\n",
      "\u001b[1m---- Epoch 21/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.83760, fg_cpg_loss 3.75887, fg_att_reg_loss 0.25150, fg_phrcls_loss 0.82723, 203.53 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.33291, fg_att_reg_loss 0.28360, fg_phrcls_loss 0.96257, 47.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4858.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.72653, fg_cpg_loss 3.66464, fg_att_reg_loss 0.25246, fg_phrcls_loss 0.80943, 205.86 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.26002, fg_att_reg_loss 0.28372, fg_phrcls_loss 0.94205, 47.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4883.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.67531, fg_cpg_loss 3.62768, fg_att_reg_loss 0.25214, fg_phrcls_loss 0.79548, 206.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.20105, fg_att_reg_loss 0.28454, fg_phrcls_loss 0.93457, 47.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4894.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.63105, fg_cpg_loss 3.58959, fg_att_reg_loss 0.25200, fg_phrcls_loss 0.78946, 201.51 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.18188, fg_att_reg_loss 0.28470, fg_phrcls_loss 0.92858, 46.81 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4901.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.63688, fg_cpg_loss 3.59535, fg_att_reg_loss 0.25248, fg_phrcls_loss 0.78905, 201.90 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 5.19986, fg_att_reg_loss 0.28480, fg_phrcls_loss 0.92931, 47.21 secs\n",
      "\u001b[1m---- Epoch 26/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.60875, fg_cpg_loss 3.57643, fg_att_reg_loss 0.25146, fg_phrcls_loss 0.78086, 205.05 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.18973, fg_att_reg_loss 0.28477, fg_phrcls_loss 0.93021, 47.39 secs\n",
      "\u001b[1m---- Epoch 27/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.57924, fg_cpg_loss 3.54534, fg_att_reg_loss 0.25175, fg_phrcls_loss 0.78215, 204.34 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.17427, fg_att_reg_loss 0.28452, fg_phrcls_loss 0.92532, 46.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4906.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.57673, fg_cpg_loss 3.54650, fg_att_reg_loss 0.25143, fg_phrcls_loss 0.77880, 201.32 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.19554, fg_att_reg_loss 0.28556, fg_phrcls_loss 0.92903, 46.99 secs\n",
      "\u001b[1m---- Epoch 29/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.65946, fg_cpg_loss 3.62596, fg_att_reg_loss 0.25293, fg_phrcls_loss 0.78056, 203.87 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.23041, fg_att_reg_loss 0.28796, fg_phrcls_loss 0.91074, 47.30 secs\n",
      "\u001b[1m---- Epoch 30/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.62997, fg_cpg_loss 3.60584, fg_att_reg_loss 0.25467, fg_phrcls_loss 0.76946, 205.67 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 5.17187, fg_att_reg_loss 0.28533, fg_phrcls_loss 0.89643, 47.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_30_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4928.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 31/150\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "Current run is terminating due to exception: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.76 GiB total capacity; 9.13 GiB already allocated; 8.56 MiB free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Engine run is terminating due to exception: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.76 GiB total capacity; 9.13 GiB already allocated; 8.56 MiB free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 976, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 850, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 541, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 134, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1087, in _run_once_on_dataset_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 472, in step_fn\n",
      "    output = step_fn__fact_grounding(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 84, in step_fn__fact_grounding\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/phrase_grounding/phrase_grounder.py\", line 98, in forward\n",
      "    output = super().forward(\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 698, in forward\n",
      "    local_feat_NxCxHxW = self.raw_image_encoder(raw_images)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torchvision/models/densenet.py\", line 123, in forward\n",
      "    new_features = layer(features)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torchvision/models/densenet.py\", line 89, in forward\n",
      "    bottleneck_output = self.bn_function(prev_features)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torchvision/models/densenet.py\", line 49, in bn_function\n",
      "    concated_features = torch.cat(inputs, 1)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.76 GiB total capacity; 9.13 GiB already allocated; 8.56 MiB free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--epochs 150 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--max_images_per_batch 35 \\\n",
    "--max_phrases_per_batch 600 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 3.0 \\\n",
    "--raw_image_encoding \"densenet-121\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 1024 \\\n",
    "--num_regions 169 \\\n",
    "--regions_width 13 \\\n",
    "--regions_height 13 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--qkv_size 256 \\\n",
    "--phrase_classifier_hidden_size 256 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--iters_to_accumulate 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_all_pos_neg_facts(hash=1013,1477415609053716381).pkl\" \\\n",
    "--exclude_noisy_images \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7f771b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 600\n",
      "   max_images_per_batch: 20\n",
      "   max_phrases_per_batch: 250\n",
      "   max_phrases_per_image: 20\n",
      "   val_batch_size_factor: 2.0\n",
      "   checkpoint_folder: models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: densenet-121\n",
      "   num_regions: 169\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 13\n",
      "   regions_height: 13\n",
      "   qkv_size: 256\n",
      "   phrase_classifier_hidden_size: 256\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   iters_to_accumulate: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_all_pos_neg_facts(hash=1013,1477415609053716381).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_bbox_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   img_aug_mode: None\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   vinbig_training_data_mode: train\n",
      "   mask_exponent: 1.0\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: densenet-121\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "mask_exponent = 1.0\n",
      "len(forbidden_train_dicom_ids) = 1030\n",
      "\u001b[1mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596394, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 177832.70it/s]\n",
      "Total number of images: 376105\n",
      "len(train_indices) = 367955\n",
      "len(test_indices) = 8150\n",
      "\u001b[1mBuilding train fact dataloaders...\u001b[0m\n",
      "Number of facts: 20, # images: 366713\n",
      "Number of facts: 19, # images: 270\n",
      "Number of facts: 17, # images: 172\n",
      "Number of facts: 12, # images: 70\n",
      "Number of facts: 7, # images: 7\n",
      "Number of facts: 11, # images: 47\n",
      "Number of facts: 16, # images: 119\n",
      "Number of facts: 18, # images: 231\n",
      "Number of facts: 15, # images: 104\n",
      "Number of facts: 10, # images: 26\n",
      "Number of facts: 14, # images: 100\n",
      "Number of facts: 13, # images: 71\n",
      "Number of facts: 9, # images: 11\n",
      "Number of facts: 5, # images: 1\n",
      "Number of facts: 8, # images: 4\n",
      "Number of facts: 6, # images: 5\n",
      "Number of facts: 4, # images: 4\n",
      "len(self.train_fact_dataloader) = 30652\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "Number of facts: 20, # images: 8129\n",
      "Number of facts: 15, # images: 5\n",
      "Number of facts: 18, # images: 3\n",
      "Number of facts: 17, # images: 7\n",
      "Number of facts: 14, # images: 2\n",
      "Number of facts: 16, # images: 4\n",
      "len(self.test_fact_dataloader) = 344\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 30652\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 344\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_163_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5368.pt', 'checkpoint_194_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5431.pt', 'checkpoint_234_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5470.pt', 'checkpoint_129_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5307.pt', 'checkpoint_30_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4928.pt', 'checkpoint_91_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5153.pt', 'checkpoint_60_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5050.pt', 'checkpoint_275_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5471.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/checkpoint_275_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5471.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 276/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.00428, fg_cpg_loss 2.25364, fg_att_reg_loss 0.22858, fg_phrcls_loss 0.52206, 118.50 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46266, fg_att_reg_loss 0.26314, fg_phrcls_loss 0.62610, 44.32 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_276_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5485.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 277/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.16641, fg_cpg_loss 2.39684, fg_att_reg_loss 0.23076, fg_phrcls_loss 0.53881, 122.00 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.54235, fg_att_reg_loss 0.26445, fg_phrcls_loss 0.64522, 43.95 secs\n",
      "\u001b[1m---- Epoch 278/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.14346, fg_cpg_loss 2.37117, fg_att_reg_loss 0.23155, fg_phrcls_loss 0.54073, 121.01 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.58739, fg_att_reg_loss 0.26377, fg_phrcls_loss 0.65002, 43.98 secs\n",
      "\u001b[1m---- Epoch 279/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.09015, fg_cpg_loss 2.32956, fg_att_reg_loss 0.22922, fg_phrcls_loss 0.53136, 120.97 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46809, fg_att_reg_loss 0.26495, fg_phrcls_loss 0.63007, 44.30 secs\n",
      "\u001b[1m---- Epoch 280/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.97796, fg_cpg_loss 2.23515, fg_att_reg_loss 0.22776, fg_phrcls_loss 0.51505, 120.04 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46345, fg_att_reg_loss 0.26506, fg_phrcls_loss 0.62813, 44.59 secs\n",
      "\u001b[1m---- Epoch 281/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.01802, fg_cpg_loss 2.26601, fg_att_reg_loss 0.22983, fg_phrcls_loss 0.52218, 121.62 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48452, fg_att_reg_loss 0.26465, fg_phrcls_loss 0.62859, 44.29 secs\n",
      "\u001b[1m---- Epoch 282/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.03913, fg_cpg_loss 2.28816, fg_att_reg_loss 0.22989, fg_phrcls_loss 0.52108, 120.96 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45901, fg_att_reg_loss 0.26412, fg_phrcls_loss 0.62467, 44.54 secs\n",
      "\u001b[1m---- Epoch 283/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.04021, fg_cpg_loss 2.28898, fg_att_reg_loss 0.22989, fg_phrcls_loss 0.52135, 121.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45034, fg_att_reg_loss 0.26332, fg_phrcls_loss 0.62276, 44.65 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_283_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5489.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 284/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.99811, fg_cpg_loss 2.25162, fg_att_reg_loss 0.22868, fg_phrcls_loss 0.51781, 120.13 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.49678, fg_att_reg_loss 0.26443, fg_phrcls_loss 0.62713, 43.87 secs\n",
      "\u001b[1m---- Epoch 285/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.12645, fg_cpg_loss 2.35847, fg_att_reg_loss 0.23090, fg_phrcls_loss 0.53709, 122.68 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.56244, fg_att_reg_loss 0.26443, fg_phrcls_loss 0.64575, 43.60 secs\n",
      "\u001b[1m---- Epoch 286/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.10909, fg_cpg_loss 2.34635, fg_att_reg_loss 0.22991, fg_phrcls_loss 0.53283, 120.89 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.49082, fg_att_reg_loss 0.26292, fg_phrcls_loss 0.63170, 44.08 secs\n",
      "\u001b[1m---- Epoch 287/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.10194, fg_cpg_loss 2.34361, fg_att_reg_loss 0.22983, fg_phrcls_loss 0.52849, 121.07 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47121, fg_att_reg_loss 0.26485, fg_phrcls_loss 0.62921, 44.33 secs\n",
      "\u001b[1m---- Epoch 288/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.04221, fg_cpg_loss 2.29361, fg_att_reg_loss 0.22805, fg_phrcls_loss 0.52055, 121.62 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46102, fg_att_reg_loss 0.26490, fg_phrcls_loss 0.62315, 44.54 secs\n",
      "\u001b[1m---- Epoch 289/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.02364, fg_cpg_loss 2.27340, fg_att_reg_loss 0.22900, fg_phrcls_loss 0.52123, 121.73 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44766, fg_att_reg_loss 0.26477, fg_phrcls_loss 0.62384, 44.62 secs\n",
      "\u001b[1m---- Epoch 290/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.00313, fg_cpg_loss 2.25786, fg_att_reg_loss 0.23004, fg_phrcls_loss 0.51522, 121.68 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46687, fg_att_reg_loss 0.26456, fg_phrcls_loss 0.62401, 44.32 secs\n",
      "\u001b[1m---- Epoch 291/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.00561, fg_cpg_loss 2.25959, fg_att_reg_loss 0.22849, fg_phrcls_loss 0.51752, 120.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44156, fg_att_reg_loss 0.26281, fg_phrcls_loss 0.62309, 43.84 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_291_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5493.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 292/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.01610, fg_cpg_loss 2.26924, fg_att_reg_loss 0.22882, fg_phrcls_loss 0.51804, 121.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45404, fg_att_reg_loss 0.26318, fg_phrcls_loss 0.62196, 44.22 secs\n",
      "\u001b[1m---- Epoch 293/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.11991, fg_cpg_loss 2.34903, fg_att_reg_loss 0.23068, fg_phrcls_loss 0.54020, 121.19 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.60627, fg_att_reg_loss 0.26415, fg_phrcls_loss 0.64822, 44.28 secs\n",
      "\u001b[1m---- Epoch 294/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.09905, fg_cpg_loss 2.33935, fg_att_reg_loss 0.22933, fg_phrcls_loss 0.53037, 120.86 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51949, fg_att_reg_loss 0.26248, fg_phrcls_loss 0.63434, 44.34 secs\n",
      "\u001b[1m---- Epoch 295/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.05696, fg_cpg_loss 2.30581, fg_att_reg_loss 0.22780, fg_phrcls_loss 0.52335, 120.64 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46410, fg_att_reg_loss 0.26314, fg_phrcls_loss 0.62755, 44.43 secs\n",
      "\u001b[1m---- Epoch 296/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.07711, fg_cpg_loss 2.31861, fg_att_reg_loss 0.22972, fg_phrcls_loss 0.52878, 122.28 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47617, fg_att_reg_loss 0.26283, fg_phrcls_loss 0.62780, 44.55 secs\n",
      "\u001b[1m---- Epoch 297/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.99817, fg_cpg_loss 2.25242, fg_att_reg_loss 0.22652, fg_phrcls_loss 0.51923, 122.12 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47092, fg_att_reg_loss 0.26232, fg_phrcls_loss 0.62312, 44.75 secs\n",
      "\u001b[1m---- Epoch 298/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.95854, fg_cpg_loss 2.22147, fg_att_reg_loss 0.22506, fg_phrcls_loss 0.51201, 121.71 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47764, fg_att_reg_loss 0.26242, fg_phrcls_loss 0.62873, 43.90 secs\n",
      "\u001b[1m---- Epoch 299/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.01200, fg_cpg_loss 2.26472, fg_att_reg_loss 0.22768, fg_phrcls_loss 0.51960, 121.55 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43434, fg_att_reg_loss 0.26217, fg_phrcls_loss 0.62058, 43.52 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_299_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5498.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 300/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.95022, fg_cpg_loss 2.21191, fg_att_reg_loss 0.22600, fg_phrcls_loss 0.51232, 121.63 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.49399, fg_att_reg_loss 0.26269, fg_phrcls_loss 0.62545, 43.80 secs\n",
      "\u001b[1m---- Epoch 301/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.08841, fg_cpg_loss 2.33074, fg_att_reg_loss 0.22699, fg_phrcls_loss 0.53068, 121.00 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.57680, fg_att_reg_loss 0.26610, fg_phrcls_loss 0.64227, 44.19 secs\n",
      "\u001b[1m---- Epoch 302/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.04072, fg_cpg_loss 2.28767, fg_att_reg_loss 0.22887, fg_phrcls_loss 0.52419, 120.48 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.52472, fg_att_reg_loss 0.26380, fg_phrcls_loss 0.62948, 44.19 secs\n",
      "\u001b[1m---- Epoch 303/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.00470, fg_cpg_loss 2.25717, fg_att_reg_loss 0.22687, fg_phrcls_loss 0.52067, 121.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46782, fg_att_reg_loss 0.26440, fg_phrcls_loss 0.62366, 44.70 secs\n",
      "\u001b[1m---- Epoch 304/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.98536, fg_cpg_loss 2.24037, fg_att_reg_loss 0.22721, fg_phrcls_loss 0.51778, 122.48 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48232, fg_att_reg_loss 0.26352, fg_phrcls_loss 0.62306, 44.72 secs\n",
      "\u001b[1m---- Epoch 305/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.98679, fg_cpg_loss 2.24524, fg_att_reg_loss 0.22772, fg_phrcls_loss 0.51382, 121.14 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43832, fg_att_reg_loss 0.26261, fg_phrcls_loss 0.62162, 44.55 secs\n",
      "\u001b[1m---- Epoch 306/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.00364, fg_cpg_loss 2.25984, fg_att_reg_loss 0.22756, fg_phrcls_loss 0.51625, 120.92 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 3.45442, fg_att_reg_loss 0.26273, fg_phrcls_loss 0.62055, 44.69 secs\n",
      "\u001b[1m---- Epoch 307/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.97923, fg_cpg_loss 2.24243, fg_att_reg_loss 0.22614, fg_phrcls_loss 0.51065, 122.03 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44909, fg_att_reg_loss 0.26374, fg_phrcls_loss 0.62250, 44.63 secs\n",
      "\u001b[1m---- Epoch 308/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.01048, fg_cpg_loss 2.26620, fg_att_reg_loss 0.22782, fg_phrcls_loss 0.51646, 122.29 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42272, fg_att_reg_loss 0.26355, fg_phrcls_loss 0.62036, 44.97 secs\n",
      "\u001b[1m---- Epoch 309/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.06968, fg_cpg_loss 2.31883, fg_att_reg_loss 0.22683, fg_phrcls_loss 0.52401, 120.87 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.55534, fg_att_reg_loss 0.26430, fg_phrcls_loss 0.64245, 43.76 secs\n",
      "\u001b[1m---- Epoch 310/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.08673, fg_cpg_loss 2.32913, fg_att_reg_loss 0.22923, fg_phrcls_loss 0.52837, 122.59 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50350, fg_att_reg_loss 0.26349, fg_phrcls_loss 0.63240, 44.00 secs\n",
      "\u001b[1m---- Epoch 311/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.07028, fg_cpg_loss 2.31551, fg_att_reg_loss 0.22941, fg_phrcls_loss 0.52536, 122.04 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46281, fg_att_reg_loss 0.26284, fg_phrcls_loss 0.62474, 43.67 secs\n",
      "\u001b[1m---- Epoch 312/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.03250, fg_cpg_loss 2.28665, fg_att_reg_loss 0.22643, fg_phrcls_loss 0.51941, 121.40 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47359, fg_att_reg_loss 0.26315, fg_phrcls_loss 0.62182, 43.67 secs\n",
      "\u001b[1m---- Epoch 313/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.98677, fg_cpg_loss 2.24402, fg_att_reg_loss 0.22691, fg_phrcls_loss 0.51584, 120.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44166, fg_att_reg_loss 0.26259, fg_phrcls_loss 0.61668, 43.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_313_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5501.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 314/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.01159, fg_cpg_loss 2.27068, fg_att_reg_loss 0.22624, fg_phrcls_loss 0.51466, 120.13 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43245, fg_att_reg_loss 0.26294, fg_phrcls_loss 0.61627, 43.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_314_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5502.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 315/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.02380, fg_cpg_loss 2.27771, fg_att_reg_loss 0.22894, fg_phrcls_loss 0.51715, 120.44 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43552, fg_att_reg_loss 0.26326, fg_phrcls_loss 0.61840, 44.44 secs\n",
      "\u001b[1m---- Epoch 316/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.00630, fg_cpg_loss 2.26438, fg_att_reg_loss 0.22746, fg_phrcls_loss 0.51446, 121.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45380, fg_att_reg_loss 0.26353, fg_phrcls_loss 0.61922, 44.66 secs\n",
      "\u001b[1m---- Epoch 317/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.13456, fg_cpg_loss 2.37056, fg_att_reg_loss 0.22989, fg_phrcls_loss 0.53411, 121.84 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51308, fg_att_reg_loss 0.26396, fg_phrcls_loss 0.63598, 44.75 secs\n",
      "\u001b[1m---- Epoch 318/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.08594, fg_cpg_loss 2.32818, fg_att_reg_loss 0.22916, fg_phrcls_loss 0.52860, 121.10 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47128, fg_att_reg_loss 0.26245, fg_phrcls_loss 0.62891, 44.33 secs\n",
      "\u001b[1m---- Epoch 319/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.05878, fg_cpg_loss 2.30855, fg_att_reg_loss 0.22716, fg_phrcls_loss 0.52306, 120.33 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47278, fg_att_reg_loss 0.26140, fg_phrcls_loss 0.62326, 43.88 secs\n",
      "\u001b[1m---- Epoch 320/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.99321, fg_cpg_loss 2.25414, fg_att_reg_loss 0.22698, fg_phrcls_loss 0.51209, 122.02 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42863, fg_att_reg_loss 0.26118, fg_phrcls_loss 0.62199, 43.99 secs\n",
      "\u001b[1m---- Epoch 321/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.96238, fg_cpg_loss 2.22689, fg_att_reg_loss 0.22568, fg_phrcls_loss 0.50981, 120.31 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43529, fg_att_reg_loss 0.26066, fg_phrcls_loss 0.62049, 44.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_321_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5503.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 322/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.97594, fg_cpg_loss 2.24058, fg_att_reg_loss 0.22650, fg_phrcls_loss 0.50886, 120.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44710, fg_att_reg_loss 0.26109, fg_phrcls_loss 0.61909, 44.64 secs\n",
      "\u001b[1m---- Epoch 323/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.95621, fg_cpg_loss 2.22307, fg_att_reg_loss 0.22597, fg_phrcls_loss 0.50717, 120.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42851, fg_att_reg_loss 0.26187, fg_phrcls_loss 0.61718, 44.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_323_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5506.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 324/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.01313, fg_cpg_loss 2.26728, fg_att_reg_loss 0.22777, fg_phrcls_loss 0.51808, 121.74 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42667, fg_att_reg_loss 0.26107, fg_phrcls_loss 0.61332, 44.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_324_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5509.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 325/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.16836, fg_cpg_loss 2.40307, fg_att_reg_loss 0.22820, fg_phrcls_loss 0.53709, 120.66 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.54804, fg_att_reg_loss 0.26385, fg_phrcls_loss 0.63817, 44.68 secs\n",
      "\u001b[1m---- Epoch 326/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.25233, fg_cpg_loss 2.47038, fg_att_reg_loss 0.23390, fg_phrcls_loss 0.54805, 124.13 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.67180, fg_att_reg_loss 0.26787, fg_phrcls_loss 0.68212, 43.75 secs\n",
      "\u001b[1m---- Epoch 327/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.35051, fg_cpg_loss 2.53052, fg_att_reg_loss 0.23780, fg_phrcls_loss 0.58219, 126.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.47775, fg_att_reg_loss 0.26308, fg_phrcls_loss 0.62325, 43.78 secs\n",
      "\u001b[1m---- Epoch 328/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.01748, fg_cpg_loss 2.27681, fg_att_reg_loss 0.22622, fg_phrcls_loss 0.51445, 122.07 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44093, fg_att_reg_loss 0.26244, fg_phrcls_loss 0.62157, 43.67 secs\n",
      "\u001b[1m---- Epoch 329/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.97907, fg_cpg_loss 2.23655, fg_att_reg_loss 0.22968, fg_phrcls_loss 0.51284, 121.98 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44102, fg_att_reg_loss 0.26367, fg_phrcls_loss 0.62053, 43.87 secs\n",
      "\u001b[1m---- Epoch 330/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.96288, fg_cpg_loss 2.22918, fg_att_reg_loss 0.22520, fg_phrcls_loss 0.50850, 121.30 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43058, fg_att_reg_loss 0.26213, fg_phrcls_loss 0.61759, 43.87 secs\n",
      "\u001b[1m---- Epoch 331/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.96411, fg_cpg_loss 2.22623, fg_att_reg_loss 0.22713, fg_phrcls_loss 0.51075, 120.48 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44890, fg_att_reg_loss 0.26293, fg_phrcls_loss 0.61628, 44.34 secs\n",
      "\u001b[1m---- Epoch 332/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.96038, fg_cpg_loss 2.22089, fg_att_reg_loss 0.22812, fg_phrcls_loss 0.51137, 122.20 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44970, fg_att_reg_loss 0.26191, fg_phrcls_loss 0.61789, 44.56 secs\n",
      "\u001b[1m---- Epoch 333/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.11360, fg_cpg_loss 2.35314, fg_att_reg_loss 0.22899, fg_phrcls_loss 0.53147, 121.52 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.61082, fg_att_reg_loss 0.26264, fg_phrcls_loss 0.65564, 44.06 secs\n",
      "\u001b[1m---- Epoch 334/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.05758, fg_cpg_loss 2.30687, fg_att_reg_loss 0.22812, fg_phrcls_loss 0.52258, 120.44 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50036, fg_att_reg_loss 0.26350, fg_phrcls_loss 0.62571, 43.69 secs\n",
      "\u001b[1m---- Epoch 335/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.00898, fg_cpg_loss 2.26225, fg_att_reg_loss 0.22935, fg_phrcls_loss 0.51738, 121.27 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 3.44183, fg_att_reg_loss 0.26327, fg_phrcls_loss 0.62158, 43.90 secs\n",
      "\u001b[1m---- Epoch 336/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.99346, fg_cpg_loss 2.25214, fg_att_reg_loss 0.22717, fg_phrcls_loss 0.51415, 120.36 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45328, fg_att_reg_loss 0.26306, fg_phrcls_loss 0.61911, 43.95 secs\n",
      "\u001b[1m---- Epoch 337/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.93370, fg_cpg_loss 2.20436, fg_att_reg_loss 0.22566, fg_phrcls_loss 0.50368, 120.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43855, fg_att_reg_loss 0.26322, fg_phrcls_loss 0.61802, 44.18 secs\n",
      "\u001b[1m---- Epoch 338/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.02008, fg_cpg_loss 2.27504, fg_att_reg_loss 0.22903, fg_phrcls_loss 0.51601, 121.11 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39818, fg_att_reg_loss 0.26231, fg_phrcls_loss 0.61527, 44.42 secs\n",
      "\u001b[1m---- Epoch 339/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.98930, fg_cpg_loss 2.24885, fg_att_reg_loss 0.22743, fg_phrcls_loss 0.51302, 121.81 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42561, fg_att_reg_loss 0.26228, fg_phrcls_loss 0.61588, 44.58 secs\n",
      "\u001b[1m---- Epoch 340/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.01835, fg_cpg_loss 2.27253, fg_att_reg_loss 0.22908, fg_phrcls_loss 0.51674, 120.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44062, fg_att_reg_loss 0.26204, fg_phrcls_loss 0.61520, 43.75 secs\n",
      "\u001b[1m---- Epoch 341/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.07707, fg_cpg_loss 2.32445, fg_att_reg_loss 0.22875, fg_phrcls_loss 0.52387, 120.71 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50565, fg_att_reg_loss 0.26222, fg_phrcls_loss 0.63350, 43.60 secs\n",
      "\u001b[1m---- Epoch 342/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.04428, fg_cpg_loss 2.29493, fg_att_reg_loss 0.22812, fg_phrcls_loss 0.52123, 119.34 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.49247, fg_att_reg_loss 0.26249, fg_phrcls_loss 0.63139, 43.90 secs\n",
      "\u001b[1m---- Epoch 343/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.00580, fg_cpg_loss 2.26154, fg_att_reg_loss 0.22752, fg_phrcls_loss 0.51674, 120.80 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.49263, fg_att_reg_loss 0.26316, fg_phrcls_loss 0.62674, 44.27 secs\n",
      "\u001b[1m---- Epoch 344/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.01236, fg_cpg_loss 2.27469, fg_att_reg_loss 0.22668, fg_phrcls_loss 0.51098, 121.41 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43110, fg_att_reg_loss 0.26207, fg_phrcls_loss 0.61733, 44.37 secs\n",
      "\u001b[1m---- Epoch 345/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.00567, fg_cpg_loss 2.26403, fg_att_reg_loss 0.22750, fg_phrcls_loss 0.51414, 121.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41161, fg_att_reg_loss 0.26163, fg_phrcls_loss 0.61469, 44.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_345_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5510.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 346/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.98606, fg_cpg_loss 2.24809, fg_att_reg_loss 0.22738, fg_phrcls_loss 0.51059, 122.36 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43241, fg_att_reg_loss 0.26217, fg_phrcls_loss 0.61852, 44.39 secs\n",
      "\u001b[1m---- Epoch 347/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.94430, fg_cpg_loss 2.21329, fg_att_reg_loss 0.22533, fg_phrcls_loss 0.50568, 120.86 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42627, fg_att_reg_loss 0.26177, fg_phrcls_loss 0.61420, 43.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_347_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5511.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 348/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.99060, fg_cpg_loss 2.25096, fg_att_reg_loss 0.22785, fg_phrcls_loss 0.51179, 121.18 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39982, fg_att_reg_loss 0.26166, fg_phrcls_loss 0.61267, 44.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_348_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5514.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 349/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.07134, fg_cpg_loss 2.31316, fg_att_reg_loss 0.22891, fg_phrcls_loss 0.52927, 121.32 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51859, fg_att_reg_loss 0.26431, fg_phrcls_loss 0.63150, 44.12 secs\n",
      "\u001b[1m---- Epoch 350/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.02250, fg_cpg_loss 2.28021, fg_att_reg_loss 0.22622, fg_phrcls_loss 0.51607, 121.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50358, fg_att_reg_loss 0.26237, fg_phrcls_loss 0.62871, 44.58 secs\n",
      "\u001b[1m---- Epoch 351/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.00420, fg_cpg_loss 2.26379, fg_att_reg_loss 0.22644, fg_phrcls_loss 0.51398, 122.15 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44423, fg_att_reg_loss 0.26020, fg_phrcls_loss 0.62128, 44.42 secs\n",
      "\u001b[1m---- Epoch 352/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.94312, fg_cpg_loss 2.21291, fg_att_reg_loss 0.22503, fg_phrcls_loss 0.50518, 121.22 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44521, fg_att_reg_loss 0.26093, fg_phrcls_loss 0.61799, 43.77 secs\n",
      "\u001b[1m---- Epoch 353/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.93838, fg_cpg_loss 2.20707, fg_att_reg_loss 0.22493, fg_phrcls_loss 0.50638, 122.15 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44281, fg_att_reg_loss 0.26029, fg_phrcls_loss 0.61662, 43.51 secs\n",
      "\u001b[1m---- Epoch 354/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.91826, fg_cpg_loss 2.19009, fg_att_reg_loss 0.22456, fg_phrcls_loss 0.50361, 120.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43139, fg_att_reg_loss 0.26011, fg_phrcls_loss 0.60948, 43.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_354_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5520.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 355/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.91220, fg_cpg_loss 2.18414, fg_att_reg_loss 0.22459, fg_phrcls_loss 0.50347, 121.07 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43982, fg_att_reg_loss 0.26083, fg_phrcls_loss 0.61331, 44.14 secs\n",
      "\u001b[1m---- Epoch 356/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.93305, fg_cpg_loss 2.20404, fg_att_reg_loss 0.22572, fg_phrcls_loss 0.50329, 122.22 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41680, fg_att_reg_loss 0.26115, fg_phrcls_loss 0.61367, 43.98 secs\n",
      "\u001b[1m---- Epoch 357/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.06862, fg_cpg_loss 2.32018, fg_att_reg_loss 0.22482, fg_phrcls_loss 0.52361, 121.25 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.52203, fg_att_reg_loss 0.26127, fg_phrcls_loss 0.63384, 44.37 secs\n",
      "\u001b[1m---- Epoch 358/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.02277, fg_cpg_loss 2.28248, fg_att_reg_loss 0.22527, fg_phrcls_loss 0.51501, 121.51 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51319, fg_att_reg_loss 0.26219, fg_phrcls_loss 0.62777, 44.06 secs\n",
      "\u001b[1m---- Epoch 359/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.00239, fg_cpg_loss 2.26372, fg_att_reg_loss 0.22768, fg_phrcls_loss 0.51100, 122.08 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45827, fg_att_reg_loss 0.26130, fg_phrcls_loss 0.61831, 44.31 secs\n",
      "\u001b[1m---- Epoch 360/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.00191, fg_cpg_loss 2.26703, fg_att_reg_loss 0.22610, fg_phrcls_loss 0.50878, 120.76 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42760, fg_att_reg_loss 0.26169, fg_phrcls_loss 0.61568, 44.39 secs\n",
      "\u001b[1m---- Epoch 361/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.94829, fg_cpg_loss 2.21612, fg_att_reg_loss 0.22608, fg_phrcls_loss 0.50608, 121.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44023, fg_att_reg_loss 0.26081, fg_phrcls_loss 0.61255, 43.67 secs\n",
      "\u001b[1m---- Epoch 362/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.96967, fg_cpg_loss 2.23135, fg_att_reg_loss 0.22819, fg_phrcls_loss 0.51013, 121.40 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43900, fg_att_reg_loss 0.26075, fg_phrcls_loss 0.61246, 43.50 secs\n",
      "\u001b[1m---- Epoch 363/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.92947, fg_cpg_loss 2.20472, fg_att_reg_loss 0.22306, fg_phrcls_loss 0.50169, 122.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38192, fg_att_reg_loss 0.26037, fg_phrcls_loss 0.61161, 43.85 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_363_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5525.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 364/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.97778, fg_cpg_loss 2.24048, fg_att_reg_loss 0.22814, fg_phrcls_loss 0.50916, 122.43 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 3.43824, fg_att_reg_loss 0.26149, fg_phrcls_loss 0.61213, 43.67 secs\n",
      "\u001b[1m---- Epoch 365/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.07789, fg_cpg_loss 2.32407, fg_att_reg_loss 0.22731, fg_phrcls_loss 0.52650, 122.54 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51330, fg_att_reg_loss 0.26200, fg_phrcls_loss 0.62899, 44.01 secs\n",
      "\u001b[1m---- Epoch 366/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.02950, fg_cpg_loss 2.28343, fg_att_reg_loss 0.22829, fg_phrcls_loss 0.51778, 122.17 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44015, fg_att_reg_loss 0.26255, fg_phrcls_loss 0.61994, 44.04 secs\n",
      "\u001b[1m---- Epoch 367/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.04603, fg_cpg_loss 2.30115, fg_att_reg_loss 0.22814, fg_phrcls_loss 0.51673, 121.57 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43695, fg_att_reg_loss 0.26128, fg_phrcls_loss 0.61355, 44.23 secs\n",
      "\u001b[1m---- Epoch 368/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.98558, fg_cpg_loss 2.25012, fg_att_reg_loss 0.22690, fg_phrcls_loss 0.50857, 122.59 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41951, fg_att_reg_loss 0.26175, fg_phrcls_loss 0.61555, 44.25 secs\n",
      "\u001b[1m---- Epoch 369/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.96454, fg_cpg_loss 2.23699, fg_att_reg_loss 0.22500, fg_phrcls_loss 0.50254, 121.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40276, fg_att_reg_loss 0.26081, fg_phrcls_loss 0.61044, 44.09 secs\n",
      "\u001b[1m---- Epoch 370/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.99581, fg_cpg_loss 2.25913, fg_att_reg_loss 0.22569, fg_phrcls_loss 0.51100, 121.36 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44262, fg_att_reg_loss 0.26117, fg_phrcls_loss 0.61308, 44.40 secs\n",
      "\u001b[1m---- Epoch 371/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.00436, fg_cpg_loss 2.26546, fg_att_reg_loss 0.22697, fg_phrcls_loss 0.51193, 121.31 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43215, fg_att_reg_loss 0.26161, fg_phrcls_loss 0.61219, 44.11 secs\n",
      "\u001b[1m---- Epoch 372/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.94431, fg_cpg_loss 2.21512, fg_att_reg_loss 0.22594, fg_phrcls_loss 0.50325, 121.61 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40977, fg_att_reg_loss 0.26080, fg_phrcls_loss 0.61019, 43.97 secs\n",
      "\u001b[1m---- Epoch 373/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.05690, fg_cpg_loss 2.30944, fg_att_reg_loss 0.22814, fg_phrcls_loss 0.51932, 121.90 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50926, fg_att_reg_loss 0.26287, fg_phrcls_loss 0.63033, 44.00 secs\n",
      "\u001b[1m---- Epoch 374/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.05226, fg_cpg_loss 2.30494, fg_att_reg_loss 0.22723, fg_phrcls_loss 0.52009, 120.83 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48767, fg_att_reg_loss 0.26161, fg_phrcls_loss 0.62356, 44.03 secs\n",
      "\u001b[1m---- Epoch 375/375\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.98960, fg_cpg_loss 2.25184, fg_att_reg_loss 0.22791, fg_phrcls_loss 0.50985, 121.24 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39858, fg_att_reg_loss 0.26135, fg_phrcls_loss 0.61371, 44.42 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--max_images_per_batch 20 \\\n",
    "--max_phrases_per_batch 250 \\\n",
    "--max_phrases_per_image 20 \\\n",
    "--val_batch_size_factor 2.0 \\\n",
    "--raw_image_encoding \"densenet-121\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 1024 \\\n",
    "--num_regions 169 \\\n",
    "--regions_width 13 \\\n",
    "--regions_height 13 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--qkv_size 256 \\\n",
    "--phrase_classifier_hidden_size 256 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--iters_to_accumulate 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_all_pos_neg_facts(hash=1013,1477415609053716381).pkl\" \\\n",
    "--exclude_noisy_images \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7819ede3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 800\n",
      "   max_images_per_batch: 20\n",
      "   max_phrases_per_batch: 250\n",
      "   max_phrases_per_image: 20\n",
      "   val_batch_size_factor: 2.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: densenet-121\n",
      "   num_regions: 169\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 13\n",
      "   regions_height: 13\n",
      "   qkv_size: 256\n",
      "   phrase_classifier_hidden_size: 256\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   iters_to_accumulate: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+wbce\n",
      "   use_weighted_phrase_classifier_loss: True\n",
      "   cluster_and_label_weights_for_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_clusters_and_cluster_weights_for_facts(hash=226,607533638975659953).pkl\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_all_pos_neg_facts(hash=1013,1477415609053716381).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_bbox_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   img_aug_mode: None\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   vinbig_training_data_mode: train\n",
      "   mask_exponent: 1.0\n",
      "   mimiccxr_balance_long_middle_short_tail: True\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = True\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: densenet-121\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "binary_loss_kwargs: {'focal_weight': 1.0, 'bce_weight': 1.0, 'wbce_weight': 1.0}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "binary_loss_kwargs: {'focal_weight': 1.0, 'bce_weight': 1.0, 'wbce_weight': 1.0}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "mask_exponent = 1.0\n",
      "len(forbidden_train_dicom_ids) = 1030\n",
      "\u001b[1mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596394, 128)\n",
      "\u001b[1mAssigning distribution classes to reports...\u001b[0m\n",
      "Loading mimiccxr_report_fact_nli_integrated_data from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl...\n",
      "labels.shape = (227835, 93)\n",
      "count_no_positives = 4994\n",
      "number of long tail classes = 29\n",
      "number of middle tail classes = 27\n",
      "number of short tail classes = 37\n",
      "number of long tail reports = 49794\n",
      "number of middle tail reports = 68991\n",
      "number of short tail reports = 109050\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 173990.00it/s]\n",
      "Total number of images: 376105\n",
      "len(train_indices) = 367955\n",
      "len(test_indices) = 8150\n",
      "avg_facts_per_image = 81.18059545324836\n",
      "train_num_facts_per_image = 20\n",
      "avg_facts_per_image = 76.93938650306748\n",
      "test_num_facts_per_image = 20\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "Balancing long, middle, and short tail classes...\n",
      "len(self.train_fact_dataloader) = 83333333333333334\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 340\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 83333333333333334\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 340\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_163_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5368.pt', 'checkpoint_194_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5431.pt', 'checkpoint_363_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5525.pt', 'checkpoint_234_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5470.pt', 'checkpoint_129_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5307.pt', 'checkpoint_30_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.4928.pt', 'checkpoint_91_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5153.pt', 'checkpoint_60_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5050.pt', 'checkpoint_275_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5471.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/checkpoint_363_fg_att_reg_loss+fg_cpg_loss+fg_phrcls_loss=0.5525.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.67468, fg_cpg_loss 2.36381, fg_att_reg_loss 0.23824, fg_phrcls_loss 1.07263, 175.54 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43581, fg_att_reg_loss 0.26128, fg_phrcls_loss 1.06782, fg_prc_auc 0.94619, 42.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_fgss+fgss+fgss+fguc=0.6037.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.63827, fg_cpg_loss 2.38030, fg_att_reg_loss 0.23845, fg_phrcls_loss 1.01952, 176.63 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42617, fg_att_reg_loss 0.25996, fg_phrcls_loss 1.03356, fg_prc_auc 0.94421, 43.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_fgss+fgss+fgss+fguc=0.6058.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.61063, fg_cpg_loss 2.39728, fg_att_reg_loss 0.23647, fg_phrcls_loss 0.97687, 174.47 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43224, fg_att_reg_loss 0.26000, fg_phrcls_loss 1.01679, fg_prc_auc 0.94292, 43.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_fgss+fgss+fgss+fguc=0.6067.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.70922, fg_cpg_loss 2.49335, fg_att_reg_loss 0.24095, fg_phrcls_loss 0.97492, 176.29 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51196, fg_att_reg_loss 0.26526, fg_phrcls_loss 1.01536, fg_prc_auc 0.93780, 43.70 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 3.67268, fg_cpg_loss 2.46765, fg_att_reg_loss 0.24092, fg_phrcls_loss 0.96411, 175.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46345, fg_att_reg_loss 0.26202, fg_phrcls_loss 0.99278, fg_prc_auc 0.94252, 43.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_fgss+fgss+fgss+fguc=0.6071.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 3.61933, fg_cpg_loss 2.42348, fg_att_reg_loss 0.23940, fg_phrcls_loss 0.95644, 176.96 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45784, fg_att_reg_loss 0.26170, fg_phrcls_loss 0.98555, fg_prc_auc 0.94248, 42.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_fgss+fgss+fgss+fguc=0.6078.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 3.63229, fg_cpg_loss 2.43214, fg_att_reg_loss 0.24074, fg_phrcls_loss 0.95941, 175.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45866, fg_att_reg_loss 0.26210, fg_phrcls_loss 0.99356, fg_prc_auc 0.94233, 43.98 secs\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.56160, fg_cpg_loss 2.37273, fg_att_reg_loss 0.23923, fg_phrcls_loss 0.94964, 176.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43791, fg_att_reg_loss 0.26122, fg_phrcls_loss 0.99446, fg_prc_auc 0.94355, 42.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_fgss+fgss+fgss+fguc=0.6081.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.60840, fg_cpg_loss 2.41670, fg_att_reg_loss 0.24009, fg_phrcls_loss 0.95162, 178.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41481, fg_att_reg_loss 0.26048, fg_phrcls_loss 0.99287, fg_prc_auc 0.94331, 43.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_fgss+fgss+fgss+fguc=0.6083.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.61004, fg_cpg_loss 2.41495, fg_att_reg_loss 0.24065, fg_phrcls_loss 0.95444, 177.31 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43431, fg_att_reg_loss 0.26226, fg_phrcls_loss 0.98198, fg_prc_auc 0.94325, 43.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_fgss+fgss+fgss+fguc=0.6084.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.52976, fg_cpg_loss 2.35127, fg_att_reg_loss 0.23881, fg_phrcls_loss 0.93969, 177.24 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44355, fg_att_reg_loss 0.26088, fg_phrcls_loss 0.98562, fg_prc_auc 0.94391, 43.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_fgss+fgss+fgss+fguc=0.6088.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.56040, fg_cpg_loss 2.38099, fg_att_reg_loss 0.23851, fg_phrcls_loss 0.94089, 164.94 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42366, fg_att_reg_loss 0.26144, fg_phrcls_loss 0.98336, fg_prc_auc 0.94386, 43.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_fgss+fgss+fgss+fguc=0.6090.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.73381, fg_cpg_loss 2.51171, fg_att_reg_loss 0.24182, fg_phrcls_loss 0.98029, 164.18 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.49004, fg_att_reg_loss 0.26367, fg_phrcls_loss 1.00576, fg_prc_auc 0.94193, 43.41 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.65165, fg_cpg_loss 2.45009, fg_att_reg_loss 0.23999, fg_phrcls_loss 0.96157, 163.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48901, fg_att_reg_loss 0.26111, fg_phrcls_loss 0.98890, fg_prc_auc 0.94206, 43.48 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.62266, fg_cpg_loss 2.42487, fg_att_reg_loss 0.23883, fg_phrcls_loss 0.95896, 166.29 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44076, fg_att_reg_loss 0.26104, fg_phrcls_loss 0.99046, fg_prc_auc 0.94451, 43.81 secs\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.58758, fg_cpg_loss 2.39892, fg_att_reg_loss 0.23915, fg_phrcls_loss 0.94951, 164.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42376, fg_att_reg_loss 0.26131, fg_phrcls_loss 0.97774, fg_prc_auc 0.94460, 43.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_fgss+fgss+fgss+fguc=0.6094.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.58695, fg_cpg_loss 2.40085, fg_att_reg_loss 0.24005, fg_phrcls_loss 0.94605, 163.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43544, fg_att_reg_loss 0.26104, fg_phrcls_loss 0.98254, fg_prc_auc 0.94426, 43.70 secs\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.58173, fg_cpg_loss 2.39315, fg_att_reg_loss 0.24049, fg_phrcls_loss 0.94809, 166.73 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41670, fg_att_reg_loss 0.26010, fg_phrcls_loss 0.98503, fg_prc_auc 0.94457, 43.67 secs\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.54998, fg_cpg_loss 2.36579, fg_att_reg_loss 0.23781, fg_phrcls_loss 0.94637, 163.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42849, fg_att_reg_loss 0.26086, fg_phrcls_loss 0.98294, fg_prc_auc 0.94458, 42.89 secs\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.58276, fg_cpg_loss 2.39068, fg_att_reg_loss 0.24008, fg_phrcls_loss 0.95200, 163.77 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40955, fg_att_reg_loss 0.26020, fg_phrcls_loss 0.98369, fg_prc_auc 0.94488, 43.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_fgss+fgss+fgss+fguc=0.6094.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.67834, fg_cpg_loss 2.46529, fg_att_reg_loss 0.24027, fg_phrcls_loss 0.97279, 166.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48888, fg_att_reg_loss 0.26360, fg_phrcls_loss 1.01505, fg_prc_auc 0.94101, 43.56 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.61749, fg_cpg_loss 2.42209, fg_att_reg_loss 0.24023, fg_phrcls_loss 0.95517, 163.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46310, fg_att_reg_loss 0.26214, fg_phrcls_loss 0.99326, fg_prc_auc 0.94344, 43.22 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.61122, fg_cpg_loss 2.41728, fg_att_reg_loss 0.23920, fg_phrcls_loss 0.95474, 163.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42038, fg_att_reg_loss 0.26092, fg_phrcls_loss 0.98463, fg_prc_auc 0.94398, 43.28 secs\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.60969, fg_cpg_loss 2.41532, fg_att_reg_loss 0.24015, fg_phrcls_loss 0.95422, 163.75 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 3.40304, fg_att_reg_loss 0.26120, fg_phrcls_loss 0.98183, fg_prc_auc 0.94538, 43.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_fgss+fgss+fgss+fguc=0.6094.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.61067, fg_cpg_loss 2.41739, fg_att_reg_loss 0.24009, fg_phrcls_loss 0.95319, 163.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44881, fg_att_reg_loss 0.26198, fg_phrcls_loss 0.98562, fg_prc_auc 0.94433, 42.75 secs\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.56913, fg_cpg_loss 2.38724, fg_att_reg_loss 0.23916, fg_phrcls_loss 0.94273, 163.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40982, fg_att_reg_loss 0.26139, fg_phrcls_loss 0.98147, fg_prc_auc 0.94553, 43.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_fgss+fgss+fgss+fguc=0.6096.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.59029, fg_cpg_loss 2.40083, fg_att_reg_loss 0.23898, fg_phrcls_loss 0.95047, 165.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40572, fg_att_reg_loss 0.26193, fg_phrcls_loss 0.97749, fg_prc_auc 0.94501, 43.48 secs\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.56842, fg_cpg_loss 2.38911, fg_att_reg_loss 0.23910, fg_phrcls_loss 0.94022, 163.74 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40396, fg_att_reg_loss 0.26078, fg_phrcls_loss 0.98355, fg_prc_auc 0.94494, 42.66 secs\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.63484, fg_cpg_loss 2.43907, fg_att_reg_loss 0.24017, fg_phrcls_loss 0.95560, 163.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.51223, fg_att_reg_loss 0.26464, fg_phrcls_loss 1.02392, fg_prc_auc 0.94034, 43.73 secs\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.66660, fg_cpg_loss 2.45950, fg_att_reg_loss 0.24219, fg_phrcls_loss 0.96491, 165.47 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45477, fg_att_reg_loss 0.26218, fg_phrcls_loss 0.98409, fg_prc_auc 0.94259, 43.37 secs\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.59944, fg_cpg_loss 2.40609, fg_att_reg_loss 0.23878, fg_phrcls_loss 0.95457, 163.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41838, fg_att_reg_loss 0.26109, fg_phrcls_loss 0.98350, fg_prc_auc 0.94441, 43.08 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.55202, fg_cpg_loss 2.36214, fg_att_reg_loss 0.23906, fg_phrcls_loss 0.95082, 163.79 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40875, fg_att_reg_loss 0.26114, fg_phrcls_loss 0.98853, fg_prc_auc 0.94499, 43.50 secs\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.57239, fg_cpg_loss 2.38615, fg_att_reg_loss 0.23883, fg_phrcls_loss 0.94740, 163.94 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39403, fg_att_reg_loss 0.26017, fg_phrcls_loss 0.97994, fg_prc_auc 0.94573, 43.43 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_fgss+fgss+fgss+fguc=0.6101.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.54485, fg_cpg_loss 2.35971, fg_att_reg_loss 0.23865, fg_phrcls_loss 0.94649, 163.77 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41445, fg_att_reg_loss 0.26080, fg_phrcls_loss 0.97812, fg_prc_auc 0.94577, 42.80 secs\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.55264, fg_cpg_loss 2.36785, fg_att_reg_loss 0.23813, fg_phrcls_loss 0.94666, 163.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39327, fg_att_reg_loss 0.26020, fg_phrcls_loss 0.97684, fg_prc_auc 0.94588, 43.77 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_fgss+fgss+fgss+fguc=0.6103.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.51425, fg_cpg_loss 2.33992, fg_att_reg_loss 0.23866, fg_phrcls_loss 0.93567, 165.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38896, fg_att_reg_loss 0.26037, fg_phrcls_loss 0.97897, fg_prc_auc 0.94584, 43.42 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_36_fgss+fgss+fgss+fguc=0.6104.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.64779, fg_cpg_loss 2.44928, fg_att_reg_loss 0.23964, fg_phrcls_loss 0.95887, 163.84 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.52763, fg_att_reg_loss 0.26086, fg_phrcls_loss 0.99470, fg_prc_auc 0.94243, 42.72 secs\n",
      "\u001b[1m---- Epoch 38/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.57152, fg_cpg_loss 2.38086, fg_att_reg_loss 0.23944, fg_phrcls_loss 0.95121, 163.87 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44363, fg_att_reg_loss 0.26197, fg_phrcls_loss 0.98294, fg_prc_auc 0.94443, 43.43 secs\n",
      "\u001b[1m---- Epoch 39/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.54933, fg_cpg_loss 2.36526, fg_att_reg_loss 0.24027, fg_phrcls_loss 0.94380, 163.83 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45106, fg_att_reg_loss 0.26195, fg_phrcls_loss 0.98008, fg_prc_auc 0.94391, 42.93 secs\n",
      "\u001b[1m---- Epoch 40/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.54340, fg_cpg_loss 2.36519, fg_att_reg_loss 0.23924, fg_phrcls_loss 0.93897, 163.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39564, fg_att_reg_loss 0.26037, fg_phrcls_loss 0.98122, fg_prc_auc 0.94556, 42.42 secs\n",
      "\u001b[1m---- Epoch 41/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.53593, fg_cpg_loss 2.35700, fg_att_reg_loss 0.23954, fg_phrcls_loss 0.93939, 163.80 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40726, fg_att_reg_loss 0.26055, fg_phrcls_loss 0.97819, fg_prc_auc 0.94640, 43.72 secs\n",
      "\u001b[1m---- Epoch 42/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.53081, fg_cpg_loss 2.35091, fg_att_reg_loss 0.23924, fg_phrcls_loss 0.94066, 164.13 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41419, fg_att_reg_loss 0.26034, fg_phrcls_loss 0.97780, fg_prc_auc 0.94572, 42.80 secs\n",
      "\u001b[1m---- Epoch 43/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.51634, fg_cpg_loss 2.33696, fg_att_reg_loss 0.23821, fg_phrcls_loss 0.94117, 179.23 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38570, fg_att_reg_loss 0.26058, fg_phrcls_loss 0.97905, fg_prc_auc 0.94591, 42.84 secs\n",
      "\u001b[1m---- Epoch 44/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.54595, fg_cpg_loss 2.36576, fg_att_reg_loss 0.23843, fg_phrcls_loss 0.94177, 177.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40498, fg_att_reg_loss 0.26043, fg_phrcls_loss 0.97833, fg_prc_auc 0.94571, 43.29 secs\n",
      "\u001b[1m---- Epoch 45/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.68471, fg_cpg_loss 2.47274, fg_att_reg_loss 0.24091, fg_phrcls_loss 0.97106, 177.52 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48816, fg_att_reg_loss 0.26299, fg_phrcls_loss 0.98450, fg_prc_auc 0.94393, 42.63 secs\n",
      "\u001b[1m---- Epoch 46/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.60210, fg_cpg_loss 2.40823, fg_att_reg_loss 0.23993, fg_phrcls_loss 0.95393, 178.70 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50452, fg_att_reg_loss 0.26123, fg_phrcls_loss 0.99332, fg_prc_auc 0.94180, 43.29 secs\n",
      "\u001b[1m---- Epoch 47/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.56571, fg_cpg_loss 2.38342, fg_att_reg_loss 0.23860, fg_phrcls_loss 0.94370, 176.41 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43789, fg_att_reg_loss 0.26091, fg_phrcls_loss 0.99243, fg_prc_auc 0.94538, 42.96 secs\n",
      "\u001b[1m---- Epoch 48/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.53808, fg_cpg_loss 2.35460, fg_att_reg_loss 0.23886, fg_phrcls_loss 0.94463, 179.16 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42600, fg_att_reg_loss 0.26122, fg_phrcls_loss 0.97976, fg_prc_auc 0.94548, 42.50 secs\n",
      "\u001b[1m---- Epoch 49/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.52613, fg_cpg_loss 2.34495, fg_att_reg_loss 0.23903, fg_phrcls_loss 0.94215, 172.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40237, fg_att_reg_loss 0.26067, fg_phrcls_loss 0.97570, fg_prc_auc 0.94640, 42.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_fgss+fgss+fgss+fguc=0.6104.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.59375, fg_cpg_loss 2.40960, fg_att_reg_loss 0.24014, fg_phrcls_loss 0.94401, 176.34 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41410, fg_att_reg_loss 0.26040, fg_phrcls_loss 0.98082, fg_prc_auc 0.94581, 43.48 secs\n",
      "\u001b[1m---- Epoch 51/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.56765, fg_cpg_loss 2.38716, fg_att_reg_loss 0.23944, fg_phrcls_loss 0.94105, 168.47 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 3.39599, fg_att_reg_loss 0.26099, fg_phrcls_loss 0.97701, fg_prc_auc 0.94620, 43.12 secs\n",
      "\u001b[1m---- Epoch 52/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.53481, fg_cpg_loss 2.35083, fg_att_reg_loss 0.23817, fg_phrcls_loss 0.94581, 179.09 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41679, fg_att_reg_loss 0.26073, fg_phrcls_loss 0.97427, fg_prc_auc 0.94612, 42.35 secs\n",
      "\u001b[1m---- Epoch 53/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.59843, fg_cpg_loss 2.41042, fg_att_reg_loss 0.23910, fg_phrcls_loss 0.94890, 178.79 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.55014, fg_att_reg_loss 0.26208, fg_phrcls_loss 1.01538, fg_prc_auc 0.94267, 43.04 secs\n",
      "\u001b[1m---- Epoch 54/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.59207, fg_cpg_loss 2.40138, fg_att_reg_loss 0.24003, fg_phrcls_loss 0.95066, 177.18 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45248, fg_att_reg_loss 0.26037, fg_phrcls_loss 0.97948, fg_prc_auc 0.94546, 42.74 secs\n",
      "\u001b[1m---- Epoch 55/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.58075, fg_cpg_loss 2.39343, fg_att_reg_loss 0.24093, fg_phrcls_loss 0.94639, 178.28 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42214, fg_att_reg_loss 0.26141, fg_phrcls_loss 0.98223, fg_prc_auc 0.94545, 42.41 secs\n",
      "\u001b[1m---- Epoch 56/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.54407, fg_cpg_loss 2.36131, fg_att_reg_loss 0.24008, fg_phrcls_loss 0.94267, 179.28 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40618, fg_att_reg_loss 0.26088, fg_phrcls_loss 0.97191, fg_prc_auc 0.94638, 42.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_56_fgss+fgss+fgss+fguc=0.6105.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 57/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.55643, fg_cpg_loss 2.37351, fg_att_reg_loss 0.24063, fg_phrcls_loss 0.94228, 178.46 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.36929, fg_att_reg_loss 0.26117, fg_phrcls_loss 0.97981, fg_prc_auc 0.94671, 42.64 secs\n",
      "\u001b[1m---- Epoch 58/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.52432, fg_cpg_loss 2.34879, fg_att_reg_loss 0.23898, fg_phrcls_loss 0.93656, 179.55 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38090, fg_att_reg_loss 0.26110, fg_phrcls_loss 0.97357, fg_prc_auc 0.94637, 42.57 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_58_fgss+fgss+fgss+fguc=0.6108.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 59/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.52750, fg_cpg_loss 2.34952, fg_att_reg_loss 0.23892, fg_phrcls_loss 0.93905, 178.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41131, fg_att_reg_loss 0.26102, fg_phrcls_loss 0.97190, fg_prc_auc 0.94655, 42.91 secs\n",
      "\u001b[1m---- Epoch 60/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.53604, fg_cpg_loss 2.35714, fg_att_reg_loss 0.23919, fg_phrcls_loss 0.93971, 170.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40906, fg_att_reg_loss 0.26022, fg_phrcls_loss 0.98049, fg_prc_auc 0.94648, 42.83 secs\n",
      "\u001b[1m---- Epoch 61/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.62387, fg_cpg_loss 2.43203, fg_att_reg_loss 0.23853, fg_phrcls_loss 0.95332, 176.92 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.48257, fg_att_reg_loss 0.26225, fg_phrcls_loss 0.99308, fg_prc_auc 0.94230, 42.18 secs\n",
      "\u001b[1m---- Epoch 62/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.52366, fg_cpg_loss 2.35108, fg_att_reg_loss 0.23887, fg_phrcls_loss 0.93370, 178.45 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43122, fg_att_reg_loss 0.26060, fg_phrcls_loss 0.98367, fg_prc_auc 0.94591, 42.92 secs\n",
      "\u001b[1m---- Epoch 63/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.56474, fg_cpg_loss 2.38654, fg_att_reg_loss 0.23904, fg_phrcls_loss 0.93917, 177.53 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42608, fg_att_reg_loss 0.26140, fg_phrcls_loss 0.98427, fg_prc_auc 0.94525, 42.66 secs\n",
      "\u001b[1m---- Epoch 64/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.49600, fg_cpg_loss 2.32708, fg_att_reg_loss 0.23860, fg_phrcls_loss 0.93031, 178.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38998, fg_att_reg_loss 0.26020, fg_phrcls_loss 0.97125, fg_prc_auc 0.94683, 42.25 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_64_fgss+fgss+fgss+fguc=0.6112.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 65/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.53564, fg_cpg_loss 2.35519, fg_att_reg_loss 0.23970, fg_phrcls_loss 0.94076, 178.52 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39064, fg_att_reg_loss 0.25987, fg_phrcls_loss 0.98040, fg_prc_auc 0.94655, 42.69 secs\n",
      "\u001b[1m---- Epoch 66/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.50634, fg_cpg_loss 2.33389, fg_att_reg_loss 0.23856, fg_phrcls_loss 0.93389, 177.65 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40624, fg_att_reg_loss 0.25971, fg_phrcls_loss 0.98083, fg_prc_auc 0.94653, 42.73 secs\n",
      "\u001b[1m---- Epoch 67/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.56902, fg_cpg_loss 2.38483, fg_att_reg_loss 0.23920, fg_phrcls_loss 0.94498, 178.81 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40497, fg_att_reg_loss 0.25970, fg_phrcls_loss 0.97658, fg_prc_auc 0.94624, 42.29 secs\n",
      "\u001b[1m---- Epoch 68/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.48993, fg_cpg_loss 2.31809, fg_att_reg_loss 0.23755, fg_phrcls_loss 0.93428, 179.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38844, fg_att_reg_loss 0.26016, fg_phrcls_loss 0.97287, fg_prc_auc 0.94692, 42.68 secs\n",
      "\u001b[1m---- Epoch 69/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.68320, fg_cpg_loss 2.48017, fg_att_reg_loss 0.24053, fg_phrcls_loss 0.96249, 178.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.50356, fg_att_reg_loss 0.26247, fg_phrcls_loss 0.96960, fg_prc_auc 0.94277, 42.96 secs\n",
      "\u001b[1m---- Epoch 70/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.58287, fg_cpg_loss 2.39932, fg_att_reg_loss 0.23847, fg_phrcls_loss 0.94508, 179.09 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43454, fg_att_reg_loss 0.26067, fg_phrcls_loss 0.98301, fg_prc_auc 0.94524, 42.40 secs\n",
      "\u001b[1m---- Epoch 71/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.49242, fg_cpg_loss 2.32077, fg_att_reg_loss 0.23800, fg_phrcls_loss 0.93364, 178.12 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40897, fg_att_reg_loss 0.25922, fg_phrcls_loss 0.97778, fg_prc_auc 0.94639, 42.98 secs\n",
      "\u001b[1m---- Epoch 72/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.48302, fg_cpg_loss 2.31503, fg_att_reg_loss 0.23701, fg_phrcls_loss 0.93098, 176.90 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39740, fg_att_reg_loss 0.25983, fg_phrcls_loss 0.98050, fg_prc_auc 0.94687, 43.21 secs\n",
      "\u001b[1m---- Epoch 73/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.49224, fg_cpg_loss 2.32325, fg_att_reg_loss 0.23741, fg_phrcls_loss 0.93159, 178.12 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38350, fg_att_reg_loss 0.25976, fg_phrcls_loss 0.97122, fg_prc_auc 0.94692, 42.61 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_73_fgss+fgss+fgss+fguc=0.6114.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 74/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.45853, fg_cpg_loss 2.29374, fg_att_reg_loss 0.23659, fg_phrcls_loss 0.92820, 178.21 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38272, fg_att_reg_loss 0.25967, fg_phrcls_loss 0.97540, fg_prc_auc 0.94689, 42.97 secs\n",
      "\u001b[1m---- Epoch 75/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.52873, fg_cpg_loss 2.35596, fg_att_reg_loss 0.23972, fg_phrcls_loss 0.93304, 176.34 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41677, fg_att_reg_loss 0.26001, fg_phrcls_loss 0.97017, fg_prc_auc 0.94672, 42.98 secs\n",
      "\u001b[1m---- Epoch 76/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.47787, fg_cpg_loss 2.31290, fg_att_reg_loss 0.23816, fg_phrcls_loss 0.92681, 168.01 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40585, fg_att_reg_loss 0.25939, fg_phrcls_loss 0.97468, fg_prc_auc 0.94637, 42.43 secs\n",
      "\u001b[1m---- Epoch 77/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.61986, fg_cpg_loss 2.42941, fg_att_reg_loss 0.23714, fg_phrcls_loss 0.95331, 165.86 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46859, fg_att_reg_loss 0.26028, fg_phrcls_loss 0.99360, fg_prc_auc 0.94296, 42.65 secs\n",
      "\u001b[1m---- Epoch 78/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.54181, fg_cpg_loss 2.37106, fg_att_reg_loss 0.23815, fg_phrcls_loss 0.93260, 163.77 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.43152, fg_att_reg_loss 0.26007, fg_phrcls_loss 0.99353, fg_prc_auc 0.94503, 43.39 secs\n",
      "\u001b[1m---- Epoch 79/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.51847, fg_cpg_loss 2.34776, fg_att_reg_loss 0.23762, fg_phrcls_loss 0.93310, 168.97 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42880, fg_att_reg_loss 0.25869, fg_phrcls_loss 0.98209, fg_prc_auc 0.94601, 42.39 secs\n",
      "\u001b[1m---- Epoch 80/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.53586, fg_cpg_loss 2.36211, fg_att_reg_loss 0.23831, fg_phrcls_loss 0.93544, 169.87 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39243, fg_att_reg_loss 0.25866, fg_phrcls_loss 0.97644, fg_prc_auc 0.94718, 42.25 secs\n",
      "\u001b[1m---- Epoch 81/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.51100, fg_cpg_loss 2.34137, fg_att_reg_loss 0.23692, fg_phrcls_loss 0.93272, 178.90 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38774, fg_att_reg_loss 0.25888, fg_phrcls_loss 0.97405, fg_prc_auc 0.94753, 42.34 secs\n",
      "\u001b[1m---- Epoch 82/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.52164, fg_cpg_loss 2.35065, fg_att_reg_loss 0.23824, fg_phrcls_loss 0.93274, 178.01 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.34125, fg_att_reg_loss 0.25842, fg_phrcls_loss 0.97270, fg_prc_auc 0.94781, 42.71 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_82_fgss+fgss+fgss+fguc=0.6121.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 83/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.51764, fg_cpg_loss 2.34845, fg_att_reg_loss 0.23818, fg_phrcls_loss 0.93102, 177.74 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.36716, fg_att_reg_loss 0.25985, fg_phrcls_loss 0.97279, fg_prc_auc 0.94697, 42.45 secs\n",
      "\u001b[1m---- Epoch 84/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.48643, fg_cpg_loss 2.31495, fg_att_reg_loss 0.23690, fg_phrcls_loss 0.93457, 178.76 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.38664, fg_att_reg_loss 0.25833, fg_phrcls_loss 0.97158, fg_prc_auc 0.94751, 42.29 secs\n",
      "\u001b[1m---- Epoch 85/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.64983, fg_cpg_loss 2.45515, fg_att_reg_loss 0.23991, fg_phrcls_loss 0.95477, 179.04 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.44582, fg_att_reg_loss 0.26045, fg_phrcls_loss 0.99339, fg_prc_auc 0.94389, 43.08 secs\n",
      "\u001b[1m---- Epoch 86/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.52669, fg_cpg_loss 2.35330, fg_att_reg_loss 0.23790, fg_phrcls_loss 0.93550, 175.76 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45122, fg_att_reg_loss 0.25927, fg_phrcls_loss 0.98555, fg_prc_auc 0.94517, 43.11 secs\n",
      "\u001b[1m---- Epoch 87/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.47679, fg_cpg_loss 2.31524, fg_att_reg_loss 0.23712, fg_phrcls_loss 0.92443, 175.24 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.42118, fg_att_reg_loss 0.26019, fg_phrcls_loss 0.97773, fg_prc_auc 0.94667, 42.38 secs\n",
      "\u001b[1m---- Epoch 88/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.52324, fg_cpg_loss 2.35624, fg_att_reg_loss 0.23965, fg_phrcls_loss 0.92735, 179.57 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.36037, fg_att_reg_loss 0.25882, fg_phrcls_loss 0.97006, fg_prc_auc 0.94745, 42.67 secs\n",
      "\u001b[1m---- Epoch 89/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.46887, fg_cpg_loss 2.30828, fg_att_reg_loss 0.23610, fg_phrcls_loss 0.92449, 178.16 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40679, fg_att_reg_loss 0.25880, fg_phrcls_loss 0.97584, fg_prc_auc 0.94693, 43.04 secs\n",
      "\u001b[1m---- Epoch 90/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.49188, fg_cpg_loss 2.32397, fg_att_reg_loss 0.23659, fg_phrcls_loss 0.93132, 179.96 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39943, fg_att_reg_loss 0.25905, fg_phrcls_loss 0.96747, fg_prc_auc 0.94699, 42.58 secs\n",
      "\u001b[1m---- Epoch 91/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.49536, fg_cpg_loss 2.33077, fg_att_reg_loss 0.23797, fg_phrcls_loss 0.92661, 179.76 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.40493, fg_att_reg_loss 0.25942, fg_phrcls_loss 0.97505, fg_prc_auc 0.94650, 42.66 secs\n",
      "\u001b[1m---- Epoch 92/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.51096, fg_cpg_loss 2.34197, fg_att_reg_loss 0.23778, fg_phrcls_loss 0.93121, 177.26 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.37217, fg_att_reg_loss 0.25895, fg_phrcls_loss 0.96861, fg_prc_auc 0.94732, 43.05 secs\n",
      "\u001b[1m---- Epoch 93/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.59705, fg_cpg_loss 2.40902, fg_att_reg_loss 0.23865, fg_phrcls_loss 0.94939, 171.17 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.46221, fg_att_reg_loss 0.25897, fg_phrcls_loss 0.98773, fg_prc_auc 0.94358, 42.36 secs\n",
      "\u001b[1m---- Epoch 94/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.55688, fg_cpg_loss 2.38118, fg_att_reg_loss 0.23847, fg_phrcls_loss 0.93722, 178.60 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.45788, fg_att_reg_loss 0.25978, fg_phrcls_loss 0.98518, fg_prc_auc 0.94544, 42.59 secs\n",
      "\u001b[1m---- Epoch 95/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.50643, fg_cpg_loss 2.33994, fg_att_reg_loss 0.23732, fg_phrcls_loss 0.92917, 177.74 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.41170, fg_att_reg_loss 0.25959, fg_phrcls_loss 0.98048, fg_prc_auc 0.94569, 43.21 secs\n",
      "\u001b[1m---- Epoch 96/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.47831, fg_cpg_loss 2.31664, fg_att_reg_loss 0.23733, fg_phrcls_loss 0.92434, 172.86 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39346, fg_att_reg_loss 0.25776, fg_phrcls_loss 0.97279, fg_prc_auc 0.94616, 42.29 secs\n",
      "\u001b[1m---- Epoch 97/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.46611, fg_cpg_loss 2.30837, fg_att_reg_loss 0.23579, fg_phrcls_loss 0.92195, 178.97 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.39452, fg_att_reg_loss 0.25882, fg_phrcls_loss 0.96630, fg_prc_auc 0.94687, 42.40 secs\n",
      "\u001b[1m---- Epoch 98/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.51188, fg_cpg_loss 2.34601, fg_att_reg_loss 0.23740, fg_phrcls_loss 0.92847, 177.42 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.37462, fg_att_reg_loss 0.25836, fg_phrcls_loss 0.96880, fg_prc_auc 0.94696, 42.76 secs\n",
      "\u001b[1m---- Epoch 99/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.47441, fg_cpg_loss 2.30913, fg_att_reg_loss 0.23743, fg_phrcls_loss 0.92785, 177.77 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.36473, fg_att_reg_loss 0.25895, fg_phrcls_loss 0.97180, fg_prc_auc 0.94735, 43.15 secs\n",
      "\u001b[1m---- Epoch 100/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.50109, fg_cpg_loss 2.33038, fg_att_reg_loss 0.23808, fg_phrcls_loss 0.93264, 177.94 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 3.35459, fg_att_reg_loss 0.25958, fg_phrcls_loss 0.96786, fg_prc_auc 0.94783, 42.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_100_fgss+fgss+fgss+fguc=0.6121.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240426_072308_mim-facts_PhraseGrounder(dn121,128,256)/\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 800 \\\n",
    "--max_images_per_batch 20 \\\n",
    "--max_phrases_per_batch 250 \\\n",
    "--max_phrases_per_image 20 \\\n",
    "--val_batch_size_factor 2.0 \\\n",
    "--raw_image_encoding \"densenet-121\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 1024 \\\n",
    "--num_regions 169 \\\n",
    "--regions_width 13 \\\n",
    "--regions_height 13 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--qkv_size 256 \\\n",
    "--phrase_classifier_hidden_size 256 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--iters_to_accumulate 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_all_pos_neg_facts(hash=1013,1477415609053716381).pkl\" \\\n",
    "--exclude_noisy_images \\\n",
    "--mimiccxr_balance_long_middle_short_tail \\\n",
    "--mimiccxr_report_fact_nli_integrated_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+wbce\" \\\n",
    "--use_weighted_phrase_classifier_loss \\\n",
    "--cluster_and_label_weights_for_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_clusters_and_cluster_weights_for_facts(hash=226,607533638975659953).pkl\" \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b51b5eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 700\n",
      "   max_images_per_batch: 20\n",
      "   max_phrases_per_batch: 500\n",
      "   max_phrases_per_image: 40\n",
      "   val_batch_size_factor: 2.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)/\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: densenet-121\n",
      "   num_regions: 169\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 13\n",
      "   regions_height: 13\n",
      "   qkv_size: 256\n",
      "   phrase_classifier_hidden_size: 256\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   iters_to_accumulate: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+wbce\n",
      "   use_weighted_phrase_classifier_loss: True\n",
      "   cluster_and_label_weights_for_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_clusters_and_cluster_weights_for_facts(hash=226,607533638975659953).pkl\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_label_based_pos_neg_facts(hash=207,1199289774163830850).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_bbox_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   img_aug_mode: None\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   vinbig_training_data_mode: train\n",
      "   mask_exponent: 1.0\n",
      "   mimiccxr_balance_long_middle_short_tail: True\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = True\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)/', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: densenet-121\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "binary_loss_kwargs: {'focal_weight': 1.0, 'bce_weight': 1.0, 'wbce_weight': 1.0}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "binary_loss_kwargs: {'focal_weight': 1.0, 'bce_weight': 1.0, 'wbce_weight': 1.0}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "mask_exponent = 1.0\n",
      "len(forbidden_train_dicom_ids) = 1030\n",
      "\u001b[1mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (93, 128)\n",
      "\u001b[1mAssigning distribution classes to reports...\u001b[0m\n",
      "Loading mimiccxr_report_fact_nli_integrated_data from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl...\n",
      "labels.shape = (227835, 93)\n",
      "count_no_positives = 4994\n",
      "number of long tail classes = 29\n",
      "number of middle tail classes = 27\n",
      "number of short tail classes = 37\n",
      "number of long tail reports = 49794\n",
      "number of middle tail reports = 68991\n",
      "number of short tail reports = 109050\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 174827.32it/s]\n",
      "Total number of images: 376105\n",
      "len(train_indices) = 367955\n",
      "len(test_indices) = 8150\n",
      "avg_facts_per_image = 47.52927124240736\n",
      "train_num_facts_per_image = 40\n",
      "avg_facts_per_image = 42.08331288343558\n",
      "test_num_facts_per_image = 40\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "Balancing long, middle, and short tail classes...\n",
      "len(self.train_fact_dataloader) = 83333333333333334\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 340\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 83333333333333334\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 340\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240504_151812_mim-facts_PhraseGrounder(dn121,128,256)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240504_151812_mim-facts_PhraseGrounder(dn121,128,256)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_100_fgss+fgss+fgss+fguc=0.6121.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)/checkpoint_100_fgss+fgss+fgss+fguc=0.6121.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240504_151812_mim-facts_PhraseGrounder(dn121,128,256)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.38299, fg_cpg_loss 3.96989, fg_att_reg_loss 0.37673, fg_phrcls_loss 1.03637, 155.18 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.83357, fg_att_reg_loss 0.37901, fg_phrcls_loss 1.06519, fg_prc_auc 0.87318, 43.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_fgss+fgss+fgss+fguc=0.5544.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 5.33692, fg_cpg_loss 3.93006, fg_att_reg_loss 0.37705, fg_phrcls_loss 1.02981, 152.41 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.82128, fg_att_reg_loss 0.37799, fg_phrcls_loss 1.04436, fg_prc_auc 0.87396, 43.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_fgss+fgss+fgss+fguc=0.5560.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 5.31035, fg_cpg_loss 3.90757, fg_att_reg_loss 0.37434, fg_phrcls_loss 1.02843, 153.84 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.79585, fg_att_reg_loss 0.37303, fg_phrcls_loss 1.03577, fg_prc_auc 0.87230, 43.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_fgss+fgss+fgss+fguc=0.5570.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.39979, fg_cpg_loss 3.98554, fg_att_reg_loss 0.35923, fg_phrcls_loss 1.05502, 152.66 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.88150, fg_att_reg_loss 0.34383, fg_phrcls_loss 1.01231, fg_prc_auc 0.87081, 44.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_fgss+fgss+fgss+fguc=0.5609.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 5.27482, fg_cpg_loss 3.90544, fg_att_reg_loss 0.33651, fg_phrcls_loss 1.03287, 152.46 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.81009, fg_att_reg_loss 0.33393, fg_phrcls_loss 1.03140, fg_prc_auc 0.87556, 43.51 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_fgss+fgss+fgss+fguc=0.5633.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 5.28904, fg_cpg_loss 3.93151, fg_att_reg_loss 0.32799, fg_phrcls_loss 1.02955, 150.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.77178, fg_att_reg_loss 0.31927, fg_phrcls_loss 1.02973, fg_prc_auc 0.87456, 43.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_fgss+fgss+fgss+fguc=0.5654.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 5.17716, fg_cpg_loss 3.83676, fg_att_reg_loss 0.31893, fg_phrcls_loss 1.02148, 151.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76178, fg_att_reg_loss 0.31517, fg_phrcls_loss 1.02998, fg_prc_auc 0.87795, 44.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_fgss+fgss+fgss+fguc=0.5672.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 5.20424, fg_cpg_loss 3.87604, fg_att_reg_loss 0.31512, fg_phrcls_loss 1.01308, 151.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75009, fg_att_reg_loss 0.31051, fg_phrcls_loss 1.03075, fg_prc_auc 0.87745, 43.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_fgss+fgss+fgss+fguc=0.5678.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 5.16546, fg_cpg_loss 3.84253, fg_att_reg_loss 0.31205, fg_phrcls_loss 1.01088, 153.16 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74458, fg_att_reg_loss 0.30955, fg_phrcls_loss 1.02395, fg_prc_auc 0.87924, 43.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_fgss+fgss+fgss+fguc=0.5688.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 5.19813, fg_cpg_loss 3.87640, fg_att_reg_loss 0.31055, fg_phrcls_loss 1.01118, 149.91 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74904, fg_att_reg_loss 0.30896, fg_phrcls_loss 1.02515, fg_prc_auc 0.87718, 44.11 secs\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.18622, fg_cpg_loss 3.86941, fg_att_reg_loss 0.30956, fg_phrcls_loss 1.00726, 152.81 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75129, fg_att_reg_loss 0.30817, fg_phrcls_loss 1.02338, fg_prc_auc 0.87824, 43.44 secs\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.19763, fg_cpg_loss 3.87507, fg_att_reg_loss 0.30955, fg_phrcls_loss 1.01301, 151.19 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74422, fg_att_reg_loss 0.30592, fg_phrcls_loss 1.02486, fg_prc_auc 0.87813, 44.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_fgss+fgss+fgss+fguc=0.5690.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.29512, fg_cpg_loss 3.95893, fg_att_reg_loss 0.30170, fg_phrcls_loss 1.03449, 149.83 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.82997, fg_att_reg_loss 0.28996, fg_phrcls_loss 1.04921, fg_prc_auc 0.86698, 43.91 secs\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.22742, fg_cpg_loss 3.92027, fg_att_reg_loss 0.28340, fg_phrcls_loss 1.02374, 152.11 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.78342, fg_att_reg_loss 0.27061, fg_phrcls_loss 1.01900, fg_prc_auc 0.87288, 43.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_fgss+fgss+fgss+fguc=0.5730.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.18512, fg_cpg_loss 3.88585, fg_att_reg_loss 0.27198, fg_phrcls_loss 1.02728, 154.10 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76805, fg_att_reg_loss 0.26755, fg_phrcls_loss 1.02753, fg_prc_auc 0.87753, 44.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_fgss+fgss+fgss+fguc=0.5744.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.15934, fg_cpg_loss 3.86979, fg_att_reg_loss 0.27091, fg_phrcls_loss 1.01864, 148.48 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75636, fg_att_reg_loss 0.26608, fg_phrcls_loss 1.03277, fg_prc_auc 0.87388, 43.72 secs\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 5.15450, fg_cpg_loss 3.87101, fg_att_reg_loss 0.26740, fg_phrcls_loss 1.01609, 145.19 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74978, fg_att_reg_loss 0.26878, fg_phrcls_loss 1.02972, fg_prc_auc 0.87965, 43.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_fgss+fgss+fgss+fguc=0.5749.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.16943, fg_cpg_loss 3.88794, fg_att_reg_loss 0.26878, fg_phrcls_loss 1.01271, 152.71 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74530, fg_att_reg_loss 0.26541, fg_phrcls_loss 1.02329, fg_prc_auc 0.87829, 44.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_fgss+fgss+fgss+fguc=0.5754.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.12771, fg_cpg_loss 3.84711, fg_att_reg_loss 0.26860, fg_phrcls_loss 1.01200, 153.44 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74518, fg_att_reg_loss 0.26370, fg_phrcls_loss 1.02541, fg_prc_auc 0.87743, 43.30 secs\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.13429, fg_cpg_loss 3.85328, fg_att_reg_loss 0.26601, fg_phrcls_loss 1.01499, 153.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73791, fg_att_reg_loss 0.26389, fg_phrcls_loss 1.02374, fg_prc_auc 0.87787, 43.35 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_fgss+fgss+fgss+fguc=0.5757.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.22999, fg_cpg_loss 3.93163, fg_att_reg_loss 0.26893, fg_phrcls_loss 1.02943, 152.65 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.85415, fg_att_reg_loss 0.26240, fg_phrcls_loss 1.03238, fg_prc_auc 0.86976, 44.11 secs\n",
      "\u001b[1m---- Epoch 22/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.22188, fg_cpg_loss 3.92114, fg_att_reg_loss 0.26379, fg_phrcls_loss 1.03696, 153.07 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76814, fg_att_reg_loss 0.25401, fg_phrcls_loss 1.05879, fg_prc_auc 0.87252, 43.29 secs\n",
      "\u001b[1m---- Epoch 23/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.15214, fg_cpg_loss 3.86937, fg_att_reg_loss 0.25977, fg_phrcls_loss 1.02300, 154.35 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74671, fg_att_reg_loss 0.25538, fg_phrcls_loss 1.02039, fg_prc_auc 0.87856, 43.61 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_fgss+fgss+fgss+fguc=0.5772.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.08344, fg_cpg_loss 3.81946, fg_att_reg_loss 0.25738, fg_phrcls_loss 1.00661, 152.89 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74258, fg_att_reg_loss 0.25476, fg_phrcls_loss 1.02299, fg_prc_auc 0.87866, 43.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_fgss+fgss+fgss+fguc=0.5775.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 5.14165, fg_cpg_loss 3.87784, fg_att_reg_loss 0.25732, fg_phrcls_loss 1.00648, 153.96 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72001, fg_att_reg_loss 0.25112, fg_phrcls_loss 1.02491, fg_prc_auc 0.88037, 43.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_fgss+fgss+fgss+fguc=0.5783.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.08724, fg_cpg_loss 3.82553, fg_att_reg_loss 0.25613, fg_phrcls_loss 1.00557, 153.54 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72452, fg_att_reg_loss 0.25030, fg_phrcls_loss 1.01540, fg_prc_auc 0.88073, 43.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_fgss+fgss+fgss+fguc=0.5791.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.11456, fg_cpg_loss 3.84881, fg_att_reg_loss 0.25598, fg_phrcls_loss 1.00977, 151.26 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72385, fg_att_reg_loss 0.25132, fg_phrcls_loss 1.02152, fg_prc_auc 0.87900, 43.47 secs\n",
      "\u001b[1m---- Epoch 28/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.10068, fg_cpg_loss 3.83724, fg_att_reg_loss 0.25584, fg_phrcls_loss 1.00760, 144.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72150, fg_att_reg_loss 0.25122, fg_phrcls_loss 1.01448, fg_prc_auc 0.88041, 43.51 secs\n",
      "\u001b[1m---- Epoch 29/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.17847, fg_cpg_loss 3.89647, fg_att_reg_loss 0.25406, fg_phrcls_loss 1.02794, 152.73 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.84418, fg_att_reg_loss 0.24921, fg_phrcls_loss 1.00891, fg_prc_auc 0.87321, 44.49 secs\n",
      "\u001b[1m---- Epoch 30/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.15068, fg_cpg_loss 3.87623, fg_att_reg_loss 0.25298, fg_phrcls_loss 1.02147, 152.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76522, fg_att_reg_loss 0.24484, fg_phrcls_loss 1.02396, fg_prc_auc 0.87520, 43.67 secs\n",
      "\u001b[1m---- Epoch 31/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.12900, fg_cpg_loss 3.87100, fg_att_reg_loss 0.25055, fg_phrcls_loss 1.00745, 147.29 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74959, fg_att_reg_loss 0.24397, fg_phrcls_loss 1.02396, fg_prc_auc 0.87878, 43.96 secs\n",
      "\u001b[1m---- Epoch 32/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.00907, fg_cpg_loss 3.76845, fg_att_reg_loss 0.24836, fg_phrcls_loss 0.99227, 153.39 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72723, fg_att_reg_loss 0.24217, fg_phrcls_loss 1.01620, fg_prc_auc 0.87890, 44.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_fgss+fgss+fgss+fguc=0.5802.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 5.02864, fg_cpg_loss 3.78456, fg_att_reg_loss 0.24960, fg_phrcls_loss 0.99448, 152.80 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73092, fg_att_reg_loss 0.24403, fg_phrcls_loss 1.01844, fg_prc_auc 0.87694, 43.53 secs\n",
      "\u001b[1m---- Epoch 34/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.00907, fg_cpg_loss 3.76719, fg_att_reg_loss 0.24735, fg_phrcls_loss 0.99453, 153.31 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72757, fg_att_reg_loss 0.24400, fg_phrcls_loss 1.01917, fg_prc_auc 0.87842, 44.33 secs\n",
      "\u001b[1m---- Epoch 35/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.03833, fg_cpg_loss 3.78916, fg_att_reg_loss 0.24789, fg_phrcls_loss 1.00128, 147.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72875, fg_att_reg_loss 0.24230, fg_phrcls_loss 1.02191, fg_prc_auc 0.87957, 44.17 secs\n",
      "\u001b[1m---- Epoch 36/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.03228, fg_cpg_loss 3.79356, fg_att_reg_loss 0.24754, fg_phrcls_loss 0.99118, 144.08 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72515, fg_att_reg_loss 0.24171, fg_phrcls_loss 1.01457, fg_prc_auc 0.87967, 43.61 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_36_fgss+fgss+fgss+fguc=0.5805.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 37/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.19454, fg_cpg_loss 3.92784, fg_att_reg_loss 0.24679, fg_phrcls_loss 1.01992, 144.55 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.87292, fg_att_reg_loss 0.24493, fg_phrcls_loss 1.02991, fg_prc_auc 0.87205, 44.38 secs\n",
      "\u001b[1m---- Epoch 38/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.18598, fg_cpg_loss 3.92139, fg_att_reg_loss 0.24621, fg_phrcls_loss 1.01838, 146.25 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74549, fg_att_reg_loss 0.23738, fg_phrcls_loss 1.03300, fg_prc_auc 0.87739, 44.19 secs\n",
      "\u001b[1m---- Epoch 39/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.10142, fg_cpg_loss 3.84784, fg_att_reg_loss 0.24429, fg_phrcls_loss 1.00929, 145.08 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73341, fg_att_reg_loss 0.23704, fg_phrcls_loss 0.99740, fg_prc_auc 0.87961, 43.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_fgss+fgss+fgss+fguc=0.5819.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.09506, fg_cpg_loss 3.84543, fg_att_reg_loss 0.24513, fg_phrcls_loss 1.00450, 150.46 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72142, fg_att_reg_loss 0.23639, fg_phrcls_loss 1.00998, fg_prc_auc 0.87928, 44.58 secs\n",
      "\u001b[1m---- Epoch 41/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 5.00510, fg_cpg_loss 3.77373, fg_att_reg_loss 0.24448, fg_phrcls_loss 0.98688, 153.84 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73018, fg_att_reg_loss 0.23637, fg_phrcls_loss 1.01012, fg_prc_auc 0.88004, 43.85 secs\n",
      "\u001b[1m---- Epoch 42/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.95910, fg_cpg_loss 3.73790, fg_att_reg_loss 0.24300, fg_phrcls_loss 0.97820, 150.82 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71965, fg_att_reg_loss 0.23632, fg_phrcls_loss 1.00794, fg_prc_auc 0.88095, 43.77 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_fgss+fgss+fgss+fguc=0.5823.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.97407, fg_cpg_loss 3.74308, fg_att_reg_loss 0.24141, fg_phrcls_loss 0.98958, 152.47 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71599, fg_att_reg_loss 0.23740, fg_phrcls_loss 1.00702, fg_prc_auc 0.88197, 44.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_43_fgss+fgss+fgss+fguc=0.5824.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 44/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.94664, fg_cpg_loss 3.71681, fg_att_reg_loss 0.24277, fg_phrcls_loss 0.98705, 151.05 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72821, fg_att_reg_loss 0.23689, fg_phrcls_loss 1.01077, fg_prc_auc 0.88055, 43.57 secs\n",
      "\u001b[1m---- Epoch 45/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.13107, fg_cpg_loss 3.86898, fg_att_reg_loss 0.24350, fg_phrcls_loss 1.01860, 152.21 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.79465, fg_att_reg_loss 0.23703, fg_phrcls_loss 1.02972, fg_prc_auc 0.87482, 43.54 secs\n",
      "\u001b[1m---- Epoch 46/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.14241, fg_cpg_loss 3.89127, fg_att_reg_loss 0.24172, fg_phrcls_loss 1.00942, 151.23 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.78046, fg_att_reg_loss 0.23624, fg_phrcls_loss 1.04041, fg_prc_auc 0.87932, 43.82 secs\n",
      "\u001b[1m---- Epoch 47/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.10187, fg_cpg_loss 3.84684, fg_att_reg_loss 0.24166, fg_phrcls_loss 1.01337, 143.94 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72798, fg_att_reg_loss 0.23357, fg_phrcls_loss 1.02456, fg_prc_auc 0.88111, 43.36 secs\n",
      "\u001b[1m---- Epoch 48/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.08356, fg_cpg_loss 3.83918, fg_att_reg_loss 0.23873, fg_phrcls_loss 1.00566, 143.94 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72336, fg_att_reg_loss 0.23212, fg_phrcls_loss 1.02482, fg_prc_auc 0.88024, 44.03 secs\n",
      "\u001b[1m---- Epoch 49/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.94912, fg_cpg_loss 3.73413, fg_att_reg_loss 0.23844, fg_phrcls_loss 0.97655, 145.93 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73090, fg_att_reg_loss 0.23272, fg_phrcls_loss 1.00993, fg_prc_auc 0.88142, 43.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_fgss+fgss+fgss+fguc=0.5829.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 5.01175, fg_cpg_loss 3.78802, fg_att_reg_loss 0.23903, fg_phrcls_loss 0.98470, 143.44 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72840, fg_att_reg_loss 0.23189, fg_phrcls_loss 1.01051, fg_prc_auc 0.88033, 43.14 secs\n",
      "\u001b[1m---- Epoch 51/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.05425, fg_cpg_loss 3.81556, fg_att_reg_loss 0.23837, fg_phrcls_loss 1.00031, 144.21 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72438, fg_att_reg_loss 0.23077, fg_phrcls_loss 1.01367, fg_prc_auc 0.88056, 44.12 secs\n",
      "\u001b[1m---- Epoch 52/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.01100, fg_cpg_loss 3.78242, fg_att_reg_loss 0.23891, fg_phrcls_loss 0.98967, 145.86 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72704, fg_att_reg_loss 0.23073, fg_phrcls_loss 1.01057, fg_prc_auc 0.88112, 43.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_52_fgss+fgss+fgss+fguc=0.5829.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 53/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.11247, fg_cpg_loss 3.86999, fg_att_reg_loss 0.23973, fg_phrcls_loss 1.00275, 143.28 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.80544, fg_att_reg_loss 0.23059, fg_phrcls_loss 1.03246, fg_prc_auc 0.87175, 43.61 secs\n",
      "\u001b[1m---- Epoch 54/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.08185, fg_cpg_loss 3.84269, fg_att_reg_loss 0.23635, fg_phrcls_loss 1.00281, 144.94 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.77018, fg_att_reg_loss 0.23151, fg_phrcls_loss 1.02346, fg_prc_auc 0.87658, 44.28 secs\n",
      "\u001b[1m---- Epoch 55/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.11616, fg_cpg_loss 3.86402, fg_att_reg_loss 0.23704, fg_phrcls_loss 1.01510, 145.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73689, fg_att_reg_loss 0.22914, fg_phrcls_loss 1.01392, fg_prc_auc 0.88052, 43.77 secs\n",
      "\u001b[1m---- Epoch 56/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.07274, fg_cpg_loss 3.84273, fg_att_reg_loss 0.23549, fg_phrcls_loss 0.99453, 143.36 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71467, fg_att_reg_loss 0.22751, fg_phrcls_loss 1.01212, fg_prc_auc 0.87810, 43.48 secs\n",
      "\u001b[1m---- Epoch 57/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.95275, fg_cpg_loss 3.74695, fg_att_reg_loss 0.23378, fg_phrcls_loss 0.97203, 153.64 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72555, fg_att_reg_loss 0.22857, fg_phrcls_loss 1.01230, fg_prc_auc 0.87971, 44.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_57_fgss+fgss+fgss+fguc=0.5831.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 58/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.96357, fg_cpg_loss 3.75721, fg_att_reg_loss 0.23318, fg_phrcls_loss 0.97317, 152.55 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71955, fg_att_reg_loss 0.22738, fg_phrcls_loss 1.00342, fg_prc_auc 0.87976, 43.47 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_58_fgss+fgss+fgss+fguc=0.5838.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 59/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.03162, fg_cpg_loss 3.80602, fg_att_reg_loss 0.23516, fg_phrcls_loss 0.99045, 153.37 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71622, fg_att_reg_loss 0.22740, fg_phrcls_loss 1.00553, fg_prc_auc 0.87924, 43.72 secs\n",
      "\u001b[1m---- Epoch 60/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.95783, fg_cpg_loss 3.75158, fg_att_reg_loss 0.23419, fg_phrcls_loss 0.97206, 153.02 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71531, fg_att_reg_loss 0.22724, fg_phrcls_loss 1.00568, fg_prc_auc 0.88033, 43.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_60_fgss+fgss+fgss+fguc=0.5839.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 61/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.05495, fg_cpg_loss 3.81592, fg_att_reg_loss 0.23611, fg_phrcls_loss 1.00292, 152.51 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.82183, fg_att_reg_loss 0.22661, fg_phrcls_loss 1.03206, fg_prc_auc 0.86912, 43.24 secs\n",
      "\u001b[1m---- Epoch 62/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.01658, fg_cpg_loss 3.78567, fg_att_reg_loss 0.23434, fg_phrcls_loss 0.99657, 153.76 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.78679, fg_att_reg_loss 0.22704, fg_phrcls_loss 1.00860, fg_prc_auc 0.87290, 43.38 secs\n",
      "\u001b[1m---- Epoch 63/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.06521, fg_cpg_loss 3.82938, fg_att_reg_loss 0.23389, fg_phrcls_loss 1.00194, 152.34 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75085, fg_att_reg_loss 0.22365, fg_phrcls_loss 1.02501, fg_prc_auc 0.87540, 43.53 secs\n",
      "\u001b[1m---- Epoch 64/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.03151, fg_cpg_loss 3.80716, fg_att_reg_loss 0.23161, fg_phrcls_loss 0.99274, 154.63 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74268, fg_att_reg_loss 0.22307, fg_phrcls_loss 1.00524, fg_prc_auc 0.87843, 43.09 secs\n",
      "\u001b[1m---- Epoch 65/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.87105, fg_cpg_loss 3.68132, fg_att_reg_loss 0.22933, fg_phrcls_loss 0.96040, 154.03 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72889, fg_att_reg_loss 0.22420, fg_phrcls_loss 0.99781, fg_prc_auc 0.88155, 43.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_65_fgss+fgss+fgss+fguc=0.5853.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 66/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.97941, fg_cpg_loss 3.77538, fg_att_reg_loss 0.23056, fg_phrcls_loss 0.97346, 154.00 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72988, fg_att_reg_loss 0.22472, fg_phrcls_loss 1.00466, fg_prc_auc 0.88094, 43.37 secs\n",
      "\u001b[1m---- Epoch 67/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.92964, fg_cpg_loss 3.71966, fg_att_reg_loss 0.23133, fg_phrcls_loss 0.97866, 154.72 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73022, fg_att_reg_loss 0.22364, fg_phrcls_loss 1.00571, fg_prc_auc 0.88064, 42.92 secs\n",
      "\u001b[1m---- Epoch 68/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.93356, fg_cpg_loss 3.72185, fg_att_reg_loss 0.23143, fg_phrcls_loss 0.98028, 153.82 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72969, fg_att_reg_loss 0.22446, fg_phrcls_loss 1.00553, fg_prc_auc 0.88061, 43.68 secs\n",
      "\u001b[1m---- Epoch 69/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.03322, fg_cpg_loss 3.80206, fg_att_reg_loss 0.23295, fg_phrcls_loss 0.99821, 151.93 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.85957, fg_att_reg_loss 0.22346, fg_phrcls_loss 1.04526, fg_prc_auc 0.87179, 43.29 secs\n",
      "\u001b[1m---- Epoch 70/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.95747, fg_cpg_loss 3.74378, fg_att_reg_loss 0.22990, fg_phrcls_loss 0.98379, 154.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.80013, fg_att_reg_loss 0.22216, fg_phrcls_loss 1.04040, fg_prc_auc 0.87458, 43.20 secs\n",
      "\u001b[1m---- Epoch 71/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.97252, fg_cpg_loss 3.75642, fg_att_reg_loss 0.22906, fg_phrcls_loss 0.98703, 151.90 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74884, fg_att_reg_loss 0.22132, fg_phrcls_loss 1.01140, fg_prc_auc 0.87543, 43.98 secs\n",
      "\u001b[1m---- Epoch 72/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.99478, fg_cpg_loss 3.77466, fg_att_reg_loss 0.22926, fg_phrcls_loss 0.99086, 154.50 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72769, fg_att_reg_loss 0.22082, fg_phrcls_loss 1.01085, fg_prc_auc 0.87709, 43.46 secs\n",
      "\u001b[1m---- Epoch 73/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.95015, fg_cpg_loss 3.74852, fg_att_reg_loss 0.22876, fg_phrcls_loss 0.97287, 155.24 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73008, fg_att_reg_loss 0.22110, fg_phrcls_loss 1.00351, fg_prc_auc 0.88022, 43.27 secs\n",
      "\u001b[1m---- Epoch 74/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.93597, fg_cpg_loss 3.73787, fg_att_reg_loss 0.22778, fg_phrcls_loss 0.97032, 153.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72771, fg_att_reg_loss 0.22046, fg_phrcls_loss 1.00620, fg_prc_auc 0.87938, 43.86 secs\n",
      "\u001b[1m---- Epoch 75/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.99848, fg_cpg_loss 3.78770, fg_att_reg_loss 0.22849, fg_phrcls_loss 0.98229, 152.37 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72167, fg_att_reg_loss 0.22070, fg_phrcls_loss 1.00450, fg_prc_auc 0.88021, 43.47 secs\n",
      "\u001b[1m---- Epoch 76/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.90553, fg_cpg_loss 3.70833, fg_att_reg_loss 0.22827, fg_phrcls_loss 0.96892, 147.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73440, fg_att_reg_loss 0.22035, fg_phrcls_loss 1.00525, fg_prc_auc 0.87961, 43.17 secs\n",
      "\u001b[1m---- Epoch 77/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 5.05605, fg_cpg_loss 3.82790, fg_att_reg_loss 0.23012, fg_phrcls_loss 0.99803, 143.94 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 4.81690, fg_att_reg_loss 0.22223, fg_phrcls_loss 1.04301, fg_prc_auc 0.87047, 43.93 secs\n",
      "\u001b[1m---- Epoch 78/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.99860, fg_cpg_loss 3.79190, fg_att_reg_loss 0.22853, fg_phrcls_loss 0.97817, 148.55 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73588, fg_att_reg_loss 0.22144, fg_phrcls_loss 1.01457, fg_prc_auc 0.88209, 43.33 secs\n",
      "\u001b[1m---- Epoch 79/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.02618, fg_cpg_loss 3.80051, fg_att_reg_loss 0.22964, fg_phrcls_loss 0.99603, 151.55 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75439, fg_att_reg_loss 0.21912, fg_phrcls_loss 1.00471, fg_prc_auc 0.87973, 43.01 secs\n",
      "\u001b[1m---- Epoch 80/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.03905, fg_cpg_loss 3.81845, fg_att_reg_loss 0.22694, fg_phrcls_loss 0.99366, 153.41 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72329, fg_att_reg_loss 0.21859, fg_phrcls_loss 1.00180, fg_prc_auc 0.87983, 43.72 secs\n",
      "\u001b[1m---- Epoch 81/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.93578, fg_cpg_loss 3.74050, fg_att_reg_loss 0.22592, fg_phrcls_loss 0.96936, 153.88 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73189, fg_att_reg_loss 0.21911, fg_phrcls_loss 1.00269, fg_prc_auc 0.88009, 43.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_81_fgss+fgss+fgss+fguc=0.5853.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 82/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.94414, fg_cpg_loss 3.74672, fg_att_reg_loss 0.22647, fg_phrcls_loss 0.97094, 154.53 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71484, fg_att_reg_loss 0.21803, fg_phrcls_loss 1.00374, fg_prc_auc 0.87964, 42.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_82_fgss+fgss+fgss+fguc=0.5854.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 83/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.00419, fg_cpg_loss 3.79301, fg_att_reg_loss 0.22753, fg_phrcls_loss 0.98365, 153.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72166, fg_att_reg_loss 0.21813, fg_phrcls_loss 1.00043, fg_prc_auc 0.88127, 43.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_83_fgss+fgss+fgss+fguc=0.5857.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 84/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.88159, fg_cpg_loss 3.68604, fg_att_reg_loss 0.22564, fg_phrcls_loss 0.96991, 152.17 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72615, fg_att_reg_loss 0.21853, fg_phrcls_loss 0.99873, fg_prc_auc 0.88071, 43.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_84_fgss+fgss+fgss+fguc=0.5859.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 85/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.99458, fg_cpg_loss 3.77189, fg_att_reg_loss 0.22902, fg_phrcls_loss 0.99368, 153.21 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.81257, fg_att_reg_loss 0.22081, fg_phrcls_loss 1.04522, fg_prc_auc 0.87333, 42.86 secs\n",
      "\u001b[1m---- Epoch 86/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.93257, fg_cpg_loss 3.73793, fg_att_reg_loss 0.22788, fg_phrcls_loss 0.96677, 154.79 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.77124, fg_att_reg_loss 0.21821, fg_phrcls_loss 1.02469, fg_prc_auc 0.87439, 43.62 secs\n",
      "\u001b[1m---- Epoch 87/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.98905, fg_cpg_loss 3.77578, fg_att_reg_loss 0.22756, fg_phrcls_loss 0.98572, 148.12 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74750, fg_att_reg_loss 0.21785, fg_phrcls_loss 0.99959, fg_prc_auc 0.87946, 43.57 secs\n",
      "\u001b[1m---- Epoch 88/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 5.00154, fg_cpg_loss 3.79216, fg_att_reg_loss 0.22684, fg_phrcls_loss 0.98255, 155.76 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72526, fg_att_reg_loss 0.21693, fg_phrcls_loss 1.00474, fg_prc_auc 0.87989, 42.52 secs\n",
      "\u001b[1m---- Epoch 89/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.86984, fg_cpg_loss 3.68824, fg_att_reg_loss 0.22575, fg_phrcls_loss 0.95585, 154.17 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73469, fg_att_reg_loss 0.21692, fg_phrcls_loss 0.99486, fg_prc_auc 0.88131, 43.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_89_fgss+fgss+fgss+fguc=0.5866.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 90/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.91228, fg_cpg_loss 3.73110, fg_att_reg_loss 0.22570, fg_phrcls_loss 0.95548, 147.90 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73141, fg_att_reg_loss 0.21639, fg_phrcls_loss 1.00278, fg_prc_auc 0.87961, 43.58 secs\n",
      "\u001b[1m---- Epoch 91/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.94216, fg_cpg_loss 3.73785, fg_att_reg_loss 0.22579, fg_phrcls_loss 0.97852, 154.84 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72667, fg_att_reg_loss 0.21665, fg_phrcls_loss 0.99508, fg_prc_auc 0.88006, 42.78 secs\n",
      "\u001b[1m---- Epoch 92/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.91509, fg_cpg_loss 3.71970, fg_att_reg_loss 0.22491, fg_phrcls_loss 0.97047, 155.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73759, fg_att_reg_loss 0.21670, fg_phrcls_loss 1.00128, fg_prc_auc 0.88051, 43.49 secs\n",
      "\u001b[1m---- Epoch 93/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.85665, fg_cpg_loss 3.66427, fg_att_reg_loss 0.22610, fg_phrcls_loss 0.96628, 153.78 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.89343, fg_att_reg_loss 0.21971, fg_phrcls_loss 1.03516, fg_prc_auc 0.87284, 43.51 secs\n",
      "\u001b[1m---- Epoch 94/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.93480, fg_cpg_loss 3.74055, fg_att_reg_loss 0.22605, fg_phrcls_loss 0.96819, 155.03 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.81350, fg_att_reg_loss 0.21913, fg_phrcls_loss 1.02114, fg_prc_auc 0.87687, 43.04 secs\n",
      "\u001b[1m---- Epoch 95/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.00501, fg_cpg_loss 3.79711, fg_att_reg_loss 0.22471, fg_phrcls_loss 0.98320, 155.33 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74638, fg_att_reg_loss 0.21628, fg_phrcls_loss 1.01070, fg_prc_auc 0.87938, 43.17 secs\n",
      "\u001b[1m---- Epoch 96/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.95371, fg_cpg_loss 3.75210, fg_att_reg_loss 0.22533, fg_phrcls_loss 0.97628, 153.81 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75358, fg_att_reg_loss 0.21538, fg_phrcls_loss 0.99379, fg_prc_auc 0.87857, 43.45 secs\n",
      "\u001b[1m---- Epoch 97/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.91813, fg_cpg_loss 3.72645, fg_att_reg_loss 0.22438, fg_phrcls_loss 0.96730, 154.60 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73823, fg_att_reg_loss 0.21567, fg_phrcls_loss 1.01212, fg_prc_auc 0.88141, 42.87 secs\n",
      "\u001b[1m---- Epoch 98/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.88432, fg_cpg_loss 3.70514, fg_att_reg_loss 0.22204, fg_phrcls_loss 0.95714, 155.45 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72187, fg_att_reg_loss 0.21556, fg_phrcls_loss 1.00479, fg_prc_auc 0.88015, 42.92 secs\n",
      "\u001b[1m---- Epoch 99/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.90622, fg_cpg_loss 3.72442, fg_att_reg_loss 0.22350, fg_phrcls_loss 0.95830, 153.45 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72897, fg_att_reg_loss 0.21487, fg_phrcls_loss 1.00112, fg_prc_auc 0.87930, 43.57 secs\n",
      "\u001b[1m---- Epoch 100/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.91803, fg_cpg_loss 3.72102, fg_att_reg_loss 0.22332, fg_phrcls_loss 0.97369, 154.65 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.71694, fg_att_reg_loss 0.21445, fg_phrcls_loss 0.99661, fg_prc_auc 0.88019, 42.58 secs\n",
      "\u001b[1m---- Epoch 101/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.88759, fg_cpg_loss 3.68616, fg_att_reg_loss 0.22429, fg_phrcls_loss 0.97715, 155.31 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.86669, fg_att_reg_loss 0.21719, fg_phrcls_loss 1.02597, fg_prc_auc 0.86976, 43.23 secs\n",
      "\u001b[1m---- Epoch 102/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.91899, fg_cpg_loss 3.72750, fg_att_reg_loss 0.22238, fg_phrcls_loss 0.96910, 153.91 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.78872, fg_att_reg_loss 0.21613, fg_phrcls_loss 0.99840, fg_prc_auc 0.87710, 43.50 secs\n",
      "\u001b[1m---- Epoch 103/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.95419, fg_cpg_loss 3.74860, fg_att_reg_loss 0.22421, fg_phrcls_loss 0.98138, 154.25 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75070, fg_att_reg_loss 0.21534, fg_phrcls_loss 0.99813, fg_prc_auc 0.87668, 42.95 secs\n",
      "\u001b[1m---- Epoch 104/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.96604, fg_cpg_loss 3.76777, fg_att_reg_loss 0.22197, fg_phrcls_loss 0.97630, 155.21 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73775, fg_att_reg_loss 0.21434, fg_phrcls_loss 0.99808, fg_prc_auc 0.88109, 43.28 secs\n",
      "\u001b[1m---- Epoch 105/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.85050, fg_cpg_loss 3.66958, fg_att_reg_loss 0.22182, fg_phrcls_loss 0.95911, 152.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75333, fg_att_reg_loss 0.21462, fg_phrcls_loss 1.00381, fg_prc_auc 0.87994, 43.32 secs\n",
      "\u001b[1m---- Epoch 106/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.85506, fg_cpg_loss 3.69052, fg_att_reg_loss 0.22134, fg_phrcls_loss 0.94320, 154.56 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75075, fg_att_reg_loss 0.21430, fg_phrcls_loss 0.99836, fg_prc_auc 0.88023, 42.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_106_fgss+fgss+fgss+fguc=0.5866.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 107/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.87845, fg_cpg_loss 3.69009, fg_att_reg_loss 0.22193, fg_phrcls_loss 0.96642, 155.99 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74154, fg_att_reg_loss 0.21503, fg_phrcls_loss 1.00033, fg_prc_auc 0.88006, 43.01 secs\n",
      "\u001b[1m---- Epoch 108/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.87220, fg_cpg_loss 3.67506, fg_att_reg_loss 0.22222, fg_phrcls_loss 0.97493, 154.69 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74193, fg_att_reg_loss 0.21430, fg_phrcls_loss 1.00158, fg_prc_auc 0.88029, 43.36 secs\n",
      "\u001b[1m---- Epoch 109/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.90291, fg_cpg_loss 3.70450, fg_att_reg_loss 0.22278, fg_phrcls_loss 0.97563, 154.46 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.89380, fg_att_reg_loss 0.21868, fg_phrcls_loss 1.03629, fg_prc_auc 0.86393, 43.26 secs\n",
      "\u001b[1m---- Epoch 110/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.92925, fg_cpg_loss 3.73967, fg_att_reg_loss 0.22326, fg_phrcls_loss 0.96631, 155.47 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.78235, fg_att_reg_loss 0.21429, fg_phrcls_loss 1.01125, fg_prc_auc 0.87523, 42.63 secs\n",
      "\u001b[1m---- Epoch 111/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.92332, fg_cpg_loss 3.72864, fg_att_reg_loss 0.22237, fg_phrcls_loss 0.97232, 154.67 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76394, fg_att_reg_loss 0.21392, fg_phrcls_loss 1.01782, fg_prc_auc 0.87874, 43.50 secs\n",
      "\u001b[1m---- Epoch 112/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.96981, fg_cpg_loss 3.76477, fg_att_reg_loss 0.22213, fg_phrcls_loss 0.98290, 153.08 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76828, fg_att_reg_loss 0.21385, fg_phrcls_loss 0.99592, fg_prc_auc 0.87912, 42.94 secs\n",
      "\u001b[1m---- Epoch 113/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.92645, fg_cpg_loss 3.74867, fg_att_reg_loss 0.22225, fg_phrcls_loss 0.95554, 155.37 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74907, fg_att_reg_loss 0.21388, fg_phrcls_loss 1.00506, fg_prc_auc 0.87982, 42.54 secs\n",
      "\u001b[1m---- Epoch 114/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.82537, fg_cpg_loss 3.65700, fg_att_reg_loss 0.22040, fg_phrcls_loss 0.94797, 155.74 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75008, fg_att_reg_loss 0.21360, fg_phrcls_loss 1.00666, fg_prc_auc 0.87844, 43.33 secs\n",
      "\u001b[1m---- Epoch 115/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.86566, fg_cpg_loss 3.68033, fg_att_reg_loss 0.22197, fg_phrcls_loss 0.96336, 154.44 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74928, fg_att_reg_loss 0.21309, fg_phrcls_loss 1.00212, fg_prc_auc 0.87868, 43.27 secs\n",
      "\u001b[1m---- Epoch 116/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.86939, fg_cpg_loss 3.69285, fg_att_reg_loss 0.22200, fg_phrcls_loss 0.95454, 155.95 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.74708, fg_att_reg_loss 0.21282, fg_phrcls_loss 0.99951, fg_prc_auc 0.87918, 42.87 secs\n",
      "\u001b[1m---- Epoch 117/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.80131, fg_cpg_loss 3.62399, fg_att_reg_loss 0.22288, fg_phrcls_loss 0.95444, 153.35 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.87626, fg_att_reg_loss 0.21923, fg_phrcls_loss 1.05431, fg_prc_auc 0.86475, 43.34 secs\n",
      "\u001b[1m---- Epoch 118/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.88503, fg_cpg_loss 3.70021, fg_att_reg_loss 0.22365, fg_phrcls_loss 0.96116, 154.85 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.81139, fg_att_reg_loss 0.21474, fg_phrcls_loss 0.99596, fg_prc_auc 0.87706, 43.54 secs\n",
      "\u001b[1m---- Epoch 119/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.91097, fg_cpg_loss 3.71766, fg_att_reg_loss 0.22201, fg_phrcls_loss 0.97129, 154.10 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.76591, fg_att_reg_loss 0.21321, fg_phrcls_loss 1.00697, fg_prc_auc 0.87411, 43.04 secs\n",
      "\u001b[1m---- Epoch 120/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.95814, fg_cpg_loss 3.76207, fg_att_reg_loss 0.22246, fg_phrcls_loss 0.97362, 154.27 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73179, fg_att_reg_loss 0.21184, fg_phrcls_loss 0.99826, fg_prc_auc 0.87832, 42.73 secs\n",
      "\u001b[1m---- Epoch 121/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.81792, fg_cpg_loss 3.64774, fg_att_reg_loss 0.21954, fg_phrcls_loss 0.95064, 153.01 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73549, fg_att_reg_loss 0.21235, fg_phrcls_loss 1.00178, fg_prc_auc 0.87944, 43.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_121_fgss+fgss+fgss+fguc=0.5867.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 122/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.83618, fg_cpg_loss 3.67564, fg_att_reg_loss 0.22040, fg_phrcls_loss 0.94014, 145.63 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73159, fg_att_reg_loss 0.21181, fg_phrcls_loss 0.99247, fg_prc_auc 0.87929, 42.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_122_fgss+fgss+fgss+fguc=0.5873.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 123/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.87208, fg_cpg_loss 3.69772, fg_att_reg_loss 0.22102, fg_phrcls_loss 0.95334, 143.42 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72601, fg_att_reg_loss 0.21264, fg_phrcls_loss 0.99486, fg_prc_auc 0.88050, 42.77 secs\n",
      "\u001b[1m---- Epoch 124/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.82412, fg_cpg_loss 3.64636, fg_att_reg_loss 0.22142, fg_phrcls_loss 0.95634, 143.36 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.72727, fg_att_reg_loss 0.21261, fg_phrcls_loss 0.99436, fg_prc_auc 0.88152, 43.39 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_124_fgss+fgss+fgss+fguc=0.5875.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 125/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.80186, fg_cpg_loss 3.62494, fg_att_reg_loss 0.22101, fg_phrcls_loss 0.95591, 143.38 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.91859, fg_att_reg_loss 0.21759, fg_phrcls_loss 1.03872, fg_prc_auc 0.86917, 43.49 secs\n",
      "\u001b[1m---- Epoch 126/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.85170, fg_cpg_loss 3.67379, fg_att_reg_loss 0.22172, fg_phrcls_loss 0.95618, 143.23 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.81257, fg_att_reg_loss 0.21332, fg_phrcls_loss 1.02613, fg_prc_auc 0.87329, 42.94 secs\n",
      "\u001b[1m---- Epoch 127/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.90553, fg_cpg_loss 3.72202, fg_att_reg_loss 0.22116, fg_phrcls_loss 0.96236, 143.24 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.77772, fg_att_reg_loss 0.21125, fg_phrcls_loss 1.00627, fg_prc_auc 0.87628, 43.01 secs\n",
      "\u001b[1m---- Epoch 128/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.93122, fg_cpg_loss 3.73618, fg_att_reg_loss 0.21778, fg_phrcls_loss 0.97725, 149.54 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.73940, fg_att_reg_loss 0.21058, fg_phrcls_loss 1.00094, fg_prc_auc 0.87683, 43.45 secs\n",
      "\u001b[1m---- Epoch 129/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.83018, fg_cpg_loss 3.67095, fg_att_reg_loss 0.21930, fg_phrcls_loss 0.93993, 153.83 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.77973, fg_att_reg_loss 0.21048, fg_phrcls_loss 1.00027, fg_prc_auc 0.87944, 42.60 secs\n",
      "\u001b[1m---- Epoch 130/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.79426, fg_cpg_loss 3.63400, fg_att_reg_loss 0.21738, fg_phrcls_loss 0.94288, 154.74 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.77673, fg_att_reg_loss 0.21120, fg_phrcls_loss 0.99965, fg_prc_auc 0.88012, 42.02 secs\n",
      "\u001b[1m---- Epoch 131/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.85220, fg_cpg_loss 3.67779, fg_att_reg_loss 0.21942, fg_phrcls_loss 0.95499, 155.00 secs\n",
      "(2) Validation stage ...\n",
      "fg_cpg_loss 4.75516, fg_att_reg_loss 0.21126, fg_phrcls_loss 0.99864, fg_prc_auc 0.87749, 43.11 secs\n",
      "\u001b[1m---- Epoch 132/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.88208, fg_cpg_loss 3.70270, fg_att_reg_loss 0.21936, fg_phrcls_loss 0.96003, 154.15 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_cpg_loss 4.74214, fg_att_reg_loss 0.21062, fg_phrcls_loss 0.99757, fg_prc_auc 0.88038, 43.54 secs\n",
      "\u001b[1m---- Epoch 133/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.71745, fg_cpg_loss 3.54589, fg_att_reg_loss 0.21907, fg_phrcls_loss 0.95249, 151.73 secs\n",
      "(2) Validation stage ...\n",
      "^C iteration 275\n",
      "Exception in thread Thread-135 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 49, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 26, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 305, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Engine run is terminating due to exception: \n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1021, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 894, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 556, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 134, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 965, in _internal_run_as_gen\n",
      "    self._fire_event(Events.EPOCH_COMPLETED)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 425, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 121, in <lambda>\n",
      "    trainer_engine.add_event_handler(Events.EPOCH_COMPLETED, lambda : validator_engine.run(val_dataloader,\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 492, in step_fn\n",
      "    output = step_fn__fact_grounding(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 99, in step_fn__fact_grounding\n",
      "    phrase_classifier_loss = phrase_classifier_criterion(phrase_classifier_logits, gt_labels.float(), phrase_weights)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/__init__.py\", line 63, in forward\n",
      "    tot = (loss1 + loss2 + loss3).detach().item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240503_230653_mim-facts_PhraseGrounder(dn121,128,256)/\" \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 700 \\\n",
    "--max_images_per_batch 20 \\\n",
    "--max_phrases_per_batch 500 \\\n",
    "--max_phrases_per_image 40 \\\n",
    "--val_batch_size_factor 2.0 \\\n",
    "--raw_image_encoding \"densenet-121\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 1024 \\\n",
    "--num_regions 169 \\\n",
    "--regions_width 13 \\\n",
    "--regions_height 13 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--qkv_size 256 \\\n",
    "--phrase_classifier_hidden_size 256 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--iters_to_accumulate 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_label_based_pos_neg_facts(hash=207,1199289774163830850).pkl\" \\\n",
    "--exclude_noisy_images \\\n",
    "--mimiccxr_balance_long_middle_short_tail \\\n",
    "--mimiccxr_report_fact_nli_integrated_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+wbce\" \\\n",
    "--use_weighted_phrase_classifier_loss \\\n",
    "--cluster_and_label_weights_for_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_clusters_and_cluster_weights_for_facts(hash=226,607533638975659953).pkl\" \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
