{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: convnextmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   classification_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: facebook/convnext-small-224\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   yolov8_use_one_detector_per_dataset: False\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   query_embed_size: None\n",
      "   local_attention_hidden_size: None\n",
      "   use_linear_head_for_classification: True\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   train_batch_size: 15\n",
      "   val_batch_size: 30\n",
      "   gradient_accumulation_steps: 2\n",
      "   num_workers: 2\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   mimiccxr_balanced_batch_size: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: train\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbcbce\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: False\n",
      "   classify_labels_vinbig: True\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[35mvinbig_class_id_offset: 0\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: convnextmodel-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "    Initializing VinBig classification task\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 1, max_grad_norm = None\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [416, 416]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [416, 416]\n",
      "Returning transform without augmentation\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=10478, #neg=4522\n",
      "Other disease     , #pos=4377, #neg=10623\n",
      "Aortic enlargement, #pos=3098, #neg=11902\n",
      "Cardiomegaly      , #pos=2316, #neg=12684\n",
      "Pleural thickening, #pos=2010, #neg=12990\n",
      "Pulmonary fibrosis, #pos=1621, #neg=13379\n",
      "Lung Opacity      , #pos=1331, #neg=13669\n",
      "Other lesion      , #pos=1154, #neg=13846\n",
      "Pleural effusion  , #pos=1038, #neg=13962\n",
      "Pneumonia         , #pos=919, #neg=14081\n",
      "Nodule/Mass       , #pos=841, #neg=14159\n",
      "Tuberculosis      , #pos=750, #neg=14250\n",
      "Infiltration      , #pos=613, #neg=14387\n",
      "Calcification     , #pos=458, #neg=14542\n",
      "ILD               , #pos=397, #neg=14603\n",
      "Consolidation     , #pos=353, #neg=14647\n",
      "Lung tumor        , #pos=291, #neg=14709\n",
      "Atelectasis       , #pos=187, #neg=14813\n",
      "Mediastinal shift , #pos=150, #neg=14850\n",
      "Enlarged PA       , #pos=131, #neg=14869\n",
      "Pneumothorax      , #pos=96, #neg=14904\n",
      "Rib fracture      , #pos=90, #neg=14910\n",
      "Emphysema         , #pos=81, #neg=14919\n",
      "Lung cavity       , #pos=51, #neg=14949\n",
      "COPD              , #pos=36, #neg=14964\n",
      "Lung cyst         , #pos=33, #neg=14967\n",
      "Clavicle fracture , #pos=27, #neg=14973\n",
      "Edema             , #pos=13, #neg=14987\n",
      "len(train_indices) = 15000\n",
      "Generating val dataset and dataloader\n",
      "len(test_indices) = 3000\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [0.3]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20250212_173558_vinbig_facebook-convnext-small-224\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20250212_173558_vinbig_facebook-convnext-small-224/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20250212_173558_vinbig_facebook-convnext-small-224/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.64080, vnb_macro_prcauc 0.14835, vnb_label_loss 1.64080, 146.72 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.09690, 43.71 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mvnb_macro_prcauc: 0.1484, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 0.1484, den = 1.0000, score = 0.1484\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mvnb_macro_prcauc: 0.0969, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 0.0969, den = 1.0000, score = 0.0969\u001b[0m\n",
      "\u001b[93mTrain score = 0.1484, Val score = 0.0969, Final score = 0.0995\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_vnb_macro_prcauc=0.0995.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.34445, vnb_macro_prcauc 0.18319, vnb_label_loss 1.34445, 143.62 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.19669, 43.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_vnb_macro_prcauc=0.1960.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.15777, vnb_macro_prcauc 0.33253, vnb_label_loss 1.15777, 143.02 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.23611, 42.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_vnb_macro_prcauc=0.2409.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.03091, vnb_macro_prcauc 0.38298, vnb_label_loss 1.03091, 140.73 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.27860, 41.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_vnb_macro_prcauc=0.2838.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.91490, vnb_macro_prcauc 0.47120, vnb_label_loss 0.91490, 142.46 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.32183, 41.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_vnb_macro_prcauc=0.3293.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.84776, vnb_macro_prcauc 0.52821, vnb_label_loss 0.84776, 139.33 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.32285, 44.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_vnb_macro_prcauc=0.3331.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.82444, vnb_macro_prcauc 0.55587, vnb_label_loss 0.82444, 141.70 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.33150, 43.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_vnb_macro_prcauc=0.3427.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.81775, vnb_macro_prcauc 0.56308, vnb_label_loss 0.81775, 139.18 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.33768, 41.62 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_vnb_macro_prcauc=0.3489.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.81296, vnb_macro_prcauc 0.57039, vnb_label_loss 0.81296, 152.12 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.33387, 51.37 secs\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.83264, vnb_macro_prcauc 0.53926, vnb_label_loss 0.83264, 161.88 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34506, 52.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_vnb_macro_prcauc=0.3548.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.76141, vnb_macro_prcauc 0.61607, vnb_label_loss 0.76141, 162.37 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34156, 53.58 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_vnb_macro_prcauc=0.3553.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72183, vnb_macro_prcauc 0.65382, vnb_label_loss 0.72183, 163.94 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34522, 54.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_vnb_macro_prcauc=0.3607.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.70926, vnb_macro_prcauc 0.66915, vnb_label_loss 0.70926, 167.46 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34839, 55.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_vnb_macro_prcauc=0.3644.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70285, vnb_macro_prcauc 0.66898, vnb_label_loss 0.70285, 169.07 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34374, 55.53 secs\n",
      "\u001b[1m---- Epoch 15/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.73512, vnb_macro_prcauc 0.63890, vnb_label_loss 0.73512, 170.05 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.35210, 55.56 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_vnb_macro_prcauc=0.3664.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.67239, vnb_macro_prcauc 0.69540, vnb_label_loss 0.67239, 168.83 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34366, 55.67 secs\n",
      "\u001b[1m---- Epoch 17/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.63955, vnb_macro_prcauc 0.73413, vnb_label_loss 0.63955, 171.63 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34239, 55.74 secs\n",
      "\u001b[1m---- Epoch 18/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.61580, vnb_macro_prcauc 0.76489, vnb_label_loss 0.61580, 171.25 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34349, 55.81 secs\n",
      "\u001b[1m---- Epoch 19/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.61393, vnb_macro_prcauc 0.76321, vnb_label_loss 0.61393, 171.36 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34245, 56.24 secs\n",
      "\u001b[1m---- Epoch 20/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.65247, vnb_macro_prcauc 0.70928, vnb_label_loss 0.65247, 170.82 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34644, 56.15 secs\n",
      "\u001b[1m---- Epoch 21/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.58793, vnb_macro_prcauc 0.79068, vnb_label_loss 0.58793, 172.95 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34425, 55.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_vnb_macro_prcauc=0.3666.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.54773, vnb_macro_prcauc 0.82129, vnb_label_loss 0.54773, 169.20 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34444, 56.35 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_vnb_macro_prcauc=0.3683.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.54058, vnb_macro_prcauc 0.83850, vnb_label_loss 0.54058, 170.95 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34319, 55.93 secs\n",
      "\u001b[1m---- Epoch 24/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.53423, vnb_macro_prcauc 0.84283, vnb_label_loss 0.53423, 172.66 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34469, 56.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_vnb_macro_prcauc=0.3696.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.58301, vnb_macro_prcauc 0.77404, vnb_label_loss 0.58301, 170.43 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.33211, 56.33 secs\n",
      "\u001b[1m---- Epoch 26/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.51849, vnb_macro_prcauc 0.84169, vnb_label_loss 0.51849, 172.15 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34332, 55.71 secs\n",
      "\u001b[1m---- Epoch 27/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.47796, vnb_macro_prcauc 0.87732, vnb_label_loss 0.47796, 171.91 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34611, 55.35 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_vnb_macro_prcauc=0.3727.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.46847, vnb_macro_prcauc 0.89136, vnb_label_loss 0.46847, 169.14 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34739, 56.15 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_vnb_macro_prcauc=0.3746.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.46831, vnb_macro_prcauc 0.88487, vnb_label_loss 0.46831, 169.23 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34635, 55.72 secs\n",
      "\u001b[1m---- Epoch 30/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.50428, vnb_macro_prcauc 0.84945, vnb_label_loss 0.50428, 171.84 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34332, 55.63 secs\n",
      "\u001b[1m---- Epoch 31/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.45159, vnb_macro_prcauc 0.89431, vnb_label_loss 0.45159, 171.54 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34322, 56.10 secs\n",
      "\u001b[1m---- Epoch 32/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.40796, vnb_macro_prcauc 0.92373, vnb_label_loss 0.40796, 171.41 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34670, 56.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_vnb_macro_prcauc=0.3756.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.40251, vnb_macro_prcauc 0.92951, vnb_label_loss 0.40251, 170.11 secs\n",
      "(2) Validation stage ...\n",
      "vnb_macro_prcauc 0.34771, 55.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_vnb_macro_prcauc=0.3768.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "^C iteration 13525\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_visual_module.py\", line 1515, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_visual_module.py\", line 1389, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_visual_module.py\", line 779, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 137, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 934, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 743, in step_fn__vinbig\n",
      "    gradient_accumulator.step(batch_loss, model)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 35, in step\n",
      "    self.scaler.step(self.optimizer)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/amp/grad_scaler.py\", line 453, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/amp/grad_scaler.py\", line 350, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/amp/grad_scaler.py\", line 350, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "--epochs 80 \\\n",
    "--batches_per_epoch 400 \\\n",
    "--train_batch_size 15 \\\n",
    "--val_batch_size 30 \\\n",
    "--num_workers 2 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--use_vinbig \\\n",
    "--vinbig_training_data_mode \"train\" \\\n",
    "--vinbig_use_validation \\\n",
    "--classify_labels_vinbig \\\n",
    "--binary_loss_name \"focal+bce+wbcbce\" \\\n",
    "--raw_image_encoding \"convnextmodel-huggingface\" \\\n",
    "--huggingface_model_name \"facebook/convnext-small-224\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 169 \\\n",
    "--use_linear_head_for_classification \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
