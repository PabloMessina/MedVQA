{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 250\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: yolov11-for-det-mlc\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   classification_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   yolov8_use_one_detector_per_dataset: False\n",
      "   yolov11_model_name_or_path: yolov8l.pt\n",
      "   yolov11_model_alias: yolov8l\n",
      "   query_embed_size: None\n",
      "   local_attention_hidden_size: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,6,1e-6,1e-4,6,1e-6\n",
      "   batch_size: 100\n",
      "   gradient_accumulation_steps: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   mimiccxr_balanced_batch_size: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230608_215137_mim+vinbig_yolov8l_dws=1.0,0.4/checkpoint_60_chou+chuc+chuc+chuc+chuc+gacc+vnou+vnf1+vnuc+vnuc=0.6742.pt_adapted\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: train\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbcbce\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: True\n",
      "   classify_labels_vinbig: False\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped).pkl...\n",
      "avg_coords.shape= (144,)\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[35mvinbig_class_id_offset: 0\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: yolov11-for-det-mlc\n",
      "Overriding model.yaml nc=80 with nc=36\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5610556  ultralytics.nn.modules.head.Detect           [36, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43,657,596 parameters, 43,657,580 gradients, 165.6 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.head.Detect           [22, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43,646,802 parameters, 43,646,786 gradients, 165.5 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "  Initializing auxiliary tasks\n",
      "    Skipping auxiliary tasks initialization for YOLOV11_FOR_DET_MLC\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,6,1e-6,1e-4,6,1e-6\n",
      "1e-06 3 0.0001 6 1e-06 0.0001 6 1e-06\n",
      "self.steps_to_restart = 6\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 1, max_grad_norm = None\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.0, 0.0, 0.0]\n",
      "  std = [1.0, 1.0, 1.0]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    returning transform (not for vinbig)\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.0, 0.0, 0.0]\n",
      "  std = [1.0, 1.0, 1.0]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Using image size mode: medium_512\n",
      "Allowed dicom ids: 240530\n",
      "227835it [00:01, 225379.22it/s]\n",
      "max_idx_count = 377110\n",
      "actual_idx_count = 240530\n",
      "** NOTE: 136580 images were skipped because they were not in the allowed DICOM IDs\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "self.bbox_coords.shape = (243310, 36, 4)\n",
      "self.bbox_presence.shape = (243310, 36)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.0, 0.0, 0.0]\n",
      "  std = [1.0, 1.0, 1.0]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.0, 0.0, 0.0]\n",
      "  std = [1.0, 1.0, 1.0]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=10601, #neg=4399\n",
      "Other disease     , #pos=4288, #neg=10712\n",
      "Aortic enlargement, #pos=3067, #neg=11933\n",
      "Cardiomegaly      , #pos=2300, #neg=12700\n",
      "Pleural thickening, #pos=1981, #neg=13019\n",
      "Pulmonary fibrosis, #pos=1617, #neg=13383\n",
      "Lung Opacity      , #pos=1322, #neg=13678\n",
      "Other lesion      , #pos=1134, #neg=13866\n",
      "Pleural effusion  , #pos=1032, #neg=13968\n",
      "Pneumonia         , #pos=917, #neg=14083\n",
      "Nodule/Mass       , #pos=830, #neg=14170\n",
      "Tuberculosis      , #pos=750, #neg=14250\n",
      "Infiltration      , #pos=613, #neg=14387\n",
      "Calcification     , #pos=452, #neg=14548\n",
      "ILD               , #pos=386, #neg=14614\n",
      "Consolidation     , #pos=353, #neg=14647\n",
      "Lung tumor        , #pos=291, #neg=14709\n",
      "Atelectasis       , #pos=186, #neg=14814\n",
      "Mediastinal shift , #pos=150, #neg=14850\n",
      "Enlarged PA       , #pos=131, #neg=14869\n",
      "Pneumothorax      , #pos=96, #neg=14904\n",
      "Rib fracture      , #pos=90, #neg=14910\n",
      "Emphysema         , #pos=78, #neg=14922\n",
      "Lung cavity       , #pos=50, #neg=14950\n",
      "COPD              , #pos=35, #neg=14965\n",
      "Lung cyst         , #pos=32, #neg=14968\n",
      "Clavicle fracture , #pos=27, #neg=14973\n",
      "Edema             , #pos=13, #neg=14987\n",
      "len(train_indices) = 15000\n",
      "len(self.test_indices) = 3000\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 2\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1, 0.3]\n",
      "merged_dataset_name = mim+vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230608_215137_mim+vinbig_yolov8l_dws=1.0,0.4/checkpoint_60_chou+chuc+chuc+chuc+chuc+gacc+vnou+vnf1+vnuc+vnuc=0.6742.pt_adapted\n",
      "\u001b[93mWarning: model state dict has 765 keys, loaded state dict has 1146 keys, intersection has 680 keys, union has 1231 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in model but not in loaded state dict:\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.0.0.bn.running_var\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv2.1.2.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.0.0.bn.running_mean\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.1.2.bias\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.1.0.bn.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.0.1.bn.bias\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.0.1.bn.running_mean\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.1.1.bn.running_mean\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.2.1.conv.weight\u001b[0m\n",
      "\u001b[93m  raw_image_encoder.original_detect.cv3.2.2.bias\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  MLC_vinbig.loc_proj.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.glob_mlc_fc.22.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.glob_mlc_fc.38.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.bbox_mid_layer.10.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.loc_mlc_fc.21.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.loc_projs.40.weight\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.glob_projs.29.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.loc_projs.21.weight\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.bbox_mid_layer.15.bias\u001b[0m\n",
      "\u001b[93m  MLC_chst_imgn.glob_mlc_fc.25.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20241122_211226_mim+vinbig_yolov8l(d:cig,vinbig)_dws=1,0.3/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m16) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.30259, vnb_y11_loss 5.03811, vnb_y11_box_loss 1.56182, vnb_y11_cls_loss 1.90688, vnb_y11_dfl_loss 1.56941, cig_y11_loss 4.08040, cig_y11_box_loss 1.27318, cig_y11_cls_loss 1.32837, cig_y11_dfl_loss 1.47885, 177.65 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.05653, cig_y11_bbox_iou 0.70525, 46.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.3809.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.82925, vnb_y11_loss 4.69118, vnb_y11_box_loss 1.50702, vnb_y11_cls_loss 1.65079, vnb_y11_dfl_loss 1.53337, cig_y11_loss 3.56888, cig_y11_box_loss 1.23541, cig_y11_cls_loss 0.89104, cig_y11_dfl_loss 1.44243, 176.52 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.06909, cig_y11_bbox_iou 0.70042, 47.85 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.3848.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.63077, vnb_y11_loss 4.50429, vnb_y11_box_loss 1.47349, vnb_y11_cls_loss 1.53107, vnb_y11_dfl_loss 1.49972, cig_y11_loss 3.36690, cig_y11_box_loss 1.18788, cig_y11_cls_loss 0.77586, cig_y11_dfl_loss 1.40316, 181.66 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.07800, cig_y11_bbox_iou 0.71371, 49.52 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.3959.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.57869, vnb_y11_loss 4.50736, vnb_y11_box_loss 1.47793, vnb_y11_cls_loss 1.53266, vnb_y11_dfl_loss 1.49677, cig_y11_loss 3.29816, cig_y11_box_loss 1.16807, cig_y11_cls_loss 0.74136, cig_y11_dfl_loss 1.38874, 185.75 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.08014, cig_y11_bbox_iou 0.72962, 50.49 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.4049.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 3.49506, vnb_y11_loss 4.33455, vnb_y11_box_loss 1.42789, vnb_y11_cls_loss 1.45419, vnb_y11_dfl_loss 1.45246, cig_y11_loss 3.24147, cig_y11_box_loss 1.15405, cig_y11_cls_loss 0.71024, cig_y11_dfl_loss 1.37717, 190.31 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.07774, cig_y11_bbox_iou 0.73363, 51.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.4057.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.44484, vnb_y11_loss 4.26383, vnb_y11_box_loss 1.41038, vnb_y11_cls_loss 1.41434, vnb_y11_dfl_loss 1.43910, cig_y11_loss 3.19744, cig_y11_box_loss 1.13899, cig_y11_cls_loss 0.69288, cig_y11_dfl_loss 1.36557, 192.65 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.07617, cig_y11_bbox_iou 0.73111, 51.46 secs\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.44938, vnb_y11_loss 4.31748, vnb_y11_box_loss 1.43144, vnb_y11_cls_loss 1.42700, vnb_y11_dfl_loss 1.45905, cig_y11_loss 3.18714, cig_y11_box_loss 1.13605, cig_y11_cls_loss 0.68803, cig_y11_dfl_loss 1.36306, 195.63 secs\n",
      "(2) Validation stage ...\n",
      "vnb_y11_bbox_iou 0.08052, cig_y11_bbox_iou 0.73413, 50.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_cig_y11_bbox_iou+vnb_y11_bbox_iou=0.4073.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n"
     ]
    }
   ],
   "source": [
    "# --pretrained_checkpoint_folder_path \\\n",
    "# \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230608_215137_mim+vinbig_yolov8l_dws=1.0,0.4\" \\\n",
    "\n",
    "!python ../train_visual_module.py \\\n",
    "--pretrained_checkpoint_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230608_215137_mim+vinbig_yolov8l_dws=1.0,0.4/checkpoint_60_chou+chuc+chuc+chuc+chuc+gacc+vnou+vnf1+vnuc+vnuc=0.6742.pt_adapted\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 250 \\\n",
    "--batch_size 100 \\\n",
    "--num_workers 3 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,1e-4,6,1e-6,1e-4,6,1e-6\" \\\n",
    "--use_mimiccxr \\\n",
    "--mimiccxr_view_mode \"chest_imagenome\" \\\n",
    "--predict_bboxes_chest_imagenome \\\n",
    "--clamp_bboxes_chest_imagenome \\\n",
    "--use_vinbig \\\n",
    "--vinbig_training_data_mode \"train\" \\\n",
    "--vinbig_use_validation \\\n",
    "--predict_bboxes_vinbig \\\n",
    "--binary_loss_name \"focal+bce+wbcbce\" \\\n",
    "--raw_image_encoding \"yolov11-for-det-mlc\" \\\n",
    "--yolov11_model_name_or_path \"yolov8l.pt\" \\\n",
    "--yolov11_model_alias \"yolov8l\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 169 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
