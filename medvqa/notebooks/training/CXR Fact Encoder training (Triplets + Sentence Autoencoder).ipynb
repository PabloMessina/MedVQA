{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bd44d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 800\n",
      "   batch_size: 30\n",
      "   val_batch_size: 120\n",
      "   radgraph_spert_batch_size: None\n",
      "   checkpoint_folder: None\n",
      "   huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   embedding_size: 128\n",
      "   n_chest_imagenome_observations: None\n",
      "   n_chest_imagenome_anatomical_locations: None\n",
      "   use_aux_task_hidden_layer: False\n",
      "   aux_task_hidden_layer_size: None\n",
      "   nli_hidden_layer_size: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_152451_MIMIC-CXR(autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   freeze_huggingface_model: False\n",
      "   spert_size_embedding: 25\n",
      "   spert_max_pairs: 1000\n",
      "   spert_prop_drop: 0.1\n",
      "   fact_decoder_embed_size: 256\n",
      "   fact_decoder_hidden_size: 256\n",
      "   fact_decoder_nhead: 1\n",
      "   fact_decoder_dim_feedforward: 256\n",
      "   fact_decoder_num_layers: 1\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,9e-5,8,2e-6,9e-5,8,2e-6\n",
      "   iters_to_accumulate: 8\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   triplet_loss_weight: 1.0\n",
      "   category_classif_loss_weight: 1.0\n",
      "   health_status_classif_loss_weight: 1.0\n",
      "   comparison_status_classif_loss_weight: 1.0\n",
      "   chest_imagenome_obs_classif_loss_weight: 1.0\n",
      "   chest_imagenome_anatloc_classif_loss_weight: 1.0\n",
      "   nli_loss_weight: 1.0\n",
      "   entcon_loss_weight: 1.0\n",
      "   triplets_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000).pkl\n",
      "   triplet_rule_weights: {'anatomical_locations': [1.0, 2.0, 1.0], 'observations': [1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0]}\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrases_jsonl_filepaths: None\n",
      "   integrated_chest_imagenome_observations_filepath: None\n",
      "   integrated_chest_imagenome_anatomical_locations_filepath: None\n",
      "   integrated_nli_jsonl_filepath: None\n",
      "   integrated_sentence_facts_jsonl_filepath: None\n",
      "   gpt4_radnli_labels_jsonl_filepath: None\n",
      "   sentences_and_cluster_ids_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/sentence_cluster_ids((2589, 1439222964121874843)).pkl\n",
      "   dataset_name: MIMIC-CXR(triplets+autoencoder)\n",
      "   triplets_weight: 1.0\n",
      "   metadata_classification_weight: 0\n",
      "   chest_imagenome_observations_classification_weight: 0\n",
      "   chest_imagenome_anatomical_locations_classification_weight: 0\n",
      "   nli_weight: 0\n",
      "   entcon_weight: 0\n",
      "   radgraph_ner_re_weight: 0\n",
      "   sentence_autoencoder_weight: 1.0\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mDefining collate batch functions ...\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000).pkl...\n",
      "----\n",
      "\u001b[1mBuilding train triplet ranking dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 3440324\n",
      "\tWeight: 1.0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 3432231\n",
      "\tWeight: 2.0\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 3184200\n",
      "\tWeight: 1.0\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 4057112\n",
      "\tWeight: 1.0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 4055244\n",
      "\tWeight: 2.0\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 4427792\n",
      "\tWeight: 1.0\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 2602759\n",
      "\tWeight: 1.0\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other\"\n",
      "\tNumber of triplets: 6247226\n",
      "\tWeight: 1.0\n",
      "observations -> rule 5: \"Rank triplets according to Chest ImaGenome labels\"\n",
      "\tNumber of triplets: 3512298\n",
      "\tWeight: 2.0\n",
      "observations -> rule 6: \"RadGraph-based triplets\"\n",
      "\tNumber of triplets: 3172933\n",
      "\tWeight: 1.0\n",
      "observations -> rule 7: \"Hard negative triplets generated by ChatGPT\"\n",
      "\tNumber of triplets: 3044779\n",
      "\tWeight: 2.0\n",
      "----\n",
      "\u001b[1mBuilding sentence autoencoder train/val dataset and dataloader...\u001b[0m\n",
      "Number of sentences: 3882542\n",
      "Number of cluster IDs: 3882542\n",
      "Number of clusters: 1000\n",
      "Number of sentences in largest cluster: 27433\n",
      "Number of sentences in smallest cluster: 440\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/fact_decoding_vocab(116, 1862760546599818235).pkl ...\n",
      "Vocabulary size: 15773\n",
      "Number of tokens in vocab: 15773\n",
      "Loading sentence IDs from cache...\n",
      "Number of validation samples: 5000\n",
      "Number of training samples: 3877542\n",
      "----\n",
      "\u001b[1mBuilding val triplets dataset and dataloader...\u001b[0m\n",
      "anatomical_locations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al0\n",
      "anatomical_locations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al1\n",
      "anatomical_locations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: al2\n",
      "observations -> rule 0: \"Rank paraphrases very highly\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob0\n",
      "observations -> rule 1: \"Rank paraphrases very highly - Hard negative\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob1\n",
      "observations -> rule 2: \"Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob2\n",
      "observations -> rule 3: \"Hard health-status-vs-others triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob3\n",
      "observations -> rule 4: \"Short observation, detailed observation, and fact must be close to each other\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob4\n",
      "observations -> rule 5: \"Rank triplets according to Chest ImaGenome labels\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob5\n",
      "observations -> rule 6: \"RadGraph-based triplets\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob6\n",
      "observations -> rule 7: \"Hard negative triplets generated by ChatGPT\"\n",
      "\tNumber of triplets: 1000\n",
      "\tRule ID: ob7\n",
      "len(_train_dataloaders) = 2\n",
      "len(_train_weights) = 2\n",
      "_train_weights = [1.0, 1.0]\n",
      "len(_val_dataloaders) = 2\n",
      "fact_embedding_trainer.name =  MIMIC-CXR(triplets+autoencoder)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mCreating instance of FactEncoder ...\u001b[0m\n",
      "Fact encoder\n",
      "  huggingface_model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "  embedding_size: 128\n",
      "  classify_category: False\n",
      "  n_categories: 6\n",
      "  classify_health_status: False\n",
      "  n_health_statuses: 5\n",
      "  classify_comparison_status: False\n",
      "  n_comparison_statuses: 15\n",
      "  classify_chest_imagenome_obs: False\n",
      "  n_chest_imagenome_observations: None\n",
      "  classify_chest_imagenome_anatloc: False\n",
      "  n_chest_imagenome_anatomical_locations: None\n",
      "  use_aux_task_hidden_layer: False\n",
      "  aux_task_hidden_layer_size: None\n",
      "  do_nli: False\n",
      "  nli_hidden_layer_size: None\n",
      "  use_spert: False\n",
      "  spert_size_embedding: None\n",
      "  spert_relation_types: None\n",
      "  spert_entity_types: None\n",
      "  spert_max_pairs: None\n",
      "  spert_prop_drop: None\n",
      "  spert_cls_token: None\n",
      "  use_fact_decoder: True\n",
      "  fact_decoder_embed_size: 256\n",
      "  fact_decoder_hidden_size: 256\n",
      "  fact_decoder_nhead: 1\n",
      "  fact_decoder_dim_feedforward: 256\n",
      "  fact_decoder_num_layers: 1\n",
      "  fact_decoder_start_idx: 1\n",
      "  fact_decoder_vocab_size: 15773\n",
      "  fact_decoder_dropout_prob: 0\n",
      "\u001b[93m\u001b[1mWARNING: unused_kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_152451_MIMIC-CXR(autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,9e-5,8,2e-6,9e-5,8,2e-6\n",
      "1e-06 3 9e-05 8 2e-06 9e-05 8 2e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 9e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 8, max_grad_norm = None\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_178_sae_loss=0.6808.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_152451_MIMIC-CXR(autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_178_sae_loss=0.6808.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.63310, triplet_loss 0.55476, sae_loss 0.71144, 86.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97500, tacc(al1) 0.89300, tacc(al2) 0.96100, tacc(ob0) 0.99700, tacc(ob1) 0.96200, tacc(ob2) 0.95300, tacc(ob3) 0.97700, tacc(ob4) 0.95100, tacc(ob5) 0.77500, tacc(ob6) 0.93500, tacc(ob7) 0.71400, sae_loss 0.44491, 9.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8532.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.63252, triplet_loss 0.54925, sae_loss 0.71580, 82.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.97900, tacc(al1) 0.89000, tacc(al2) 0.96600, tacc(ob0) 0.99700, tacc(ob1) 0.96300, tacc(ob2) 0.95900, tacc(ob3) 0.98000, tacc(ob4) 0.95600, tacc(ob5) 0.77300, tacc(ob6) 0.94200, tacc(ob7) 0.71600, sae_loss 0.44467, 10.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8545.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.63078, triplet_loss 0.53686, sae_loss 0.72469, 83.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.98200, tacc(al1) 0.90700, tacc(al2) 0.97500, tacc(ob0) 0.99800, tacc(ob1) 0.96900, tacc(ob2) 0.96700, tacc(ob3) 0.98300, tacc(ob4) 0.96800, tacc(ob5) 0.79700, tacc(ob6) 0.94900, tacc(ob7) 0.74200, sae_loss 0.44765, 10.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8648.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.63481, triplet_loss 0.52379, sae_loss 0.74582, 84.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.92300, tacc(al2) 0.98000, tacc(ob0) 0.99700, tacc(ob1) 0.97900, tacc(ob2) 0.96900, tacc(ob3) 0.98500, tacc(ob4) 0.97400, tacc(ob5) 0.81300, tacc(ob6) 0.95500, tacc(ob7) 0.78300, sae_loss 0.47572, 9.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8743.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 0.62582, triplet_loss 0.51570, sae_loss 0.73594, 84.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.93200, tacc(al2) 0.97500, tacc(ob0) 0.99800, tacc(ob1) 0.98200, tacc(ob2) 0.97600, tacc(ob3) 0.98600, tacc(ob4) 0.98100, tacc(ob5) 0.83200, tacc(ob6) 0.96300, tacc(ob7) 0.80300, sae_loss 0.46561, 10.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8817.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000035) ...\n",
      "loss 0.62134, triplet_loss 0.51010, sae_loss 0.73258, 83.10 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.93000, tacc(al2) 0.97800, tacc(ob0) 0.99800, tacc(ob1) 0.98400, tacc(ob2) 0.97400, tacc(ob3) 0.98600, tacc(ob4) 0.98100, tacc(ob5) 0.82300, tacc(ob6) 0.96300, tacc(ob7) 0.80700, sae_loss 0.46255, 10.10 secs\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.62022, triplet_loss 0.51201, sae_loss 0.72843, 84.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.93400, tacc(al2) 0.97700, tacc(ob0) 0.99800, tacc(ob1) 0.98500, tacc(ob2) 0.97600, tacc(ob3) 0.98600, tacc(ob4) 0.98300, tacc(ob5) 0.82900, tacc(ob6) 0.96400, tacc(ob7) 0.80500, sae_loss 0.46147, 9.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8829.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.62448, triplet_loss 0.50873, sae_loss 0.74024, 84.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99500, tacc(al1) 0.93900, tacc(al2) 0.97700, tacc(ob0) 0.99800, tacc(ob1) 0.98300, tacc(ob2) 0.97500, tacc(ob3) 0.98600, tacc(ob4) 0.98200, tacc(ob5) 0.82800, tacc(ob6) 0.96600, tacc(ob7) 0.81300, sae_loss 0.46033, 10.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8838.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.62212, triplet_loss 0.50795, sae_loss 0.73628, 83.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94100, tacc(al2) 0.97600, tacc(ob0) 0.99800, tacc(ob1) 0.98300, tacc(ob2) 0.97400, tacc(ob3) 0.98600, tacc(ob4) 0.98200, tacc(ob5) 0.83000, tacc(ob6) 0.96600, tacc(ob7) 0.81100, sae_loss 0.45963, 9.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8840.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.61805, triplet_loss 0.50809, sae_loss 0.72800, 85.98 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.93600, tacc(al2) 0.97700, tacc(ob0) 0.99800, tacc(ob1) 0.98400, tacc(ob2) 0.97500, tacc(ob3) 0.98700, tacc(ob4) 0.98200, tacc(ob5) 0.83100, tacc(ob6) 0.96700, tacc(ob7) 0.81400, sae_loss 0.45941, 10.07 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8845.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.61914, triplet_loss 0.50812, sae_loss 0.73015, 84.70 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99400, tacc(al1) 0.93700, tacc(al2) 0.97800, tacc(ob0) 0.99800, tacc(ob1) 0.98200, tacc(ob2) 0.97500, tacc(ob3) 0.98700, tacc(ob4) 0.98100, tacc(ob5) 0.83200, tacc(ob6) 0.96700, tacc(ob7) 0.81500, sae_loss 0.45937, 10.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8845.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.61194, triplet_loss 0.50864, sae_loss 0.71524, 84.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.93900, tacc(al2) 0.97800, tacc(ob0) 0.99800, tacc(ob1) 0.98200, tacc(ob2) 0.97500, tacc(ob3) 0.98700, tacc(ob4) 0.98200, tacc(ob5) 0.83300, tacc(ob6) 0.96700, tacc(ob7) 0.81400, sae_loss 0.45889, 9.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8853.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.63593, triplet_loss 0.50576, sae_loss 0.76610, 87.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.93800, tacc(al2) 0.97300, tacc(ob0) 0.99800, tacc(ob1) 0.98400, tacc(ob2) 0.97300, tacc(ob3) 0.98400, tacc(ob4) 0.98300, tacc(ob5) 0.83200, tacc(ob6) 0.96900, tacc(ob7) 0.82100, sae_loss 0.49288, 9.99 secs\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.61907, triplet_loss 0.50373, sae_loss 0.73442, 82.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94200, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.97400, tacc(ob3) 0.98900, tacc(ob4) 0.98100, tacc(ob5) 0.84300, tacc(ob6) 0.96800, tacc(ob7) 0.82400, sae_loss 0.46774, 10.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8871.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.62638, triplet_loss 0.50210, sae_loss 0.75065, 83.79 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94400, tacc(al2) 0.97600, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.97100, tacc(ob3) 0.98800, tacc(ob4) 0.98400, tacc(ob5) 0.84700, tacc(ob6) 0.97000, tacc(ob7) 0.82700, sae_loss 0.46610, 10.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8878.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.61199, triplet_loss 0.49981, sae_loss 0.72418, 85.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94400, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.97000, tacc(ob3) 0.99000, tacc(ob4) 0.98500, tacc(ob5) 0.84900, tacc(ob6) 0.97100, tacc(ob7) 0.83100, sae_loss 0.46414, 10.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8896.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.61708, triplet_loss 0.49894, sae_loss 0.73523, 84.41 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94400, tacc(al2) 0.97500, tacc(ob0) 0.99800, tacc(ob1) 0.98500, tacc(ob2) 0.97000, tacc(ob3) 0.98900, tacc(ob4) 0.98400, tacc(ob5) 0.84900, tacc(ob6) 0.97100, tacc(ob7) 0.83500, sae_loss 0.46381, 10.16 secs\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.61527, triplet_loss 0.49968, sae_loss 0.73086, 86.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94300, tacc(al2) 0.97500, tacc(ob0) 0.99800, tacc(ob1) 0.98600, tacc(ob2) 0.97000, tacc(ob3) 0.98900, tacc(ob4) 0.98400, tacc(ob5) 0.84600, tacc(ob6) 0.97000, tacc(ob7) 0.83200, sae_loss 0.46282, 10.13 secs\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.61552, triplet_loss 0.50080, sae_loss 0.73023, 83.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94500, tacc(al2) 0.97500, tacc(ob0) 0.99800, tacc(ob1) 0.98600, tacc(ob2) 0.97100, tacc(ob3) 0.98900, tacc(ob4) 0.98500, tacc(ob5) 0.84700, tacc(ob6) 0.97200, tacc(ob7) 0.83000, sae_loss 0.46223, 10.07 secs\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.61065, triplet_loss 0.49909, sae_loss 0.72221, 88.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94300, tacc(al2) 0.97500, tacc(ob0) 0.99800, tacc(ob1) 0.98600, tacc(ob2) 0.97100, tacc(ob3) 0.99000, tacc(ob4) 0.98500, tacc(ob5) 0.84700, tacc(ob6) 0.97200, tacc(ob7) 0.83200, sae_loss 0.46233, 10.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8897.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61937, triplet_loss 0.50003, sae_loss 0.73870, 88.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94200, tacc(al2) 0.97200, tacc(ob0) 0.99800, tacc(ob1) 0.98400, tacc(ob2) 0.97500, tacc(ob3) 0.99000, tacc(ob4) 0.98000, tacc(ob5) 0.83900, tacc(ob6) 0.97400, tacc(ob7) 0.84200, sae_loss 0.48892, 10.11 secs\n",
      "\u001b[1m---- Epoch 22/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.61794, triplet_loss 0.49502, sae_loss 0.74085, 86.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94700, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.97200, tacc(ob3) 0.98900, tacc(ob4) 0.98300, tacc(ob5) 0.83800, tacc(ob6) 0.97500, tacc(ob7) 0.84200, sae_loss 0.47033, 10.00 secs\n",
      "\u001b[1m---- Epoch 23/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.61401, triplet_loss 0.49577, sae_loss 0.73225, 86.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94400, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96900, tacc(ob3) 0.99000, tacc(ob4) 0.98700, tacc(ob5) 0.84400, tacc(ob6) 0.97400, tacc(ob7) 0.84600, sae_loss 0.46682, 10.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8904.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.61809, triplet_loss 0.49656, sae_loss 0.73962, 86.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94400, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.97000, tacc(ob3) 0.99000, tacc(ob4) 0.98600, tacc(ob5) 0.84400, tacc(ob6) 0.97400, tacc(ob7) 0.85200, sae_loss 0.46495, 10.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8909.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.61594, triplet_loss 0.49348, sae_loss 0.73841, 88.59 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94600, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.97200, tacc(ob3) 0.98900, tacc(ob4) 0.98400, tacc(ob5) 0.84200, tacc(ob6) 0.97400, tacc(ob7) 0.84700, sae_loss 0.46326, 10.02 secs\n",
      "\u001b[1m---- Epoch 26/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.61689, triplet_loss 0.49527, sae_loss 0.73851, 85.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94600, tacc(al2) 0.97500, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97000, tacc(ob3) 0.98900, tacc(ob4) 0.98500, tacc(ob5) 0.84100, tacc(ob6) 0.97500, tacc(ob7) 0.84900, sae_loss 0.46284, 10.09 secs\n",
      "\u001b[1m---- Epoch 27/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.61357, triplet_loss 0.49439, sae_loss 0.73275, 89.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94500, tacc(al2) 0.97500, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.97000, tacc(ob3) 0.98900, tacc(ob4) 0.98600, tacc(ob5) 0.84300, tacc(ob6) 0.97500, tacc(ob7) 0.85000, sae_loss 0.46262, 10.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8910.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.61208, triplet_loss 0.49413, sae_loss 0.73004, 85.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94500, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97100, tacc(ob3) 0.98900, tacc(ob4) 0.98600, tacc(ob5) 0.84200, tacc(ob6) 0.97500, tacc(ob7) 0.84900, sae_loss 0.46265, 9.98 secs\n",
      "\u001b[1m---- Epoch 29/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.63034, triplet_loss 0.49591, sae_loss 0.76476, 84.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.94800, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97200, tacc(ob3) 0.99100, tacc(ob4) 0.98400, tacc(ob5) 0.85100, tacc(ob6) 0.97400, tacc(ob7) 0.84600, sae_loss 0.51423, 9.99 secs\n",
      "\u001b[1m---- Epoch 30/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.61506, triplet_loss 0.49249, sae_loss 0.73763, 81.52 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95100, tacc(al2) 0.97600, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97100, tacc(ob3) 0.98900, tacc(ob4) 0.98600, tacc(ob5) 0.84200, tacc(ob6) 0.97500, tacc(ob7) 0.85600, sae_loss 0.47033, 9.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_30_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8917.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 31/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.61414, triplet_loss 0.49097, sae_loss 0.73732, 85.76 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.94700, tacc(al2) 0.97500, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.96900, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.84200, tacc(ob6) 0.97500, tacc(ob7) 0.86300, sae_loss 0.46776, 10.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_31_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8922.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 32/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.61566, triplet_loss 0.48930, sae_loss 0.74202, 85.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94800, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97200, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.84800, tacc(ob6) 0.97700, tacc(ob7) 0.85800, sae_loss 0.46488, 9.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8924.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.61162, triplet_loss 0.49201, sae_loss 0.73122, 85.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.94900, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97000, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.84700, tacc(ob6) 0.97800, tacc(ob7) 0.85600, sae_loss 0.46459, 10.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8925.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60968, triplet_loss 0.49215, sae_loss 0.72720, 85.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95100, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.97000, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.84600, tacc(ob6) 0.97700, tacc(ob7) 0.86100, sae_loss 0.46355, 10.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_34_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8933.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 35/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.60699, triplet_loss 0.49054, sae_loss 0.72343, 83.92 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95000, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.97100, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.84500, tacc(ob6) 0.97700, tacc(ob7) 0.86200, sae_loss 0.46341, 10.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8935.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.61250, triplet_loss 0.48985, sae_loss 0.73515, 85.31 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95000, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.97100, tacc(ob3) 0.98800, tacc(ob4) 0.98600, tacc(ob5) 0.84600, tacc(ob6) 0.97700, tacc(ob7) 0.86300, sae_loss 0.46300, 10.04 secs\n",
      "\u001b[1m---- Epoch 37/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.62115, triplet_loss 0.48962, sae_loss 0.75268, 85.49 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95300, tacc(al2) 0.97300, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.96900, tacc(ob3) 0.98800, tacc(ob4) 0.98200, tacc(ob5) 0.84700, tacc(ob6) 0.97800, tacc(ob7) 0.86100, sae_loss 0.49482, 10.07 secs\n",
      "\u001b[1m---- Epoch 38/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.62112, triplet_loss 0.48934, sae_loss 0.75291, 85.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95600, tacc(al2) 0.97400, tacc(ob0) 0.99700, tacc(ob1) 0.98700, tacc(ob2) 0.96900, tacc(ob3) 0.98700, tacc(ob4) 0.98700, tacc(ob5) 0.84500, tacc(ob6) 0.97700, tacc(ob7) 0.86300, sae_loss 0.46941, 9.93 secs\n",
      "\u001b[1m---- Epoch 39/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.61602, triplet_loss 0.48861, sae_loss 0.74344, 85.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95400, tacc(al2) 0.97100, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96800, tacc(ob3) 0.98900, tacc(ob4) 0.98600, tacc(ob5) 0.84800, tacc(ob6) 0.97800, tacc(ob7) 0.87000, sae_loss 0.46676, 10.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8943.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.60499, triplet_loss 0.48838, sae_loss 0.72160, 84.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.97100, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96800, tacc(ob3) 0.99100, tacc(ob4) 0.98600, tacc(ob5) 0.84600, tacc(ob6) 0.97800, tacc(ob7) 0.86600, sae_loss 0.46548, 9.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_40_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8947.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 41/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.61079, triplet_loss 0.48771, sae_loss 0.73386, 85.24 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95800, tacc(al2) 0.96800, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96700, tacc(ob3) 0.99000, tacc(ob4) 0.98500, tacc(ob5) 0.84800, tacc(ob6) 0.97800, tacc(ob7) 0.86800, sae_loss 0.46357, 10.12 secs\n",
      "\u001b[1m---- Epoch 42/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60881, triplet_loss 0.48712, sae_loss 0.73051, 85.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.96900, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96700, tacc(ob3) 0.99000, tacc(ob4) 0.98400, tacc(ob5) 0.85100, tacc(ob6) 0.97600, tacc(ob7) 0.86800, sae_loss 0.46279, 10.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8948.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.60752, triplet_loss 0.48787, sae_loss 0.72716, 86.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.97000, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.96800, tacc(ob3) 0.99000, tacc(ob4) 0.98500, tacc(ob5) 0.84700, tacc(ob6) 0.97900, tacc(ob7) 0.86700, sae_loss 0.46246, 10.02 secs\n",
      "\u001b[1m---- Epoch 44/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.61151, triplet_loss 0.48810, sae_loss 0.73492, 85.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.97000, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96800, tacc(ob3) 0.99000, tacc(ob4) 0.98700, tacc(ob5) 0.84700, tacc(ob6) 0.97700, tacc(ob7) 0.86800, sae_loss 0.46291, 9.89 secs\n",
      "\u001b[1m---- Epoch 45/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.62832, triplet_loss 0.48794, sae_loss 0.76870, 85.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95100, tacc(al2) 0.97000, tacc(ob0) 0.99800, tacc(ob1) 0.98800, tacc(ob2) 0.96400, tacc(ob3) 0.98700, tacc(ob4) 0.98600, tacc(ob5) 0.84300, tacc(ob6) 0.97400, tacc(ob7) 0.86100, sae_loss 0.50566, 9.92 secs\n",
      "\u001b[1m---- Epoch 46/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.61597, triplet_loss 0.48748, sae_loss 0.74446, 85.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95300, tacc(al2) 0.97200, tacc(ob0) 0.99800, tacc(ob1) 0.98300, tacc(ob2) 0.96800, tacc(ob3) 0.99000, tacc(ob4) 0.99100, tacc(ob5) 0.85600, tacc(ob6) 0.97900, tacc(ob7) 0.86400, sae_loss 0.46937, 9.92 secs\n",
      "\u001b[1m---- Epoch 47/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.61304, triplet_loss 0.48670, sae_loss 0.73937, 85.42 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95400, tacc(al2) 0.97200, tacc(ob0) 0.99800, tacc(ob1) 0.98500, tacc(ob2) 0.96800, tacc(ob3) 0.98700, tacc(ob4) 0.99200, tacc(ob5) 0.84700, tacc(ob6) 0.97900, tacc(ob7) 0.86800, sae_loss 0.46618, 10.12 secs\n",
      "\u001b[1m---- Epoch 48/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.61477, triplet_loss 0.48513, sae_loss 0.74440, 86.01 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96800, tacc(ob0) 0.99800, tacc(ob1) 0.98500, tacc(ob2) 0.96600, tacc(ob3) 0.98900, tacc(ob4) 0.99200, tacc(ob5) 0.84600, tacc(ob6) 0.97800, tacc(ob7) 0.86600, sae_loss 0.46438, 9.90 secs\n",
      "\u001b[1m---- Epoch 49/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60615, triplet_loss 0.48509, sae_loss 0.72720, 85.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.97100, tacc(ob0) 0.99800, tacc(ob1) 0.98500, tacc(ob2) 0.96700, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.84600, tacc(ob6) 0.97900, tacc(ob7) 0.86600, sae_loss 0.46283, 10.06 secs\n",
      "\u001b[1m---- Epoch 50/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60698, triplet_loss 0.48643, sae_loss 0.72752, 85.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.97000, tacc(ob0) 0.99800, tacc(ob1) 0.98600, tacc(ob2) 0.96500, tacc(ob3) 0.98900, tacc(ob4) 0.99200, tacc(ob5) 0.85100, tacc(ob6) 0.97900, tacc(ob7) 0.86700, sae_loss 0.46242, 10.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_50_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8953.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 51/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.61102, triplet_loss 0.48546, sae_loss 0.73658, 85.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.97000, tacc(ob0) 0.99800, tacc(ob1) 0.98700, tacc(ob2) 0.96800, tacc(ob3) 0.98900, tacc(ob4) 0.99200, tacc(ob5) 0.84800, tacc(ob6) 0.98000, tacc(ob7) 0.86800, sae_loss 0.46155, 10.02 secs\n",
      "\u001b[1m---- Epoch 52/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.60608, triplet_loss 0.48619, sae_loss 0.72598, 83.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.97000, tacc(ob0) 0.99800, tacc(ob1) 0.98600, tacc(ob2) 0.96700, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.84800, tacc(ob6) 0.98000, tacc(ob7) 0.86800, sae_loss 0.46123, 10.04 secs\n",
      "\u001b[1m---- Epoch 53/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61728, triplet_loss 0.48543, sae_loss 0.74913, 86.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95100, tacc(al2) 0.97200, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96700, tacc(ob3) 0.98700, tacc(ob4) 0.98700, tacc(ob5) 0.83800, tacc(ob6) 0.97900, tacc(ob7) 0.85900, sae_loss 0.49617, 9.84 secs\n",
      "\u001b[1m---- Epoch 54/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.62188, triplet_loss 0.48430, sae_loss 0.75946, 85.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95300, tacc(al2) 0.96700, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.96800, tacc(ob3) 0.99100, tacc(ob4) 0.99000, tacc(ob5) 0.84300, tacc(ob6) 0.97500, tacc(ob7) 0.86600, sae_loss 0.46831, 10.14 secs\n",
      "\u001b[1m---- Epoch 55/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60526, triplet_loss 0.48196, sae_loss 0.72856, 86.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95300, tacc(al2) 0.96900, tacc(ob0) 0.99700, tacc(ob1) 0.97900, tacc(ob2) 0.96800, tacc(ob3) 0.99200, tacc(ob4) 0.98700, tacc(ob5) 0.84900, tacc(ob6) 0.97700, tacc(ob7) 0.86900, sae_loss 0.46519, 9.86 secs\n",
      "\u001b[1m---- Epoch 56/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.60649, triplet_loss 0.48135, sae_loss 0.73163, 85.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95400, tacc(al2) 0.96900, tacc(ob0) 0.99700, tacc(ob1) 0.98000, tacc(ob2) 0.96700, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.84800, tacc(ob6) 0.97900, tacc(ob7) 0.87000, sae_loss 0.46407, 10.05 secs\n",
      "\u001b[1m---- Epoch 57/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60791, triplet_loss 0.48284, sae_loss 0.73297, 85.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95400, tacc(al2) 0.96800, tacc(ob0) 0.99700, tacc(ob1) 0.98000, tacc(ob2) 0.96900, tacc(ob3) 0.99100, tacc(ob4) 0.98800, tacc(ob5) 0.85100, tacc(ob6) 0.97700, tacc(ob7) 0.87100, sae_loss 0.46156, 9.99 secs\n",
      "\u001b[1m---- Epoch 58/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60523, triplet_loss 0.48160, sae_loss 0.72886, 85.87 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96800, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.96700, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.85100, tacc(ob6) 0.97900, tacc(ob7) 0.87200, sae_loss 0.46093, 9.99 secs\n",
      "\u001b[1m---- Epoch 59/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.60801, triplet_loss 0.48144, sae_loss 0.73457, 84.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96900, tacc(ob0) 0.99700, tacc(ob1) 0.98200, tacc(ob2) 0.96700, tacc(ob3) 0.99200, tacc(ob4) 0.98800, tacc(ob5) 0.85200, tacc(ob6) 0.97900, tacc(ob7) 0.87100, sae_loss 0.46056, 9.91 secs\n",
      "\u001b[1m---- Epoch 60/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59928, triplet_loss 0.48090, sae_loss 0.71767, 84.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.96900, tacc(ob0) 0.99700, tacc(ob1) 0.98100, tacc(ob2) 0.96700, tacc(ob3) 0.99100, tacc(ob4) 0.98800, tacc(ob5) 0.85300, tacc(ob6) 0.97900, tacc(ob7) 0.87300, sae_loss 0.46058, 10.13 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_60_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8959.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 61/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61545, triplet_loss 0.48401, sae_loss 0.74689, 85.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95200, tacc(al2) 0.96500, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.96600, tacc(ob3) 0.98700, tacc(ob4) 0.99100, tacc(ob5) 0.85200, tacc(ob6) 0.98000, tacc(ob7) 0.87900, sae_loss 0.48496, 9.96 secs\n",
      "\u001b[1m---- Epoch 62/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.61312, triplet_loss 0.48366, sae_loss 0.74259, 85.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95400, tacc(al2) 0.96700, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96800, tacc(ob3) 0.99000, tacc(ob4) 0.99200, tacc(ob5) 0.85800, tacc(ob6) 0.98200, tacc(ob7) 0.87700, sae_loss 0.46585, 10.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_62_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8968.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 63/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60915, triplet_loss 0.48284, sae_loss 0.73545, 85.03 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.96800, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96700, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.85300, tacc(ob6) 0.98200, tacc(ob7) 0.87600, sae_loss 0.46437, 10.02 secs\n",
      "\u001b[1m---- Epoch 64/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.60816, triplet_loss 0.48405, sae_loss 0.73228, 85.81 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.96900, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96600, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.85100, tacc(ob6) 0.97900, tacc(ob7) 0.87900, sae_loss 0.46245, 9.85 secs\n",
      "\u001b[1m---- Epoch 65/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60724, triplet_loss 0.48174, sae_loss 0.73274, 85.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96800, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96800, tacc(ob3) 0.99000, tacc(ob4) 0.99000, tacc(ob5) 0.85100, tacc(ob6) 0.98000, tacc(ob7) 0.88000, sae_loss 0.46075, 10.02 secs\n",
      "\u001b[1m---- Epoch 66/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60322, triplet_loss 0.48233, sae_loss 0.72412, 85.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96700, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96800, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.84700, tacc(ob6) 0.98200, tacc(ob7) 0.87700, sae_loss 0.46007, 9.96 secs\n",
      "\u001b[1m---- Epoch 67/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.60337, triplet_loss 0.48167, sae_loss 0.72506, 85.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.96600, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96900, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.85000, tacc(ob6) 0.98100, tacc(ob7) 0.87700, sae_loss 0.45985, 9.91 secs\n",
      "\u001b[1m---- Epoch 68/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.60166, triplet_loss 0.47922, sae_loss 0.72410, 85.31 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.96800, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96800, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.84800, tacc(ob6) 0.98000, tacc(ob7) 0.87800, sae_loss 0.45937, 9.93 secs\n",
      "\u001b[1m---- Epoch 69/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61716, triplet_loss 0.48093, sae_loss 0.75339, 84.00 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95500, tacc(al2) 0.96400, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96900, tacc(ob3) 0.98800, tacc(ob4) 0.98700, tacc(ob5) 0.85000, tacc(ob6) 0.97800, tacc(ob7) 0.87600, sae_loss 0.50721, 9.99 secs\n",
      "\u001b[1m---- Epoch 70/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.61463, triplet_loss 0.48015, sae_loss 0.74911, 84.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96300, tacc(ob0) 0.99700, tacc(ob1) 0.98300, tacc(ob2) 0.96900, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.84700, tacc(ob6) 0.98000, tacc(ob7) 0.87700, sae_loss 0.46977, 10.05 secs\n",
      "\u001b[1m---- Epoch 71/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60833, triplet_loss 0.48203, sae_loss 0.73462, 85.34 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96700, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.85600, tacc(ob6) 0.98000, tacc(ob7) 0.89000, sae_loss 0.46148, 9.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_71_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8978.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 72/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.60593, triplet_loss 0.47671, sae_loss 0.73515, 85.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96800, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.85500, tacc(ob6) 0.98300, tacc(ob7) 0.88800, sae_loss 0.46122, 10.02 secs\n",
      "\u001b[1m---- Epoch 73/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60703, triplet_loss 0.48015, sae_loss 0.73391, 85.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95800, tacc(al2) 0.96200, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96700, tacc(ob3) 0.99200, tacc(ob4) 0.98700, tacc(ob5) 0.85600, tacc(ob6) 0.98200, tacc(ob7) 0.88800, sae_loss 0.45970, 10.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_73_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8980.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 74/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60134, triplet_loss 0.47828, sae_loss 0.72440, 85.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95900, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96600, tacc(ob3) 0.99100, tacc(ob4) 0.98700, tacc(ob5) 0.86000, tacc(ob6) 0.98400, tacc(ob7) 0.88800, sae_loss 0.45921, 9.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_74_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8989.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 75/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59787, triplet_loss 0.47814, sae_loss 0.71760, 85.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96500, tacc(ob3) 0.99100, tacc(ob4) 0.98700, tacc(ob5) 0.85800, tacc(ob6) 0.98300, tacc(ob7) 0.89000, sae_loss 0.45893, 10.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_75_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8989.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 76/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.60313, triplet_loss 0.47878, sae_loss 0.72747, 85.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96500, tacc(ob3) 0.99000, tacc(ob4) 0.98700, tacc(ob5) 0.85600, tacc(ob6) 0.98200, tacc(ob7) 0.88900, sae_loss 0.45861, 10.02 secs\n",
      "\u001b[1m---- Epoch 77/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61405, triplet_loss 0.48093, sae_loss 0.74718, 85.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.96100, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96300, tacc(ob3) 0.98900, tacc(ob4) 0.99000, tacc(ob5) 0.85400, tacc(ob6) 0.97900, tacc(ob7) 0.88700, sae_loss 0.48189, 10.08 secs\n",
      "\u001b[1m---- Epoch 78/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.61115, triplet_loss 0.48001, sae_loss 0.74228, 84.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95800, tacc(al2) 0.96400, tacc(ob0) 0.99500, tacc(ob1) 0.98700, tacc(ob2) 0.96300, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.85800, tacc(ob6) 0.97900, tacc(ob7) 0.88600, sae_loss 0.46360, 9.88 secs\n",
      "\u001b[1m---- Epoch 79/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60147, triplet_loss 0.47779, sae_loss 0.72514, 85.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96500, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85700, tacc(ob6) 0.98100, tacc(ob7) 0.88500, sae_loss 0.46160, 10.13 secs\n",
      "\u001b[1m---- Epoch 80/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.60476, triplet_loss 0.47869, sae_loss 0.73084, 85.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96400, tacc(ob3) 0.99000, tacc(ob4) 0.98800, tacc(ob5) 0.85400, tacc(ob6) 0.97900, tacc(ob7) 0.88900, sae_loss 0.45884, 10.05 secs\n",
      "\u001b[1m---- Epoch 81/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60071, triplet_loss 0.47716, sae_loss 0.72425, 84.84 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95900, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96400, tacc(ob3) 0.99000, tacc(ob4) 0.99000, tacc(ob5) 0.85100, tacc(ob6) 0.98000, tacc(ob7) 0.88500, sae_loss 0.45891, 10.10 secs\n",
      "\u001b[1m---- Epoch 82/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.60221, triplet_loss 0.47843, sae_loss 0.72599, 85.11 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95800, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85300, tacc(ob6) 0.98000, tacc(ob7) 0.89100, sae_loss 0.45844, 10.00 secs\n",
      "\u001b[1m---- Epoch 83/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.60674, triplet_loss 0.47905, sae_loss 0.73444, 85.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95800, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96300, tacc(ob3) 0.99000, tacc(ob4) 0.99000, tacc(ob5) 0.85100, tacc(ob6) 0.98000, tacc(ob7) 0.88600, sae_loss 0.45832, 10.13 secs\n",
      "\u001b[1m---- Epoch 84/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.60050, triplet_loss 0.47845, sae_loss 0.72255, 85.54 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95900, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85200, tacc(ob6) 0.98000, tacc(ob7) 0.88600, sae_loss 0.45758, 10.08 secs\n",
      "\u001b[1m---- Epoch 85/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60980, triplet_loss 0.47721, sae_loss 0.74238, 85.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.96600, tacc(ob0) 0.99500, tacc(ob1) 0.98900, tacc(ob2) 0.96300, tacc(ob3) 0.99000, tacc(ob4) 0.98600, tacc(ob5) 0.85000, tacc(ob6) 0.98400, tacc(ob7) 0.89000, sae_loss 0.48543, 9.99 secs\n",
      "\u001b[1m---- Epoch 86/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.60181, triplet_loss 0.47930, sae_loss 0.72432, 85.36 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.96300, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96000, tacc(ob3) 0.99100, tacc(ob4) 0.98800, tacc(ob5) 0.85100, tacc(ob6) 0.98200, tacc(ob7) 0.89600, sae_loss 0.46436, 10.12 secs\n",
      "\u001b[1m---- Epoch 87/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60322, triplet_loss 0.47708, sae_loss 0.72937, 86.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95600, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96300, tacc(ob3) 0.99000, tacc(ob4) 0.99000, tacc(ob5) 0.85500, tacc(ob6) 0.98200, tacc(ob7) 0.89000, sae_loss 0.46013, 9.95 secs\n",
      "\u001b[1m---- Epoch 88/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.60576, triplet_loss 0.47816, sae_loss 0.73336, 85.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96200, tacc(ob3) 0.99200, tacc(ob4) 0.98800, tacc(ob5) 0.86200, tacc(ob6) 0.98300, tacc(ob7) 0.89400, sae_loss 0.45788, 10.11 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_88_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8991.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 89/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60226, triplet_loss 0.47654, sae_loss 0.72799, 85.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96100, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96000, tacc(ob3) 0.99200, tacc(ob4) 0.98900, tacc(ob5) 0.85700, tacc(ob6) 0.98200, tacc(ob7) 0.89200, sae_loss 0.45742, 9.81 secs\n",
      "\u001b[1m---- Epoch 90/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59933, triplet_loss 0.47640, sae_loss 0.72227, 85.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.96300, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96200, tacc(ob3) 0.99200, tacc(ob4) 0.98900, tacc(ob5) 0.86000, tacc(ob6) 0.98200, tacc(ob7) 0.89500, sae_loss 0.45729, 10.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_90_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 91/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59907, triplet_loss 0.47742, sae_loss 0.72072, 84.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95900, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96200, tacc(ob3) 0.99200, tacc(ob4) 0.98800, tacc(ob5) 0.86000, tacc(ob6) 0.98200, tacc(ob7) 0.89500, sae_loss 0.45641, 10.00 secs\n",
      "\u001b[1m---- Epoch 92/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59659, triplet_loss 0.47795, sae_loss 0.71524, 84.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.96000, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96100, tacc(ob3) 0.99200, tacc(ob4) 0.98800, tacc(ob5) 0.85900, tacc(ob6) 0.98200, tacc(ob7) 0.89500, sae_loss 0.45635, 9.99 secs\n",
      "\u001b[1m---- Epoch 93/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61524, triplet_loss 0.47681, sae_loss 0.75367, 86.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96400, tacc(al2) 0.96500, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96100, tacc(ob3) 0.98800, tacc(ob4) 0.98900, tacc(ob5) 0.84400, tacc(ob6) 0.98100, tacc(ob7) 0.88100, sae_loss 0.47577, 9.86 secs\n",
      "\u001b[1m---- Epoch 94/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.60552, triplet_loss 0.47548, sae_loss 0.73557, 84.72 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.96000, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96400, tacc(ob3) 0.99100, tacc(ob4) 0.98900, tacc(ob5) 0.85000, tacc(ob6) 0.98100, tacc(ob7) 0.89300, sae_loss 0.46233, 9.96 secs\n",
      "\u001b[1m---- Epoch 95/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60586, triplet_loss 0.47451, sae_loss 0.73721, 85.48 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.96100, tacc(ob0) 0.99500, tacc(ob1) 0.98600, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.84700, tacc(ob6) 0.98200, tacc(ob7) 0.89000, sae_loss 0.45964, 9.95 secs\n",
      "\u001b[1m---- Epoch 96/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.60743, triplet_loss 0.47516, sae_loss 0.73971, 86.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95400, tacc(al2) 0.95900, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.96100, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.84700, tacc(ob6) 0.98200, tacc(ob7) 0.89100, sae_loss 0.45753, 10.17 secs\n",
      "\u001b[1m---- Epoch 97/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60453, triplet_loss 0.47445, sae_loss 0.73461, 85.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.96000, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.96100, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.84700, tacc(ob6) 0.98100, tacc(ob7) 0.88900, sae_loss 0.45754, 9.97 secs\n",
      "\u001b[1m---- Epoch 98/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59135, triplet_loss 0.47520, sae_loss 0.70750, 85.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96000, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96100, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85200, tacc(ob6) 0.98300, tacc(ob7) 0.88900, sae_loss 0.45524, 10.04 secs\n",
      "\u001b[1m---- Epoch 99/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59782, triplet_loss 0.47524, sae_loss 0.72041, 85.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96000, tacc(al2) 0.95800, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85500, tacc(ob6) 0.98200, tacc(ob7) 0.89000, sae_loss 0.45562, 10.04 secs\n",
      "\u001b[1m---- Epoch 100/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59861, triplet_loss 0.47527, sae_loss 0.72195, 84.86 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95900, tacc(al2) 0.95800, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85300, tacc(ob6) 0.98200, tacc(ob7) 0.89100, sae_loss 0.45501, 10.12 secs\n",
      "\u001b[1m---- Epoch 101/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60648, triplet_loss 0.47583, sae_loss 0.73713, 85.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95300, tacc(al2) 0.96200, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.96600, tacc(ob3) 0.99100, tacc(ob4) 0.99200, tacc(ob5) 0.84200, tacc(ob6) 0.98300, tacc(ob7) 0.89100, sae_loss 0.48229, 10.00 secs\n",
      "\u001b[1m---- Epoch 102/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59582, triplet_loss 0.47516, sae_loss 0.71648, 82.97 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96000, tacc(al2) 0.96300, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.99000, tacc(ob5) 0.85100, tacc(ob6) 0.98400, tacc(ob7) 0.89900, sae_loss 0.46008, 9.96 secs\n",
      "\u001b[1m---- Epoch 103/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59413, triplet_loss 0.47579, sae_loss 0.71246, 84.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95500, tacc(al2) 0.96200, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.96400, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.85000, tacc(ob6) 0.98300, tacc(ob7) 0.89700, sae_loss 0.45814, 10.02 secs\n",
      "\u001b[1m---- Epoch 104/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59924, triplet_loss 0.47605, sae_loss 0.72243, 85.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95600, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96400, tacc(ob3) 0.98900, tacc(ob4) 0.99000, tacc(ob5) 0.85000, tacc(ob6) 0.98300, tacc(ob7) 0.89700, sae_loss 0.45645, 10.03 secs\n",
      "\u001b[1m---- Epoch 105/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.59672, triplet_loss 0.47260, sae_loss 0.72085, 86.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96200, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96500, tacc(ob3) 0.98800, tacc(ob4) 0.99200, tacc(ob5) 0.85600, tacc(ob6) 0.98300, tacc(ob7) 0.89900, sae_loss 0.45583, 9.88 secs\n",
      "\u001b[1m---- Epoch 106/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59823, triplet_loss 0.47514, sae_loss 0.72132, 84.47 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96300, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96500, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85500, tacc(ob6) 0.98400, tacc(ob7) 0.89900, sae_loss 0.45473, 10.12 secs\n",
      "\u001b[1m---- Epoch 107/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59503, triplet_loss 0.47462, sae_loss 0.71544, 85.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96200, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96300, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85300, tacc(ob6) 0.98400, tacc(ob7) 0.89800, sae_loss 0.45419, 9.99 secs\n",
      "\u001b[1m---- Epoch 108/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59316, triplet_loss 0.47388, sae_loss 0.71243, 85.43 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96300, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85300, tacc(ob6) 0.98400, tacc(ob7) 0.89700, sae_loss 0.45413, 9.97 secs\n",
      "\u001b[1m---- Epoch 109/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.61152, triplet_loss 0.47640, sae_loss 0.74664, 85.61 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.96300, tacc(ob3) 0.98600, tacc(ob4) 0.98600, tacc(ob5) 0.85300, tacc(ob6) 0.98300, tacc(ob7) 0.89300, sae_loss 0.47482, 10.07 secs\n",
      "\u001b[1m---- Epoch 110/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.60299, triplet_loss 0.47516, sae_loss 0.73081, 85.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95800, tacc(al2) 0.96200, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.96600, tacc(ob3) 0.98800, tacc(ob4) 0.98600, tacc(ob5) 0.85500, tacc(ob6) 0.98500, tacc(ob7) 0.89600, sae_loss 0.45929, 9.98 secs\n",
      "\u001b[1m---- Epoch 111/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59671, triplet_loss 0.47385, sae_loss 0.71957, 85.50 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.96100, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.96500, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85000, tacc(ob6) 0.98200, tacc(ob7) 0.89700, sae_loss 0.45664, 9.95 secs\n",
      "\u001b[1m---- Epoch 112/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59667, triplet_loss 0.47398, sae_loss 0.71936, 85.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.95900, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.96600, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85300, tacc(ob6) 0.98200, tacc(ob7) 0.89700, sae_loss 0.45499, 10.10 secs\n",
      "\u001b[1m---- Epoch 113/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.59826, triplet_loss 0.47199, sae_loss 0.72453, 85.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.95800, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96600, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85100, tacc(ob6) 0.98300, tacc(ob7) 0.90000, sae_loss 0.45365, 10.04 secs\n",
      "\u001b[1m---- Epoch 114/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59186, triplet_loss 0.47248, sae_loss 0.71124, 83.96 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95300, tacc(al2) 0.95600, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96600, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.84800, tacc(ob6) 0.98400, tacc(ob7) 0.89600, sae_loss 0.45360, 10.11 secs\n",
      "\u001b[1m---- Epoch 115/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59677, triplet_loss 0.47159, sae_loss 0.72195, 82.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.95700, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96600, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.85000, tacc(ob6) 0.98400, tacc(ob7) 0.89700, sae_loss 0.45264, 9.90 secs\n",
      "\u001b[1m---- Epoch 116/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59723, triplet_loss 0.47469, sae_loss 0.71977, 85.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95600, tacc(al2) 0.95600, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96700, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.85100, tacc(ob6) 0.98400, tacc(ob7) 0.89600, sae_loss 0.45262, 10.06 secs\n",
      "\u001b[1m---- Epoch 117/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60987, triplet_loss 0.47466, sae_loss 0.74508, 84.82 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.96300, tacc(al2) 0.95500, tacc(ob0) 0.99500, tacc(ob1) 0.98600, tacc(ob2) 0.96400, tacc(ob3) 0.98700, tacc(ob4) 0.98600, tacc(ob5) 0.85400, tacc(ob6) 0.98300, tacc(ob7) 0.89800, sae_loss 0.48762, 9.99 secs\n",
      "\u001b[1m---- Epoch 118/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.60026, triplet_loss 0.47276, sae_loss 0.72777, 84.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.95400, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96500, tacc(ob3) 0.98900, tacc(ob4) 0.99000, tacc(ob5) 0.85500, tacc(ob6) 0.98000, tacc(ob7) 0.89400, sae_loss 0.45990, 10.04 secs\n",
      "\u001b[1m---- Epoch 119/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.60572, triplet_loss 0.47280, sae_loss 0.73864, 84.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95900, tacc(al2) 0.95500, tacc(ob0) 0.99500, tacc(ob1) 0.98200, tacc(ob2) 0.96700, tacc(ob3) 0.99100, tacc(ob4) 0.98800, tacc(ob5) 0.85700, tacc(ob6) 0.98100, tacc(ob7) 0.90200, sae_loss 0.45743, 9.89 secs\n",
      "\u001b[1m---- Epoch 120/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59365, triplet_loss 0.47447, sae_loss 0.71282, 84.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95600, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96400, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85900, tacc(ob6) 0.98000, tacc(ob7) 0.89900, sae_loss 0.45469, 10.05 secs\n",
      "\u001b[1m---- Epoch 121/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.59473, triplet_loss 0.47470, sae_loss 0.71475, 84.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96200, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85600, tacc(ob6) 0.98100, tacc(ob7) 0.90100, sae_loss 0.45400, 10.08 secs\n",
      "\u001b[1m---- Epoch 122/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59627, triplet_loss 0.47278, sae_loss 0.71975, 85.40 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95600, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96300, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85800, tacc(ob6) 0.98100, tacc(ob7) 0.90100, sae_loss 0.45260, 9.99 secs\n",
      "\u001b[1m---- Epoch 123/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59309, triplet_loss 0.47183, sae_loss 0.71435, 84.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96400, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85800, tacc(ob6) 0.98200, tacc(ob7) 0.90200, sae_loss 0.45211, 9.95 secs\n",
      "\u001b[1m---- Epoch 124/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59194, triplet_loss 0.47210, sae_loss 0.71177, 85.80 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95800, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96400, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85900, tacc(ob6) 0.98100, tacc(ob7) 0.89900, sae_loss 0.45143, 10.01 secs\n",
      "\u001b[1m---- Epoch 125/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60339, triplet_loss 0.47431, sae_loss 0.73248, 84.67 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95300, tacc(al2) 0.96400, tacc(ob0) 0.99500, tacc(ob1) 0.98300, tacc(ob2) 0.96300, tacc(ob3) 0.98800, tacc(ob4) 0.99200, tacc(ob5) 0.85800, tacc(ob6) 0.98400, tacc(ob7) 0.90100, sae_loss 0.47097, 9.95 secs\n",
      "\u001b[1m---- Epoch 126/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.60132, triplet_loss 0.47308, sae_loss 0.72956, 85.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95300, tacc(al2) 0.95800, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.97000, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.85900, tacc(ob6) 0.98400, tacc(ob7) 0.89800, sae_loss 0.45740, 10.00 secs\n",
      "\u001b[1m---- Epoch 127/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59482, triplet_loss 0.47131, sae_loss 0.71832, 85.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95600, tacc(al2) 0.95800, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96500, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85600, tacc(ob6) 0.98100, tacc(ob7) 0.90000, sae_loss 0.45492, 10.22 secs\n",
      "\u001b[1m---- Epoch 128/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59657, triplet_loss 0.47060, sae_loss 0.72253, 84.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95600, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96700, tacc(ob3) 0.98900, tacc(ob4) 0.99200, tacc(ob5) 0.85900, tacc(ob6) 0.98200, tacc(ob7) 0.90000, sae_loss 0.45138, 9.95 secs\n",
      "\u001b[1m---- Epoch 129/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.59615, triplet_loss 0.47239, sae_loss 0.71992, 86.22 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95500, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96700, tacc(ob3) 0.98900, tacc(ob4) 0.99200, tacc(ob5) 0.85800, tacc(ob6) 0.98100, tacc(ob7) 0.89800, sae_loss 0.45155, 9.96 secs\n",
      "\u001b[1m---- Epoch 130/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59726, triplet_loss 0.47086, sae_loss 0.72366, 85.24 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95300, tacc(al2) 0.95600, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96800, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.85600, tacc(ob6) 0.98000, tacc(ob7) 0.89800, sae_loss 0.45022, 10.10 secs\n",
      "\u001b[1m---- Epoch 131/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59219, triplet_loss 0.47043, sae_loss 0.71394, 85.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95200, tacc(al2) 0.95800, tacc(ob0) 0.99700, tacc(ob1) 0.98700, tacc(ob2) 0.96700, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85700, tacc(ob6) 0.98300, tacc(ob7) 0.89900, sae_loss 0.45010, 9.98 secs\n",
      "\u001b[1m---- Epoch 132/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59119, triplet_loss 0.46928, sae_loss 0.71310, 84.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95300, tacc(al2) 0.95800, tacc(ob0) 0.99700, tacc(ob1) 0.98700, tacc(ob2) 0.96700, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.85500, tacc(ob6) 0.98000, tacc(ob7) 0.90000, sae_loss 0.45019, 9.88 secs\n",
      "\u001b[1m---- Epoch 133/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60906, triplet_loss 0.47337, sae_loss 0.74474, 85.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95900, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.96100, tacc(ob3) 0.98400, tacc(ob4) 0.98900, tacc(ob5) 0.85500, tacc(ob6) 0.98100, tacc(ob7) 0.90000, sae_loss 0.47445, 10.07 secs\n",
      "\u001b[1m---- Epoch 134/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59840, triplet_loss 0.46992, sae_loss 0.72687, 85.28 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96400, tacc(ob3) 0.98900, tacc(ob4) 0.99200, tacc(ob5) 0.85800, tacc(ob6) 0.98000, tacc(ob7) 0.89800, sae_loss 0.45690, 10.13 secs\n",
      "\u001b[1m---- Epoch 135/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59397, triplet_loss 0.47227, sae_loss 0.71567, 85.10 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.96000, tacc(ob3) 0.98800, tacc(ob4) 0.98900, tacc(ob5) 0.85600, tacc(ob6) 0.98000, tacc(ob7) 0.90600, sae_loss 0.45382, 10.01 secs\n",
      "\u001b[1m---- Epoch 136/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59111, triplet_loss 0.47147, sae_loss 0.71075, 85.35 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99500, tacc(al1) 0.95600, tacc(al2) 0.96100, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96300, tacc(ob3) 0.98600, tacc(ob4) 0.99100, tacc(ob5) 0.86000, tacc(ob6) 0.98100, tacc(ob7) 0.90400, sae_loss 0.45158, 9.91 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_136_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9007.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 137/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.60105, triplet_loss 0.47199, sae_loss 0.73010, 84.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95700, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.96300, tacc(ob3) 0.98600, tacc(ob4) 0.99000, tacc(ob5) 0.85900, tacc(ob6) 0.98200, tacc(ob7) 0.90300, sae_loss 0.45001, 9.98 secs\n",
      "\u001b[1m---- Epoch 138/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59379, triplet_loss 0.47109, sae_loss 0.71649, 86.05 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99500, tacc(al1) 0.95700, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.96200, tacc(ob3) 0.98600, tacc(ob4) 0.99100, tacc(ob5) 0.86100, tacc(ob6) 0.98300, tacc(ob7) 0.90400, sae_loss 0.44944, 9.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_138_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9010.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 139/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59414, triplet_loss 0.47176, sae_loss 0.71651, 84.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99500, tacc(al1) 0.95600, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.99000, tacc(ob2) 0.96200, tacc(ob3) 0.98600, tacc(ob4) 0.99000, tacc(ob5) 0.86000, tacc(ob6) 0.98200, tacc(ob7) 0.90400, sae_loss 0.44863, 9.98 secs\n",
      "\u001b[1m---- Epoch 140/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59354, triplet_loss 0.47124, sae_loss 0.71584, 85.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99500, tacc(al1) 0.95700, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.99000, tacc(ob2) 0.96300, tacc(ob3) 0.98600, tacc(ob4) 0.99000, tacc(ob5) 0.85900, tacc(ob6) 0.98100, tacc(ob7) 0.90400, sae_loss 0.44899, 10.04 secs\n",
      "\u001b[1m---- Epoch 141/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60266, triplet_loss 0.47130, sae_loss 0.73403, 85.70 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95200, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.96300, tacc(ob3) 0.99100, tacc(ob4) 0.99000, tacc(ob5) 0.85300, tacc(ob6) 0.97800, tacc(ob7) 0.90500, sae_loss 0.47469, 10.03 secs\n",
      "\u001b[1m---- Epoch 142/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59479, triplet_loss 0.47133, sae_loss 0.71826, 85.77 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95800, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95900, tacc(ob3) 0.99000, tacc(ob4) 0.99200, tacc(ob5) 0.85000, tacc(ob6) 0.98100, tacc(ob7) 0.90700, sae_loss 0.45557, 9.93 secs\n",
      "\u001b[1m---- Epoch 143/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59091, triplet_loss 0.46924, sae_loss 0.71257, 84.07 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.95800, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95800, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85100, tacc(ob6) 0.98200, tacc(ob7) 0.90800, sae_loss 0.45359, 10.02 secs\n",
      "\u001b[1m---- Epoch 144/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59075, triplet_loss 0.47031, sae_loss 0.71119, 84.78 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95600, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96100, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.85000, tacc(ob6) 0.97800, tacc(ob7) 0.90500, sae_loss 0.45075, 10.05 secs\n",
      "\u001b[1m---- Epoch 145/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.58892, triplet_loss 0.47021, sae_loss 0.70764, 85.15 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96000, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85400, tacc(ob6) 0.98000, tacc(ob7) 0.90800, sae_loss 0.44938, 9.97 secs\n",
      "\u001b[1m---- Epoch 146/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59602, triplet_loss 0.46925, sae_loss 0.72280, 85.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95800, tacc(ob3) 0.98800, tacc(ob4) 0.99100, tacc(ob5) 0.85300, tacc(ob6) 0.98200, tacc(ob7) 0.90800, sae_loss 0.44863, 10.01 secs\n",
      "\u001b[1m---- Epoch 147/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59444, triplet_loss 0.46924, sae_loss 0.71965, 84.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95700, tacc(al2) 0.96000, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.95800, tacc(ob3) 0.98800, tacc(ob4) 0.99200, tacc(ob5) 0.85400, tacc(ob6) 0.98200, tacc(ob7) 0.90900, sae_loss 0.44816, 9.90 secs\n",
      "\u001b[1m---- Epoch 148/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.59145, triplet_loss 0.47119, sae_loss 0.71172, 85.58 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95800, tacc(al2) 0.96000, tacc(ob0) 0.99700, tacc(ob1) 0.98400, tacc(ob2) 0.95700, tacc(ob3) 0.98800, tacc(ob4) 0.99200, tacc(ob5) 0.85400, tacc(ob6) 0.98200, tacc(ob7) 0.90900, sae_loss 0.44810, 10.15 secs\n",
      "\u001b[1m---- Epoch 149/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60299, triplet_loss 0.47167, sae_loss 0.73432, 85.13 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tacc(al0) 0.99500, tacc(al1) 0.95800, tacc(al2) 0.95600, tacc(ob0) 0.99600, tacc(ob1) 0.98100, tacc(ob2) 0.96100, tacc(ob3) 0.98700, tacc(ob4) 0.98800, tacc(ob5) 0.84900, tacc(ob6) 0.98000, tacc(ob7) 0.89600, sae_loss 0.47133, 10.02 secs\n",
      "\u001b[1m---- Epoch 150/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59179, triplet_loss 0.47046, sae_loss 0.71313, 84.08 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95900, tacc(al2) 0.95400, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95900, tacc(ob3) 0.99000, tacc(ob4) 0.98900, tacc(ob5) 0.85000, tacc(ob6) 0.98000, tacc(ob7) 0.90600, sae_loss 0.45318, 10.02 secs\n",
      "\u001b[1m---- Epoch 151/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59372, triplet_loss 0.46692, sae_loss 0.72052, 85.24 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95500, tacc(al2) 0.95300, tacc(ob0) 0.99600, tacc(ob1) 0.98100, tacc(ob2) 0.96100, tacc(ob3) 0.98800, tacc(ob4) 0.98800, tacc(ob5) 0.84600, tacc(ob6) 0.97900, tacc(ob7) 0.91100, sae_loss 0.45098, 10.04 secs\n",
      "\u001b[1m---- Epoch 152/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59086, triplet_loss 0.46822, sae_loss 0.71351, 85.21 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.96200, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85400, tacc(ob6) 0.98100, tacc(ob7) 0.90900, sae_loss 0.44942, 10.07 secs\n",
      "\u001b[1m---- Epoch 153/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.59319, triplet_loss 0.46604, sae_loss 0.72033, 85.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96100, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.85300, tacc(ob6) 0.98000, tacc(ob7) 0.91100, sae_loss 0.44792, 10.06 secs\n",
      "\u001b[1m---- Epoch 154/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59184, triplet_loss 0.47070, sae_loss 0.71298, 85.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.95600, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96100, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.85400, tacc(ob6) 0.98200, tacc(ob7) 0.91100, sae_loss 0.44687, 10.02 secs\n",
      "\u001b[1m---- Epoch 155/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59122, triplet_loss 0.46874, sae_loss 0.71370, 86.44 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95600, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.96300, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.85000, tacc(ob6) 0.98100, tacc(ob7) 0.91000, sae_loss 0.44730, 10.12 secs\n",
      "\u001b[1m---- Epoch 156/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58779, triplet_loss 0.47016, sae_loss 0.70541, 86.12 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.95900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96200, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.85200, tacc(ob6) 0.98100, tacc(ob7) 0.90900, sae_loss 0.44652, 9.91 secs\n",
      "\u001b[1m---- Epoch 157/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60120, triplet_loss 0.46883, sae_loss 0.73358, 86.23 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.95800, tacc(ob3) 0.99000, tacc(ob4) 0.98600, tacc(ob5) 0.84200, tacc(ob6) 0.97900, tacc(ob7) 0.90300, sae_loss 0.46565, 9.85 secs\n",
      "\u001b[1m---- Epoch 158/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59126, triplet_loss 0.47039, sae_loss 0.71212, 84.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95600, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96200, tacc(ob3) 0.98700, tacc(ob4) 0.98900, tacc(ob5) 0.85500, tacc(ob6) 0.98500, tacc(ob7) 0.91000, sae_loss 0.45345, 10.04 secs\n",
      "\u001b[1m---- Epoch 159/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.58787, triplet_loss 0.46991, sae_loss 0.70582, 86.46 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95900, tacc(al2) 0.96000, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.95900, tacc(ob3) 0.98700, tacc(ob4) 0.98800, tacc(ob5) 0.85700, tacc(ob6) 0.98100, tacc(ob7) 0.91100, sae_loss 0.45047, 10.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_159_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9013.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 160/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.59123, triplet_loss 0.46879, sae_loss 0.71366, 86.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95800, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96300, tacc(ob3) 0.98700, tacc(ob4) 0.98700, tacc(ob5) 0.85200, tacc(ob6) 0.98100, tacc(ob7) 0.91100, sae_loss 0.44809, 10.08 secs\n",
      "\u001b[1m---- Epoch 161/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.59208, triplet_loss 0.46792, sae_loss 0.71623, 85.95 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95800, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96200, tacc(ob3) 0.98700, tacc(ob4) 0.98800, tacc(ob5) 0.85500, tacc(ob6) 0.98000, tacc(ob7) 0.91500, sae_loss 0.44645, 10.15 secs\n",
      "\u001b[1m---- Epoch 162/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.59033, triplet_loss 0.46768, sae_loss 0.71298, 88.16 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95800, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96100, tacc(ob3) 0.98700, tacc(ob4) 0.98700, tacc(ob5) 0.85100, tacc(ob6) 0.98200, tacc(ob7) 0.91200, sae_loss 0.44608, 10.08 secs\n",
      "\u001b[1m---- Epoch 163/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.59247, triplet_loss 0.46984, sae_loss 0.71510, 85.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98700, tacc(ob2) 0.96000, tacc(ob3) 0.98700, tacc(ob4) 0.98700, tacc(ob5) 0.85400, tacc(ob6) 0.98300, tacc(ob7) 0.91200, sae_loss 0.44568, 9.91 secs\n",
      "\u001b[1m---- Epoch 164/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58994, triplet_loss 0.46721, sae_loss 0.71267, 85.32 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96100, tacc(ob3) 0.98600, tacc(ob4) 0.98700, tacc(ob5) 0.85500, tacc(ob6) 0.98300, tacc(ob7) 0.91200, sae_loss 0.44531, 9.99 secs\n",
      "\u001b[1m---- Epoch 165/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.59825, triplet_loss 0.47091, sae_loss 0.72559, 85.90 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95700, tacc(ob0) 0.99700, tacc(ob1) 0.98700, tacc(ob2) 0.95800, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85900, tacc(ob6) 0.98300, tacc(ob7) 0.90700, sae_loss 0.47820, 10.00 secs\n",
      "\u001b[1m---- Epoch 166/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59680, triplet_loss 0.47063, sae_loss 0.72298, 84.74 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95700, tacc(al2) 0.96000, tacc(ob0) 0.99700, tacc(ob1) 0.98700, tacc(ob2) 0.96000, tacc(ob3) 0.99100, tacc(ob4) 0.99000, tacc(ob5) 0.86700, tacc(ob6) 0.98700, tacc(ob7) 0.91200, sae_loss 0.45131, 9.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 167/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.58825, triplet_loss 0.46974, sae_loss 0.70676, 86.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96000, tacc(al2) 0.95600, tacc(ob0) 0.99500, tacc(ob1) 0.98400, tacc(ob2) 0.95700, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.85000, tacc(ob6) 0.98300, tacc(ob7) 0.91500, sae_loss 0.44722, 10.12 secs\n",
      "\u001b[1m---- Epoch 168/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.58905, triplet_loss 0.46704, sae_loss 0.71105, 86.68 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95700, tacc(al2) 0.95800, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.95600, tacc(ob3) 0.98900, tacc(ob4) 0.98700, tacc(ob5) 0.85400, tacc(ob6) 0.98500, tacc(ob7) 0.91000, sae_loss 0.44582, 9.96 secs\n",
      "\u001b[1m---- Epoch 169/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.58982, triplet_loss 0.46706, sae_loss 0.71259, 87.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95700, tacc(al2) 0.95600, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95900, tacc(ob3) 0.98800, tacc(ob4) 0.98800, tacc(ob5) 0.85100, tacc(ob6) 0.98400, tacc(ob7) 0.91600, sae_loss 0.44487, 10.15 secs\n",
      "\u001b[1m---- Epoch 170/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.58858, triplet_loss 0.46666, sae_loss 0.71050, 86.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95700, tacc(al2) 0.95600, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.95500, tacc(ob3) 0.98800, tacc(ob4) 0.98700, tacc(ob5) 0.85400, tacc(ob6) 0.98400, tacc(ob7) 0.91600, sae_loss 0.44503, 9.99 secs\n",
      "\u001b[1m---- Epoch 171/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.58785, triplet_loss 0.46848, sae_loss 0.70722, 85.93 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95700, tacc(al2) 0.95700, tacc(ob0) 0.99500, tacc(ob1) 0.98500, tacc(ob2) 0.95800, tacc(ob3) 0.98800, tacc(ob4) 0.98700, tacc(ob5) 0.85500, tacc(ob6) 0.98400, tacc(ob7) 0.91600, sae_loss 0.44399, 10.05 secs\n",
      "\u001b[1m---- Epoch 172/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58797, triplet_loss 0.46813, sae_loss 0.70782, 84.09 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95600, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95600, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.85600, tacc(ob6) 0.98400, tacc(ob7) 0.91600, sae_loss 0.44419, 10.21 secs\n",
      "\u001b[1m---- Epoch 173/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.59699, triplet_loss 0.46779, sae_loss 0.72620, 85.56 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95200, tacc(al2) 0.94900, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.95900, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.85400, tacc(ob6) 0.97900, tacc(ob7) 0.91300, sae_loss 0.46368, 10.07 secs\n",
      "\u001b[1m---- Epoch 174/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59604, triplet_loss 0.46972, sae_loss 0.72236, 83.30 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.95600, tacc(al2) 0.95100, tacc(ob0) 0.99600, tacc(ob1) 0.98900, tacc(ob2) 0.95900, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.85600, tacc(ob6) 0.98000, tacc(ob7) 0.90900, sae_loss 0.44735, 10.24 secs\n",
      "\u001b[1m---- Epoch 175/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.59432, triplet_loss 0.46911, sae_loss 0.71953, 85.01 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.95400, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.95800, tacc(ob3) 0.98800, tacc(ob4) 0.98900, tacc(ob5) 0.85500, tacc(ob6) 0.98300, tacc(ob7) 0.91100, sae_loss 0.44759, 10.16 secs\n",
      "\u001b[1m---- Epoch 176/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.58220, triplet_loss 0.46926, sae_loss 0.69515, 84.83 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95500, tacc(al2) 0.94900, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.95900, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85800, tacc(ob6) 0.98400, tacc(ob7) 0.91500, sae_loss 0.44440, 10.09 secs\n",
      "\u001b[1m---- Epoch 177/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.58481, triplet_loss 0.46560, sae_loss 0.70403, 86.14 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95000, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.95900, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85600, tacc(ob6) 0.98200, tacc(ob7) 0.91600, sae_loss 0.44428, 10.00 secs\n",
      "\u001b[1m---- Epoch 178/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.58843, triplet_loss 0.46773, sae_loss 0.70912, 86.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95500, tacc(al2) 0.95000, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.95900, tacc(ob3) 0.99100, tacc(ob4) 0.99000, tacc(ob5) 0.85900, tacc(ob6) 0.98300, tacc(ob7) 0.91400, sae_loss 0.44347, 10.10 secs\n",
      "\u001b[1m---- Epoch 179/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.58559, triplet_loss 0.46743, sae_loss 0.70375, 84.55 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.95100, tacc(ob0) 0.99600, tacc(ob1) 0.98900, tacc(ob2) 0.95800, tacc(ob3) 0.99000, tacc(ob4) 0.99100, tacc(ob5) 0.86000, tacc(ob6) 0.98200, tacc(ob7) 0.91400, sae_loss 0.44354, 10.11 secs\n",
      "\u001b[1m---- Epoch 180/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58628, triplet_loss 0.46792, sae_loss 0.70464, 86.02 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95700, tacc(al2) 0.95300, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.95900, tacc(ob3) 0.98900, tacc(ob4) 0.99100, tacc(ob5) 0.85800, tacc(ob6) 0.98200, tacc(ob7) 0.91400, sae_loss 0.44318, 10.07 secs\n",
      "\u001b[1m---- Epoch 181/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.59607, triplet_loss 0.46821, sae_loss 0.72393, 89.26 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95100, tacc(ob0) 0.99700, tacc(ob1) 0.98600, tacc(ob2) 0.96200, tacc(ob3) 0.98700, tacc(ob4) 0.98800, tacc(ob5) 0.85700, tacc(ob6) 0.98000, tacc(ob7) 0.91800, sae_loss 0.47112, 10.14 secs\n",
      "\u001b[1m---- Epoch 182/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59408, triplet_loss 0.46849, sae_loss 0.71967, 88.13 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99400, tacc(al1) 0.96100, tacc(al2) 0.95300, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.96500, tacc(ob3) 0.99000, tacc(ob4) 0.98700, tacc(ob5) 0.85700, tacc(ob6) 0.98200, tacc(ob7) 0.91400, sae_loss 0.44630, 9.93 secs\n",
      "\u001b[1m---- Epoch 183/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.58769, triplet_loss 0.46687, sae_loss 0.70850, 85.69 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96200, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.95700, tacc(ob3) 0.98800, tacc(ob4) 0.99000, tacc(ob5) 0.85600, tacc(ob6) 0.98200, tacc(ob7) 0.91500, sae_loss 0.44486, 9.94 secs\n",
      "\u001b[1m---- Epoch 184/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.58351, triplet_loss 0.46497, sae_loss 0.70205, 85.64 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96000, tacc(al2) 0.95400, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95500, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85900, tacc(ob6) 0.98100, tacc(ob7) 0.91400, sae_loss 0.44482, 10.04 secs\n",
      "\u001b[1m---- Epoch 185/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.58442, triplet_loss 0.46716, sae_loss 0.70168, 86.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96100, tacc(al2) 0.95300, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95600, tacc(ob3) 0.98800, tacc(ob4) 0.98900, tacc(ob5) 0.85100, tacc(ob6) 0.98200, tacc(ob7) 0.91400, sae_loss 0.44288, 10.15 secs\n",
      "\u001b[1m---- Epoch 186/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.58375, triplet_loss 0.46543, sae_loss 0.70208, 88.62 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.96000, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98500, tacc(ob2) 0.95300, tacc(ob3) 0.98800, tacc(ob4) 0.98900, tacc(ob5) 0.85400, tacc(ob6) 0.98100, tacc(ob7) 0.91500, sae_loss 0.44266, 10.12 secs\n",
      "\u001b[1m---- Epoch 187/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.58928, triplet_loss 0.46539, sae_loss 0.71318, 89.20 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.96000, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.95300, tacc(ob3) 0.98900, tacc(ob4) 0.98900, tacc(ob5) 0.85500, tacc(ob6) 0.98000, tacc(ob7) 0.91500, sae_loss 0.44238, 10.22 secs\n",
      "\u001b[1m---- Epoch 188/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58381, triplet_loss 0.46586, sae_loss 0.70175, 90.33 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.96000, tacc(al2) 0.95700, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.95400, tacc(ob3) 0.98900, tacc(ob4) 0.99000, tacc(ob5) 0.85600, tacc(ob6) 0.98000, tacc(ob7) 0.91500, sae_loss 0.44182, 10.36 secs\n",
      "\u001b[1m---- Epoch 189/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.60023, triplet_loss 0.46772, sae_loss 0.73273, 98.60 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95300, tacc(al2) 0.95300, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96000, tacc(ob3) 0.98900, tacc(ob4) 0.98800, tacc(ob5) 0.85600, tacc(ob6) 0.98300, tacc(ob7) 0.91400, sae_loss 0.45827, 11.18 secs\n",
      "\u001b[1m---- Epoch 190/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.58766, triplet_loss 0.46756, sae_loss 0.70776, 101.71 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95700, tacc(al2) 0.95000, tacc(ob0) 0.99600, tacc(ob1) 0.98300, tacc(ob2) 0.95800, tacc(ob3) 0.98600, tacc(ob4) 0.98700, tacc(ob5) 0.84600, tacc(ob6) 0.98000, tacc(ob7) 0.92000, sae_loss 0.44787, 11.54 secs\n",
      "\u001b[1m---- Epoch 191/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.58700, triplet_loss 0.46572, sae_loss 0.70827, 102.38 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95800, tacc(al2) 0.95600, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.96000, tacc(ob3) 0.98700, tacc(ob4) 0.98700, tacc(ob5) 0.84700, tacc(ob6) 0.97900, tacc(ob7) 0.91600, sae_loss 0.44450, 11.09 secs\n",
      "\u001b[1m---- Epoch 192/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.58390, triplet_loss 0.46600, sae_loss 0.70181, 101.66 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.96000, tacc(al2) 0.94900, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.95400, tacc(ob3) 0.98600, tacc(ob4) 0.98600, tacc(ob5) 0.84900, tacc(ob6) 0.97900, tacc(ob7) 0.92100, sae_loss 0.44369, 11.00 secs\n",
      "\u001b[1m---- Epoch 193/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.58951, triplet_loss 0.46744, sae_loss 0.71158, 101.37 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95600, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.96000, tacc(ob3) 0.98600, tacc(ob4) 0.98700, tacc(ob5) 0.84900, tacc(ob6) 0.97900, tacc(ob7) 0.91900, sae_loss 0.44197, 11.17 secs\n",
      "\u001b[1m---- Epoch 194/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.57770, triplet_loss 0.46503, sae_loss 0.69037, 101.89 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.95800, tacc(al2) 0.95300, tacc(ob0) 0.99600, tacc(ob1) 0.98700, tacc(ob2) 0.95800, tacc(ob3) 0.98600, tacc(ob4) 0.98700, tacc(ob5) 0.84700, tacc(ob6) 0.97900, tacc(ob7) 0.91900, sae_loss 0.44190, 11.15 secs\n",
      "\u001b[1m---- Epoch 195/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.58675, triplet_loss 0.46449, sae_loss 0.70902, 96.63 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95900, tacc(al2) 0.95100, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.95700, tacc(ob3) 0.98600, tacc(ob4) 0.98600, tacc(ob5) 0.84800, tacc(ob6) 0.97900, tacc(ob7) 0.92000, sae_loss 0.44033, 11.49 secs\n",
      "\u001b[1m---- Epoch 196/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.58319, triplet_loss 0.46474, sae_loss 0.70164, 99.06 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99300, tacc(al1) 0.95900, tacc(al2) 0.95100, tacc(ob0) 0.99600, tacc(ob1) 0.98800, tacc(ob2) 0.95700, tacc(ob3) 0.98700, tacc(ob4) 0.98600, tacc(ob5) 0.85100, tacc(ob6) 0.97900, tacc(ob7) 0.92000, sae_loss 0.44067, 12.47 secs\n",
      "\u001b[1m---- Epoch 197/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.59663, triplet_loss 0.46690, sae_loss 0.72636, 98.73 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.95800, tacc(al2) 0.95400, tacc(ob0) 0.99700, tacc(ob1) 0.98200, tacc(ob2) 0.95800, tacc(ob3) 0.98500, tacc(ob4) 0.98800, tacc(ob5) 0.86100, tacc(ob6) 0.98000, tacc(ob7) 0.91300, sae_loss 0.48029, 10.91 secs\n",
      "\u001b[1m---- Epoch 198/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.59021, triplet_loss 0.46636, sae_loss 0.71406, 103.27 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99100, tacc(al1) 0.96100, tacc(al2) 0.95500, tacc(ob0) 0.99600, tacc(ob1) 0.98600, tacc(ob2) 0.95900, tacc(ob3) 0.98700, tacc(ob4) 0.99000, tacc(ob5) 0.84900, tacc(ob6) 0.98000, tacc(ob7) 0.91200, sae_loss 0.44350, 12.28 secs\n",
      "\u001b[1m---- Epoch 199/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.58364, triplet_loss 0.46279, sae_loss 0.70448, 107.53 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.96100, tacc(al2) 0.94800, tacc(ob0) 0.99700, tacc(ob1) 0.98500, tacc(ob2) 0.95900, tacc(ob3) 0.98700, tacc(ob4) 0.98800, tacc(ob5) 0.84900, tacc(ob6) 0.97700, tacc(ob7) 0.91000, sae_loss 0.44274, 11.98 secs\n",
      "\u001b[1m---- Epoch 200/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.58250, triplet_loss 0.46461, sae_loss 0.70039, 103.39 secs\n",
      "(2) Validation stage ...\n",
      "tacc(al0) 0.99200, tacc(al1) 0.96000, tacc(al2) 0.94800, tacc(ob0) 0.99600, tacc(ob1) 0.98400, tacc(ob2) 0.95500, tacc(ob3) 0.98800, tacc(ob4) 0.98700, tacc(ob5) 0.84400, tacc(ob6) 0.97800, tacc(ob7) 0.91300, sae_loss 0.44134, 11.30 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_fact_embedding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_152451_MIMIC-CXR(autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 800 \\\n",
    "--batch_size 30 \\\n",
    "--val_batch_size 120 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 8 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,9e-5,8,2e-6,9e-5,8,2e-6\" \\\n",
    "--triplets_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000).pkl\" \\\n",
    "--triplet_rule_weights \\\n",
    "\"{'anatomical_locations': [1., 2., 1.], 'observations': [1., 2., 1., 1., 1., 2., 1., 2.]}\" \\\n",
    "--sentences_and_cluster_ids_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/sentence_cluster_ids((2589, 1439222964121874843)).pkl\" \\\n",
    "--triplets_weight 1.0 \\\n",
    "--sentence_autoencoder_weight 1.0 \\\n",
    "--triplet_loss_weight 2.0 \\\n",
    "--dataset_name \"MIMIC-CXR(triplets+autoencoder)\" \\\n",
    "--huggingface_model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--embedding_size 128 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
