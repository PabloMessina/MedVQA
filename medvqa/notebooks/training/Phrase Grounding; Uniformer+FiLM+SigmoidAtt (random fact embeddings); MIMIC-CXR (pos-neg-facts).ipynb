{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648a5f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 100\n",
      "   max_images_per_batch: 12\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 4.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: cxrmate-rrg24-uniformer-huggingface\n",
      "   huggingface_model_name: aehrc/cxrmate-rrg24\n",
      "   num_regions: 144\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 12\n",
      "   regions_height: 12\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp__no_grounding\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 4\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [384, 384]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: False\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: True\n",
      "   use_vinbig_with_modified_labels: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: cxrmate-rrg24-uniformer-huggingface\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [384, 384]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [384, 384]\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 1030\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "\u001b[93m\u001b[1mNOTE: Replacing fact_embeddings with random vectors\u001b[0m\n",
      "\u001b[93mRandom vectors already saved at /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl.random_vectors.pkl\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (936863, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 146472.13it/s]\n",
      "Total number of images: 376105\n",
      "len(train_indices) = 367955\n",
      "len(test_indices) = 8150\n",
      "len(set(train_indices) & set(test_indices)) = 0\n",
      "avg_facts_per_image = 508.2566427959941\n",
      "train_num_facts_per_image = 45\n",
      "avg_facts_per_image = 509.0689570552147\n",
      "test_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 12\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 30663\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 170\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 30663\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 170\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_171539_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_171539_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_171539_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.18763, mimfg_phrcls_loss 2.18763, mimfg_prc_auc 0.05550, 37.83 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.16376, mimfg_prc_auc 0.06729, 113.30 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.3137, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.0555, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 0.3692, den = 2.0000, score = 0.1846\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.3161, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.0673, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 0.3834, den = 2.0000, score = 0.1917\u001b[0m\n",
      "\u001b[93mTrain score = 0.1846, Val score = 0.1917, Final score = 0.1913\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_mimfg_phrcls_loss+mimfg_prc_auc=0.1913.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.18492, mimfg_phrcls_loss 2.18492, mimfg_prc_auc 0.05044, 36.04 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.15305, mimfg_prc_auc 0.06863, 112.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_mimfg_phrcls_loss+mimfg_prc_auc=0.1924.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 2.15630, mimfg_phrcls_loss 2.15630, mimfg_prc_auc 0.05152, 35.94 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.10782, mimfg_prc_auc 0.07466, 112.32 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_mimfg_phrcls_loss+mimfg_prc_auc=0.1975.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.00660, mimfg_phrcls_loss 2.00660, mimfg_prc_auc 0.05425, 36.36 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.87275, mimfg_prc_auc 0.10066, 112.79 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_mimfg_phrcls_loss+mimfg_prc_auc=0.2228.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.89692, mimfg_phrcls_loss 1.89692, mimfg_prc_auc 0.06929, 36.53 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.96056, mimfg_prc_auc 0.12066, 113.18 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_mimfg_phrcls_loss+mimfg_prc_auc=0.2281.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.01177, mimfg_phrcls_loss 2.01177, mimfg_prc_auc 0.09645, 36.20 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.03009, mimfg_prc_auc 0.12744, 113.93 secs\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.04240, mimfg_phrcls_loss 2.04240, mimfg_prc_auc 0.09826, 36.48 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.04645, mimfg_prc_auc 0.12843, 114.75 secs\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.04095, mimfg_phrcls_loss 2.04095, mimfg_prc_auc 0.10037, 37.22 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.04825, mimfg_prc_auc 0.12874, 112.79 secs\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.04401, mimfg_phrcls_loss 2.04401, mimfg_prc_auc 0.10200, 37.09 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.03442, mimfg_prc_auc 0.12975, 115.28 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_mimfg_phrcls_loss+mimfg_prc_auc=0.2289.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.06365, mimfg_phrcls_loss 2.06365, mimfg_prc_auc 0.10038, 37.13 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.98050, mimfg_prc_auc 0.14749, 115.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_mimfg_phrcls_loss+mimfg_prc_auc=0.2401.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.04301, mimfg_phrcls_loss 2.04301, mimfg_prc_auc 0.10524, 36.90 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.03305, mimfg_prc_auc 0.13742, 114.14 secs\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.03582, mimfg_phrcls_loss 2.03582, mimfg_prc_auc 0.10743, 37.38 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.01659, mimfg_prc_auc 0.14443, 111.49 secs\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.02178, mimfg_phrcls_loss 2.02178, mimfg_prc_auc 0.12674, 36.90 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.01563, mimfg_prc_auc 0.14352, 115.37 secs\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.02159, mimfg_phrcls_loss 2.02159, mimfg_prc_auc 0.12615, 35.65 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00526, mimfg_prc_auc 0.14544, 114.68 secs\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.00782, mimfg_phrcls_loss 2.00782, mimfg_prc_auc 0.13690, 35.30 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.04012, mimfg_prc_auc 0.14376, 111.86 secs\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.01630, mimfg_phrcls_loss 2.01630, mimfg_prc_auc 0.12837, 36.00 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00080, mimfg_prc_auc 0.14874, 109.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_mimfg_phrcls_loss+mimfg_prc_auc=0.2404.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.99929, mimfg_phrcls_loss 1.99929, mimfg_prc_auc 0.13054, 35.38 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00432, mimfg_prc_auc 0.15134, 109.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_mimfg_phrcls_loss+mimfg_prc_auc=0.2416.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.00874, mimfg_phrcls_loss 2.00874, mimfg_prc_auc 0.13286, 35.32 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.01124, mimfg_prc_auc 0.15094, 114.94 secs\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.02226, mimfg_phrcls_loss 2.02226, mimfg_prc_auc 0.12064, 37.06 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.97998, mimfg_prc_auc 0.15145, 111.81 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_mimfg_phrcls_loss+mimfg_prc_auc=0.2426.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.02845, mimfg_phrcls_loss 2.02845, mimfg_prc_auc 0.12993, 37.26 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.98882, mimfg_prc_auc 0.15261, 114.71 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_mimfg_phrcls_loss+mimfg_prc_auc=0.2429.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.98669, mimfg_phrcls_loss 1.98669, mimfg_prc_auc 0.14208, 37.03 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00271, mimfg_prc_auc 0.15511, 113.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_mimfg_phrcls_loss+mimfg_prc_auc=0.2438.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.01881, mimfg_phrcls_loss 2.01881, mimfg_prc_auc 0.13128, 36.50 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00751, mimfg_prc_auc 0.15644, 112.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_mimfg_phrcls_loss+mimfg_prc_auc=0.2438.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.03185, mimfg_phrcls_loss 2.03185, mimfg_prc_auc 0.12200, 37.56 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.98545, mimfg_prc_auc 0.15631, 111.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_mimfg_phrcls_loss+mimfg_prc_auc=0.2446.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.01334, mimfg_phrcls_loss 2.01334, mimfg_prc_auc 0.13639, 36.24 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00537, mimfg_prc_auc 0.15602, 112.60 secs\n",
      "\u001b[1m---- Epoch 25/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.00571, mimfg_phrcls_loss 2.00571, mimfg_prc_auc 0.12909, 36.84 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.01208, mimfg_prc_auc 0.15457, 114.60 secs\n",
      "\u001b[1m---- Epoch 26/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.01961, mimfg_phrcls_loss 2.01961, mimfg_prc_auc 0.15131, 36.38 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.97443, mimfg_prc_auc 0.15651, 110.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_26_mimfg_phrcls_loss+mimfg_prc_auc=0.2461.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 27/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.99240, mimfg_phrcls_loss 1.99240, mimfg_prc_auc 0.13515, 36.92 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.98083, mimfg_prc_auc 0.15634, 109.98 secs\n",
      "\u001b[1m---- Epoch 28/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.97037, mimfg_phrcls_loss 1.97037, mimfg_prc_auc 0.15731, 37.16 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00283, mimfg_prc_auc 0.15633, 111.57 secs\n",
      "\u001b[1m---- Epoch 29/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.01310, mimfg_phrcls_loss 2.01310, mimfg_prc_auc 0.13219, 36.53 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.96237, mimfg_prc_auc 0.15683, 111.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_29_mimfg_phrcls_loss+mimfg_prc_auc=0.2464.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 30/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.04038, mimfg_phrcls_loss 2.04038, mimfg_prc_auc 0.12395, 36.35 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.00550, mimfg_prc_auc 0.15668, 109.64 secs\n",
      "\u001b[1m---- Epoch 31/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.02718, mimfg_phrcls_loss 2.02718, mimfg_prc_auc 0.13185, 36.95 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.03567, mimfg_prc_auc 0.16054, 110.97 secs\n",
      "\u001b[1m---- Epoch 32/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.03031, mimfg_phrcls_loss 2.03031, mimfg_prc_auc 0.15436, 36.97 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 2.01704, mimfg_prc_auc 0.15904, 109.61 secs\n",
      "\u001b[1m---- Epoch 33/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.00889, mimfg_phrcls_loss 2.00889, mimfg_prc_auc 0.14834, 37.49 secs\n",
      "(2) Validation stage ...\n",
      "^C iteration 75\n",
      "Engine run is terminating due to exception: \n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 100 \\\n",
    "--max_images_per_batch 12 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 4.0 \\\n",
    "--raw_image_encoding \"cxrmate-rrg24-uniformer-huggingface\" \\\n",
    "--huggingface_model_name \"aehrc/cxrmate-rrg24\" \\\n",
    "--image_size 384 384 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 144 \\\n",
    "--regions_width 12 \\\n",
    "--regions_height 12 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp__no_grounding\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--replace_phrase_embeddings_with_random_vectors \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
