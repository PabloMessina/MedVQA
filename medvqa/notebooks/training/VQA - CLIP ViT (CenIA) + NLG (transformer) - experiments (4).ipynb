{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/vte-vit-base-patch16-bio-clinical-bert-finetuned-v2\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,4e-4,76,5e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 6\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "Downloading: 100%|█████████████████████████| 4.49k/4.49k [00:00<00:00, 2.10MB/s]\n",
      "Downloading: 100%|███████████████████████████| 746M/746M [00:36<00:00, 21.7MB/s]\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-bp16bcbf-v2+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 11.97317, a_loss 8.55411, cD 0.00070, wmdcmp 0.00214, oracc 0.34953, orien_loss 1.10398, chxlmicf1 0.18342, chxlmacf1 0.24919, chx_loss 1.09565, chxlacc 0.50402, chxlrocaucmic 0.46913, chxlrocaucmac 0.51451, qlmicf1 0.11515, qlmacf1 0.11995, ql_loss 1.08294, gacc 0.47636, gloss 0.71001, cxr14micf1 0.13921, cxr14macf1 0.16479, cxr14_loss 1.24772, vnbgmicf1 0.14419, vnbgmacf1 0.17353, vnbg_loss 9.61212, ema 0.00000, 170.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00082, wmdcmp 0.00209, oracc 0.24620, chxlmicf1 0.20126, chxlmacf1 0.26302, chxlacc 0.49326, chxlrocaucmic 0.45570, chxlrocaucmac 0.50777, qlmicf1 0.14087, qlmacf1 0.14503, ema 0.00000, 117.24 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 11.75332, a_loss 7.27105, cD 0.00015, wmdcmp 0.00024, oracc 0.51655, orien_loss 1.02485, chxlmicf1 0.23253, chxlmacf1 0.29112, chx_loss 1.08259, chxlacc 0.53321, chxlrocaucmic 0.52713, chxlrocaucmac 0.56651, qlmicf1 0.14085, qlmacf1 0.13250, ql_loss 1.07017, gacc 0.49886, gloss 0.69998, cxr14micf1 0.15146, cxr14macf1 0.17735, cxr14_loss 1.24133, vnbgmicf1 0.15696, vnbgmacf1 0.18790, vnbg_loss 8.00760, ema 0.01958, 116.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, oracc 0.59544, chxlmicf1 0.26558, chxlmacf1 0.31686, chxlacc 0.53058, chxlrocaucmic 0.54051, chxlrocaucmac 0.57461, qlmicf1 0.18606, qlmacf1 0.16187, ema 0.03636, 63.44 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 10.50329, a_loss 4.99661, cD 0.03864, wmdcmp 0.00906, oracc 0.77278, orien_loss 0.79448, chxlmicf1 0.40700, chxlmacf1 0.39353, chx_loss 1.04296, chxlacc 0.60886, chxlrocaucmic 0.68667, chxlrocaucmac 0.67898, qlmicf1 0.26313, qlmacf1 0.16555, ql_loss 1.01936, gacc 0.57761, gloss 0.67699, cxr14micf1 0.18497, cxr14macf1 0.21191, cxr14_loss 1.21706, vnbgmicf1 0.27455, vnbgmacf1 0.27204, vnbg_loss 5.39711, ema 0.00477, 154.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.01802, wmdcmp 0.02036, oracc 0.83120, chxlmicf1 0.46507, chxlmacf1 0.42435, chxlacc 0.61764, chxlrocaucmic 0.70628, chxlrocaucmac 0.68970, qlmicf1 0.33278, qlmacf1 0.19317, ema 0.00000, 81.56 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-05.\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 8.58069, a_loss 2.83307, cD 0.08516, wmdcmp 0.02158, oracc 0.86296, orien_loss 0.46299, chxlmicf1 0.48836, chxlmacf1 0.44629, chx_loss 0.96499, chxlacc 0.66903, chxlrocaucmic 0.76961, chxlrocaucmac 0.74647, qlmicf1 0.36210, qlmacf1 0.19463, ql_loss 0.93172, gacc 0.62307, gloss 0.64891, cxr14micf1 0.28085, cxr14macf1 0.28375, cxr14_loss 1.13637, vnbgmicf1 0.51086, vnbgmacf1 0.36956, vnbg_loss 3.06577, ema 0.16713, 119.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.17839, wmdcmp 0.04627, oracc 0.90009, chxlmicf1 0.50893, chxlmacf1 0.46044, chxlacc 0.66248, chxlrocaucmic 0.75391, chxlrocaucmac 0.73193, qlmicf1 0.37056, qlmacf1 0.22046, ema 0.42364, 100.71 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-04.\n",
      "\u001b[1m---- Epoch 5/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 7.28941, a_loss 1.59041, cD 0.46219, wmdcmp 0.07340, oracc 0.91814, orien_loss 0.23605, chxlmicf1 0.50762, chxlmacf1 0.46390, chx_loss 0.90656, chxlacc 0.69632, chxlrocaucmic 0.78967, chxlrocaucmac 0.76762, qlmicf1 0.36284, qlmacf1 0.20844, ql_loss 0.86766, gacc 0.70761, gloss 0.58304, cxr14micf1 0.31059, cxr14macf1 0.31004, cxr14_loss 1.03770, vnbgmicf1 0.53572, vnbgmacf1 0.40230, vnbg_loss 1.36123, ema 0.53486, 132.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.86385, wmdcmp 0.13552, oracc 0.95094, chxlmicf1 0.51917, chxlmacf1 0.47041, chxlacc 0.67510, chxlrocaucmic 0.76598, chxlrocaucmac 0.74268, qlmicf1 0.36516, qlmacf1 0.23712, ema 0.63182, 63.69 secs\n",
      "Adjusting learning rate of group 0 to 3.7759e-04.\n",
      "\u001b[1m---- Epoch 6/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000378) ...\n",
      "loss 5.66517, a_loss 1.22607, cD 0.83463, wmdcmp 0.11892, oracc 0.94733, orien_loss 0.15088, chxlmicf1 0.51743, chxlmacf1 0.47113, chx_loss 0.89172, chxlacc 0.70560, chxlrocaucmic 0.79417, chxlrocaucmac 0.77405, qlmicf1 0.36372, qlmacf1 0.21424, ql_loss 0.84506, gacc 0.76000, gloss 0.52995, cxr14micf1 0.33504, cxr14macf1 0.32762, cxr14_loss 0.98277, vnbgmicf1 0.53911, vnbgmacf1 0.40409, vnbg_loss 0.92817, ema 0.65056, 140.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.98591, wmdcmp 0.15517, oracc 0.96317, chxlmicf1 0.52560, chxlmacf1 0.47281, chxlacc 0.69182, chxlrocaucmic 0.76634, chxlrocaucmac 0.74179, qlmicf1 0.35758, qlmacf1 0.24774, ema 0.65455, 75.14 secs\n",
      "Adjusting learning rate of group 0 to 3.5643e-04.\n",
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000356) ...\n",
      "loss 5.26200, a_loss 1.13739, cD 0.96951, wmdcmp 0.13505, oracc 0.95781, orien_loss 0.11915, chxlmicf1 0.51420, chxlmacf1 0.46845, chx_loss 0.89121, chxlacc 0.70446, chxlrocaucmic 0.79421, chxlrocaucmac 0.77348, qlmicf1 0.36002, qlmacf1 0.21682, ql_loss 0.83865, gacc 0.77670, gloss 0.49827, cxr14micf1 0.34437, cxr14macf1 0.33358, cxr14_loss 0.96443, vnbgmicf1 0.54806, vnbgmacf1 0.41404, vnbg_loss 0.86220, ema 0.67403, 129.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05197, wmdcmp 0.15567, oracc 0.96883, chxlmicf1 0.52345, chxlmacf1 0.46577, chxlacc 0.69563, chxlrocaucmic 0.76881, chxlrocaucmac 0.74192, qlmicf1 0.37915, qlmacf1 0.25364, ema 0.66182, 83.83 secs\n",
      "Adjusting learning rate of group 0 to 3.3646e-04.\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000336) ...\n",
      "loss 4.89295, a_loss 1.08470, cD 1.03866, wmdcmp 0.14347, oracc 0.96214, orien_loss 0.10224, chxlmicf1 0.51647, chxlmacf1 0.47099, chx_loss 0.88826, chxlacc 0.70499, chxlrocaucmic 0.79519, chxlrocaucmac 0.77534, qlmicf1 0.36632, qlmacf1 0.21985, ql_loss 0.82952, gacc 0.79102, gloss 0.47114, cxr14micf1 0.33717, cxr14macf1 0.33225, cxr14_loss 0.96263, vnbgmicf1 0.54526, vnbgmacf1 0.41227, vnbg_loss 0.84176, ema 0.68380, 129.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.98185, wmdcmp 0.15082, oracc 0.97316, chxlmicf1 0.52336, chxlmacf1 0.46984, chxlacc 0.68748, chxlrocaucmic 0.76878, chxlrocaucmac 0.74391, qlmicf1 0.37097, qlmacf1 0.25498, ema 0.66273, 61.72 secs\n",
      "Adjusting learning rate of group 0 to 3.1761e-04.\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000318) ...\n",
      "loss 5.28647, a_loss 1.04917, cD 1.09614, wmdcmp 0.15027, oracc 0.96663, orien_loss 0.09015, chxlmicf1 0.51781, chxlmacf1 0.47065, chx_loss 0.88641, chxlacc 0.70641, chxlrocaucmic 0.79502, chxlrocaucmac 0.77439, qlmicf1 0.36332, qlmacf1 0.21931, ql_loss 0.82917, gacc 0.79977, gloss 0.45984, cxr14micf1 0.34232, cxr14macf1 0.33392, cxr14_loss 0.96018, vnbgmicf1 0.54811, vnbgmacf1 0.41694, vnbg_loss 0.82361, ema 0.68731, 133.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00764, wmdcmp 0.15575, oracc 0.97316, chxlmicf1 0.52294, chxlmacf1 0.46983, chxlacc 0.69090, chxlrocaucmic 0.76707, chxlrocaucmac 0.74463, qlmicf1 0.36356, qlmacf1 0.25280, ema 0.64727, 74.77 secs\n",
      "Adjusting learning rate of group 0 to 2.9982e-04.\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 4.75434, a_loss 1.02307, cD 1.14237, wmdcmp 0.15640, oracc 0.96740, orien_loss 0.08068, chxlmicf1 0.51664, chxlmacf1 0.47028, chx_loss 0.88708, chxlacc 0.70603, chxlrocaucmic 0.79443, chxlrocaucmac 0.77387, qlmicf1 0.36096, qlmacf1 0.21836, ql_loss 0.82385, gacc 0.81205, gloss 0.44356, cxr14micf1 0.34240, cxr14macf1 0.33541, cxr14_loss 0.95909, vnbgmicf1 0.54855, vnbgmacf1 0.41895, vnbg_loss 0.79776, ema 0.68847, 132.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18873, wmdcmp 0.17248, oracc 0.97316, chxlmicf1 0.52627, chxlmacf1 0.47343, chxlacc 0.68850, chxlrocaucmic 0.77106, chxlrocaucmac 0.74769, qlmicf1 0.37188, qlmacf1 0.25745, ema 0.66455, 62.52 secs\n",
      "Adjusting learning rate of group 0 to 2.8302e-04.\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000283) ...\n",
      "loss 4.73106, a_loss 1.00235, cD 1.16222, wmdcmp 0.15664, oracc 0.97106, orien_loss 0.07331, chxlmicf1 0.51780, chxlmacf1 0.47224, chx_loss 0.88587, chxlacc 0.70805, chxlrocaucmic 0.79606, chxlrocaucmac 0.77669, qlmicf1 0.36485, qlmacf1 0.21961, ql_loss 0.82510, gacc 0.81625, gloss 0.43153, cxr14micf1 0.35018, cxr14macf1 0.33832, cxr14_loss 0.95054, vnbgmicf1 0.55133, vnbgmacf1 0.41670, vnbg_loss 0.80418, ema 0.69310, 129.20 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.06209, wmdcmp 0.16037, oracc 0.97629, chxlmicf1 0.52528, chxlmacf1 0.47348, chxlacc 0.68778, chxlrocaucmic 0.77094, chxlrocaucmac 0.74772, qlmicf1 0.37265, qlmacf1 0.25541, ema 0.66273, 65.43 secs\n",
      "Adjusting learning rate of group 0 to 2.6716e-04.\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000267) ...\n",
      "loss 4.63291, a_loss 0.98955, cD 1.22328, wmdcmp 0.16492, oracc 0.97266, orien_loss 0.06543, chxlmicf1 0.51774, chxlmacf1 0.47037, chx_loss 0.88327, chxlacc 0.70740, chxlrocaucmic 0.79663, chxlrocaucmac 0.77659, qlmicf1 0.36508, qlmacf1 0.21970, ql_loss 0.82619, gacc 0.81830, gloss 0.42470, cxr14micf1 0.34776, cxr14macf1 0.33699, cxr14_loss 0.94535, vnbgmicf1 0.56079, vnbgmacf1 0.42504, vnbg_loss 0.78145, ema 0.69926, 128.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09043, wmdcmp 0.16143, oracc 0.97629, chxlmicf1 0.52441, chxlmacf1 0.47293, chxlacc 0.69335, chxlrocaucmic 0.76804, chxlrocaucmac 0.74736, qlmicf1 0.37636, qlmacf1 0.25557, ema 0.67273, 62.83 secs\n",
      "Adjusting learning rate of group 0 to 2.5219e-04.\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000252) ...\n",
      "loss 4.59816, a_loss 0.97533, cD 1.23807, wmdcmp 0.16618, oracc 0.97182, orien_loss 0.06504, chxlmicf1 0.52029, chxlmacf1 0.47347, chx_loss 0.88122, chxlacc 0.70896, chxlrocaucmic 0.79757, chxlrocaucmac 0.77702, qlmicf1 0.36839, qlmacf1 0.22149, ql_loss 0.81917, gacc 0.81955, gloss 0.42013, cxr14micf1 0.35675, cxr14macf1 0.34463, cxr14_loss 0.94621, vnbgmicf1 0.55759, vnbgmacf1 0.42261, vnbg_loss 0.76786, ema 0.69931, 125.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25998, wmdcmp 0.17780, oracc 0.97793, chxlmicf1 0.53014, chxlmacf1 0.47773, chxlacc 0.69096, chxlrocaucmic 0.77087, chxlrocaucmac 0.74820, qlmicf1 0.37817, qlmacf1 0.25853, ema 0.65909, 63.61 secs\n",
      "Adjusting learning rate of group 0 to 2.3806e-04.\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000238) ...\n",
      "loss 4.60588, a_loss 0.96464, cD 1.23506, wmdcmp 0.16636, oracc 0.97359, orien_loss 0.06040, chxlmicf1 0.52203, chxlmacf1 0.47533, chx_loss 0.87833, chxlacc 0.70985, chxlrocaucmic 0.79883, chxlrocaucmac 0.77859, qlmicf1 0.36556, qlmacf1 0.22216, ql_loss 0.82301, gacc 0.82193, gloss 0.41952, cxr14micf1 0.34302, cxr14macf1 0.33365, cxr14_loss 0.95317, vnbgmicf1 0.56338, vnbgmacf1 0.43344, vnbg_loss 0.75504, ema 0.70486, 124.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.10878, wmdcmp 0.16412, oracc 0.97793, chxlmicf1 0.52026, chxlmacf1 0.46969, chxlacc 0.68674, chxlrocaucmic 0.76737, chxlrocaucmac 0.74712, qlmicf1 0.38439, qlmacf1 0.26143, ema 0.68455, 65.66 secs\n",
      "Adjusting learning rate of group 0 to 2.2473e-04.\n",
      "\u001b[1m---- Epoch 15/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000225) ...\n",
      "loss 4.42224, a_loss 0.96165, cD 1.25677, wmdcmp 0.16786, oracc 0.97398, orien_loss 0.05710, chxlmicf1 0.52191, chxlmacf1 0.47446, chx_loss 0.87996, chxlacc 0.70969, chxlrocaucmic 0.79831, chxlrocaucmac 0.77732, qlmicf1 0.36810, qlmacf1 0.22205, ql_loss 0.81250, gacc 0.82693, gloss 0.40950, cxr14micf1 0.35249, cxr14macf1 0.34220, cxr14_loss 0.95105, vnbgmicf1 0.56282, vnbgmacf1 0.42972, vnbg_loss 0.77266, ema 0.70134, 133.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15585, wmdcmp 0.17205, oracc 0.97793, chxlmicf1 0.52103, chxlmacf1 0.47294, chxlacc 0.68519, chxlrocaucmic 0.76761, chxlrocaucmac 0.74703, qlmicf1 0.37901, qlmacf1 0.26062, ema 0.67455, 66.67 secs\n",
      "Adjusting learning rate of group 0 to 2.1214e-04.\n",
      "\u001b[1m---- Epoch 16/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000212) ...\n",
      "loss 4.64648, a_loss 0.95423, cD 1.26235, wmdcmp 0.17015, oracc 0.97421, orien_loss 0.05670, chxlmicf1 0.51869, chxlmacf1 0.47152, chx_loss 0.88145, chxlacc 0.70838, chxlrocaucmic 0.79779, chxlrocaucmac 0.77844, qlmicf1 0.36565, qlmacf1 0.22085, ql_loss 0.81692, gacc 0.83023, gloss 0.40243, cxr14micf1 0.36410, cxr14macf1 0.34766, cxr14_loss 0.93717, vnbgmicf1 0.56759, vnbgmacf1 0.44121, vnbg_loss 0.75184, ema 0.70810, 119.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32203, wmdcmp 0.18356, oracc 0.98181, chxlmicf1 0.52125, chxlmacf1 0.47199, chxlacc 0.68601, chxlrocaucmic 0.76819, chxlrocaucmac 0.74694, qlmicf1 0.38348, qlmacf1 0.25740, ema 0.67545, 59.13 secs\n",
      "Adjusting learning rate of group 0 to 2.0025e-04.\n",
      "\u001b[1m---- Epoch 17/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 4.77971, a_loss 0.93869, cD 1.30835, wmdcmp 0.17395, oracc 0.97641, orien_loss 0.05251, chxlmicf1 0.52278, chxlmacf1 0.47634, chx_loss 0.87717, chxlacc 0.71047, chxlrocaucmic 0.79886, chxlrocaucmac 0.77983, qlmicf1 0.37157, qlmacf1 0.22266, ql_loss 0.81829, gacc 0.83000, gloss 0.40268, cxr14micf1 0.35190, cxr14macf1 0.34067, cxr14_loss 0.95121, vnbgmicf1 0.57532, vnbgmacf1 0.43850, vnbg_loss 0.73830, ema 0.70657, 124.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27399, wmdcmp 0.18168, oracc 0.97793, chxlmicf1 0.52648, chxlmacf1 0.47302, chxlacc 0.69128, chxlrocaucmic 0.76999, chxlrocaucmac 0.74682, qlmicf1 0.38066, qlmacf1 0.26047, ema 0.68000, 69.69 secs\n",
      "Adjusting learning rate of group 0 to 1.8903e-04.\n",
      "\u001b[1m---- Epoch 18/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 4.46961, a_loss 0.93456, cD 1.31736, wmdcmp 0.17544, oracc 0.97637, orien_loss 0.05202, chxlmicf1 0.52148, chxlmacf1 0.47320, chx_loss 0.87869, chxlacc 0.71182, chxlrocaucmic 0.79869, chxlrocaucmac 0.77859, qlmicf1 0.37329, qlmacf1 0.22286, ql_loss 0.81255, gacc 0.83114, gloss 0.39669, cxr14micf1 0.35547, cxr14macf1 0.34633, cxr14_loss 0.93849, vnbgmicf1 0.56602, vnbgmacf1 0.42774, vnbg_loss 0.74626, ema 0.70361, 126.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16501, wmdcmp 0.17025, oracc 0.97942, chxlmicf1 0.52251, chxlmacf1 0.47468, chxlacc 0.68457, chxlrocaucmic 0.76879, chxlrocaucmac 0.74798, qlmicf1 0.37940, qlmacf1 0.25848, ema 0.68636, 64.70 secs\n",
      "Adjusting learning rate of group 0 to 1.7844e-04.\n",
      "\u001b[1m---- Epoch 19/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000178) ...\n",
      "loss 4.59944, a_loss 0.93156, cD 1.32002, wmdcmp 0.17537, oracc 0.97745, orien_loss 0.04711, chxlmicf1 0.51964, chxlmacf1 0.47282, chx_loss 0.88170, chxlacc 0.70863, chxlrocaucmic 0.79748, chxlrocaucmac 0.77750, qlmicf1 0.37108, qlmacf1 0.22735, ql_loss 0.81261, gacc 0.83148, gloss 0.39447, cxr14micf1 0.35957, cxr14macf1 0.34869, cxr14_loss 0.92349, vnbgmicf1 0.57440, vnbgmacf1 0.43778, vnbg_loss 0.72735, ema 0.70852, 122.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30105, wmdcmp 0.18298, oracc 0.98181, chxlmicf1 0.52494, chxlmacf1 0.47665, chxlacc 0.68746, chxlrocaucmic 0.76797, chxlrocaucmac 0.74854, qlmicf1 0.37560, qlmacf1 0.25785, ema 0.67818, 63.02 secs\n",
      "Adjusting learning rate of group 0 to 1.6844e-04.\n",
      "\u001b[1m---- Epoch 20/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 4.26812, a_loss 0.92073, cD 1.34481, wmdcmp 0.17951, oracc 0.97814, orien_loss 0.04803, chxlmicf1 0.52338, chxlmacf1 0.47536, chx_loss 0.87866, chxlacc 0.71037, chxlrocaucmic 0.79950, chxlrocaucmac 0.77874, qlmicf1 0.36889, qlmacf1 0.22313, ql_loss 0.81375, gacc 0.83352, gloss 0.39278, cxr14micf1 0.35244, cxr14macf1 0.34345, cxr14_loss 0.94606, vnbgmicf1 0.56731, vnbgmacf1 0.43320, vnbg_loss 0.74114, ema 0.71222, 121.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28499, wmdcmp 0.18355, oracc 0.97942, chxlmicf1 0.52469, chxlmacf1 0.47713, chxlacc 0.68931, chxlrocaucmic 0.76683, chxlrocaucmac 0.74715, qlmicf1 0.37847, qlmacf1 0.26110, ema 0.67091, 54.90 secs\n",
      "Adjusting learning rate of group 0 to 1.5900e-04.\n",
      "\u001b[1m---- Epoch 21/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 4.43958, a_loss 0.91556, cD 1.37292, wmdcmp 0.18249, oracc 0.97720, orien_loss 0.04669, chxlmicf1 0.52291, chxlmacf1 0.47548, chx_loss 0.87501, chxlacc 0.71201, chxlrocaucmic 0.79966, chxlrocaucmac 0.78067, qlmicf1 0.37131, qlmacf1 0.22170, ql_loss 0.81268, gacc 0.83977, gloss 0.38532, cxr14micf1 0.35171, cxr14macf1 0.34344, cxr14_loss 0.94191, vnbgmicf1 0.57551, vnbgmacf1 0.44291, vnbg_loss 0.72371, ema 0.70972, 125.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18035, wmdcmp 0.17317, oracc 0.98181, chxlmicf1 0.52346, chxlmacf1 0.47277, chxlacc 0.68449, chxlrocaucmic 0.76931, chxlrocaucmac 0.74815, qlmicf1 0.37517, qlmacf1 0.25891, ema 0.67273, 68.84 secs\n",
      "Adjusting learning rate of group 0 to 1.5010e-04.\n",
      "\u001b[1m---- Epoch 22/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "loss 4.52195, a_loss 0.91727, cD 1.35109, wmdcmp 0.17956, oracc 0.97684, orien_loss 0.04793, chxlmicf1 0.52518, chxlmacf1 0.47654, chx_loss 0.87402, chxlacc 0.71274, chxlrocaucmic 0.80235, chxlrocaucmac 0.78339, qlmicf1 0.37275, qlmacf1 0.22440, ql_loss 0.81221, gacc 0.83648, gloss 0.38238, cxr14micf1 0.36460, cxr14macf1 0.34868, cxr14_loss 0.93509, vnbgmicf1 0.57441, vnbgmacf1 0.43753, vnbg_loss 0.72252, ema 0.71773, 128.98 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.23120, wmdcmp 0.18018, oracc 0.97942, chxlmicf1 0.52103, chxlmacf1 0.47091, chxlacc 0.68298, chxlrocaucmic 0.76777, chxlrocaucmac 0.74631, qlmicf1 0.37968, qlmacf1 0.25924, ema 0.67182, 61.00 secs\n",
      "Adjusting learning rate of group 0 to 1.4169e-04.\n",
      "\u001b[1m---- Epoch 23/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 4.33713, a_loss 0.90936, cD 1.36991, wmdcmp 0.18316, oracc 0.97824, orien_loss 0.04283, chxlmicf1 0.52166, chxlmacf1 0.47463, chx_loss 0.87803, chxlacc 0.71020, chxlrocaucmic 0.79866, chxlrocaucmac 0.77866, qlmicf1 0.36986, qlmacf1 0.22383, ql_loss 0.81284, gacc 0.83636, gloss 0.38191, cxr14micf1 0.35804, cxr14macf1 0.34687, cxr14_loss 0.93077, vnbgmicf1 0.57272, vnbgmacf1 0.43785, vnbg_loss 0.73090, ema 0.71630, 121.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24264, wmdcmp 0.17892, oracc 0.98181, chxlmicf1 0.52712, chxlmacf1 0.47796, chxlacc 0.68932, chxlrocaucmic 0.76935, chxlrocaucmac 0.74762, qlmicf1 0.37616, qlmacf1 0.25832, ema 0.67727, 58.09 secs\n",
      "Adjusting learning rate of group 0 to 1.3375e-04.\n",
      "\u001b[1m---- Epoch 24/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 4.38156, a_loss 0.90427, cD 1.36903, wmdcmp 0.18128, oracc 0.97723, orien_loss 0.04152, chxlmicf1 0.52073, chxlmacf1 0.47341, chx_loss 0.88049, chxlacc 0.71017, chxlrocaucmic 0.79926, chxlrocaucmac 0.77994, qlmicf1 0.37276, qlmacf1 0.22376, ql_loss 0.80724, gacc 0.83636, gloss 0.38802, cxr14micf1 0.35354, cxr14macf1 0.34014, cxr14_loss 0.94206, vnbgmicf1 0.57907, vnbgmacf1 0.44742, vnbg_loss 0.70712, ema 0.71806, 123.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23220, wmdcmp 0.17848, oracc 0.97704, chxlmicf1 0.52516, chxlmacf1 0.47448, chxlacc 0.68805, chxlrocaucmic 0.77044, chxlrocaucmac 0.74925, qlmicf1 0.38003, qlmacf1 0.25865, ema 0.66364, 57.67 secs\n",
      "Adjusting learning rate of group 0 to 1.2625e-04.\n",
      "\u001b[1m---- Epoch 25/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000126) ...\n",
      "loss 4.31075, a_loss 0.90173, cD 1.37827, wmdcmp 0.18279, oracc 0.97871, orien_loss 0.04393, chxlmicf1 0.51999, chxlmacf1 0.47393, chx_loss 0.87760, chxlacc 0.70922, chxlrocaucmic 0.79855, chxlrocaucmac 0.77989, qlmicf1 0.37337, qlmacf1 0.22957, ql_loss 0.80883, gacc 0.84148, gloss 0.38065, cxr14micf1 0.35993, cxr14macf1 0.34408, cxr14_loss 0.93660, vnbgmicf1 0.57581, vnbgmacf1 0.44186, vnbg_loss 0.72494, ema 0.71838, 122.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28771, wmdcmp 0.18454, oracc 0.98181, chxlmicf1 0.52376, chxlmacf1 0.47366, chxlacc 0.68791, chxlrocaucmic 0.77099, chxlrocaucmac 0.74957, qlmicf1 0.38110, qlmacf1 0.26331, ema 0.67545, 59.23 secs\n",
      "Adjusting learning rate of group 0 to 1.1918e-04.\n",
      "\u001b[1m---- Epoch 26/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000119) ...\n",
      "loss 4.21615, a_loss 0.89718, cD 1.39364, wmdcmp 0.18331, oracc 0.97742, orien_loss 0.04236, chxlmicf1 0.52193, chxlmacf1 0.47511, chx_loss 0.87552, chxlacc 0.71084, chxlrocaucmic 0.80040, chxlrocaucmac 0.78061, qlmicf1 0.37084, qlmacf1 0.22510, ql_loss 0.81015, gacc 0.83216, gloss 0.38552, cxr14micf1 0.35590, cxr14macf1 0.34429, cxr14_loss 0.93062, vnbgmicf1 0.58253, vnbgmacf1 0.45086, vnbg_loss 0.70694, ema 0.72130, 131.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31803, wmdcmp 0.18689, oracc 0.98181, chxlmicf1 0.52662, chxlmacf1 0.47287, chxlacc 0.69311, chxlrocaucmic 0.77281, chxlrocaucmac 0.74887, qlmicf1 0.38115, qlmacf1 0.26120, ema 0.66273, 65.60 secs\n",
      "Adjusting learning rate of group 0 to 1.1250e-04.\n",
      "\u001b[1m---- Epoch 27/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 4.23258, a_loss 0.89058, cD 1.41681, wmdcmp 0.18851, oracc 0.97916, orien_loss 0.04208, chxlmicf1 0.52102, chxlmacf1 0.47368, chx_loss 0.87484, chxlacc 0.70966, chxlrocaucmic 0.79952, chxlrocaucmac 0.77969, qlmicf1 0.37232, qlmacf1 0.23085, ql_loss 0.80464, gacc 0.83955, gloss 0.37885, cxr14micf1 0.35726, cxr14macf1 0.34762, cxr14_loss 0.93356, vnbgmicf1 0.57372, vnbgmacf1 0.43955, vnbg_loss 0.72131, ema 0.72037, 121.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21214, wmdcmp 0.17681, oracc 0.98181, chxlmicf1 0.52177, chxlmacf1 0.47206, chxlacc 0.69055, chxlrocaucmic 0.76836, chxlrocaucmac 0.74908, qlmicf1 0.38438, qlmacf1 0.26192, ema 0.66909, 57.18 secs\n",
      "Adjusting learning rate of group 0 to 1.0620e-04.\n",
      "\u001b[1m---- Epoch 28/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 4.20447, a_loss 0.88474, cD 1.43798, wmdcmp 0.18991, oracc 0.97877, orien_loss 0.04118, chxlmicf1 0.52212, chxlmacf1 0.47468, chx_loss 0.87381, chxlacc 0.71082, chxlrocaucmic 0.79981, chxlrocaucmac 0.78099, qlmicf1 0.37390, qlmacf1 0.23310, ql_loss 0.80552, gacc 0.84591, gloss 0.37022, cxr14micf1 0.35567, cxr14macf1 0.34665, cxr14_loss 0.93587, vnbgmicf1 0.57318, vnbgmacf1 0.44193, vnbg_loss 0.71223, ema 0.72162, 121.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29689, wmdcmp 0.18430, oracc 0.98181, chxlmicf1 0.52116, chxlmacf1 0.47189, chxlacc 0.68717, chxlrocaucmic 0.76968, chxlrocaucmac 0.74818, qlmicf1 0.38740, qlmacf1 0.26067, ema 0.67545, 59.35 secs\n",
      "Adjusting learning rate of group 0 to 1.0025e-04.\n",
      "\u001b[1m---- Epoch 29/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.50954, a_loss 0.88584, cD 1.42952, wmdcmp 0.18846, oracc 0.97710, orien_loss 0.04371, chxlmicf1 0.52234, chxlmacf1 0.47469, chx_loss 0.87628, chxlacc 0.71031, chxlrocaucmic 0.80015, chxlrocaucmac 0.78132, qlmicf1 0.37681, qlmacf1 0.22949, ql_loss 0.80339, gacc 0.84545, gloss 0.37342, cxr14micf1 0.36003, cxr14macf1 0.34785, cxr14_loss 0.93263, vnbgmicf1 0.58389, vnbgmacf1 0.44841, vnbg_loss 0.69780, ema 0.72269, 123.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34211, wmdcmp 0.18961, oracc 0.98181, chxlmicf1 0.51756, chxlmacf1 0.46940, chxlacc 0.68312, chxlrocaucmic 0.76860, chxlrocaucmac 0.74861, qlmicf1 0.38211, qlmacf1 0.25936, ema 0.66636, 62.05 secs\n",
      "Adjusting learning rate of group 0 to 9.4633e-05.\n",
      "\u001b[1m---- Epoch 30/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "Current run is terminating due to exception: Caught OSError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2809, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "OSError: [Errno 5] Input/output error: '/mnt/workspace/mimic-cxr-jpg/images-small/p12/p12356657/s59324537/24fce839-0dad416b-53edc021-d87b5cb4-42583816.jpg'\n",
      "\n",
      "Engine run is terminating due to exception: Caught OSError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2809, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "OSError: [Errno 5] Input/output error: '/mnt/workspace/mimic-cxr-jpg/images-small/p12/p12356657/s59324537/24fce839-0dad416b-53edc021-d87b5cb4-42583816.jpg'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_vqa.py\", line 1449, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_vqa.py\", line 1348, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_vqa.py\", line 890, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 801, in _run_once_on_dataset\n",
      "    self.state.batch = next(self._dataloader_iter)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 169, in balanced_dataloaders_generator\n",
      "    yield next(cyclic_dataloaders[i])\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 135, in cyclic_dataloader_generator\n",
      "    for batch in dataloader:\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "OSError: Caught OSError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2809, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "OSError: [Errno 5] Input/output error: '/mnt/workspace/mimic-cxr-jpg/images-small/p12/p12356657/s59324537/24fce839-0dad416b-53edc021-d87b5cb4-42583816.jpg'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 80 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 6 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,4e-4,76,5e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --raw-image-encoding \"clip-vit-huggingface\" \\\n",
    "        --clip-version \"CenIA/vte-vit-base-patch16-bio-clinical-bert-finetuned-v2\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 20\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   iuxray_qa_adapted_reports_filename: None\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: bilstm\n",
      "   answer_decoding: lstm\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adam\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.05\n",
      "   mimiccxr_weight_chexpert_mode: 0.2\n",
      "   iuxray_weight_chexpert_mode: 0.05\n",
      "   mimiccxr_include_chexpert_mode: False\n",
      "   iuxray_include_chexpert_mode: False\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: False\n",
      "   medical_tokenization: False\n",
      "   medical_terms_frequency_filename: None\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: False\n",
      "   balanced_dataloading: False\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: None\n",
      "   mimiccxr_balanced_metadata_filename: None\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   iuxray_train_with_all: False\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: None\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_questions: False\n",
      "   n_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-bp16bcbf-v2+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_28_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5595.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_28_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5595.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 29/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.48799, a_loss 0.83807, cD 1.55308, wmdcmp 0.20154, oracc 0.97861, orien_loss 0.04342, chxlmicf1 0.52360, chxlmacf1 0.47563, chx_loss 0.87288, chxlacc 0.71260, chxlrocaucmic 0.80145, chxlrocaucmac 0.78118, qlmicf1 0.37570, qlmacf1 0.23379, ql_loss 0.80063, gacc 0.83955, gloss 0.38169, cxr14micf1 0.36040, cxr14macf1 0.34655, cxr14_loss 0.93428, vnbgmicf1 0.58321, vnbgmacf1 0.44935, vnbg_loss 0.70153, ema 0.72236, 231.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22054, wmdcmp 0.17689, oracc 0.97957, chxlmicf1 0.51982, chxlmacf1 0.47027, chxlacc 0.68671, chxlrocaucmic 0.76842, chxlrocaucmac 0.74723, qlmicf1 0.38413, qlmacf1 0.26091, ema 0.66727, 85.55 secs\n",
      "Adjusting learning rate of group 0 to 9.4633e-05.\n",
      "\u001b[1m---- Epoch 30/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 4.45390, a_loss 0.87834, cD 1.45013, wmdcmp 0.19109, oracc 0.97937, orien_loss 0.04065, chxlmicf1 0.52401, chxlmacf1 0.47546, chx_loss 0.87152, chxlacc 0.71221, chxlrocaucmic 0.80074, chxlrocaucmac 0.78097, qlmicf1 0.37483, qlmacf1 0.22936, ql_loss 0.80727, gacc 0.84193, gloss 0.37501, cxr14micf1 0.36980, cxr14macf1 0.35220, cxr14_loss 0.92595, vnbgmicf1 0.57699, vnbgmacf1 0.44699, vnbg_loss 0.71140, ema 0.72185, 187.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36413, wmdcmp 0.19030, oracc 0.97718, chxlmicf1 0.51909, chxlmacf1 0.46871, chxlacc 0.68483, chxlrocaucmic 0.76951, chxlrocaucmac 0.74677, qlmicf1 0.38422, qlmacf1 0.25959, ema 0.66182, 69.99 secs\n",
      "Adjusting learning rate of group 0 to 8.9331e-05.\n",
      "\u001b[1m---- Epoch 31/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 4.20227, a_loss 0.88082, cD 1.44048, wmdcmp 0.18985, oracc 0.97954, orien_loss 0.03809, chxlmicf1 0.52359, chxlmacf1 0.47630, chx_loss 0.87488, chxlacc 0.71276, chxlrocaucmic 0.80127, chxlrocaucmac 0.78215, qlmicf1 0.37635, qlmacf1 0.22868, ql_loss 0.80159, gacc 0.84659, gloss 0.37499, cxr14micf1 0.35528, cxr14macf1 0.34423, cxr14_loss 0.93738, vnbgmicf1 0.57770, vnbgmacf1 0.44268, vnbg_loss 0.70250, ema 0.72310, 191.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35356, wmdcmp 0.18995, oracc 0.97957, chxlmicf1 0.52341, chxlmacf1 0.47440, chxlacc 0.69020, chxlrocaucmic 0.76826, chxlrocaucmac 0.74703, qlmicf1 0.38120, qlmacf1 0.25960, ema 0.67273, 57.26 secs\n",
      "Adjusting learning rate of group 0 to 8.4326e-05.\n",
      "\u001b[1m---- Epoch 32/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000084) ...\n",
      "loss 4.33072, a_loss 0.88277, cD 1.41876, wmdcmp 0.18776, oracc 0.97851, orien_loss 0.04068, chxlmicf1 0.52341, chxlmacf1 0.47422, chx_loss 0.87784, chxlacc 0.71072, chxlrocaucmic 0.79960, chxlrocaucmac 0.77929, qlmicf1 0.37636, qlmacf1 0.22632, ql_loss 0.80581, gacc 0.84216, gloss 0.37594, cxr14micf1 0.35569, cxr14macf1 0.34554, cxr14_loss 0.93294, vnbgmicf1 0.58138, vnbgmacf1 0.45054, vnbg_loss 0.69194, ema 0.72292, 178.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28707, wmdcmp 0.18324, oracc 0.97718, chxlmicf1 0.51851, chxlmacf1 0.47252, chxlacc 0.68423, chxlrocaucmic 0.76547, chxlrocaucmac 0.74708, qlmicf1 0.38524, qlmacf1 0.26204, ema 0.67636, 65.91 secs\n",
      "Adjusting learning rate of group 0 to 7.9602e-05.\n",
      "\u001b[1m---- Epoch 33/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 4.28534, a_loss 0.87520, cD 1.45645, wmdcmp 0.19099, oracc 0.97851, orien_loss 0.03696, chxlmicf1 0.52236, chxlmacf1 0.47595, chx_loss 0.87409, chxlacc 0.71073, chxlrocaucmic 0.79966, chxlrocaucmac 0.78111, qlmicf1 0.37767, qlmacf1 0.22993, ql_loss 0.80119, gacc 0.84489, gloss 0.37300, cxr14micf1 0.36613, cxr14macf1 0.35024, cxr14_loss 0.92398, vnbgmicf1 0.57957, vnbgmacf1 0.44612, vnbg_loss 0.70263, ema 0.72449, 188.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30582, wmdcmp 0.18621, oracc 0.97718, chxlmicf1 0.52080, chxlmacf1 0.47135, chxlacc 0.68503, chxlrocaucmic 0.76700, chxlrocaucmac 0.74729, qlmicf1 0.37916, qlmacf1 0.25962, ema 0.68636, 55.50 secs\n",
      "Adjusting learning rate of group 0 to 7.5142e-05.\n",
      "\u001b[1m---- Epoch 34/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000075) ...\n",
      "loss 4.31430, a_loss 0.87043, cD 1.47705, wmdcmp 0.19380, oracc 0.97840, orien_loss 0.03833, chxlmicf1 0.52242, chxlmacf1 0.47566, chx_loss 0.87197, chxlacc 0.71206, chxlrocaucmic 0.80057, chxlrocaucmac 0.78218, qlmicf1 0.37450, qlmacf1 0.22501, ql_loss 0.80800, gacc 0.84909, gloss 0.36602, cxr14micf1 0.36654, cxr14macf1 0.34936, cxr14_loss 0.92649, vnbgmicf1 0.58121, vnbgmacf1 0.44355, vnbg_loss 0.70328, ema 0.72333, 190.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31019, wmdcmp 0.18605, oracc 0.97718, chxlmicf1 0.52555, chxlmacf1 0.47514, chxlacc 0.68906, chxlrocaucmic 0.77131, chxlrocaucmac 0.74674, qlmicf1 0.38510, qlmacf1 0.25893, ema 0.67727, 56.21 secs\n",
      "Adjusting learning rate of group 0 to 7.0932e-05.\n",
      "\u001b[1m---- Epoch 35/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 4.14996, a_loss 0.87494, cD 1.44582, wmdcmp 0.19166, oracc 0.97937, orien_loss 0.03814, chxlmicf1 0.52550, chxlmacf1 0.47627, chx_loss 0.87175, chxlacc 0.71289, chxlrocaucmic 0.80151, chxlrocaucmac 0.78185, qlmicf1 0.37546, qlmacf1 0.23105, ql_loss 0.79840, gacc 0.84182, gloss 0.37514, cxr14micf1 0.35819, cxr14macf1 0.34557, cxr14_loss 0.92245, vnbgmicf1 0.58689, vnbgmacf1 0.45356, vnbg_loss 0.70140, ema 0.72468, 177.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27907, wmdcmp 0.18312, oracc 0.97957, chxlmicf1 0.52443, chxlmacf1 0.47352, chxlacc 0.69078, chxlrocaucmic 0.76969, chxlrocaucmac 0.74733, qlmicf1 0.38166, qlmacf1 0.25906, ema 0.68182, 68.25 secs\n",
      "Adjusting learning rate of group 0 to 6.6958e-05.\n",
      "\u001b[1m---- Epoch 36/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 4.11044, a_loss 0.87565, cD 1.46504, wmdcmp 0.19297, oracc 0.97903, orien_loss 0.03675, chxlmicf1 0.52455, chxlmacf1 0.47730, chx_loss 0.87392, chxlacc 0.71351, chxlrocaucmic 0.80070, chxlrocaucmac 0.78287, qlmicf1 0.37752, qlmacf1 0.22638, ql_loss 0.80418, gacc 0.84727, gloss 0.37469, cxr14micf1 0.36809, cxr14macf1 0.35205, cxr14_loss 0.92669, vnbgmicf1 0.58256, vnbgmacf1 0.45054, vnbg_loss 0.70314, ema 0.72542, 194.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29220, wmdcmp 0.18445, oracc 0.97957, chxlmicf1 0.52267, chxlmacf1 0.47306, chxlacc 0.68710, chxlrocaucmic 0.76883, chxlrocaucmac 0.74816, qlmicf1 0.38486, qlmacf1 0.26124, ema 0.68273, 53.43 secs\n",
      "Adjusting learning rate of group 0 to 6.3206e-05.\n",
      "\u001b[1m---- Epoch 37/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 4.50407, a_loss 0.86673, cD 1.47030, wmdcmp 0.19318, oracc 0.98013, orien_loss 0.03953, chxlmicf1 0.52442, chxlmacf1 0.47693, chx_loss 0.87456, chxlacc 0.71291, chxlrocaucmic 0.80078, chxlrocaucmac 0.78156, qlmicf1 0.37515, qlmacf1 0.22986, ql_loss 0.80507, gacc 0.84034, gloss 0.37720, cxr14micf1 0.36915, cxr14macf1 0.35244, cxr14_loss 0.91958, vnbgmicf1 0.58021, vnbgmacf1 0.44731, vnbg_loss 0.70211, ema 0.72898, 196.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32907, wmdcmp 0.18901, oracc 0.97957, chxlmicf1 0.51898, chxlmacf1 0.47042, chxlacc 0.68376, chxlrocaucmic 0.76903, chxlrocaucmac 0.74812, qlmicf1 0.38309, qlmacf1 0.26035, ema 0.66909, 54.42 secs\n",
      "Adjusting learning rate of group 0 to 5.9665e-05.\n",
      "\u001b[1m---- Epoch 38/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 4.23212, a_loss 0.87084, cD 1.45859, wmdcmp 0.19176, oracc 0.97966, orien_loss 0.03952, chxlmicf1 0.52491, chxlmacf1 0.47671, chx_loss 0.87196, chxlacc 0.71285, chxlrocaucmic 0.80114, chxlrocaucmac 0.78239, qlmicf1 0.37716, qlmacf1 0.22928, ql_loss 0.79838, gacc 0.83852, gloss 0.37277, cxr14micf1 0.36535, cxr14macf1 0.34992, cxr14_loss 0.93357, vnbgmicf1 0.59036, vnbgmacf1 0.45816, vnbg_loss 0.68528, ema 0.72856, 175.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28577, wmdcmp 0.18385, oracc 0.97957, chxlmicf1 0.52040, chxlmacf1 0.47203, chxlacc 0.68597, chxlrocaucmic 0.76886, chxlrocaucmac 0.74798, qlmicf1 0.38760, qlmacf1 0.26369, ema 0.68273, 68.92 secs\n",
      "Adjusting learning rate of group 0 to 5.6322e-05.\n",
      "\u001b[1m---- Epoch 39/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 4.26587, a_loss 0.86586, cD 1.46477, wmdcmp 0.19277, oracc 0.98052, orien_loss 0.03692, chxlmicf1 0.52623, chxlmacf1 0.47923, chx_loss 0.87168, chxlacc 0.71329, chxlrocaucmic 0.80151, chxlrocaucmac 0.78221, qlmicf1 0.37492, qlmacf1 0.23121, ql_loss 0.80344, gacc 0.85364, gloss 0.35696, cxr14micf1 0.36907, cxr14macf1 0.35095, cxr14_loss 0.92063, vnbgmicf1 0.58375, vnbgmacf1 0.45367, vnbg_loss 0.69874, ema 0.73208, 188.42 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.32552, wmdcmp 0.18904, oracc 0.97957, chxlmicf1 0.51916, chxlmacf1 0.47037, chxlacc 0.68651, chxlrocaucmic 0.76870, chxlrocaucmac 0.74823, qlmicf1 0.38521, qlmacf1 0.26260, ema 0.67727, 55.12 secs\n",
      "Adjusting learning rate of group 0 to 5.3166e-05.\n",
      "\u001b[1m---- Epoch 40/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 4.23549, a_loss 0.86208, cD 1.49046, wmdcmp 0.19542, oracc 0.98096, orien_loss 0.03829, chxlmicf1 0.52101, chxlmacf1 0.47382, chx_loss 0.87712, chxlacc 0.71246, chxlrocaucmic 0.80008, chxlrocaucmac 0.78168, qlmicf1 0.37631, qlmacf1 0.22508, ql_loss 0.80593, gacc 0.84943, gloss 0.36310, cxr14micf1 0.37171, cxr14macf1 0.35343, cxr14_loss 0.91630, vnbgmicf1 0.58252, vnbgmacf1 0.45029, vnbg_loss 0.68546, ema 0.72759, 196.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33929, wmdcmp 0.18943, oracc 0.97957, chxlmicf1 0.51856, chxlmacf1 0.46916, chxlacc 0.68308, chxlrocaucmic 0.76866, chxlrocaucmac 0.74739, qlmicf1 0.38328, qlmacf1 0.26237, ema 0.67364, 54.82 secs\n",
      "Adjusting learning rate of group 0 to 5.0188e-05.\n",
      "\u001b[1m---- Epoch 41/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n",
      "loss 4.16628, a_loss 0.86788, cD 1.47280, wmdcmp 0.19327, oracc 0.97930, orien_loss 0.03494, chxlmicf1 0.52117, chxlmacf1 0.47345, chx_loss 0.87661, chxlacc 0.71171, chxlrocaucmic 0.80028, chxlrocaucmac 0.78128, qlmicf1 0.37829, qlmacf1 0.22853, ql_loss 0.79798, gacc 0.84693, gloss 0.36516, cxr14micf1 0.37550, cxr14macf1 0.35704, cxr14_loss 0.90857, vnbgmicf1 0.58471, vnbgmacf1 0.45060, vnbg_loss 0.70742, ema 0.73051, 174.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34014, wmdcmp 0.18897, oracc 0.97957, chxlmicf1 0.51952, chxlmacf1 0.47031, chxlacc 0.68535, chxlrocaucmic 0.76923, chxlrocaucmac 0.74780, qlmicf1 0.38612, qlmacf1 0.26274, ema 0.67455, 69.74 secs\n",
      "Adjusting learning rate of group 0 to 4.7376e-05.\n",
      "\u001b[1m---- Epoch 42/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 4.18083, a_loss 0.86302, cD 1.48528, wmdcmp 0.19447, oracc 0.97967, orien_loss 0.03567, chxlmicf1 0.52179, chxlmacf1 0.47436, chx_loss 0.87727, chxlacc 0.71064, chxlrocaucmic 0.80008, chxlrocaucmac 0.78088, qlmicf1 0.37779, qlmacf1 0.22753, ql_loss 0.80466, gacc 0.85239, gloss 0.36014, cxr14micf1 0.36696, cxr14macf1 0.35069, cxr14_loss 0.91210, vnbgmicf1 0.58176, vnbgmacf1 0.44871, vnbg_loss 0.68802, ema 0.72884, 192.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31365, wmdcmp 0.18652, oracc 0.97957, chxlmicf1 0.52026, chxlmacf1 0.47084, chxlacc 0.68510, chxlrocaucmic 0.76735, chxlrocaucmac 0.74770, qlmicf1 0.38707, qlmacf1 0.26402, ema 0.68273, 56.94 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-05.\n",
      "\u001b[1m---- Epoch 43/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 3.96987, a_loss 0.86471, cD 1.50226, wmdcmp 0.19637, oracc 0.97963, orien_loss 0.03663, chxlmicf1 0.52403, chxlmacf1 0.47729, chx_loss 0.87330, chxlacc 0.71195, chxlrocaucmic 0.80030, chxlrocaucmac 0.78258, qlmicf1 0.37679, qlmacf1 0.22955, ql_loss 0.79925, gacc 0.84830, gloss 0.36775, cxr14micf1 0.35995, cxr14macf1 0.34729, cxr14_loss 0.93437, vnbgmicf1 0.58442, vnbgmacf1 0.44870, vnbg_loss 0.69070, ema 0.72690, 194.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32058, wmdcmp 0.18731, oracc 0.97957, chxlmicf1 0.52000, chxlmacf1 0.47140, chxlacc 0.68419, chxlrocaucmic 0.76895, chxlrocaucmac 0.74794, qlmicf1 0.38562, qlmacf1 0.26314, ema 0.67909, 55.26 secs\n",
      "Adjusting learning rate of group 0 to 4.2216e-05.\n",
      "\u001b[1m---- Epoch 44/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 4.26756, a_loss 0.85818, cD 1.48895, wmdcmp 0.19572, oracc 0.97882, orien_loss 0.03719, chxlmicf1 0.52377, chxlmacf1 0.47652, chx_loss 0.87214, chxlacc 0.71254, chxlrocaucmic 0.80090, chxlrocaucmac 0.78202, qlmicf1 0.37529, qlmacf1 0.22901, ql_loss 0.80805, gacc 0.84727, gloss 0.35830, cxr14micf1 0.36349, cxr14macf1 0.34854, cxr14_loss 0.92398, vnbgmicf1 0.58598, vnbgmacf1 0.45076, vnbg_loss 0.69610, ema 0.73630, 170.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26590, wmdcmp 0.18342, oracc 0.97957, chxlmicf1 0.52103, chxlmacf1 0.47189, chxlacc 0.68593, chxlrocaucmic 0.76881, chxlrocaucmac 0.74818, qlmicf1 0.38714, qlmacf1 0.26236, ema 0.67727, 61.59 secs\n",
      "Adjusting learning rate of group 0 to 3.9850e-05.\n",
      "\u001b[1m---- Epoch 45/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 4.53897, a_loss 0.85272, cD 1.53030, wmdcmp 0.19930, oracc 0.97918, orien_loss 0.03711, chxlmicf1 0.52633, chxlmacf1 0.47844, chx_loss 0.86905, chxlacc 0.71338, chxlrocaucmic 0.80294, chxlrocaucmac 0.78500, qlmicf1 0.37489, qlmacf1 0.22558, ql_loss 0.80204, gacc 0.84898, gloss 0.36584, cxr14micf1 0.35475, cxr14macf1 0.34317, cxr14_loss 0.93071, vnbgmicf1 0.58289, vnbgmacf1 0.45008, vnbg_loss 0.68573, ema 0.73032, 194.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31058, wmdcmp 0.18780, oracc 0.98017, chxlmicf1 0.52113, chxlmacf1 0.47171, chxlacc 0.68759, chxlrocaucmic 0.76887, chxlrocaucmac 0.74787, qlmicf1 0.38848, qlmacf1 0.26370, ema 0.68273, 58.24 secs\n",
      "Adjusting learning rate of group 0 to 3.7618e-05.\n",
      "\u001b[1m---- Epoch 46/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 4.15665, a_loss 0.85828, cD 1.49043, wmdcmp 0.19539, oracc 0.97997, orien_loss 0.03740, chxlmicf1 0.52578, chxlmacf1 0.47825, chx_loss 0.86594, chxlacc 0.71340, chxlrocaucmic 0.80400, chxlrocaucmac 0.78495, qlmicf1 0.37791, qlmacf1 0.23165, ql_loss 0.79954, gacc 0.84784, gloss 0.36807, cxr14micf1 0.35184, cxr14macf1 0.34252, cxr14_loss 0.93790, vnbgmicf1 0.58519, vnbgmacf1 0.44659, vnbg_loss 0.68123, ema 0.72903, 190.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31873, wmdcmp 0.18758, oracc 0.98285, chxlmicf1 0.52100, chxlmacf1 0.47124, chxlacc 0.68696, chxlrocaucmic 0.76933, chxlrocaucmac 0.74810, qlmicf1 0.38847, qlmacf1 0.26402, ema 0.67455, 62.72 secs\n",
      "Adjusting learning rate of group 0 to 3.5510e-05.\n",
      "\u001b[1m---- Epoch 47/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 4.28083, a_loss 0.86206, cD 1.47639, wmdcmp 0.19418, oracc 0.98046, orien_loss 0.03773, chxlmicf1 0.52302, chxlmacf1 0.47612, chx_loss 0.87389, chxlacc 0.71172, chxlrocaucmic 0.79953, chxlrocaucmac 0.78148, qlmicf1 0.37334, qlmacf1 0.23032, ql_loss 0.80451, gacc 0.85375, gloss 0.36146, cxr14micf1 0.35592, cxr14macf1 0.34577, cxr14_loss 0.93120, vnbgmicf1 0.59313, vnbgmacf1 0.46448, vnbg_loss 0.67532, ema 0.73347, 163.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28089, wmdcmp 0.18417, oracc 0.98047, chxlmicf1 0.52183, chxlmacf1 0.47174, chxlacc 0.68664, chxlrocaucmic 0.77014, chxlrocaucmac 0.74803, qlmicf1 0.38971, qlmacf1 0.26341, ema 0.67455, 56.44 secs\n",
      "Adjusting learning rate of group 0 to 3.3521e-05.\n",
      "\u001b[1m---- Epoch 48/48\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.31796, a_loss 0.85563, cD 1.50948, wmdcmp 0.19642, oracc 0.97983, orien_loss 0.03643, chxlmicf1 0.52583, chxlmacf1 0.47777, chx_loss 0.87180, chxlacc 0.71374, chxlrocaucmic 0.80204, chxlrocaucmac 0.78370, qlmicf1 0.37683, qlmacf1 0.22985, ql_loss 0.80319, gacc 0.84886, gloss 0.36010, cxr14micf1 0.35302, cxr14macf1 0.34505, cxr14_loss 0.93459, vnbgmicf1 0.58620, vnbgmacf1 0.45330, vnbg_loss 0.69294, ema 0.73074, 204.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35321, wmdcmp 0.19036, oracc 0.98285, chxlmicf1 0.51966, chxlmacf1 0.47008, chxlacc 0.68579, chxlrocaucmic 0.76909, chxlrocaucmac 0.74785, qlmicf1 0.38496, qlmacf1 0.26252, ema 0.67000, 55.26 secs\n",
      "Adjusting learning rate of group 0 to 3.1643e-05.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 20 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 3 \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 50\n",
      "   batches_per_epoch: 399\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/vte-vit-base-patch16-bio-clinical-bert-finetuned-v2\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,1e-4,46,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 50\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-bp16bcbf-v2+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,1e-4,46,1e-6\n",
      "1e-06 4 0.0001 46 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 50\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|███████████████████████████████████████████| 97/97 [00:09<00:00, 10.16it/s]\n",
      " *** merging from i=0 to j=2, acc_size = 71\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=50,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 50\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|██████████████████████████████████████████| 91/91 [00:00<00:00, 716.04it/s]\n",
      " *** merging from i=0 to j=18, acc_size = 50\n",
      " *** merging from i=19 to j=25, acc_size = 59\n",
      " *** merging from i=26 to j=30, acc_size = 60\n",
      " *** merging from i=31 to j=34, acc_size = 65\n",
      " *** merging from i=35 to j=37, acc_size = 79\n",
      " *** merging from i=38 to j=39, acc_size = 83\n",
      " *** merging from i=40 to j=41, acc_size = 91\n",
      " *** merging from i=42 to j=43, acc_size = 98\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=50,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 55\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "checkpoint_names = ['checkpoint_45_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5625.pt', 'checkpoint_28_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5595.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_45_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5625.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.33245, a_loss 0.79216, cD 1.71560, wmdcmp 0.21743, oracc 0.97998, orien_loss 0.03563, chxlmicf1 0.52980, chxlmacf1 0.47965, chx_loss 0.86512, chxlacc 0.71770, chxlrocaucmic 0.80413, chxlrocaucmac 0.78349, qlmicf1 0.38025, qlmacf1 0.23575, ql_loss 0.74112, gacc 0.85800, gloss 0.35038, cxr14micf1 0.37031, cxr14macf1 0.35320, cxr14_loss 0.91234, vnbgmicf1 0.58754, vnbgmacf1 0.45148, vnbg_loss 0.66851, ema 0.73182, 128.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33125, wmdcmp 0.18944, oracc 0.98464, chxlmicf1 0.52466, chxlmacf1 0.47531, chxlacc 0.69216, chxlrocaucmic 0.77116, chxlrocaucmac 0.75030, qlmicf1 0.39413, qlmacf1 0.26492, ema 0.67818, 47.97 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 2/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.82071, a_loss 0.85471, cD 1.52025, wmdcmp 0.19640, oracc 0.97978, orien_loss 0.03409, chxlmicf1 0.52862, chxlmacf1 0.47844, chx_loss 0.86347, chxlacc 0.71921, chxlrocaucmic 0.80561, chxlrocaucmac 0.78494, qlmicf1 0.37972, qlmacf1 0.23684, ql_loss 0.74313, gacc 0.86945, gloss 0.32005, cxr14micf1 0.34959, cxr14macf1 0.34146, cxr14_loss 0.94343, vnbgmicf1 0.58833, vnbgmacf1 0.45201, vnbg_loss 0.64677, ema 0.73212, 127.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34015, wmdcmp 0.19035, oracc 0.98390, chxlmicf1 0.52094, chxlmacf1 0.47145, chxlacc 0.69293, chxlrocaucmic 0.76897, chxlrocaucmac 0.75084, qlmicf1 0.39601, qlmacf1 0.26366, ema 0.68182, 49.28 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 3/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.79122, a_loss 0.85381, cD 1.50985, wmdcmp 0.19614, oracc 0.98135, orien_loss 0.03215, chxlmicf1 0.53070, chxlmacf1 0.48123, chx_loss 0.86718, chxlacc 0.71801, chxlrocaucmic 0.80298, chxlrocaucmac 0.78370, qlmicf1 0.39939, qlmacf1 0.24409, ql_loss 0.74443, gacc 0.88745, gloss 0.26198, cxr14micf1 0.36512, cxr14macf1 0.35004, cxr14_loss 0.91558, vnbgmicf1 0.59792, vnbgmacf1 0.45950, vnbg_loss 0.65046, ema 0.73271, 129.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32703, wmdcmp 0.18858, oracc 0.98703, chxlmicf1 0.52047, chxlmacf1 0.46928, chxlacc 0.69988, chxlrocaucmic 0.76626, chxlrocaucmac 0.75110, qlmicf1 0.40205, qlmacf1 0.26588, ema 0.69455, 49.42 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-05.\n",
      "\u001b[1m---- Epoch 4/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.73383, a_loss 0.85908, cD 1.48693, wmdcmp 0.19314, oracc 0.98265, orien_loss 0.02251, chxlmicf1 0.52608, chxlmacf1 0.47735, chx_loss 0.86529, chxlacc 0.71441, chxlrocaucmic 0.80248, chxlrocaucmac 0.78330, qlmicf1 0.39934, qlmacf1 0.23982, ql_loss 0.73803, gacc 0.90582, gloss 0.23287, cxr14micf1 0.36915, cxr14macf1 0.35471, cxr14_loss 0.92143, vnbgmicf1 0.59130, vnbgmacf1 0.44984, vnbg_loss 0.65203, ema 0.73585, 139.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31408, wmdcmp 0.18560, oracc 0.98703, chxlmicf1 0.53156, chxlmacf1 0.47788, chxlacc 0.71697, chxlrocaucmic 0.76918, chxlrocaucmac 0.75545, qlmicf1 0.40329, qlmacf1 0.26771, ema 0.67091, 70.31 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[1m---- Epoch 5/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.38778, a_loss 0.87131, cD 1.48629, wmdcmp 0.19249, oracc 0.98057, orien_loss 0.03596, chxlmicf1 0.51655, chxlmacf1 0.46842, chx_loss 0.88567, chxlacc 0.70552, chxlrocaucmic 0.79302, chxlrocaucmac 0.77187, qlmicf1 0.39101, qlmacf1 0.22895, ql_loss 0.75235, gacc 0.90073, gloss 0.25664, cxr14micf1 0.34184, cxr14macf1 0.33699, cxr14_loss 0.95231, vnbgmicf1 0.58263, vnbgmacf1 0.45021, vnbg_loss 0.69276, ema 0.71792, 159.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37375, wmdcmp 0.19154, oracc 0.98703, chxlmicf1 0.52972, chxlmacf1 0.47767, chxlacc 0.67759, chxlrocaucmic 0.77720, chxlrocaucmac 0.75125, qlmicf1 0.41515, qlmacf1 0.26106, ema 0.67636, 54.95 secs\n",
      "Adjusting learning rate of group 0 to 9.0474e-05.\n",
      "\u001b[1m---- Epoch 6/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 1.36303, a_loss 0.86388, cD 1.48848, wmdcmp 0.19417, oracc 0.98147, orien_loss 0.03005, chxlmicf1 0.52293, chxlmacf1 0.47532, chx_loss 0.86983, chxlacc 0.70955, chxlrocaucmic 0.79894, chxlrocaucmac 0.77954, qlmicf1 0.39851, qlmacf1 0.23406, ql_loss 0.74524, gacc 0.92569, gloss 0.18869, cxr14micf1 0.36098, cxr14macf1 0.34784, cxr14_loss 0.91999, vnbgmicf1 0.59921, vnbgmacf1 0.45643, vnbg_loss 0.62854, ema 0.73056, 156.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36688, wmdcmp 0.19042, oracc 0.98703, chxlmicf1 0.51978, chxlmacf1 0.47387, chxlacc 0.68709, chxlrocaucmic 0.76923, chxlrocaucmac 0.75565, qlmicf1 0.39537, qlmacf1 0.25867, ema 0.67091, 74.08 secs\n",
      "Adjusting learning rate of group 0 to 8.1855e-05.\n",
      "\u001b[1m---- Epoch 7/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000082) ...\n",
      "loss 1.55900, a_loss 0.85499, cD 1.47766, wmdcmp 0.19266, oracc 0.98446, orien_loss 0.02706, chxlmicf1 0.52837, chxlmacf1 0.48022, chx_loss 0.85574, chxlacc 0.71556, chxlrocaucmic 0.80524, chxlrocaucmac 0.78617, qlmicf1 0.40156, qlmacf1 0.23462, ql_loss 0.74433, gacc 0.94109, gloss 0.14943, cxr14micf1 0.36378, cxr14macf1 0.35416, cxr14_loss 0.92852, vnbgmicf1 0.61958, vnbgmacf1 0.47576, vnbg_loss 0.60081, ema 0.73563, 170.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36264, wmdcmp 0.18917, oracc 0.98643, chxlmicf1 0.51982, chxlmacf1 0.47300, chxlacc 0.69023, chxlrocaucmic 0.76377, chxlrocaucmac 0.75067, qlmicf1 0.39361, qlmacf1 0.25849, ema 0.67182, 75.01 secs\n",
      "Adjusting learning rate of group 0 to 7.4057e-05.\n",
      "\u001b[1m---- Epoch 8/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000074) ...\n",
      "loss 4.31375, a_loss 0.86444, cD 1.47090, wmdcmp 0.19241, oracc 0.98369, orien_loss 0.02275, chxlmicf1 0.52931, chxlmacf1 0.48130, chx_loss 0.85673, chxlacc 0.71611, chxlrocaucmic 0.80614, chxlrocaucmac 0.78706, qlmicf1 0.39714, qlmacf1 0.23535, ql_loss 0.73990, gacc 0.94073, gloss 0.16012, cxr14micf1 0.38275, cxr14macf1 0.36556, cxr14_loss 0.90977, vnbgmicf1 0.62059, vnbgmacf1 0.48485, vnbg_loss 0.59574, ema 0.73338, 175.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32392, wmdcmp 0.18725, oracc 0.98911, chxlmicf1 0.53236, chxlmacf1 0.47824, chxlacc 0.69995, chxlrocaucmic 0.77597, chxlrocaucmac 0.75954, qlmicf1 0.39002, qlmacf1 0.26102, ema 0.66545, 76.98 secs\n",
      "Adjusting learning rate of group 0 to 6.7002e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 9/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 1.71595, a_loss 0.85891, cD 1.50262, wmdcmp 0.19627, oracc 0.98490, orien_loss 0.02355, chxlmicf1 0.53363, chxlmacf1 0.48581, chx_loss 0.84625, chxlacc 0.72183, chxlrocaucmic 0.80889, chxlrocaucmac 0.79175, qlmicf1 0.40316, qlmacf1 0.23569, ql_loss 0.73400, gacc 0.96200, gloss 0.10290, cxr14micf1 0.37618, cxr14macf1 0.36785, cxr14_loss 0.88409, vnbgmicf1 0.64186, vnbgmacf1 0.51387, vnbg_loss 0.54148, ema 0.74498, 174.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32691, wmdcmp 0.18663, oracc 0.98911, chxlmicf1 0.53118, chxlmacf1 0.47986, chxlacc 0.71663, chxlrocaucmic 0.77371, chxlrocaucmac 0.75991, qlmicf1 0.40830, qlmacf1 0.26616, ema 0.67364, 75.84 secs\n",
      "Adjusting learning rate of group 0 to 6.0619e-05.\n",
      "\u001b[1m---- Epoch 10/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 0.54901, a_loss 0.85705, cD 1.47189, wmdcmp 0.19326, oracc 0.98224, orien_loss 0.02460, chxlmicf1 0.53466, chxlmacf1 0.48589, chx_loss 0.84248, chxlacc 0.72426, chxlrocaucmic 0.81149, chxlrocaucmac 0.79514, qlmicf1 0.40985, qlmacf1 0.24323, ql_loss 0.73158, gacc 0.96309, gloss 0.10325, cxr14micf1 0.38924, cxr14macf1 0.37760, cxr14_loss 0.88600, vnbgmicf1 0.63952, vnbgmacf1 0.50826, vnbg_loss 0.54642, ema 0.74104, 171.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28581, wmdcmp 0.18291, oracc 0.98911, chxlmicf1 0.53806, chxlmacf1 0.48287, chxlacc 0.69979, chxlrocaucmic 0.78726, chxlrocaucmac 0.75847, qlmicf1 0.40517, qlmacf1 0.26227, ema 0.67455, 75.19 secs\n",
      "Adjusting learning rate of group 0 to 5.4844e-05.\n",
      "\u001b[1m---- Epoch 11/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000055) ...\n",
      "loss 3.91489, a_loss 0.85812, cD 1.49973, wmdcmp 0.19349, oracc 0.98391, orien_loss 0.01989, chxlmicf1 0.54079, chxlmacf1 0.49050, chx_loss 0.83510, chxlacc 0.72681, chxlrocaucmic 0.81461, chxlrocaucmac 0.79761, qlmicf1 0.41025, qlmacf1 0.24669, ql_loss 0.72634, gacc 0.96239, gloss 0.09795, cxr14micf1 0.38247, cxr14macf1 0.37286, cxr14_loss 0.86821, vnbgmicf1 0.66116, vnbgmacf1 0.53786, vnbg_loss 0.51576, ema 0.74788, 166.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37293, wmdcmp 0.19276, oracc 0.98911, chxlmicf1 0.53542, chxlmacf1 0.48365, chxlacc 0.70970, chxlrocaucmic 0.78007, chxlrocaucmac 0.76192, qlmicf1 0.42324, qlmacf1 0.26830, ema 0.68636, 73.73 secs\n",
      "Adjusting learning rate of group 0 to 4.9619e-05.\n",
      "\u001b[1m---- Epoch 12/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n",
      "loss 1.09514, a_loss 0.85300, cD 1.51103, wmdcmp 0.19727, oracc 0.98418, orien_loss 0.02005, chxlmicf1 0.54024, chxlmacf1 0.49143, chx_loss 0.83602, chxlacc 0.72749, chxlrocaucmic 0.81389, chxlrocaucmac 0.79852, qlmicf1 0.41253, qlmacf1 0.24355, ql_loss 0.72179, gacc 0.96345, gloss 0.09733, cxr14micf1 0.38534, cxr14macf1 0.38070, cxr14_loss 0.87955, vnbgmicf1 0.66767, vnbgmacf1 0.54038, vnbg_loss 0.50546, ema 0.74401, 167.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32485, wmdcmp 0.18837, oracc 0.98658, chxlmicf1 0.53933, chxlmacf1 0.48405, chxlacc 0.70512, chxlrocaucmic 0.78737, chxlrocaucmac 0.76692, qlmicf1 0.39200, qlmacf1 0.26688, ema 0.67727, 75.20 secs\n",
      "Adjusting learning rate of group 0 to 4.4893e-05.\n",
      "\u001b[1m---- Epoch 13/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 1.60523, a_loss 0.86332, cD 1.49741, wmdcmp 0.19567, oracc 0.98290, orien_loss 0.01658, chxlmicf1 0.54241, chxlmacf1 0.49412, chx_loss 0.82488, chxlacc 0.73027, chxlrocaucmic 0.81810, chxlrocaucmac 0.80342, qlmicf1 0.41840, qlmacf1 0.25787, ql_loss 0.71605, gacc 0.96495, gloss 0.09761, cxr14micf1 0.40087, cxr14macf1 0.38996, cxr14_loss 0.85152, vnbgmicf1 0.67721, vnbgmacf1 0.55004, vnbg_loss 0.48590, ema 0.74996, 168.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36895, wmdcmp 0.19294, oracc 0.98703, chxlmicf1 0.54162, chxlmacf1 0.48363, chxlacc 0.70535, chxlrocaucmic 0.79012, chxlrocaucmac 0.76607, qlmicf1 0.43610, qlmacf1 0.27123, ema 0.67727, 75.35 secs\n",
      "Adjusting learning rate of group 0 to 4.0616e-05.\n",
      "\u001b[1m---- Epoch 14/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 1.00246, a_loss 0.83998, cD 1.53857, wmdcmp 0.20018, oracc 0.98410, orien_loss 0.02016, chxlmicf1 0.55054, chxlmacf1 0.50096, chx_loss 0.82080, chxlacc 0.73626, chxlrocaucmic 0.82189, chxlrocaucmac 0.80639, qlmicf1 0.42432, qlmacf1 0.25618, ql_loss 0.71129, gacc 0.96655, gloss 0.08501, cxr14micf1 0.40492, cxr14macf1 0.39540, cxr14_loss 0.83856, vnbgmicf1 0.68291, vnbgmacf1 0.56498, vnbg_loss 0.47639, ema 0.75541, 169.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33641, wmdcmp 0.18963, oracc 0.98911, chxlmicf1 0.53999, chxlmacf1 0.48168, chxlacc 0.69989, chxlrocaucmic 0.78749, chxlrocaucmac 0.76327, qlmicf1 0.40468, qlmacf1 0.26863, ema 0.67091, 74.77 secs\n",
      "Adjusting learning rate of group 0 to 3.6747e-05.\n",
      "\u001b[1m---- Epoch 15/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 3.97888, a_loss 0.84789, cD 1.51477, wmdcmp 0.19669, oracc 0.98445, orien_loss 0.01371, chxlmicf1 0.55133, chxlmacf1 0.50111, chx_loss 0.81241, chxlacc 0.73662, chxlrocaucmic 0.82409, chxlrocaucmac 0.80762, qlmicf1 0.41985, qlmacf1 0.25096, ql_loss 0.71384, gacc 0.97182, gloss 0.07120, cxr14micf1 0.40118, cxr14macf1 0.39724, cxr14_loss 0.85257, vnbgmicf1 0.69364, vnbgmacf1 0.58761, vnbg_loss 0.45157, ema 0.75156, 168.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37577, wmdcmp 0.19321, oracc 0.98911, chxlmicf1 0.54266, chxlmacf1 0.48398, chxlacc 0.70879, chxlrocaucmic 0.78361, chxlrocaucmac 0.76236, qlmicf1 0.40613, qlmacf1 0.26853, ema 0.68000, 76.68 secs\n",
      "Adjusting learning rate of group 0 to 3.3246e-05.\n",
      "\u001b[1m---- Epoch 16/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 3.15537, a_loss 0.84906, cD 1.52101, wmdcmp 0.19885, oracc 0.98459, orien_loss 0.01605, chxlmicf1 0.55116, chxlmacf1 0.50197, chx_loss 0.81409, chxlacc 0.73668, chxlrocaucmic 0.82349, chxlrocaucmac 0.80853, qlmicf1 0.42401, qlmacf1 0.25942, ql_loss 0.70961, gacc 0.97455, gloss 0.07191, cxr14micf1 0.41014, cxr14macf1 0.40581, cxr14_loss 0.83944, vnbgmicf1 0.69593, vnbgmacf1 0.58991, vnbg_loss 0.44862, ema 0.74662, 171.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37576, wmdcmp 0.19448, oracc 0.98911, chxlmicf1 0.54784, chxlmacf1 0.48589, chxlacc 0.71868, chxlrocaucmic 0.79420, chxlrocaucmac 0.76484, qlmicf1 0.40769, qlmacf1 0.26869, ema 0.68818, 74.37 secs\n",
      "Adjusting learning rate of group 0 to 3.0079e-05.\n",
      "\u001b[1m---- Epoch 17/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 1.59548, a_loss 0.84345, cD 1.51758, wmdcmp 0.19739, oracc 0.98433, orien_loss 0.01685, chxlmicf1 0.55342, chxlmacf1 0.50335, chx_loss 0.81113, chxlacc 0.73955, chxlrocaucmic 0.82473, chxlrocaucmac 0.81225, qlmicf1 0.42389, qlmacf1 0.25036, ql_loss 0.71068, gacc 0.97564, gloss 0.06765, cxr14micf1 0.40727, cxr14macf1 0.40094, cxr14_loss 0.83892, vnbgmicf1 0.70879, vnbgmacf1 0.61200, vnbg_loss 0.43001, ema 0.75637, 176.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36373, wmdcmp 0.19210, oracc 0.98911, chxlmicf1 0.53323, chxlmacf1 0.47670, chxlacc 0.70558, chxlrocaucmic 0.78662, chxlrocaucmac 0.76147, qlmicf1 0.39562, qlmacf1 0.26503, ema 0.68364, 76.31 secs\n",
      "Adjusting learning rate of group 0 to 2.7213e-05.\n",
      "\u001b[1m---- Epoch 18/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.19263, a_loss 0.85245, cD 1.51564, wmdcmp 0.19695, oracc 0.98472, orien_loss 0.01437, chxlmicf1 0.55444, chxlmacf1 0.50453, chx_loss 0.80447, chxlacc 0.73981, chxlrocaucmic 0.82662, chxlrocaucmac 0.81328, qlmicf1 0.42983, qlmacf1 0.26187, ql_loss 0.70442, gacc 0.97431, gloss 0.07913, cxr14micf1 0.41050, cxr14macf1 0.40817, cxr14_loss 0.84441, vnbgmicf1 0.71535, vnbgmacf1 0.61347, vnbg_loss 0.42434, ema 0.75435, 167.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33782, wmdcmp 0.18991, oracc 0.98911, chxlmicf1 0.54163, chxlmacf1 0.48159, chxlacc 0.71621, chxlrocaucmic 0.78935, chxlrocaucmac 0.76183, qlmicf1 0.42291, qlmacf1 0.26936, ema 0.68273, 74.93 secs\n",
      "Adjusting learning rate of group 0 to 2.4621e-05.\n",
      "\u001b[1m---- Epoch 19/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 1.14664, a_loss 0.84653, cD 1.50823, wmdcmp 0.19663, oracc 0.98532, orien_loss 0.01422, chxlmicf1 0.55968, chxlmacf1 0.50895, chx_loss 0.79440, chxlacc 0.74467, chxlrocaucmic 0.83050, chxlrocaucmac 0.81640, qlmicf1 0.42611, qlmacf1 0.26618, ql_loss 0.70166, gacc 0.97618, gloss 0.06801, cxr14micf1 0.40824, cxr14macf1 0.40623, cxr14_loss 0.85017, vnbgmicf1 0.71587, vnbgmacf1 0.61495, vnbg_loss 0.40427, ema 0.76045, 172.46 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.32726, wmdcmp 0.18763, oracc 0.98643, chxlmicf1 0.54467, chxlmacf1 0.48598, chxlacc 0.72856, chxlrocaucmic 0.78454, chxlrocaucmac 0.76395, qlmicf1 0.41882, qlmacf1 0.27036, ema 0.69000, 76.34 secs\n",
      "Adjusting learning rate of group 0 to 2.2275e-05.\n",
      "\u001b[1m---- Epoch 20/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.56826, a_loss 0.83652, cD 1.53054, wmdcmp 0.20061, oracc 0.98569, orien_loss 0.01214, chxlmicf1 0.55622, chxlmacf1 0.50615, chx_loss 0.80177, chxlacc 0.74203, chxlrocaucmic 0.82798, chxlrocaucmac 0.81531, qlmicf1 0.43113, qlmacf1 0.26246, ql_loss 0.69984, gacc 0.97582, gloss 0.06832, cxr14micf1 0.41614, cxr14macf1 0.41672, cxr14_loss 0.83050, vnbgmicf1 0.72365, vnbgmacf1 0.63663, vnbg_loss 0.40020, ema 0.76563, 175.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32697, wmdcmp 0.18828, oracc 0.98911, chxlmicf1 0.55287, chxlmacf1 0.49021, chxlacc 0.71454, chxlrocaucmic 0.79933, chxlrocaucmac 0.76959, qlmicf1 0.42243, qlmacf1 0.26621, ema 0.68818, 74.88 secs\n",
      "Adjusting learning rate of group 0 to 2.0153e-05.\n",
      "\u001b[1m---- Epoch 21/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 4.09849, a_loss 0.84152, cD 1.51081, wmdcmp 0.19706, oracc 0.98770, orien_loss 0.01268, chxlmicf1 0.55887, chxlmacf1 0.50835, chx_loss 0.79327, chxlacc 0.74481, chxlrocaucmic 0.83179, chxlrocaucmac 0.81854, qlmicf1 0.43407, qlmacf1 0.26312, ql_loss 0.69326, gacc 0.97618, gloss 0.06834, cxr14micf1 0.41367, cxr14macf1 0.41416, cxr14_loss 0.82994, vnbgmicf1 0.72692, vnbgmacf1 0.63237, vnbg_loss 0.38742, ema 0.76097, 170.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37727, wmdcmp 0.19327, oracc 0.98911, chxlmicf1 0.55024, chxlmacf1 0.48630, chxlacc 0.72696, chxlrocaucmic 0.79581, chxlrocaucmac 0.76785, qlmicf1 0.42727, qlmacf1 0.27180, ema 0.68455, 74.55 secs\n",
      "Adjusting learning rate of group 0 to 1.8233e-05.\n",
      "\u001b[1m---- Epoch 22/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.42968, a_loss 0.85391, cD 1.53382, wmdcmp 0.19809, oracc 0.98515, orien_loss 0.01295, chxlmicf1 0.56336, chxlmacf1 0.51226, chx_loss 0.78837, chxlacc 0.74794, chxlrocaucmic 0.83350, chxlrocaucmac 0.82032, qlmicf1 0.43350, qlmacf1 0.26240, ql_loss 0.69589, gacc 0.97963, gloss 0.05832, cxr14micf1 0.42418, cxr14macf1 0.42276, cxr14_loss 0.81099, vnbgmicf1 0.73850, vnbgmacf1 0.64557, vnbg_loss 0.38152, ema 0.76208, 175.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35055, wmdcmp 0.19077, oracc 0.98643, chxlmicf1 0.53907, chxlmacf1 0.48601, chxlacc 0.71313, chxlrocaucmic 0.78789, chxlrocaucmac 0.76929, qlmicf1 0.41524, qlmacf1 0.27042, ema 0.69182, 74.42 secs\n",
      "Adjusting learning rate of group 0 to 1.6496e-05.\n",
      "\u001b[1m---- Epoch 23/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 1.02227, a_loss 0.84750, cD 1.52560, wmdcmp 0.19751, oracc 0.98589, orien_loss 0.01326, chxlmicf1 0.56243, chxlmacf1 0.51312, chx_loss 0.78615, chxlacc 0.74706, chxlrocaucmic 0.83339, chxlrocaucmac 0.82136, qlmicf1 0.43916, qlmacf1 0.26283, ql_loss 0.68885, gacc 0.97709, gloss 0.06213, cxr14micf1 0.41920, cxr14macf1 0.41741, cxr14_loss 0.82161, vnbgmicf1 0.73574, vnbgmacf1 0.64354, vnbg_loss 0.38666, ema 0.76171, 175.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32906, wmdcmp 0.18855, oracc 0.98911, chxlmicf1 0.55152, chxlmacf1 0.49023, chxlacc 0.72100, chxlrocaucmic 0.79251, chxlrocaucmac 0.77001, qlmicf1 0.42366, qlmacf1 0.27164, ema 0.69000, 74.67 secs\n",
      "Adjusting learning rate of group 0 to 1.4925e-05.\n",
      "\u001b[1m---- Epoch 24/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.38866, a_loss 0.83239, cD 1.54042, wmdcmp 0.19987, oracc 0.98720, orien_loss 0.01085, chxlmicf1 0.56426, chxlmacf1 0.51529, chx_loss 0.78126, chxlacc 0.74948, chxlrocaucmic 0.83471, chxlrocaucmac 0.82358, qlmicf1 0.43602, qlmacf1 0.25842, ql_loss 0.68526, gacc 0.97636, gloss 0.05858, cxr14micf1 0.42054, cxr14macf1 0.42246, cxr14_loss 0.81578, vnbgmicf1 0.73980, vnbgmacf1 0.65752, vnbg_loss 0.36569, ema 0.76415, 173.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35428, wmdcmp 0.19000, oracc 0.98911, chxlmicf1 0.54924, chxlmacf1 0.49007, chxlacc 0.72549, chxlrocaucmic 0.79184, chxlrocaucmac 0.76793, qlmicf1 0.42691, qlmacf1 0.27179, ema 0.68000, 74.44 secs\n",
      "Adjusting learning rate of group 0 to 1.3503e-05.\n",
      "\u001b[1m---- Epoch 25/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.72989, a_loss 0.84366, cD 1.54611, wmdcmp 0.20297, oracc 0.98596, orien_loss 0.01357, chxlmicf1 0.56655, chxlmacf1 0.51707, chx_loss 0.78065, chxlacc 0.74938, chxlrocaucmic 0.83508, chxlrocaucmac 0.82197, qlmicf1 0.44028, qlmacf1 0.28132, ql_loss 0.69183, gacc 0.97963, gloss 0.05580, cxr14micf1 0.42967, cxr14macf1 0.43173, cxr14_loss 0.79978, vnbgmicf1 0.75048, vnbgmacf1 0.66883, vnbg_loss 0.35671, ema 0.76721, 175.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34453, wmdcmp 0.18896, oracc 0.98911, chxlmicf1 0.54739, chxlmacf1 0.48951, chxlacc 0.71647, chxlrocaucmic 0.79341, chxlrocaucmac 0.77056, qlmicf1 0.42550, qlmacf1 0.27502, ema 0.69091, 75.53 secs\n",
      "Adjusting learning rate of group 0 to 1.2217e-05.\n",
      "\u001b[1m---- Epoch 26/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.41671, a_loss 0.84004, cD 1.54504, wmdcmp 0.20092, oracc 0.98457, orien_loss 0.01400, chxlmicf1 0.56780, chxlmacf1 0.51922, chx_loss 0.77523, chxlacc 0.75180, chxlrocaucmic 0.83748, chxlrocaucmac 0.82639, qlmicf1 0.44245, qlmacf1 0.27973, ql_loss 0.68721, gacc 0.98145, gloss 0.05866, cxr14micf1 0.42390, cxr14macf1 0.42694, cxr14_loss 0.80633, vnbgmicf1 0.74603, vnbgmacf1 0.67441, vnbg_loss 0.35853, ema 0.76602, 171.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33142, wmdcmp 0.18889, oracc 0.98911, chxlmicf1 0.55343, chxlmacf1 0.49022, chxlacc 0.72866, chxlrocaucmic 0.79611, chxlrocaucmac 0.76835, qlmicf1 0.42897, qlmacf1 0.27700, ema 0.69636, 74.64 secs\n",
      "Adjusting learning rate of group 0 to 1.1053e-05.\n",
      "\u001b[1m---- Epoch 27/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.34395, a_loss 0.83577, cD 1.54040, wmdcmp 0.19984, oracc 0.98401, orien_loss 0.01406, chxlmicf1 0.56902, chxlmacf1 0.51917, chx_loss 0.77463, chxlacc 0.75182, chxlrocaucmic 0.83858, chxlrocaucmac 0.82605, qlmicf1 0.44660, qlmacf1 0.26996, ql_loss 0.68232, gacc 0.98091, gloss 0.05491, cxr14micf1 0.41999, cxr14macf1 0.42192, cxr14_loss 0.80773, vnbgmicf1 0.74972, vnbgmacf1 0.67640, vnbg_loss 0.35753, ema 0.77185, 173.67 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33555, wmdcmp 0.18891, oracc 0.98911, chxlmicf1 0.54806, chxlmacf1 0.49095, chxlacc 0.72526, chxlrocaucmic 0.79186, chxlrocaucmac 0.76849, qlmicf1 0.43138, qlmacf1 0.27376, ema 0.68909, 75.06 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 28/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.82082, a_loss 0.84858, cD 1.52446, wmdcmp 0.19926, oracc 0.98597, orien_loss 0.01418, chxlmicf1 0.56548, chxlmacf1 0.51563, chx_loss 0.78132, chxlacc 0.75226, chxlrocaucmic 0.83626, chxlrocaucmac 0.82532, qlmicf1 0.44074, qlmacf1 0.26504, ql_loss 0.68085, gacc 0.98218, gloss 0.05093, cxr14micf1 0.42550, cxr14macf1 0.42907, cxr14_loss 0.79642, vnbgmicf1 0.75721, vnbgmacf1 0.67753, vnbg_loss 0.34460, ema 0.76320, 173.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35344, wmdcmp 0.19126, oracc 0.98911, chxlmicf1 0.55135, chxlmacf1 0.49113, chxlacc 0.72323, chxlrocaucmic 0.79449, chxlrocaucmac 0.76772, qlmicf1 0.43051, qlmacf1 0.27637, ema 0.68273, 74.80 secs\n",
      "Adjusting learning rate of group 0 to 9.0474e-06.\n",
      "\u001b[1m---- Epoch 29/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.66202, a_loss 0.83977, cD 1.55358, wmdcmp 0.20182, oracc 0.98480, orien_loss 0.01658, chxlmicf1 0.56982, chxlmacf1 0.52038, chx_loss 0.77392, chxlacc 0.75308, chxlrocaucmic 0.83794, chxlrocaucmac 0.82792, qlmicf1 0.44293, qlmacf1 0.28285, ql_loss 0.68282, gacc 0.98220, gloss 0.05469, cxr14micf1 0.42674, cxr14macf1 0.43063, cxr14_loss 0.81210, vnbgmicf1 0.75727, vnbgmacf1 0.68296, vnbg_loss 0.34364, ema 0.77428, 178.60 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34240, wmdcmp 0.19105, oracc 0.98911, chxlmicf1 0.55209, chxlmacf1 0.49185, chxlacc 0.72093, chxlrocaucmic 0.79494, chxlrocaucmac 0.76784, qlmicf1 0.42978, qlmacf1 0.27402, ema 0.69000, 76.61 secs\n",
      "Adjusting learning rate of group 0 to 8.1855e-06.\n",
      "\u001b[1m---- Epoch 30/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.00914, a_loss 0.83851, cD 1.56192, wmdcmp 0.20325, oracc 0.98679, orien_loss 0.01271, chxlmicf1 0.57094, chxlmacf1 0.52219, chx_loss 0.76237, chxlacc 0.75429, chxlrocaucmic 0.84198, chxlrocaucmac 0.83118, qlmicf1 0.44532, qlmacf1 0.27472, ql_loss 0.68252, gacc 0.98273, gloss 0.05275, cxr14micf1 0.42454, cxr14macf1 0.42369, cxr14_loss 0.81071, vnbgmicf1 0.76223, vnbgmacf1 0.69796, vnbg_loss 0.34200, ema 0.76644, 174.81 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.34797, wmdcmp 0.19036, oracc 0.98911, chxlmicf1 0.55427, chxlmacf1 0.49080, chxlacc 0.72553, chxlrocaucmic 0.79688, chxlrocaucmac 0.76895, qlmicf1 0.42393, qlmacf1 0.27239, ema 0.68273, 75.71 secs\n",
      "Adjusting learning rate of group 0 to 7.4057e-06.\n",
      "\u001b[1m---- Epoch 31/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.10182, a_loss 0.84319, cD 1.52544, wmdcmp 0.19872, oracc 0.98536, orien_loss 0.01048, chxlmicf1 0.57811, chxlmacf1 0.52875, chx_loss 0.75950, chxlacc 0.75909, chxlrocaucmic 0.84613, chxlrocaucmac 0.83371, qlmicf1 0.44549, qlmacf1 0.27250, ql_loss 0.68111, gacc 0.98349, gloss 0.04730, cxr14micf1 0.42409, cxr14macf1 0.42943, cxr14_loss 0.80098, vnbgmicf1 0.76507, vnbgmacf1 0.69509, vnbg_loss 0.33436, ema 0.77071, 176.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34501, wmdcmp 0.19012, oracc 0.98911, chxlmicf1 0.55554, chxlmacf1 0.49287, chxlacc 0.72796, chxlrocaucmic 0.79613, chxlrocaucmac 0.76903, qlmicf1 0.42714, qlmacf1 0.27200, ema 0.69182, 76.51 secs\n",
      "Adjusting learning rate of group 0 to 6.7002e-06.\n",
      "\u001b[1m---- Epoch 32/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.08700, a_loss 0.83974, cD 1.52408, wmdcmp 0.19812, oracc 0.98591, orien_loss 0.00971, chxlmicf1 0.57270, chxlmacf1 0.52354, chx_loss 0.76668, chxlacc 0.75645, chxlrocaucmic 0.84011, chxlrocaucmac 0.82950, qlmicf1 0.44009, qlmacf1 0.27927, ql_loss 0.68478, gacc 0.98382, gloss 0.04970, cxr14micf1 0.43164, cxr14macf1 0.43421, cxr14_loss 0.78961, vnbgmicf1 0.76835, vnbgmacf1 0.70660, vnbg_loss 0.33766, ema 0.76840, 175.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35763, wmdcmp 0.19163, oracc 0.98911, chxlmicf1 0.56347, chxlmacf1 0.49654, chxlacc 0.72779, chxlrocaucmic 0.80158, chxlrocaucmac 0.76903, qlmicf1 0.42894, qlmacf1 0.27475, ema 0.68182, 74.83 secs\n",
      "Adjusting learning rate of group 0 to 6.0619e-06.\n",
      "\u001b[1m---- Epoch 33/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.48943, a_loss 0.84113, cD 1.53413, wmdcmp 0.19910, oracc 0.98652, orien_loss 0.01198, chxlmicf1 0.57605, chxlmacf1 0.52640, chx_loss 0.75876, chxlacc 0.75799, chxlrocaucmic 0.84456, chxlrocaucmac 0.83449, qlmicf1 0.44566, qlmacf1 0.27575, ql_loss 0.68048, gacc 0.98091, gloss 0.05646, cxr14micf1 0.42850, cxr14macf1 0.43471, cxr14_loss 0.79991, vnbgmicf1 0.77030, vnbgmacf1 0.70232, vnbg_loss 0.32924, ema 0.77078, 175.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36289, wmdcmp 0.19226, oracc 0.98911, chxlmicf1 0.55689, chxlmacf1 0.49203, chxlacc 0.72745, chxlrocaucmic 0.79852, chxlrocaucmac 0.76813, qlmicf1 0.42747, qlmacf1 0.27442, ema 0.68636, 75.12 secs\n",
      "Adjusting learning rate of group 0 to 5.4844e-06.\n",
      "\u001b[1m---- Epoch 34/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.29423, a_loss 0.83411, cD 1.55458, wmdcmp 0.20174, oracc 0.98483, orien_loss 0.01310, chxlmicf1 0.57691, chxlmacf1 0.52671, chx_loss 0.75821, chxlacc 0.75782, chxlrocaucmic 0.84404, chxlrocaucmac 0.83256, qlmicf1 0.44641, qlmacf1 0.27408, ql_loss 0.67336, gacc 0.98255, gloss 0.04653, cxr14micf1 0.42753, cxr14macf1 0.43505, cxr14_loss 0.79757, vnbgmicf1 0.77058, vnbgmacf1 0.70143, vnbg_loss 0.33054, ema 0.77407, 173.67 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36345, wmdcmp 0.19223, oracc 0.98911, chxlmicf1 0.55755, chxlmacf1 0.49434, chxlacc 0.72913, chxlrocaucmic 0.79577, chxlrocaucmac 0.76799, qlmicf1 0.42794, qlmacf1 0.27444, ema 0.68455, 74.76 secs\n",
      "Adjusting learning rate of group 0 to 4.9619e-06.\n",
      "\u001b[1m---- Epoch 35/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.90803, a_loss 0.83810, cD 1.51226, wmdcmp 0.19851, oracc 0.98461, orien_loss 0.00978, chxlmicf1 0.57748, chxlmacf1 0.52850, chx_loss 0.75657, chxlacc 0.75941, chxlrocaucmic 0.84452, chxlrocaucmac 0.83393, qlmicf1 0.44881, qlmacf1 0.27579, ql_loss 0.67221, gacc 0.98257, gloss 0.05134, cxr14micf1 0.43665, cxr14macf1 0.44018, cxr14_loss 0.79148, vnbgmicf1 0.77327, vnbgmacf1 0.70740, vnbg_loss 0.31436, ema 0.77167, 175.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36206, wmdcmp 0.19273, oracc 0.98911, chxlmicf1 0.55087, chxlmacf1 0.48929, chxlacc 0.72342, chxlrocaucmic 0.79488, chxlrocaucmac 0.76916, qlmicf1 0.42857, qlmacf1 0.27494, ema 0.68909, 75.01 secs\n",
      "Adjusting learning rate of group 0 to 4.4893e-06.\n",
      "\u001b[1m---- Epoch 36/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.06958, a_loss 0.83545, cD 1.56170, wmdcmp 0.20269, oracc 0.98610, orien_loss 0.01023, chxlmicf1 0.57670, chxlmacf1 0.52780, chx_loss 0.75791, chxlacc 0.75848, chxlrocaucmic 0.84353, chxlrocaucmac 0.83351, qlmicf1 0.44999, qlmacf1 0.28044, ql_loss 0.67237, gacc 0.98618, gloss 0.04160, cxr14micf1 0.44251, cxr14macf1 0.44771, cxr14_loss 0.78156, vnbgmicf1 0.77169, vnbgmacf1 0.70694, vnbg_loss 0.31515, ema 0.77234, 174.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36547, wmdcmp 0.19274, oracc 0.98911, chxlmicf1 0.56349, chxlmacf1 0.49674, chxlacc 0.73451, chxlrocaucmic 0.79940, chxlrocaucmac 0.77013, qlmicf1 0.42951, qlmacf1 0.27203, ema 0.69182, 74.81 secs\n",
      "Adjusting learning rate of group 0 to 4.0616e-06.\n",
      "\u001b[1m---- Epoch 37/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.51834, a_loss 0.83483, cD 1.52262, wmdcmp 0.19866, oracc 0.98488, orien_loss 0.01049, chxlmicf1 0.57818, chxlmacf1 0.52918, chx_loss 0.75027, chxlacc 0.76026, chxlrocaucmic 0.84650, chxlrocaucmac 0.83674, qlmicf1 0.45086, qlmacf1 0.27684, ql_loss 0.67645, gacc 0.98127, gloss 0.04855, cxr14micf1 0.43364, cxr14macf1 0.43968, cxr14_loss 0.78117, vnbgmicf1 0.77613, vnbgmacf1 0.70808, vnbg_loss 0.31607, ema 0.77141, 175.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36736, wmdcmp 0.19258, oracc 0.98911, chxlmicf1 0.55650, chxlmacf1 0.49115, chxlacc 0.73200, chxlrocaucmic 0.79741, chxlrocaucmac 0.76949, qlmicf1 0.42799, qlmacf1 0.27471, ema 0.68455, 73.71 secs\n",
      "Adjusting learning rate of group 0 to 3.6747e-06.\n",
      "\u001b[1m---- Epoch 38/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.93049, a_loss 0.82955, cD 1.55510, wmdcmp 0.20305, oracc 0.98592, orien_loss 0.01214, chxlmicf1 0.57820, chxlmacf1 0.52972, chx_loss 0.75500, chxlacc 0.75996, chxlrocaucmic 0.84514, chxlrocaucmac 0.83399, qlmicf1 0.44989, qlmacf1 0.27832, ql_loss 0.67339, gacc 0.98422, gloss 0.04287, cxr14micf1 0.43861, cxr14macf1 0.44616, cxr14_loss 0.78668, vnbgmicf1 0.77524, vnbgmacf1 0.70829, vnbg_loss 0.32084, ema 0.77078, 173.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35865, wmdcmp 0.19221, oracc 0.98911, chxlmicf1 0.56202, chxlmacf1 0.49646, chxlacc 0.73574, chxlrocaucmic 0.79988, chxlrocaucmac 0.77013, qlmicf1 0.43309, qlmacf1 0.27621, ema 0.69091, 74.87 secs\n",
      "Adjusting learning rate of group 0 to 3.3246e-06.\n",
      "\u001b[1m---- Epoch 39/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.99564, a_loss 0.83918, cD 1.51798, wmdcmp 0.19703, oracc 0.98497, orien_loss 0.01032, chxlmicf1 0.57759, chxlmacf1 0.52786, chx_loss 0.75000, chxlacc 0.76127, chxlrocaucmic 0.84727, chxlrocaucmac 0.83642, qlmicf1 0.44867, qlmacf1 0.28392, ql_loss 0.67040, gacc 0.98527, gloss 0.04383, cxr14micf1 0.44546, cxr14macf1 0.45042, cxr14_loss 0.77019, vnbgmicf1 0.77306, vnbgmacf1 0.71250, vnbg_loss 0.32054, ema 0.77160, 175.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36645, wmdcmp 0.19256, oracc 0.98911, chxlmicf1 0.55637, chxlmacf1 0.49306, chxlacc 0.73183, chxlrocaucmic 0.79784, chxlrocaucmac 0.77007, qlmicf1 0.42827, qlmacf1 0.27576, ema 0.68545, 75.31 secs\n",
      "Adjusting learning rate of group 0 to 3.0079e-06.\n",
      "\u001b[1m---- Epoch 40/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.54853, a_loss 0.83474, cD 1.54339, wmdcmp 0.19887, oracc 0.98497, orien_loss 0.00961, chxlmicf1 0.57750, chxlmacf1 0.52828, chx_loss 0.75597, chxlacc 0.76008, chxlrocaucmic 0.84483, chxlrocaucmac 0.83391, qlmicf1 0.44664, qlmacf1 0.28084, ql_loss 0.67311, gacc 0.98527, gloss 0.04322, cxr14micf1 0.44158, cxr14macf1 0.44659, cxr14_loss 0.76900, vnbgmicf1 0.78238, vnbgmacf1 0.72668, vnbg_loss 0.30782, ema 0.77252, 173.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36144, wmdcmp 0.19246, oracc 0.98911, chxlmicf1 0.55924, chxlmacf1 0.49601, chxlacc 0.73048, chxlrocaucmic 0.79909, chxlrocaucmac 0.77066, qlmicf1 0.42999, qlmacf1 0.27379, ema 0.68818, 75.05 secs\n",
      "Adjusting learning rate of group 0 to 2.7213e-06.\n",
      "\u001b[1m---- Epoch 41/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.95322, a_loss 0.84103, cD 1.53474, wmdcmp 0.19928, oracc 0.98638, orien_loss 0.00998, chxlmicf1 0.58160, chxlmacf1 0.53323, chx_loss 0.74982, chxlacc 0.76308, chxlrocaucmic 0.84679, chxlrocaucmac 0.83720, qlmicf1 0.44940, qlmacf1 0.27740, ql_loss 0.67163, gacc 0.98436, gloss 0.05033, cxr14micf1 0.43958, cxr14macf1 0.44712, cxr14_loss 0.75611, vnbgmicf1 0.78213, vnbgmacf1 0.72491, vnbg_loss 0.30829, ema 0.77822, 178.98 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.36369, wmdcmp 0.19260, oracc 0.98911, chxlmicf1 0.55647, chxlmacf1 0.49440, chxlacc 0.72916, chxlrocaucmic 0.79805, chxlrocaucmac 0.77090, qlmicf1 0.42963, qlmacf1 0.27442, ema 0.68636, 74.09 secs\n",
      "Adjusting learning rate of group 0 to 2.4621e-06.\n",
      "\u001b[1m---- Epoch 42/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.02598, a_loss 0.83079, cD 1.54336, wmdcmp 0.19934, oracc 0.98699, orien_loss 0.00875, chxlmicf1 0.57961, chxlmacf1 0.52989, chx_loss 0.75106, chxlacc 0.76079, chxlrocaucmic 0.84636, chxlrocaucmac 0.83696, qlmicf1 0.45009, qlmacf1 0.27771, ql_loss 0.67344, gacc 0.98727, gloss 0.04011, cxr14micf1 0.43888, cxr14macf1 0.44509, cxr14_loss 0.76569, vnbgmicf1 0.78296, vnbgmacf1 0.73310, vnbg_loss 0.30811, ema 0.77926, 178.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36060, wmdcmp 0.19247, oracc 0.98911, chxlmicf1 0.55733, chxlmacf1 0.49314, chxlacc 0.73409, chxlrocaucmic 0.79844, chxlrocaucmac 0.77037, qlmicf1 0.43303, qlmacf1 0.27621, ema 0.68545, 74.36 secs\n",
      "Adjusting learning rate of group 0 to 2.2275e-06.\n",
      "\u001b[1m---- Epoch 43/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.28686, a_loss 0.83246, cD 1.56235, wmdcmp 0.20242, oracc 0.98591, orien_loss 0.01039, chxlmicf1 0.58137, chxlmacf1 0.53216, chx_loss 0.74831, chxlacc 0.76207, chxlrocaucmic 0.84723, chxlrocaucmac 0.83823, qlmicf1 0.44835, qlmacf1 0.28286, ql_loss 0.66538, gacc 0.98327, gloss 0.04554, cxr14micf1 0.44328, cxr14macf1 0.44839, cxr14_loss 0.76420, vnbgmicf1 0.78178, vnbgmacf1 0.72272, vnbg_loss 0.30888, ema 0.77576, 183.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36271, wmdcmp 0.19253, oracc 0.98911, chxlmicf1 0.56171, chxlmacf1 0.49705, chxlacc 0.73309, chxlrocaucmic 0.79991, chxlrocaucmac 0.77083, qlmicf1 0.43730, qlmacf1 0.27608, ema 0.69091, 74.70 secs\n",
      "Adjusting learning rate of group 0 to 2.0153e-06.\n",
      "\u001b[1m---- Epoch 44/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.44887, a_loss 0.82985, cD 1.52968, wmdcmp 0.19845, oracc 0.98581, orien_loss 0.01036, chxlmicf1 0.57921, chxlmacf1 0.53064, chx_loss 0.74966, chxlacc 0.76224, chxlrocaucmic 0.84799, chxlrocaucmac 0.83709, qlmicf1 0.45069, qlmacf1 0.28560, ql_loss 0.66927, gacc 0.98255, gloss 0.05137, cxr14micf1 0.44114, cxr14macf1 0.44754, cxr14_loss 0.76724, vnbgmicf1 0.78138, vnbgmacf1 0.71748, vnbg_loss 0.30755, ema 0.77163, 177.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36771, wmdcmp 0.19258, oracc 0.98911, chxlmicf1 0.55732, chxlmacf1 0.49238, chxlacc 0.73230, chxlrocaucmic 0.79869, chxlrocaucmac 0.77034, qlmicf1 0.43521, qlmacf1 0.27464, ema 0.69000, 74.44 secs\n",
      "Adjusting learning rate of group 0 to 1.8233e-06.\n",
      "\u001b[1m---- Epoch 45/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.05475, a_loss 0.83641, cD 1.54422, wmdcmp 0.20088, oracc 0.98551, orien_loss 0.01077, chxlmicf1 0.57790, chxlmacf1 0.53019, chx_loss 0.75432, chxlacc 0.75970, chxlrocaucmic 0.84529, chxlrocaucmac 0.83476, qlmicf1 0.44868, qlmacf1 0.28091, ql_loss 0.67080, gacc 0.98312, gloss 0.04136, cxr14micf1 0.43364, cxr14macf1 0.43985, cxr14_loss 0.78126, vnbgmicf1 0.78629, vnbgmacf1 0.72778, vnbg_loss 0.30916, ema 0.77338, 175.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36405, wmdcmp 0.19242, oracc 0.98911, chxlmicf1 0.55737, chxlmacf1 0.49420, chxlacc 0.72966, chxlrocaucmic 0.79875, chxlrocaucmac 0.77091, qlmicf1 0.42994, qlmacf1 0.27366, ema 0.68909, 75.27 secs\n",
      "Adjusting learning rate of group 0 to 1.6496e-06.\n",
      "\u001b[1m---- Epoch 46/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.99244, a_loss 0.83794, cD 1.56849, wmdcmp 0.20265, oracc 0.98543, orien_loss 0.01181, chxlmicf1 0.57928, chxlmacf1 0.53119, chx_loss 0.74890, chxlacc 0.76024, chxlrocaucmic 0.84621, chxlrocaucmac 0.83719, qlmicf1 0.45076, qlmacf1 0.28170, ql_loss 0.66642, gacc 0.98624, gloss 0.04068, cxr14micf1 0.43273, cxr14macf1 0.44045, cxr14_loss 0.78170, vnbgmicf1 0.78609, vnbgmacf1 0.73229, vnbg_loss 0.30746, ema 0.77331, 184.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37313, wmdcmp 0.19323, oracc 0.98911, chxlmicf1 0.56050, chxlmacf1 0.49562, chxlacc 0.73631, chxlrocaucmic 0.80016, chxlrocaucmac 0.77100, qlmicf1 0.43221, qlmacf1 0.27446, ema 0.68545, 73.83 secs\n",
      "Adjusting learning rate of group 0 to 1.4925e-06.\n",
      "\u001b[1m---- Epoch 47/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.91224, a_loss 0.83387, cD 1.54055, wmdcmp 0.19795, oracc 0.98631, orien_loss 0.00657, chxlmicf1 0.58090, chxlmacf1 0.53430, chx_loss 0.74342, chxlacc 0.76279, chxlrocaucmic 0.84699, chxlrocaucmac 0.83949, qlmicf1 0.45050, qlmacf1 0.28713, ql_loss 0.66572, gacc 0.98473, gloss 0.04807, cxr14micf1 0.43550, cxr14macf1 0.44519, cxr14_loss 0.77394, vnbgmicf1 0.78324, vnbgmacf1 0.73855, vnbg_loss 0.30797, ema 0.77474, 181.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37604, wmdcmp 0.19359, oracc 0.98911, chxlmicf1 0.55998, chxlmacf1 0.49517, chxlacc 0.73748, chxlrocaucmic 0.80020, chxlrocaucmac 0.77057, qlmicf1 0.42918, qlmacf1 0.27342, ema 0.68727, 69.56 secs\n",
      "Adjusting learning rate of group 0 to 1.3503e-06.\n",
      "\u001b[1m---- Epoch 48/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.69494, a_loss 0.83839, cD 1.53122, wmdcmp 0.20079, oracc 0.98714, orien_loss 0.00852, chxlmicf1 0.58198, chxlmacf1 0.53276, chx_loss 0.75367, chxlacc 0.76364, chxlrocaucmic 0.84715, chxlrocaucmac 0.83731, qlmicf1 0.45074, qlmacf1 0.28075, ql_loss 0.66910, gacc 0.98745, gloss 0.03978, cxr14micf1 0.44284, cxr14macf1 0.45138, cxr14_loss 0.76385, vnbgmicf1 0.78144, vnbgmacf1 0.72559, vnbg_loss 0.30853, ema 0.77643, 150.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36904, wmdcmp 0.19311, oracc 0.98911, chxlmicf1 0.55490, chxlmacf1 0.49065, chxlacc 0.72840, chxlrocaucmic 0.79849, chxlrocaucmac 0.77031, qlmicf1 0.42917, qlmacf1 0.27403, ema 0.68727, 52.11 secs\n",
      "Adjusting learning rate of group 0 to 1.2217e-06.\n",
      "\u001b[1m---- Epoch 49/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "   iteration 19380\r"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\" \\\n",
    "        --epochs 50 \\\n",
    "        --batches-per-epoch 399 \\\n",
    "        --batch-size 50 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --num-workers 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,1e-4,46,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --raw-image-encoding \"clip-vit-huggingface\" \\\n",
    "        --clip-version \"CenIA/vte-vit-base-patch16-bio-clinical-bert-finetuned-v2\" \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
