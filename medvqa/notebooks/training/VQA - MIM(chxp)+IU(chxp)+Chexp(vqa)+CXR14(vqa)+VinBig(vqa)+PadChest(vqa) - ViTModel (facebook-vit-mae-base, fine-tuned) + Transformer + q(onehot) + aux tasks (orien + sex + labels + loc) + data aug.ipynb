{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 pamessina pamessina 1.3G Jan  6 14:27 '/mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: facebook/vit-mae-base\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,2e-4,93,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 55\n",
      "   iters_to_accumulate: 5\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path /mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_norm.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.mask_token', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.5.layernorm_after.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,2e-4,93,1e-6\n",
      "1e-06 7 0.0002 93 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 55\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,1651436623822174339).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 55\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,4034709835837782143).pkl\n",
      "\tlen(question_datasets) = 54\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading CXR14 labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1440: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 126771.06it/s]\n",
      "Done. Example answer: <s> unchanged </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 131897.74it/s]\n",
      "Done. Example answer: <s> loc right upper lobe </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 70738.49it/s]\n",
      "Done. Example answer: <s> pleural effusion loc bilateral loc left loc pleural </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc right upper lobe </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:27,  7.11it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 11.76019, a_loss 8.64980, cD 0.00066, wmdcmp 0.00153, ema 0.00000, oracc 0.46701, orien_loss 1.14176, qlmicf1 0.11252, qlmacf1 0.09312, ql_loss 1.03253, chxlmicf1 0.14604, chxlmacf1 0.16591, chx_loss 1.09650, chxlacc 0.49087, chxlrocaucmic 0.47552, chxlrocaucmac 0.51055, gacc 0.47430, gloss 0.69553, cxr14micf1 0.15578, cxr14macf1 0.13826, cxr14_loss 1.24372, vnbgmicf1 0.14814, vnbgmacf1 0.14610, vnbg_loss 9.88172, b1 0.00047, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01532, padchxlmicf1 0.01462, padchxlzmacf1 0.01939, padchxlzmicf1 0.01401, padchxl_loss 0.84610, padchxlz_loss 0.90406, 93.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00043, wmdcmp 0.00146, ema 0.00000, oracc 0.63941, qlmicf1 0.10297, qlmacf1 0.09229, chxlmicf1 0.14503, chxlmacf1 0.16590, chxlacc 0.49917, chxlrocaucmic 0.47514, chxlrocaucmac 0.51180, 19.96 secs\n",
      "Adjusting learning rate of group 0 to 2.1317e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 11.64556, a_loss 8.45862, cD 0.00084, wmdcmp 0.00166, ema 0.00000, oracc 0.66559, orien_loss 0.99696, qlmicf1 0.10498, qlmacf1 0.09086, ql_loss 1.03797, chxlmicf1 0.17180, chxlmacf1 0.18670, chx_loss 1.09698, chxlacc 0.55750, chxlrocaucmic 0.51401, chxlrocaucmac 0.51092, gacc 0.55927, gloss 0.68562, cxr14micf1 0.17087, cxr14macf1 0.15020, cxr14_loss 1.24217, vnbgmicf1 0.18992, vnbgmacf1 0.15954, vnbg_loss 9.60940, b1 0.00062, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01492, padchxlmicf1 0.01885, padchxlzmacf1 0.02129, padchxlzmicf1 0.01837, padchxl_loss 0.83753, padchxlz_loss 0.89419, 79.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00058, wmdcmp 0.00115, ema 0.00000, oracc 0.63941, qlmicf1 0.12111, qlmacf1 0.09280, chxlmicf1 0.17794, chxlmacf1 0.14434, chxlacc 0.58678, chxlrocaucmic 0.53148, chxlrocaucmac 0.51439, 19.70 secs\n",
      "Adjusting learning rate of group 0 to 4.5440e-06.\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 10.98971, a_loss 7.83253, cD 0.00074, wmdcmp 0.00035, ema 0.03271, oracc 0.66999, orien_loss 0.78501, qlmicf1 0.12954, qlmacf1 0.09192, ql_loss 1.03275, chxlmicf1 0.15885, chxlmacf1 0.16549, chx_loss 1.09596, chxlacc 0.61164, chxlrocaucmic 0.54986, chxlrocaucmac 0.50986, gacc 0.55498, gloss 0.68481, cxr14micf1 0.13880, cxr14macf1 0.12081, cxr14_loss 1.24492, vnbgmicf1 0.20455, vnbgmacf1 0.14095, vnbg_loss 8.73792, b1 0.00025, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01372, padchxlmicf1 0.01930, padchxlzmacf1 0.02203, padchxlzmicf1 0.01829, padchxl_loss 0.82498, padchxlz_loss 0.89986, 76.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.63941, qlmicf1 0.14330, qlmacf1 0.08652, chxlmicf1 0.13365, chxlmacf1 0.14616, chxlacc 0.58856, chxlrocaucmic 0.53054, chxlrocaucmac 0.52040, 18.18 secs\n",
      "Adjusting learning rate of group 0 to 9.6863e-06.\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 10.81200, a_loss 6.98572, cD 0.00000, wmdcmp 0.00000, ema 0.04388, oracc 0.75193, orien_loss 0.59433, qlmicf1 0.18993, qlmacf1 0.10820, ql_loss 0.99862, chxlmicf1 0.26637, chxlmacf1 0.29318, chx_loss 1.09253, chxlacc 0.59348, chxlrocaucmic 0.60351, chxlrocaucmac 0.55105, gacc 0.55367, gloss 0.68593, cxr14micf1 0.10058, cxr14macf1 0.12178, cxr14_loss 1.24189, vnbgmicf1 0.21655, vnbgmacf1 0.16896, vnbg_loss 7.60064, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01293, padchxlmicf1 0.02135, padchxlzmacf1 0.02221, padchxlzmicf1 0.02052, padchxl_loss 0.77081, padchxlz_loss 0.86311, 76.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.88310, qlmicf1 0.28775, qlmacf1 0.12499, chxlmicf1 0.36779, chxlmacf1 0.35330, chxlacc 0.57737, chxlrocaucmic 0.62990, chxlrocaucmac 0.59911, 18.46 secs\n",
      "Adjusting learning rate of group 0 to 2.0648e-05.\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 9.66048, a_loss 6.33597, cD 0.00000, wmdcmp 0.00000, ema 0.04428, oracc 0.84671, orien_loss 0.39105, qlmicf1 0.26345, qlmacf1 0.12828, ql_loss 0.96597, chxlmicf1 0.34661, chxlmacf1 0.34597, chx_loss 1.07722, chxlacc 0.56791, chxlrocaucmic 0.63033, chxlrocaucmac 0.59814, gacc 0.55879, gloss 0.68387, cxr14micf1 0.12125, cxr14macf1 0.17743, cxr14_loss 1.23504, vnbgmicf1 0.23922, vnbgmacf1 0.18291, vnbg_loss 6.80285, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01282, padchxlmicf1 0.02905, padchxlzmacf1 0.02125, padchxlzmicf1 0.04048, padchxl_loss 0.68066, padchxlz_loss 0.77099, 76.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.94862, qlmicf1 0.27132, qlmacf1 0.13738, chxlmicf1 0.41226, chxlmacf1 0.36962, chxlacc 0.56389, chxlrocaucmic 0.65200, chxlrocaucmac 0.61114, 18.43 secs\n",
      "Adjusting learning rate of group 0 to 4.4014e-05.\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 7.65093, a_loss 5.58190, cD 0.02264, wmdcmp 0.00415, ema 0.03662, oracc 0.90414, orien_loss 0.24752, qlmicf1 0.27536, qlmacf1 0.13629, ql_loss 0.93124, chxlmicf1 0.36915, chxlmacf1 0.35418, chx_loss 1.07275, chxlacc 0.56331, chxlrocaucmic 0.64354, chxlrocaucmac 0.60662, gacc 0.59231, gloss 0.67294, cxr14micf1 0.13514, cxr14macf1 0.19413, cxr14_loss 1.21965, vnbgmicf1 0.19447, vnbgmacf1 0.17324, vnbg_loss 5.99750, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01943, padchxlmicf1 0.07971, padchxlzmacf1 0.03701, padchxlzmicf1 0.08351, padchxl_loss 0.56235, padchxlz_loss 0.67016, 76.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.09083, wmdcmp 0.01461, ema 0.00000, oracc 0.96347, qlmicf1 0.26968, qlmacf1 0.13939, chxlmicf1 0.41744, chxlmacf1 0.37146, chxlacc 0.55301, chxlrocaucmic 0.65703, chxlrocaucmac 0.61796, 18.35 secs\n",
      "Adjusting learning rate of group 0 to 9.3823e-05.\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 6.04069, a_loss 4.46294, cD 0.06329, wmdcmp 0.01276, ema 0.02775, oracc 0.94963, orien_loss 0.13284, qlmicf1 0.26583, qlmacf1 0.14160, ql_loss 0.91595, chxlmicf1 0.38515, chxlmacf1 0.36163, chx_loss 1.06529, chxlacc 0.56174, chxlrocaucmic 0.65574, chxlrocaucmac 0.61994, gacc 0.72294, gloss 0.53348, cxr14micf1 0.15308, cxr14macf1 0.20234, cxr14_loss 1.20218, vnbgmicf1 0.23793, vnbgmacf1 0.20006, vnbg_loss 4.77629, b1 0.00446, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02549, padchxlmicf1 0.10043, padchxlzmacf1 0.04522, padchxlzmicf1 0.09853, padchxl_loss 0.49226, padchxlz_loss 0.61501, 77.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.12699, wmdcmp 0.02125, ema 0.07431, oracc 0.97997, qlmicf1 0.25130, qlmacf1 0.14196, chxlmicf1 0.42676, chxlmacf1 0.37413, chxlacc 0.56305, chxlrocaucmic 0.68028, chxlrocaucmac 0.62248, 18.67 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 8.03681, a_loss 3.19379, cD 0.08948, wmdcmp 0.01792, ema 0.22701, oracc 0.96393, orien_loss 0.08803, qlmicf1 0.27020, qlmacf1 0.14651, ql_loss 0.90678, chxlmicf1 0.39383, chxlmacf1 0.36842, chx_loss 1.04978, chxlacc 0.58997, chxlrocaucmic 0.67332, chxlrocaucmac 0.63996, gacc 0.82465, gloss 0.38543, cxr14micf1 0.15488, cxr14macf1 0.20329, cxr14_loss 1.20406, vnbgmicf1 0.29472, vnbgmacf1 0.23307, vnbg_loss 3.45884, b1 0.00804, b2 0.00215, b3 0.00108, b4 0.00067, padchxlmacf1 0.02864, padchxlmicf1 0.10278, padchxlzmacf1 0.04790, padchxlzmicf1 0.10280, padchxl_loss 0.45893, padchxlz_loss 0.56506, 79.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.14806, wmdcmp 0.02386, ema 0.44763, oracc 0.96983, qlmicf1 0.29724, qlmacf1 0.15213, chxlmicf1 0.45515, chxlmacf1 0.40022, chxlacc 0.59962, chxlrocaucmic 0.72587, chxlrocaucmac 0.66215, 20.73 secs\n",
      "Adjusting learning rate of group 0 to 1.8892e-04.\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 2.81339, a_loss 2.39445, cD 0.15913, wmdcmp 0.02813, ema 0.41375, oracc 0.96934, orien_loss 0.06956, qlmicf1 0.27410, qlmacf1 0.15428, ql_loss 0.90148, chxlmicf1 0.42568, chxlmacf1 0.38903, chx_loss 1.02743, chxlacc 0.61535, chxlrocaucmic 0.70252, chxlrocaucmac 0.67225, gacc 0.90262, gloss 0.24186, cxr14micf1 0.19478, cxr14macf1 0.22999, cxr14_loss 1.17787, vnbgmicf1 0.43262, vnbgmacf1 0.30512, vnbg_loss 2.34749, b1 0.09890, b2 0.04980, b3 0.02892, b4 0.01948, padchxlmacf1 0.03218, padchxlmicf1 0.12212, padchxlzmacf1 0.05010, padchxlzmicf1 0.12184, padchxl_loss 0.42744, padchxlz_loss 0.55875, 86.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.22275, wmdcmp 0.03275, ema 0.59803, oracc 0.98256, qlmicf1 0.29787, qlmacf1 0.16287, chxlmicf1 0.48456, chxlmacf1 0.41366, chxlacc 0.66885, chxlrocaucmic 0.73608, chxlrocaucmac 0.68871, 21.11 secs\n",
      "Adjusting learning rate of group 0 to 1.7846e-04.\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000178) ...\n",
      "loss 2.16913, a_loss 2.07080, cD 0.23820, wmdcmp 0.04041, ema 0.48786, oracc 0.97540, orien_loss 0.05915, qlmicf1 0.28752, qlmacf1 0.16210, ql_loss 0.89243, chxlmicf1 0.44527, chxlmacf1 0.40484, chx_loss 1.00437, chxlacc 0.62811, chxlrocaucmic 0.72053, chxlrocaucmac 0.69070, gacc 0.91154, gloss 0.21993, cxr14micf1 0.20822, cxr14macf1 0.23876, cxr14_loss 1.14724, vnbgmicf1 0.44718, vnbgmacf1 0.31384, vnbg_loss 1.70275, b1 0.19292, b2 0.11113, b3 0.07041, b4 0.04795, padchxlmacf1 0.03650, padchxlmicf1 0.11419, padchxlzmacf1 0.05831, padchxlzmicf1 0.13199, padchxl_loss 0.43228, padchxlz_loss 0.55436, 83.73 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.27288, wmdcmp 0.04361, ema 0.63474, oracc 0.98185, qlmicf1 0.29472, qlmacf1 0.17145, chxlmicf1 0.46124, chxlmacf1 0.41494, chxlacc 0.59326, chxlrocaucmic 0.72917, chxlrocaucmac 0.69006, 21.04 secs\n",
      "Adjusting learning rate of group 0 to 1.6858e-04.\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000169) ...\n",
      "loss 1.71740, a_loss 1.91196, cD 0.34272, wmdcmp 0.05366, ema 0.50883, oracc 0.97443, orien_loss 0.05458, qlmicf1 0.29498, qlmacf1 0.16567, ql_loss 0.88536, chxlmicf1 0.44483, chxlmacf1 0.40534, chx_loss 0.99457, chxlacc 0.63091, chxlrocaucmic 0.72153, chxlrocaucmac 0.69820, gacc 0.92173, gloss 0.19170, cxr14micf1 0.20796, cxr14macf1 0.24076, cxr14_loss 1.15861, vnbgmicf1 0.45779, vnbgmacf1 0.33214, vnbg_loss 1.44860, b1 0.24708, b2 0.15255, b3 0.09601, b4 0.06556, padchxlmacf1 0.03886, padchxlmicf1 0.11831, padchxlzmacf1 0.06070, padchxlzmicf1 0.12639, padchxl_loss 0.41703, padchxlz_loss 0.53819, 83.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.31381, wmdcmp 0.04851, ema 0.61415, oracc 0.98209, qlmicf1 0.32014, qlmacf1 0.17513, chxlmicf1 0.45113, chxlmacf1 0.40991, chxlacc 0.65556, chxlrocaucmic 0.70712, chxlrocaucmac 0.69280, 21.30 secs\n",
      "Adjusting learning rate of group 0 to 1.5924e-04.\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 6.30700, a_loss 1.80830, cD 0.42169, wmdcmp 0.06375, ema 0.53164, oracc 0.97532, orien_loss 0.05287, qlmicf1 0.30461, qlmacf1 0.16945, ql_loss 0.86863, chxlmicf1 0.45627, chxlmacf1 0.41521, chx_loss 0.98378, chxlacc 0.64032, chxlrocaucmic 0.73252, chxlrocaucmac 0.70861, gacc 0.92885, gloss 0.18448, cxr14micf1 0.23050, cxr14macf1 0.25403, cxr14_loss 1.12957, vnbgmicf1 0.46768, vnbgmacf1 0.34071, vnbg_loss 1.29168, b1 0.31037, b2 0.20172, b3 0.12796, b4 0.08114, padchxlmacf1 0.04525, padchxlmicf1 0.13816, padchxlzmacf1 0.06279, padchxlzmicf1 0.13689, padchxl_loss 0.38575, padchxlz_loss 0.52051, 84.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37223, wmdcmp 0.05686, ema 0.63384, oracc 0.98327, qlmicf1 0.31192, qlmacf1 0.17596, chxlmicf1 0.47756, chxlmacf1 0.42132, chxlacc 0.66754, chxlrocaucmic 0.73667, chxlrocaucmac 0.70915, 20.93 secs\n",
      "Adjusting learning rate of group 0 to 1.5042e-04.\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "loss 3.53940, a_loss 1.72700, cD 0.47904, wmdcmp 0.07148, ema 0.54789, oracc 0.97620, orien_loss 0.04750, qlmicf1 0.30718, qlmacf1 0.17290, ql_loss 0.86685, chxlmicf1 0.46169, chxlmacf1 0.42125, chx_loss 0.96803, chxlacc 0.64966, chxlrocaucmic 0.74120, chxlrocaucmac 0.71780, gacc 0.92779, gloss 0.16876, cxr14micf1 0.23630, cxr14macf1 0.25859, cxr14_loss 1.12022, vnbgmicf1 0.47988, vnbgmacf1 0.35129, vnbg_loss 1.18621, b1 0.33111, b2 0.22023, b3 0.14969, b4 0.10714, padchxlmacf1 0.04528, padchxlmicf1 0.12717, padchxlzmacf1 0.06428, padchxlzmicf1 0.13871, padchxl_loss 0.41246, padchxlz_loss 0.53527, 87.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.48383, wmdcmp 0.07309, ema 0.63653, oracc 0.98397, qlmicf1 0.32889, qlmacf1 0.18437, chxlmicf1 0.48899, chxlmacf1 0.43370, chxlacc 0.64294, chxlrocaucmic 0.75828, chxlrocaucmac 0.71489, 20.35 secs\n",
      "Adjusting learning rate of group 0 to 1.4209e-04.\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 5.66201, a_loss 1.66607, cD 0.53164, wmdcmp 0.07924, ema 0.55804, oracc 0.97666, orien_loss 0.04507, qlmicf1 0.31219, qlmacf1 0.17678, ql_loss 0.85953, chxlmicf1 0.45994, chxlmacf1 0.42286, chx_loss 0.96607, chxlacc 0.65140, chxlrocaucmic 0.74611, chxlrocaucmac 0.72329, gacc 0.93951, gloss 0.14957, cxr14micf1 0.25295, cxr14macf1 0.27036, cxr14_loss 1.08843, vnbgmicf1 0.48585, vnbgmacf1 0.36814, vnbg_loss 1.13191, b1 0.39735, b2 0.27582, b3 0.18810, b4 0.13310, padchxlmacf1 0.04729, padchxlmicf1 0.14766, padchxlzmacf1 0.06734, padchxlzmicf1 0.15502, padchxl_loss 0.39263, padchxlz_loss 0.54282, 91.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.55188, wmdcmp 0.08191, ema 0.65085, oracc 0.98492, qlmicf1 0.33007, qlmacf1 0.18438, chxlmicf1 0.48678, chxlmacf1 0.43970, chxlacc 0.64441, chxlrocaucmic 0.75127, chxlrocaucmac 0.72563, 21.02 secs\n",
      "Adjusting learning rate of group 0 to 1.3423e-04.\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 2.02499, a_loss 1.61318, cD 0.56956, wmdcmp 0.08350, ema 0.56564, oracc 0.97821, orien_loss 0.04432, qlmicf1 0.31566, qlmacf1 0.17911, ql_loss 0.85459, chxlmicf1 0.46294, chxlmacf1 0.42388, chx_loss 0.96141, chxlacc 0.65414, chxlrocaucmic 0.74476, chxlrocaucmac 0.72486, gacc 0.93514, gloss 0.15860, cxr14micf1 0.26974, cxr14macf1 0.28134, cxr14_loss 1.06807, vnbgmicf1 0.49343, vnbgmacf1 0.36438, vnbg_loss 1.05930, b1 0.36790, b2 0.24975, b3 0.16648, b4 0.11520, padchxlmacf1 0.04681, padchxlmicf1 0.14092, padchxlzmacf1 0.06615, padchxlzmicf1 0.14233, padchxl_loss 0.39500, padchxlz_loss 0.51585, 88.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.64452, wmdcmp 0.09538, ema 0.63563, oracc 0.98515, qlmicf1 0.32742, qlmacf1 0.18801, chxlmicf1 0.48264, chxlmacf1 0.43676, chxlacc 0.64354, chxlrocaucmic 0.75005, chxlrocaucmac 0.71794, 21.64 secs\n",
      "Adjusting learning rate of group 0 to 1.2679e-04.\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000127) ...\n",
      "loss 5.98758, a_loss 1.58655, cD 0.61350, wmdcmp 0.08906, ema 0.56538, oracc 0.97934, orien_loss 0.04328, qlmicf1 0.31802, qlmacf1 0.18303, ql_loss 0.84960, chxlmicf1 0.46846, chxlmacf1 0.42956, chx_loss 0.95094, chxlacc 0.66119, chxlrocaucmic 0.75372, chxlrocaucmac 0.73282, gacc 0.94423, gloss 0.14561, cxr14micf1 0.26236, cxr14macf1 0.27887, cxr14_loss 1.08016, vnbgmicf1 0.49256, vnbgmacf1 0.36629, vnbg_loss 1.02771, b1 0.40659, b2 0.28255, b3 0.19130, b4 0.13355, padchxlmacf1 0.04736, padchxlmicf1 0.14010, padchxlzmacf1 0.07106, padchxlzmicf1 0.15667, padchxl_loss 0.39722, padchxlz_loss 0.52563, 87.27 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.66189, wmdcmp 0.10007, ema 0.64816, oracc 0.98515, qlmicf1 0.32989, qlmacf1 0.18944, chxlmicf1 0.48227, chxlmacf1 0.43518, chxlacc 0.66387, chxlrocaucmic 0.74428, chxlrocaucmac 0.72385, 21.98 secs\n",
      "Adjusting learning rate of group 0 to 1.1977e-04.\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000120) ...\n",
      "loss 1.30621, a_loss 1.54792, cD 0.62042, wmdcmp 0.09085, ema 0.56781, oracc 0.98141, orien_loss 0.03214, qlmicf1 0.32984, qlmacf1 0.18579, ql_loss 0.84754, chxlmicf1 0.46716, chxlmacf1 0.42862, chx_loss 0.95228, chxlacc 0.66212, chxlrocaucmic 0.75176, chxlrocaucmac 0.73353, gacc 0.94268, gloss 0.14449, cxr14micf1 0.29660, cxr14macf1 0.29815, cxr14_loss 1.04619, vnbgmicf1 0.50861, vnbgmacf1 0.37931, vnbg_loss 0.97686, b1 0.42643, b2 0.30204, b3 0.21051, b4 0.15032, padchxlmacf1 0.05225, padchxlmicf1 0.14641, padchxlzmacf1 0.06858, padchxlzmicf1 0.15351, padchxl_loss 0.38857, padchxlz_loss 0.51458, 86.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.69266, wmdcmp 0.10150, ema 0.63832, oracc 0.98397, qlmicf1 0.32891, qlmacf1 0.19302, chxlmicf1 0.48782, chxlmacf1 0.43920, chxlacc 0.63309, chxlrocaucmic 0.76381, chxlrocaucmac 0.72681, 21.61 secs\n",
      "Adjusting learning rate of group 0 to 1.1314e-04.\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 1.56452, a_loss 1.52291, cD 0.66662, wmdcmp 0.09612, ema 0.57364, oracc 0.97906, orien_loss 0.03845, qlmicf1 0.32905, qlmacf1 0.18898, ql_loss 0.84237, chxlmicf1 0.47850, chxlmacf1 0.43965, chx_loss 0.93711, chxlacc 0.66872, chxlrocaucmic 0.75991, chxlrocaucmac 0.74360, gacc 0.95065, gloss 0.12989, cxr14micf1 0.27642, cxr14macf1 0.29100, cxr14_loss 1.03798, vnbgmicf1 0.51513, vnbgmacf1 0.38729, vnbg_loss 0.95156, b1 0.39231, b2 0.27132, b3 0.18360, b4 0.12912, padchxlmacf1 0.05033, padchxlmicf1 0.13467, padchxlzmacf1 0.06814, padchxlzmicf1 0.15544, padchxl_loss 0.40176, padchxlz_loss 0.53421, 86.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.76049, wmdcmp 0.11218, ema 0.65712, oracc 0.98515, qlmicf1 0.34242, qlmacf1 0.19557, chxlmicf1 0.49913, chxlmacf1 0.44644, chxlacc 0.67099, chxlrocaucmic 0.76016, chxlrocaucmac 0.73275, 21.44 secs\n",
      "Adjusting learning rate of group 0 to 1.0687e-04.\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000107) ...\n",
      "loss 1.80335, a_loss 1.47783, cD 0.68203, wmdcmp 0.09837, ema 0.58034, oracc 0.98100, orien_loss 0.03677, qlmicf1 0.32920, qlmacf1 0.18857, ql_loss 0.83252, chxlmicf1 0.47338, chxlmacf1 0.43177, chx_loss 0.94027, chxlacc 0.67008, chxlrocaucmic 0.75872, chxlrocaucmac 0.73989, gacc 0.95402, gloss 0.12391, cxr14micf1 0.27572, cxr14macf1 0.29006, cxr14_loss 1.03788, vnbgmicf1 0.52465, vnbgmacf1 0.38832, vnbg_loss 0.93366, b1 0.41963, b2 0.28739, b3 0.19564, b4 0.13880, padchxlmacf1 0.05210, padchxlmicf1 0.14862, padchxlzmacf1 0.07220, padchxlzmicf1 0.16478, padchxl_loss 0.36615, padchxlz_loss 0.49627, 88.43 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.76868, wmdcmp 0.11385, ema 0.66517, oracc 0.98539, qlmicf1 0.34487, qlmacf1 0.19527, chxlmicf1 0.48857, chxlmacf1 0.44158, chxlacc 0.66531, chxlrocaucmic 0.75114, chxlrocaucmac 0.73262, 21.02 secs\n",
      "Adjusting learning rate of group 0 to 1.0095e-04.\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000101) ...\n",
      "loss 5.87946, a_loss 1.48681, cD 0.70146, wmdcmp 0.10077, ema 0.58811, oracc 0.98049, orien_loss 0.03636, qlmicf1 0.32702, qlmacf1 0.19180, ql_loss 0.83817, chxlmicf1 0.47901, chxlmacf1 0.43927, chx_loss 0.92619, chxlacc 0.67298, chxlrocaucmic 0.76384, chxlrocaucmac 0.74629, gacc 0.95000, gloss 0.12510, cxr14micf1 0.26899, cxr14macf1 0.28115, cxr14_loss 1.06527, vnbgmicf1 0.52695, vnbgmacf1 0.39364, vnbg_loss 0.91397, b1 0.40347, b2 0.28251, b3 0.19369, b4 0.13550, padchxlmacf1 0.05254, padchxlmicf1 0.14319, padchxlzmacf1 0.06924, padchxlzmicf1 0.15637, padchxl_loss 0.39486, padchxlz_loss 0.50944, 91.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.84407, wmdcmp 0.12158, ema 0.66249, oracc 0.98468, qlmicf1 0.33942, qlmacf1 0.19896, chxlmicf1 0.49860, chxlmacf1 0.44891, chxlacc 0.66323, chxlrocaucmic 0.76666, chxlrocaucmac 0.73875, 19.98 secs\n",
      "Adjusting learning rate of group 0 to 9.5363e-05.\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 2.70296, a_loss 1.44506, cD 0.73903, wmdcmp 0.10564, ema 0.58652, oracc 0.97840, orien_loss 0.03750, qlmicf1 0.33910, qlmacf1 0.19388, ql_loss 0.83388, chxlmicf1 0.48128, chxlmacf1 0.44070, chx_loss 0.92489, chxlacc 0.67546, chxlrocaucmic 0.76676, chxlrocaucmac 0.74700, gacc 0.95671, gloss 0.11583, cxr14micf1 0.29996, cxr14macf1 0.30103, cxr14_loss 1.02217, vnbgmicf1 0.52541, vnbgmacf1 0.38694, vnbg_loss 0.87044, b1 0.44287, b2 0.31341, b3 0.22079, b4 0.15830, padchxlmacf1 0.05349, padchxlmicf1 0.15098, padchxlzmacf1 0.07420, padchxlzmicf1 0.16137, padchxl_loss 0.36679, padchxlz_loss 0.50287, 89.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.88969, wmdcmp 0.12708, ema 0.68218, oracc 0.98586, qlmicf1 0.35488, qlmacf1 0.19984, chxlmicf1 0.49347, chxlmacf1 0.44386, chxlacc 0.67257, chxlrocaucmic 0.75671, chxlrocaucmac 0.73597, 21.25 secs\n",
      "Adjusting learning rate of group 0 to 9.0082e-05.\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.99567, a_loss 1.42626, cD 0.74759, wmdcmp 0.10652, ema 0.59269, oracc 0.97974, orien_loss 0.04116, qlmicf1 0.33746, qlmacf1 0.19486, ql_loss 0.82858, chxlmicf1 0.48559, chxlmacf1 0.44525, chx_loss 0.92293, chxlacc 0.68024, chxlrocaucmic 0.76825, chxlrocaucmac 0.75030, gacc 0.95315, gloss 0.12422, cxr14micf1 0.30532, cxr14macf1 0.30822, cxr14_loss 1.01639, vnbgmicf1 0.52095, vnbgmacf1 0.38942, vnbg_loss 0.87975, b1 0.41705, b2 0.29553, b3 0.20866, b4 0.15041, padchxlmacf1 0.05995, padchxlmicf1 0.15632, padchxlzmacf1 0.08000, padchxlzmicf1 0.17067, padchxl_loss 0.38506, padchxlz_loss 0.51316, 87.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.88216, wmdcmp 0.12705, ema 0.69293, oracc 0.98633, qlmicf1 0.35482, qlmacf1 0.20177, chxlmicf1 0.49411, chxlmacf1 0.44669, chxlacc 0.66300, chxlrocaucmic 0.75810, chxlrocaucmac 0.73056, 21.94 secs\n",
      "Adjusting learning rate of group 0 to 8.5093e-05.\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000085) ...\n",
      "loss 1.83036, a_loss 1.41977, cD 0.75425, wmdcmp 0.10666, ema 0.59530, oracc 0.98340, orien_loss 0.03304, qlmicf1 0.34590, qlmacf1 0.20120, ql_loss 0.81809, chxlmicf1 0.48878, chxlmacf1 0.44678, chx_loss 0.91459, chxlacc 0.68456, chxlrocaucmic 0.77162, chxlrocaucmac 0.75484, gacc 0.95455, gloss 0.11633, cxr14micf1 0.30086, cxr14macf1 0.30506, cxr14_loss 1.02108, vnbgmicf1 0.53101, vnbgmacf1 0.39787, vnbg_loss 0.85441, b1 0.43068, b2 0.30702, b3 0.21362, b4 0.14896, padchxlmacf1 0.05412, padchxlmicf1 0.15038, padchxlzmacf1 0.07128, padchxlzmicf1 0.15533, padchxl_loss 0.35838, padchxlz_loss 0.50378, 87.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.89390, wmdcmp 0.12961, ema 0.67234, oracc 0.98680, qlmicf1 0.35175, qlmacf1 0.19942, chxlmicf1 0.48928, chxlmacf1 0.44263, chxlacc 0.66904, chxlrocaucmic 0.75311, chxlrocaucmac 0.73897, 22.23 secs\n",
      "Adjusting learning rate of group 0 to 8.0381e-05.\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 5.26601, a_loss 1.41966, cD 0.77638, wmdcmp 0.10970, ema 0.59327, oracc 0.98077, orien_loss 0.03761, qlmicf1 0.33458, qlmacf1 0.19550, ql_loss 0.82182, chxlmicf1 0.48472, chxlmacf1 0.44527, chx_loss 0.91538, chxlacc 0.68110, chxlrocaucmic 0.76890, chxlrocaucmac 0.75368, gacc 0.96434, gloss 0.09648, cxr14micf1 0.31303, cxr14macf1 0.31026, cxr14_loss 1.00609, vnbgmicf1 0.53934, vnbgmacf1 0.40006, vnbg_loss 0.83464, b1 0.43856, b2 0.31510, b3 0.22206, b4 0.15738, padchxlmacf1 0.05582, padchxlmicf1 0.15131, padchxlzmacf1 0.07860, padchxlzmicf1 0.16445, padchxl_loss 0.38474, padchxlz_loss 0.51402, 87.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.95357, wmdcmp 0.13784, ema 0.67681, oracc 0.98327, qlmicf1 0.34896, qlmacf1 0.20570, chxlmicf1 0.50063, chxlmacf1 0.44318, chxlacc 0.68501, chxlrocaucmic 0.76333, chxlrocaucmac 0.73974, 21.79 secs\n",
      "Adjusting learning rate of group 0 to 7.5930e-05.\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000076) ...\n",
      "loss 2.10546, a_loss 1.38984, cD 0.82838, wmdcmp 0.11464, ema 0.60174, oracc 0.98069, orien_loss 0.03363, qlmicf1 0.34697, qlmacf1 0.20051, ql_loss 0.81534, chxlmicf1 0.49075, chxlmacf1 0.45013, chx_loss 0.90801, chxlacc 0.68516, chxlrocaucmic 0.77546, chxlrocaucmac 0.76021, gacc 0.95594, gloss 0.11061, cxr14micf1 0.31170, cxr14macf1 0.30843, cxr14_loss 1.00963, vnbgmicf1 0.54632, vnbgmacf1 0.40990, vnbg_loss 0.82091, b1 0.42516, b2 0.30270, b3 0.21122, b4 0.14708, padchxlmacf1 0.05580, padchxlmicf1 0.15531, padchxlzmacf1 0.07922, padchxlzmicf1 0.17310, padchxl_loss 0.36817, padchxlz_loss 0.50566, 88.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.92922, wmdcmp 0.13615, ema 0.66607, oracc 0.98704, qlmicf1 0.35886, qlmacf1 0.20259, chxlmicf1 0.51813, chxlmacf1 0.45334, chxlacc 0.68380, chxlrocaucmic 0.78642, chxlrocaucmac 0.73902, 21.14 secs\n",
      "Adjusting learning rate of group 0 to 7.1725e-05.\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000072) ...\n",
      "loss 1.13502, a_loss 1.36739, cD 0.83658, wmdcmp 0.11798, ema 0.60313, oracc 0.98139, orien_loss 0.03205, qlmicf1 0.34445, qlmacf1 0.20219, ql_loss 0.81804, chxlmicf1 0.49193, chxlmacf1 0.44935, chx_loss 0.90683, chxlacc 0.68737, chxlrocaucmic 0.77779, chxlrocaucmac 0.75928, gacc 0.95602, gloss 0.11057, cxr14micf1 0.31663, cxr14macf1 0.31102, cxr14_loss 1.00066, vnbgmicf1 0.53897, vnbgmacf1 0.40531, vnbg_loss 0.82562, b1 0.45209, b2 0.32555, b3 0.23090, b4 0.16641, padchxlmacf1 0.05813, padchxlmicf1 0.16111, padchxlzmacf1 0.07406, padchxlzmicf1 0.16790, padchxl_loss 0.36479, padchxlz_loss 0.49387, 89.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.93841, wmdcmp 0.13739, ema 0.68845, oracc 0.98657, qlmicf1 0.35688, qlmacf1 0.20459, chxlmicf1 0.50159, chxlmacf1 0.45375, chxlacc 0.66286, chxlrocaucmic 0.77065, chxlrocaucmac 0.74229, 20.48 secs\n",
      "Adjusting learning rate of group 0 to 6.7753e-05.\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 5.59193, a_loss 1.38571, cD 0.82398, wmdcmp 0.11599, ema 0.60271, oracc 0.97996, orien_loss 0.03492, qlmicf1 0.34458, qlmacf1 0.20223, ql_loss 0.81666, chxlmicf1 0.49680, chxlmacf1 0.45430, chx_loss 0.90066, chxlacc 0.68911, chxlrocaucmic 0.77830, chxlrocaucmac 0.76374, gacc 0.95297, gloss 0.11608, cxr14micf1 0.31201, cxr14macf1 0.31260, cxr14_loss 1.01412, vnbgmicf1 0.54400, vnbgmacf1 0.40680, vnbg_loss 0.82882, b1 0.45703, b2 0.32856, b3 0.23349, b4 0.16614, padchxlmacf1 0.05533, padchxlmicf1 0.15869, padchxlzmacf1 0.07473, padchxlzmicf1 0.16012, padchxl_loss 0.36196, padchxlz_loss 0.48090, 90.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.97002, wmdcmp 0.14055, ema 0.68218, oracc 0.98609, qlmicf1 0.37031, qlmacf1 0.20672, chxlmicf1 0.51147, chxlmacf1 0.45437, chxlacc 0.68322, chxlrocaucmic 0.77890, chxlrocaucmac 0.74182, 21.98 secs\n",
      "Adjusting learning rate of group 0 to 6.4001e-05.\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000064) ...\n",
      "loss 3.06788, a_loss 1.36154, cD 0.87218, wmdcmp 0.12259, ema 0.61018, oracc 0.98319, orien_loss 0.03437, qlmicf1 0.34514, qlmacf1 0.20149, ql_loss 0.81399, chxlmicf1 0.49109, chxlmacf1 0.44930, chx_loss 0.90648, chxlacc 0.68751, chxlrocaucmic 0.77713, chxlrocaucmac 0.76036, gacc 0.96035, gloss 0.10857, cxr14micf1 0.31619, cxr14macf1 0.31452, cxr14_loss 0.98907, vnbgmicf1 0.54679, vnbgmacf1 0.41132, vnbg_loss 0.79909, b1 0.46746, b2 0.34200, b3 0.24696, b4 0.17545, padchxlmacf1 0.06019, padchxlmicf1 0.16224, padchxlzmacf1 0.08133, padchxlzmicf1 0.17522, padchxl_loss 0.37126, padchxlz_loss 0.49710, 87.78 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 0.93764, wmdcmp 0.13906, ema 0.68666, oracc 0.98609, qlmicf1 0.36135, qlmacf1 0.20703, chxlmicf1 0.51081, chxlmacf1 0.45024, chxlacc 0.67353, chxlrocaucmic 0.78175, chxlrocaucmac 0.73964, 21.96 secs\n",
      "Adjusting learning rate of group 0 to 6.0456e-05.\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 1.93145, a_loss 1.35544, cD 0.84616, wmdcmp 0.12001, ema 0.60522, oracc 0.98251, orien_loss 0.03104, qlmicf1 0.35209, qlmacf1 0.20387, ql_loss 0.80963, chxlmicf1 0.49888, chxlmacf1 0.45580, chx_loss 0.90371, chxlacc 0.69303, chxlrocaucmic 0.78137, chxlrocaucmac 0.76403, gacc 0.96643, gloss 0.09646, cxr14micf1 0.31738, cxr14macf1 0.31245, cxr14_loss 0.99707, vnbgmicf1 0.55255, vnbgmacf1 0.41838, vnbg_loss 0.80157, b1 0.48155, b2 0.34922, b3 0.24984, b4 0.18105, padchxlmacf1 0.06800, padchxlmicf1 0.16436, padchxlzmacf1 0.07831, padchxlzmicf1 0.17368, padchxl_loss 0.36867, padchxlz_loss 0.50394, 87.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.98163, wmdcmp 0.14347, ema 0.68218, oracc 0.98586, qlmicf1 0.34541, qlmacf1 0.20538, chxlmicf1 0.51987, chxlmacf1 0.45637, chxlacc 0.68601, chxlrocaucmic 0.78374, chxlrocaucmac 0.74104, 22.12 secs\n",
      "Adjusting learning rate of group 0 to 5.7108e-05.\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000057) ...\n",
      "loss 1.31644, a_loss 1.35048, cD 0.86905, wmdcmp 0.12185, ema 0.61288, oracc 0.98392, orien_loss 0.02981, qlmicf1 0.34734, qlmacf1 0.20482, ql_loss 0.80664, chxlmicf1 0.50056, chxlmacf1 0.45797, chx_loss 0.89484, chxlacc 0.69369, chxlrocaucmic 0.78192, chxlrocaucmac 0.76687, gacc 0.96173, gloss 0.09441, cxr14micf1 0.31702, cxr14macf1 0.31696, cxr14_loss 0.98146, vnbgmicf1 0.54258, vnbgmacf1 0.41160, vnbg_loss 0.79715, b1 0.45137, b2 0.33059, b3 0.24046, b4 0.17651, padchxlmacf1 0.05766, padchxlmicf1 0.15975, padchxlzmacf1 0.07625, padchxlzmicf1 0.16741, padchxl_loss 0.36256, padchxlz_loss 0.48713, 87.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00853, wmdcmp 0.14614, ema 0.68935, oracc 0.98397, qlmicf1 0.34449, qlmacf1 0.20785, chxlmicf1 0.51778, chxlmacf1 0.45560, chxlacc 0.68766, chxlrocaucmic 0.78666, chxlrocaucmac 0.74828, 21.69 secs\n",
      "Adjusting learning rate of group 0 to 5.3946e-05.\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 5.33980, a_loss 1.34856, cD 0.86877, wmdcmp 0.12121, ema 0.61049, oracc 0.98157, orien_loss 0.02659, qlmicf1 0.35194, qlmacf1 0.20596, ql_loss 0.80331, chxlmicf1 0.49585, chxlmacf1 0.45179, chx_loss 0.89647, chxlacc 0.69264, chxlrocaucmic 0.78173, chxlrocaucmac 0.76451, gacc 0.96451, gloss 0.09014, cxr14micf1 0.31114, cxr14macf1 0.31105, cxr14_loss 0.99518, vnbgmicf1 0.55532, vnbgmacf1 0.42361, vnbg_loss 0.75448, b1 0.46935, b2 0.34206, b3 0.24320, b4 0.17257, padchxlmacf1 0.06012, padchxlmicf1 0.16354, padchxlzmacf1 0.07390, padchxlzmicf1 0.15972, padchxl_loss 0.36099, padchxlz_loss 0.50250, 88.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.03659, wmdcmp 0.14771, ema 0.68487, oracc 0.98657, qlmicf1 0.34520, qlmacf1 0.20716, chxlmicf1 0.52486, chxlmacf1 0.45821, chxlacc 0.70059, chxlrocaucmic 0.78815, chxlrocaucmac 0.74865, 20.80 secs\n",
      "Adjusting learning rate of group 0 to 5.0958e-05.\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 0.70936, a_loss 1.33230, cD 0.89954, wmdcmp 0.12506, ema 0.61531, oracc 0.98292, orien_loss 0.02842, qlmicf1 0.35033, qlmacf1 0.20744, ql_loss 0.80319, chxlmicf1 0.50244, chxlmacf1 0.46008, chx_loss 0.88550, chxlacc 0.69894, chxlrocaucmic 0.78536, chxlrocaucmac 0.77131, gacc 0.96801, gloss 0.09010, cxr14micf1 0.32761, cxr14macf1 0.31602, cxr14_loss 0.98580, vnbgmicf1 0.55708, vnbgmacf1 0.42020, vnbg_loss 0.78086, b1 0.46040, b2 0.33495, b3 0.23989, b4 0.17339, padchxlmacf1 0.06280, padchxlmicf1 0.15843, padchxlzmacf1 0.07817, padchxlzmicf1 0.16013, padchxl_loss 0.36579, padchxlz_loss 0.50694, 90.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.02023, wmdcmp 0.14733, ema 0.69382, oracc 0.98704, qlmicf1 0.35135, qlmacf1 0.20992, chxlmicf1 0.50022, chxlmacf1 0.45403, chxlacc 0.66374, chxlrocaucmic 0.77034, chxlrocaucmac 0.74213, 20.49 secs\n",
      "Adjusting learning rate of group 0 to 4.8136e-05.\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 1.87602, a_loss 1.32930, cD 0.91810, wmdcmp 0.12725, ema 0.60931, oracc 0.98053, orien_loss 0.03410, qlmicf1 0.35403, qlmacf1 0.20825, ql_loss 0.80251, chxlmicf1 0.50222, chxlmacf1 0.46071, chx_loss 0.88998, chxlacc 0.69806, chxlrocaucmic 0.78525, chxlrocaucmac 0.77124, gacc 0.96206, gloss 0.09448, cxr14micf1 0.32608, cxr14macf1 0.32281, cxr14_loss 0.97626, vnbgmicf1 0.55548, vnbgmacf1 0.41739, vnbg_loss 0.76680, b1 0.45407, b2 0.33440, b3 0.24269, b4 0.17783, padchxlmacf1 0.06653, padchxlmicf1 0.15894, padchxlzmacf1 0.07877, padchxlzmicf1 0.17327, padchxl_loss 0.36818, padchxlz_loss 0.52924, 90.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.02420, wmdcmp 0.14959, ema 0.66786, oracc 0.98704, qlmicf1 0.35955, qlmacf1 0.20837, chxlmicf1 0.50529, chxlmacf1 0.45413, chxlacc 0.67414, chxlrocaucmic 0.77519, chxlrocaucmac 0.74531, 21.76 secs\n",
      "Adjusting learning rate of group 0 to 4.5471e-05.\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 1.36912, a_loss 1.30992, cD 0.92467, wmdcmp 0.12803, ema 0.62053, oracc 0.98305, orien_loss 0.02918, qlmicf1 0.35676, qlmacf1 0.20815, ql_loss 0.79766, chxlmicf1 0.50303, chxlmacf1 0.45961, chx_loss 0.88336, chxlacc 0.69848, chxlrocaucmic 0.78768, chxlrocaucmac 0.77195, gacc 0.96537, gloss 0.09342, cxr14micf1 0.33991, cxr14macf1 0.32713, cxr14_loss 0.96241, vnbgmicf1 0.55565, vnbgmacf1 0.41795, vnbg_loss 0.76732, b1 0.47190, b2 0.34296, b3 0.24711, b4 0.17966, padchxlmacf1 0.06658, padchxlmicf1 0.16891, padchxlzmacf1 0.08518, padchxlzmicf1 0.16996, padchxl_loss 0.34657, padchxlz_loss 0.48309, 87.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.04293, wmdcmp 0.15029, ema 0.70367, oracc 0.98704, qlmicf1 0.37221, qlmacf1 0.21365, chxlmicf1 0.53100, chxlmacf1 0.46219, chxlacc 0.70029, chxlrocaucmic 0.79698, chxlrocaucmac 0.75145, 22.76 secs\n",
      "Adjusting learning rate of group 0 to 4.2953e-05.\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 5.24799, a_loss 1.32787, cD 0.90140, wmdcmp 0.12674, ema 0.61434, oracc 0.98488, orien_loss 0.02922, qlmicf1 0.35945, qlmacf1 0.21088, ql_loss 0.79545, chxlmicf1 0.50537, chxlmacf1 0.46125, chx_loss 0.88068, chxlacc 0.70073, chxlrocaucmic 0.78999, chxlrocaucmac 0.77506, gacc 0.96853, gloss 0.08518, cxr14micf1 0.30992, cxr14macf1 0.31227, cxr14_loss 0.99434, vnbgmicf1 0.56037, vnbgmacf1 0.42643, vnbg_loss 0.74429, b1 0.47105, b2 0.34284, b3 0.24427, b4 0.17443, padchxlmacf1 0.06681, padchxlmicf1 0.16772, padchxlzmacf1 0.08149, padchxlzmicf1 0.17179, padchxl_loss 0.36555, padchxlz_loss 0.49852, 87.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05210, wmdcmp 0.15244, ema 0.69472, oracc 0.98751, qlmicf1 0.36029, qlmacf1 0.20941, chxlmicf1 0.51942, chxlmacf1 0.45705, chxlacc 0.69402, chxlrocaucmic 0.78758, chxlrocaucmac 0.74927, 21.98 secs\n",
      "Adjusting learning rate of group 0 to 4.0574e-05.\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 2.64482, a_loss 1.31129, cD 0.92226, wmdcmp 0.12774, ema 0.62479, oracc 0.98227, orien_loss 0.02843, qlmicf1 0.36013, qlmacf1 0.21063, ql_loss 0.79504, chxlmicf1 0.50789, chxlmacf1 0.46401, chx_loss 0.87552, chxlacc 0.70426, chxlrocaucmic 0.79000, chxlrocaucmac 0.77644, gacc 0.96433, gloss 0.09362, cxr14micf1 0.33414, cxr14macf1 0.32020, cxr14_loss 0.97847, vnbgmicf1 0.56619, vnbgmacf1 0.42948, vnbg_loss 0.73303, b1 0.47374, b2 0.34976, b3 0.25657, b4 0.18846, padchxlmacf1 0.06526, padchxlmicf1 0.16451, padchxlzmacf1 0.07803, padchxlzmicf1 0.17447, padchxl_loss 0.35645, padchxlz_loss 0.49873, 87.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07129, wmdcmp 0.15607, ema 0.69472, oracc 0.98657, qlmicf1 0.37002, qlmacf1 0.21152, chxlmicf1 0.52937, chxlmacf1 0.46227, chxlacc 0.69838, chxlrocaucmic 0.79709, chxlrocaucmac 0.75227, 22.38 secs\n",
      "Adjusting learning rate of group 0 to 3.8327e-05.\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 4.49550, a_loss 1.31782, cD 0.92432, wmdcmp 0.12867, ema 0.61049, oracc 0.98144, orien_loss 0.03290, qlmicf1 0.35738, qlmacf1 0.21230, ql_loss 0.79409, chxlmicf1 0.50997, chxlmacf1 0.46453, chx_loss 0.87847, chxlacc 0.70722, chxlrocaucmic 0.79186, chxlrocaucmac 0.77681, gacc 0.97010, gloss 0.07860, cxr14micf1 0.33169, cxr14macf1 0.32678, cxr14_loss 0.96687, vnbgmicf1 0.55987, vnbgmacf1 0.42762, vnbg_loss 0.74881, b1 0.47776, b2 0.35527, b3 0.25937, b4 0.19039, padchxlmacf1 0.06858, padchxlmicf1 0.16440, padchxlzmacf1 0.08303, padchxlzmicf1 0.17675, padchxl_loss 0.36597, padchxlz_loss 0.49929, 89.44 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.04325, wmdcmp 0.15336, ema 0.68845, oracc 0.98680, qlmicf1 0.37018, qlmacf1 0.21412, chxlmicf1 0.51776, chxlmacf1 0.45746, chxlacc 0.69453, chxlrocaucmic 0.78445, chxlrocaucmac 0.74957, 20.68 secs\n",
      "Adjusting learning rate of group 0 to 3.6204e-05.\n",
      "\u001b[1m---- Epoch 38/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 1.72231, a_loss 1.29688, cD 0.91844, wmdcmp 0.12721, ema 0.61905, oracc 0.98232, orien_loss 0.03130, qlmicf1 0.36281, qlmacf1 0.21257, ql_loss 0.79380, chxlmicf1 0.51067, chxlmacf1 0.46726, chx_loss 0.86970, chxlacc 0.70478, chxlrocaucmic 0.79454, chxlrocaucmac 0.77986, gacc 0.96556, gloss 0.08859, cxr14micf1 0.31644, cxr14macf1 0.31435, cxr14_loss 0.97769, vnbgmicf1 0.57620, vnbgmacf1 0.43504, vnbg_loss 0.72614, b1 0.47790, b2 0.35457, b3 0.25947, b4 0.19335, padchxlmacf1 0.06283, padchxlmicf1 0.16498, padchxlzmacf1 0.08043, padchxlzmicf1 0.16454, padchxl_loss 0.34947, padchxlz_loss 0.48343, 93.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07789, wmdcmp 0.15636, ema 0.69472, oracc 0.98704, qlmicf1 0.35948, qlmacf1 0.21197, chxlmicf1 0.51843, chxlmacf1 0.45573, chxlacc 0.69417, chxlrocaucmic 0.78768, chxlrocaucmac 0.75143, 20.85 secs\n",
      "Adjusting learning rate of group 0 to 3.4200e-05.\n",
      "\u001b[1m---- Epoch 39/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 5.13484, a_loss 1.31592, cD 0.93930, wmdcmp 0.13026, ema 0.62115, oracc 0.98227, orien_loss 0.02879, qlmicf1 0.35711, qlmacf1 0.21148, ql_loss 0.79116, chxlmicf1 0.50945, chxlmacf1 0.46640, chx_loss 0.86800, chxlacc 0.70647, chxlrocaucmic 0.79527, chxlrocaucmac 0.78193, gacc 0.97273, gloss 0.07299, cxr14micf1 0.32467, cxr14macf1 0.32230, cxr14_loss 0.98692, vnbgmicf1 0.56941, vnbgmacf1 0.42841, vnbg_loss 0.72982, b1 0.44824, b2 0.32830, b3 0.23727, b4 0.17013, padchxlmacf1 0.06872, padchxlmicf1 0.17946, padchxlzmacf1 0.08381, padchxlzmicf1 0.17334, padchxl_loss 0.36221, padchxlz_loss 0.50381, 90.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09110, wmdcmp 0.15787, ema 0.70278, oracc 0.98751, qlmicf1 0.37391, qlmacf1 0.21338, chxlmicf1 0.51780, chxlmacf1 0.45949, chxlacc 0.69574, chxlrocaucmic 0.78592, chxlrocaucmac 0.75355, 22.10 secs\n",
      "Adjusting learning rate of group 0 to 3.2306e-05.\n",
      "\u001b[1m---- Epoch 40/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.28867, a_loss 1.29809, cD 0.96499, wmdcmp 0.13300, ema 0.61731, oracc 0.98285, orien_loss 0.02726, qlmicf1 0.36065, qlmacf1 0.21229, ql_loss 0.79071, chxlmicf1 0.51313, chxlmacf1 0.46940, chx_loss 0.86763, chxlacc 0.70979, chxlrocaucmic 0.79554, chxlrocaucmac 0.78214, gacc 0.96745, gloss 0.08368, cxr14micf1 0.33010, cxr14macf1 0.32388, cxr14_loss 0.96309, vnbgmicf1 0.58342, vnbgmacf1 0.44332, vnbg_loss 0.73201, b1 0.46682, b2 0.34133, b3 0.24928, b4 0.18156, padchxlmacf1 0.06433, padchxlmicf1 0.16606, padchxlzmacf1 0.08115, padchxlzmicf1 0.16034, padchxl_loss 0.35521, padchxlz_loss 0.50035, 88.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13426, wmdcmp 0.16352, ema 0.69651, oracc 0.98680, qlmicf1 0.36046, qlmacf1 0.21258, chxlmicf1 0.51849, chxlmacf1 0.45949, chxlacc 0.68648, chxlrocaucmic 0.78965, chxlrocaucmac 0.75242, 22.46 secs\n",
      "Adjusting learning rate of group 0 to 3.0517e-05.\n",
      "\u001b[1m---- Epoch 41/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 1.22881, a_loss 1.29793, cD 0.94756, wmdcmp 0.13232, ema 0.62027, oracc 0.98306, orien_loss 0.02750, qlmicf1 0.36460, qlmacf1 0.21914, ql_loss 0.78876, chxlmicf1 0.51261, chxlmacf1 0.46960, chx_loss 0.86610, chxlacc 0.70815, chxlrocaucmic 0.79615, chxlrocaucmac 0.78249, gacc 0.96848, gloss 0.07992, cxr14micf1 0.32450, cxr14macf1 0.32461, cxr14_loss 0.96982, vnbgmicf1 0.57287, vnbgmacf1 0.44350, vnbg_loss 0.72177, b1 0.46282, b2 0.33964, b3 0.24745, b4 0.17863, padchxlmacf1 0.07107, padchxlmicf1 0.16479, padchxlzmacf1 0.08388, padchxlzmicf1 0.17080, padchxl_loss 0.36316, padchxlz_loss 0.51414, 88.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13973, wmdcmp 0.16245, ema 0.69024, oracc 0.98657, qlmicf1 0.37235, qlmacf1 0.21482, chxlmicf1 0.52794, chxlmacf1 0.46041, chxlacc 0.71014, chxlrocaucmic 0.79278, chxlrocaucmac 0.75255, 22.22 secs\n",
      "Adjusting learning rate of group 0 to 2.8827e-05.\n",
      "\u001b[1m---- Epoch 42/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.75096, a_loss 1.28730, cD 0.95980, wmdcmp 0.13306, ema 0.62906, oracc 0.98674, orien_loss 0.02352, qlmicf1 0.36431, qlmacf1 0.21730, ql_loss 0.78881, chxlmicf1 0.51693, chxlmacf1 0.47227, chx_loss 0.86104, chxlacc 0.71147, chxlrocaucmic 0.79929, chxlrocaucmac 0.78608, gacc 0.96678, gloss 0.08109, cxr14micf1 0.33052, cxr14macf1 0.32419, cxr14_loss 0.95880, vnbgmicf1 0.58293, vnbgmacf1 0.44397, vnbg_loss 0.71897, b1 0.45822, b2 0.33112, b3 0.23798, b4 0.17117, padchxlmacf1 0.06613, padchxlmicf1 0.16809, padchxlzmacf1 0.08063, padchxlzmicf1 0.15582, padchxl_loss 0.34590, padchxlz_loss 0.49228, 88.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13800, wmdcmp 0.16388, ema 0.70098, oracc 0.98704, qlmicf1 0.36377, qlmacf1 0.21255, chxlmicf1 0.52444, chxlmacf1 0.46432, chxlacc 0.70165, chxlrocaucmic 0.78765, chxlrocaucmac 0.75495, 22.13 secs\n",
      "Adjusting learning rate of group 0 to 2.7230e-05.\n",
      "\u001b[1m---- Epoch 43/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.13166, a_loss 1.30766, cD 0.94504, wmdcmp 0.13091, ema 0.62037, oracc 0.98374, orien_loss 0.02715, qlmicf1 0.36490, qlmacf1 0.21315, ql_loss 0.78728, chxlmicf1 0.51200, chxlmacf1 0.46745, chx_loss 0.86727, chxlacc 0.70860, chxlrocaucmic 0.79403, chxlrocaucmac 0.77883, gacc 0.97325, gloss 0.07206, cxr14micf1 0.34741, cxr14macf1 0.33952, cxr14_loss 0.94720, vnbgmicf1 0.58474, vnbgmacf1 0.44618, vnbg_loss 0.69266, b1 0.46093, b2 0.33551, b3 0.24064, b4 0.17308, padchxlmacf1 0.07072, padchxlmicf1 0.17240, padchxlzmacf1 0.08003, padchxlzmicf1 0.16505, padchxl_loss 0.35351, padchxlz_loss 0.49664, 89.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13370, wmdcmp 0.16314, ema 0.70636, oracc 0.98680, qlmicf1 0.37911, qlmacf1 0.21707, chxlmicf1 0.52666, chxlmacf1 0.46317, chxlacc 0.70036, chxlrocaucmic 0.79260, chxlrocaucmac 0.75565, 20.61 secs\n",
      "Adjusting learning rate of group 0 to 2.5722e-05.\n",
      "\u001b[1m---- Epoch 44/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 2.57306, a_loss 1.26733, cD 0.97186, wmdcmp 0.13442, ema 0.62410, oracc 0.98184, orien_loss 0.02946, qlmicf1 0.36549, qlmacf1 0.21690, ql_loss 0.78475, chxlmicf1 0.51727, chxlmacf1 0.47324, chx_loss 0.85940, chxlacc 0.71075, chxlrocaucmic 0.80026, chxlrocaucmac 0.78441, gacc 0.97108, gloss 0.07429, cxr14micf1 0.33123, cxr14macf1 0.32447, cxr14_loss 0.96706, vnbgmicf1 0.58920, vnbgmacf1 0.44669, vnbg_loss 0.68815, b1 0.46198, b2 0.34395, b3 0.25586, b4 0.19122, padchxlmacf1 0.06818, padchxlmicf1 0.17978, padchxlzmacf1 0.08845, padchxlzmicf1 0.18132, padchxl_loss 0.34227, padchxlz_loss 0.48470, 93.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13766, wmdcmp 0.16395, ema 0.69203, oracc 0.98680, qlmicf1 0.35753, qlmacf1 0.21491, chxlmicf1 0.51916, chxlmacf1 0.45875, chxlacc 0.69174, chxlrocaucmic 0.78852, chxlrocaucmac 0.75376, 20.16 secs\n",
      "Adjusting learning rate of group 0 to 2.4298e-05.\n",
      "\u001b[1m---- Epoch 45/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.76088, a_loss 1.28149, cD 0.96154, wmdcmp 0.13270, ema 0.62349, oracc 0.98361, orien_loss 0.02715, qlmicf1 0.36964, qlmacf1 0.21959, ql_loss 0.78087, chxlmicf1 0.51997, chxlmacf1 0.47423, chx_loss 0.85739, chxlacc 0.71290, chxlrocaucmic 0.80114, chxlrocaucmac 0.78677, gacc 0.97150, gloss 0.07596, cxr14micf1 0.31910, cxr14macf1 0.31824, cxr14_loss 0.97409, vnbgmicf1 0.57380, vnbgmacf1 0.43188, vnbg_loss 0.71304, b1 0.47557, b2 0.35146, b3 0.25497, b4 0.18156, padchxlmacf1 0.07135, padchxlmicf1 0.17180, padchxlzmacf1 0.08496, padchxlzmicf1 0.16671, padchxl_loss 0.35935, padchxlz_loss 0.50628, 91.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13721, wmdcmp 0.16390, ema 0.68577, oracc 0.98633, qlmicf1 0.36736, qlmacf1 0.21787, chxlmicf1 0.52256, chxlmacf1 0.46198, chxlacc 0.69406, chxlrocaucmic 0.79164, chxlrocaucmac 0.75495, 23.12 secs\n",
      "Adjusting learning rate of group 0 to 2.2952e-05.\n",
      "\u001b[1m---- Epoch 46/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.54159, a_loss 1.27936, cD 0.94595, wmdcmp 0.13141, ema 0.62140, oracc 0.98483, orien_loss 0.02496, qlmicf1 0.36479, qlmacf1 0.21741, ql_loss 0.78184, chxlmicf1 0.51880, chxlmacf1 0.47549, chx_loss 0.86068, chxlacc 0.71406, chxlrocaucmic 0.79943, chxlrocaucmac 0.78556, gacc 0.97168, gloss 0.07486, cxr14micf1 0.31218, cxr14macf1 0.31208, cxr14_loss 0.98141, vnbgmicf1 0.58094, vnbgmacf1 0.45218, vnbg_loss 0.71490, b1 0.46183, b2 0.34415, b3 0.25469, b4 0.18817, padchxlmacf1 0.06962, padchxlmicf1 0.17313, padchxlzmacf1 0.08165, padchxlzmicf1 0.16525, padchxl_loss 0.34199, padchxlz_loss 0.48417, 88.50 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.14862, wmdcmp 0.16545, ema 0.69740, oracc 0.98633, qlmicf1 0.36624, qlmacf1 0.21683, chxlmicf1 0.51640, chxlmacf1 0.46083, chxlacc 0.69220, chxlrocaucmic 0.78380, chxlrocaucmac 0.75643, 23.03 secs\n",
      "Adjusting learning rate of group 0 to 2.1681e-05.\n",
      "\u001b[1m---- Epoch 47/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 5.01965, a_loss 1.28049, cD 0.97508, wmdcmp 0.13446, ema 0.63112, oracc 0.98347, orien_loss 0.02320, qlmicf1 0.37056, qlmacf1 0.21557, ql_loss 0.78550, chxlmicf1 0.51742, chxlmacf1 0.47377, chx_loss 0.85807, chxlacc 0.71198, chxlrocaucmic 0.79894, chxlrocaucmac 0.78756, gacc 0.97045, gloss 0.07332, cxr14micf1 0.34981, cxr14macf1 0.33512, cxr14_loss 0.93254, vnbgmicf1 0.57512, vnbgmacf1 0.43618, vnbg_loss 0.70224, b1 0.48400, b2 0.35625, b3 0.25731, b4 0.18360, padchxlmacf1 0.06759, padchxlmicf1 0.17347, padchxlzmacf1 0.07940, padchxlzmicf1 0.16813, padchxl_loss 0.35082, padchxlz_loss 0.49514, 88.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14573, wmdcmp 0.16451, ema 0.69382, oracc 0.98680, qlmicf1 0.37011, qlmacf1 0.21545, chxlmicf1 0.52371, chxlmacf1 0.45971, chxlacc 0.70042, chxlrocaucmic 0.79289, chxlrocaucmac 0.75788, 22.34 secs\n",
      "Adjusting learning rate of group 0 to 2.0480e-05.\n",
      "\u001b[1m---- Epoch 48/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 1.89288, a_loss 1.26847, cD 0.96488, wmdcmp 0.13248, ema 0.63950, oracc 0.98492, orien_loss 0.02327, qlmicf1 0.36482, qlmacf1 0.21608, ql_loss 0.78166, chxlmicf1 0.51800, chxlmacf1 0.47388, chx_loss 0.85405, chxlacc 0.71614, chxlrocaucmic 0.80276, chxlrocaucmac 0.78943, gacc 0.96836, gloss 0.08504, cxr14micf1 0.34420, cxr14macf1 0.33309, cxr14_loss 0.96577, vnbgmicf1 0.58809, vnbgmacf1 0.45008, vnbg_loss 0.69186, b1 0.45592, b2 0.33279, b3 0.23958, b4 0.16993, padchxlmacf1 0.06672, padchxlmicf1 0.17214, padchxlzmacf1 0.07922, padchxlzmicf1 0.16639, padchxl_loss 0.34797, padchxlz_loss 0.48604, 91.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16712, wmdcmp 0.16627, ema 0.69203, oracc 0.98704, qlmicf1 0.36678, qlmacf1 0.21673, chxlmicf1 0.52767, chxlmacf1 0.46268, chxlacc 0.70333, chxlrocaucmic 0.79538, chxlrocaucmac 0.75979, 23.57 secs\n",
      "Adjusting learning rate of group 0 to 1.9346e-05.\n",
      "\u001b[1m---- Epoch 49/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.14410, a_loss 1.27542, cD 0.97182, wmdcmp 0.13456, ema 0.63201, oracc 0.98670, orien_loss 0.01915, qlmicf1 0.36621, qlmacf1 0.21882, ql_loss 0.78220, chxlmicf1 0.51883, chxlmacf1 0.47657, chx_loss 0.85546, chxlacc 0.71275, chxlrocaucmic 0.79974, chxlrocaucmac 0.78596, gacc 0.96866, gloss 0.07995, cxr14micf1 0.33688, cxr14macf1 0.33226, cxr14_loss 0.94429, vnbgmicf1 0.57520, vnbgmacf1 0.43947, vnbg_loss 0.70395, b1 0.49136, b2 0.35821, b3 0.25829, b4 0.18680, padchxlmacf1 0.06289, padchxlmicf1 0.16704, padchxlzmacf1 0.08415, padchxlzmicf1 0.17119, padchxl_loss 0.35048, padchxlz_loss 0.49977, 93.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16105, wmdcmp 0.16520, ema 0.69740, oracc 0.98680, qlmicf1 0.37246, qlmacf1 0.21903, chxlmicf1 0.52386, chxlmacf1 0.46231, chxlacc 0.70315, chxlrocaucmic 0.78993, chxlrocaucmac 0.75637, 23.15 secs\n",
      "Adjusting learning rate of group 0 to 1.8275e-05.\n",
      "\u001b[1m---- Epoch 50/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 4.82820, a_loss 1.28095, cD 0.96671, wmdcmp 0.13316, ema 0.62684, oracc 0.98278, orien_loss 0.02298, qlmicf1 0.36934, qlmacf1 0.21695, ql_loss 0.78003, chxlmicf1 0.51829, chxlmacf1 0.47390, chx_loss 0.85026, chxlacc 0.71553, chxlrocaucmic 0.80366, chxlrocaucmac 0.79044, gacc 0.97360, gloss 0.06652, cxr14micf1 0.34240, cxr14macf1 0.33368, cxr14_loss 0.94305, vnbgmicf1 0.58068, vnbgmacf1 0.45630, vnbg_loss 0.68815, b1 0.48199, b2 0.35722, b3 0.26328, b4 0.19630, padchxlmacf1 0.07442, padchxlmicf1 0.17411, padchxlzmacf1 0.08715, padchxlzmicf1 0.18002, padchxl_loss 0.35050, padchxlz_loss 0.48718, 95.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15917, wmdcmp 0.16613, ema 0.70009, oracc 0.98727, qlmicf1 0.37033, qlmacf1 0.21762, chxlmicf1 0.52207, chxlmacf1 0.45931, chxlacc 0.70273, chxlrocaucmic 0.78984, chxlrocaucmac 0.75563, 22.36 secs\n",
      "Adjusting learning rate of group 0 to 1.7263e-05.\n",
      "\u001b[1m---- Epoch 51/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.61890, a_loss 1.27447, cD 0.98007, wmdcmp 0.13506, ema 0.62366, oracc 0.98539, orien_loss 0.02517, qlmicf1 0.36586, qlmacf1 0.21551, ql_loss 0.78506, chxlmicf1 0.52119, chxlmacf1 0.47756, chx_loss 0.84830, chxlacc 0.71742, chxlrocaucmic 0.80493, chxlrocaucmac 0.79063, gacc 0.97351, gloss 0.06843, cxr14micf1 0.32395, cxr14macf1 0.32641, cxr14_loss 0.96877, vnbgmicf1 0.58430, vnbgmacf1 0.44353, vnbg_loss 0.68747, b1 0.46796, b2 0.34032, b3 0.24205, b4 0.17035, padchxlmacf1 0.07235, padchxlmicf1 0.18310, padchxlzmacf1 0.09180, padchxlzmicf1 0.17490, padchxl_loss 0.33917, padchxlz_loss 0.49989, 107.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.12326, wmdcmp 0.16245, ema 0.71173, oracc 0.98704, qlmicf1 0.37017, qlmacf1 0.21908, chxlmicf1 0.52482, chxlmacf1 0.46355, chxlacc 0.70193, chxlrocaucmic 0.79254, chxlrocaucmac 0.75941, 61.12 secs\n",
      "Adjusting learning rate of group 0 to 1.6307e-05.\n",
      "\u001b[1m---- Epoch 52/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 1.81013, a_loss 1.27178, cD 0.97440, wmdcmp 0.13486, ema 0.62819, oracc 0.98305, orien_loss 0.02713, qlmicf1 0.37103, qlmacf1 0.22163, ql_loss 0.78104, chxlmicf1 0.52142, chxlmacf1 0.47705, chx_loss 0.85283, chxlacc 0.71637, chxlrocaucmic 0.80242, chxlrocaucmac 0.78942, gacc 0.96748, gloss 0.08456, cxr14micf1 0.34331, cxr14macf1 0.33210, cxr14_loss 0.94045, vnbgmicf1 0.57876, vnbgmacf1 0.44282, vnbg_loss 0.69618, b1 0.47969, b2 0.35577, b3 0.26134, b4 0.19242, padchxlmacf1 0.07290, padchxlmicf1 0.16192, padchxlzmacf1 0.08457, padchxlzmicf1 0.17425, padchxl_loss 0.36702, padchxlz_loss 0.49269, 98.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16573, wmdcmp 0.16706, ema 0.69740, oracc 0.98727, qlmicf1 0.35738, qlmacf1 0.21666, chxlmicf1 0.52499, chxlmacf1 0.46502, chxlacc 0.69159, chxlrocaucmic 0.79574, chxlrocaucmac 0.75983, 65.80 secs\n",
      "Adjusting learning rate of group 0 to 1.5404e-05.\n",
      "\u001b[1m---- Epoch 53/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.11611, a_loss 1.25485, cD 0.99532, wmdcmp 0.13785, ema 0.63062, oracc 0.98489, orien_loss 0.02433, qlmicf1 0.36506, qlmacf1 0.22015, ql_loss 0.77784, chxlmicf1 0.52458, chxlmacf1 0.48045, chx_loss 0.84707, chxlacc 0.71794, chxlrocaucmic 0.80468, chxlrocaucmac 0.79178, gacc 0.97524, gloss 0.07041, cxr14micf1 0.34106, cxr14macf1 0.33563, cxr14_loss 0.94409, vnbgmicf1 0.57908, vnbgmacf1 0.44550, vnbg_loss 0.68358, b1 0.48665, b2 0.36526, b3 0.26932, b4 0.19752, padchxlmacf1 0.07344, padchxlmicf1 0.17608, padchxlzmacf1 0.08319, padchxlzmicf1 0.17262, padchxl_loss 0.33487, padchxlz_loss 0.48073, 98.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16046, wmdcmp 0.16665, ema 0.69651, oracc 0.98704, qlmicf1 0.36766, qlmacf1 0.21909, chxlmicf1 0.52268, chxlmacf1 0.46485, chxlacc 0.69611, chxlrocaucmic 0.78985, chxlrocaucmac 0.76169, 66.06 secs\n",
      "Adjusting learning rate of group 0 to 1.4551e-05.\n",
      "\u001b[1m---- Epoch 54/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 5.38004, a_loss 1.27467, cD 0.98286, wmdcmp 0.13730, ema 0.63645, oracc 0.98354, orien_loss 0.02549, qlmicf1 0.37090, qlmacf1 0.22236, ql_loss 0.77497, chxlmicf1 0.52188, chxlmacf1 0.47812, chx_loss 0.84837, chxlacc 0.71688, chxlrocaucmic 0.80306, chxlrocaucmac 0.79079, gacc 0.97395, gloss 0.07207, cxr14micf1 0.32149, cxr14macf1 0.32313, cxr14_loss 0.95924, vnbgmicf1 0.59382, vnbgmacf1 0.45634, vnbg_loss 0.66997, b1 0.47798, b2 0.35414, b3 0.25672, b4 0.18533, padchxlmacf1 0.07892, padchxlmicf1 0.17516, padchxlzmacf1 0.08134, padchxlzmicf1 0.17025, padchxl_loss 0.34745, padchxlz_loss 0.50231, 99.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19109, wmdcmp 0.16935, ema 0.69740, oracc 0.98704, qlmicf1 0.37404, qlmacf1 0.21832, chxlmicf1 0.52603, chxlmacf1 0.46569, chxlacc 0.70163, chxlrocaucmic 0.79223, chxlrocaucmac 0.76036, 62.62 secs\n",
      "Adjusting learning rate of group 0 to 1.3745e-05.\n",
      "\u001b[1m---- Epoch 55/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.68899, a_loss 1.25239, cD 0.97139, wmdcmp 0.13466, ema 0.63897, oracc 0.98436, orien_loss 0.02247, qlmicf1 0.36749, qlmacf1 0.21958, ql_loss 0.77616, chxlmicf1 0.52341, chxlmacf1 0.47883, chx_loss 0.84405, chxlacc 0.71682, chxlrocaucmic 0.80705, chxlrocaucmac 0.79313, gacc 0.97430, gloss 0.07202, cxr14micf1 0.35073, cxr14macf1 0.33686, cxr14_loss 0.94079, vnbgmicf1 0.59107, vnbgmacf1 0.45161, vnbg_loss 0.67029, b1 0.47497, b2 0.34960, b3 0.25525, b4 0.18379, padchxlmacf1 0.06707, padchxlmicf1 0.17481, padchxlzmacf1 0.08264, padchxlzmicf1 0.16893, padchxl_loss 0.33745, padchxlz_loss 0.47839, 102.98 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.15338, wmdcmp 0.16571, ema 0.70546, oracc 0.98704, qlmicf1 0.36964, qlmacf1 0.21953, chxlmicf1 0.51712, chxlmacf1 0.46041, chxlacc 0.69744, chxlrocaucmic 0.78423, chxlrocaucmac 0.75805, 58.64 secs\n",
      "Adjusting learning rate of group 0 to 1.2984e-05.\n",
      "\u001b[1m---- Epoch 56/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.69633, a_loss 1.25350, cD 1.00471, wmdcmp 0.13779, ema 0.63932, oracc 0.98441, orien_loss 0.02586, qlmicf1 0.37203, qlmacf1 0.21830, ql_loss 0.77412, chxlmicf1 0.52713, chxlmacf1 0.48211, chx_loss 0.83760, chxlacc 0.72238, chxlrocaucmic 0.80869, chxlrocaucmac 0.79574, gacc 0.97413, gloss 0.07027, cxr14micf1 0.35923, cxr14macf1 0.34310, cxr14_loss 0.93346, vnbgmicf1 0.59512, vnbgmacf1 0.46406, vnbg_loss 0.66118, b1 0.47690, b2 0.35209, b3 0.25651, b4 0.18951, padchxlmacf1 0.07219, padchxlmicf1 0.17803, padchxlzmacf1 0.08212, padchxlzmicf1 0.16627, padchxl_loss 0.35560, padchxlz_loss 0.49015, 107.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15001, wmdcmp 0.16614, ema 0.70098, oracc 0.98680, qlmicf1 0.37392, qlmacf1 0.22000, chxlmicf1 0.52787, chxlmacf1 0.46497, chxlacc 0.70477, chxlrocaucmic 0.79447, chxlrocaucmac 0.75725, 22.97 secs\n",
      "Adjusting learning rate of group 0 to 1.2265e-05.\n",
      "\u001b[1m---- Epoch 57/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.14392, a_loss 1.24891, cD 0.97931, wmdcmp 0.13540, ema 0.63619, oracc 0.98601, orien_loss 0.02334, qlmicf1 0.37583, qlmacf1 0.21909, ql_loss 0.77186, chxlmicf1 0.52580, chxlmacf1 0.48227, chx_loss 0.84178, chxlacc 0.72047, chxlrocaucmic 0.80778, chxlrocaucmac 0.79587, gacc 0.97576, gloss 0.06786, cxr14micf1 0.37214, cxr14macf1 0.35096, cxr14_loss 0.91911, vnbgmicf1 0.58758, vnbgmacf1 0.44903, vnbg_loss 0.65502, b1 0.50806, b2 0.38434, b3 0.28926, b4 0.21973, padchxlmacf1 0.06705, padchxlmicf1 0.17636, padchxlzmacf1 0.07989, padchxlzmicf1 0.17066, padchxl_loss 0.34107, padchxlz_loss 0.50259, 114.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18619, wmdcmp 0.16858, ema 0.69919, oracc 0.98727, qlmicf1 0.37495, qlmacf1 0.21912, chxlmicf1 0.52892, chxlmacf1 0.46327, chxlacc 0.70723, chxlrocaucmic 0.79586, chxlrocaucmac 0.75769, 40.33 secs\n",
      "Adjusting learning rate of group 0 to 1.1586e-05.\n",
      "\u001b[1m---- Epoch 58/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 5.13388, a_loss 1.27020, cD 0.95803, wmdcmp 0.13261, ema 0.63278, oracc 0.98521, orien_loss 0.02565, qlmicf1 0.37113, qlmacf1 0.22220, ql_loss 0.77000, chxlmicf1 0.52084, chxlmacf1 0.47716, chx_loss 0.85120, chxlacc 0.71816, chxlrocaucmic 0.80549, chxlrocaucmac 0.79179, gacc 0.97570, gloss 0.06270, cxr14micf1 0.33176, cxr14macf1 0.32898, cxr14_loss 0.94179, vnbgmicf1 0.59027, vnbgmacf1 0.45544, vnbg_loss 0.68034, b1 0.47534, b2 0.34924, b3 0.25375, b4 0.18378, padchxlmacf1 0.07339, padchxlmicf1 0.17562, padchxlzmacf1 0.08497, padchxlzmicf1 0.18236, padchxl_loss 0.34972, padchxlz_loss 0.49249, 108.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18766, wmdcmp 0.16948, ema 0.69561, oracc 0.98727, qlmicf1 0.37738, qlmacf1 0.22182, chxlmicf1 0.52866, chxlmacf1 0.46294, chxlacc 0.70346, chxlrocaucmic 0.79578, chxlrocaucmac 0.75519, 55.75 secs\n",
      "Adjusting learning rate of group 0 to 1.0944e-05.\n",
      "\u001b[1m---- Epoch 59/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 2.81572, a_loss 1.26225, cD 1.00409, wmdcmp 0.13798, ema 0.62819, oracc 0.98367, orien_loss 0.02485, qlmicf1 0.37947, qlmacf1 0.22073, ql_loss 0.77399, chxlmicf1 0.52695, chxlmacf1 0.48332, chx_loss 0.84063, chxlacc 0.72020, chxlrocaucmic 0.80950, chxlrocaucmac 0.79607, gacc 0.96987, gloss 0.07224, cxr14micf1 0.34453, cxr14macf1 0.33507, cxr14_loss 0.96166, vnbgmicf1 0.59144, vnbgmacf1 0.46750, vnbg_loss 0.65709, b1 0.46869, b2 0.34363, b3 0.24874, b4 0.18030, padchxlmacf1 0.07551, padchxlmicf1 0.18009, padchxlzmacf1 0.08056, padchxlzmicf1 0.17850, padchxl_loss 0.35010, padchxlz_loss 0.48180, 102.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18665, wmdcmp 0.17034, ema 0.69740, oracc 0.98704, qlmicf1 0.37171, qlmacf1 0.22004, chxlmicf1 0.52337, chxlmacf1 0.46329, chxlacc 0.69835, chxlrocaucmic 0.79258, chxlrocaucmac 0.75834, 64.91 secs\n",
      "Adjusting learning rate of group 0 to 1.0338e-05.\n",
      "\u001b[1m---- Epoch 60/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 4.12870, a_loss 1.25702, cD 0.99239, wmdcmp 0.13850, ema 0.63628, oracc 0.98331, orien_loss 0.02653, qlmicf1 0.37298, qlmacf1 0.21982, ql_loss 0.76783, chxlmicf1 0.52647, chxlmacf1 0.48279, chx_loss 0.83989, chxlacc 0.72159, chxlrocaucmic 0.80907, chxlrocaucmac 0.79613, gacc 0.97570, gloss 0.07507, cxr14micf1 0.35612, cxr14macf1 0.34018, cxr14_loss 0.92100, vnbgmicf1 0.59274, vnbgmacf1 0.45704, vnbg_loss 0.67478, b1 0.46930, b2 0.34866, b3 0.25729, b4 0.18744, padchxlmacf1 0.07518, padchxlmicf1 0.18936, padchxlzmacf1 0.08553, padchxlzmicf1 0.17959, padchxl_loss 0.35564, padchxlz_loss 0.49989, 101.42 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18982, wmdcmp 0.16870, ema 0.69293, oracc 0.98727, qlmicf1 0.37145, qlmacf1 0.21979, chxlmicf1 0.52414, chxlmacf1 0.46177, chxlacc 0.70310, chxlrocaucmic 0.79205, chxlrocaucmac 0.75627, 65.45 secs\n",
      "Adjusting learning rate of group 0 to 9.7654e-06.\n",
      "\u001b[1m---- Epoch 61/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.66570, a_loss 1.25886, cD 0.98368, wmdcmp 0.13624, ema 0.64124, oracc 0.98427, orien_loss 0.02644, qlmicf1 0.37484, qlmacf1 0.22706, ql_loss 0.77277, chxlmicf1 0.53055, chxlmacf1 0.48498, chx_loss 0.83823, chxlacc 0.72363, chxlrocaucmic 0.80991, chxlrocaucmac 0.79737, gacc 0.97780, gloss 0.06387, cxr14micf1 0.35165, cxr14macf1 0.34064, cxr14_loss 0.91730, vnbgmicf1 0.59845, vnbgmacf1 0.46844, vnbg_loss 0.64728, b1 0.48317, b2 0.36462, b3 0.27309, b4 0.20412, padchxlmacf1 0.07403, padchxlmicf1 0.18349, padchxlzmacf1 0.08392, padchxlzmicf1 0.17404, padchxl_loss 0.34389, padchxlz_loss 0.47843, 100.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18568, wmdcmp 0.16806, ema 0.69561, oracc 0.98751, qlmicf1 0.37382, qlmacf1 0.22112, chxlmicf1 0.52785, chxlmacf1 0.46365, chxlacc 0.70877, chxlrocaucmic 0.79376, chxlrocaucmac 0.75976, 61.52 secs\n",
      "Adjusting learning rate of group 0 to 9.2246e-06.\n",
      "\u001b[1m---- Epoch 62/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.59827, a_loss 1.25506, cD 0.97802, wmdcmp 0.13503, ema 0.63121, oracc 0.98608, orien_loss 0.02535, qlmicf1 0.37355, qlmacf1 0.22386, ql_loss 0.77414, chxlmicf1 0.52415, chxlmacf1 0.47861, chx_loss 0.84360, chxlacc 0.71959, chxlrocaucmic 0.80740, chxlrocaucmac 0.79566, gacc 0.97325, gloss 0.06539, cxr14micf1 0.32475, cxr14macf1 0.32426, cxr14_loss 0.96983, vnbgmicf1 0.58262, vnbgmacf1 0.45557, vnbg_loss 0.67574, b1 0.50179, b2 0.37563, b3 0.27770, b4 0.20199, padchxlmacf1 0.07485, padchxlmicf1 0.17345, padchxlzmacf1 0.08267, padchxlzmicf1 0.17766, padchxl_loss 0.34292, padchxlz_loss 0.46768, 102.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18162, wmdcmp 0.16885, ema 0.70098, oracc 0.98704, qlmicf1 0.37806, qlmacf1 0.22165, chxlmicf1 0.52730, chxlmacf1 0.46674, chxlacc 0.70222, chxlrocaucmic 0.79451, chxlrocaucmac 0.76210, 31.66 secs\n",
      "Adjusting learning rate of group 0 to 8.7138e-06.\n",
      "\u001b[1m---- Epoch 63/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.28590, a_loss 1.26197, cD 0.98636, wmdcmp 0.13562, ema 0.62923, oracc 0.98536, orien_loss 0.02558, qlmicf1 0.37109, qlmacf1 0.22457, ql_loss 0.77361, chxlmicf1 0.52717, chxlmacf1 0.48220, chx_loss 0.84234, chxlacc 0.72060, chxlrocaucmic 0.80810, chxlrocaucmac 0.79428, gacc 0.97957, gloss 0.06249, cxr14micf1 0.35302, cxr14macf1 0.34115, cxr14_loss 0.94592, vnbgmicf1 0.59655, vnbgmacf1 0.45509, vnbg_loss 0.66673, b1 0.47166, b2 0.35157, b3 0.25678, b4 0.18739, padchxlmacf1 0.08066, padchxlmicf1 0.17753, padchxlzmacf1 0.09055, padchxlzmicf1 0.17871, padchxl_loss 0.34452, padchxlz_loss 0.49316, 108.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17603, wmdcmp 0.16940, ema 0.69024, oracc 0.98704, qlmicf1 0.36169, qlmacf1 0.21717, chxlmicf1 0.52302, chxlmacf1 0.46324, chxlacc 0.69659, chxlrocaucmic 0.79164, chxlrocaucmac 0.75788, 41.45 secs\n",
      "Adjusting learning rate of group 0 to 8.2312e-06.\n",
      "\u001b[1m---- Epoch 64/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.20085, a_loss 1.25070, cD 1.00975, wmdcmp 0.13859, ema 0.63889, oracc 0.98676, orien_loss 0.01807, qlmicf1 0.37743, qlmacf1 0.22322, ql_loss 0.77026, chxlmicf1 0.52662, chxlmacf1 0.48194, chx_loss 0.84030, chxlacc 0.72175, chxlrocaucmic 0.80873, chxlrocaucmac 0.79501, gacc 0.97541, gloss 0.06514, cxr14micf1 0.35661, cxr14macf1 0.34485, cxr14_loss 0.94536, vnbgmicf1 0.59574, vnbgmacf1 0.45537, vnbg_loss 0.66574, b1 0.47021, b2 0.34653, b3 0.25283, b4 0.18529, padchxlmacf1 0.07554, padchxlmicf1 0.17479, padchxlzmacf1 0.07527, padchxlzmicf1 0.15962, padchxl_loss 0.34742, padchxlz_loss 0.47854, 108.14 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.19875, wmdcmp 0.17078, ema 0.69382, oracc 0.98727, qlmicf1 0.38171, qlmacf1 0.22026, chxlmicf1 0.52837, chxlmacf1 0.46659, chxlacc 0.70160, chxlrocaucmic 0.79761, chxlrocaucmac 0.76097, 30.06 secs\n",
      "Adjusting learning rate of group 0 to 7.7754e-06.\n",
      "\u001b[1m---- Epoch 65/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.74497, a_loss 1.25686, cD 0.98413, wmdcmp 0.13578, ema 0.63462, oracc 0.98434, orien_loss 0.02478, qlmicf1 0.37156, qlmacf1 0.22220, ql_loss 0.76991, chxlmicf1 0.52269, chxlmacf1 0.47890, chx_loss 0.84546, chxlacc 0.71867, chxlrocaucmic 0.80706, chxlrocaucmac 0.79375, gacc 0.97430, gloss 0.06871, cxr14micf1 0.37072, cxr14macf1 0.35127, cxr14_loss 0.91693, vnbgmicf1 0.58649, vnbgmacf1 0.44675, vnbg_loss 0.66838, b1 0.45997, b2 0.33795, b3 0.24520, b4 0.17704, padchxlmacf1 0.07782, padchxlmicf1 0.18047, padchxlzmacf1 0.08292, padchxlzmicf1 0.17374, padchxl_loss 0.34324, padchxlz_loss 0.49381, 107.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20482, wmdcmp 0.17202, ema 0.70457, oracc 0.98657, qlmicf1 0.37301, qlmacf1 0.22135, chxlmicf1 0.52988, chxlmacf1 0.46669, chxlacc 0.70366, chxlrocaucmic 0.79724, chxlrocaucmac 0.75968, 44.29 secs\n",
      "Adjusting learning rate of group 0 to 7.3448e-06.\n",
      "\u001b[1m---- Epoch 66/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.83934, a_loss 1.25328, cD 1.00404, wmdcmp 0.13847, ema 0.63767, oracc 0.98252, orien_loss 0.02487, qlmicf1 0.37345, qlmacf1 0.22353, ql_loss 0.76914, chxlmicf1 0.52756, chxlmacf1 0.48241, chx_loss 0.83947, chxlacc 0.72348, chxlrocaucmic 0.80948, chxlrocaucmac 0.79661, gacc 0.97413, gloss 0.06717, cxr14micf1 0.34670, cxr14macf1 0.33791, cxr14_loss 0.91518, vnbgmicf1 0.59736, vnbgmacf1 0.46403, vnbg_loss 0.65170, b1 0.48348, b2 0.35950, b3 0.26489, b4 0.19513, padchxlmacf1 0.07555, padchxlmicf1 0.18370, padchxlzmacf1 0.08144, padchxlzmicf1 0.17503, padchxl_loss 0.33668, padchxlz_loss 0.47011, 106.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17677, wmdcmp 0.16828, ema 0.69919, oracc 0.98751, qlmicf1 0.37684, qlmacf1 0.22184, chxlmicf1 0.52769, chxlmacf1 0.46504, chxlacc 0.70467, chxlrocaucmic 0.79531, chxlrocaucmac 0.76074, 35.29 secs\n",
      "Adjusting learning rate of group 0 to 6.9380e-06.\n",
      "\u001b[1m---- Epoch 67/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.43366, a_loss 1.24961, cD 0.98719, wmdcmp 0.13573, ema 0.63175, oracc 0.98468, orien_loss 0.02430, qlmicf1 0.37502, qlmacf1 0.22378, ql_loss 0.77104, chxlmicf1 0.52158, chxlmacf1 0.47840, chx_loss 0.83806, chxlacc 0.71721, chxlrocaucmic 0.80704, chxlrocaucmac 0.79540, gacc 0.96952, gloss 0.08178, cxr14micf1 0.36166, cxr14macf1 0.34562, cxr14_loss 0.93060, vnbgmicf1 0.60768, vnbgmacf1 0.47516, vnbg_loss 0.63191, b1 0.48354, b2 0.35780, b3 0.26447, b4 0.19608, padchxlmacf1 0.07584, padchxlmicf1 0.18047, padchxlzmacf1 0.08505, padchxlzmicf1 0.17352, padchxl_loss 0.34401, padchxlz_loss 0.47944, 108.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17531, wmdcmp 0.16901, ema 0.69830, oracc 0.98704, qlmicf1 0.37206, qlmacf1 0.21892, chxlmicf1 0.52850, chxlmacf1 0.46663, chxlacc 0.70047, chxlrocaucmic 0.79691, chxlrocaucmac 0.76205, 45.10 secs\n",
      "Adjusting learning rate of group 0 to 6.5538e-06.\n",
      "\u001b[1m---- Epoch 68/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.60975, a_loss 1.25152, cD 0.99426, wmdcmp 0.13757, ema 0.63375, oracc 0.98319, orien_loss 0.02629, qlmicf1 0.37711, qlmacf1 0.22443, ql_loss 0.76924, chxlmicf1 0.52967, chxlmacf1 0.48293, chx_loss 0.83819, chxlacc 0.72371, chxlrocaucmic 0.80973, chxlrocaucmac 0.79486, gacc 0.97640, gloss 0.06653, cxr14micf1 0.35511, cxr14macf1 0.34134, cxr14_loss 0.92869, vnbgmicf1 0.59859, vnbgmacf1 0.46537, vnbg_loss 0.65776, b1 0.46743, b2 0.34454, b3 0.24999, b4 0.17926, padchxlmacf1 0.08047, padchxlmicf1 0.18261, padchxlzmacf1 0.08952, padchxlzmicf1 0.17825, padchxl_loss 0.34098, padchxlz_loss 0.48326, 104.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19657, wmdcmp 0.17050, ema 0.70725, oracc 0.98704, qlmicf1 0.37785, qlmacf1 0.22154, chxlmicf1 0.53168, chxlmacf1 0.46732, chxlacc 0.71215, chxlrocaucmic 0.79649, chxlrocaucmac 0.76332, 64.59 secs\n",
      "Adjusting learning rate of group 0 to 6.1909e-06.\n",
      "\u001b[1m---- Epoch 69/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.40826, a_loss 1.24983, cD 0.97883, wmdcmp 0.13647, ema 0.63471, oracc 0.98461, orien_loss 0.02288, qlmicf1 0.37348, qlmacf1 0.22369, ql_loss 0.76886, chxlmicf1 0.52673, chxlmacf1 0.48241, chx_loss 0.83590, chxlacc 0.72326, chxlrocaucmic 0.80943, chxlrocaucmac 0.79666, gacc 0.97535, gloss 0.06598, cxr14micf1 0.36092, cxr14macf1 0.34881, cxr14_loss 0.90924, vnbgmicf1 0.59996, vnbgmacf1 0.46792, vnbg_loss 0.64147, b1 0.49199, b2 0.36909, b3 0.27248, b4 0.19931, padchxlmacf1 0.07969, padchxlmicf1 0.17557, padchxlzmacf1 0.08942, padchxlzmicf1 0.18495, padchxl_loss 0.36697, padchxlz_loss 0.49473, 101.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18296, wmdcmp 0.16943, ema 0.70725, oracc 0.98704, qlmicf1 0.37460, qlmacf1 0.22101, chxlmicf1 0.52871, chxlmacf1 0.46490, chxlacc 0.70934, chxlrocaucmic 0.79512, chxlrocaucmac 0.76301, 67.05 secs\n",
      "Adjusting learning rate of group 0 to 5.8480e-06.\n",
      "\u001b[1m---- Epoch 70/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.91080, a_loss 1.25605, cD 0.99671, wmdcmp 0.13686, ema 0.63584, oracc 0.98634, orien_loss 0.02435, qlmicf1 0.37585, qlmacf1 0.22257, ql_loss 0.76954, chxlmicf1 0.52372, chxlmacf1 0.47870, chx_loss 0.83812, chxlacc 0.72118, chxlrocaucmic 0.80916, chxlrocaucmac 0.79734, gacc 0.97465, gloss 0.07121, cxr14micf1 0.33255, cxr14macf1 0.33113, cxr14_loss 0.93651, vnbgmicf1 0.59372, vnbgmacf1 0.46412, vnbg_loss 0.64852, b1 0.47433, b2 0.34907, b3 0.25474, b4 0.18541, padchxlmacf1 0.07160, padchxlmicf1 0.18432, padchxlzmacf1 0.09155, padchxlzmicf1 0.17517, padchxl_loss 0.32996, padchxlz_loss 0.47745, 100.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18719, wmdcmp 0.16946, ema 0.69830, oracc 0.98704, qlmicf1 0.37434, qlmacf1 0.22176, chxlmicf1 0.52817, chxlmacf1 0.46676, chxlacc 0.70291, chxlrocaucmic 0.79461, chxlrocaucmac 0.76243, 66.12 secs\n",
      "Adjusting learning rate of group 0 to 5.5242e-06.\n",
      "\u001b[1m---- Epoch 71/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.72547, a_loss 1.24539, cD 0.99898, wmdcmp 0.13743, ema 0.64150, oracc 0.98398, orien_loss 0.02229, qlmicf1 0.37971, qlmacf1 0.22486, ql_loss 0.76794, chxlmicf1 0.52901, chxlmacf1 0.48418, chx_loss 0.83174, chxlacc 0.72398, chxlrocaucmic 0.81030, chxlrocaucmac 0.79850, gacc 0.97850, gloss 0.06123, cxr14micf1 0.37131, cxr14macf1 0.35511, cxr14_loss 0.90730, vnbgmicf1 0.60282, vnbgmacf1 0.45520, vnbg_loss 0.65644, b1 0.47409, b2 0.35295, b3 0.25883, b4 0.18989, padchxlmacf1 0.07972, padchxlmicf1 0.17634, padchxlzmacf1 0.08650, padchxlzmicf1 0.17317, padchxl_loss 0.34764, padchxlz_loss 0.49307, 99.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21580, wmdcmp 0.17251, ema 0.69561, oracc 0.98727, qlmicf1 0.37861, qlmacf1 0.22323, chxlmicf1 0.53016, chxlmacf1 0.46656, chxlacc 0.70411, chxlrocaucmic 0.79763, chxlrocaucmac 0.76362, 65.72 secs\n",
      "Adjusting learning rate of group 0 to 5.2183e-06.\n",
      "\u001b[1m---- Epoch 72/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.03238, a_loss 1.23631, cD 1.00465, wmdcmp 0.13874, ema 0.63227, oracc 0.98506, orien_loss 0.02515, qlmicf1 0.37790, qlmacf1 0.22652, ql_loss 0.76923, chxlmicf1 0.53134, chxlmacf1 0.48695, chx_loss 0.83124, chxlacc 0.72232, chxlrocaucmic 0.81187, chxlrocaucmac 0.80029, gacc 0.97714, gloss 0.06488, cxr14micf1 0.34189, cxr14macf1 0.33422, cxr14_loss 0.94837, vnbgmicf1 0.59268, vnbgmacf1 0.44775, vnbg_loss 0.66472, b1 0.48402, b2 0.36349, b3 0.27060, b4 0.20092, padchxlmacf1 0.07263, padchxlmicf1 0.18126, padchxlzmacf1 0.09115, padchxlzmicf1 0.18448, padchxl_loss 0.34314, padchxlz_loss 0.48904, 102.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17451, wmdcmp 0.16848, ema 0.69382, oracc 0.98751, qlmicf1 0.37649, qlmacf1 0.22092, chxlmicf1 0.53193, chxlmacf1 0.46839, chxlacc 0.70828, chxlrocaucmic 0.79717, chxlrocaucmac 0.76408, 58.26 secs\n",
      "Adjusting learning rate of group 0 to 4.9293e-06.\n",
      "\u001b[1m---- Epoch 73/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 5.00778, a_loss 1.26288, cD 1.00305, wmdcmp 0.13782, ema 0.63094, oracc 0.98390, orien_loss 0.02388, qlmicf1 0.37747, qlmacf1 0.22362, ql_loss 0.77123, chxlmicf1 0.52702, chxlmacf1 0.48150, chx_loss 0.83912, chxlacc 0.72336, chxlrocaucmic 0.80936, chxlrocaucmac 0.79650, gacc 0.97203, gloss 0.06887, cxr14micf1 0.34686, cxr14macf1 0.33910, cxr14_loss 0.93684, vnbgmicf1 0.60614, vnbgmacf1 0.47066, vnbg_loss 0.63846, b1 0.47448, b2 0.34920, b3 0.25424, b4 0.18540, padchxlmacf1 0.07941, padchxlmicf1 0.18522, padchxlzmacf1 0.08269, padchxlzmicf1 0.17634, padchxl_loss 0.34786, padchxlz_loss 0.48968, 107.84 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.17767, wmdcmp 0.16840, ema 0.70636, oracc 0.98751, qlmicf1 0.37571, qlmacf1 0.22358, chxlmicf1 0.52463, chxlmacf1 0.46669, chxlacc 0.70202, chxlrocaucmic 0.79139, chxlrocaucmac 0.76346, 24.73 secs\n",
      "Adjusting learning rate of group 0 to 4.6563e-06.\n",
      "\u001b[1m---- Epoch 74/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.47660, a_loss 1.24274, cD 0.99514, wmdcmp 0.13680, ema 0.63680, oracc 0.98494, orien_loss 0.02463, qlmicf1 0.37929, qlmacf1 0.22600, ql_loss 0.76682, chxlmicf1 0.52739, chxlmacf1 0.48211, chx_loss 0.83276, chxlacc 0.72237, chxlrocaucmic 0.81019, chxlrocaucmac 0.79738, gacc 0.97229, gloss 0.07181, cxr14micf1 0.33918, cxr14macf1 0.33625, cxr14_loss 0.95196, vnbgmicf1 0.60104, vnbgmacf1 0.46261, vnbg_loss 0.66240, b1 0.49422, b2 0.36911, b3 0.27638, b4 0.20772, padchxlmacf1 0.07669, padchxlmicf1 0.17858, padchxlzmacf1 0.08514, padchxlzmicf1 0.17204, padchxl_loss 0.33672, padchxlz_loss 0.47407, 115.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19688, wmdcmp 0.17026, ema 0.70367, oracc 0.98822, qlmicf1 0.37565, qlmacf1 0.22324, chxlmicf1 0.52879, chxlmacf1 0.46621, chxlacc 0.70315, chxlrocaucmic 0.79572, chxlrocaucmac 0.76139, 40.87 secs\n",
      "Adjusting learning rate of group 0 to 4.3984e-06.\n",
      "\u001b[1m---- Epoch 75/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.73122, a_loss 1.24933, cD 0.98422, wmdcmp 0.13532, ema 0.64054, oracc 0.98627, orien_loss 0.02130, qlmicf1 0.37839, qlmacf1 0.22917, ql_loss 0.76753, chxlmicf1 0.52691, chxlmacf1 0.48228, chx_loss 0.83625, chxlacc 0.72313, chxlrocaucmic 0.80914, chxlrocaucmac 0.79798, gacc 0.97920, gloss 0.06000, cxr14micf1 0.35481, cxr14macf1 0.34406, cxr14_loss 0.92807, vnbgmicf1 0.59678, vnbgmacf1 0.46472, vnbg_loss 0.62857, b1 0.47263, b2 0.34963, b3 0.25401, b4 0.18289, padchxlmacf1 0.07981, padchxlmicf1 0.18091, padchxlzmacf1 0.08579, padchxlzmicf1 0.18050, padchxl_loss 0.36103, padchxlz_loss 0.50568, 107.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18891, wmdcmp 0.16942, ema 0.70098, oracc 0.98751, qlmicf1 0.37374, qlmacf1 0.22165, chxlmicf1 0.52857, chxlmacf1 0.46627, chxlacc 0.70163, chxlrocaucmic 0.79733, chxlrocaucmac 0.76158, 56.25 secs\n",
      "Adjusting learning rate of group 0 to 4.1549e-06.\n",
      "\u001b[1m---- Epoch 76/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.21675, a_loss 1.23655, cD 1.00768, wmdcmp 0.13973, ema 0.64158, oracc 0.98433, orien_loss 0.02546, qlmicf1 0.37930, qlmacf1 0.22561, ql_loss 0.76890, chxlmicf1 0.52968, chxlmacf1 0.48583, chx_loss 0.83070, chxlacc 0.72647, chxlrocaucmic 0.81404, chxlrocaucmac 0.80258, gacc 0.97541, gloss 0.06839, cxr14micf1 0.32956, cxr14macf1 0.33074, cxr14_loss 0.93462, vnbgmicf1 0.60257, vnbgmacf1 0.46234, vnbg_loss 0.64856, b1 0.49014, b2 0.36536, b3 0.26857, b4 0.19818, padchxlmacf1 0.07245, padchxlmicf1 0.17147, padchxlzmacf1 0.08498, padchxlzmicf1 0.18075, padchxl_loss 0.34870, padchxlz_loss 0.47990, 103.60 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20880, wmdcmp 0.17238, ema 0.69561, oracc 0.98751, qlmicf1 0.37897, qlmacf1 0.22168, chxlmicf1 0.52840, chxlmacf1 0.46724, chxlacc 0.70416, chxlrocaucmic 0.79568, chxlrocaucmac 0.76369, 62.43 secs\n",
      "Adjusting learning rate of group 0 to 3.9248e-06.\n",
      "\u001b[1m---- Epoch 77/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.00117, a_loss 1.25891, cD 0.97682, wmdcmp 0.13550, ema 0.63619, oracc 0.98411, orien_loss 0.02572, qlmicf1 0.37853, qlmacf1 0.22715, ql_loss 0.76499, chxlmicf1 0.53172, chxlmacf1 0.48725, chx_loss 0.82701, chxlacc 0.72596, chxlrocaucmic 0.81401, chxlrocaucmac 0.80245, gacc 0.97780, gloss 0.06275, cxr14micf1 0.35631, cxr14macf1 0.34314, cxr14_loss 0.92762, vnbgmicf1 0.59590, vnbgmacf1 0.45697, vnbg_loss 0.65537, b1 0.49239, b2 0.36954, b3 0.27409, b4 0.20110, padchxlmacf1 0.07056, padchxlmicf1 0.17610, padchxlzmacf1 0.08918, padchxlzmicf1 0.17726, padchxl_loss 0.34271, padchxlz_loss 0.47977, 100.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19271, wmdcmp 0.17160, ema 0.71083, oracc 0.98704, qlmicf1 0.37773, qlmacf1 0.22303, chxlmicf1 0.53022, chxlmacf1 0.46808, chxlacc 0.70754, chxlrocaucmic 0.79639, chxlrocaucmac 0.76294, 66.69 secs\n",
      "Adjusting learning rate of group 0 to 3.7074e-06.\n",
      "\u001b[1m---- Epoch 78/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.83932, a_loss 1.23641, cD 0.99575, wmdcmp 0.13712, ema 0.63062, oracc 0.98490, orien_loss 0.02632, qlmicf1 0.37757, qlmacf1 0.22281, ql_loss 0.76906, chxlmicf1 0.53137, chxlmacf1 0.48711, chx_loss 0.82531, chxlacc 0.72529, chxlrocaucmic 0.81320, chxlrocaucmac 0.80127, gacc 0.97570, gloss 0.06300, cxr14micf1 0.34459, cxr14macf1 0.33839, cxr14_loss 0.92256, vnbgmicf1 0.59385, vnbgmacf1 0.45741, vnbg_loss 0.65036, b1 0.50307, b2 0.37640, b3 0.27782, b4 0.20352, padchxlmacf1 0.07629, padchxlmicf1 0.17527, padchxlzmacf1 0.08549, padchxlzmicf1 0.17844, padchxl_loss 0.33249, padchxlz_loss 0.48286, 102.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20133, wmdcmp 0.17189, ema 0.70367, oracc 0.98751, qlmicf1 0.37769, qlmacf1 0.22268, chxlmicf1 0.52935, chxlmacf1 0.46609, chxlacc 0.70524, chxlrocaucmic 0.79689, chxlrocaucmac 0.76129, 66.26 secs\n",
      "Adjusting learning rate of group 0 to 3.5021e-06.\n",
      "\u001b[1m---- Epoch 79/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.68564, a_loss 1.23875, cD 1.01009, wmdcmp 0.13863, ema 0.63863, oracc 0.98494, orien_loss 0.02133, qlmicf1 0.37386, qlmacf1 0.22838, ql_loss 0.77092, chxlmicf1 0.53051, chxlmacf1 0.48754, chx_loss 0.82620, chxlacc 0.72638, chxlrocaucmic 0.81397, chxlrocaucmac 0.80250, gacc 0.97570, gloss 0.06718, cxr14micf1 0.36022, cxr14macf1 0.34446, cxr14_loss 0.91225, vnbgmicf1 0.60427, vnbgmacf1 0.47563, vnbg_loss 0.63860, b1 0.48987, b2 0.37053, b3 0.27863, b4 0.20603, padchxlmacf1 0.07669, padchxlmicf1 0.17857, padchxlzmacf1 0.08729, padchxlzmicf1 0.18164, padchxl_loss 0.34124, padchxlz_loss 0.47438, 104.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19417, wmdcmp 0.17104, ema 0.69561, oracc 0.98774, qlmicf1 0.37628, qlmacf1 0.22201, chxlmicf1 0.53190, chxlmacf1 0.46650, chxlacc 0.70904, chxlrocaucmic 0.79923, chxlrocaucmac 0.76214, 31.87 secs\n",
      "Adjusting learning rate of group 0 to 3.3082e-06.\n",
      "\u001b[1m---- Epoch 80/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.20695, a_loss 1.23323, cD 1.01500, wmdcmp 0.14003, ema 0.64237, oracc 0.98468, orien_loss 0.02101, qlmicf1 0.37654, qlmacf1 0.22404, ql_loss 0.76809, chxlmicf1 0.53515, chxlmacf1 0.48907, chx_loss 0.82313, chxlacc 0.72768, chxlrocaucmic 0.81599, chxlrocaucmac 0.80388, gacc 0.97714, gloss 0.06519, cxr14micf1 0.34693, cxr14macf1 0.34134, cxr14_loss 0.93675, vnbgmicf1 0.59735, vnbgmacf1 0.46706, vnbg_loss 0.65083, b1 0.49679, b2 0.37130, b3 0.27586, b4 0.20523, padchxlmacf1 0.07666, padchxlmicf1 0.18864, padchxlzmacf1 0.08827, padchxlzmicf1 0.18836, padchxl_loss 0.33486, padchxlz_loss 0.47910, 107.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19316, wmdcmp 0.17002, ema 0.69919, oracc 0.98704, qlmicf1 0.37352, qlmacf1 0.22289, chxlmicf1 0.53235, chxlmacf1 0.46848, chxlacc 0.70762, chxlrocaucmic 0.79913, chxlrocaucmac 0.76262, 46.83 secs\n",
      "Adjusting learning rate of group 0 to 3.1250e-06.\n",
      "\u001b[1m---- Epoch 81/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.90288, a_loss 1.24719, cD 1.00076, wmdcmp 0.13812, ema 0.64248, oracc 0.98380, orien_loss 0.02289, qlmicf1 0.38072, qlmacf1 0.22648, ql_loss 0.76579, chxlmicf1 0.53337, chxlmacf1 0.48721, chx_loss 0.82457, chxlacc 0.72695, chxlrocaucmic 0.81514, chxlrocaucmac 0.80245, gacc 0.98182, gloss 0.05386, cxr14micf1 0.36468, cxr14macf1 0.35015, cxr14_loss 0.91693, vnbgmicf1 0.60716, vnbgmacf1 0.46434, vnbg_loss 0.63079, b1 0.48977, b2 0.36439, b3 0.26726, b4 0.19639, padchxlmacf1 0.07461, padchxlmicf1 0.18072, padchxlzmacf1 0.08823, padchxlzmicf1 0.18861, padchxl_loss 0.33697, padchxlz_loss 0.47866, 106.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19290, wmdcmp 0.17096, ema 0.70278, oracc 0.98704, qlmicf1 0.37147, qlmacf1 0.22201, chxlmicf1 0.52488, chxlmacf1 0.46472, chxlacc 0.70088, chxlrocaucmic 0.79500, chxlrocaucmac 0.76211, 50.93 secs\n",
      "Adjusting learning rate of group 0 to 2.9519e-06.\n",
      "\u001b[1m---- Epoch 82/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.21196, a_loss 1.25449, cD 0.98954, wmdcmp 0.13611, ema 0.63071, oracc 0.98568, orien_loss 0.02381, qlmicf1 0.38184, qlmacf1 0.22700, ql_loss 0.76172, chxlmicf1 0.53308, chxlmacf1 0.48879, chx_loss 0.82553, chxlacc 0.72668, chxlrocaucmic 0.81423, chxlrocaucmac 0.80224, gacc 0.97749, gloss 0.06526, cxr14micf1 0.33552, cxr14macf1 0.33164, cxr14_loss 0.95283, vnbgmicf1 0.58792, vnbgmacf1 0.45492, vnbg_loss 0.65294, b1 0.48934, b2 0.36647, b3 0.27396, b4 0.20770, padchxlmacf1 0.08103, padchxlmicf1 0.18093, padchxlzmacf1 0.08890, padchxlzmicf1 0.16547, padchxl_loss 0.34866, padchxlz_loss 0.49230, 105.75 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.19935, wmdcmp 0.17119, ema 0.70188, oracc 0.98751, qlmicf1 0.37834, qlmacf1 0.22291, chxlmicf1 0.53056, chxlmacf1 0.46785, chxlacc 0.70872, chxlrocaucmic 0.79571, chxlrocaucmac 0.76130, 29.05 secs\n",
      "Adjusting learning rate of group 0 to 2.7884e-06.\n",
      "\u001b[1m---- Epoch 83/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.25581, a_loss 1.25002, cD 1.00497, wmdcmp 0.13925, ema 0.63837, oracc 0.98595, orien_loss 0.01871, qlmicf1 0.38104, qlmacf1 0.22961, ql_loss 0.76330, chxlmicf1 0.53081, chxlmacf1 0.48598, chx_loss 0.82852, chxlacc 0.72541, chxlrocaucmic 0.81116, chxlrocaucmac 0.79919, gacc 0.97815, gloss 0.06194, cxr14micf1 0.35958, cxr14macf1 0.34306, cxr14_loss 0.93097, vnbgmicf1 0.59980, vnbgmacf1 0.47213, vnbg_loss 0.64772, b1 0.48295, b2 0.35784, b3 0.26359, b4 0.19271, padchxlmacf1 0.06898, padchxlmicf1 0.17291, padchxlzmacf1 0.09160, padchxlzmicf1 0.16802, padchxl_loss 0.33202, padchxlz_loss 0.47586, 109.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21154, wmdcmp 0.17194, ema 0.69651, oracc 0.98751, qlmicf1 0.37502, qlmacf1 0.22230, chxlmicf1 0.53188, chxlmacf1 0.46782, chxlacc 0.71066, chxlrocaucmic 0.79791, chxlrocaucmac 0.76340, 36.54 secs\n",
      "Adjusting learning rate of group 0 to 2.6340e-06.\n",
      "\u001b[1m---- Epoch 84/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.75047, a_loss 1.23985, cD 1.01281, wmdcmp 0.14009, ema 0.63880, oracc 0.98333, orien_loss 0.02454, qlmicf1 0.36996, qlmacf1 0.22479, ql_loss 0.76891, chxlmicf1 0.52991, chxlmacf1 0.48338, chx_loss 0.82827, chxlacc 0.72541, chxlrocaucmic 0.81228, chxlrocaucmac 0.79982, gacc 0.97727, gloss 0.06701, cxr14micf1 0.36089, cxr14macf1 0.34628, cxr14_loss 0.91332, vnbgmicf1 0.59865, vnbgmacf1 0.45939, vnbg_loss 0.64414, b1 0.46564, b2 0.34622, b3 0.25492, b4 0.18717, padchxlmacf1 0.08055, padchxlmicf1 0.17769, padchxlzmacf1 0.09483, padchxlzmicf1 0.17799, padchxl_loss 0.35187, padchxlz_loss 0.49584, 109.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20827, wmdcmp 0.17233, ema 0.68845, oracc 0.98727, qlmicf1 0.37735, qlmacf1 0.22315, chxlmicf1 0.52903, chxlmacf1 0.46457, chxlacc 0.70965, chxlrocaucmic 0.79737, chxlrocaucmac 0.76273, 39.04 secs\n",
      "Adjusting learning rate of group 0 to 2.4881e-06.\n",
      "\u001b[1m---- Epoch 85/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.17002, a_loss 1.24914, cD 1.00461, wmdcmp 0.13878, ema 0.63322, oracc 0.98347, orien_loss 0.02411, qlmicf1 0.37721, qlmacf1 0.22621, ql_loss 0.76442, chxlmicf1 0.52964, chxlmacf1 0.48486, chx_loss 0.82882, chxlacc 0.72553, chxlrocaucmic 0.81298, chxlrocaucmac 0.80105, gacc 0.97500, gloss 0.06544, cxr14micf1 0.34897, cxr14macf1 0.34259, cxr14_loss 0.92039, vnbgmicf1 0.59610, vnbgmacf1 0.47200, vnbg_loss 0.64470, b1 0.47810, b2 0.35363, b3 0.25982, b4 0.19250, padchxlmacf1 0.08582, padchxlmicf1 0.18012, padchxlzmacf1 0.09080, padchxlzmicf1 0.19156, padchxl_loss 0.33965, padchxlz_loss 0.48694, 105.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19971, wmdcmp 0.17058, ema 0.70636, oracc 0.98751, qlmicf1 0.37619, qlmacf1 0.22255, chxlmicf1 0.52849, chxlmacf1 0.46649, chxlacc 0.70565, chxlrocaucmic 0.79597, chxlrocaucmac 0.76344, 62.87 secs\n",
      "Adjusting learning rate of group 0 to 2.3504e-06.\n",
      "\u001b[1m---- Epoch 86/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.00443, a_loss 1.24617, cD 1.00870, wmdcmp 0.13899, ema 0.63880, oracc 0.98352, orien_loss 0.02745, qlmicf1 0.37765, qlmacf1 0.22822, ql_loss 0.76642, chxlmicf1 0.53490, chxlmacf1 0.48976, chx_loss 0.82532, chxlacc 0.72797, chxlrocaucmic 0.81477, chxlrocaucmac 0.80371, gacc 0.97905, gloss 0.05756, cxr14micf1 0.36255, cxr14macf1 0.34631, cxr14_loss 0.90936, vnbgmicf1 0.59733, vnbgmacf1 0.46294, vnbg_loss 0.65109, b1 0.48631, b2 0.36351, b3 0.27147, b4 0.20277, padchxlmacf1 0.07639, padchxlmicf1 0.17542, padchxlzmacf1 0.08594, padchxlzmicf1 0.17624, padchxl_loss 0.34949, padchxlz_loss 0.47622, 102.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19882, wmdcmp 0.17141, ema 0.70815, oracc 0.98727, qlmicf1 0.37775, qlmacf1 0.22283, chxlmicf1 0.53074, chxlmacf1 0.46698, chxlacc 0.70950, chxlrocaucmic 0.79756, chxlrocaucmac 0.76463, 67.79 secs\n",
      "Adjusting learning rate of group 0 to 2.2202e-06.\n",
      "\u001b[1m---- Epoch 87/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.06845, a_loss 1.22803, cD 1.02838, wmdcmp 0.14050, ema 0.63175, oracc 0.98596, orien_loss 0.02343, qlmicf1 0.38069, qlmacf1 0.22707, ql_loss 0.76301, chxlmicf1 0.53231, chxlmacf1 0.48638, chx_loss 0.82688, chxlacc 0.72742, chxlrocaucmic 0.81456, chxlrocaucmac 0.80255, gacc 0.97766, gloss 0.06033, cxr14micf1 0.35186, cxr14macf1 0.34478, cxr14_loss 0.93134, vnbgmicf1 0.59015, vnbgmacf1 0.45492, vnbg_loss 0.66226, b1 0.46760, b2 0.34173, b3 0.24840, b4 0.18125, padchxlmacf1 0.07650, padchxlmicf1 0.17412, padchxlzmacf1 0.08703, padchxlzmicf1 0.16604, padchxl_loss 0.33852, padchxlz_loss 0.49590, 103.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21294, wmdcmp 0.17193, ema 0.70278, oracc 0.98727, qlmicf1 0.37631, qlmacf1 0.22339, chxlmicf1 0.52925, chxlmacf1 0.46810, chxlacc 0.70614, chxlrocaucmic 0.79656, chxlrocaucmac 0.76475, 67.85 secs\n",
      "Adjusting learning rate of group 0 to 2.0972e-06.\n",
      "\u001b[1m---- Epoch 88/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.71903, a_loss 1.23949, cD 0.99429, wmdcmp 0.13732, ema 0.63923, oracc 0.98481, orien_loss 0.02165, qlmicf1 0.37494, qlmacf1 0.22570, ql_loss 0.76857, chxlmicf1 0.53121, chxlmacf1 0.48587, chx_loss 0.82310, chxlacc 0.72520, chxlrocaucmic 0.81310, chxlrocaucmac 0.80137, gacc 0.97587, gloss 0.06439, cxr14micf1 0.36568, cxr14macf1 0.35208, cxr14_loss 0.91311, vnbgmicf1 0.59885, vnbgmacf1 0.46449, vnbg_loss 0.63393, b1 0.47889, b2 0.35634, b3 0.26029, b4 0.18927, padchxlmacf1 0.07998, padchxlmicf1 0.17662, padchxlzmacf1 0.09319, padchxlzmicf1 0.18331, padchxl_loss 0.35251, padchxlz_loss 0.49069, 101.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21061, wmdcmp 0.17238, ema 0.70098, oracc 0.98751, qlmicf1 0.37674, qlmacf1 0.22217, chxlmicf1 0.53245, chxlmacf1 0.46800, chxlacc 0.70914, chxlrocaucmic 0.79894, chxlrocaucmac 0.76462, 68.18 secs\n",
      "Adjusting learning rate of group 0 to 1.9811e-06.\n",
      "\u001b[1m---- Epoch 89/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.85151, a_loss 1.25267, cD 1.00360, wmdcmp 0.13958, ema 0.63462, oracc 0.98485, orien_loss 0.01961, qlmicf1 0.38290, qlmacf1 0.22998, ql_loss 0.76158, chxlmicf1 0.53509, chxlmacf1 0.48770, chx_loss 0.82491, chxlacc 0.72827, chxlrocaucmic 0.81567, chxlrocaucmac 0.80256, gacc 0.97675, gloss 0.06617, cxr14micf1 0.35634, cxr14macf1 0.34879, cxr14_loss 0.91758, vnbgmicf1 0.60429, vnbgmacf1 0.47774, vnbg_loss 0.65472, b1 0.46754, b2 0.34192, b3 0.24412, b4 0.17713, padchxlmacf1 0.07531, padchxlmicf1 0.17190, padchxlzmacf1 0.08356, padchxlzmicf1 0.16733, padchxl_loss 0.33743, padchxlz_loss 0.47082, 100.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19792, wmdcmp 0.17201, ema 0.70457, oracc 0.98727, qlmicf1 0.37933, qlmacf1 0.22151, chxlmicf1 0.53580, chxlmacf1 0.47030, chxlacc 0.70890, chxlrocaucmic 0.80320, chxlrocaucmac 0.76577, 63.62 secs\n",
      "Adjusting learning rate of group 0 to 1.8714e-06.\n",
      "\u001b[1m---- Epoch 90/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.08176, a_loss 1.24682, cD 0.99534, wmdcmp 0.13766, ema 0.63802, oracc 0.98394, orien_loss 0.02488, qlmicf1 0.38223, qlmacf1 0.22709, ql_loss 0.76726, chxlmicf1 0.53560, chxlmacf1 0.49051, chx_loss 0.82245, chxlacc 0.72880, chxlrocaucmic 0.81658, chxlrocaucmac 0.80410, gacc 0.97351, gloss 0.07057, cxr14micf1 0.37054, cxr14macf1 0.35046, cxr14_loss 0.90815, vnbgmicf1 0.60645, vnbgmacf1 0.46489, vnbg_loss 0.62393, b1 0.48889, b2 0.36613, b3 0.27060, b4 0.19871, padchxlmacf1 0.07968, padchxlmicf1 0.18556, padchxlzmacf1 0.08476, padchxlzmicf1 0.18516, padchxl_loss 0.34089, padchxlz_loss 0.48241, 101.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20213, wmdcmp 0.17142, ema 0.69830, oracc 0.98704, qlmicf1 0.37812, qlmacf1 0.22240, chxlmicf1 0.52897, chxlmacf1 0.46550, chxlacc 0.70627, chxlrocaucmic 0.79616, chxlrocaucmac 0.76175, 20.45 secs\n",
      "Adjusting learning rate of group 0 to 1.7678e-06.\n",
      "\u001b[1m---- Epoch 91/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.60540, a_loss 1.21931, cD 1.02021, wmdcmp 0.14095, ema 0.64915, oracc 0.98274, orien_loss 0.02235, qlmicf1 0.37623, qlmacf1 0.22399, ql_loss 0.76104, chxlmicf1 0.53311, chxlmacf1 0.48650, chx_loss 0.82323, chxlacc 0.72890, chxlrocaucmic 0.81501, chxlrocaucmac 0.80296, gacc 0.97622, gloss 0.06161, cxr14micf1 0.34971, cxr14macf1 0.34267, cxr14_loss 0.92582, vnbgmicf1 0.59844, vnbgmacf1 0.46359, vnbg_loss 0.64435, b1 0.48842, b2 0.36558, b3 0.27060, b4 0.19694, padchxlmacf1 0.07342, padchxlmicf1 0.18745, padchxlzmacf1 0.08422, padchxlzmicf1 0.17865, padchxl_loss 0.33678, padchxlz_loss 0.46745, 89.77 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.20323, wmdcmp 0.17237, ema 0.70636, oracc 0.98727, qlmicf1 0.37531, qlmacf1 0.22081, chxlmicf1 0.53189, chxlmacf1 0.46614, chxlacc 0.70986, chxlrocaucmic 0.79869, chxlrocaucmac 0.76302, 21.88 secs\n",
      "Adjusting learning rate of group 0 to 1.6699e-06.\n",
      "\u001b[1m---- Epoch 92/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.32628, a_loss 1.24090, cD 0.99949, wmdcmp 0.13821, ema 0.63619, oracc 0.98540, orien_loss 0.02352, qlmicf1 0.38140, qlmacf1 0.23012, ql_loss 0.76116, chxlmicf1 0.53404, chxlmacf1 0.48665, chx_loss 0.82961, chxlacc 0.72781, chxlrocaucmic 0.81279, chxlrocaucmac 0.79997, gacc 0.97657, gloss 0.06632, cxr14micf1 0.34539, cxr14macf1 0.34115, cxr14_loss 0.92300, vnbgmicf1 0.60159, vnbgmacf1 0.46358, vnbg_loss 0.62314, b1 0.49261, b2 0.36838, b3 0.27108, b4 0.19981, padchxlmacf1 0.07883, padchxlmicf1 0.18947, padchxlzmacf1 0.09336, padchxlzmicf1 0.18453, padchxl_loss 0.33879, padchxlz_loss 0.49794, 88.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19383, wmdcmp 0.17145, ema 0.70278, oracc 0.98727, qlmicf1 0.37677, qlmacf1 0.22243, chxlmicf1 0.53344, chxlmacf1 0.46842, chxlacc 0.70944, chxlrocaucmic 0.79886, chxlrocaucmac 0.76261, 21.88 secs\n",
      "Adjusting learning rate of group 0 to 1.5774e-06.\n",
      "\u001b[1m---- Epoch 93/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.02019, a_loss 1.24881, cD 1.00193, wmdcmp 0.13657, ema 0.64187, oracc 0.98331, orien_loss 0.02522, qlmicf1 0.37744, qlmacf1 0.22379, ql_loss 0.76420, chxlmicf1 0.53274, chxlmacf1 0.48723, chx_loss 0.82390, chxlacc 0.72761, chxlrocaucmic 0.81596, chxlrocaucmac 0.80354, gacc 0.97937, gloss 0.05465, cxr14micf1 0.34977, cxr14macf1 0.34653, cxr14_loss 0.93089, vnbgmicf1 0.59399, vnbgmacf1 0.46273, vnbg_loss 0.65707, b1 0.48436, b2 0.35882, b3 0.26412, b4 0.19398, padchxlmacf1 0.07864, padchxlmicf1 0.18384, padchxlzmacf1 0.08890, padchxlzmicf1 0.18034, padchxl_loss 0.34130, padchxlz_loss 0.46253, 86.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20754, wmdcmp 0.17211, ema 0.69293, oracc 0.98774, qlmicf1 0.37785, qlmacf1 0.22193, chxlmicf1 0.53090, chxlmacf1 0.46872, chxlacc 0.70715, chxlrocaucmic 0.79755, chxlrocaucmac 0.76408, 22.21 secs\n",
      "Adjusting learning rate of group 0 to 1.4900e-06.\n",
      "\u001b[1m---- Epoch 94/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.79693, a_loss 1.22581, cD 1.01377, wmdcmp 0.13900, ema 0.64350, oracc 0.98413, orien_loss 0.02200, qlmicf1 0.38613, qlmacf1 0.22566, ql_loss 0.76319, chxlmicf1 0.53592, chxlmacf1 0.48955, chx_loss 0.82448, chxlacc 0.72976, chxlrocaucmic 0.81539, chxlrocaucmac 0.80324, gacc 0.97832, gloss 0.05495, cxr14micf1 0.35540, cxr14macf1 0.34404, cxr14_loss 0.91838, vnbgmicf1 0.60921, vnbgmacf1 0.47976, vnbg_loss 0.61559, b1 0.48694, b2 0.36523, b3 0.27159, b4 0.20263, padchxlmacf1 0.06933, padchxlmicf1 0.17645, padchxlzmacf1 0.08452, padchxlzmicf1 0.18013, padchxl_loss 0.33942, padchxlz_loss 0.47660, 89.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20367, wmdcmp 0.17227, ema 0.69919, oracc 0.98751, qlmicf1 0.37748, qlmacf1 0.22153, chxlmicf1 0.52959, chxlmacf1 0.46582, chxlacc 0.70705, chxlrocaucmic 0.79694, chxlrocaucmac 0.76282, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 1.4075e-06.\n",
      "\u001b[1m---- Epoch 95/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.07047, a_loss 1.24162, cD 1.02552, wmdcmp 0.14039, ema 0.63575, oracc 0.98473, orien_loss 0.02606, qlmicf1 0.38166, qlmacf1 0.22825, ql_loss 0.76053, chxlmicf1 0.53948, chxlmacf1 0.49319, chx_loss 0.82416, chxlacc 0.73046, chxlrocaucmic 0.81635, chxlrocaucmac 0.80498, gacc 0.97714, gloss 0.06706, cxr14micf1 0.35954, cxr14macf1 0.34811, cxr14_loss 0.90422, vnbgmicf1 0.60482, vnbgmacf1 0.46478, vnbg_loss 0.63499, b1 0.47836, b2 0.35458, b3 0.25874, b4 0.18741, padchxlmacf1 0.07910, padchxlmicf1 0.18481, padchxlzmacf1 0.08451, padchxlzmicf1 0.16884, padchxl_loss 0.34375, padchxlz_loss 0.49247, 92.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20132, wmdcmp 0.17145, ema 0.69024, oracc 0.98727, qlmicf1 0.37630, qlmacf1 0.22230, chxlmicf1 0.53106, chxlmacf1 0.46809, chxlacc 0.70815, chxlrocaucmic 0.79719, chxlrocaucmac 0.76564, 21.45 secs\n",
      "Adjusting learning rate of group 0 to 1.3296e-06.\n",
      "\u001b[1m---- Epoch 96/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.02324, a_loss 1.23800, cD 0.99894, wmdcmp 0.13710, ema 0.64056, oracc 0.98528, orien_loss 0.02328, qlmicf1 0.37878, qlmacf1 0.22953, ql_loss 0.76179, chxlmicf1 0.53329, chxlmacf1 0.48951, chx_loss 0.82239, chxlacc 0.72886, chxlrocaucmic 0.81414, chxlrocaucmac 0.80402, gacc 0.97290, gloss 0.06636, cxr14micf1 0.38293, cxr14macf1 0.35763, cxr14_loss 0.90321, vnbgmicf1 0.60604, vnbgmacf1 0.46499, vnbg_loss 0.62595, b1 0.50125, b2 0.37971, b3 0.28377, b4 0.21093, padchxlmacf1 0.07441, padchxlmicf1 0.17517, padchxlzmacf1 0.08970, padchxlzmicf1 0.18839, padchxl_loss 0.34043, padchxlz_loss 0.48524, 88.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19978, wmdcmp 0.17118, ema 0.70188, oracc 0.98774, qlmicf1 0.37782, qlmacf1 0.22195, chxlmicf1 0.53255, chxlmacf1 0.46771, chxlacc 0.70957, chxlrocaucmic 0.79933, chxlrocaucmac 0.76398, 22.54 secs\n",
      "Adjusting learning rate of group 0 to 1.2559e-06.\n",
      "\u001b[1m---- Epoch 97/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.41891, a_loss 1.24822, cD 0.99970, wmdcmp 0.13827, ema 0.63262, oracc 0.98244, orien_loss 0.02536, qlmicf1 0.37912, qlmacf1 0.22852, ql_loss 0.75800, chxlmicf1 0.52890, chxlmacf1 0.48491, chx_loss 0.82801, chxlacc 0.72597, chxlrocaucmic 0.81202, chxlrocaucmac 0.79998, gacc 0.97853, gloss 0.05466, cxr14micf1 0.35143, cxr14macf1 0.34016, cxr14_loss 0.93513, vnbgmicf1 0.59411, vnbgmacf1 0.46258, vnbg_loss 0.64762, b1 0.48957, b2 0.36388, b3 0.26577, b4 0.19602, padchxlmacf1 0.07527, padchxlmicf1 0.17932, padchxlzmacf1 0.08770, padchxlzmicf1 0.18306, padchxl_loss 0.33858, padchxlz_loss 0.48230, 87.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19594, wmdcmp 0.17046, ema 0.69919, oracc 0.98751, qlmicf1 0.37694, qlmacf1 0.22243, chxlmicf1 0.53369, chxlmacf1 0.46832, chxlacc 0.71045, chxlrocaucmic 0.80068, chxlrocaucmac 0.76422, 22.26 secs\n",
      "Adjusting learning rate of group 0 to 1.1864e-06.\n",
      "\u001b[1m---- Epoch 98/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.82931, a_loss 1.24237, cD 1.02405, wmdcmp 0.14113, ema 0.64237, oracc 0.98324, orien_loss 0.02445, qlmicf1 0.37786, qlmacf1 0.22751, ql_loss 0.76777, chxlmicf1 0.52986, chxlmacf1 0.48539, chx_loss 0.82861, chxlacc 0.72549, chxlrocaucmic 0.81290, chxlrocaucmac 0.80235, gacc 0.98024, gloss 0.05216, cxr14micf1 0.35046, cxr14macf1 0.34093, cxr14_loss 0.93426, vnbgmicf1 0.60837, vnbgmacf1 0.46732, vnbg_loss 0.62840, b1 0.49247, b2 0.36269, b3 0.26355, b4 0.19031, padchxlmacf1 0.07375, padchxlmicf1 0.17771, padchxlzmacf1 0.08329, padchxlzmicf1 0.17258, padchxl_loss 0.34422, padchxlz_loss 0.48641, 86.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.19642, wmdcmp 0.17074, ema 0.70636, oracc 0.98727, qlmicf1 0.37655, qlmacf1 0.22206, chxlmicf1 0.53290, chxlmacf1 0.46804, chxlacc 0.70970, chxlrocaucmic 0.79924, chxlrocaucmac 0.76420, 22.32 secs\n",
      "Adjusting learning rate of group 0 to 1.1207e-06.\n",
      "\u001b[1m---- Epoch 99/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.22176, a_loss 1.23952, cD 0.99971, wmdcmp 0.13644, ema 0.64176, oracc 0.98481, orien_loss 0.01951, qlmicf1 0.37599, qlmacf1 0.22572, ql_loss 0.76554, chxlmicf1 0.53272, chxlmacf1 0.48696, chx_loss 0.82386, chxlacc 0.72743, chxlrocaucmic 0.81486, chxlrocaucmac 0.80294, gacc 0.97714, gloss 0.06074, cxr14micf1 0.35712, cxr14macf1 0.34709, cxr14_loss 0.92386, vnbgmicf1 0.59951, vnbgmacf1 0.46032, vnbg_loss 0.63165, b1 0.47462, b2 0.35087, b3 0.25667, b4 0.18725, padchxlmacf1 0.07155, padchxlmicf1 0.17032, padchxlzmacf1 0.08677, padchxlzmicf1 0.17943, padchxl_loss 0.35889, padchxlz_loss 0.48469, 90.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21203, wmdcmp 0.17240, ema 0.70188, oracc 0.98727, qlmicf1 0.37753, qlmacf1 0.22232, chxlmicf1 0.53114, chxlmacf1 0.46676, chxlacc 0.70945, chxlrocaucmic 0.79896, chxlrocaucmac 0.76419, 20.22 secs\n",
      "Adjusting learning rate of group 0 to 1.0586e-06.\n",
      "\u001b[1m---- Epoch 100/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.74898, a_loss 1.24475, cD 1.01067, wmdcmp 0.13976, ema 0.64790, oracc 0.98481, orien_loss 0.02337, qlmicf1 0.38411, qlmacf1 0.22649, ql_loss 0.76653, chxlmicf1 0.53753, chxlmacf1 0.49127, chx_loss 0.81616, chxlacc 0.73031, chxlrocaucmic 0.81809, chxlrocaucmac 0.80666, gacc 0.97483, gloss 0.06042, cxr14micf1 0.36758, cxr14macf1 0.35281, cxr14_loss 0.91588, vnbgmicf1 0.60543, vnbgmacf1 0.47381, vnbg_loss 0.62356, b1 0.47453, b2 0.34797, b3 0.25167, b4 0.18180, padchxlmacf1 0.07046, padchxlmicf1 0.17655, padchxlzmacf1 0.08374, padchxlzmicf1 0.17715, padchxl_loss 0.34108, padchxlz_loss 0.47900, 92.04 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.19706, wmdcmp 0.17082, ema 0.70994, oracc 0.98751, qlmicf1 0.37781, qlmacf1 0.22264, chxlmicf1 0.53436, chxlmacf1 0.47012, chxlacc 0.70986, chxlrocaucmic 0.79983, chxlrocaucmac 0.76524, 22.00 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 100 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 55 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,2e-4,93,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"facebook/vit-mae-base\" \\\n",
    "        --image-encoder-pretrained-weights-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
