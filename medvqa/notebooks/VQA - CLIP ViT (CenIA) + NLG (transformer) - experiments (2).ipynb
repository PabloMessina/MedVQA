{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-large-huggingface\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/vte-vit-large-patch16-bio-clinical-bert-finetuned-v2\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,4e-4,76,5e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 6\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "Downloading: 100%|█████████████████████████| 4.49k/4.49k [00:00<00:00, 2.74MB/s]\n",
      "Downloading: 100%|█████████████████████████| 1.54G/1.54G [01:14<00:00, 22.2MB/s]\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf-v2+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 12.03087, a_loss 8.39146, cD 0.00068, wmdcmp 0.00154, oracc 0.37693, orien_loss 1.15161, chxlmicf1 0.21168, chxlmacf1 0.26783, chx_loss 1.10727, chxlacc 0.50024, chxlrocaucmic 0.50557, chxlrocaucmac 0.51618, qlmicf1 0.08881, qlmacf1 0.11698, ql_loss 1.09867, gacc 0.51557, gloss 0.70867, cxr14micf1 0.12542, cxr14macf1 0.17219, cxr14_loss 1.24822, vnbgmicf1 0.10706, vnbgmacf1 0.16387, vnbg_loss 9.43556, ema 0.00000, 290.78 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.00060, wmdcmp 0.00139, oracc 0.45273, chxlmicf1 0.22137, chxlmacf1 0.27986, chxlacc 0.48887, chxlrocaucmic 0.48867, chxlrocaucmac 0.50012, qlmicf1 0.10975, qlmacf1 0.14088, ema 0.00000, 99.90 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 11.72906, a_loss 7.03816, cD 0.00029, wmdcmp 0.00022, oracc 0.53493, orien_loss 1.01795, chxlmicf1 0.26849, chxlmacf1 0.31125, chx_loss 1.08049, chxlacc 0.52903, chxlrocaucmic 0.56722, chxlrocaucmac 0.57357, qlmicf1 0.11681, qlmacf1 0.12955, ql_loss 1.07106, gacc 0.55125, gloss 0.68793, cxr14micf1 0.14173, cxr14macf1 0.18636, cxr14_loss 1.23930, vnbgmicf1 0.15063, vnbgmacf1 0.19860, vnbg_loss 7.73891, ema 0.01926, 263.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, oracc 0.66895, chxlmicf1 0.31969, chxlmacf1 0.34579, chxlacc 0.53244, chxlrocaucmic 0.57926, chxlrocaucmac 0.58527, qlmicf1 0.15962, qlmacf1 0.15858, ema 0.03636, 94.42 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 10.45847, a_loss 4.91428, cD 0.05773, wmdcmp 0.01050, oracc 0.75258, orien_loss 0.69713, chxlmicf1 0.44596, chxlmacf1 0.40995, chx_loss 1.00731, chxlacc 0.62462, chxlrocaucmic 0.72062, chxlrocaucmac 0.70564, qlmicf1 0.24848, qlmacf1 0.16826, ql_loss 0.99376, gacc 0.60216, gloss 0.66237, cxr14micf1 0.20303, cxr14macf1 0.23222, cxr14_loss 1.18503, vnbgmicf1 0.36802, vnbgmacf1 0.29916, vnbg_loss 5.27802, ema 0.00306, 263.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.11765, wmdcmp 0.02042, oracc 0.86415, chxlmicf1 0.48675, chxlmacf1 0.43666, chxlacc 0.64129, chxlrocaucmic 0.73301, chxlrocaucmac 0.71057, qlmicf1 0.32748, qlmacf1 0.20818, ema 0.00000, 95.00 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-05.\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 8.41381, a_loss 2.58277, cD 0.09362, wmdcmp 0.02140, oracc 0.89864, orien_loss 0.33751, chxlmicf1 0.50579, chxlmacf1 0.46076, chx_loss 0.92324, chxlacc 0.68908, chxlrocaucmic 0.78324, chxlrocaucmac 0.76086, qlmicf1 0.35874, qlmacf1 0.20772, ql_loss 0.89033, gacc 0.66602, gloss 0.61887, cxr14micf1 0.30170, cxr14macf1 0.30380, cxr14_loss 1.06477, vnbgmicf1 0.51755, vnbgmacf1 0.38020, vnbg_loss 2.73597, ema 0.27875, 264.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.11632, wmdcmp 0.02680, oracc 0.95616, chxlmicf1 0.52840, chxlmacf1 0.47360, chxlacc 0.68751, chxlrocaucmic 0.77134, chxlrocaucmac 0.74920, qlmicf1 0.37316, qlmacf1 0.24214, ema 0.64545, 94.72 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-04.\n",
      "\u001b[1m---- Epoch 5/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 7.06849, a_loss 1.53867, cD 0.45017, wmdcmp 0.07074, oracc 0.95406, orien_loss 0.14278, chxlmicf1 0.51264, chxlmacf1 0.46706, chx_loss 0.89434, chxlacc 0.70439, chxlrocaucmic 0.79230, chxlrocaucmac 0.77104, qlmicf1 0.35781, qlmacf1 0.21556, ql_loss 0.83464, gacc 0.71864, gloss 0.56335, cxr14micf1 0.33908, cxr14macf1 0.32979, cxr14_loss 0.98870, vnbgmicf1 0.53260, vnbgmacf1 0.40577, vnbg_loss 1.21722, ema 0.57389, 265.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.79901, wmdcmp 0.12024, oracc 0.96600, chxlmicf1 0.52624, chxlmacf1 0.47140, chxlacc 0.68436, chxlrocaucmic 0.78087, chxlrocaucmac 0.75257, qlmicf1 0.35462, qlmacf1 0.24505, ema 0.64273, 96.21 secs\n",
      "Adjusting learning rate of group 0 to 3.7759e-04.\n",
      "\u001b[1m---- Epoch 6/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000378) ...\n",
      "loss 5.76229, a_loss 1.23328, cD 0.77086, wmdcmp 0.11083, oracc 0.96862, orien_loss 0.08778, chxlmicf1 0.52131, chxlmacf1 0.47351, chx_loss 0.88506, chxlacc 0.71107, chxlrocaucmic 0.79695, chxlrocaucmac 0.77626, qlmicf1 0.35577, qlmacf1 0.21672, ql_loss 0.82823, gacc 0.75648, gloss 0.51265, cxr14micf1 0.34214, cxr14macf1 0.33781, cxr14_loss 0.96091, vnbgmicf1 0.53983, vnbgmacf1 0.41317, vnbg_loss 0.87594, ema 0.65287, 264.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.74742, wmdcmp 0.12681, oracc 0.97599, chxlmicf1 0.53555, chxlmacf1 0.47881, chxlacc 0.69717, chxlrocaucmic 0.78164, chxlrocaucmac 0.75563, qlmicf1 0.36806, qlmacf1 0.25221, ema 0.66364, 96.70 secs\n",
      "Adjusting learning rate of group 0 to 3.5643e-04.\n",
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000356) ...\n",
      "loss 5.12484, a_loss 1.14028, cD 0.94418, wmdcmp 0.13167, oracc 0.97271, orien_loss 0.06809, chxlmicf1 0.52325, chxlmacf1 0.47440, chx_loss 0.88018, chxlacc 0.71198, chxlrocaucmic 0.79885, chxlrocaucmac 0.77882, qlmicf1 0.35833, qlmacf1 0.21973, ql_loss 0.82051, gacc 0.78273, gloss 0.48046, cxr14micf1 0.35290, cxr14macf1 0.34197, cxr14_loss 0.94362, vnbgmicf1 0.55186, vnbgmacf1 0.41662, vnbg_loss 0.81880, ema 0.66685, 267.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.96553, wmdcmp 0.15037, oracc 0.97882, chxlmicf1 0.53675, chxlmacf1 0.48274, chxlacc 0.69641, chxlrocaucmic 0.78233, chxlrocaucmac 0.75795, qlmicf1 0.36565, qlmacf1 0.25656, ema 0.67727, 105.95 secs\n",
      "Adjusting learning rate of group 0 to 3.3646e-04.\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000336) ...\n",
      "loss 4.94245, a_loss 1.08878, cD 1.02308, wmdcmp 0.14058, oracc 0.97443, orien_loss 0.05981, chxlmicf1 0.52650, chxlmacf1 0.47788, chx_loss 0.87705, chxlacc 0.71260, chxlrocaucmic 0.80168, chxlrocaucmac 0.78108, qlmicf1 0.36067, qlmacf1 0.22127, ql_loss 0.81994, gacc 0.80159, gloss 0.45675, cxr14micf1 0.34487, cxr14macf1 0.33839, cxr14_loss 0.95322, vnbgmicf1 0.55594, vnbgmacf1 0.42418, vnbg_loss 0.79199, ema 0.67347, 268.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.97122, wmdcmp 0.14914, oracc 0.98285, chxlmicf1 0.53213, chxlmacf1 0.47951, chxlacc 0.70066, chxlrocaucmic 0.77816, chxlrocaucmac 0.75617, qlmicf1 0.37174, qlmacf1 0.25393, ema 0.68364, 148.53 secs\n",
      "Adjusting learning rate of group 0 to 3.1761e-04.\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000318) ...\n",
      "loss 5.15841, a_loss 1.05092, cD 1.06980, wmdcmp 0.14768, oracc 0.97721, orien_loss 0.04994, chxlmicf1 0.52191, chxlmacf1 0.47415, chx_loss 0.87965, chxlacc 0.71145, chxlrocaucmic 0.79963, chxlrocaucmac 0.77823, qlmicf1 0.36348, qlmacf1 0.22339, ql_loss 0.81722, gacc 0.81057, gloss 0.44141, cxr14micf1 0.35383, cxr14macf1 0.34307, cxr14_loss 0.95020, vnbgmicf1 0.56301, vnbgmacf1 0.43110, vnbg_loss 0.75858, ema 0.69014, 278.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00607, wmdcmp 0.15022, oracc 0.98285, chxlmicf1 0.52838, chxlmacf1 0.48068, chxlacc 0.69502, chxlrocaucmic 0.77255, chxlrocaucmac 0.75678, qlmicf1 0.37403, qlmacf1 0.25686, ema 0.67727, 148.63 secs\n",
      "Adjusting learning rate of group 0 to 2.9982e-04.\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 5.09296, a_loss 1.02883, cD 1.11116, wmdcmp 0.15296, oracc 0.97847, orien_loss 0.04858, chxlmicf1 0.52414, chxlmacf1 0.47546, chx_loss 0.87772, chxlacc 0.71462, chxlrocaucmic 0.80058, chxlrocaucmac 0.78058, qlmicf1 0.36724, qlmacf1 0.22526, ql_loss 0.81335, gacc 0.81841, gloss 0.42661, cxr14micf1 0.35405, cxr14macf1 0.34656, cxr14_loss 0.94387, vnbgmicf1 0.57355, vnbgmacf1 0.43804, vnbg_loss 0.74358, ema 0.69093, 272.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.94472, wmdcmp 0.14837, oracc 0.98002, chxlmicf1 0.53511, chxlmacf1 0.48280, chxlacc 0.69587, chxlrocaucmic 0.78079, chxlrocaucmac 0.75957, qlmicf1 0.37947, qlmacf1 0.25775, ema 0.69182, 184.93 secs\n",
      "Adjusting learning rate of group 0 to 2.8302e-04.\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000283) ...\n",
      "loss 4.36733, a_loss 1.00584, cD 1.14441, wmdcmp 0.15560, oracc 0.97976, orien_loss 0.04523, chxlmicf1 0.52619, chxlmacf1 0.47815, chx_loss 0.87185, chxlacc 0.71613, chxlrocaucmic 0.80331, chxlrocaucmac 0.78344, qlmicf1 0.36870, qlmacf1 0.22534, ql_loss 0.80928, gacc 0.81875, gloss 0.41755, cxr14micf1 0.37191, cxr14macf1 0.35462, cxr14_loss 0.91729, vnbgmicf1 0.57804, vnbgmacf1 0.44399, vnbg_loss 0.72997, ema 0.70130, 261.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.03936, wmdcmp 0.15405, oracc 0.98285, chxlmicf1 0.53643, chxlmacf1 0.48437, chxlacc 0.69866, chxlrocaucmic 0.77965, chxlrocaucmac 0.76281, qlmicf1 0.37062, qlmacf1 0.25872, ema 0.68273, 156.52 secs\n",
      "Adjusting learning rate of group 0 to 2.6716e-04.\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000267) ...\n",
      "loss 4.54860, a_loss 0.99586, cD 1.16874, wmdcmp 0.15885, oracc 0.98055, orien_loss 0.03798, chxlmicf1 0.52842, chxlmacf1 0.47959, chx_loss 0.87104, chxlacc 0.71639, chxlrocaucmic 0.80331, chxlrocaucmac 0.78408, qlmicf1 0.37055, qlmacf1 0.22531, ql_loss 0.80465, gacc 0.82852, gloss 0.40764, cxr14micf1 0.34609, cxr14macf1 0.34191, cxr14_loss 0.94133, vnbgmicf1 0.57726, vnbgmacf1 0.43670, vnbg_loss 0.70886, ema 0.70148, 259.40 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.07670, wmdcmp 0.16230, oracc 0.98002, chxlmicf1 0.54120, chxlmacf1 0.48788, chxlacc 0.70802, chxlrocaucmic 0.78060, chxlrocaucmac 0.76203, qlmicf1 0.39245, qlmacf1 0.25743, ema 0.69455, 151.86 secs\n",
      "Adjusting learning rate of group 0 to 2.5219e-04.\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000252) ...\n",
      "loss 4.60646, a_loss 0.97703, cD 1.19556, wmdcmp 0.16213, oracc 0.98029, orien_loss 0.03838, chxlmicf1 0.52719, chxlmacf1 0.47883, chx_loss 0.87259, chxlacc 0.71684, chxlrocaucmic 0.80353, chxlrocaucmac 0.78307, qlmicf1 0.37353, qlmacf1 0.23069, ql_loss 0.80271, gacc 0.82955, gloss 0.40408, cxr14micf1 0.37140, cxr14macf1 0.35730, cxr14_loss 0.92065, vnbgmicf1 0.58136, vnbgmacf1 0.44848, vnbg_loss 0.70729, ema 0.71028, 265.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20595, wmdcmp 0.17226, oracc 0.98285, chxlmicf1 0.53551, chxlmacf1 0.48315, chxlacc 0.70028, chxlrocaucmic 0.78096, chxlrocaucmac 0.76004, qlmicf1 0.37820, qlmacf1 0.25798, ema 0.68909, 141.13 secs\n",
      "Adjusting learning rate of group 0 to 2.3806e-04.\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000238) ...\n",
      "loss 4.35210, a_loss 0.96503, cD 1.22961, wmdcmp 0.16630, oracc 0.98041, orien_loss 0.03648, chxlmicf1 0.52786, chxlmacf1 0.47915, chx_loss 0.87041, chxlacc 0.71713, chxlrocaucmic 0.80476, chxlrocaucmac 0.78632, qlmicf1 0.37332, qlmacf1 0.22576, ql_loss 0.80391, gacc 0.82784, gloss 0.39665, cxr14micf1 0.36931, cxr14macf1 0.35096, cxr14_loss 0.92938, vnbgmicf1 0.58505, vnbgmacf1 0.44917, vnbg_loss 0.69434, ema 0.71556, 266.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07415, wmdcmp 0.15908, oracc 0.98285, chxlmicf1 0.53694, chxlmacf1 0.48588, chxlacc 0.70164, chxlrocaucmic 0.77847, chxlrocaucmac 0.76292, qlmicf1 0.37641, qlmacf1 0.25728, ema 0.71273, 137.01 secs\n",
      "Adjusting learning rate of group 0 to 2.2473e-04.\n",
      "\u001b[1m---- Epoch 15/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000225) ...\n",
      "loss 4.37897, a_loss 0.96369, cD 1.25372, wmdcmp 0.16817, oracc 0.97973, orien_loss 0.03803, chxlmicf1 0.52923, chxlmacf1 0.48083, chx_loss 0.86863, chxlacc 0.71732, chxlrocaucmic 0.80523, chxlrocaucmac 0.78526, qlmicf1 0.37124, qlmacf1 0.22636, ql_loss 0.79868, gacc 0.84102, gloss 0.38422, cxr14micf1 0.37887, cxr14macf1 0.36131, cxr14_loss 0.91377, vnbgmicf1 0.58545, vnbgmacf1 0.45288, vnbg_loss 0.70412, ema 0.70861, 260.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24709, wmdcmp 0.18171, oracc 0.98285, chxlmicf1 0.53851, chxlmacf1 0.48706, chxlacc 0.70599, chxlrocaucmic 0.78175, chxlrocaucmac 0.76290, qlmicf1 0.38425, qlmacf1 0.25956, ema 0.70182, 130.22 secs\n",
      "Adjusting learning rate of group 0 to 2.1214e-04.\n",
      "\u001b[1m---- Epoch 16/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000212) ...\n",
      "loss 4.54483, a_loss 0.95233, cD 1.28012, wmdcmp 0.17184, oracc 0.98106, orien_loss 0.03267, chxlmicf1 0.53088, chxlmacf1 0.48249, chx_loss 0.86926, chxlacc 0.71896, chxlrocaucmic 0.80529, chxlrocaucmac 0.78631, qlmicf1 0.37577, qlmacf1 0.23189, ql_loss 0.79813, gacc 0.83864, gloss 0.38447, cxr14micf1 0.37370, cxr14macf1 0.35685, cxr14_loss 0.92527, vnbgmicf1 0.58714, vnbgmacf1 0.45269, vnbg_loss 0.68458, ema 0.71745, 257.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23535, wmdcmp 0.17671, oracc 0.98285, chxlmicf1 0.53526, chxlmacf1 0.48189, chxlacc 0.70102, chxlrocaucmic 0.78115, chxlrocaucmac 0.76093, qlmicf1 0.38389, qlmacf1 0.26287, ema 0.70091, 131.92 secs\n",
      "Adjusting learning rate of group 0 to 2.0025e-04.\n",
      "\u001b[1m---- Epoch 17/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 4.65082, a_loss 0.94019, cD 1.28965, wmdcmp 0.17245, oracc 0.98142, orien_loss 0.03384, chxlmicf1 0.53083, chxlmacf1 0.48253, chx_loss 0.86314, chxlacc 0.71844, chxlrocaucmic 0.80615, chxlrocaucmac 0.78713, qlmicf1 0.37796, qlmacf1 0.23156, ql_loss 0.79340, gacc 0.84670, gloss 0.37339, cxr14micf1 0.37016, cxr14macf1 0.35417, cxr14_loss 0.92141, vnbgmicf1 0.59186, vnbgmacf1 0.45160, vnbg_loss 0.68284, ema 0.71574, 251.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20651, wmdcmp 0.17543, oracc 0.98285, chxlmicf1 0.54054, chxlmacf1 0.48689, chxlacc 0.70589, chxlrocaucmic 0.78420, chxlrocaucmac 0.76367, qlmicf1 0.38715, qlmacf1 0.26410, ema 0.69909, 143.90 secs\n",
      "Adjusting learning rate of group 0 to 1.8903e-04.\n",
      "\u001b[1m---- Epoch 18/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 4.58151, a_loss 0.93155, cD 1.30871, wmdcmp 0.17582, oracc 0.98066, orien_loss 0.03268, chxlmicf1 0.53196, chxlmacf1 0.48220, chx_loss 0.86173, chxlacc 0.71910, chxlrocaucmic 0.80637, chxlrocaucmac 0.78730, qlmicf1 0.37529, qlmacf1 0.22925, ql_loss 0.79743, gacc 0.84284, gloss 0.37848, cxr14micf1 0.37541, cxr14macf1 0.35896, cxr14_loss 0.90008, vnbgmicf1 0.59181, vnbgmacf1 0.45659, vnbg_loss 0.67489, ema 0.72343, 263.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22660, wmdcmp 0.17547, oracc 0.98285, chxlmicf1 0.54057, chxlmacf1 0.48890, chxlacc 0.70896, chxlrocaucmic 0.78127, chxlrocaucmac 0.76283, qlmicf1 0.38516, qlmacf1 0.26319, ema 0.72091, 148.36 secs\n",
      "Adjusting learning rate of group 0 to 1.7844e-04.\n",
      "\u001b[1m---- Epoch 19/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000178) ...\n",
      "loss 4.43750, a_loss 0.93017, cD 1.30587, wmdcmp 0.17551, oracc 0.98197, orien_loss 0.03139, chxlmicf1 0.53088, chxlmacf1 0.48156, chx_loss 0.86349, chxlacc 0.71963, chxlrocaucmic 0.80679, chxlrocaucmac 0.78735, qlmicf1 0.37934, qlmacf1 0.22987, ql_loss 0.79018, gacc 0.85170, gloss 0.36479, cxr14micf1 0.36807, cxr14macf1 0.35388, cxr14_loss 0.92111, vnbgmicf1 0.60192, vnbgmacf1 0.46077, vnbg_loss 0.65627, ema 0.72361, 262.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29635, wmdcmp 0.18332, oracc 0.98285, chxlmicf1 0.54271, chxlmacf1 0.49124, chxlacc 0.70249, chxlrocaucmic 0.78320, chxlrocaucmac 0.76260, qlmicf1 0.38947, qlmacf1 0.26166, ema 0.72091, 147.22 secs\n",
      "Adjusting learning rate of group 0 to 1.6844e-04.\n",
      "\u001b[1m---- Epoch 20/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 4.42424, a_loss 0.92478, cD 1.32212, wmdcmp 0.17689, oracc 0.98201, orien_loss 0.03262, chxlmicf1 0.53141, chxlmacf1 0.48246, chx_loss 0.86299, chxlacc 0.71959, chxlrocaucmic 0.80681, chxlrocaucmac 0.78765, qlmicf1 0.38051, qlmacf1 0.23172, ql_loss 0.78874, gacc 0.85034, gloss 0.36825, cxr14micf1 0.37914, cxr14macf1 0.36323, cxr14_loss 0.90757, vnbgmicf1 0.60032, vnbgmacf1 0.46514, vnbg_loss 0.66709, ema 0.71852, 267.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17974, wmdcmp 0.17319, oracc 0.98285, chxlmicf1 0.54172, chxlmacf1 0.48770, chxlacc 0.70701, chxlrocaucmic 0.78234, chxlrocaucmac 0.76266, qlmicf1 0.38519, qlmacf1 0.26173, ema 0.69818, 134.09 secs\n",
      "Adjusting learning rate of group 0 to 1.5900e-04.\n",
      "\u001b[1m---- Epoch 21/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 4.24490, a_loss 0.91659, cD 1.34842, wmdcmp 0.18036, oracc 0.98110, orien_loss 0.03100, chxlmicf1 0.52922, chxlmacf1 0.48017, chx_loss 0.86689, chxlacc 0.71861, chxlrocaucmic 0.80588, chxlrocaucmac 0.78696, qlmicf1 0.37560, qlmacf1 0.23449, ql_loss 0.79559, gacc 0.84636, gloss 0.36697, cxr14micf1 0.37071, cxr14macf1 0.36029, cxr14_loss 0.91432, vnbgmicf1 0.59758, vnbgmacf1 0.45657, vnbg_loss 0.66544, ema 0.72324, 266.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18363, wmdcmp 0.17237, oracc 0.98285, chxlmicf1 0.53844, chxlmacf1 0.48631, chxlacc 0.69817, chxlrocaucmic 0.78282, chxlrocaucmac 0.76331, qlmicf1 0.39266, qlmacf1 0.26533, ema 0.71000, 131.09 secs\n",
      "Adjusting learning rate of group 0 to 1.5010e-04.\n",
      "\u001b[1m---- Epoch 22/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "Current run is terminating due to exception: Caught OSError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\n",
      "    return self.datasets[idx][j]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2809, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "OSError: [Errno 5] Input/output error: '/mnt/workspace/mimic-cxr-jpg/images-small/p17/p17996251/s52808277/81743f70-88f54abe-7f516b76-d90f4a00-06226d03.jpg'\n",
      "\n",
      "Engine run is terminating due to exception: Caught OSError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\r\n",
      "    return self.datasets[idx][j]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\r\n",
      "    return self.datasets[idx][j]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\r\n",
      "    return self.datasets[idx][j]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\r\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2809, in open\r\n",
      "    fp = builtins.open(filename, \"rb\")\r\n",
      "OSError: [Errno 5] Input/output error: '/mnt/workspace/mimic-cxr-jpg/images-small/p17/p17996251/s52808277/81743f70-88f54abe-7f516b76-d90f4a00-06226d03.jpg'\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"../train_vqa.py\", line 1449, in <module>\r\n",
      "    train_from_scratch(**args)\r\n",
      "  File \"../train_vqa.py\", line 1348, in train_from_scratch\r\n",
      "    debug=debug)\r\n",
      "  File \"../train_vqa.py\", line 890, in train_model\r\n",
      "    epoch_length = batches_per_epoch)\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\r\n",
      "    return self._internal_run()\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\r\n",
      "    self._handle_exception(e)\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\r\n",
      "    raise e\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\r\n",
      "    time_taken = self._run_once_on_dataset()\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\r\n",
      "    self._handle_exception(e)\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\r\n",
      "    raise e\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 801, in _run_once_on_dataset\r\n",
      "    self.state.batch = next(self._dataloader_iter)\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 169, in balanced_dataloaders_generator\r\n",
      "    yield next(cyclic_dataloaders[i])\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 135, in cyclic_dataloader_generator\r\n",
      "    for batch in dataloader:\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\r\n",
      "    return self._process_data(data)\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/_utils.py\", line 434, in reraise\r\n",
      "    raise exception\r\n",
      "OSError: Caught OSError in DataLoader worker process 0.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\r\n",
      "    return self.datasets[idx][j]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\r\n",
      "    return self.datasets[idx][j]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 90, in __getitem__\r\n",
      "    return self.datasets[idx][j]\r\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/vqa.py\", line 322, in __getitem__\r\n",
      "    img = Image.open(self.images[idx]).convert('RGB')\r\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2809, in open\r\n",
      "    fp = builtins.open(filename, \"rb\")\r\n",
      "OSError: [Errno 5] Input/output error: '/mnt/workspace/mimic-cxr-jpg/images-small/p17/p17996251/s52808277/81743f70-88f54abe-7f516b76-d90f4a00-06226d03.jpg'\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 80 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 6 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,4e-4,76,5e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --raw-image-encoding \"clip-vit-large-huggingface\" \\\n",
    "        --clip-version \"CenIA/vte-vit-large-patch16-bio-clinical-bert-finetuned-v2\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 30\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   iuxray_qa_adapted_reports_filename: None\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: bilstm\n",
      "   answer_decoding: lstm\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adam\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 80\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 6\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.05\n",
      "   mimiccxr_weight_chexpert_mode: 0.2\n",
      "   iuxray_weight_chexpert_mode: 0.05\n",
      "   mimiccxr_include_chexpert_mode: False\n",
      "   iuxray_include_chexpert_mode: False\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: False\n",
      "   medical_tokenization: False\n",
      "   medical_terms_frequency_filename: None\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: False\n",
      "   balanced_dataloading: False\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: None\n",
      "   mimiccxr_balanced_metadata_filename: None\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   iuxray_train_with_all: False\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: None\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_questions: False\n",
      "   n_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf-v2+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,76,5e-6\n",
      "1e-06 4 0.0004 76 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=291,232191628010637280).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 94\n",
      "len(self.val_indices) = 5904\n",
      "len(val_indices) = 5904\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43305, len(neg_indices)=179786\n",
      "label = 1, onehot=98, len(pos_indices)=43438, len(neg_indices)=179653\n",
      "label = 2, onehot=99, len(pos_indices)=72070, len(neg_indices)=151021\n",
      "label = 3, onehot=100, len(pos_indices)=9732, len(neg_indices)=213359\n",
      "label = 4, onehot=101, len(pos_indices)=74057, len(neg_indices)=149034\n",
      "label = 5, onehot=102, len(pos_indices)=42882, len(neg_indices)=180209\n",
      "label = 6, onehot=103, len(pos_indices)=19895, len(neg_indices)=203196\n",
      "label = 7, onehot=104, len(pos_indices)=37512, len(neg_indices)=185579\n",
      "label = 8, onehot=105, len(pos_indices)=70066, len(neg_indices)=153025\n",
      "label = 9, onehot=106, len(pos_indices)=13126, len(neg_indices)=209965\n",
      "label = 10, onehot=107, len(pos_indices)=68917, len(neg_indices)=154174\n",
      "label = 11, onehot=108, len(pos_indices)=4965, len(neg_indices)=218126\n",
      "label = 12, onehot=109, len(pos_indices)=8410, len(neg_indices)=214681\n",
      "label = 13, onehot=110, len(pos_indices)=88455, len(neg_indices)=134636\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=23, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1100\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=306,1949366693876782620).pkl.balanced_train_data(bs=80,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 50\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 6\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.1, 0.08, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_19_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5767.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_19_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5767.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 20/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 3.50432, a_loss 0.87230, cD 1.41716, wmdcmp 0.18728, oracc 0.98157, orien_loss 0.03575, chxlmicf1 0.52982, chxlmacf1 0.48043, chx_loss 0.86735, chxlacc 0.71836, chxlrocaucmic 0.80616, chxlrocaucmac 0.78675, qlmicf1 0.38215, qlmacf1 0.23057, ql_loss 0.78604, gacc 0.84114, gloss 0.36789, cxr14micf1 0.38005, cxr14macf1 0.36440, cxr14_loss 0.90893, vnbgmicf1 0.59581, vnbgmacf1 0.46209, vnbg_loss 0.65344, ema 0.71394, 293.56 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.18425, wmdcmp 0.17224, oracc 0.98419, chxlmicf1 0.53873, chxlmacf1 0.48507, chxlacc 0.70786, chxlrocaucmic 0.78253, chxlrocaucmac 0.76352, qlmicf1 0.38444, qlmacf1 0.25895, ema 0.69364, 137.20 secs\n",
      "Adjusting learning rate of group 0 to 1.5900e-04.\n",
      "\u001b[1m---- Epoch 21/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000159) ...\n",
      "loss 4.29946, a_loss 0.90998, cD 1.35076, wmdcmp 0.18006, oracc 0.98200, orien_loss 0.02895, chxlmicf1 0.52986, chxlmacf1 0.48118, chx_loss 0.86468, chxlacc 0.71875, chxlrocaucmic 0.80682, chxlrocaucmac 0.78773, qlmicf1 0.38331, qlmacf1 0.23727, ql_loss 0.78584, gacc 0.85136, gloss 0.36182, cxr14micf1 0.36764, cxr14macf1 0.35547, cxr14_loss 0.92097, vnbgmicf1 0.59817, vnbgmacf1 0.46564, vnbg_loss 0.66319, ema 0.72417, 267.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28960, wmdcmp 0.18213, oracc 0.98419, chxlmicf1 0.54070, chxlmacf1 0.48678, chxlacc 0.70666, chxlrocaucmic 0.78389, chxlrocaucmac 0.76356, qlmicf1 0.39485, qlmacf1 0.26242, ema 0.69818, 101.28 secs\n",
      "Adjusting learning rate of group 0 to 1.5010e-04.\n",
      "\u001b[1m---- Epoch 22/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000150) ...\n",
      "loss 4.18261, a_loss 0.90993, cD 1.37154, wmdcmp 0.18243, oracc 0.98243, orien_loss 0.03202, chxlmicf1 0.52870, chxlmacf1 0.48024, chx_loss 0.86401, chxlacc 0.71884, chxlrocaucmic 0.80576, chxlrocaucmac 0.78821, qlmicf1 0.37993, qlmacf1 0.23562, ql_loss 0.78822, gacc 0.84636, gloss 0.36988, cxr14micf1 0.37643, cxr14macf1 0.36210, cxr14_loss 0.90337, vnbgmicf1 0.59934, vnbgmacf1 0.46367, vnbg_loss 0.65898, ema 0.72208, 266.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20398, wmdcmp 0.17106, oracc 0.98419, chxlmicf1 0.54065, chxlmacf1 0.48704, chxlacc 0.70472, chxlrocaucmic 0.78210, chxlrocaucmac 0.76316, qlmicf1 0.39541, qlmacf1 0.26573, ema 0.69091, 110.23 secs\n",
      "Adjusting learning rate of group 0 to 1.4169e-04.\n",
      "\u001b[1m---- Epoch 23/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 4.32260, a_loss 0.90184, cD 1.38234, wmdcmp 0.18268, oracc 0.98191, orien_loss 0.03058, chxlmicf1 0.53214, chxlmacf1 0.48247, chx_loss 0.86356, chxlacc 0.71931, chxlrocaucmic 0.80680, chxlrocaucmac 0.78704, qlmicf1 0.38027, qlmacf1 0.23694, ql_loss 0.78761, gacc 0.84852, gloss 0.36637, cxr14micf1 0.39357, cxr14macf1 0.36952, cxr14_loss 0.89245, vnbgmicf1 0.60186, vnbgmacf1 0.46695, vnbg_loss 0.64662, ema 0.72514, 253.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26820, wmdcmp 0.17997, oracc 0.98419, chxlmicf1 0.53700, chxlmacf1 0.48268, chxlacc 0.70507, chxlrocaucmic 0.78102, chxlrocaucmac 0.76297, qlmicf1 0.38812, qlmacf1 0.26244, ema 0.68909, 118.48 secs\n",
      "Adjusting learning rate of group 0 to 1.3375e-04.\n",
      "\u001b[1m---- Epoch 24/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 4.44250, a_loss 0.89765, cD 1.38199, wmdcmp 0.18336, oracc 0.98287, orien_loss 0.03175, chxlmicf1 0.53089, chxlmacf1 0.48182, chx_loss 0.86288, chxlacc 0.71978, chxlrocaucmic 0.80703, chxlrocaucmac 0.78786, qlmicf1 0.38569, qlmacf1 0.23832, ql_loss 0.78816, gacc 0.84943, gloss 0.36188, cxr14micf1 0.37117, cxr14macf1 0.35631, cxr14_loss 0.90749, vnbgmicf1 0.60659, vnbgmacf1 0.46941, vnbg_loss 0.63974, ema 0.72884, 267.27 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31157, wmdcmp 0.18641, oracc 0.98419, chxlmicf1 0.54100, chxlmacf1 0.48717, chxlacc 0.70538, chxlrocaucmic 0.78605, chxlrocaucmac 0.76412, qlmicf1 0.38361, qlmacf1 0.26122, ema 0.69000, 113.82 secs\n",
      "Adjusting learning rate of group 0 to 1.2625e-04.\n",
      "\u001b[1m---- Epoch 25/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000126) ...\n",
      "loss 4.45411, a_loss 0.89778, cD 1.40975, wmdcmp 0.18626, oracc 0.98089, orien_loss 0.03266, chxlmicf1 0.53111, chxlmacf1 0.48162, chx_loss 0.86126, chxlacc 0.71874, chxlrocaucmic 0.80677, chxlrocaucmac 0.78805, qlmicf1 0.38284, qlmacf1 0.23172, ql_loss 0.78826, gacc 0.84977, gloss 0.35421, cxr14micf1 0.37393, cxr14macf1 0.35827, cxr14_loss 0.91851, vnbgmicf1 0.60981, vnbgmacf1 0.47199, vnbg_loss 0.63838, ema 0.73153, 267.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28126, wmdcmp 0.18168, oracc 0.98419, chxlmicf1 0.53740, chxlmacf1 0.48580, chxlacc 0.70713, chxlrocaucmic 0.78061, chxlrocaucmac 0.76216, qlmicf1 0.38821, qlmacf1 0.25999, ema 0.70727, 112.80 secs\n",
      "Adjusting learning rate of group 0 to 1.1918e-04.\n",
      "\u001b[1m---- Epoch 26/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000119) ...\n",
      "loss 4.31619, a_loss 0.89905, cD 1.39109, wmdcmp 0.18454, oracc 0.98155, orien_loss 0.03059, chxlmicf1 0.53316, chxlmacf1 0.48377, chx_loss 0.85970, chxlacc 0.71991, chxlrocaucmic 0.80796, chxlrocaucmac 0.78911, qlmicf1 0.38390, qlmacf1 0.23949, ql_loss 0.78885, gacc 0.85841, gloss 0.34989, cxr14micf1 0.37891, cxr14macf1 0.35983, cxr14_loss 0.90146, vnbgmicf1 0.60587, vnbgmacf1 0.46452, vnbg_loss 0.63470, ema 0.73236, 265.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31729, wmdcmp 0.18600, oracc 0.98419, chxlmicf1 0.54102, chxlmacf1 0.48896, chxlacc 0.70601, chxlrocaucmic 0.78289, chxlrocaucmac 0.76240, qlmicf1 0.39713, qlmacf1 0.26436, ema 0.69364, 115.51 secs\n",
      "Adjusting learning rate of group 0 to 1.1250e-04.\n",
      "\u001b[1m---- Epoch 27/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000113) ...\n",
      "loss 4.28169, a_loss 0.89320, cD 1.40305, wmdcmp 0.18609, oracc 0.98193, orien_loss 0.02896, chxlmicf1 0.53343, chxlmacf1 0.48423, chx_loss 0.85811, chxlacc 0.72044, chxlrocaucmic 0.80897, chxlrocaucmac 0.79019, qlmicf1 0.38630, qlmacf1 0.23730, ql_loss 0.78620, gacc 0.85182, gloss 0.35681, cxr14micf1 0.36942, cxr14macf1 0.35674, cxr14_loss 0.90584, vnbgmicf1 0.60658, vnbgmacf1 0.47069, vnbg_loss 0.64114, ema 0.73097, 267.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21809, wmdcmp 0.17757, oracc 0.98419, chxlmicf1 0.53782, chxlmacf1 0.48510, chxlacc 0.70486, chxlrocaucmic 0.78208, chxlrocaucmac 0.76406, qlmicf1 0.39496, qlmacf1 0.26242, ema 0.69182, 113.20 secs\n",
      "Adjusting learning rate of group 0 to 1.0620e-04.\n",
      "\u001b[1m---- Epoch 28/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 4.44899, a_loss 0.88663, cD 1.42021, wmdcmp 0.18877, oracc 0.98306, orien_loss 0.02827, chxlmicf1 0.53051, chxlmacf1 0.48118, chx_loss 0.86195, chxlacc 0.72051, chxlrocaucmic 0.80710, chxlrocaucmac 0.78832, qlmicf1 0.38312, qlmacf1 0.24056, ql_loss 0.78434, gacc 0.85693, gloss 0.35599, cxr14micf1 0.37047, cxr14macf1 0.35748, cxr14_loss 0.91063, vnbgmicf1 0.60885, vnbgmacf1 0.47243, vnbg_loss 0.63831, ema 0.73329, 268.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27110, wmdcmp 0.18195, oracc 0.98419, chxlmicf1 0.53786, chxlmacf1 0.48650, chxlacc 0.70379, chxlrocaucmic 0.78086, chxlrocaucmac 0.76333, qlmicf1 0.38611, qlmacf1 0.26151, ema 0.69545, 124.88 secs\n",
      "Adjusting learning rate of group 0 to 1.0025e-04.\n",
      "\u001b[1m---- Epoch 29/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.43070, a_loss 0.88670, cD 1.41146, wmdcmp 0.18786, oracc 0.98286, orien_loss 0.02747, chxlmicf1 0.53453, chxlmacf1 0.48457, chx_loss 0.85724, chxlacc 0.72265, chxlrocaucmic 0.80797, chxlrocaucmac 0.79017, qlmicf1 0.38694, qlmacf1 0.24299, ql_loss 0.78124, gacc 0.85239, gloss 0.35750, cxr14micf1 0.38705, cxr14macf1 0.36916, cxr14_loss 0.90021, vnbgmicf1 0.61324, vnbgmacf1 0.47475, vnbg_loss 0.61672, ema 0.73505, 265.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22026, wmdcmp 0.17497, oracc 0.98419, chxlmicf1 0.54695, chxlmacf1 0.49411, chxlacc 0.70648, chxlrocaucmic 0.78598, chxlrocaucmac 0.76526, qlmicf1 0.38928, qlmacf1 0.26272, ema 0.69545, 113.57 secs\n",
      "Adjusting learning rate of group 0 to 9.4633e-05.\n",
      "\u001b[1m---- Epoch 30/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 4.21585, a_loss 0.88215, cD 1.41205, wmdcmp 0.18803, oracc 0.98342, orien_loss 0.02760, chxlmicf1 0.53101, chxlmacf1 0.48198, chx_loss 0.86289, chxlacc 0.72063, chxlrocaucmic 0.80741, chxlrocaucmac 0.78967, qlmicf1 0.38369, qlmacf1 0.24309, ql_loss 0.78618, gacc 0.86182, gloss 0.33861, cxr14micf1 0.37853, cxr14macf1 0.36399, cxr14_loss 0.90380, vnbgmicf1 0.61148, vnbgmacf1 0.47806, vnbg_loss 0.62979, ema 0.73176, 268.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28112, wmdcmp 0.18501, oracc 0.98419, chxlmicf1 0.54051, chxlmacf1 0.48846, chxlacc 0.70251, chxlrocaucmic 0.78486, chxlrocaucmac 0.76396, qlmicf1 0.38933, qlmacf1 0.26258, ema 0.70091, 119.56 secs\n",
      "Adjusting learning rate of group 0 to 8.9331e-05.\n",
      "\u001b[1m---- Epoch 31/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 4.02254, a_loss 0.88522, cD 1.44089, wmdcmp 0.18988, oracc 0.98331, orien_loss 0.02534, chxlmicf1 0.53424, chxlmacf1 0.48438, chx_loss 0.85534, chxlacc 0.72286, chxlrocaucmic 0.81009, chxlrocaucmac 0.79155, qlmicf1 0.38677, qlmacf1 0.23369, ql_loss 0.77935, gacc 0.86125, gloss 0.34206, cxr14micf1 0.38907, cxr14macf1 0.36545, cxr14_loss 0.89985, vnbgmicf1 0.61082, vnbgmacf1 0.47638, vnbg_loss 0.62330, ema 0.73245, 264.65 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.27346, wmdcmp 0.18133, oracc 0.98419, chxlmicf1 0.53876, chxlmacf1 0.48572, chxlacc 0.70573, chxlrocaucmic 0.78279, chxlrocaucmac 0.76339, qlmicf1 0.39624, qlmacf1 0.26480, ema 0.69364, 111.35 secs\n",
      "Adjusting learning rate of group 0 to 8.4326e-05.\n",
      "\u001b[1m---- Epoch 32/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000084) ...\n",
      "loss 4.34440, a_loss 0.87818, cD 1.42996, wmdcmp 0.18923, oracc 0.98271, orien_loss 0.02783, chxlmicf1 0.53251, chxlmacf1 0.48368, chx_loss 0.86086, chxlacc 0.72133, chxlrocaucmic 0.80781, chxlrocaucmac 0.78923, qlmicf1 0.38540, qlmacf1 0.23860, ql_loss 0.78426, gacc 0.86318, gloss 0.34085, cxr14micf1 0.37924, cxr14macf1 0.36324, cxr14_loss 0.90512, vnbgmicf1 0.61238, vnbgmacf1 0.47685, vnbg_loss 0.62862, ema 0.73130, 270.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32911, wmdcmp 0.18838, oracc 0.98419, chxlmicf1 0.54109, chxlmacf1 0.48773, chxlacc 0.70538, chxlrocaucmic 0.78422, chxlrocaucmac 0.76396, qlmicf1 0.38718, qlmacf1 0.26372, ema 0.70455, 120.18 secs\n",
      "Adjusting learning rate of group 0 to 7.9602e-05.\n",
      "\u001b[1m---- Epoch 33/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 4.25057, a_loss 0.87698, cD 1.44583, wmdcmp 0.19030, oracc 0.98121, orien_loss 0.03423, chxlmicf1 0.53348, chxlmacf1 0.48311, chx_loss 0.86103, chxlacc 0.72150, chxlrocaucmic 0.80834, chxlrocaucmac 0.79026, qlmicf1 0.38671, qlmacf1 0.23480, ql_loss 0.78222, gacc 0.85545, gloss 0.35196, cxr14micf1 0.38613, cxr14macf1 0.36917, cxr14_loss 0.88595, vnbgmicf1 0.61081, vnbgmacf1 0.47577, vnbg_loss 0.62267, ema 0.73319, 270.16 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21699, wmdcmp 0.17679, oracc 0.98419, chxlmicf1 0.53747, chxlmacf1 0.48377, chxlacc 0.70266, chxlrocaucmic 0.78392, chxlrocaucmac 0.76425, qlmicf1 0.38198, qlmacf1 0.26273, ema 0.71182, 110.17 secs\n",
      "Adjusting learning rate of group 0 to 7.5142e-05.\n",
      "\u001b[1m---- Epoch 34/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000075) ...\n",
      "loss 4.12034, a_loss 0.87662, cD 1.45648, wmdcmp 0.19167, oracc 0.98304, orien_loss 0.02808, chxlmicf1 0.53427, chxlmacf1 0.48504, chx_loss 0.85989, chxlacc 0.72143, chxlrocaucmic 0.80861, chxlrocaucmac 0.78993, qlmicf1 0.38763, qlmacf1 0.24753, ql_loss 0.77875, gacc 0.85966, gloss 0.34505, cxr14micf1 0.38661, cxr14macf1 0.36635, cxr14_loss 0.89278, vnbgmicf1 0.61088, vnbgmacf1 0.47434, vnbg_loss 0.62339, ema 0.73083, 269.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23229, wmdcmp 0.17923, oracc 0.98419, chxlmicf1 0.53929, chxlmacf1 0.48792, chxlacc 0.70429, chxlrocaucmic 0.78340, chxlrocaucmac 0.76384, qlmicf1 0.39814, qlmacf1 0.26845, ema 0.71818, 115.28 secs\n",
      "Adjusting learning rate of group 0 to 7.0932e-05.\n",
      "\u001b[1m---- Epoch 35/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 4.41067, a_loss 0.86965, cD 1.45407, wmdcmp 0.19125, oracc 0.98218, orien_loss 0.02736, chxlmicf1 0.53294, chxlmacf1 0.48371, chx_loss 0.85863, chxlacc 0.72017, chxlrocaucmic 0.80756, chxlrocaucmac 0.78974, qlmicf1 0.38769, qlmacf1 0.24688, ql_loss 0.78403, gacc 0.85716, gloss 0.34368, cxr14micf1 0.37920, cxr14macf1 0.36463, cxr14_loss 0.89634, vnbgmicf1 0.60875, vnbgmacf1 0.47590, vnbg_loss 0.62675, ema 0.73333, 267.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37870, wmdcmp 0.19056, oracc 0.98419, chxlmicf1 0.54069, chxlmacf1 0.48607, chxlacc 0.70543, chxlrocaucmic 0.78490, chxlrocaucmac 0.76356, qlmicf1 0.38998, qlmacf1 0.26368, ema 0.69545, 96.79 secs\n",
      "Adjusting learning rate of group 0 to 6.6958e-05.\n",
      "\u001b[1m---- Epoch 36/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 4.37205, a_loss 0.86678, cD 1.46753, wmdcmp 0.19374, oracc 0.98141, orien_loss 0.02885, chxlmicf1 0.53221, chxlmacf1 0.48272, chx_loss 0.85924, chxlacc 0.72208, chxlrocaucmic 0.80814, chxlrocaucmac 0.78971, qlmicf1 0.38762, qlmacf1 0.24258, ql_loss 0.78265, gacc 0.86000, gloss 0.34411, cxr14micf1 0.38167, cxr14macf1 0.36097, cxr14_loss 0.90107, vnbgmicf1 0.61740, vnbgmacf1 0.48088, vnbg_loss 0.61850, ema 0.73556, 269.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28996, wmdcmp 0.18406, oracc 0.98419, chxlmicf1 0.54208, chxlmacf1 0.48943, chxlacc 0.70487, chxlrocaucmic 0.78371, chxlrocaucmac 0.76397, qlmicf1 0.38979, qlmacf1 0.26553, ema 0.68364, 100.06 secs\n",
      "Adjusting learning rate of group 0 to 6.3206e-05.\n",
      "\u001b[1m---- Epoch 37/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000063) ...\n",
      "loss 4.20606, a_loss 0.86304, cD 1.48860, wmdcmp 0.19676, oracc 0.98391, orien_loss 0.02432, chxlmicf1 0.53560, chxlmacf1 0.48639, chx_loss 0.85494, chxlacc 0.72277, chxlrocaucmic 0.81043, chxlrocaucmac 0.79167, qlmicf1 0.39344, qlmacf1 0.24739, ql_loss 0.77436, gacc 0.86807, gloss 0.33217, cxr14micf1 0.38910, cxr14macf1 0.36845, cxr14_loss 0.90261, vnbgmicf1 0.61836, vnbgmacf1 0.48353, vnbg_loss 0.61620, ema 0.73921, 273.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38049, wmdcmp 0.19390, oracc 0.98419, chxlmicf1 0.54039, chxlmacf1 0.49033, chxlacc 0.70570, chxlrocaucmic 0.78351, chxlrocaucmac 0.76617, qlmicf1 0.39511, qlmacf1 0.26512, ema 0.71182, 98.22 secs\n",
      "Adjusting learning rate of group 0 to 5.9665e-05.\n",
      "\u001b[1m---- Epoch 38/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 4.27183, a_loss 0.86911, cD 1.47238, wmdcmp 0.19348, oracc 0.98176, orien_loss 0.02728, chxlmicf1 0.53146, chxlmacf1 0.48332, chx_loss 0.85941, chxlacc 0.72022, chxlrocaucmic 0.80722, chxlrocaucmac 0.78872, qlmicf1 0.38638, qlmacf1 0.23391, ql_loss 0.78032, gacc 0.85898, gloss 0.34461, cxr14micf1 0.38939, cxr14macf1 0.36950, cxr14_loss 0.89071, vnbgmicf1 0.61839, vnbgmacf1 0.47913, vnbg_loss 0.61441, ema 0.74019, 267.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35562, wmdcmp 0.18941, oracc 0.98419, chxlmicf1 0.54525, chxlmacf1 0.49427, chxlacc 0.70601, chxlrocaucmic 0.78371, chxlrocaucmac 0.76523, qlmicf1 0.39597, qlmacf1 0.26406, ema 0.71091, 100.83 secs\n",
      "Adjusting learning rate of group 0 to 5.6322e-05.\n",
      "\u001b[1m---- Epoch 39/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 4.14962, a_loss 0.86286, cD 1.47283, wmdcmp 0.19383, oracc 0.98428, orien_loss 0.02481, chxlmicf1 0.53520, chxlmacf1 0.48561, chx_loss 0.85642, chxlacc 0.72288, chxlrocaucmic 0.81067, chxlrocaucmac 0.79140, qlmicf1 0.38792, qlmacf1 0.23915, ql_loss 0.77817, gacc 0.85250, gloss 0.34778, cxr14micf1 0.39366, cxr14macf1 0.37085, cxr14_loss 0.88377, vnbgmicf1 0.61588, vnbgmacf1 0.48203, vnbg_loss 0.62275, ema 0.74468, 269.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38282, wmdcmp 0.19365, oracc 0.98419, chxlmicf1 0.54370, chxlmacf1 0.49129, chxlacc 0.70710, chxlrocaucmic 0.78337, chxlrocaucmac 0.76446, qlmicf1 0.39575, qlmacf1 0.26610, ema 0.70273, 100.15 secs\n",
      "Adjusting learning rate of group 0 to 5.3166e-05.\n",
      "\u001b[1m---- Epoch 40/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 4.29583, a_loss 0.85965, cD 1.49048, wmdcmp 0.19641, oracc 0.98425, orien_loss 0.02479, chxlmicf1 0.53589, chxlmacf1 0.48602, chx_loss 0.85519, chxlacc 0.72284, chxlrocaucmic 0.80994, chxlrocaucmac 0.79145, qlmicf1 0.39107, qlmacf1 0.25152, ql_loss 0.77857, gacc 0.85534, gloss 0.34843, cxr14micf1 0.39713, cxr14macf1 0.37371, cxr14_loss 0.87854, vnbgmicf1 0.61449, vnbgmacf1 0.47900, vnbg_loss 0.60634, ema 0.74134, 268.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27665, wmdcmp 0.18199, oracc 0.98419, chxlmicf1 0.54542, chxlmacf1 0.49268, chxlacc 0.70790, chxlrocaucmic 0.78431, chxlrocaucmac 0.76576, qlmicf1 0.39485, qlmacf1 0.26468, ema 0.70091, 102.16 secs\n",
      "Adjusting learning rate of group 0 to 5.0188e-05.\n",
      "\u001b[1m---- Epoch 41/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n",
      "loss 4.06116, a_loss 0.86388, cD 1.48743, wmdcmp 0.19601, oracc 0.98214, orien_loss 0.02701, chxlmicf1 0.53349, chxlmacf1 0.48444, chx_loss 0.85822, chxlacc 0.72129, chxlrocaucmic 0.80866, chxlrocaucmac 0.79011, qlmicf1 0.38910, qlmacf1 0.24719, ql_loss 0.77832, gacc 0.85784, gloss 0.34171, cxr14micf1 0.37822, cxr14macf1 0.36393, cxr14_loss 0.90008, vnbgmicf1 0.62529, vnbgmacf1 0.49563, vnbg_loss 0.60451, ema 0.73602, 267.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28984, wmdcmp 0.18437, oracc 0.98419, chxlmicf1 0.54093, chxlmacf1 0.48884, chxlacc 0.70291, chxlrocaucmic 0.78361, chxlrocaucmac 0.76405, qlmicf1 0.39148, qlmacf1 0.26182, ema 0.70909, 99.32 secs\n",
      "Adjusting learning rate of group 0 to 4.7376e-05.\n",
      "\u001b[1m---- Epoch 42/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 4.25458, a_loss 0.86405, cD 1.48298, wmdcmp 0.19599, oracc 0.98271, orien_loss 0.02644, chxlmicf1 0.53487, chxlmacf1 0.48551, chx_loss 0.85810, chxlacc 0.72294, chxlrocaucmic 0.80890, chxlrocaucmac 0.79015, qlmicf1 0.39066, qlmacf1 0.24175, ql_loss 0.77384, gacc 0.86932, gloss 0.33007, cxr14micf1 0.38389, cxr14macf1 0.36511, cxr14_loss 0.89466, vnbgmicf1 0.62073, vnbgmacf1 0.48556, vnbg_loss 0.60671, ema 0.74157, 265.58 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.35114, wmdcmp 0.18970, oracc 0.98419, chxlmicf1 0.54000, chxlmacf1 0.48920, chxlacc 0.70324, chxlrocaucmic 0.78324, chxlrocaucmac 0.76452, qlmicf1 0.39858, qlmacf1 0.26351, ema 0.70273, 99.47 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-05.\n",
      "\u001b[1m---- Epoch 43/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.09166, a_loss 0.85585, cD 1.47657, wmdcmp 0.19408, oracc 0.98231, orien_loss 0.02565, chxlmicf1 0.53684, chxlmacf1 0.48720, chx_loss 0.85387, chxlacc 0.72199, chxlrocaucmic 0.81029, chxlrocaucmac 0.79186, qlmicf1 0.39104, qlmacf1 0.24207, ql_loss 0.77538, gacc 0.86125, gloss 0.33854, cxr14micf1 0.38457, cxr14macf1 0.36678, cxr14_loss 0.89597, vnbgmicf1 0.61875, vnbgmacf1 0.48240, vnbg_loss 0.60718, ema 0.74324, 270.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36231, wmdcmp 0.19186, oracc 0.98419, chxlmicf1 0.54280, chxlmacf1 0.49021, chxlacc 0.70943, chxlrocaucmic 0.78235, chxlrocaucmac 0.76458, qlmicf1 0.39093, qlmacf1 0.26285, ema 0.71273, 100.15 secs\n",
      "Adjusting learning rate of group 0 to 4.2216e-05.\n",
      "\u001b[1m---- Epoch 44/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 4.13688, a_loss 0.85476, cD 1.49220, wmdcmp 0.19574, oracc 0.98358, orien_loss 0.02509, chxlmicf1 0.53358, chxlmacf1 0.48389, chx_loss 0.85680, chxlacc 0.72226, chxlrocaucmic 0.80919, chxlrocaucmac 0.79080, qlmicf1 0.38816, qlmacf1 0.25297, ql_loss 0.77760, gacc 0.85580, gloss 0.34319, cxr14micf1 0.38487, cxr14macf1 0.36734, cxr14_loss 0.88917, vnbgmicf1 0.62654, vnbgmacf1 0.49444, vnbg_loss 0.59957, ema 0.74310, 272.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35979, wmdcmp 0.19109, oracc 0.98419, chxlmicf1 0.54281, chxlmacf1 0.48947, chxlacc 0.70623, chxlrocaucmic 0.78474, chxlrocaucmac 0.76443, qlmicf1 0.39048, qlmacf1 0.26358, ema 0.70636, 101.82 secs\n",
      "Adjusting learning rate of group 0 to 3.9850e-05.\n",
      "\u001b[1m---- Epoch 45/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 4.11468, a_loss 0.85293, cD 1.52034, wmdcmp 0.19928, oracc 0.98223, orien_loss 0.02539, chxlmicf1 0.53580, chxlmacf1 0.48630, chx_loss 0.85391, chxlacc 0.72262, chxlrocaucmic 0.80975, chxlrocaucmac 0.79173, qlmicf1 0.38911, qlmacf1 0.24210, ql_loss 0.77790, gacc 0.86284, gloss 0.33608, cxr14micf1 0.38068, cxr14macf1 0.36420, cxr14_loss 0.88877, vnbgmicf1 0.61376, vnbgmacf1 0.47556, vnbg_loss 0.61186, ema 0.74023, 269.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37053, wmdcmp 0.19190, oracc 0.98419, chxlmicf1 0.54192, chxlmacf1 0.48974, chxlacc 0.70433, chxlrocaucmic 0.78481, chxlrocaucmac 0.76453, qlmicf1 0.39697, qlmacf1 0.26423, ema 0.69818, 100.23 secs\n",
      "Adjusting learning rate of group 0 to 3.7618e-05.\n",
      "\u001b[1m---- Epoch 46/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000038) ...\n",
      "loss 4.28635, a_loss 0.85545, cD 1.49291, wmdcmp 0.19551, oracc 0.98182, orien_loss 0.02505, chxlmicf1 0.53576, chxlmacf1 0.48630, chx_loss 0.85496, chxlacc 0.72260, chxlrocaucmic 0.81059, chxlrocaucmac 0.79241, qlmicf1 0.39132, qlmacf1 0.24369, ql_loss 0.77671, gacc 0.85909, gloss 0.34132, cxr14micf1 0.39418, cxr14macf1 0.37101, cxr14_loss 0.89054, vnbgmicf1 0.62007, vnbgmacf1 0.48783, vnbg_loss 0.59966, ema 0.74685, 268.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34141, wmdcmp 0.19024, oracc 0.98419, chxlmicf1 0.54165, chxlmacf1 0.48993, chxlacc 0.70377, chxlrocaucmic 0.78385, chxlrocaucmac 0.76501, qlmicf1 0.39291, qlmacf1 0.26536, ema 0.70545, 102.93 secs\n",
      "Adjusting learning rate of group 0 to 3.5510e-05.\n",
      "\u001b[1m---- Epoch 47/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 4.07185, a_loss 0.85344, cD 1.51849, wmdcmp 0.19816, oracc 0.98302, orien_loss 0.02839, chxlmicf1 0.53553, chxlmacf1 0.48574, chx_loss 0.85173, chxlacc 0.72279, chxlrocaucmic 0.81058, chxlrocaucmac 0.79289, qlmicf1 0.39086, qlmacf1 0.25076, ql_loss 0.77667, gacc 0.85955, gloss 0.33612, cxr14micf1 0.38781, cxr14macf1 0.36617, cxr14_loss 0.89436, vnbgmicf1 0.62411, vnbgmacf1 0.48832, vnbg_loss 0.60418, ema 0.74056, 165.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31689, wmdcmp 0.18702, oracc 0.98419, chxlmicf1 0.54385, chxlmacf1 0.49072, chxlacc 0.70837, chxlrocaucmic 0.78405, chxlrocaucmac 0.76440, qlmicf1 0.39319, qlmacf1 0.26536, ema 0.70364, 54.98 secs\n",
      "Adjusting learning rate of group 0 to 3.3521e-05.\n",
      "\u001b[1m---- Epoch 48/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.12089, a_loss 0.85423, cD 1.49354, wmdcmp 0.19740, oracc 0.98353, orien_loss 0.02663, chxlmicf1 0.53542, chxlmacf1 0.48628, chx_loss 0.85473, chxlacc 0.72245, chxlrocaucmic 0.81040, chxlrocaucmac 0.79229, qlmicf1 0.39083, qlmacf1 0.24502, ql_loss 0.77312, gacc 0.85773, gloss 0.34371, cxr14micf1 0.39362, cxr14macf1 0.37345, cxr14_loss 0.88887, vnbgmicf1 0.61913, vnbgmacf1 0.48678, vnbg_loss 0.60583, ema 0.74222, 143.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34001, wmdcmp 0.18972, oracc 0.98419, chxlmicf1 0.54258, chxlmacf1 0.49035, chxlacc 0.70800, chxlrocaucmic 0.78340, chxlrocaucmac 0.76415, qlmicf1 0.39969, qlmacf1 0.26731, ema 0.70455, 55.35 secs\n",
      "Adjusting learning rate of group 0 to 3.1643e-05.\n",
      "\u001b[1m---- Epoch 49/49\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 4.09730, a_loss 0.85440, cD 1.48418, wmdcmp 0.19518, oracc 0.98273, orien_loss 0.02776, chxlmicf1 0.53440, chxlmacf1 0.48471, chx_loss 0.85896, chxlacc 0.72254, chxlrocaucmic 0.80938, chxlrocaucmac 0.79127, qlmicf1 0.38973, qlmacf1 0.23591, ql_loss 0.77616, gacc 0.86318, gloss 0.33212, cxr14micf1 0.38307, cxr14macf1 0.36676, cxr14_loss 0.88758, vnbgmicf1 0.61785, vnbgmacf1 0.48243, vnbg_loss 0.60604, ema 0.74139, 173.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32608, wmdcmp 0.18919, oracc 0.98419, chxlmicf1 0.54202, chxlmacf1 0.49012, chxlacc 0.70378, chxlrocaucmic 0.78398, chxlrocaucmac 0.76488, qlmicf1 0.40123, qlmacf1 0.26503, ema 0.70727, 69.77 secs\n",
      "Adjusting learning rate of group 0 to 2.9870e-05.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221106_121711_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 30 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 80 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --num-workers 6 \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
