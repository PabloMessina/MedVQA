{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21105500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 2000\n",
      "   max_images_per_batch: 4\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 3.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino-maira-2\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp__no_grounding\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: False\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.5307, 0.5307, 0.5307], std = [0.2583, 0.2583, 0.2583], image_size = [416, 416]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.5307, 0.5307, 0.5307], std = [0.2583, 0.2583, 0.2583], image_size = [416, 416]\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (936863, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 147081.03it/s]\n",
      "Total number of images: 377110\n",
      "len(train_indices) = 368960\n",
      "len(test_indices) = 8150\n",
      "len(set(train_indices) & set(test_indices)) = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_facts_per_image = 508.2554423243712\n",
      "train_num_facts_per_image = 30\n",
      "avg_facts_per_image = 509.0689570552147\n",
      "test_num_facts_per_image = 30\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 4\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 92240\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 680\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 92240\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 680\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.99007, mimfg_phrcls_loss 1.99007, mimfg_prc_auc 0.07891, 418.38 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.86334, mimfg_prc_auc 0.26878, 333.05 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.3344, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.0789, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 0.4134, den = 2.0000, score = 0.2067\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.3492, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.2688, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 0.6180, den = 2.0000, score = 0.3090\u001b[0m\n",
      "\u001b[93mTrain score = 0.2067, Val score = 0.3090, Final score = 0.3039\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_mimfg_phrcls_loss+mimfg_prc_auc=0.3039.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.82817, mimfg_phrcls_loss 1.82817, mimfg_prc_auc 0.14965, 430.55 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.77792, mimfg_prc_auc 0.47197, 336.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_mimfg_phrcls_loss+mimfg_prc_auc=0.4078.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.61444, mimfg_phrcls_loss 1.61444, mimfg_prc_auc 0.46745, 421.11 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.53303, mimfg_prc_auc 0.58038, 338.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_mimfg_phrcls_loss+mimfg_prc_auc=0.4845.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.46559, mimfg_phrcls_loss 1.46559, mimfg_prc_auc 0.52992, 432.93 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.41997, mimfg_prc_auc 0.59675, 340.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_mimfg_phrcls_loss+mimfg_prc_auc=0.5031.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.35733, mimfg_phrcls_loss 1.35733, mimfg_prc_auc 0.59782, 432.48 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.37865, mimfg_prc_auc 0.63468, 318.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_mimfg_phrcls_loss+mimfg_prc_auc=0.5267.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.31316, mimfg_phrcls_loss 1.31316, mimfg_prc_auc 0.62267, 434.31 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.32805, mimfg_prc_auc 0.64374, 316.52 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_mimfg_phrcls_loss+mimfg_prc_auc=0.5362.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.30776, mimfg_phrcls_loss 1.30776, mimfg_prc_auc 0.63359, 436.51 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.35717, mimfg_prc_auc 0.65317, 299.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_mimfg_phrcls_loss+mimfg_prc_auc=0.5384.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.28584, mimfg_phrcls_loss 1.28584, mimfg_prc_auc 0.63765, 436.04 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.37712, mimfg_prc_auc 0.65470, 313.51 secs\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.29047, mimfg_phrcls_loss 1.29047, mimfg_prc_auc 0.64031, 430.91 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.32986, mimfg_prc_auc 0.65778, 313.58 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_mimfg_phrcls_loss+mimfg_prc_auc=0.5432.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.33044, mimfg_phrcls_loss 1.33044, mimfg_prc_auc 0.60866, 437.55 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.39823, mimfg_prc_auc 0.64470, 307.87 secs\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.27172, mimfg_phrcls_loss 1.27172, mimfg_prc_auc 0.64776, 438.82 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.29957, mimfg_prc_auc 0.66596, 343.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_mimfg_phrcls_loss+mimfg_prc_auc=0.5501.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.21529, mimfg_phrcls_loss 1.21529, mimfg_prc_auc 0.67616, 443.43 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.22863, mimfg_prc_auc 0.68703, 307.26 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_mimfg_phrcls_loss+mimfg_prc_auc=0.5677.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.22452, mimfg_phrcls_loss 1.22452, mimfg_prc_auc 0.67992, 447.21 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.23356, mimfg_prc_auc 0.69194, 341.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_mimfg_phrcls_loss+mimfg_prc_auc=0.5696.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.19504, mimfg_phrcls_loss 1.19504, mimfg_prc_auc 0.68876, 441.20 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.25347, mimfg_prc_auc 0.69284, 305.33 secs\n",
      "\u001b[1m---- Epoch 15/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.25587, mimfg_phrcls_loss 1.25587, mimfg_prc_auc 0.64702, 435.87 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.26677, mimfg_prc_auc 0.69034, 301.48 secs\n",
      "\u001b[1m---- Epoch 16/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.19066, mimfg_phrcls_loss 1.19066, mimfg_prc_auc 0.69000, 439.44 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.20642, mimfg_prc_auc 0.70795, 301.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_mimfg_phrcls_loss+mimfg_prc_auc=0.5802.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.14998, mimfg_phrcls_loss 1.14998, mimfg_prc_auc 0.71000, 439.18 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.15669, mimfg_prc_auc 0.71807, 298.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_mimfg_phrcls_loss+mimfg_prc_auc=0.5907.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.14782, mimfg_phrcls_loss 1.14782, mimfg_prc_auc 0.70793, 434.95 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.18915, mimfg_prc_auc 0.72251, 311.68 secs\n",
      "\u001b[1m---- Epoch 19/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.16166, mimfg_phrcls_loss 1.16166, mimfg_prc_auc 0.71451, 433.45 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.18113, mimfg_prc_auc 0.72255, 330.74 secs\n",
      "\u001b[1m---- Epoch 20/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.16148, mimfg_phrcls_loss 1.16148, mimfg_prc_auc 0.69303, 421.50 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.22194, mimfg_prc_auc 0.71596, 325.30 secs\n",
      "\u001b[1m---- Epoch 21/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.15606, mimfg_phrcls_loss 1.15606, mimfg_prc_auc 0.70965, 419.15 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.12964, mimfg_prc_auc 0.73169, 320.55 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_mimfg_phrcls_loss+mimfg_prc_auc=0.5999.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.11248, mimfg_phrcls_loss 1.11248, mimfg_prc_auc 0.72363, 430.43 secs\n",
      "(2) Validation stage ...\n",
      "loss 1.09551, mimfg_phrcls_loss 1.09551, mimfg_prc_auc 0.72866, 432.26 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.13588, mimfg_prc_auc 0.74005, 331.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_mimfg_phrcls_loss+mimfg_prc_auc=0.6041.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.09378, mimfg_phrcls_loss 1.09378, mimfg_prc_auc 0.73524, 430.26 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.14519, mimfg_prc_auc 0.74164, 328.05 secs\n",
      "\u001b[1m---- Epoch 25/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.15867, mimfg_phrcls_loss 1.15867, mimfg_prc_auc 0.69819, 430.20 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.18717, mimfg_prc_auc 0.73285, 325.13 secs\n",
      "\u001b[1m---- Epoch 26/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.08572, mimfg_phrcls_loss 1.08572, mimfg_prc_auc 0.73765, 418.03 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.15923, mimfg_prc_auc 0.74346, 325.72 secs\n",
      "\u001b[1m---- Epoch 27/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.05834, mimfg_phrcls_loss 1.05834, mimfg_prc_auc 0.74178, 429.84 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.18330, mimfg_prc_auc 0.75360, 322.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_mimfg_phrcls_loss+mimfg_prc_auc=0.6062.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.03788, mimfg_phrcls_loss 1.03788, mimfg_prc_auc 0.75490, 423.24 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.06125, mimfg_prc_auc 0.76103, 324.58 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_mimfg_phrcls_loss+mimfg_prc_auc=0.6231.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.05158, mimfg_phrcls_loss 1.05158, mimfg_prc_auc 0.75632, 429.86 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.09797, mimfg_prc_auc 0.76132, 323.50 secs\n",
      "\u001b[1m---- Epoch 30/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.10359, mimfg_phrcls_loss 1.10359, mimfg_prc_auc 0.71867, 429.28 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.16189, mimfg_prc_auc 0.74600, 321.20 secs\n",
      "\u001b[1m---- Epoch 31/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.05856, mimfg_phrcls_loss 1.05856, mimfg_prc_auc 0.74383, 427.78 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.11377, mimfg_prc_auc 0.76484, 321.21 secs\n",
      "\u001b[1m---- Epoch 32/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.01937, mimfg_phrcls_loss 1.01937, mimfg_prc_auc 0.76230, 417.24 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.10088, mimfg_prc_auc 0.76842, 318.07 secs\n",
      "\u001b[1m---- Epoch 33/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.01965, mimfg_phrcls_loss 1.01965, mimfg_prc_auc 0.76292, 424.32 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.07054, mimfg_prc_auc 0.77645, 319.90 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_mimfg_phrcls_loss+mimfg_prc_auc=0.6297.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.02425, mimfg_phrcls_loss 1.02425, mimfg_prc_auc 0.76408, 428.83 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04608, mimfg_prc_auc 0.77493, 314.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_34_mimfg_phrcls_loss+mimfg_prc_auc=0.6317.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 35/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.06391, mimfg_phrcls_loss 1.06391, mimfg_prc_auc 0.73370, 423.68 secs\n",
      "(2) Validation stage ...\n",
      "^C iteration 275\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--epochs 80 \\\n",
    "--batches_per_epoch 2000 \\\n",
    "--max_images_per_batch 4 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 3 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino-maira-2\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp__no_grounding\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b7fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 3000\n",
      "   max_images_per_batch: 4\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 3.0\n",
      "   checkpoint_folder: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino-maira-2\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp__no_grounding\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: False\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.5307, 0.5307, 0.5307], std = [0.2583, 0.2583, 0.2583], image_size = [416, 416]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.5307, 0.5307, 0.5307], std = [0.2583, 0.2583, 0.2583], image_size = [416, 416]\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (936863, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 147482.40it/s]\n",
      "Total number of images: 377110\n",
      "len(train_indices) = 368960\n",
      "len(test_indices) = 8150\n",
      "len(set(train_indices) & set(test_indices)) = 0\n",
      "avg_facts_per_image = 508.2554423243712\n",
      "train_num_facts_per_image = 30\n",
      "avg_facts_per_image = 509.0689570552147\n",
      "test_num_facts_per_image = 30\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 4\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 92240\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 680\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 92240\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 680\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_34_mimfg_phrcls_loss+mimfg_prc_auc=0.6317.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/checkpoint_34_mimfg_phrcls_loss+mimfg_prc_auc=0.6317.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 35/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.06891, mimfg_phrcls_loss 1.06891, mimfg_prc_auc 0.73640, 642.10 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.03453, mimfg_prc_auc 0.76220, 312.66 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.4833, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.7364, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.2197, den = 2.0000, score = 0.6099\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.4915, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.7622, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.2537, den = 2.0000, score = 0.6269\u001b[0m\n",
      "\u001b[93mTrain score = 0.6099, Val score = 0.6269, Final score = 0.6260\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_35_mimfg_phrcls_loss+mimfg_prc_auc=0.6260.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 36/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.00740, mimfg_phrcls_loss 1.00740, mimfg_prc_auc 0.76807, 645.02 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.09427, mimfg_prc_auc 0.77850, 313.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_36_mimfg_phrcls_loss+mimfg_prc_auc=0.6283.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 37/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.98410, mimfg_phrcls_loss 0.98410, mimfg_prc_auc 0.78094, 643.86 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.05937, mimfg_prc_auc 0.78413, 320.48 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_37_mimfg_phrcls_loss+mimfg_prc_auc=0.6352.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 38/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.99045, mimfg_phrcls_loss 0.99045, mimfg_prc_auc 0.77717, 643.36 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.00661, mimfg_prc_auc 0.78958, 320.06 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_38_mimfg_phrcls_loss+mimfg_prc_auc=0.6438.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 39/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.96420, mimfg_phrcls_loss 0.96420, mimfg_prc_auc 0.78253, 645.79 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.02882, mimfg_prc_auc 0.79072, 324.17 secs\n",
      "\u001b[1m---- Epoch 40/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.02869, mimfg_phrcls_loss 1.02869, mimfg_prc_auc 0.75296, 633.19 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04480, mimfg_prc_auc 0.77014, 322.86 secs\n",
      "\u001b[1m---- Epoch 41/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.97232, mimfg_phrcls_loss 0.97232, mimfg_prc_auc 0.77670, 643.57 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.01466, mimfg_prc_auc 0.78305, 323.85 secs\n",
      "\u001b[1m---- Epoch 42/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.94412, mimfg_phrcls_loss 0.94412, mimfg_prc_auc 0.78733, 619.88 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.01235, mimfg_prc_auc 0.79731, 319.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_mimfg_phrcls_loss+mimfg_prc_auc=0.6473.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.94609, mimfg_phrcls_loss 0.94609, mimfg_prc_auc 0.79119, 646.05 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.98976, mimfg_prc_auc 0.79898, 322.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_43_mimfg_phrcls_loss+mimfg_prc_auc=0.6509.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 44/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.94013, mimfg_phrcls_loss 0.94013, mimfg_prc_auc 0.79325, 645.74 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.98189, mimfg_prc_auc 0.80197, 320.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_44_mimfg_phrcls_loss+mimfg_prc_auc=0.6533.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 45/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.98488, mimfg_phrcls_loss 0.98488, mimfg_prc_auc 0.76741, 642.70 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04422, mimfg_prc_auc 0.78973, 320.33 secs\n",
      "\u001b[1m---- Epoch 46/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.96063, mimfg_phrcls_loss 0.96063, mimfg_prc_auc 0.78329, 644.05 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04856, mimfg_prc_auc 0.79108, 317.76 secs\n",
      "\u001b[1m---- Epoch 47/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.93467, mimfg_phrcls_loss 0.93467, mimfg_prc_auc 0.79279, 628.51 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.97976, mimfg_prc_auc 0.80742, 318.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_47_mimfg_phrcls_loss+mimfg_prc_auc=0.6562.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 48/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.92143, mimfg_phrcls_loss 0.92143, mimfg_prc_auc 0.79698, 646.13 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.96322, mimfg_prc_auc 0.80812, 320.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_48_mimfg_phrcls_loss+mimfg_prc_auc=0.6587.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 49/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.91559, mimfg_phrcls_loss 0.91559, mimfg_prc_auc 0.80370, 646.63 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.96307, mimfg_prc_auc 0.81028, 326.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_49_mimfg_phrcls_loss+mimfg_prc_auc=0.6600.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 50/74\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "   iteration 47725\r"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)\" \\\n",
    "--epochs 40 \\\n",
    "--batches_per_epoch 3000 \\\n",
    "--max_images_per_batch 4 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 3 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino-maira-2\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp__no_grounding\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_rel_facts=404064,num_clusters=100,max_neg=500,skip_nli)(hash=980,2800495312613355816).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
