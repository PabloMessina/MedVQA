{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4137853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 2000\n",
      "   max_images_per_batch: 10\n",
      "   max_phrases_per_batch: 400\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 5.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: True\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: film_layers_plus_sigmoid_attention_and_custom_classifier\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: 256\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,5,5e-6,2e-4,5,5e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 2.0\n",
      "   phrase_classifier_loss_weight: 2.0\n",
      "   foreground_loss_weight: 1.5\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: True\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\n",
      "   chexpert_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.5\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 4.0\n",
      "   vinbig_weight: 1.5\n",
      "   chexlocalize_weight: 0.4\n",
      "   chexpert_weight: 0.5\n",
      "   iuxray_weight: 0.5\n",
      "   img_aug_mode: random-color\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: True\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: True\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: True\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: True\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: True\n",
      "   use_cxrlt2024_custom_labels: True\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   vinbig_training_data_mode: all\n",
      "   chexpert_training_data_mode: all\n",
      "   mask_exponent: 0.4\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,5,5e-6,2e-4,5,5e-6\n",
      "1e-06 3 0.0002 5 5e-06 0.0002 5 5e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.5\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating CheXLocalize Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loding class_phrase_embeddings_filepath and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl...\n",
      "class_phrase_embeddings.shape = (10, 128)\n",
      "len(class_phrases) = 10\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t airspace opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t support devices seen\n",
      "Compute phrase grounding masks and labels\n",
      "Without masks: 216/902\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 902\n",
      "batch_size = 10\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating CheXpert Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train_visualCheXbert.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_train_visualchexbert) = 223414\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/valid.csv\n",
      "len(df_valid) = 234\n",
      "len(df) = 223648\n",
      "Loading images\n",
      "Loading chexpert labels\n",
      "Loading test set\n",
      "len(self.test_image_paths) = 668\n",
      "self.test_labels.shape = (668, 14)\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl...\n",
      "phrase_embeddings.shape = (14, 128)\n",
      "len(phrases) = 14\n",
      "\t no findings\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t lung opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t pneumonia seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t other pleural abnormality seen\n",
      "\t fracture seen\n",
      "\t support devices seen\n",
      "len(all_image_paths) = 224316\n",
      "all_labels.shape = (224316, 14)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 224316\n",
      "No labels: 3246\n",
      "Pneumothorax: 25357\n",
      "Pleural Other: 26334\n",
      "Lung Lesion: 31042\n",
      "No Finding: 35673\n",
      "Pneumonia: 52248\n",
      "Fracture: 61696\n",
      "Edema: 94500\n",
      "Pleural Effusion: 103837\n",
      "Consolidation: 107297\n",
      "Cardiomegaly: 122164\n",
      "Atelectasis: 124182\n",
      "Support Devices: 136382\n",
      "Enlarged Cardiomediastinum: 144377\n",
      "Lung Opacity: 151937\n",
      "Group sizes: [61397, 30579, 25357, 21626, 18526, 17225, 11525, 11092, 10885, 7083, 4085, 3246, 1170, 347, 173]\n",
      "  len(indices) = 61397, weight = 4024.1406302660666\n",
      "  len(indices) = 30579, weight = 3308.1179132413095\n",
      "  len(indices) = 25357, weight = 3131.4217784165476\n",
      "  len(indices) = 21626, weight = 2986.2821261955132\n",
      "  len(indices) = 18526, weight = 2849.5564265118087\n",
      "  len(indices) = 17225, weight = 2786.68263628706\n",
      "  len(indices) = 11525, weight = 2456.265254834705\n",
      "  len(indices) = 11092, weight = 2426.215857884437\n",
      "  len(indices) = 10885, weight = 2411.5238383991996\n",
      "  len(indices) = 7083, weight = 2092.3117139635237\n",
      "  len(indices) = 4085, weight = 1726.3245386288693\n",
      "  len(indices) = 3246, weight = 1587.0568876515586\n",
      "  len(indices) = 1170, weight = 1058.8042504564921\n",
      "  len(indices) = 347, weight = 600.9534388852762\n",
      "  len(indices) = 173, weight = 410.9393870934724\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n",
      "self.phrase_grounding_masks.shape = (18000, 22, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 18000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 29\n",
      "Lung cyst: 35\n",
      "COPD: 37\n",
      "Lung cavity: 60\n",
      "Emphysema: 84\n",
      "Rib fracture: 101\n",
      "Pneumothorax: 114\n",
      "Enlarged PA: 139\n",
      "Mediastinal shift: 170\n",
      "Atelectasis: 273\n",
      "Lung tumor: 371\n",
      "Consolidation: 449\n",
      "ILD: 618\n",
      "Calcification: 652\n",
      "Infiltration: 671\n",
      "Tuberculosis: 914\n",
      "Nodule/Mass: 1017\n",
      "Pleural effusion: 1149\n",
      "Pneumonia: 1163\n",
      "Other lesion: 1248\n",
      "Lung Opacity: 1415\n",
      "Pulmonary fibrosis: 1838\n",
      "Pleural thickening: 2179\n",
      "Cardiomegaly: 2625\n",
      "Aortic enlargement: 3318\n",
      "Other disease: 4945\n",
      "No finding: 12652\n",
      "Group sizes: [12529, 891, 444, 428, 364, 344, 307, 283, 273, 267, 245, 236, 206, 193, 170, 138, 127, 100, 99, 90, 56, 54, 49, 34, 73]\n",
      "  len(indices) = 12529, weight = 2522.6672479595745\n",
      "  len(indices) = 891, weight = 940.9850359649141\n",
      "  len(indices) = 444, weight = 680.1755171156125\n",
      "  len(indices) = 428, weight = 667.9638591411331\n",
      "  len(indices) = 364, weight = 615.8160380252455\n",
      "  len(indices) = 344, weight = 598.2811252947056\n",
      "  len(indices) = 307, weight = 563.9888635691133\n",
      "  len(indices) = 283, weight = 540.2796339164162\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 267, weight = 523.7422583945496\n",
      "  len(indices) = 245, weight = 499.93058392418243\n",
      "  len(indices) = 236, weight = 489.7963928535281\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 193, weight = 437.6702522239849\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 138, weight = 359.20170201154343\n",
      "  len(indices) = 127, weight = 341.33933626931963\n",
      "  len(indices) = 100, weight = 293.26529386579296\n",
      "  len(indices) = 99, weight = 291.34941227248714\n",
      "  len(indices) = 90, weight = 273.5936736738282\n",
      "  len(indices) = 56, weight = 195.85520038280242\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 34, weight = 131.67512839151652\n",
      "  len(indices) = 73, weight = 237.15649291307946\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "mask_exponent = 0.4\n",
      "len(cxrlt2024_train_dicom_ids) = 258871\n",
      "len(cxrlt2024_dev_dicom_ids) = 39293\n",
      "len(forbidden_train_dicom_ids) = 40220\n",
      "\u001b[1m\u001b[35mPreparing CXR-LT-2024 challenge datasets and dataloaders for training/testing...\u001b[0m\n",
      "Using image size mode: medium_512\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"train\"]) = 128427\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"dev\"]) = 13136\n",
      "Total number of images: 141230\n",
      "\u001b[1mBuilding cxrlt2024 train phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 85554\n",
      "num_phrases = 2, len(indices) = 30817\n",
      "num_phrases = 3, len(indices) = 8659\n",
      "num_phrases = 4, len(indices) = 2127\n",
      "num_phrases = 8, len(indices) = 104\n",
      "num_phrases = 5, len(indices) = 567\n",
      "num_phrases = 14, len(indices) = 97\n",
      "num_phrases = 6, len(indices) = 116\n",
      "num_phrases = 10, len(indices) = 45\n",
      "num_phrases = 7, len(indices) = 8\n",
      "\u001b[1mBuilding cxrlt2024 dev phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 10269\n",
      "num_phrases = 2, len(indices) = 2268\n",
      "num_phrases = 3, len(indices) = 404\n",
      "num_phrases = 8, len(indices) = 28\n",
      "num_phrases = 14, len(indices) = 54\n",
      "num_phrases = 4, len(indices) = 80\n",
      "num_phrases = 10, len(indices) = 12\n",
      "num_phrases = 5, len(indices) = 21\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596394, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 176994.34it/s]\n",
      "Total number of images: 258164\n",
      "len(train_indices) = 258164\n",
      "avg_facts_per_image = 81.27329914318031\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 8\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 32271\n",
      "\u001b[1m\u001b[35mPreparing Chest Imagenome dataset and dataloader for training...\u001b[0m\n",
      "Loding bbox_phrase_embeddings and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox_phrase_embeddings.shape = (36, 128)\n",
      "len(bbox_phrases) = 36\n",
      "\t right lung\n",
      "\t right upper lung zone\n",
      "\t right mid lung zone\n",
      "\t right lower lung zone\n",
      "\t right hilar structures\n",
      "\t right apical zone\n",
      "\t right costophrenic angle\n",
      "\t right cardiophrenic angle\n",
      "\t right hemidiaphragm\n",
      "\t left lung\n",
      "\t left upper lung zone\n",
      "\t left mid lung zone\n",
      "\t left lower lung zone\n",
      "\t left hilar structures\n",
      "\t left apical zone\n",
      "\t left costophrenic angle\n",
      "\t left hemidiaphragm\n",
      "\t trachea\n",
      "\t spine\n",
      "\t right clavicle\n",
      "\t left clavicle\n",
      "\t aortic arch\n",
      "\t mediastinum\n",
      "\t upper mediastinum\n",
      "\t svc\n",
      "\t cardiac silhouette\n",
      "\t left cardiac silhouette\n",
      "\t right cardiac silhouette\n",
      "\t cavoatrial junction\n",
      "\t right atrium\n",
      "\t descending aorta\n",
      "\t carina\n",
      "\t left upper abdomen\n",
      "\t right upper abdomen\n",
      "\t abdomen\n",
      "\t left cardiophrenic angle\n",
      "Using image size mode: medium_512\n",
      "\u001b[1mLoading precomputed bbox_coords_and_presence_and_mask from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/bbox_coords_and_presence_and_mask(29,29,243310).pkl...\u001b[0m\n",
      "227835it [01:35, 2375.90it/s]\n",
      "Total number of images: 165768\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mCreating IU X-Ray Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[1mPreparing data for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (2331, 128)\n",
      "Number of invalid images removed: 111\n",
      "avg_facts_per_image = 2327.3329256692487\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train dataloader...\u001b[0m\n",
      "len(self.train_dataloader) = 920\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 32271\n",
      "len(mimiccxr_trainer.train_chest_imagenome_dataloader) = 16577\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_train_dataloader) = 12813\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_dev_dataloader) = 268\n",
      "len(vinbig_trainer.train_dataloader) = 100000000000000000\n",
      "len(chexlocalize_trainer.train_dataloader) = 91\n",
      "len(chexpert_trainer.train_dataloader) = 100000000000000000\n",
      "len(iuxray_trainer.train_dataloader) = 920\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.5, 1.0, 4.0, 1.5, 0.4, 0.5, 0.5]\n",
      "merged_dataset_name = mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m16) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m17) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.00543, mimfg_att_reg_loss 0.48795, mimfg_phrcls_loss 1.56464, mimfg_prc_auc 0.52532, cibg_att_sup_loss 2.24172, cibg_segmask_iou 0.08027, vbg_phrcls_loss 3.53367, vbg_prc_auc 0.15031, vbg_att_reg_loss 0.48953, vbg_att_sup_loss 2.09886, vbg_segmask_iou 0.04462, cl_att_sup_loss 2.51247, cl_segmask_iou 0.11479, cl_phrcls_loss 3.49181, cl_phrase_acc 0.38250, chxp_att_reg_loss 0.48643, chxp_phrcls_loss 3.56868, chxp_prc_auc 0.36770, iufg_att_reg_loss 0.48812, iufg_phrcls_loss 1.68734, iufg_prc_auc 0.04707, cxrlt2024c_att_reg_loss 0.48781, cxrlt2024c_phrcls_loss 1.58804, cxrlt2024c_prc_auc 0.43178, 582.35 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.48494, cxrlt2024c_phrcls_loss 0.77839, cxrlt2024c_prc_auc 0.46413, 330.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.5455.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.84987, mimfg_att_reg_loss 0.47480, mimfg_phrcls_loss 1.55679, mimfg_prc_auc 0.52051, cibg_att_sup_loss 2.24512, cibg_segmask_iou 0.07975, vbg_phrcls_loss 3.09515, vbg_prc_auc 0.14988, vbg_att_reg_loss 0.47507, vbg_att_sup_loss 2.08731, vbg_segmask_iou 0.04409, cl_att_sup_loss 2.52216, cl_segmask_iou 0.11301, cl_phrcls_loss 3.19695, cl_phrase_acc 0.75857, chxp_att_reg_loss 0.47275, chxp_phrcls_loss 3.47197, chxp_prc_auc 0.36019, iufg_att_reg_loss 0.47539, iufg_phrcls_loss 1.25009, iufg_prc_auc 0.04299, cxrlt2024c_att_reg_loss 0.47384, cxrlt2024c_phrcls_loss 1.50192, cxrlt2024c_prc_auc 0.41749, 588.29 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.46014, cxrlt2024c_phrcls_loss 0.78170, cxrlt2024c_prc_auc 0.46287, 335.30 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.5506.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 2.70203, mimfg_att_reg_loss 0.39860, mimfg_phrcls_loss 1.57120, mimfg_prc_auc 0.71483, cibg_att_sup_loss 2.20733, cibg_segmask_iou 0.08092, vbg_phrcls_loss 2.82051, vbg_prc_auc 0.14684, vbg_att_reg_loss 0.40139, vbg_att_sup_loss 1.97054, vbg_segmask_iou 0.04992, cl_att_sup_loss 2.50545, cl_segmask_iou 0.11683, cl_phrcls_loss 3.02886, cl_phrase_acc 0.75822, chxp_att_reg_loss 0.40656, chxp_phrcls_loss 3.52342, chxp_prc_auc 0.37387, iufg_att_reg_loss 0.40734, iufg_phrcls_loss 0.95209, iufg_prc_auc 0.06973, cxrlt2024c_att_reg_loss 0.41477, cxrlt2024c_phrcls_loss 1.49219, cxrlt2024c_prc_auc 0.42096, 585.76 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.30580, cxrlt2024c_phrcls_loss 0.77156, cxrlt2024c_prc_auc 0.51963, 335.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.5951.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.15262, mimfg_att_reg_loss 0.27346, mimfg_phrcls_loss 1.27648, mimfg_prc_auc 0.81070, cibg_att_sup_loss 1.45073, cibg_segmask_iou 0.14390, vbg_phrcls_loss 2.43200, vbg_prc_auc 0.24196, vbg_att_reg_loss 0.22715, vbg_att_sup_loss 1.32189, vbg_segmask_iou 0.10816, cl_att_sup_loss 1.23491, cl_segmask_iou 0.29225, cl_phrcls_loss 2.63105, cl_phrase_acc 0.77506, chxp_att_reg_loss 0.38539, chxp_phrcls_loss 3.17143, chxp_prc_auc 0.52759, iufg_att_reg_loss 0.34038, iufg_phrcls_loss 0.67135, iufg_prc_auc 0.15275, cxrlt2024c_att_reg_loss 0.34654, cxrlt2024c_phrcls_loss 1.32324, cxrlt2024c_prc_auc 0.51944, 590.24 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16559, cxrlt2024c_phrcls_loss 0.67095, cxrlt2024c_prc_auc 0.62819, 333.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6732.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000096) ...\n",
      "loss 1.89736, mimfg_att_reg_loss 0.24171, mimfg_phrcls_loss 1.16463, mimfg_prc_auc 0.85565, cibg_att_sup_loss 1.08939, cibg_segmask_iou 0.20584, vbg_phrcls_loss 2.20792, vbg_prc_auc 0.30941, vbg_att_reg_loss 0.17817, vbg_att_sup_loss 1.12906, vbg_segmask_iou 0.14185, cl_att_sup_loss 0.83723, cl_segmask_iou 0.31471, cl_phrcls_loss 2.38749, cl_phrase_acc 0.81350, chxp_att_reg_loss 0.36367, chxp_phrcls_loss 2.91704, chxp_prc_auc 0.59956, iufg_att_reg_loss 0.30761, iufg_phrcls_loss 0.49811, iufg_prc_auc 0.20445, cxrlt2024c_att_reg_loss 0.29742, cxrlt2024c_phrcls_loss 1.21696, cxrlt2024c_prc_auc 0.57636, 587.76 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16207, cxrlt2024c_phrcls_loss 0.62870, cxrlt2024c_prc_auc 0.64600, 337.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6883.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 1.83195, mimfg_att_reg_loss 0.23276, mimfg_phrcls_loss 1.10726, mimfg_prc_auc 0.87418, cibg_att_sup_loss 1.01975, cibg_segmask_iou 0.22181, vbg_phrcls_loss 2.13767, vbg_prc_auc 0.34062, vbg_att_reg_loss 0.17163, vbg_att_sup_loss 1.11849, vbg_segmask_iou 0.14573, cl_att_sup_loss 0.77529, cl_segmask_iou 0.31955, cl_phrcls_loss 2.26795, cl_phrase_acc 0.83266, chxp_att_reg_loss 0.36185, chxp_phrcls_loss 2.88043, chxp_prc_auc 0.61459, iufg_att_reg_loss 0.31109, iufg_phrcls_loss 0.48756, iufg_prc_auc 0.21042, cxrlt2024c_att_reg_loss 0.28828, cxrlt2024c_phrcls_loss 1.17137, cxrlt2024c_prc_auc 0.59241, 590.04 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16361, cxrlt2024c_phrcls_loss 0.61878, cxrlt2024c_prc_auc 0.65135, 332.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6917.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.80906, mimfg_att_reg_loss 0.23905, mimfg_phrcls_loss 1.11060, mimfg_prc_auc 0.87154, cibg_att_sup_loss 1.00366, cibg_segmask_iou 0.22571, vbg_phrcls_loss 2.10596, vbg_prc_auc 0.34692, vbg_att_reg_loss 0.16721, vbg_att_sup_loss 1.08634, vbg_segmask_iou 0.14903, cl_att_sup_loss 0.76751, cl_segmask_iou 0.31701, cl_phrcls_loss 2.24985, cl_phrase_acc 0.83349, chxp_att_reg_loss 0.35991, chxp_phrcls_loss 2.86178, chxp_prc_auc 0.61111, iufg_att_reg_loss 0.30722, iufg_phrcls_loss 0.46638, iufg_prc_auc 0.23096, cxrlt2024c_att_reg_loss 0.28657, cxrlt2024c_phrcls_loss 1.15127, cxrlt2024c_prc_auc 0.59774, 588.50 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15964, cxrlt2024c_phrcls_loss 0.61913, cxrlt2024c_prc_auc 0.65568, 337.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6942.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.80796, mimfg_att_reg_loss 0.23476, mimfg_phrcls_loss 1.10035, mimfg_prc_auc 0.87446, cibg_att_sup_loss 1.00062, cibg_segmask_iou 0.22672, vbg_phrcls_loss 2.11144, vbg_prc_auc 0.34522, vbg_att_reg_loss 0.17021, vbg_att_sup_loss 1.09959, vbg_segmask_iou 0.15008, cl_att_sup_loss 0.77895, cl_segmask_iou 0.31889, cl_phrcls_loss 2.19581, cl_phrase_acc 0.83697, chxp_att_reg_loss 0.35486, chxp_phrcls_loss 2.84096, chxp_prc_auc 0.63427, iufg_att_reg_loss 0.30881, iufg_phrcls_loss 0.45841, iufg_prc_auc 0.24299, cxrlt2024c_att_reg_loss 0.28736, cxrlt2024c_phrcls_loss 1.15395, cxrlt2024c_prc_auc 0.60457, 588.83 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16007, cxrlt2024c_phrcls_loss 0.61994, cxrlt2024c_prc_auc 0.65592, 334.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6943.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.80209, mimfg_att_reg_loss 0.23307, mimfg_phrcls_loss 1.09096, mimfg_prc_auc 0.87799, cibg_att_sup_loss 0.99780, cibg_segmask_iou 0.22859, vbg_phrcls_loss 2.08781, vbg_prc_auc 0.35263, vbg_att_reg_loss 0.16724, vbg_att_sup_loss 1.09850, vbg_segmask_iou 0.14838, cl_att_sup_loss 0.75881, cl_segmask_iou 0.31712, cl_phrcls_loss 2.21386, cl_phrase_acc 0.83872, chxp_att_reg_loss 0.35649, chxp_phrcls_loss 2.81609, chxp_prc_auc 0.63021, iufg_att_reg_loss 0.30233, iufg_phrcls_loss 0.45464, iufg_prc_auc 0.24137, cxrlt2024c_att_reg_loss 0.29013, cxrlt2024c_phrcls_loss 1.15973, cxrlt2024c_prc_auc 0.61325, 590.79 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15971, cxrlt2024c_phrcls_loss 0.61629, cxrlt2024c_prc_auc 0.65633, 333.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6951.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.78431, mimfg_att_reg_loss 0.23221, mimfg_phrcls_loss 1.08416, mimfg_prc_auc 0.87703, cibg_att_sup_loss 0.95191, cibg_segmask_iou 0.23890, vbg_phrcls_loss 2.10543, vbg_prc_auc 0.34518, vbg_att_reg_loss 0.16800, vbg_att_sup_loss 1.08483, vbg_segmask_iou 0.15321, cl_att_sup_loss 0.74689, cl_segmask_iou 0.33042, cl_phrcls_loss 2.20165, cl_phrase_acc 0.84601, chxp_att_reg_loss 0.35045, chxp_phrcls_loss 2.84311, chxp_prc_auc 0.61299, iufg_att_reg_loss 0.30026, iufg_phrcls_loss 0.44937, iufg_prc_auc 0.24131, cxrlt2024c_att_reg_loss 0.28847, cxrlt2024c_phrcls_loss 1.13241, cxrlt2024c_prc_auc 0.60208, 586.53 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15173, cxrlt2024c_phrcls_loss 0.61506, cxrlt2024c_prc_auc 0.67097, 335.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7016.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 20950\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1416, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1283, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 830, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 135, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 819, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 258, in step_fn__mimiccxr_fact_grounding\n",
      "    return _step_fn__fact_grounding(batch, mimiccxr_phrase_classifier_criterion, use_weighted_phrase_classifier_loss)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 95, in _step_fn__fact_grounding\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/phrase_grounding/phrase_grounder.py\", line 215, in forward\n",
      "    output = super().forward(\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 819, in forward\n",
      "    tmp = self.raw_image_encoder(raw_images)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 633, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 452, in forward\n",
      "    layer_outputs = layer_module(hidden_states, layer_head_mask, output_attentions)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 408, in forward\n",
      "    layer_output = self.mlp(layer_output)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 347, in forward\n",
      "    hidden_state = self.fc2(hidden_state)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 2000 \\\n",
    "--max_images_per_batch 10 \\\n",
    "--max_phrases_per_batch 400 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 5.0 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino\" \\\n",
    "--img_aug_mode \"random-color\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--freeze_image_encoder \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"film_layers_plus_sigmoid_attention_and_custom_classifier\" \\\n",
    "--visual_feature_proj_size 256 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,5,5e-6,2e-4,5,5e-6\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce\" \\\n",
    "--use_attention_regularization_loss \\\n",
    "--attention_supervision_loss_weight 2.0 \\\n",
    "--phrase_classifier_loss_weight 2.0 \\\n",
    "--foreground_loss_weight 1.5 \\\n",
    "--mask_exponent 0.4 \\\n",
    "--use_cxrlt2024_challenge_split \\\n",
    "--use_cxrlt2024_custom_labels \\\n",
    "--cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--mimiccxr_report_fact_nli_integrated_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--use_chest_imagenome_for_train \\\n",
    "--chest_imagenome_bbox_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\" \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--use_vinbig_for_train \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\" \\\n",
    "--vinbig_training_data_mode \"all\" \\\n",
    "--use_chexlocalize_for_train \\\n",
    "--chexlocalize_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\" \\\n",
    "--use_chexpert_for_train \\\n",
    "--chexpert_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\" \\\n",
    "--use_iuxray_for_train \\\n",
    "--iuxray_image_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\" \\\n",
    "--cxrlt2024_weight 4.0 \\\n",
    "--mimiccxr_facts_weight 1.5 \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--iuxray_weight 0.5 \\\n",
    "--vinbig_weight 1.5 \\\n",
    "--chexpert_weight 0.5 \\\n",
    "--chexlocalize_weight 0.4 \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dccd4d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 2000\n",
      "   max_images_per_batch: 10\n",
      "   max_phrases_per_batch: 400\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 5.0\n",
      "   checkpoint_folder: models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: True\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: film_layers_plus_sigmoid_attention_and_custom_classifier\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: 256\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,2e-4,5,5e-6,2e-4,5,5e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 2.0\n",
      "   phrase_classifier_loss_weight: 2.0\n",
      "   foreground_loss_weight: 1.5\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: True\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\n",
      "   chexpert_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.5\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 4.0\n",
      "   vinbig_weight: 1.5\n",
      "   chexlocalize_weight: 0.4\n",
      "   chexpert_weight: 0.5\n",
      "   iuxray_weight: 0.5\n",
      "   img_aug_mode: random-color\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: True\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: True\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: True\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: True\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: True\n",
      "   use_cxrlt2024_custom_labels: True\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   vinbig_training_data_mode: all\n",
      "   chexpert_training_data_mode: all\n",
      "   mask_exponent: 0.4\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,2e-4,5,5e-6,2e-4,5,5e-6\n",
      "1e-06 3 0.0002 5 5e-06 0.0002 5 5e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.5\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating CheXLocalize Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loding class_phrase_embeddings_filepath and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl...\n",
      "class_phrase_embeddings.shape = (10, 128)\n",
      "len(class_phrases) = 10\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t airspace opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t support devices seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without masks: 216/902\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 902\n",
      "batch_size = 10\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating CheXpert Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train_visualCheXbert.csv\n",
      "len(df_train_visualchexbert) = 223414\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/valid.csv\n",
      "len(df_valid) = 234\n",
      "len(df) = 223648\n",
      "Loading images\n",
      "Loading chexpert labels\n",
      "Loading test set\n",
      "len(self.test_image_paths) = 668\n",
      "self.test_labels.shape = (668, 14)\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl...\n",
      "phrase_embeddings.shape = (14, 128)\n",
      "len(phrases) = 14\n",
      "\t no findings\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t lung opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t pneumonia seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t other pleural abnormality seen\n",
      "\t fracture seen\n",
      "\t support devices seen\n",
      "len(all_image_paths) = 224316\n",
      "all_labels.shape = (224316, 14)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 224316\n",
      "No labels: 3246\n",
      "Pneumothorax: 25357\n",
      "Pleural Other: 26334\n",
      "Lung Lesion: 31042\n",
      "No Finding: 35673\n",
      "Pneumonia: 52248\n",
      "Fracture: 61696\n",
      "Edema: 94500\n",
      "Pleural Effusion: 103837\n",
      "Consolidation: 107297\n",
      "Cardiomegaly: 122164\n",
      "Atelectasis: 124182\n",
      "Support Devices: 136382\n",
      "Enlarged Cardiomediastinum: 144377\n",
      "Lung Opacity: 151937\n",
      "Group sizes: [61397, 30579, 25357, 21626, 18526, 17225, 11525, 11092, 10885, 7083, 4085, 3246, 1170, 347, 173]\n",
      "  len(indices) = 61397, weight = 4024.1406302660666\n",
      "  len(indices) = 30579, weight = 3308.1179132413095\n",
      "  len(indices) = 25357, weight = 3131.4217784165476\n",
      "  len(indices) = 21626, weight = 2986.2821261955132\n",
      "  len(indices) = 18526, weight = 2849.5564265118087\n",
      "  len(indices) = 17225, weight = 2786.68263628706\n",
      "  len(indices) = 11525, weight = 2456.265254834705\n",
      "  len(indices) = 11092, weight = 2426.215857884437\n",
      "  len(indices) = 10885, weight = 2411.5238383991996\n",
      "  len(indices) = 7083, weight = 2092.3117139635237\n",
      "  len(indices) = 4085, weight = 1726.3245386288693\n",
      "  len(indices) = 3246, weight = 1587.0568876515586\n",
      "  len(indices) = 1170, weight = 1058.8042504564921\n",
      "  len(indices) = 347, weight = 600.9534388852762\n",
      "  len(indices) = 173, weight = 410.9393870934724\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n",
      "self.phrase_grounding_masks.shape = (18000, 22, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 18000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 29\n",
      "Lung cyst: 35\n",
      "COPD: 37\n",
      "Lung cavity: 60\n",
      "Emphysema: 84\n",
      "Rib fracture: 101\n",
      "Pneumothorax: 114\n",
      "Enlarged PA: 139\n",
      "Mediastinal shift: 170\n",
      "Atelectasis: 273\n",
      "Lung tumor: 371\n",
      "Consolidation: 449\n",
      "ILD: 618\n",
      "Calcification: 652\n",
      "Infiltration: 671\n",
      "Tuberculosis: 914\n",
      "Nodule/Mass: 1017\n",
      "Pleural effusion: 1149\n",
      "Pneumonia: 1163\n",
      "Other lesion: 1248\n",
      "Lung Opacity: 1415\n",
      "Pulmonary fibrosis: 1838\n",
      "Pleural thickening: 2179\n",
      "Cardiomegaly: 2625\n",
      "Aortic enlargement: 3318\n",
      "Other disease: 4945\n",
      "No finding: 12652\n",
      "Group sizes: [12529, 891, 444, 428, 364, 344, 307, 283, 273, 267, 245, 236, 206, 193, 170, 138, 127, 100, 99, 90, 56, 54, 49, 34, 73]\n",
      "  len(indices) = 12529, weight = 2522.6672479595745\n",
      "  len(indices) = 891, weight = 940.9850359649141\n",
      "  len(indices) = 444, weight = 680.1755171156125\n",
      "  len(indices) = 428, weight = 667.9638591411331\n",
      "  len(indices) = 364, weight = 615.8160380252455\n",
      "  len(indices) = 344, weight = 598.2811252947056\n",
      "  len(indices) = 307, weight = 563.9888635691133\n",
      "  len(indices) = 283, weight = 540.2796339164162\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 267, weight = 523.7422583945496\n",
      "  len(indices) = 245, weight = 499.93058392418243\n",
      "  len(indices) = 236, weight = 489.7963928535281\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 193, weight = 437.6702522239849\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 138, weight = 359.20170201154343\n",
      "  len(indices) = 127, weight = 341.33933626931963\n",
      "  len(indices) = 100, weight = 293.26529386579296\n",
      "  len(indices) = 99, weight = 291.34941227248714\n",
      "  len(indices) = 90, weight = 273.5936736738282\n",
      "  len(indices) = 56, weight = 195.85520038280242\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 34, weight = 131.67512839151652\n",
      "  len(indices) = 73, weight = 237.15649291307946\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'mask_exponent': 0.4}\u001b[0m\n",
      "len(cxrlt2024_train_dicom_ids) = 258871\n",
      "len(cxrlt2024_dev_dicom_ids) = 39293\n",
      "len(forbidden_train_dicom_ids) = 40220\n",
      "\u001b[1m\u001b[35mPreparing CXR-LT-2024 challenge datasets and dataloaders for training/testing...\u001b[0m\n",
      "Using image size mode: medium_512\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"train\"]) = 128427\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"dev\"]) = 13136\n",
      "Total number of images: 141230\n",
      "\u001b[1mBuilding cxrlt2024 train phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 85554\n",
      "num_phrases = 2, len(indices) = 30817\n",
      "num_phrases = 3, len(indices) = 8659\n",
      "num_phrases = 4, len(indices) = 2127\n",
      "num_phrases = 8, len(indices) = 104\n",
      "num_phrases = 5, len(indices) = 567\n",
      "num_phrases = 14, len(indices) = 97\n",
      "num_phrases = 6, len(indices) = 116\n",
      "num_phrases = 10, len(indices) = 45\n",
      "num_phrases = 7, len(indices) = 8\n",
      "\u001b[1mBuilding cxrlt2024 dev phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 10269\n",
      "num_phrases = 2, len(indices) = 2268\n",
      "num_phrases = 3, len(indices) = 404\n",
      "num_phrases = 8, len(indices) = 28\n",
      "num_phrases = 14, len(indices) = 54\n",
      "num_phrases = 4, len(indices) = 80\n",
      "num_phrases = 10, len(indices) = 12\n",
      "num_phrases = 5, len(indices) = 21\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_embeddings.shape = (596394, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 190929.05it/s]\n",
      "Total number of images: 258164\n",
      "len(train_indices) = 258164\n",
      "avg_facts_per_image = 81.27329914318031\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 8\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 32271\n",
      "\u001b[1m\u001b[35mPreparing Chest Imagenome dataset and dataloader for training...\u001b[0m\n",
      "Loding bbox_phrase_embeddings and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl...\n",
      "bbox_phrase_embeddings.shape = (36, 128)\n",
      "len(bbox_phrases) = 36\n",
      "\t right lung\n",
      "\t right upper lung zone\n",
      "\t right mid lung zone\n",
      "\t right lower lung zone\n",
      "\t right hilar structures\n",
      "\t right apical zone\n",
      "\t right costophrenic angle\n",
      "\t right cardiophrenic angle\n",
      "\t right hemidiaphragm\n",
      "\t left lung\n",
      "\t left upper lung zone\n",
      "\t left mid lung zone\n",
      "\t left lower lung zone\n",
      "\t left hilar structures\n",
      "\t left apical zone\n",
      "\t left costophrenic angle\n",
      "\t left hemidiaphragm\n",
      "\t trachea\n",
      "\t spine\n",
      "\t right clavicle\n",
      "\t left clavicle\n",
      "\t aortic arch\n",
      "\t mediastinum\n",
      "\t upper mediastinum\n",
      "\t svc\n",
      "\t cardiac silhouette\n",
      "\t left cardiac silhouette\n",
      "\t right cardiac silhouette\n",
      "\t cavoatrial junction\n",
      "\t right atrium\n",
      "\t descending aorta\n",
      "\t carina\n",
      "\t left upper abdomen\n",
      "\t right upper abdomen\n",
      "\t abdomen\n",
      "\t left cardiophrenic angle\n",
      "Using image size mode: medium_512\n",
      "\u001b[1mLoading precomputed bbox_coords_and_presence_and_mask from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/bbox_coords_and_presence_and_mask(29,29,243310).pkl...\u001b[0m\n",
      "File size: 7553074787 bytes (7376049.60 KB, 7203.17 MB, 7.03 GB)\n",
      "227835it [00:01, 207756.90it/s]\n",
      "Total number of images: 165768\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mCreating IU X-Ray Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[1mPreparing data for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (2331, 128)\n",
      "Number of invalid images removed: 111\n",
      "avg_facts_per_image = 2327.3329256692487\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train dataloader...\u001b[0m\n",
      "len(self.train_dataloader) = 920\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 32271\n",
      "len(mimiccxr_trainer.train_chest_imagenome_dataloader) = 16577\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_train_dataloader) = 12813\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_dev_dataloader) = 268\n",
      "len(vinbig_trainer.train_dataloader) = 100000000000000000\n",
      "len(chexlocalize_trainer.train_dataloader) = 91\n",
      "len(chexpert_trainer.train_dataloader) = 100000000000000000\n",
      "len(iuxray_trainer.train_dataloader) = 920\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.5, 1.0, 4.0, 1.5, 0.4, 0.5, 0.5]\n",
      "merged_dataset_name = mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_10_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7016.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/checkpoint_10_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7016.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m16) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m17) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 11/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.67906, mimfg_att_reg_loss 0.23443, mimfg_phrcls_loss 1.05582, mimfg_prc_auc 0.88409, cibg_att_sup_loss 0.83105, cibg_segmask_iou 0.25090, vbg_phrcls_loss 2.07149, vbg_prc_auc 0.35463, vbg_att_reg_loss 0.15893, vbg_att_sup_loss 0.80775, vbg_segmask_iou 0.14823, cl_att_sup_loss 0.68238, cl_segmask_iou 0.31181, cl_phrcls_loss 2.09598, cl_phrase_acc 0.85905, chxp_att_reg_loss 0.34798, chxp_phrcls_loss 2.74559, chxp_prc_auc 0.63782, iufg_att_reg_loss 0.30566, iufg_phrcls_loss 0.44070, iufg_prc_auc 0.26584, cxrlt2024c_att_reg_loss 0.27993, cxrlt2024c_phrcls_loss 1.08492, cxrlt2024c_prc_auc 0.61897, 568.10 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16030, cxrlt2024c_phrcls_loss 0.59510, cxrlt2024c_prc_auc 0.67010, 319.38 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6786.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.65808, mimfg_att_reg_loss 0.23062, mimfg_phrcls_loss 1.03938, mimfg_prc_auc 0.88764, cibg_att_sup_loss 0.79756, cibg_segmask_iou 0.25266, vbg_phrcls_loss 2.05286, vbg_prc_auc 0.36713, vbg_att_reg_loss 0.15800, vbg_att_sup_loss 0.75995, vbg_segmask_iou 0.14005, cl_att_sup_loss 0.66411, cl_segmask_iou 0.31910, cl_phrcls_loss 2.03949, cl_phrase_acc 0.85763, chxp_att_reg_loss 0.34456, chxp_phrcls_loss 2.71194, chxp_prc_auc 0.65224, iufg_att_reg_loss 0.31848, iufg_phrcls_loss 0.43802, iufg_prc_auc 0.25110, cxrlt2024c_att_reg_loss 0.27915, cxrlt2024c_phrcls_loss 1.08162, cxrlt2024c_prc_auc 0.63591, 573.01 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15902, cxrlt2024c_phrcls_loss 0.59740, cxrlt2024c_prc_auc 0.67374, 321.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6815.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.64384, mimfg_att_reg_loss 0.22746, mimfg_phrcls_loss 1.01874, mimfg_prc_auc 0.89364, cibg_att_sup_loss 0.79033, cibg_segmask_iou 0.25207, vbg_phrcls_loss 2.03567, vbg_prc_auc 0.36582, vbg_att_reg_loss 0.15182, vbg_att_sup_loss 0.74656, vbg_segmask_iou 0.13992, cl_att_sup_loss 0.66745, cl_segmask_iou 0.31628, cl_phrcls_loss 2.01843, cl_phrase_acc 0.86491, chxp_att_reg_loss 0.34463, chxp_phrcls_loss 2.72380, chxp_prc_auc 0.66092, iufg_att_reg_loss 0.30186, iufg_phrcls_loss 0.42281, iufg_prc_auc 0.27026, cxrlt2024c_att_reg_loss 0.27338, cxrlt2024c_phrcls_loss 1.08780, cxrlt2024c_prc_auc 0.63330, 575.34 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15781, cxrlt2024c_phrcls_loss 0.59081, cxrlt2024c_prc_auc 0.67413, 319.98 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6824.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.64793, mimfg_att_reg_loss 0.22852, mimfg_phrcls_loss 1.02118, mimfg_prc_auc 0.89310, cibg_att_sup_loss 0.78951, cibg_segmask_iou 0.25233, vbg_phrcls_loss 2.04464, vbg_prc_auc 0.37410, vbg_att_reg_loss 0.15558, vbg_att_sup_loss 0.74213, vbg_segmask_iou 0.13838, cl_att_sup_loss 0.66435, cl_segmask_iou 0.31680, cl_phrcls_loss 2.02577, cl_phrase_acc 0.86449, chxp_att_reg_loss 0.34302, chxp_phrcls_loss 2.73869, chxp_prc_auc 0.63873, iufg_att_reg_loss 0.30045, iufg_phrcls_loss 0.43101, iufg_prc_auc 0.26536, cxrlt2024c_att_reg_loss 0.28102, cxrlt2024c_phrcls_loss 1.08018, cxrlt2024c_prc_auc 0.63205, 576.35 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.15782, cxrlt2024c_phrcls_loss 0.59202, cxrlt2024c_prc_auc 0.67479, 321.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6826.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.63917, mimfg_att_reg_loss 0.22737, mimfg_phrcls_loss 1.03238, mimfg_prc_auc 0.88933, cibg_att_sup_loss 0.76541, cibg_segmask_iou 0.25866, vbg_phrcls_loss 2.02876, vbg_prc_auc 0.35690, vbg_att_reg_loss 0.14993, vbg_att_sup_loss 0.73733, vbg_segmask_iou 0.14084, cl_att_sup_loss 0.65753, cl_segmask_iou 0.32983, cl_phrcls_loss 2.05956, cl_phrase_acc 0.86538, chxp_att_reg_loss 0.33922, chxp_phrcls_loss 2.73877, chxp_prc_auc 0.63883, iufg_att_reg_loss 0.30607, iufg_phrcls_loss 0.42151, iufg_prc_auc 0.27062, cxrlt2024c_att_reg_loss 0.27915, cxrlt2024c_phrcls_loss 1.07373, cxrlt2024c_prc_auc 0.63268, 576.59 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14914, cxrlt2024c_phrcls_loss 0.57646, cxrlt2024c_prc_auc 0.67966, 323.22 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6875.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.61952, mimfg_att_reg_loss 0.22798, mimfg_phrcls_loss 1.02140, mimfg_prc_auc 0.89285, cibg_att_sup_loss 0.74022, cibg_segmask_iou 0.26198, vbg_phrcls_loss 2.01919, vbg_prc_auc 0.36882, vbg_att_reg_loss 0.15092, vbg_att_sup_loss 0.70115, vbg_segmask_iou 0.14234, cl_att_sup_loss 0.63596, cl_segmask_iou 0.33096, cl_phrcls_loss 2.00623, cl_phrase_acc 0.86865, chxp_att_reg_loss 0.33748, chxp_phrcls_loss 2.74240, chxp_prc_auc 0.64188, iufg_att_reg_loss 0.30058, iufg_phrcls_loss 0.42436, iufg_prc_auc 0.27841, cxrlt2024c_att_reg_loss 0.27370, cxrlt2024c_phrcls_loss 1.06760, cxrlt2024c_prc_auc 0.64632, 576.29 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14784, cxrlt2024c_phrcls_loss 0.58438, cxrlt2024c_prc_auc 0.68383, 320.34 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6905.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.59800, mimfg_att_reg_loss 0.22349, mimfg_phrcls_loss 1.00194, mimfg_prc_auc 0.89730, cibg_att_sup_loss 0.72780, cibg_segmask_iou 0.26356, vbg_phrcls_loss 1.99127, vbg_prc_auc 0.38492, vbg_att_reg_loss 0.14777, vbg_att_sup_loss 0.69103, vbg_segmask_iou 0.14229, cl_att_sup_loss 0.62083, cl_segmask_iou 0.32973, cl_phrcls_loss 1.95660, cl_phrase_acc 0.87767, chxp_att_reg_loss 0.33830, chxp_phrcls_loss 2.71381, chxp_prc_auc 0.66016, iufg_att_reg_loss 0.29787, iufg_phrcls_loss 0.41091, iufg_prc_auc 0.28134, cxrlt2024c_att_reg_loss 0.26953, cxrlt2024c_phrcls_loss 1.05877, cxrlt2024c_prc_auc 0.63682, 575.46 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14876, cxrlt2024c_phrcls_loss 0.57675, cxrlt2024c_prc_auc 0.68713, 319.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6931.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.59822, mimfg_att_reg_loss 0.22483, mimfg_phrcls_loss 0.99914, mimfg_prc_auc 0.89828, cibg_att_sup_loss 0.71756, cibg_segmask_iou 0.26341, vbg_phrcls_loss 1.99310, vbg_prc_auc 0.38100, vbg_att_reg_loss 0.14827, vbg_att_sup_loss 0.68904, vbg_segmask_iou 0.13955, cl_att_sup_loss 0.61797, cl_segmask_iou 0.33144, cl_phrcls_loss 1.92787, cl_phrase_acc 0.87981, chxp_att_reg_loss 0.33670, chxp_phrcls_loss 2.71500, chxp_prc_auc 0.66124, iufg_att_reg_loss 0.30431, iufg_phrcls_loss 0.42313, iufg_prc_auc 0.26824, cxrlt2024c_att_reg_loss 0.27208, cxrlt2024c_phrcls_loss 1.06021, cxrlt2024c_prc_auc 0.63595, 571.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15160, cxrlt2024c_phrcls_loss 0.57890, cxrlt2024c_prc_auc 0.68586, 320.15 secs\n",
      "\u001b[1m---- Epoch 19/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.58457, mimfg_att_reg_loss 0.22718, mimfg_phrcls_loss 0.99315, mimfg_prc_auc 0.89883, cibg_att_sup_loss 0.72453, cibg_segmask_iou 0.26254, vbg_phrcls_loss 1.98452, vbg_prc_auc 0.38971, vbg_att_reg_loss 0.14771, vbg_att_sup_loss 0.69483, vbg_segmask_iou 0.13899, cl_att_sup_loss 0.62272, cl_segmask_iou 0.32983, cl_phrcls_loss 1.96060, cl_phrase_acc 0.87411, chxp_att_reg_loss 0.33393, chxp_phrcls_loss 2.67462, chxp_prc_auc 0.67507, iufg_att_reg_loss 0.29610, iufg_phrcls_loss 0.42202, iufg_prc_auc 0.27895, cxrlt2024c_att_reg_loss 0.26748, cxrlt2024c_phrcls_loss 1.03870, cxrlt2024c_prc_auc 0.65474, 572.80 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15027, cxrlt2024c_phrcls_loss 0.57534, cxrlt2024c_prc_auc 0.68664, 316.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6931.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.60504, mimfg_att_reg_loss 0.22627, mimfg_phrcls_loss 1.00353, mimfg_prc_auc 0.89665, cibg_att_sup_loss 0.70942, cibg_segmask_iou 0.26899, vbg_phrcls_loss 2.00177, vbg_prc_auc 0.36594, vbg_att_reg_loss 0.14825, vbg_att_sup_loss 0.68675, vbg_segmask_iou 0.14321, cl_att_sup_loss 0.62320, cl_segmask_iou 0.32823, cl_phrcls_loss 1.96180, cl_phrase_acc 0.87876, chxp_att_reg_loss 0.32958, chxp_phrcls_loss 2.73890, chxp_prc_auc 0.64211, iufg_att_reg_loss 0.30681, iufg_phrcls_loss 0.42168, iufg_prc_auc 0.27285, cxrlt2024c_att_reg_loss 0.27250, cxrlt2024c_phrcls_loss 1.06926, cxrlt2024c_prc_auc 0.63194, 571.50 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15018, cxrlt2024c_phrcls_loss 0.57765, cxrlt2024c_prc_auc 0.68736, 317.20 secs\n",
      "\u001b[1m---- Epoch 21/110\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 20825\n",
      "Exception in thread Thread-159 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1414, in <module>\n",
      "    del args['override_lr']\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1371, in resume_training\n",
      "    lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 832, in train_model\n",
      "    update_lr_batchwise=update_lr_batchwise,\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 135, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 819, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 757, in step_fn__cxrlt2024_custom_labels\n",
      "    phrase_classifier_loss = generic_phrase_classifier_criterion(phrase_classifier_logits, phrase_classification_labels.float())\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/__init__.py\", line 91, in forward\n",
      "    tot = (loss1 + loss2).detach().item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 2000 \\\n",
    "--max_images_per_batch 10 \\\n",
    "--max_phrases_per_batch 400 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 5.0 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino\" \\\n",
    "--img_aug_mode \"random-color\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--freeze_image_encoder \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"film_layers_plus_sigmoid_attention_and_custom_classifier\" \\\n",
    "--visual_feature_proj_size 256 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,2e-4,5,5e-6,2e-4,5,5e-6\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce\" \\\n",
    "--use_attention_regularization_loss \\\n",
    "--attention_supervision_loss_weight 2.0 \\\n",
    "--phrase_classifier_loss_weight 2.0 \\\n",
    "--foreground_loss_weight 1.5 \\\n",
    "--mask_exponent 0.4 \\\n",
    "--use_cxrlt2024_challenge_split \\\n",
    "--use_cxrlt2024_custom_labels \\\n",
    "--cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--mimiccxr_report_fact_nli_integrated_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--use_chest_imagenome_for_train \\\n",
    "--chest_imagenome_bbox_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\" \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--use_vinbig_for_train \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\" \\\n",
    "--vinbig_training_data_mode \"all\" \\\n",
    "--use_chexlocalize_for_train \\\n",
    "--chexlocalize_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\" \\\n",
    "--use_chexpert_for_train \\\n",
    "--chexpert_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\" \\\n",
    "--use_iuxray_for_train \\\n",
    "--iuxray_image_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\" \\\n",
    "--cxrlt2024_weight 4.0 \\\n",
    "--mimiccxr_facts_weight 1.5 \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--iuxray_weight 0.5 \\\n",
    "--vinbig_weight 1.5 \\\n",
    "--chexpert_weight 0.5 \\\n",
    "--chexlocalize_weight 0.4 \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00098a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 130\n",
      "   batches_per_epoch: 2000\n",
      "   max_images_per_batch: 10\n",
      "   max_phrases_per_batch: 400\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 5.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: film_layers_plus_sigmoid_attention_and_custom_classifier\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: 256\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 2.0\n",
      "   phrase_classifier_loss_weight: 2.0\n",
      "   foreground_loss_weight: 1.5\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: True\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\n",
      "   chexpert_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.5\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 4.0\n",
      "   vinbig_weight: 1.5\n",
      "   chexlocalize_weight: 0.4\n",
      "   chexpert_weight: 0.5\n",
      "   iuxray_weight: 0.5\n",
      "   img_aug_mode: random-color\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: True\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: True\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: True\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: True\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: True\n",
      "   use_cxrlt2024_custom_labels: True\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   vinbig_training_data_mode: all\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.5\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating CheXLocalize Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loding class_phrase_embeddings_filepath and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl...\n",
      "class_phrase_embeddings.shape = (10, 128)\n",
      "len(class_phrases) = 10\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t airspace opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t support devices seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without masks: 216/902\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 902\n",
      "batch_size = 10\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating CheXpert Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train_visualCheXbert.csv\n",
      "len(df_train_visualchexbert) = 223414\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/valid.csv\n",
      "len(df_valid) = 234\n",
      "len(df) = 223648\n",
      "Loading images\n",
      "Loading chexpert labels\n",
      "Loading test set\n",
      "len(self.test_image_paths) = 668\n",
      "self.test_labels.shape = (668, 14)\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl...\n",
      "phrase_embeddings.shape = (14, 128)\n",
      "len(phrases) = 14\n",
      "\t no findings\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t lung opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t pneumonia seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t other pleural abnormality seen\n",
      "\t fracture seen\n",
      "\t support devices seen\n",
      "len(all_image_paths) = 224316\n",
      "all_labels.shape = (224316, 14)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 224316\n",
      "No labels: 3246\n",
      "Pneumothorax: 25357\n",
      "Pleural Other: 26334\n",
      "Lung Lesion: 31042\n",
      "No Finding: 35673\n",
      "Pneumonia: 52248\n",
      "Fracture: 61696\n",
      "Edema: 94500\n",
      "Pleural Effusion: 103837\n",
      "Consolidation: 107297\n",
      "Cardiomegaly: 122164\n",
      "Atelectasis: 124182\n",
      "Support Devices: 136382\n",
      "Enlarged Cardiomediastinum: 144377\n",
      "Lung Opacity: 151937\n",
      "Group sizes: [61397, 30579, 25357, 21626, 18526, 17225, 11525, 11092, 10885, 7083, 4085, 3246, 1170, 347, 173]\n",
      "  len(indices) = 61397, weight = 4024.1406302660666\n",
      "  len(indices) = 30579, weight = 3308.1179132413095\n",
      "  len(indices) = 25357, weight = 3131.4217784165476\n",
      "  len(indices) = 21626, weight = 2986.2821261955132\n",
      "  len(indices) = 18526, weight = 2849.5564265118087\n",
      "  len(indices) = 17225, weight = 2786.68263628706\n",
      "  len(indices) = 11525, weight = 2456.265254834705\n",
      "  len(indices) = 11092, weight = 2426.215857884437\n",
      "  len(indices) = 10885, weight = 2411.5238383991996\n",
      "  len(indices) = 7083, weight = 2092.3117139635237\n",
      "  len(indices) = 4085, weight = 1726.3245386288693\n",
      "  len(indices) = 3246, weight = 1587.0568876515586\n",
      "  len(indices) = 1170, weight = 1058.8042504564921\n",
      "  len(indices) = 347, weight = 600.9534388852762\n",
      "  len(indices) = 173, weight = 410.9393870934724\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n",
      "self.phrase_grounding_masks.shape = (18000, 22, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 18000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 29\n",
      "Lung cyst: 35\n",
      "COPD: 37\n",
      "Lung cavity: 60\n",
      "Emphysema: 84\n",
      "Rib fracture: 101\n",
      "Pneumothorax: 114\n",
      "Enlarged PA: 139\n",
      "Mediastinal shift: 170\n",
      "Atelectasis: 273\n",
      "Lung tumor: 371\n",
      "Consolidation: 449\n",
      "ILD: 618\n",
      "Calcification: 652\n",
      "Infiltration: 671\n",
      "Tuberculosis: 914\n",
      "Nodule/Mass: 1017\n",
      "Pleural effusion: 1149\n",
      "Pneumonia: 1163\n",
      "Other lesion: 1248\n",
      "Lung Opacity: 1415\n",
      "Pulmonary fibrosis: 1838\n",
      "Pleural thickening: 2179\n",
      "Cardiomegaly: 2625\n",
      "Aortic enlargement: 3318\n",
      "Other disease: 4945\n",
      "No finding: 12652\n",
      "Group sizes: [12529, 891, 444, 428, 364, 344, 307, 283, 273, 267, 245, 236, 206, 193, 170, 138, 127, 100, 99, 90, 56, 54, 49, 34, 73]\n",
      "  len(indices) = 12529, weight = 2522.6672479595745\n",
      "  len(indices) = 891, weight = 940.9850359649141\n",
      "  len(indices) = 444, weight = 680.1755171156125\n",
      "  len(indices) = 428, weight = 667.9638591411331\n",
      "  len(indices) = 364, weight = 615.8160380252455\n",
      "  len(indices) = 344, weight = 598.2811252947056\n",
      "  len(indices) = 307, weight = 563.9888635691133\n",
      "  len(indices) = 283, weight = 540.2796339164162\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 267, weight = 523.7422583945496\n",
      "  len(indices) = 245, weight = 499.93058392418243\n",
      "  len(indices) = 236, weight = 489.7963928535281\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 193, weight = 437.6702522239849\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 138, weight = 359.20170201154343\n",
      "  len(indices) = 127, weight = 341.33933626931963\n",
      "  len(indices) = 100, weight = 293.26529386579296\n",
      "  len(indices) = 99, weight = 291.34941227248714\n",
      "  len(indices) = 90, weight = 273.5936736738282\n",
      "  len(indices) = 56, weight = 195.85520038280242\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 34, weight = 131.67512839151652\n",
      "  len(indices) = 73, weight = 237.15649291307946\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "len(cxrlt2024_train_dicom_ids) = 258871\n",
      "len(cxrlt2024_dev_dicom_ids) = 39293\n",
      "len(forbidden_train_dicom_ids) = 40220\n",
      "\u001b[1m\u001b[35mPreparing CXR-LT-2024 challenge datasets and dataloaders for training/testing...\u001b[0m\n",
      "Using image size mode: medium_512\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"train\"]) = 128427\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"dev\"]) = 13136\n",
      "Total number of images: 141230\n",
      "\u001b[1mBuilding cxrlt2024 train phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 85554\n",
      "num_phrases = 2, len(indices) = 30817\n",
      "num_phrases = 3, len(indices) = 8659\n",
      "num_phrases = 4, len(indices) = 2127\n",
      "num_phrases = 8, len(indices) = 104\n",
      "num_phrases = 5, len(indices) = 567\n",
      "num_phrases = 14, len(indices) = 97\n",
      "num_phrases = 6, len(indices) = 116\n",
      "num_phrases = 10, len(indices) = 45\n",
      "num_phrases = 7, len(indices) = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBuilding cxrlt2024 dev phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 10269\n",
      "num_phrases = 2, len(indices) = 2268\n",
      "num_phrases = 3, len(indices) = 404\n",
      "num_phrases = 8, len(indices) = 28\n",
      "num_phrases = 14, len(indices) = 54\n",
      "num_phrases = 4, len(indices) = 80\n",
      "num_phrases = 10, len(indices) = 12\n",
      "num_phrases = 5, len(indices) = 21\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596394, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 190585.09it/s]\n",
      "Total number of images: 258164\n",
      "len(train_indices) = 258164\n",
      "avg_facts_per_image = 81.27329914318031\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 8\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 32271\n",
      "\u001b[1m\u001b[35mPreparing Chest Imagenome dataset and dataloader for training...\u001b[0m\n",
      "Loding bbox_phrase_embeddings and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl...\n",
      "bbox_phrase_embeddings.shape = (36, 128)\n",
      "len(bbox_phrases) = 36\n",
      "\t right lung\n",
      "\t right upper lung zone\n",
      "\t right mid lung zone\n",
      "\t right lower lung zone\n",
      "\t right hilar structures\n",
      "\t right apical zone\n",
      "\t right costophrenic angle\n",
      "\t right cardiophrenic angle\n",
      "\t right hemidiaphragm\n",
      "\t left lung\n",
      "\t left upper lung zone\n",
      "\t left mid lung zone\n",
      "\t left lower lung zone\n",
      "\t left hilar structures\n",
      "\t left apical zone\n",
      "\t left costophrenic angle\n",
      "\t left hemidiaphragm\n",
      "\t trachea\n",
      "\t spine\n",
      "\t right clavicle\n",
      "\t left clavicle\n",
      "\t aortic arch\n",
      "\t mediastinum\n",
      "\t upper mediastinum\n",
      "\t svc\n",
      "\t cardiac silhouette\n",
      "\t left cardiac silhouette\n",
      "\t right cardiac silhouette\n",
      "\t cavoatrial junction\n",
      "\t right atrium\n",
      "\t descending aorta\n",
      "\t carina\n",
      "\t left upper abdomen\n",
      "\t right upper abdomen\n",
      "\t abdomen\n",
      "\t left cardiophrenic angle\n",
      "Using image size mode: medium_512\n",
      "\u001b[1mLoading precomputed bbox_coords_and_presence_and_mask from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/bbox_coords_and_presence_and_mask(29,29,243310).pkl...\u001b[0m\n",
      "File size: 7553074787 bytes (7376049.60 KB, 7203.17 MB, 7.03 GB)\n",
      "227835it [00:01, 211731.03it/s]\n",
      "Total number of images: 165768\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mCreating IU X-Ray Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[1mPreparing data for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (2331, 128)\n",
      "Number of invalid images removed: 111\n",
      "avg_facts_per_image = 2327.3329256692487\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train dataloader...\u001b[0m\n",
      "len(self.train_dataloader) = 920\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 32271\n",
      "len(mimiccxr_trainer.train_chest_imagenome_dataloader) = 16577\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_train_dataloader) = 12813\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_dev_dataloader) = 268\n",
      "len(vinbig_trainer.train_dataloader) = 100000000000000000\n",
      "len(chexlocalize_trainer.train_dataloader) = 91\n",
      "len(chexpert_trainer.train_dataloader) = 100000000000000000\n",
      "len(iuxray_trainer.train_dataloader) = 920\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.5, 1.0, 4.0, 1.5, 0.4, 0.5, 0.5]\n",
      "merged_dataset_name = mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m16) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_19_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6931.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/checkpoint_19_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6931.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m17) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m18) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.58449, mimfg_att_reg_loss 0.22887, mimfg_phrcls_loss 1.01026, mimfg_prc_auc 0.89458, cibg_att_sup_loss 0.72243, cibg_segmask_iou 0.26481, vbg_phrcls_loss 1.97586, vbg_prc_auc 0.38905, vbg_att_reg_loss 0.14793, vbg_att_sup_loss 0.67488, vbg_segmask_iou 0.14256, cl_att_sup_loss 0.60693, cl_segmask_iou 0.32789, cl_phrcls_loss 1.91342, cl_phrase_acc 0.87869, chxp_att_reg_loss 0.33423, chxp_phrcls_loss 2.67406, chxp_prc_auc 0.67778, iufg_att_reg_loss 0.30588, iufg_phrcls_loss 0.41492, iufg_prc_auc 0.29089, cxrlt2024c_att_reg_loss 0.26780, cxrlt2024c_phrcls_loss 1.04971, cxrlt2024c_prc_auc 0.64941, 811.58 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15025, cxrlt2024c_phrcls_loss 0.57556, cxrlt2024c_prc_auc 0.68695, 177.84 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6933.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.57404, mimfg_att_reg_loss 0.22447, mimfg_phrcls_loss 0.99200, mimfg_prc_auc 0.90019, cibg_att_sup_loss 0.71565, cibg_segmask_iou 0.26483, vbg_phrcls_loss 1.97420, vbg_prc_auc 0.38218, vbg_att_reg_loss 0.14597, vbg_att_sup_loss 0.69133, vbg_segmask_iou 0.13923, cl_att_sup_loss 0.59518, cl_segmask_iou 0.32890, cl_phrcls_loss 1.90316, cl_phrase_acc 0.88216, chxp_att_reg_loss 0.33304, chxp_phrcls_loss 2.67421, chxp_prc_auc 0.68925, iufg_att_reg_loss 0.29310, iufg_phrcls_loss 0.40817, iufg_prc_auc 0.28734, cxrlt2024c_att_reg_loss 0.26970, cxrlt2024c_phrcls_loss 1.02740, cxrlt2024c_prc_auc 0.64908, 811.11 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14932, cxrlt2024c_phrcls_loss 0.57026, cxrlt2024c_prc_auc 0.68854, 178.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6948.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.57127, mimfg_att_reg_loss 0.22860, mimfg_phrcls_loss 0.99712, mimfg_prc_auc 0.89820, cibg_att_sup_loss 0.70946, cibg_segmask_iou 0.26554, vbg_phrcls_loss 1.96175, vbg_prc_auc 0.38325, vbg_att_reg_loss 0.14514, vbg_att_sup_loss 0.65200, vbg_segmask_iou 0.14257, cl_att_sup_loss 0.59911, cl_segmask_iou 0.32923, cl_phrcls_loss 1.88709, cl_phrase_acc 0.88040, chxp_att_reg_loss 0.33158, chxp_phrcls_loss 2.72669, chxp_prc_auc 0.64815, iufg_att_reg_loss 0.30079, iufg_phrcls_loss 0.41369, iufg_prc_auc 0.29032, cxrlt2024c_att_reg_loss 0.26626, cxrlt2024c_phrcls_loss 1.04033, cxrlt2024c_prc_auc 0.65592, 811.15 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.14991, cxrlt2024c_phrcls_loss 0.57740, cxrlt2024c_prc_auc 0.69466, 178.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6983.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.60571, mimfg_att_reg_loss 0.22606, mimfg_phrcls_loss 1.00120, mimfg_prc_auc 0.89755, cibg_att_sup_loss 0.70706, cibg_segmask_iou 0.26486, vbg_phrcls_loss 1.99094, vbg_prc_auc 0.36768, vbg_att_reg_loss 0.14492, vbg_att_sup_loss 0.68065, vbg_segmask_iou 0.13639, cl_att_sup_loss 0.59595, cl_segmask_iou 0.31390, cl_phrcls_loss 1.91087, cl_phrase_acc 0.88005, chxp_att_reg_loss 0.33220, chxp_phrcls_loss 2.69107, chxp_prc_auc 0.66879, iufg_att_reg_loss 0.30441, iufg_phrcls_loss 0.43687, iufg_prc_auc 0.27461, cxrlt2024c_att_reg_loss 0.27093, cxrlt2024c_phrcls_loss 1.09133, cxrlt2024c_prc_auc 0.64177, 809.37 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14712, cxrlt2024c_phrcls_loss 0.57020, cxrlt2024c_prc_auc 0.69436, 178.16 secs\n",
      "\u001b[1m---- Epoch 5/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.51198, mimfg_att_reg_loss 0.22324, mimfg_phrcls_loss 0.98183, mimfg_prc_auc 0.90274, cibg_att_sup_loss 0.64608, cibg_segmask_iou 0.28006, vbg_phrcls_loss 1.86911, vbg_prc_auc 0.41489, vbg_att_reg_loss 0.13286, vbg_att_sup_loss 0.58476, vbg_segmask_iou 0.14345, cl_att_sup_loss 0.50430, cl_segmask_iou 0.33469, cl_phrcls_loss 1.77879, cl_phrase_acc 0.88803, chxp_att_reg_loss 0.31993, chxp_phrcls_loss 2.67160, chxp_prc_auc 0.68548, iufg_att_reg_loss 0.28796, iufg_phrcls_loss 0.39998, iufg_prc_auc 0.31770, cxrlt2024c_att_reg_loss 0.25892, cxrlt2024c_phrcls_loss 1.02747, cxrlt2024c_prc_auc 0.66136, 809.93 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14274, cxrlt2024c_phrcls_loss 0.56169, cxrlt2024c_prc_auc 0.71062, 178.46 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7113.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.46340, mimfg_att_reg_loss 0.22058, mimfg_phrcls_loss 0.97431, mimfg_prc_auc 0.90303, cibg_att_sup_loss 0.62835, cibg_segmask_iou 0.28310, vbg_phrcls_loss 1.79298, vbg_prc_auc 0.45346, vbg_att_reg_loss 0.12483, vbg_att_sup_loss 0.55305, vbg_segmask_iou 0.15214, cl_att_sup_loss 0.47517, cl_segmask_iou 0.33048, cl_phrcls_loss 1.66252, cl_phrase_acc 0.90428, chxp_att_reg_loss 0.30801, chxp_phrcls_loss 2.51550, chxp_prc_auc 0.71450, iufg_att_reg_loss 0.28506, iufg_phrcls_loss 0.38864, iufg_prc_auc 0.31834, cxrlt2024c_att_reg_loss 0.26071, cxrlt2024c_phrcls_loss 1.00017, cxrlt2024c_prc_auc 0.67829, 809.08 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14428, cxrlt2024c_phrcls_loss 0.54711, cxrlt2024c_prc_auc 0.71598, 178.37 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7164.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.44148, mimfg_att_reg_loss 0.21962, mimfg_phrcls_loss 0.95501, mimfg_prc_auc 0.90775, cibg_att_sup_loss 0.63213, cibg_segmask_iou 0.28351, vbg_phrcls_loss 1.76067, vbg_prc_auc 0.46010, vbg_att_reg_loss 0.12218, vbg_att_sup_loss 0.52166, vbg_segmask_iou 0.14619, cl_att_sup_loss 0.46054, cl_segmask_iou 0.33512, cl_phrcls_loss 1.63207, cl_phrase_acc 0.90796, chxp_att_reg_loss 0.31089, chxp_phrcls_loss 2.58073, chxp_prc_auc 0.71195, iufg_att_reg_loss 0.28528, iufg_phrcls_loss 0.37834, iufg_prc_auc 0.31881, cxrlt2024c_att_reg_loss 0.25105, cxrlt2024c_phrcls_loss 0.98546, cxrlt2024c_prc_auc 0.66949, 811.26 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14210, cxrlt2024c_phrcls_loss 0.55241, cxrlt2024c_prc_auc 0.71788, 178.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7175.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.43003, mimfg_att_reg_loss 0.21905, mimfg_phrcls_loss 0.95585, mimfg_prc_auc 0.90723, cibg_att_sup_loss 0.62111, cibg_segmask_iou 0.28510, vbg_phrcls_loss 1.72934, vbg_prc_auc 0.46194, vbg_att_reg_loss 0.12078, vbg_att_sup_loss 0.50462, vbg_segmask_iou 0.15000, cl_att_sup_loss 0.44972, cl_segmask_iou 0.34087, cl_phrcls_loss 1.60174, cl_phrase_acc 0.90822, chxp_att_reg_loss 0.30279, chxp_phrcls_loss 2.52997, chxp_prc_auc 0.70894, iufg_att_reg_loss 0.28365, iufg_phrcls_loss 0.36257, iufg_prc_auc 0.30672, cxrlt2024c_att_reg_loss 0.25016, cxrlt2024c_phrcls_loss 0.99398, cxrlt2024c_prc_auc 0.69996, 810.93 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14340, cxrlt2024c_phrcls_loss 0.54541, cxrlt2024c_prc_auc 0.71803, 178.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7186.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.42728, mimfg_att_reg_loss 0.22000, mimfg_phrcls_loss 0.96174, mimfg_prc_auc 0.90550, cibg_att_sup_loss 0.62094, cibg_segmask_iou 0.28460, vbg_phrcls_loss 1.72559, vbg_prc_auc 0.47230, vbg_att_reg_loss 0.11833, vbg_att_sup_loss 0.50976, vbg_segmask_iou 0.15140, cl_att_sup_loss 0.44532, cl_segmask_iou 0.33546, cl_phrcls_loss 1.56064, cl_phrase_acc 0.91295, chxp_att_reg_loss 0.30385, chxp_phrcls_loss 2.49693, chxp_prc_auc 0.72531, iufg_att_reg_loss 0.29151, iufg_phrcls_loss 0.37665, iufg_prc_auc 0.31945, cxrlt2024c_att_reg_loss 0.25323, cxrlt2024c_phrcls_loss 0.98976, cxrlt2024c_prc_auc 0.69448, 811.72 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14361, cxrlt2024c_phrcls_loss 0.54833, cxrlt2024c_prc_auc 0.71899, 178.24 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7191.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.50884, mimfg_att_reg_loss 0.21996, mimfg_phrcls_loss 0.97084, mimfg_prc_auc 0.90454, cibg_att_sup_loss 0.65641, cibg_segmask_iou 0.27982, vbg_phrcls_loss 1.87754, vbg_prc_auc 0.41595, vbg_att_reg_loss 0.13211, vbg_att_sup_loss 0.59110, vbg_segmask_iou 0.14318, cl_att_sup_loss 0.51155, cl_segmask_iou 0.32130, cl_phrcls_loss 1.74707, cl_phrase_acc 0.89378, chxp_att_reg_loss 0.31005, chxp_phrcls_loss 2.63762, chxp_prc_auc 0.67441, iufg_att_reg_loss 0.28926, iufg_phrcls_loss 0.40755, iufg_prc_auc 0.29321, cxrlt2024c_att_reg_loss 0.25072, cxrlt2024c_phrcls_loss 1.03271, cxrlt2024c_prc_auc 0.66462, 811.29 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14098, cxrlt2024c_phrcls_loss 0.55202, cxrlt2024c_prc_auc 0.70976, 178.31 secs\n",
      "\u001b[1m---- Epoch 11/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.48215, mimfg_att_reg_loss 0.21415, mimfg_phrcls_loss 0.95916, mimfg_prc_auc 0.90703, cibg_att_sup_loss 0.60429, cibg_segmask_iou 0.29413, vbg_phrcls_loss 1.74512, vbg_prc_auc 0.46560, vbg_att_reg_loss 0.11596, vbg_att_sup_loss 0.48634, vbg_segmask_iou 0.15086, cl_att_sup_loss 0.42893, cl_segmask_iou 0.33935, cl_phrcls_loss 1.60330, cl_phrase_acc 0.91127, chxp_att_reg_loss 0.29521, chxp_phrcls_loss 2.50497, chxp_prc_auc 0.73084, iufg_att_reg_loss 0.29061, iufg_phrcls_loss 0.37833, iufg_prc_auc 0.30201, cxrlt2024c_att_reg_loss 0.27810, cxrlt2024c_phrcls_loss 1.09746, cxrlt2024c_prc_auc 0.67861, 811.15 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13898, cxrlt2024c_phrcls_loss 0.54548, cxrlt2024c_prc_auc 0.72312, 178.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7219.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.44374, mimfg_att_reg_loss 0.21230, mimfg_phrcls_loss 0.94764, mimfg_prc_auc 0.91051, cibg_att_sup_loss 0.59795, cibg_segmask_iou 0.29410, vbg_phrcls_loss 1.67573, vbg_prc_auc 0.49818, vbg_att_reg_loss 0.11277, vbg_att_sup_loss 0.45609, vbg_segmask_iou 0.15409, cl_att_sup_loss 0.39856, cl_segmask_iou 0.33677, cl_phrcls_loss 1.52540, cl_phrase_acc 0.91627, chxp_att_reg_loss 0.29374, chxp_phrcls_loss 2.50392, chxp_prc_auc 0.72283, iufg_att_reg_loss 0.28193, iufg_phrcls_loss 0.35928, iufg_prc_auc 0.34603, cxrlt2024c_att_reg_loss 0.27180, cxrlt2024c_phrcls_loss 1.07578, cxrlt2024c_prc_auc 0.68945, 810.88 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.14064, cxrlt2024c_phrcls_loss 0.54077, cxrlt2024c_prc_auc 0.72660, 178.27 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7251.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.43295, mimfg_att_reg_loss 0.21624, mimfg_phrcls_loss 0.95883, mimfg_prc_auc 0.90638, cibg_att_sup_loss 0.59892, cibg_segmask_iou 0.29396, vbg_phrcls_loss 1.64750, vbg_prc_auc 0.50978, vbg_att_reg_loss 0.10953, vbg_att_sup_loss 0.44703, vbg_segmask_iou 0.15601, cl_att_sup_loss 0.39086, cl_segmask_iou 0.33665, cl_phrcls_loss 1.47328, cl_phrase_acc 0.92257, chxp_att_reg_loss 0.28485, chxp_phrcls_loss 2.45335, chxp_prc_auc 0.72358, iufg_att_reg_loss 0.28129, iufg_phrcls_loss 0.36600, iufg_prc_auc 0.32635, cxrlt2024c_att_reg_loss 0.26985, cxrlt2024c_phrcls_loss 1.07427, cxrlt2024c_prc_auc 0.70149, 810.24 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13868, cxrlt2024c_phrcls_loss 0.54062, cxrlt2024c_prc_auc 0.72920, 178.09 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7272.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.44946, mimfg_att_reg_loss 0.21123, mimfg_phrcls_loss 0.94535, mimfg_prc_auc 0.91037, cibg_att_sup_loss 0.59168, cibg_segmask_iou 0.29517, vbg_phrcls_loss 1.64235, vbg_prc_auc 0.51638, vbg_att_reg_loss 0.10835, vbg_att_sup_loss 0.44533, vbg_segmask_iou 0.15912, cl_att_sup_loss 0.39500, cl_segmask_iou 0.33766, cl_phrcls_loss 1.49437, cl_phrase_acc 0.92254, chxp_att_reg_loss 0.28812, chxp_phrcls_loss 2.46595, chxp_prc_auc 0.73161, iufg_att_reg_loss 0.28768, iufg_phrcls_loss 0.35376, iufg_prc_auc 0.32172, cxrlt2024c_att_reg_loss 0.28095, cxrlt2024c_phrcls_loss 1.10659, cxrlt2024c_prc_auc 0.69762, 810.62 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13816, cxrlt2024c_phrcls_loss 0.54138, cxrlt2024c_prc_auc 0.72874, 178.05 secs\n",
      "\u001b[1m---- Epoch 15/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.49346, mimfg_att_reg_loss 0.20963, mimfg_phrcls_loss 0.95530, mimfg_prc_auc 0.90923, cibg_att_sup_loss 0.58771, cibg_segmask_iou 0.29465, vbg_phrcls_loss 1.72627, vbg_prc_auc 0.47087, vbg_att_reg_loss 0.11497, vbg_att_sup_loss 0.47937, vbg_segmask_iou 0.15325, cl_att_sup_loss 0.41404, cl_segmask_iou 0.33397, cl_phrcls_loss 1.51891, cl_phrase_acc 0.91520, chxp_att_reg_loss 0.28874, chxp_phrcls_loss 2.50769, chxp_prc_auc 0.70932, iufg_att_reg_loss 0.26936, iufg_phrcls_loss 0.37425, iufg_prc_auc 0.33736, cxrlt2024c_att_reg_loss 0.28576, cxrlt2024c_phrcls_loss 1.14971, cxrlt2024c_prc_auc 0.70330, 816.42 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13576, cxrlt2024c_phrcls_loss 0.55055, cxrlt2024c_prc_auc 0.73163, 178.08 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7282.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.35266, mimfg_att_reg_loss 0.21001, mimfg_phrcls_loss 0.93740, mimfg_prc_auc 0.90974, cibg_att_sup_loss 0.56984, cibg_segmask_iou 0.29854, vbg_phrcls_loss 1.64574, vbg_prc_auc 0.50761, vbg_att_reg_loss 0.10966, vbg_att_sup_loss 0.44019, vbg_segmask_iou 0.15801, cl_att_sup_loss 0.37245, cl_segmask_iou 0.33458, cl_phrcls_loss 1.36515, cl_phrase_acc 0.92993, chxp_att_reg_loss 0.27675, chxp_phrcls_loss 2.45265, chxp_prc_auc 0.72936, iufg_att_reg_loss 0.27913, iufg_phrcls_loss 0.35603, iufg_prc_auc 0.33344, cxrlt2024c_att_reg_loss 0.23984, cxrlt2024c_phrcls_loss 0.95345, cxrlt2024c_prc_auc 0.72431, 809.27 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13484, cxrlt2024c_phrcls_loss 0.53308, cxrlt2024c_prc_auc 0.73990, 178.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7359.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.29903, mimfg_att_reg_loss 0.20836, mimfg_phrcls_loss 0.92238, mimfg_prc_auc 0.91375, cibg_att_sup_loss 0.56501, cibg_segmask_iou 0.30124, vbg_phrcls_loss 1.52317, vbg_prc_auc 0.55824, vbg_att_reg_loss 0.10022, vbg_att_sup_loss 0.40898, vbg_segmask_iou 0.16154, cl_att_sup_loss 0.34708, cl_segmask_iou 0.33408, cl_phrcls_loss 1.24666, cl_phrase_acc 0.93835, chxp_att_reg_loss 0.26758, chxp_phrcls_loss 2.39630, chxp_prc_auc 0.73196, iufg_att_reg_loss 0.27888, iufg_phrcls_loss 0.34045, iufg_prc_auc 0.32042, cxrlt2024c_att_reg_loss 0.23706, cxrlt2024c_phrcls_loss 0.92184, cxrlt2024c_prc_auc 0.74133, 790.19 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13451, cxrlt2024c_phrcls_loss 0.52334, cxrlt2024c_prc_auc 0.74166, 178.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7384.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.28211, mimfg_att_reg_loss 0.20581, mimfg_phrcls_loss 0.90528, mimfg_prc_auc 0.91708, cibg_att_sup_loss 0.56073, cibg_segmask_iou 0.29975, vbg_phrcls_loss 1.51167, vbg_prc_auc 0.57128, vbg_att_reg_loss 0.09939, vbg_att_sup_loss 0.39022, vbg_segmask_iou 0.16135, cl_att_sup_loss 0.33710, cl_segmask_iou 0.33822, cl_phrcls_loss 1.16480, cl_phrase_acc 0.94460, chxp_att_reg_loss 0.26818, chxp_phrcls_loss 2.40814, chxp_prc_auc 0.74353, iufg_att_reg_loss 0.27174, iufg_phrcls_loss 0.34193, iufg_prc_auc 0.34817, cxrlt2024c_att_reg_loss 0.23596, cxrlt2024c_phrcls_loss 0.91034, cxrlt2024c_prc_auc 0.75122, 809.70 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13515, cxrlt2024c_phrcls_loss 0.52438, cxrlt2024c_prc_auc 0.74430, 177.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7406.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.26919, mimfg_att_reg_loss 0.20939, mimfg_phrcls_loss 0.92429, mimfg_prc_auc 0.91168, cibg_att_sup_loss 0.56649, cibg_segmask_iou 0.30076, vbg_phrcls_loss 1.48483, vbg_prc_auc 0.57739, vbg_att_reg_loss 0.09980, vbg_att_sup_loss 0.38187, vbg_segmask_iou 0.16293, cl_att_sup_loss 0.33347, cl_segmask_iou 0.33222, cl_phrcls_loss 1.14885, cl_phrase_acc 0.94394, chxp_att_reg_loss 0.26333, chxp_phrcls_loss 2.34475, chxp_prc_auc 0.74816, iufg_att_reg_loss 0.28087, iufg_phrcls_loss 0.36020, iufg_prc_auc 0.31868, cxrlt2024c_att_reg_loss 0.22954, cxrlt2024c_phrcls_loss 0.89620, cxrlt2024c_prc_auc 0.74096, 810.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13481, cxrlt2024c_phrcls_loss 0.52554, cxrlt2024c_prc_auc 0.74422, 178.13 secs\n",
      "\u001b[1m---- Epoch 20/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.37980, mimfg_att_reg_loss 0.20877, mimfg_phrcls_loss 0.94436, mimfg_prc_auc 0.90891, cibg_att_sup_loss 0.58294, cibg_segmask_iou 0.29962, vbg_phrcls_loss 1.65978, vbg_prc_auc 0.49557, vbg_att_reg_loss 0.11161, vbg_att_sup_loss 0.45284, vbg_segmask_iou 0.15566, cl_att_sup_loss 0.39625, cl_segmask_iou 0.33068, cl_phrcls_loss 1.38137, cl_phrase_acc 0.92660, chxp_att_reg_loss 0.27100, chxp_phrcls_loss 2.46698, chxp_prc_auc 0.70553, iufg_att_reg_loss 0.27545, iufg_phrcls_loss 0.37001, iufg_prc_auc 0.31456, cxrlt2024c_att_reg_loss 0.24267, cxrlt2024c_phrcls_loss 0.99057, cxrlt2024c_prc_auc 0.69509, 809.45 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13962, cxrlt2024c_phrcls_loss 0.54939, cxrlt2024c_prc_auc 0.72198, 178.27 secs\n",
      "\u001b[1m---- Epoch 21/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.30529, mimfg_att_reg_loss 0.20649, mimfg_phrcls_loss 0.92245, mimfg_prc_auc 0.91412, cibg_att_sup_loss 0.56368, cibg_segmask_iou 0.30437, vbg_phrcls_loss 1.55292, vbg_prc_auc 0.55310, vbg_att_reg_loss 0.10076, vbg_att_sup_loss 0.40718, vbg_segmask_iou 0.16224, cl_att_sup_loss 0.34946, cl_segmask_iou 0.33488, cl_phrcls_loss 1.23439, cl_phrase_acc 0.94131, chxp_att_reg_loss 0.25931, chxp_phrcls_loss 2.42600, chxp_prc_auc 0.72868, iufg_att_reg_loss 0.28349, iufg_phrcls_loss 0.36185, iufg_prc_auc 0.31577, cxrlt2024c_att_reg_loss 0.23296, cxrlt2024c_phrcls_loss 0.92567, cxrlt2024c_prc_auc 0.72408, 810.21 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.13391, cxrlt2024c_phrcls_loss 0.53470, cxrlt2024c_prc_auc 0.73728, 178.05 secs\n",
      "\u001b[1m---- Epoch 22/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.26534, mimfg_att_reg_loss 0.20622, mimfg_phrcls_loss 0.91130, mimfg_prc_auc 0.91502, cibg_att_sup_loss 0.55628, cibg_segmask_iou 0.30657, vbg_phrcls_loss 1.45204, vbg_prc_auc 0.60644, vbg_att_reg_loss 0.09326, vbg_att_sup_loss 0.36571, vbg_segmask_iou 0.16616, cl_att_sup_loss 0.32626, cl_segmask_iou 0.33399, cl_phrcls_loss 1.08857, cl_phrase_acc 0.95059, chxp_att_reg_loss 0.25510, chxp_phrcls_loss 2.39946, chxp_prc_auc 0.74627, iufg_att_reg_loss 0.26429, iufg_phrcls_loss 0.33477, iufg_prc_auc 0.34242, cxrlt2024c_att_reg_loss 0.23126, cxrlt2024c_phrcls_loss 0.92302, cxrlt2024c_prc_auc 0.71851, 804.45 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13580, cxrlt2024c_phrcls_loss 0.52197, cxrlt2024c_prc_auc 0.74482, 178.21 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7407.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.25055, mimfg_att_reg_loss 0.20778, mimfg_phrcls_loss 0.91243, mimfg_prc_auc 0.91464, cibg_att_sup_loss 0.55891, cibg_segmask_iou 0.30622, vbg_phrcls_loss 1.41147, vbg_prc_auc 0.61889, vbg_att_reg_loss 0.09003, vbg_att_sup_loss 0.35924, vbg_segmask_iou 0.16762, cl_att_sup_loss 0.32186, cl_segmask_iou 0.32861, cl_phrcls_loss 1.05105, cl_phrase_acc 0.95796, chxp_att_reg_loss 0.25745, chxp_phrcls_loss 2.39614, chxp_prc_auc 0.74741, iufg_att_reg_loss 0.26420, iufg_phrcls_loss 0.32469, iufg_prc_auc 0.35353, cxrlt2024c_att_reg_loss 0.22710, cxrlt2024c_phrcls_loss 0.91428, cxrlt2024c_prc_auc 0.71545, 810.72 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13524, cxrlt2024c_phrcls_loss 0.52377, cxrlt2024c_prc_auc 0.74425, 178.21 secs\n",
      "\u001b[1m---- Epoch 24/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.23981, mimfg_att_reg_loss 0.20778, mimfg_phrcls_loss 0.91607, mimfg_prc_auc 0.91333, cibg_att_sup_loss 0.55362, cibg_segmask_iou 0.30776, vbg_phrcls_loss 1.39187, vbg_prc_auc 0.62897, vbg_att_reg_loss 0.09033, vbg_att_sup_loss 0.35769, vbg_segmask_iou 0.16853, cl_att_sup_loss 0.32156, cl_segmask_iou 0.33533, cl_phrcls_loss 1.04896, cl_phrase_acc 0.95646, chxp_att_reg_loss 0.25217, chxp_phrcls_loss 2.39753, chxp_prc_auc 0.73349, iufg_att_reg_loss 0.27074, iufg_phrcls_loss 0.32820, iufg_prc_auc 0.34515, cxrlt2024c_att_reg_loss 0.22431, cxrlt2024c_phrcls_loss 0.89729, cxrlt2024c_prc_auc 0.75968, 798.22 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13431, cxrlt2024c_phrcls_loss 0.52289, cxrlt2024c_prc_auc 0.74514, 178.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7420.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.35288, mimfg_att_reg_loss 0.21237, mimfg_phrcls_loss 0.95614, mimfg_prc_auc 0.90553, cibg_att_sup_loss 0.58113, cibg_segmask_iou 0.30111, vbg_phrcls_loss 1.57994, vbg_prc_auc 0.54175, vbg_att_reg_loss 0.10029, vbg_att_sup_loss 0.42357, vbg_segmask_iou 0.15965, cl_att_sup_loss 0.36879, cl_segmask_iou 0.34143, cl_phrcls_loss 1.22485, cl_phrase_acc 0.94192, chxp_att_reg_loss 0.26096, chxp_phrcls_loss 2.49538, chxp_prc_auc 0.69819, iufg_att_reg_loss 0.27991, iufg_phrcls_loss 0.37022, iufg_prc_auc 0.29552, cxrlt2024c_att_reg_loss 0.24128, cxrlt2024c_phrcls_loss 0.98375, cxrlt2024c_prc_auc 0.70417, 798.64 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.14249, cxrlt2024c_phrcls_loss 0.55069, cxrlt2024c_prc_auc 0.71557, 179.18 secs\n",
      "\u001b[1m---- Epoch 26/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.33222, mimfg_att_reg_loss 0.20313, mimfg_phrcls_loss 0.92437, mimfg_prc_auc 0.91397, cibg_att_sup_loss 0.55624, cibg_segmask_iou 0.30636, vbg_phrcls_loss 1.45069, vbg_prc_auc 0.61584, vbg_att_reg_loss 0.09382, vbg_att_sup_loss 0.36758, vbg_segmask_iou 0.16610, cl_att_sup_loss 0.32558, cl_segmask_iou 0.32955, cl_phrcls_loss 1.12937, cl_phrase_acc 0.95451, chxp_att_reg_loss 0.25192, chxp_phrcls_loss 2.46711, chxp_prc_auc 0.71204, iufg_att_reg_loss 0.28073, iufg_phrcls_loss 0.34996, iufg_prc_auc 0.31372, cxrlt2024c_att_reg_loss 0.25769, cxrlt2024c_phrcls_loss 1.03148, cxrlt2024c_prc_auc 0.72335, 824.45 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13492, cxrlt2024c_phrcls_loss 0.52749, cxrlt2024c_prc_auc 0.74361, 186.73 secs\n",
      "\u001b[1m---- Epoch 27/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.28767, mimfg_att_reg_loss 0.20549, mimfg_phrcls_loss 0.91777, mimfg_prc_auc 0.91634, cibg_att_sup_loss 0.54226, cibg_segmask_iou 0.30962, vbg_phrcls_loss 1.35035, vbg_prc_auc 0.65211, vbg_att_reg_loss 0.08459, vbg_att_sup_loss 0.34028, vbg_segmask_iou 0.16868, cl_att_sup_loss 0.32882, cl_segmask_iou 0.33826, cl_phrcls_loss 0.97329, cl_phrase_acc 0.96185, chxp_att_reg_loss 0.23549, chxp_phrcls_loss 2.36278, chxp_prc_auc 0.75134, iufg_att_reg_loss 0.26676, iufg_phrcls_loss 0.34133, iufg_prc_auc 0.33394, cxrlt2024c_att_reg_loss 0.25133, cxrlt2024c_phrcls_loss 1.02168, cxrlt2024c_prc_auc 0.71921, 829.96 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13140, cxrlt2024c_phrcls_loss 0.52453, cxrlt2024c_prc_auc 0.74504, 180.06 secs\n",
      "\u001b[1m---- Epoch 28/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.28064, mimfg_att_reg_loss 0.20499, mimfg_phrcls_loss 0.92110, mimfg_prc_auc 0.91506, cibg_att_sup_loss 0.53854, cibg_segmask_iou 0.31108, vbg_phrcls_loss 1.32364, vbg_prc_auc 0.66893, vbg_att_reg_loss 0.08465, vbg_att_sup_loss 0.32141, vbg_segmask_iou 0.17067, cl_att_sup_loss 0.29203, cl_segmask_iou 0.34382, cl_phrcls_loss 0.91486, cl_phrase_acc 0.96734, chxp_att_reg_loss 0.23671, chxp_phrcls_loss 2.37010, chxp_prc_auc 0.73736, iufg_att_reg_loss 0.26737, iufg_phrcls_loss 0.32908, iufg_prc_auc 0.33038, cxrlt2024c_att_reg_loss 0.25493, cxrlt2024c_phrcls_loss 1.02958, cxrlt2024c_prc_auc 0.71298, 810.73 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13078, cxrlt2024c_phrcls_loss 0.52774, cxrlt2024c_prc_auc 0.74772, 178.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7430.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.28045, mimfg_att_reg_loss 0.20454, mimfg_phrcls_loss 0.91768, mimfg_prc_auc 0.91615, cibg_att_sup_loss 0.54316, cibg_segmask_iou 0.31210, vbg_phrcls_loss 1.29618, vbg_prc_auc 0.67924, vbg_att_reg_loss 0.08091, vbg_att_sup_loss 0.32981, vbg_segmask_iou 0.17374, cl_att_sup_loss 0.29283, cl_segmask_iou 0.33763, cl_phrcls_loss 0.88171, cl_phrase_acc 0.96925, chxp_att_reg_loss 0.22724, chxp_phrcls_loss 2.29497, chxp_prc_auc 0.75917, iufg_att_reg_loss 0.26801, iufg_phrcls_loss 0.33409, iufg_prc_auc 0.33573, cxrlt2024c_att_reg_loss 0.25997, cxrlt2024c_phrcls_loss 1.04749, cxrlt2024c_prc_auc 0.73837, 812.85 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13047, cxrlt2024c_phrcls_loss 0.52393, cxrlt2024c_prc_auc 0.74788, 179.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_29_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7440.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 30/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.33105, mimfg_att_reg_loss 0.20378, mimfg_phrcls_loss 0.92279, mimfg_prc_auc 0.91410, cibg_att_sup_loss 0.53488, cibg_segmask_iou 0.31360, vbg_phrcls_loss 1.43180, vbg_prc_auc 0.61550, vbg_att_reg_loss 0.08855, vbg_att_sup_loss 0.36672, vbg_segmask_iou 0.16501, cl_att_sup_loss 0.31276, cl_segmask_iou 0.33904, cl_phrcls_loss 0.97747, cl_phrase_acc 0.95951, chxp_att_reg_loss 0.24092, chxp_phrcls_loss 2.47122, chxp_prc_auc 0.71841, iufg_att_reg_loss 0.28017, iufg_phrcls_loss 0.37298, iufg_prc_auc 0.33023, cxrlt2024c_att_reg_loss 0.26534, cxrlt2024c_phrcls_loss 1.05023, cxrlt2024c_prc_auc 0.75800, 818.55 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13071, cxrlt2024c_phrcls_loss 0.54607, cxrlt2024c_prc_auc 0.74594, 178.35 secs\n",
      "\u001b[1m---- Epoch 31/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.18458, mimfg_att_reg_loss 0.20347, mimfg_phrcls_loss 0.90572, mimfg_prc_auc 0.91524, cibg_att_sup_loss 0.53516, cibg_segmask_iou 0.31360, vbg_phrcls_loss 1.34029, vbg_prc_auc 0.64791, vbg_att_reg_loss 0.08132, vbg_att_sup_loss 0.34440, vbg_segmask_iou 0.17136, cl_att_sup_loss 0.30201, cl_segmask_iou 0.32679, cl_phrcls_loss 0.81981, cl_phrase_acc 0.96947, chxp_att_reg_loss 0.22990, chxp_phrcls_loss 2.30608, chxp_prc_auc 0.74702, iufg_att_reg_loss 0.26161, iufg_phrcls_loss 0.33874, iufg_prc_auc 0.34190, cxrlt2024c_att_reg_loss 0.21942, cxrlt2024c_phrcls_loss 0.85010, cxrlt2024c_prc_auc 0.79019, 811.27 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.13037, cxrlt2024c_phrcls_loss 0.52213, cxrlt2024c_prc_auc 0.75003, 178.14 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_31_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7467.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 32/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.13081, mimfg_att_reg_loss 0.20690, mimfg_phrcls_loss 0.90336, mimfg_prc_auc 0.91393, cibg_att_sup_loss 0.53018, cibg_segmask_iou 0.31709, vbg_phrcls_loss 1.23178, vbg_prc_auc 0.71328, vbg_att_reg_loss 0.07787, vbg_att_sup_loss 0.31695, vbg_segmask_iou 0.17174, cl_att_sup_loss 0.27960, cl_segmask_iou 0.32544, cl_phrcls_loss 0.68939, cl_phrase_acc 0.97746, chxp_att_reg_loss 0.22335, chxp_phrcls_loss 2.34698, chxp_prc_auc 0.74387, iufg_att_reg_loss 0.26329, iufg_phrcls_loss 0.31535, iufg_prc_auc 0.36132, cxrlt2024c_att_reg_loss 0.20882, cxrlt2024c_phrcls_loss 0.80127, cxrlt2024c_prc_auc 0.81161, 810.09 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12891, cxrlt2024c_phrcls_loss 0.51486, cxrlt2024c_prc_auc 0.75069, 178.84 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7488.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.10809, mimfg_att_reg_loss 0.20205, mimfg_phrcls_loss 0.88104, mimfg_prc_auc 0.91906, cibg_att_sup_loss 0.52547, cibg_segmask_iou 0.31786, vbg_phrcls_loss 1.17902, vbg_prc_auc 0.72256, vbg_att_reg_loss 0.07475, vbg_att_sup_loss 0.30544, vbg_segmask_iou 0.17690, cl_att_sup_loss 0.26335, cl_segmask_iou 0.33447, cl_phrcls_loss 0.60607, cl_phrase_acc 0.98407, chxp_att_reg_loss 0.22313, chxp_phrcls_loss 2.34687, chxp_prc_auc 0.75543, iufg_att_reg_loss 0.26128, iufg_phrcls_loss 0.31105, iufg_prc_auc 0.35441, cxrlt2024c_att_reg_loss 0.20307, cxrlt2024c_phrcls_loss 0.80077, cxrlt2024c_prc_auc 0.79199, 811.14 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12914, cxrlt2024c_phrcls_loss 0.51357, cxrlt2024c_prc_auc 0.75154, 178.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_33_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7493.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 34/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.09928, mimfg_att_reg_loss 0.20194, mimfg_phrcls_loss 0.88551, mimfg_prc_auc 0.91795, cibg_att_sup_loss 0.52724, cibg_segmask_iou 0.31822, vbg_phrcls_loss 1.15455, vbg_prc_auc 0.73776, vbg_att_reg_loss 0.07209, vbg_att_sup_loss 0.30498, vbg_segmask_iou 0.17443, cl_att_sup_loss 0.26446, cl_segmask_iou 0.32866, cl_phrcls_loss 0.59539, cl_phrase_acc 0.98658, chxp_att_reg_loss 0.22165, chxp_phrcls_loss 2.32711, chxp_prc_auc 0.74943, iufg_att_reg_loss 0.26552, iufg_phrcls_loss 0.32721, iufg_prc_auc 0.34823, cxrlt2024c_att_reg_loss 0.20609, cxrlt2024c_phrcls_loss 0.78665, cxrlt2024c_prc_auc 0.78740, 807.09 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12934, cxrlt2024c_phrcls_loss 0.51481, cxrlt2024c_prc_auc 0.75179, 178.82 secs\n",
      "\u001b[1m---- Epoch 35/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.21854, mimfg_att_reg_loss 0.20506, mimfg_phrcls_loss 0.91293, mimfg_prc_auc 0.91337, cibg_att_sup_loss 0.55548, cibg_segmask_iou 0.30877, vbg_phrcls_loss 1.37220, vbg_prc_auc 0.64322, vbg_att_reg_loss 0.08629, vbg_att_sup_loss 0.36856, vbg_segmask_iou 0.16695, cl_att_sup_loss 0.32774, cl_segmask_iou 0.32240, cl_phrcls_loss 0.88137, cl_phrase_acc 0.96162, chxp_att_reg_loss 0.22872, chxp_phrcls_loss 2.38322, chxp_prc_auc 0.73228, iufg_att_reg_loss 0.27257, iufg_phrcls_loss 0.34595, iufg_prc_auc 0.31135, cxrlt2024c_att_reg_loss 0.22302, cxrlt2024c_phrcls_loss 0.87702, cxrlt2024c_prc_auc 0.76379, 814.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12983, cxrlt2024c_phrcls_loss 0.53301, cxrlt2024c_prc_auc 0.73682, 179.29 secs\n",
      "\u001b[1m---- Epoch 36/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.14727, mimfg_att_reg_loss 0.20658, mimfg_phrcls_loss 0.90287, mimfg_prc_auc 0.91459, cibg_att_sup_loss 0.52294, cibg_segmask_iou 0.31563, vbg_phrcls_loss 1.24240, vbg_prc_auc 0.70254, vbg_att_reg_loss 0.07469, vbg_att_sup_loss 0.32559, vbg_segmask_iou 0.16930, cl_att_sup_loss 0.29057, cl_segmask_iou 0.31856, cl_phrcls_loss 0.69829, cl_phrase_acc 0.97791, chxp_att_reg_loss 0.22078, chxp_phrcls_loss 2.33808, chxp_prc_auc 0.75241, iufg_att_reg_loss 0.26296, iufg_phrcls_loss 0.33117, iufg_prc_auc 0.35009, cxrlt2024c_att_reg_loss 0.21220, cxrlt2024c_phrcls_loss 0.82921, cxrlt2024c_prc_auc 0.80759, 812.74 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12712, cxrlt2024c_phrcls_loss 0.52316, cxrlt2024c_prc_auc 0.74889, 179.66 secs\n",
      "\u001b[1m---- Epoch 37/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.10871, mimfg_att_reg_loss 0.20301, mimfg_phrcls_loss 0.89968, mimfg_prc_auc 0.91497, cibg_att_sup_loss 0.51487, cibg_segmask_iou 0.31960, vbg_phrcls_loss 1.14683, vbg_prc_auc 0.75168, vbg_att_reg_loss 0.07065, vbg_att_sup_loss 0.30581, vbg_segmask_iou 0.17387, cl_att_sup_loss 0.27081, cl_segmask_iou 0.32468, cl_phrcls_loss 0.55997, cl_phrase_acc 0.98545, chxp_att_reg_loss 0.21051, chxp_phrcls_loss 2.36265, chxp_prc_auc 0.75248, iufg_att_reg_loss 0.26372, iufg_phrcls_loss 0.32632, iufg_prc_auc 0.35759, cxrlt2024c_att_reg_loss 0.20752, cxrlt2024c_phrcls_loss 0.80830, cxrlt2024c_prc_auc 0.79541, 814.21 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12919, cxrlt2024c_phrcls_loss 0.51522, cxrlt2024c_prc_auc 0.75408, 181.19 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_37_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7509.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 38/130\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "^C iteration 75325\n",
      "Exception in thread Thread-465 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\" \\\n",
    "--epochs 130 \\\n",
    "--batches_per_epoch 2000 \\\n",
    "--max_images_per_batch 10 \\\n",
    "--max_phrases_per_batch 400 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 5.0 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino\" \\\n",
    "--img_aug_mode \"random-color\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"film_layers_plus_sigmoid_attention_and_custom_classifier\" \\\n",
    "--visual_feature_proj_size 256 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce\" \\\n",
    "--use_attention_regularization_loss \\\n",
    "--attention_supervision_loss_weight 2.0 \\\n",
    "--phrase_classifier_loss_weight 2.0 \\\n",
    "--foreground_loss_weight 1.5 \\\n",
    "--use_cxrlt2024_challenge_split \\\n",
    "--use_cxrlt2024_custom_labels \\\n",
    "--cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--mimiccxr_report_fact_nli_integrated_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--use_chest_imagenome_for_train \\\n",
    "--chest_imagenome_bbox_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\" \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--use_vinbig_for_train \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\" \\\n",
    "--vinbig_training_data_mode \"all\" \\\n",
    "--use_chexlocalize_for_train \\\n",
    "--chexlocalize_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\" \\\n",
    "--use_chexpert_for_train \\\n",
    "--chexpert_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\" \\\n",
    "--use_iuxray_for_train \\\n",
    "--iuxray_image_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\" \\\n",
    "--cxrlt2024_weight 4.0 \\\n",
    "--mimiccxr_facts_weight 1.5 \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--iuxray_weight 0.5 \\\n",
    "--vinbig_weight 1.5 \\\n",
    "--chexpert_weight 0.5 \\\n",
    "--chexlocalize_weight 0.4 \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdba2a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 95\n",
      "   batches_per_epoch: 2000\n",
      "   max_images_per_batch: 10\n",
      "   max_phrases_per_batch: 400\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 5.0\n",
      "   checkpoint_folder: models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: film_layers_plus_sigmoid_attention_and_custom_classifier\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: 256\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 2.0\n",
      "   phrase_classifier_loss_weight: 2.0\n",
      "   foreground_loss_weight: 1.5\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: True\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\n",
      "   chexpert_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 1.5\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 4.0\n",
      "   vinbig_weight: 1.5\n",
      "   chexlocalize_weight: 0.4\n",
      "   chexpert_weight: 0.5\n",
      "   iuxray_weight: 0.5\n",
      "   img_aug_mode: random-color\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: True\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: True\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: True\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: True\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: True\n",
      "   use_cxrlt2024_custom_labels: True\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   vinbig_training_data_mode: all\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240723_194207_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.5\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_Loss(): focal_weight = 0.5 bce_weight = 0.5\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating CheXLocalize Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loding class_phrase_embeddings_filepath and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl...\n",
      "class_phrase_embeddings.shape = (10, 128)\n",
      "len(class_phrases) = 10\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t airspace opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t support devices seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without masks: 216/902\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 902\n",
      "batch_size = 10\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating CheXpert Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train_visualCheXbert.csv\n",
      "len(df_train_visualchexbert) = 223414\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/valid.csv\n",
      "len(df_valid) = 234\n",
      "len(df) = 223648\n",
      "Loading images\n",
      "Loading chexpert labels\n",
      "Loading test set\n",
      "len(self.test_image_paths) = 668\n",
      "self.test_labels.shape = (668, 14)\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl...\n",
      "phrase_embeddings.shape = (14, 128)\n",
      "len(phrases) = 14\n",
      "\t no findings\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t lung opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t pneumonia seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t other pleural abnormality seen\n",
      "\t fracture seen\n",
      "\t support devices seen\n",
      "len(all_image_paths) = 224316\n",
      "all_labels.shape = (224316, 14)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 224316\n",
      "No labels: 3246\n",
      "Pneumothorax: 25357\n",
      "Pleural Other: 26334\n",
      "Lung Lesion: 31042\n",
      "No Finding: 35673\n",
      "Pneumonia: 52248\n",
      "Fracture: 61696\n",
      "Edema: 94500\n",
      "Pleural Effusion: 103837\n",
      "Consolidation: 107297\n",
      "Cardiomegaly: 122164\n",
      "Atelectasis: 124182\n",
      "Support Devices: 136382\n",
      "Enlarged Cardiomediastinum: 144377\n",
      "Lung Opacity: 151937\n",
      "Group sizes: [61397, 30579, 25357, 21626, 18526, 17225, 11525, 11092, 10885, 7083, 4085, 3246, 1170, 347, 173]\n",
      "  len(indices) = 61397, weight = 4024.1406302660666\n",
      "  len(indices) = 30579, weight = 3308.1179132413095\n",
      "  len(indices) = 25357, weight = 3131.4217784165476\n",
      "  len(indices) = 21626, weight = 2986.2821261955132\n",
      "  len(indices) = 18526, weight = 2849.5564265118087\n",
      "  len(indices) = 17225, weight = 2786.68263628706\n",
      "  len(indices) = 11525, weight = 2456.265254834705\n",
      "  len(indices) = 11092, weight = 2426.215857884437\n",
      "  len(indices) = 10885, weight = 2411.5238383991996\n",
      "  len(indices) = 7083, weight = 2092.3117139635237\n",
      "  len(indices) = 4085, weight = 1726.3245386288693\n",
      "  len(indices) = 3246, weight = 1587.0568876515586\n",
      "  len(indices) = 1170, weight = 1058.8042504564921\n",
      "  len(indices) = 347, weight = 600.9534388852762\n",
      "  len(indices) = 173, weight = 410.9393870934724\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n",
      "self.phrase_grounding_masks.shape = (18000, 22, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 18000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 29\n",
      "Lung cyst: 35\n",
      "COPD: 37\n",
      "Lung cavity: 60\n",
      "Emphysema: 84\n",
      "Rib fracture: 101\n",
      "Pneumothorax: 114\n",
      "Enlarged PA: 139\n",
      "Mediastinal shift: 170\n",
      "Atelectasis: 273\n",
      "Lung tumor: 371\n",
      "Consolidation: 449\n",
      "ILD: 618\n",
      "Calcification: 652\n",
      "Infiltration: 671\n",
      "Tuberculosis: 914\n",
      "Nodule/Mass: 1017\n",
      "Pleural effusion: 1149\n",
      "Pneumonia: 1163\n",
      "Other lesion: 1248\n",
      "Lung Opacity: 1415\n",
      "Pulmonary fibrosis: 1838\n",
      "Pleural thickening: 2179\n",
      "Cardiomegaly: 2625\n",
      "Aortic enlargement: 3318\n",
      "Other disease: 4945\n",
      "No finding: 12652\n",
      "Group sizes: [12529, 891, 444, 428, 364, 344, 307, 283, 273, 267, 245, 236, 206, 193, 170, 138, 127, 100, 99, 90, 56, 54, 49, 34, 73]\n",
      "  len(indices) = 12529, weight = 2522.6672479595745\n",
      "  len(indices) = 891, weight = 940.9850359649141\n",
      "  len(indices) = 444, weight = 680.1755171156125\n",
      "  len(indices) = 428, weight = 667.9638591411331\n",
      "  len(indices) = 364, weight = 615.8160380252455\n",
      "  len(indices) = 344, weight = 598.2811252947056\n",
      "  len(indices) = 307, weight = 563.9888635691133\n",
      "  len(indices) = 283, weight = 540.2796339164162\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 267, weight = 523.7422583945496\n",
      "  len(indices) = 245, weight = 499.93058392418243\n",
      "  len(indices) = 236, weight = 489.7963928535281\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 193, weight = 437.6702522239849\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 138, weight = 359.20170201154343\n",
      "  len(indices) = 127, weight = 341.33933626931963\n",
      "  len(indices) = 100, weight = 293.26529386579296\n",
      "  len(indices) = 99, weight = 291.34941227248714\n",
      "  len(indices) = 90, weight = 273.5936736738282\n",
      "  len(indices) = 56, weight = 195.85520038280242\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 34, weight = 131.67512839151652\n",
      "  len(indices) = 73, weight = 237.15649291307946\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "len(cxrlt2024_train_dicom_ids) = 258871\n",
      "len(cxrlt2024_dev_dicom_ids) = 39293\n",
      "len(forbidden_train_dicom_ids) = 40220\n",
      "\u001b[1m\u001b[35mPreparing CXR-LT-2024 challenge datasets and dataloaders for training/testing...\u001b[0m\n",
      "Using image size mode: medium_512\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"train\"]) = 128427\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"dev\"]) = 13136\n",
      "Total number of images: 141230\n",
      "\u001b[1mBuilding cxrlt2024 train phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 1, len(indices) = 85554\n",
      "num_phrases = 2, len(indices) = 30817\n",
      "num_phrases = 3, len(indices) = 8659\n",
      "num_phrases = 4, len(indices) = 2127\n",
      "num_phrases = 8, len(indices) = 104\n",
      "num_phrases = 5, len(indices) = 567\n",
      "num_phrases = 14, len(indices) = 97\n",
      "num_phrases = 6, len(indices) = 116\n",
      "num_phrases = 10, len(indices) = 45\n",
      "num_phrases = 7, len(indices) = 8\n",
      "\u001b[1mBuilding cxrlt2024 dev phrase classifier dataloader...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_phrases = 1, len(indices) = 10269\n",
      "num_phrases = 2, len(indices) = 2268\n",
      "num_phrases = 3, len(indices) = 404\n",
      "num_phrases = 8, len(indices) = 28\n",
      "num_phrases = 14, len(indices) = 54\n",
      "num_phrases = 4, len(indices) = 80\n",
      "num_phrases = 10, len(indices) = 12\n",
      "num_phrases = 5, len(indices) = 21\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596394, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 192131.73it/s]\n",
      "Total number of images: 258164\n",
      "len(train_indices) = 258164\n",
      "avg_facts_per_image = 81.27329914318031\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 8\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 32271\n",
      "\u001b[1m\u001b[35mPreparing Chest Imagenome dataset and dataloader for training...\u001b[0m\n",
      "Loding bbox_phrase_embeddings and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl...\n",
      "bbox_phrase_embeddings.shape = (36, 128)\n",
      "len(bbox_phrases) = 36\n",
      "\t right lung\n",
      "\t right upper lung zone\n",
      "\t right mid lung zone\n",
      "\t right lower lung zone\n",
      "\t right hilar structures\n",
      "\t right apical zone\n",
      "\t right costophrenic angle\n",
      "\t right cardiophrenic angle\n",
      "\t right hemidiaphragm\n",
      "\t left lung\n",
      "\t left upper lung zone\n",
      "\t left mid lung zone\n",
      "\t left lower lung zone\n",
      "\t left hilar structures\n",
      "\t left apical zone\n",
      "\t left costophrenic angle\n",
      "\t left hemidiaphragm\n",
      "\t trachea\n",
      "\t spine\n",
      "\t right clavicle\n",
      "\t left clavicle\n",
      "\t aortic arch\n",
      "\t mediastinum\n",
      "\t upper mediastinum\n",
      "\t svc\n",
      "\t cardiac silhouette\n",
      "\t left cardiac silhouette\n",
      "\t right cardiac silhouette\n",
      "\t cavoatrial junction\n",
      "\t right atrium\n",
      "\t descending aorta\n",
      "\t carina\n",
      "\t left upper abdomen\n",
      "\t right upper abdomen\n",
      "\t abdomen\n",
      "\t left cardiophrenic angle\n",
      "Using image size mode: medium_512\n",
      "\u001b[1mLoading precomputed bbox_coords_and_presence_and_mask from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/bbox_coords_and_presence_and_mask(29,29,243310).pkl...\u001b[0m\n",
      "File size: 7553074787 bytes (7376049.60 KB, 7203.17 MB, 7.03 GB)\n",
      "227835it [00:01, 211186.56it/s]\n",
      "Total number of images: 165768\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mCreating IU X-Ray Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "len(final_transforms) = 4\n",
      "default_prob = 0.5\n",
      "Returning augmented transforms with mode random-color\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [416, 416], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[1mPreparing data for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (2331, 128)\n",
      "Number of invalid images removed: 111\n",
      "avg_facts_per_image = 2327.3329256692487\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train dataloader...\u001b[0m\n",
      "len(self.train_dataloader) = 920\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 32271\n",
      "len(mimiccxr_trainer.train_chest_imagenome_dataloader) = 16577\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_train_dataloader) = 12813\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_dev_dataloader) = 268\n",
      "len(vinbig_trainer.train_dataloader) = 100000000000000000\n",
      "len(chexlocalize_trainer.train_dataloader) = 91\n",
      "len(chexpert_trainer.train_dataloader) = 100000000000000000\n",
      "len(iuxray_trainer.train_dataloader) = 920\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.5, 1.0, 4.0, 1.5, 0.4, 0.5, 0.5]\n",
      "merged_dataset_name = mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_37_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7509.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/checkpoint_37_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7509.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m16) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m17) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 38/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.03496, mimfg_att_reg_loss 0.20470, mimfg_phrcls_loss 0.89351, mimfg_prc_auc 0.91569, cibg_att_sup_loss 0.52366, cibg_segmask_iou 0.31891, vbg_phrcls_loss 1.07479, vbg_prc_auc 0.77114, vbg_att_reg_loss 0.06732, vbg_att_sup_loss 0.29281, vbg_segmask_iou 0.17715, cl_att_sup_loss 0.26010, cl_segmask_iou 0.33015, cl_phrcls_loss 0.49983, cl_phrase_acc 0.98893, chxp_att_reg_loss 0.20210, chxp_phrcls_loss 2.26006, chxp_prc_auc 0.76212, iufg_att_reg_loss 0.26540, iufg_phrcls_loss 0.31344, iufg_prc_auc 0.34023, cxrlt2024c_att_reg_loss 0.18857, cxrlt2024c_phrcls_loss 0.70858, cxrlt2024c_prc_auc 0.84984, 812.01 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12962, cxrlt2024c_phrcls_loss 0.51250, cxrlt2024c_prc_auc 0.75415, 178.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_38_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7526.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 39/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.03328, mimfg_att_reg_loss 0.20057, mimfg_phrcls_loss 0.87509, mimfg_prc_auc 0.91921, cibg_att_sup_loss 0.52470, cibg_segmask_iou 0.31827, vbg_phrcls_loss 1.06500, vbg_prc_auc 0.78611, vbg_att_reg_loss 0.06576, vbg_att_sup_loss 0.28853, vbg_segmask_iou 0.17524, cl_att_sup_loss 0.25383, cl_segmask_iou 0.32470, cl_phrcls_loss 0.46778, cl_phrase_acc 0.99061, chxp_att_reg_loss 0.20605, chxp_phrcls_loss 2.33173, chxp_prc_auc 0.74596, iufg_att_reg_loss 0.26606, iufg_phrcls_loss 0.31937, iufg_prc_auc 0.36562, cxrlt2024c_att_reg_loss 0.19326, cxrlt2024c_phrcls_loss 0.70652, cxrlt2024c_prc_auc 0.85723, 814.50 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12949, cxrlt2024c_phrcls_loss 0.51362, cxrlt2024c_prc_auc 0.75407, 178.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7527.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.14228, mimfg_att_reg_loss 0.20397, mimfg_phrcls_loss 0.90440, mimfg_prc_auc 0.91387, cibg_att_sup_loss 0.53815, cibg_segmask_iou 0.31793, vbg_phrcls_loss 1.28844, vbg_prc_auc 0.67920, vbg_att_reg_loss 0.07815, vbg_att_sup_loss 0.36127, vbg_segmask_iou 0.16853, cl_att_sup_loss 0.31737, cl_segmask_iou 0.32051, cl_phrcls_loss 0.72732, cl_phrase_acc 0.97136, chxp_att_reg_loss 0.21770, chxp_phrcls_loss 2.36891, chxp_prc_auc 0.73474, iufg_att_reg_loss 0.26596, iufg_phrcls_loss 0.33456, iufg_prc_auc 0.32307, cxrlt2024c_att_reg_loss 0.20600, cxrlt2024c_phrcls_loss 0.78216, cxrlt2024c_prc_auc 0.79947, 813.28 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12789, cxrlt2024c_phrcls_loss 0.54105, cxrlt2024c_prc_auc 0.73899, 180.03 secs\n",
      "\u001b[1m---- Epoch 41/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.08664, mimfg_att_reg_loss 0.20404, mimfg_phrcls_loss 0.89341, mimfg_prc_auc 0.91534, cibg_att_sup_loss 0.51982, cibg_segmask_iou 0.32572, vbg_phrcls_loss 1.15814, vbg_prc_auc 0.74039, vbg_att_reg_loss 0.07018, vbg_att_sup_loss 0.31211, vbg_segmask_iou 0.17224, cl_att_sup_loss 0.26750, cl_segmask_iou 0.31726, cl_phrcls_loss 0.56331, cl_phrase_acc 0.98337, chxp_att_reg_loss 0.20670, chxp_phrcls_loss 2.38771, chxp_prc_auc 0.73861, iufg_att_reg_loss 0.26370, iufg_phrcls_loss 0.32594, iufg_prc_auc 0.33339, cxrlt2024c_att_reg_loss 0.19432, cxrlt2024c_phrcls_loss 0.75951, cxrlt2024c_prc_auc 0.82393, 816.76 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12794, cxrlt2024c_phrcls_loss 0.52360, cxrlt2024c_prc_auc 0.74370, 180.44 secs\n",
      "\u001b[1m---- Epoch 42/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.03956, mimfg_att_reg_loss 0.20118, mimfg_phrcls_loss 0.88467, mimfg_prc_auc 0.91750, cibg_att_sup_loss 0.51811, cibg_segmask_iou 0.32495, vbg_phrcls_loss 1.05372, vbg_prc_auc 0.78086, vbg_att_reg_loss 0.06302, vbg_att_sup_loss 0.28913, vbg_segmask_iou 0.17506, cl_att_sup_loss 0.26293, cl_segmask_iou 0.32272, cl_phrcls_loss 0.45662, cl_phrase_acc 0.98897, chxp_att_reg_loss 0.19951, chxp_phrcls_loss 2.25584, chxp_prc_auc 0.76820, iufg_att_reg_loss 0.26444, iufg_phrcls_loss 0.33927, iufg_prc_auc 0.32540, cxrlt2024c_att_reg_loss 0.19267, cxrlt2024c_phrcls_loss 0.73545, cxrlt2024c_prc_auc 0.84677, 816.44 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12651, cxrlt2024c_phrcls_loss 0.52787, cxrlt2024c_prc_auc 0.74493, 180.03 secs\n",
      "\u001b[1m---- Epoch 43/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.02169, mimfg_att_reg_loss 0.20159, mimfg_phrcls_loss 0.88728, mimfg_prc_auc 0.91617, cibg_att_sup_loss 0.51413, cibg_segmask_iou 0.32429, vbg_phrcls_loss 1.00676, vbg_prc_auc 0.81977, vbg_att_reg_loss 0.05996, vbg_att_sup_loss 0.28299, vbg_segmask_iou 0.17773, cl_att_sup_loss 0.24612, cl_segmask_iou 0.32946, cl_phrcls_loss 0.39968, cl_phrase_acc 0.99323, chxp_att_reg_loss 0.19793, chxp_phrcls_loss 2.28972, chxp_prc_auc 0.75542, iufg_att_reg_loss 0.25955, iufg_phrcls_loss 0.32560, iufg_prc_auc 0.35127, cxrlt2024c_att_reg_loss 0.19010, cxrlt2024c_phrcls_loss 0.72111, cxrlt2024c_prc_auc 0.82770, 817.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12818, cxrlt2024c_phrcls_loss 0.52216, cxrlt2024c_prc_auc 0.74515, 180.74 secs\n",
      "\u001b[1m---- Epoch 44/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.00814, mimfg_att_reg_loss 0.19985, mimfg_phrcls_loss 0.87171, mimfg_prc_auc 0.91930, cibg_att_sup_loss 0.52213, cibg_segmask_iou 0.32042, vbg_phrcls_loss 0.98569, vbg_prc_auc 0.82701, vbg_att_reg_loss 0.06112, vbg_att_sup_loss 0.27074, vbg_segmask_iou 0.17895, cl_att_sup_loss 0.24963, cl_segmask_iou 0.32128, cl_phrcls_loss 0.40185, cl_phrase_acc 0.99323, chxp_att_reg_loss 0.19700, chxp_phrcls_loss 2.30266, chxp_prc_auc 0.76206, iufg_att_reg_loss 0.26136, iufg_phrcls_loss 0.31149, iufg_prc_auc 0.34263, cxrlt2024c_att_reg_loss 0.18836, cxrlt2024c_phrcls_loss 0.70642, cxrlt2024c_prc_auc 0.85226, 818.45 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12740, cxrlt2024c_phrcls_loss 0.52452, cxrlt2024c_prc_auc 0.74529, 180.88 secs\n",
      "\u001b[1m---- Epoch 45/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.10861, mimfg_att_reg_loss 0.20040, mimfg_phrcls_loss 0.89169, mimfg_prc_auc 0.91625, cibg_att_sup_loss 0.53164, cibg_segmask_iou 0.32163, vbg_phrcls_loss 1.19396, vbg_prc_auc 0.71817, vbg_att_reg_loss 0.07198, vbg_att_sup_loss 0.33466, vbg_segmask_iou 0.17356, cl_att_sup_loss 0.28809, cl_segmask_iou 0.32597, cl_phrcls_loss 0.60319, cl_phrase_acc 0.97676, chxp_att_reg_loss 0.20601, chxp_phrcls_loss 2.36881, chxp_prc_auc 0.73493, iufg_att_reg_loss 0.26071, iufg_phrcls_loss 0.36273, iufg_prc_auc 0.33229, cxrlt2024c_att_reg_loss 0.20014, cxrlt2024c_phrcls_loss 0.77568, cxrlt2024c_prc_auc 0.80686, 819.33 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13153, cxrlt2024c_phrcls_loss 0.53349, cxrlt2024c_prc_auc 0.73656, 181.11 secs\n",
      "\u001b[1m---- Epoch 46/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.05015, mimfg_att_reg_loss 0.19895, mimfg_phrcls_loss 0.87677, mimfg_prc_auc 0.91855, cibg_att_sup_loss 0.51447, cibg_segmask_iou 0.32210, vbg_phrcls_loss 1.07053, vbg_prc_auc 0.78360, vbg_att_reg_loss 0.06487, vbg_att_sup_loss 0.29774, vbg_segmask_iou 0.17373, cl_att_sup_loss 0.25986, cl_segmask_iou 0.32462, cl_phrcls_loss 0.47195, cl_phrase_acc 0.98800, chxp_att_reg_loss 0.19545, chxp_phrcls_loss 2.28831, chxp_prc_auc 0.75808, iufg_att_reg_loss 0.24782, iufg_phrcls_loss 0.31446, iufg_prc_auc 0.36352, cxrlt2024c_att_reg_loss 0.19899, cxrlt2024c_phrcls_loss 0.74746, cxrlt2024c_prc_auc 0.81415, 821.35 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12566, cxrlt2024c_phrcls_loss 0.52776, cxrlt2024c_prc_auc 0.74753, 181.11 secs\n",
      "\u001b[1m---- Epoch 47/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.01426, mimfg_att_reg_loss 0.20059, mimfg_phrcls_loss 0.87786, mimfg_prc_auc 0.91820, cibg_att_sup_loss 0.52012, cibg_segmask_iou 0.32351, vbg_phrcls_loss 0.97834, vbg_prc_auc 0.81684, vbg_att_reg_loss 0.05719, vbg_att_sup_loss 0.27966, vbg_segmask_iou 0.17670, cl_att_sup_loss 0.25210, cl_segmask_iou 0.31605, cl_phrcls_loss 0.37875, cl_phrase_acc 0.99237, chxp_att_reg_loss 0.19090, chxp_phrcls_loss 2.30404, chxp_prc_auc 0.74859, iufg_att_reg_loss 0.26305, iufg_phrcls_loss 0.32680, iufg_prc_auc 0.32907, cxrlt2024c_att_reg_loss 0.18996, cxrlt2024c_phrcls_loss 0.72059, cxrlt2024c_prc_auc 0.81898, 818.99 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12571, cxrlt2024c_phrcls_loss 0.51850, cxrlt2024c_prc_auc 0.74919, 182.40 secs\n",
      "\u001b[1m---- Epoch 48/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.12777, mimfg_att_reg_loss 0.19904, mimfg_phrcls_loss 0.88014, mimfg_prc_auc 0.91901, cibg_att_sup_loss 0.51014, cibg_segmask_iou 0.32414, vbg_phrcls_loss 0.95628, vbg_prc_auc 0.84466, vbg_att_reg_loss 0.05644, vbg_att_sup_loss 0.26658, vbg_segmask_iou 0.17779, cl_att_sup_loss 0.23223, cl_segmask_iou 0.32644, cl_phrcls_loss 0.33381, cl_phrase_acc 0.99624, chxp_att_reg_loss 0.18093, chxp_phrcls_loss 2.26223, chxp_prc_auc 0.77474, iufg_att_reg_loss 0.25605, iufg_phrcls_loss 0.31867, iufg_prc_auc 0.33650, cxrlt2024c_att_reg_loss 0.23779, cxrlt2024c_phrcls_loss 0.96682, cxrlt2024c_prc_auc 0.73946, 821.83 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12742, cxrlt2024c_phrcls_loss 0.51338, cxrlt2024c_prc_auc 0.74775, 182.13 secs\n",
      "\u001b[1m---- Epoch 49/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.13219, mimfg_att_reg_loss 0.19699, mimfg_phrcls_loss 0.87730, mimfg_prc_auc 0.92060, cibg_att_sup_loss 0.50933, cibg_segmask_iou 0.32327, vbg_phrcls_loss 0.94876, vbg_prc_auc 0.85081, vbg_att_reg_loss 0.05612, vbg_att_sup_loss 0.27153, vbg_segmask_iou 0.18014, cl_att_sup_loss 0.24110, cl_segmask_iou 0.32062, cl_phrcls_loss 0.37080, cl_phrase_acc 0.99537, chxp_att_reg_loss 0.17935, chxp_phrcls_loss 2.27140, chxp_prc_auc 0.77646, iufg_att_reg_loss 0.25619, iufg_phrcls_loss 0.32642, iufg_prc_auc 0.35064, cxrlt2024c_att_reg_loss 0.24030, cxrlt2024c_phrcls_loss 0.97137, cxrlt2024c_prc_auc 0.73679, 813.58 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12724, cxrlt2024c_phrcls_loss 0.51695, cxrlt2024c_prc_auc 0.74930, 183.40 secs\n",
      "\u001b[1m---- Epoch 50/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.18610, mimfg_att_reg_loss 0.20126, mimfg_phrcls_loss 0.89923, mimfg_prc_auc 0.91894, cibg_att_sup_loss 0.50433, cibg_segmask_iou 0.32760, vbg_phrcls_loss 1.08303, vbg_prc_auc 0.77998, vbg_att_reg_loss 0.06591, vbg_att_sup_loss 0.29811, vbg_segmask_iou 0.17459, cl_att_sup_loss 0.26512, cl_segmask_iou 0.32431, cl_phrcls_loss 0.46856, cl_phrase_acc 0.98979, chxp_att_reg_loss 0.18936, chxp_phrcls_loss 2.31211, chxp_prc_auc 0.75019, iufg_att_reg_loss 0.26204, iufg_phrcls_loss 0.35876, iufg_prc_auc 0.34336, cxrlt2024c_att_reg_loss 0.23967, cxrlt2024c_phrcls_loss 1.00337, cxrlt2024c_prc_auc 0.72599, 823.45 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12965, cxrlt2024c_phrcls_loss 0.52602, cxrlt2024c_prc_auc 0.74564, 182.46 secs\n",
      "\u001b[1m---- Epoch 51/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.13990, mimfg_att_reg_loss 0.20073, mimfg_phrcls_loss 0.88657, mimfg_prc_auc 0.92144, cibg_att_sup_loss 0.49401, cibg_segmask_iou 0.33085, vbg_phrcls_loss 0.97663, vbg_prc_auc 0.82520, vbg_att_reg_loss 0.05553, vbg_att_sup_loss 0.27564, vbg_segmask_iou 0.17985, cl_att_sup_loss 0.24838, cl_segmask_iou 0.32680, cl_phrcls_loss 0.36656, cl_phrase_acc 0.99085, chxp_att_reg_loss 0.18091, chxp_phrcls_loss 2.28137, chxp_prc_auc 0.75726, iufg_att_reg_loss 0.25253, iufg_phrcls_loss 0.32799, iufg_prc_auc 0.34796, cxrlt2024c_att_reg_loss 0.23993, cxrlt2024c_phrcls_loss 0.97487, cxrlt2024c_prc_auc 0.77667, 825.12 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.12352, cxrlt2024c_phrcls_loss 0.51024, cxrlt2024c_prc_auc 0.75321, 183.29 secs\n",
      "\u001b[1m---- Epoch 52/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.09479, mimfg_att_reg_loss 0.19715, mimfg_phrcls_loss 0.86837, mimfg_prc_auc 0.92393, cibg_att_sup_loss 0.48297, cibg_segmask_iou 0.33638, vbg_phrcls_loss 0.87528, vbg_prc_auc 0.86794, vbg_att_reg_loss 0.05487, vbg_att_sup_loss 0.26448, vbg_segmask_iou 0.18090, cl_att_sup_loss 0.22837, cl_segmask_iou 0.32585, cl_phrcls_loss 0.27400, cl_phrase_acc 0.99489, chxp_att_reg_loss 0.17377, chxp_phrcls_loss 2.26532, chxp_prc_auc 0.75652, iufg_att_reg_loss 0.25378, iufg_phrcls_loss 0.29984, iufg_prc_auc 0.36837, cxrlt2024c_att_reg_loss 0.23903, cxrlt2024c_phrcls_loss 0.94120, cxrlt2024c_prc_auc 0.81435, 834.07 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12117, cxrlt2024c_phrcls_loss 0.50687, cxrlt2024c_prc_auc 0.75782, 182.20 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_52_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7560.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 53/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.92433, mimfg_att_reg_loss 0.19682, mimfg_phrcls_loss 0.86312, mimfg_prc_auc 0.92190, cibg_att_sup_loss 0.49147, cibg_segmask_iou 0.33261, vbg_phrcls_loss 0.80841, vbg_prc_auc 0.88792, vbg_att_reg_loss 0.05014, vbg_att_sup_loss 0.25056, vbg_segmask_iou 0.18202, cl_att_sup_loss 0.21722, cl_segmask_iou 0.33067, cl_phrcls_loss 0.22365, cl_phrase_acc 0.99765, chxp_att_reg_loss 0.18383, chxp_phrcls_loss 2.26777, chxp_prc_auc 0.75456, iufg_att_reg_loss 0.25579, iufg_phrcls_loss 0.31153, iufg_prc_auc 0.35659, cxrlt2024c_att_reg_loss 0.17435, cxrlt2024c_phrcls_loss 0.64388, cxrlt2024c_prc_auc 0.88691, 824.58 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12201, cxrlt2024c_phrcls_loss 0.51045, cxrlt2024c_prc_auc 0.75621, 182.57 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_53_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7568.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 54/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.91138, mimfg_att_reg_loss 0.19646, mimfg_phrcls_loss 0.86394, mimfg_prc_auc 0.92169, cibg_att_sup_loss 0.49697, cibg_segmask_iou 0.33238, vbg_phrcls_loss 0.79005, vbg_prc_auc 0.89374, vbg_att_reg_loss 0.05029, vbg_att_sup_loss 0.25781, vbg_segmask_iou 0.18117, cl_att_sup_loss 0.22531, cl_segmask_iou 0.32440, cl_phrcls_loss 0.20944, cl_phrase_acc 0.99741, chxp_att_reg_loss 0.17589, chxp_phrcls_loss 2.22470, chxp_prc_auc 0.76483, iufg_att_reg_loss 0.25682, iufg_phrcls_loss 0.30701, iufg_prc_auc 0.36431, cxrlt2024c_att_reg_loss 0.16788, cxrlt2024c_phrcls_loss 0.62731, cxrlt2024c_prc_auc 0.87677, 824.57 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12241, cxrlt2024c_phrcls_loss 0.51211, cxrlt2024c_prc_auc 0.75712, 182.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_54_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7572.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 55/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.03501, mimfg_att_reg_loss 0.19901, mimfg_phrcls_loss 0.88865, mimfg_prc_auc 0.91539, cibg_att_sup_loss 0.52237, cibg_segmask_iou 0.32531, vbg_phrcls_loss 1.10640, vbg_prc_auc 0.74751, vbg_att_reg_loss 0.06714, vbg_att_sup_loss 0.32045, vbg_segmask_iou 0.17109, cl_att_sup_loss 0.27453, cl_segmask_iou 0.32128, cl_phrcls_loss 0.43633, cl_phrase_acc 0.98451, chxp_att_reg_loss 0.18919, chxp_phrcls_loss 2.32096, chxp_prc_auc 0.75161, iufg_att_reg_loss 0.26558, iufg_phrcls_loss 0.33366, iufg_prc_auc 0.34962, cxrlt2024c_att_reg_loss 0.18006, cxrlt2024c_phrcls_loss 0.69609, cxrlt2024c_prc_auc 0.84139, 825.30 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12273, cxrlt2024c_phrcls_loss 0.57415, cxrlt2024c_prc_auc 0.73169, 182.64 secs\n",
      "\u001b[1m---- Epoch 56/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "cxrlt2024c_att_reg_loss 0.12548, cxrlt2024c_phrcls_loss 0.53294, cxrlt2024c_prc_auc 0.74200, 182.18 secs\n",
      "\u001b[1m---- Epoch 57/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.91308, mimfg_att_reg_loss 0.19439, mimfg_phrcls_loss 0.86639, mimfg_prc_auc 0.91932, cibg_att_sup_loss 0.49389, cibg_segmask_iou 0.33000, vbg_phrcls_loss 0.85009, vbg_prc_auc 0.85772, vbg_att_reg_loss 0.05309, vbg_att_sup_loss 0.26569, vbg_segmask_iou 0.17787, cl_att_sup_loss 0.22998, cl_segmask_iou 0.31848, cl_phrcls_loss 0.21550, cl_phrase_acc 0.99584, chxp_att_reg_loss 0.17467, chxp_phrcls_loss 2.29885, chxp_prc_auc 0.75570, iufg_att_reg_loss 0.24791, iufg_phrcls_loss 0.31748, iufg_prc_auc 0.35002, cxrlt2024c_att_reg_loss 0.17222, cxrlt2024c_phrcls_loss 0.59129, cxrlt2024c_prc_auc 0.87691, 816.07 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12423, cxrlt2024c_phrcls_loss 0.53103, cxrlt2024c_prc_auc 0.74622, 182.07 secs\n",
      "\u001b[1m---- Epoch 58/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.88756, mimfg_att_reg_loss 0.19504, mimfg_phrcls_loss 0.85899, mimfg_prc_auc 0.92113, cibg_att_sup_loss 0.49843, cibg_segmask_iou 0.33069, vbg_phrcls_loss 0.76750, vbg_prc_auc 0.89205, vbg_att_reg_loss 0.04573, vbg_att_sup_loss 0.24907, vbg_segmask_iou 0.18002, cl_att_sup_loss 0.21674, cl_segmask_iou 0.32546, cl_phrcls_loss 0.19269, cl_phrase_acc 0.99660, chxp_att_reg_loss 0.17604, chxp_phrcls_loss 2.25679, chxp_prc_auc 0.76178, iufg_att_reg_loss 0.25053, iufg_phrcls_loss 0.31553, iufg_prc_auc 0.34484, cxrlt2024c_att_reg_loss 0.16635, cxrlt2024c_phrcls_loss 0.58736, cxrlt2024c_prc_auc 0.90164, 822.23 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12401, cxrlt2024c_phrcls_loss 0.53556, cxrlt2024c_prc_auc 0.74676, 181.36 secs\n",
      "\u001b[1m---- Epoch 59/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.89810, mimfg_att_reg_loss 0.19836, mimfg_phrcls_loss 0.87880, mimfg_prc_auc 0.91755, cibg_att_sup_loss 0.50247, cibg_segmask_iou 0.32876, vbg_phrcls_loss 0.78306, vbg_prc_auc 0.88390, vbg_att_reg_loss 0.05036, vbg_att_sup_loss 0.25371, vbg_segmask_iou 0.17964, cl_att_sup_loss 0.20861, cl_segmask_iou 0.31804, cl_phrcls_loss 0.17907, cl_phrase_acc 0.99789, chxp_att_reg_loss 0.17302, chxp_phrcls_loss 2.20810, chxp_prc_auc 0.76360, iufg_att_reg_loss 0.24859, iufg_phrcls_loss 0.31408, iufg_prc_auc 0.34681, cxrlt2024c_att_reg_loss 0.17418, cxrlt2024c_phrcls_loss 0.59568, cxrlt2024c_prc_auc 0.88758, 820.90 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12435, cxrlt2024c_phrcls_loss 0.53422, cxrlt2024c_prc_auc 0.74703, 181.98 secs\n",
      "\u001b[1m---- Epoch 60/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.01271, mimfg_att_reg_loss 0.20152, mimfg_phrcls_loss 0.89722, mimfg_prc_auc 0.91339, cibg_att_sup_loss 0.51211, cibg_segmask_iou 0.32983, vbg_phrcls_loss 1.01335, vbg_prc_auc 0.79294, vbg_att_reg_loss 0.05882, vbg_att_sup_loss 0.29854, vbg_segmask_iou 0.17617, cl_att_sup_loss 0.26243, cl_segmask_iou 0.32079, cl_phrcls_loss 0.35888, cl_phrase_acc 0.98765, chxp_att_reg_loss 0.18000, chxp_phrcls_loss 2.28543, chxp_prc_auc 0.73967, iufg_att_reg_loss 0.25969, iufg_phrcls_loss 0.34451, iufg_prc_auc 0.33744, cxrlt2024c_att_reg_loss 0.18308, cxrlt2024c_phrcls_loss 0.69905, cxrlt2024c_prc_auc 0.84499, 817.81 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12660, cxrlt2024c_phrcls_loss 0.54946, cxrlt2024c_prc_auc 0.73319, 181.12 secs\n",
      "\u001b[1m---- Epoch 61/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.93525, mimfg_att_reg_loss 0.20160, mimfg_phrcls_loss 0.88700, mimfg_prc_auc 0.91553, cibg_att_sup_loss 0.50140, cibg_segmask_iou 0.33066, vbg_phrcls_loss 0.86686, vbg_prc_auc 0.84997, vbg_att_reg_loss 0.05327, vbg_att_sup_loss 0.26659, vbg_segmask_iou 0.17693, cl_att_sup_loss 0.22891, cl_segmask_iou 0.32019, cl_phrcls_loss 0.26331, cl_phrase_acc 0.99390, chxp_att_reg_loss 0.17908, chxp_phrcls_loss 2.26628, chxp_prc_auc 0.75676, iufg_att_reg_loss 0.24781, iufg_phrcls_loss 0.31229, iufg_prc_auc 0.36117, cxrlt2024c_att_reg_loss 0.16841, cxrlt2024c_phrcls_loss 0.62736, cxrlt2024c_prc_auc 0.88626, 820.60 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12410, cxrlt2024c_phrcls_loss 0.53915, cxrlt2024c_prc_auc 0.74747, 180.99 secs\n",
      "\u001b[1m---- Epoch 62/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.91115, mimfg_att_reg_loss 0.19862, mimfg_phrcls_loss 0.88215, mimfg_prc_auc 0.91699, cibg_att_sup_loss 0.49673, cibg_segmask_iou 0.33509, vbg_phrcls_loss 0.78356, vbg_prc_auc 0.89545, vbg_att_reg_loss 0.04704, vbg_att_sup_loss 0.26308, vbg_segmask_iou 0.18107, cl_att_sup_loss 0.22528, cl_segmask_iou 0.32691, cl_phrcls_loss 0.17905, cl_phrase_acc 0.99608, chxp_att_reg_loss 0.17692, chxp_phrcls_loss 2.30383, chxp_prc_auc 0.74692, iufg_att_reg_loss 0.25061, iufg_phrcls_loss 0.31727, iufg_prc_auc 0.35733, cxrlt2024c_att_reg_loss 0.16713, cxrlt2024c_phrcls_loss 0.61452, cxrlt2024c_prc_auc 0.88130, 819.20 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.12429, cxrlt2024c_phrcls_loss 0.53645, cxrlt2024c_prc_auc 0.74897, 180.36 secs\n",
      "\u001b[1m---- Epoch 63/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.03389, mimfg_att_reg_loss 0.19556, mimfg_phrcls_loss 0.86633, mimfg_prc_auc 0.92055, cibg_att_sup_loss 0.49329, cibg_segmask_iou 0.33307, vbg_phrcls_loss 0.74593, vbg_prc_auc 0.91677, vbg_att_reg_loss 0.04444, vbg_att_sup_loss 0.24200, vbg_segmask_iou 0.18009, cl_att_sup_loss 0.21222, cl_segmask_iou 0.32351, cl_phrcls_loss 0.19530, cl_phrase_acc 0.99822, chxp_att_reg_loss 0.17204, chxp_phrcls_loss 2.26412, chxp_prc_auc 0.78008, iufg_att_reg_loss 0.26255, iufg_phrcls_loss 0.31741, iufg_prc_auc 0.32604, cxrlt2024c_att_reg_loss 0.22392, cxrlt2024c_phrcls_loss 0.87840, cxrlt2024c_prc_auc 0.78087, 820.20 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12549, cxrlt2024c_phrcls_loss 0.52382, cxrlt2024c_prc_auc 0.74815, 180.81 secs\n",
      "\u001b[1m---- Epoch 64/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.03812, mimfg_att_reg_loss 0.19928, mimfg_phrcls_loss 0.87250, mimfg_prc_auc 0.92065, cibg_att_sup_loss 0.49724, cibg_segmask_iou 0.33091, vbg_phrcls_loss 0.75201, vbg_prc_auc 0.92041, vbg_att_reg_loss 0.04709, vbg_att_sup_loss 0.23997, vbg_segmask_iou 0.18209, cl_att_sup_loss 0.21436, cl_segmask_iou 0.33156, cl_phrcls_loss 0.18077, cl_phrase_acc 0.99742, chxp_att_reg_loss 0.16693, chxp_phrcls_loss 2.23983, chxp_prc_auc 0.78835, iufg_att_reg_loss 0.23873, iufg_phrcls_loss 0.30532, iufg_prc_auc 0.38670, cxrlt2024c_att_reg_loss 0.22237, cxrlt2024c_phrcls_loss 0.89308, cxrlt2024c_prc_auc 0.78523, 818.31 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12560, cxrlt2024c_phrcls_loss 0.52254, cxrlt2024c_prc_auc 0.74804, 180.40 secs\n",
      "\u001b[1m---- Epoch 65/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.09955, mimfg_att_reg_loss 0.19362, mimfg_phrcls_loss 0.86852, mimfg_prc_auc 0.92387, cibg_att_sup_loss 0.48938, cibg_segmask_iou 0.33458, vbg_phrcls_loss 0.86462, vbg_prc_auc 0.86976, vbg_att_reg_loss 0.05070, vbg_att_sup_loss 0.27232, vbg_segmask_iou 0.18041, cl_att_sup_loss 0.23129, cl_segmask_iou 0.32511, cl_phrcls_loss 0.28377, cl_phrase_acc 0.99335, chxp_att_reg_loss 0.17947, chxp_phrcls_loss 2.35799, chxp_prc_auc 0.73713, iufg_att_reg_loss 0.26001, iufg_phrcls_loss 0.33426, iufg_prc_auc 0.33060, cxrlt2024c_att_reg_loss 0.22616, cxrlt2024c_phrcls_loss 0.94876, cxrlt2024c_prc_auc 0.76690, 813.03 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12115, cxrlt2024c_phrcls_loss 0.51728, cxrlt2024c_prc_auc 0.75097, 180.39 secs\n",
      "\u001b[1m---- Epoch 66/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.05378, mimfg_att_reg_loss 0.19353, mimfg_phrcls_loss 0.85911, mimfg_prc_auc 0.92575, cibg_att_sup_loss 0.48533, cibg_segmask_iou 0.33697, vbg_phrcls_loss 0.76528, vbg_prc_auc 0.88857, vbg_att_reg_loss 0.04553, vbg_att_sup_loss 0.25825, vbg_segmask_iou 0.18066, cl_att_sup_loss 0.21889, cl_segmask_iou 0.33375, cl_phrcls_loss 0.19792, cl_phrase_acc 0.99671, chxp_att_reg_loss 0.17245, chxp_phrcls_loss 2.25778, chxp_prc_auc 0.76879, iufg_att_reg_loss 0.24580, iufg_phrcls_loss 0.30642, iufg_prc_auc 0.37049, cxrlt2024c_att_reg_loss 0.22613, cxrlt2024c_phrcls_loss 0.92090, cxrlt2024c_prc_auc 0.80621, 801.42 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12094, cxrlt2024c_phrcls_loss 0.50410, cxrlt2024c_prc_auc 0.75783, 180.27 secs\n",
      "\u001b[1m---- Epoch 67/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.03081, mimfg_att_reg_loss 0.19687, mimfg_phrcls_loss 0.86273, mimfg_prc_auc 0.92402, cibg_att_sup_loss 0.47564, cibg_segmask_iou 0.33985, vbg_phrcls_loss 0.68394, vbg_prc_auc 0.92477, vbg_att_reg_loss 0.04275, vbg_att_sup_loss 0.23759, vbg_segmask_iou 0.18377, cl_att_sup_loss 0.21290, cl_segmask_iou 0.32834, cl_phrcls_loss 0.14613, cl_phrase_acc 0.99707, chxp_att_reg_loss 0.17342, chxp_phrcls_loss 2.28599, chxp_prc_auc 0.76407, iufg_att_reg_loss 0.25003, iufg_phrcls_loss 0.31230, iufg_prc_auc 0.37528, cxrlt2024c_att_reg_loss 0.22825, cxrlt2024c_phrcls_loss 0.90224, cxrlt2024c_prc_auc 0.82541, 809.31 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12000, cxrlt2024c_phrcls_loss 0.50583, cxrlt2024c_prc_auc 0.76378, 179.77 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_67_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7608.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 68/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.82609, mimfg_att_reg_loss 0.19144, mimfg_phrcls_loss 0.83388, mimfg_prc_auc 0.92759, cibg_att_sup_loss 0.47702, cibg_segmask_iou 0.34254, vbg_phrcls_loss 0.61738, vbg_prc_auc 0.93217, vbg_att_reg_loss 0.04144, vbg_att_sup_loss 0.23128, vbg_segmask_iou 0.18486, cl_att_sup_loss 0.20148, cl_segmask_iou 0.33724, cl_phrcls_loss 0.10407, cl_phrase_acc 0.99868, chxp_att_reg_loss 0.17333, chxp_phrcls_loss 2.21464, chxp_prc_auc 0.77345, iufg_att_reg_loss 0.24156, iufg_phrcls_loss 0.29676, iufg_prc_auc 0.38085, cxrlt2024c_att_reg_loss 0.15411, cxrlt2024c_phrcls_loss 0.55330, cxrlt2024c_prc_auc 0.92050, 815.85 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12000, cxrlt2024c_phrcls_loss 0.51685, cxrlt2024c_prc_auc 0.75980, 180.04 secs\n",
      "\u001b[1m---- Epoch 69/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.80503, mimfg_att_reg_loss 0.19427, mimfg_phrcls_loss 0.85566, mimfg_prc_auc 0.92159, cibg_att_sup_loss 0.48102, cibg_segmask_iou 0.34341, vbg_phrcls_loss 0.58631, vbg_prc_auc 0.94501, vbg_att_reg_loss 0.04003, vbg_att_sup_loss 0.22993, vbg_segmask_iou 0.18470, cl_att_sup_loss 0.20076, cl_segmask_iou 0.32928, cl_phrcls_loss 0.09012, cl_phrase_acc 0.99906, chxp_att_reg_loss 0.16963, chxp_phrcls_loss 2.15531, chxp_prc_auc 0.78020, iufg_att_reg_loss 0.24796, iufg_phrcls_loss 0.29810, iufg_prc_auc 0.37876, cxrlt2024c_att_reg_loss 0.15137, cxrlt2024c_phrcls_loss 0.51891, cxrlt2024c_prc_auc 0.94389, 809.87 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11997, cxrlt2024c_phrcls_loss 0.51840, cxrlt2024c_prc_auc 0.75958, 180.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_69_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.7610.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 70/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.92791, mimfg_att_reg_loss 0.19794, mimfg_phrcls_loss 0.88047, mimfg_prc_auc 0.91695, cibg_att_sup_loss 0.50348, cibg_segmask_iou 0.33196, vbg_phrcls_loss 0.89589, vbg_prc_auc 0.84742, vbg_att_reg_loss 0.05436, vbg_att_sup_loss 0.28526, vbg_segmask_iou 0.17389, cl_att_sup_loss 0.25074, cl_segmask_iou 0.32106, cl_phrcls_loss 0.29122, cl_phrase_acc 0.98977, chxp_att_reg_loss 0.18135, chxp_phrcls_loss 2.30107, chxp_prc_auc 0.73288, iufg_att_reg_loss 0.26042, iufg_phrcls_loss 0.33834, iufg_prc_auc 0.33185, cxrlt2024c_att_reg_loss 0.15792, cxrlt2024c_phrcls_loss 0.59188, cxrlt2024c_prc_auc 0.86212, 815.91 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.13023, cxrlt2024c_phrcls_loss 0.55491, cxrlt2024c_prc_auc 0.73575, 179.98 secs\n",
      "\u001b[1m---- Epoch 71/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.87813, mimfg_att_reg_loss 0.19760, mimfg_phrcls_loss 0.87915, mimfg_prc_auc 0.91661, cibg_att_sup_loss 0.49896, cibg_segmask_iou 0.33705, vbg_phrcls_loss 0.78493, vbg_prc_auc 0.88388, vbg_att_reg_loss 0.04640, vbg_att_sup_loss 0.25745, vbg_segmask_iou 0.17689, cl_att_sup_loss 0.23121, cl_segmask_iou 0.32105, cl_phrcls_loss 0.22240, cl_phrase_acc 0.99157, chxp_att_reg_loss 0.17694, chxp_phrcls_loss 2.32445, chxp_prc_auc 0.75719, iufg_att_reg_loss 0.24766, iufg_phrcls_loss 0.32786, iufg_prc_auc 0.35223, cxrlt2024c_att_reg_loss 0.15463, cxrlt2024c_phrcls_loss 0.54363, cxrlt2024c_prc_auc 0.90220, 817.16 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12355, cxrlt2024c_phrcls_loss 0.55909, cxrlt2024c_prc_auc 0.74466, 180.09 secs\n",
      "\u001b[1m---- Epoch 72/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.81372, mimfg_att_reg_loss 0.19617, mimfg_phrcls_loss 0.86413, mimfg_prc_auc 0.92054, cibg_att_sup_loss 0.50159, cibg_segmask_iou 0.33449, vbg_phrcls_loss 0.66639, vbg_prc_auc 0.91701, vbg_att_reg_loss 0.04254, vbg_att_sup_loss 0.24288, vbg_segmask_iou 0.18089, cl_att_sup_loss 0.20719, cl_segmask_iou 0.32759, cl_phrcls_loss 0.11714, cl_phrase_acc 0.99683, chxp_att_reg_loss 0.16884, chxp_phrcls_loss 2.22373, chxp_prc_auc 0.78564, iufg_att_reg_loss 0.24729, iufg_phrcls_loss 0.30681, iufg_prc_auc 0.36767, cxrlt2024c_att_reg_loss 0.14761, cxrlt2024c_phrcls_loss 0.48803, cxrlt2024c_prc_auc 0.92928, 815.94 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.12397, cxrlt2024c_phrcls_loss 0.56350, cxrlt2024c_prc_auc 0.74421, 180.22 secs\n",
      "\u001b[1m---- Epoch 73/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.79351, mimfg_att_reg_loss 0.19287, mimfg_phrcls_loss 0.85503, mimfg_prc_auc 0.92158, cibg_att_sup_loss 0.49306, cibg_segmask_iou 0.33380, vbg_phrcls_loss 0.60797, vbg_prc_auc 0.93452, vbg_att_reg_loss 0.04161, vbg_att_sup_loss 0.23844, vbg_segmask_iou 0.18239, cl_att_sup_loss 0.20386, cl_segmask_iou 0.32998, cl_phrcls_loss 0.09901, cl_phrase_acc 0.99762, chxp_att_reg_loss 0.17459, chxp_phrcls_loss 2.23715, chxp_prc_auc 0.77153, iufg_att_reg_loss 0.25389, iufg_phrcls_loss 0.30851, iufg_prc_auc 0.37088, cxrlt2024c_att_reg_loss 0.14545, cxrlt2024c_phrcls_loss 0.46904, cxrlt2024c_prc_auc 0.91312, 817.31 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12375, cxrlt2024c_phrcls_loss 0.56221, cxrlt2024c_prc_auc 0.74619, 179.71 secs\n",
      "\u001b[1m---- Epoch 74/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.78326, mimfg_att_reg_loss 0.19344, mimfg_phrcls_loss 0.85719, mimfg_prc_auc 0.92124, cibg_att_sup_loss 0.48690, cibg_segmask_iou 0.33766, vbg_phrcls_loss 0.58401, vbg_prc_auc 0.94232, vbg_att_reg_loss 0.03916, vbg_att_sup_loss 0.23008, vbg_segmask_iou 0.18558, cl_att_sup_loss 0.19970, cl_segmask_iou 0.32852, cl_phrcls_loss 0.09388, cl_phrase_acc 0.99918, chxp_att_reg_loss 0.16818, chxp_phrcls_loss 2.24450, chxp_prc_auc 0.76592, iufg_att_reg_loss 0.23889, iufg_phrcls_loss 0.29886, iufg_prc_auc 0.37148, cxrlt2024c_att_reg_loss 0.14223, cxrlt2024c_phrcls_loss 0.46639, cxrlt2024c_prc_auc 0.93126, 816.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12392, cxrlt2024c_phrcls_loss 0.56511, cxrlt2024c_prc_auc 0.74642, 180.36 secs\n",
      "\u001b[1m---- Epoch 75/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.89856, mimfg_att_reg_loss 0.19780, mimfg_phrcls_loss 0.87594, mimfg_prc_auc 0.91738, cibg_att_sup_loss 0.49904, cibg_segmask_iou 0.33528, vbg_phrcls_loss 0.82837, vbg_prc_auc 0.86620, vbg_att_reg_loss 0.05045, vbg_att_sup_loss 0.26698, vbg_segmask_iou 0.17582, cl_att_sup_loss 0.23325, cl_segmask_iou 0.32574, cl_phrcls_loss 0.21972, cl_phrase_acc 0.99276, chxp_att_reg_loss 0.17902, chxp_phrcls_loss 2.35039, chxp_prc_auc 0.74883, iufg_att_reg_loss 0.25098, iufg_phrcls_loss 0.32504, iufg_prc_auc 0.34072, cxrlt2024c_att_reg_loss 0.15912, cxrlt2024c_phrcls_loss 0.56387, cxrlt2024c_prc_auc 0.90509, 814.11 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12833, cxrlt2024c_phrcls_loss 0.56558, cxrlt2024c_prc_auc 0.73493, 179.89 secs\n",
      "\u001b[1m---- Epoch 76/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.84366, mimfg_att_reg_loss 0.19705, mimfg_phrcls_loss 0.87470, mimfg_prc_auc 0.91851, cibg_att_sup_loss 0.48677, cibg_segmask_iou 0.33615, vbg_phrcls_loss 0.72077, vbg_prc_auc 0.89515, vbg_att_reg_loss 0.04482, vbg_att_sup_loss 0.25347, vbg_segmask_iou 0.17912, cl_att_sup_loss 0.21172, cl_segmask_iou 0.32973, cl_phrcls_loss 0.15254, cl_phrase_acc 0.99572, chxp_att_reg_loss 0.16951, chxp_phrcls_loss 2.18884, chxp_prc_auc 0.77021, iufg_att_reg_loss 0.24985, iufg_phrcls_loss 0.30733, iufg_prc_auc 0.36953, cxrlt2024c_att_reg_loss 0.15172, cxrlt2024c_phrcls_loss 0.52541, cxrlt2024c_prc_auc 0.90908, 815.99 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12276, cxrlt2024c_phrcls_loss 0.57174, cxrlt2024c_prc_auc 0.74385, 179.71 secs\n",
      "\u001b[1m---- Epoch 77/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.80058, mimfg_att_reg_loss 0.19309, mimfg_phrcls_loss 0.85004, mimfg_prc_auc 0.92298, cibg_att_sup_loss 0.48507, cibg_segmask_iou 0.33837, vbg_phrcls_loss 0.60182, vbg_prc_auc 0.92644, vbg_att_reg_loss 0.03905, vbg_att_sup_loss 0.22836, vbg_segmask_iou 0.18079, cl_att_sup_loss 0.20363, cl_segmask_iou 0.32981, cl_phrcls_loss 0.10151, cl_phrase_acc 0.99777, chxp_att_reg_loss 0.16648, chxp_phrcls_loss 2.25521, chxp_prc_auc 0.76728, iufg_att_reg_loss 0.25135, iufg_phrcls_loss 0.31135, iufg_prc_auc 0.35624, cxrlt2024c_att_reg_loss 0.15070, cxrlt2024c_phrcls_loss 0.49210, cxrlt2024c_prc_auc 0.91039, 805.67 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12444, cxrlt2024c_phrcls_loss 0.56192, cxrlt2024c_prc_auc 0.74290, 179.66 secs\n",
      "\u001b[1m---- Epoch 78/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.96663, mimfg_att_reg_loss 0.19138, mimfg_phrcls_loss 0.84996, mimfg_prc_auc 0.92323, cibg_att_sup_loss 0.48281, cibg_segmask_iou 0.33996, vbg_phrcls_loss 0.59247, vbg_prc_auc 0.94765, vbg_att_reg_loss 0.03771, vbg_att_sup_loss 0.22746, vbg_segmask_iou 0.18326, cl_att_sup_loss 0.21154, cl_segmask_iou 0.32601, cl_phrcls_loss 0.11791, cl_phrase_acc 0.99883, chxp_att_reg_loss 0.16894, chxp_phrcls_loss 2.33314, chxp_prc_auc 0.75930, iufg_att_reg_loss 0.24727, iufg_phrcls_loss 0.32440, iufg_prc_auc 0.35914, cxrlt2024c_att_reg_loss 0.21220, cxrlt2024c_phrcls_loss 0.80962, cxrlt2024c_prc_auc 0.81389, 815.82 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12556, cxrlt2024c_phrcls_loss 0.53309, cxrlt2024c_prc_auc 0.74525, 179.50 secs\n",
      "\u001b[1m---- Epoch 79/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.95879, mimfg_att_reg_loss 0.19543, mimfg_phrcls_loss 0.85190, mimfg_prc_auc 0.92382, cibg_att_sup_loss 0.47771, cibg_segmask_iou 0.33963, vbg_phrcls_loss 0.58227, vbg_prc_auc 0.95505, vbg_att_reg_loss 0.03799, vbg_att_sup_loss 0.22554, vbg_segmask_iou 0.18416, cl_att_sup_loss 0.19269, cl_segmask_iou 0.33203, cl_phrcls_loss 0.10597, cl_phrase_acc 0.99929, chxp_att_reg_loss 0.16641, chxp_phrcls_loss 2.28273, chxp_prc_auc 0.76700, iufg_att_reg_loss 0.23874, iufg_phrcls_loss 0.30875, iufg_prc_auc 0.37998, cxrlt2024c_att_reg_loss 0.20610, cxrlt2024c_phrcls_loss 0.81271, cxrlt2024c_prc_auc 0.81754, 806.98 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12606, cxrlt2024c_phrcls_loss 0.53111, cxrlt2024c_prc_auc 0.74578, 179.29 secs\n",
      "\u001b[1m---- Epoch 80/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.02919, mimfg_att_reg_loss 0.19654, mimfg_phrcls_loss 0.86085, mimfg_prc_auc 0.92387, cibg_att_sup_loss 0.47720, cibg_segmask_iou 0.34166, vbg_phrcls_loss 0.72167, vbg_prc_auc 0.91052, vbg_att_reg_loss 0.04401, vbg_att_sup_loss 0.24687, vbg_segmask_iou 0.18124, cl_att_sup_loss 0.21872, cl_segmask_iou 0.33324, cl_phrcls_loss 0.20428, cl_phrase_acc 0.99561, chxp_att_reg_loss 0.17702, chxp_phrcls_loss 2.30838, chxp_prc_auc 0.75319, iufg_att_reg_loss 0.24738, iufg_phrcls_loss 0.32403, iufg_prc_auc 0.35993, cxrlt2024c_att_reg_loss 0.21569, cxrlt2024c_phrcls_loss 0.88202, cxrlt2024c_prc_auc 0.79671, 815.40 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12108, cxrlt2024c_phrcls_loss 0.52059, cxrlt2024c_prc_auc 0.74765, 179.83 secs\n",
      "\u001b[1m---- Epoch 81/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.98630, mimfg_att_reg_loss 0.18941, mimfg_phrcls_loss 0.83669, mimfg_prc_auc 0.92949, cibg_att_sup_loss 0.46826, cibg_segmask_iou 0.34525, vbg_phrcls_loss 0.62005, vbg_prc_auc 0.92833, vbg_att_reg_loss 0.03813, vbg_att_sup_loss 0.24005, vbg_segmask_iou 0.18054, cl_att_sup_loss 0.20265, cl_segmask_iou 0.32565, cl_phrcls_loss 0.11505, cl_phrase_acc 0.99800, chxp_att_reg_loss 0.16353, chxp_phrcls_loss 2.20471, chxp_prc_auc 0.78332, iufg_att_reg_loss 0.24125, iufg_phrcls_loss 0.31174, iufg_prc_auc 0.38123, cxrlt2024c_att_reg_loss 0.21660, cxrlt2024c_phrcls_loss 0.86544, cxrlt2024c_prc_auc 0.82811, 816.89 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11948, cxrlt2024c_phrcls_loss 0.51711, cxrlt2024c_prc_auc 0.75204, 178.85 secs\n",
      "\u001b[1m---- Epoch 82/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.96804, mimfg_att_reg_loss 0.19245, mimfg_phrcls_loss 0.84318, mimfg_prc_auc 0.92742, cibg_att_sup_loss 0.47060, cibg_segmask_iou 0.34630, vbg_phrcls_loss 0.53015, vbg_prc_auc 0.95288, vbg_att_reg_loss 0.03601, vbg_att_sup_loss 0.21344, vbg_segmask_iou 0.18585, cl_att_sup_loss 0.18915, cl_segmask_iou 0.33360, cl_phrcls_loss 0.07417, cl_phrase_acc 0.99893, chxp_att_reg_loss 0.16207, chxp_phrcls_loss 2.17845, chxp_prc_auc 0.77475, iufg_att_reg_loss 0.23796, iufg_phrcls_loss 0.31422, iufg_prc_auc 0.40024, cxrlt2024c_att_reg_loss 0.21640, cxrlt2024c_phrcls_loss 0.87105, cxrlt2024c_prc_auc 0.83480, 821.57 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11891, cxrlt2024c_phrcls_loss 0.51079, cxrlt2024c_prc_auc 0.75683, 178.46 secs\n",
      "\u001b[1m---- Epoch 83/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.74727, mimfg_att_reg_loss 0.18806, mimfg_phrcls_loss 0.82200, mimfg_prc_auc 0.92900, cibg_att_sup_loss 0.46133, cibg_segmask_iou 0.34810, vbg_phrcls_loss 0.47814, vbg_prc_auc 0.95827, vbg_att_reg_loss 0.03372, vbg_att_sup_loss 0.21973, vbg_segmask_iou 0.18739, cl_att_sup_loss 0.19527, cl_segmask_iou 0.33739, cl_phrcls_loss 0.06762, cl_phrase_acc 0.99859, chxp_att_reg_loss 0.16775, chxp_phrcls_loss 2.20379, chxp_prc_auc 0.76548, iufg_att_reg_loss 0.24749, iufg_phrcls_loss 0.28431, iufg_prc_auc 0.38564, cxrlt2024c_att_reg_loss 0.13661, cxrlt2024c_phrcls_loss 0.46306, cxrlt2024c_prc_auc 0.95363, 812.18 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12020, cxrlt2024c_phrcls_loss 0.53115, cxrlt2024c_prc_auc 0.75348, 178.25 secs\n",
      "\u001b[1m---- Epoch 84/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70908, mimfg_att_reg_loss 0.19437, mimfg_phrcls_loss 0.85058, mimfg_prc_auc 0.92266, cibg_att_sup_loss 0.46844, cibg_segmask_iou 0.34744, vbg_phrcls_loss 0.44714, vbg_prc_auc 0.96424, vbg_att_reg_loss 0.03241, vbg_att_sup_loss 0.21011, vbg_segmask_iou 0.18463, cl_att_sup_loss 0.20643, cl_segmask_iou 0.33807, cl_phrcls_loss 0.05528, cl_phrase_acc 0.99893, chxp_att_reg_loss 0.16439, chxp_phrcls_loss 2.14125, chxp_prc_auc 0.77531, iufg_att_reg_loss 0.23591, iufg_phrcls_loss 0.29272, iufg_prc_auc 0.38105, cxrlt2024c_att_reg_loss 0.12282, cxrlt2024c_phrcls_loss 0.39619, cxrlt2024c_prc_auc 0.95903, 812.46 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11985, cxrlt2024c_phrcls_loss 0.53994, cxrlt2024c_prc_auc 0.75366, 178.29 secs\n",
      "\u001b[1m---- Epoch 85/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.86794, mimfg_att_reg_loss 0.19978, mimfg_phrcls_loss 0.88859, mimfg_prc_auc 0.91462, cibg_att_sup_loss 0.49164, cibg_segmask_iou 0.33925, vbg_phrcls_loss 0.79937, vbg_prc_auc 0.85985, vbg_att_reg_loss 0.04770, vbg_att_sup_loss 0.27321, vbg_segmask_iou 0.17900, cl_att_sup_loss 0.24487, cl_segmask_iou 0.31614, cl_phrcls_loss 0.24386, cl_phrase_acc 0.99108, chxp_att_reg_loss 0.17653, chxp_phrcls_loss 2.28605, chxp_prc_auc 0.75447, iufg_att_reg_loss 0.24347, iufg_phrcls_loss 0.32439, iufg_prc_auc 0.34745, cxrlt2024c_att_reg_loss 0.15325, cxrlt2024c_phrcls_loss 0.51141, cxrlt2024c_prc_auc 0.91642, 802.38 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12822, cxrlt2024c_phrcls_loss 0.55459, cxrlt2024c_prc_auc 0.73886, 178.26 secs\n",
      "\u001b[1m---- Epoch 86/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.78316, mimfg_att_reg_loss 0.19778, mimfg_phrcls_loss 0.86450, mimfg_prc_auc 0.91955, cibg_att_sup_loss 0.48564, cibg_segmask_iou 0.33951, vbg_phrcls_loss 0.64573, vbg_prc_auc 0.90062, vbg_att_reg_loss 0.04055, vbg_att_sup_loss 0.23986, vbg_segmask_iou 0.17949, cl_att_sup_loss 0.20582, cl_segmask_iou 0.32645, cl_phrcls_loss 0.13108, cl_phrase_acc 0.99584, chxp_att_reg_loss 0.16993, chxp_phrcls_loss 2.19706, chxp_prc_auc 0.78172, iufg_att_reg_loss 0.25094, iufg_phrcls_loss 0.31055, iufg_prc_auc 0.37226, cxrlt2024c_att_reg_loss 0.13279, cxrlt2024c_phrcls_loss 0.44274, cxrlt2024c_prc_auc 0.91970, 811.85 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12275, cxrlt2024c_phrcls_loss 0.59762, cxrlt2024c_prc_auc 0.74239, 178.20 secs\n",
      "\u001b[1m---- Epoch 87/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72843, mimfg_att_reg_loss 0.19478, mimfg_phrcls_loss 0.87111, mimfg_prc_auc 0.91929, cibg_att_sup_loss 0.47551, cibg_segmask_iou 0.34542, vbg_phrcls_loss 0.53757, vbg_prc_auc 0.93922, vbg_att_reg_loss 0.03638, vbg_att_sup_loss 0.22307, vbg_segmask_iou 0.18363, cl_att_sup_loss 0.19194, cl_segmask_iou 0.33785, cl_phrcls_loss 0.07206, cl_phrase_acc 0.99871, chxp_att_reg_loss 0.16328, chxp_phrcls_loss 2.16754, chxp_prc_auc 0.78032, iufg_att_reg_loss 0.24487, iufg_phrcls_loss 0.31466, iufg_prc_auc 0.36477, cxrlt2024c_att_reg_loss 0.12589, cxrlt2024c_phrcls_loss 0.38255, cxrlt2024c_prc_auc 0.94085, 811.27 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12365, cxrlt2024c_phrcls_loss 0.59454, cxrlt2024c_prc_auc 0.74444, 178.11 secs\n",
      "\u001b[1m---- Epoch 88/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.71009, mimfg_att_reg_loss 0.19336, mimfg_phrcls_loss 0.86117, mimfg_prc_auc 0.92175, cibg_att_sup_loss 0.47822, cibg_segmask_iou 0.34389, vbg_phrcls_loss 0.47071, vbg_prc_auc 0.95976, vbg_att_reg_loss 0.03485, vbg_att_sup_loss 0.21236, vbg_segmask_iou 0.18304, cl_att_sup_loss 0.18744, cl_segmask_iou 0.33731, cl_phrcls_loss 0.05648, cl_phrase_acc 0.99894, chxp_att_reg_loss 0.16331, chxp_phrcls_loss 2.21941, chxp_prc_auc 0.77060, iufg_att_reg_loss 0.24333, iufg_phrcls_loss 0.31387, iufg_prc_auc 0.36247, cxrlt2024c_att_reg_loss 0.12425, cxrlt2024c_phrcls_loss 0.36954, cxrlt2024c_prc_auc 0.95556, 811.02 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12278, cxrlt2024c_phrcls_loss 0.59747, cxrlt2024c_prc_auc 0.74323, 178.23 secs\n",
      "\u001b[1m---- Epoch 89/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70892, mimfg_att_reg_loss 0.19566, mimfg_phrcls_loss 0.86791, mimfg_prc_auc 0.91894, cibg_att_sup_loss 0.48230, cibg_segmask_iou 0.34462, vbg_phrcls_loss 0.44315, vbg_prc_auc 0.96614, vbg_att_reg_loss 0.03116, vbg_att_sup_loss 0.21281, vbg_segmask_iou 0.18380, cl_att_sup_loss 0.18555, cl_segmask_iou 0.33383, cl_phrcls_loss 0.05609, cl_phrase_acc 0.99906, chxp_att_reg_loss 0.17102, chxp_phrcls_loss 2.27458, chxp_prc_auc 0.75306, iufg_att_reg_loss 0.24432, iufg_phrcls_loss 0.30003, iufg_prc_auc 0.37661, cxrlt2024c_att_reg_loss 0.12417, cxrlt2024c_phrcls_loss 0.37050, cxrlt2024c_prc_auc 0.94640, 810.70 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12270, cxrlt2024c_phrcls_loss 0.59629, cxrlt2024c_prc_auc 0.74385, 178.07 secs\n",
      "\u001b[1m---- Epoch 90/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.83689, mimfg_att_reg_loss 0.19488, mimfg_phrcls_loss 0.87778, mimfg_prc_auc 0.91715, cibg_att_sup_loss 0.48313, cibg_segmask_iou 0.34440, vbg_phrcls_loss 0.70665, vbg_prc_auc 0.88767, vbg_att_reg_loss 0.04344, vbg_att_sup_loss 0.24995, vbg_segmask_iou 0.18012, cl_att_sup_loss 0.23461, cl_segmask_iou 0.33110, cl_phrcls_loss 0.17192, cl_phrase_acc 0.99406, chxp_att_reg_loss 0.17581, chxp_phrcls_loss 2.28078, chxp_prc_auc 0.75217, iufg_att_reg_loss 0.24716, iufg_phrcls_loss 0.33617, iufg_prc_auc 0.35965, cxrlt2024c_att_reg_loss 0.14844, cxrlt2024c_phrcls_loss 0.50136, cxrlt2024c_prc_auc 0.92001, 811.71 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12547, cxrlt2024c_phrcls_loss 0.58432, cxrlt2024c_prc_auc 0.73474, 178.02 secs\n",
      "\u001b[1m---- Epoch 91/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.76348, mimfg_att_reg_loss 0.19580, mimfg_phrcls_loss 0.87892, mimfg_prc_auc 0.91720, cibg_att_sup_loss 0.48051, cibg_segmask_iou 0.34754, vbg_phrcls_loss 0.59576, vbg_prc_auc 0.91603, vbg_att_reg_loss 0.03584, vbg_att_sup_loss 0.22935, vbg_segmask_iou 0.18136, cl_att_sup_loss 0.20191, cl_segmask_iou 0.32371, cl_phrcls_loss 0.10479, cl_phrase_acc 0.99707, chxp_att_reg_loss 0.16609, chxp_phrcls_loss 2.24841, chxp_prc_auc 0.75447, iufg_att_reg_loss 0.24476, iufg_phrcls_loss 0.31598, iufg_prc_auc 0.36691, cxrlt2024c_att_reg_loss 0.13414, cxrlt2024c_phrcls_loss 0.41356, cxrlt2024c_prc_auc 0.95245, 807.42 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12445, cxrlt2024c_phrcls_loss 0.59032, cxrlt2024c_prc_auc 0.74100, 178.12 secs\n",
      "\u001b[1m---- Epoch 92/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.71999, mimfg_att_reg_loss 0.19037, mimfg_phrcls_loss 0.85422, mimfg_prc_auc 0.92299, cibg_att_sup_loss 0.48339, cibg_segmask_iou 0.34477, vbg_phrcls_loss 0.49006, vbg_prc_auc 0.95180, vbg_att_reg_loss 0.03380, vbg_att_sup_loss 0.21450, vbg_segmask_iou 0.18497, cl_att_sup_loss 0.19220, cl_segmask_iou 0.33277, cl_phrcls_loss 0.06081, cl_phrase_acc 0.99869, chxp_att_reg_loss 0.16600, chxp_phrcls_loss 2.18409, chxp_prc_auc 0.77072, iufg_att_reg_loss 0.24456, iufg_phrcls_loss 0.30044, iufg_prc_auc 0.36603, cxrlt2024c_att_reg_loss 0.12579, cxrlt2024c_phrcls_loss 0.39031, cxrlt2024c_prc_auc 0.94583, 791.90 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12432, cxrlt2024c_phrcls_loss 0.59777, cxrlt2024c_prc_auc 0.74210, 178.22 secs\n",
      "\u001b[1m---- Epoch 93/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.90021, mimfg_att_reg_loss 0.19430, mimfg_phrcls_loss 0.86021, mimfg_prc_auc 0.91996, cibg_att_sup_loss 0.48248, cibg_segmask_iou 0.34141, vbg_phrcls_loss 0.48718, vbg_prc_auc 0.95864, vbg_att_reg_loss 0.03250, vbg_att_sup_loss 0.21018, vbg_segmask_iou 0.18211, cl_att_sup_loss 0.18322, cl_segmask_iou 0.32972, cl_phrcls_loss 0.06907, cl_phrase_acc 0.99917, chxp_att_reg_loss 0.16401, chxp_phrcls_loss 2.25990, chxp_prc_auc 0.78095, iufg_att_reg_loss 0.23388, iufg_phrcls_loss 0.30505, iufg_prc_auc 0.36929, cxrlt2024c_att_reg_loss 0.19223, cxrlt2024c_phrcls_loss 0.73740, cxrlt2024c_prc_auc 0.84708, 811.51 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.12514, cxrlt2024c_phrcls_loss 0.55323, cxrlt2024c_prc_auc 0.74198, 178.04 secs\n",
      "\u001b[1m---- Epoch 94/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.88665, mimfg_att_reg_loss 0.18921, mimfg_phrcls_loss 0.82773, mimfg_prc_auc 0.92690, cibg_att_sup_loss 0.46574, cibg_segmask_iou 0.34435, vbg_phrcls_loss 0.47288, vbg_prc_auc 0.96767, vbg_att_reg_loss 0.03136, vbg_att_sup_loss 0.20806, vbg_segmask_iou 0.18666, cl_att_sup_loss 0.19338, cl_segmask_iou 0.32611, cl_phrcls_loss 0.07411, cl_phrase_acc 0.99941, chxp_att_reg_loss 0.16272, chxp_phrcls_loss 2.23985, chxp_prc_auc 0.77526, iufg_att_reg_loss 0.23876, iufg_phrcls_loss 0.31748, iufg_prc_auc 0.36058, cxrlt2024c_att_reg_loss 0.19425, cxrlt2024c_phrcls_loss 0.72781, cxrlt2024c_prc_auc 0.85789, 809.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12473, cxrlt2024c_phrcls_loss 0.55129, cxrlt2024c_prc_auc 0.74267, 178.06 secs\n",
      "\u001b[1m---- Epoch 95/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.95172, mimfg_att_reg_loss 0.19219, mimfg_phrcls_loss 0.85137, mimfg_prc_auc 0.92448, cibg_att_sup_loss 0.47781, cibg_segmask_iou 0.34431, vbg_phrcls_loss 0.59756, vbg_prc_auc 0.92373, vbg_att_reg_loss 0.03833, vbg_att_sup_loss 0.23585, vbg_segmask_iou 0.18548, cl_att_sup_loss 0.20349, cl_segmask_iou 0.33698, cl_phrcls_loss 0.16427, cl_phrase_acc 0.99561, chxp_att_reg_loss 0.16478, chxp_phrcls_loss 2.24030, chxp_prc_auc 0.76206, iufg_att_reg_loss 0.24314, iufg_phrcls_loss 0.31284, iufg_prc_auc 0.36875, cxrlt2024c_att_reg_loss 0.19852, cxrlt2024c_phrcls_loss 0.79304, cxrlt2024c_prc_auc 0.83382, 808.90 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12207, cxrlt2024c_phrcls_loss 0.52992, cxrlt2024c_prc_auc 0.74650, 178.70 secs\n",
      "\u001b[1m---- Epoch 96/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.93789, mimfg_att_reg_loss 0.19609, mimfg_phrcls_loss 0.85286, mimfg_prc_auc 0.92414, cibg_att_sup_loss 0.46229, cibg_segmask_iou 0.35010, vbg_phrcls_loss 0.51541, vbg_prc_auc 0.94289, vbg_att_reg_loss 0.03196, vbg_att_sup_loss 0.20868, vbg_segmask_iou 0.18904, cl_att_sup_loss 0.19174, cl_segmask_iou 0.34522, cl_phrcls_loss 0.08872, cl_phrase_acc 0.99859, chxp_att_reg_loss 0.16436, chxp_phrcls_loss 2.19824, chxp_prc_auc 0.77040, iufg_att_reg_loss 0.23584, iufg_phrcls_loss 0.31437, iufg_prc_auc 0.38787, cxrlt2024c_att_reg_loss 0.20695, cxrlt2024c_phrcls_loss 0.81203, cxrlt2024c_prc_auc 0.84435, 813.76 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.12150, cxrlt2024c_phrcls_loss 0.52139, cxrlt2024c_prc_auc 0.74990, 178.42 secs\n",
      "\u001b[1m---- Epoch 97/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.93807, mimfg_att_reg_loss 0.19221, mimfg_phrcls_loss 0.84453, mimfg_prc_auc 0.92704, cibg_att_sup_loss 0.45424, cibg_segmask_iou 0.35095, vbg_phrcls_loss 0.43657, vbg_prc_auc 0.96678, vbg_att_reg_loss 0.03189, vbg_att_sup_loss 0.21447, vbg_segmask_iou 0.18614, cl_att_sup_loss 0.18373, cl_segmask_iou 0.34355, cl_phrcls_loss 0.06634, cl_phrase_acc 0.99918, chxp_att_reg_loss 0.16181, chxp_phrcls_loss 2.21619, chxp_prc_auc 0.76269, iufg_att_reg_loss 0.24116, iufg_phrcls_loss 0.31506, iufg_prc_auc 0.37701, cxrlt2024c_att_reg_loss 0.21143, cxrlt2024c_phrcls_loss 0.84337, cxrlt2024c_prc_auc 0.84389, 819.92 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11967, cxrlt2024c_phrcls_loss 0.51330, cxrlt2024c_prc_auc 0.75508, 178.48 secs\n",
      "\u001b[1m---- Epoch 98/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.67486, mimfg_att_reg_loss 0.18728, mimfg_phrcls_loss 0.81405, mimfg_prc_auc 0.93011, cibg_att_sup_loss 0.45845, cibg_segmask_iou 0.35426, vbg_phrcls_loss 0.37134, vbg_prc_auc 0.97699, vbg_att_reg_loss 0.02894, vbg_att_sup_loss 0.19951, vbg_segmask_iou 0.19164, cl_att_sup_loss 0.17761, cl_segmask_iou 0.34989, cl_phrcls_loss 0.03429, cl_phrase_acc 0.99952, chxp_att_reg_loss 0.16870, chxp_phrcls_loss 2.19639, chxp_prc_auc 0.77815, iufg_att_reg_loss 0.23809, iufg_phrcls_loss 0.29119, iufg_prc_auc 0.40816, cxrlt2024c_att_reg_loss 0.11174, cxrlt2024c_phrcls_loss 0.37697, cxrlt2024c_prc_auc 0.97295, 814.47 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11993, cxrlt2024c_phrcls_loss 0.54874, cxrlt2024c_prc_auc 0.75137, 178.94 secs\n",
      "\u001b[1m---- Epoch 99/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.65486, mimfg_att_reg_loss 0.18928, mimfg_phrcls_loss 0.83923, mimfg_prc_auc 0.92445, cibg_att_sup_loss 0.45561, cibg_segmask_iou 0.35201, vbg_phrcls_loss 0.35392, vbg_prc_auc 0.97876, vbg_att_reg_loss 0.03071, vbg_att_sup_loss 0.19576, vbg_segmask_iou 0.19086, cl_att_sup_loss 0.17669, cl_segmask_iou 0.34962, cl_phrcls_loss 0.03384, cl_phrase_acc 0.99929, chxp_att_reg_loss 0.16423, chxp_phrcls_loss 2.16621, chxp_prc_auc 0.77748, iufg_att_reg_loss 0.22583, iufg_phrcls_loss 0.29402, iufg_prc_auc 0.41265, cxrlt2024c_att_reg_loss 0.11022, cxrlt2024c_phrcls_loss 0.33530, cxrlt2024c_prc_auc 0.97623, 814.73 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.11998, cxrlt2024c_phrcls_loss 0.55935, cxrlt2024c_prc_auc 0.75079, 179.49 secs\n",
      "\u001b[1m---- Epoch 100/132\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 124200\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1411, in <module>\n",
      "    resume_training(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1368, in resume_training\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 831, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 135, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 819, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 387, in step_fn__chest_imagenome_bbox_grounding\n",
      "    gradient_accumulator.step(batch_loss, model)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 29, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/phrase_grounding/20240724_023122_mim-facts+chst-img-anat+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(microsoft-rad-dino,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\" \\\n",
    "--epochs 95 \\\n",
    "--batches_per_epoch 2000 \\\n",
    "--max_images_per_batch 10 \\\n",
    "--max_phrases_per_batch 400 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 5.0 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino\" \\\n",
    "--img_aug_mode \"random-color\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"film_layers_plus_sigmoid_attention_and_custom_classifier\" \\\n",
    "--visual_feature_proj_size 256 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce\" \\\n",
    "--use_attention_regularization_loss \\\n",
    "--attention_supervision_loss_weight 2.0 \\\n",
    "--phrase_classifier_loss_weight 2.0 \\\n",
    "--foreground_loss_weight 1.5 \\\n",
    "--use_cxrlt2024_challenge_split \\\n",
    "--use_cxrlt2024_custom_labels \\\n",
    "--cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts(num_facts=596394)(hash=469,647223496013944140).pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--mimiccxr_report_fact_nli_integrated_data_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_integrated_data(hash=1649,2670402002373726730).pkl\" \\\n",
    "--use_chest_imagenome_for_train \\\n",
    "--chest_imagenome_bbox_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\" \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--use_vinbig_for_train \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\" \\\n",
    "--vinbig_training_data_mode \"all\" \\\n",
    "--use_chexlocalize_for_train \\\n",
    "--chexlocalize_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\" \\\n",
    "--use_chexpert_for_train \\\n",
    "--chexpert_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\" \\\n",
    "--use_iuxray_for_train \\\n",
    "--iuxray_image_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\" \\\n",
    "--cxrlt2024_weight 4.0 \\\n",
    "--mimiccxr_facts_weight 1.5 \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--iuxray_weight 0.5 \\\n",
    "--vinbig_weight 1.5 \\\n",
    "--chexpert_weight 0.5 \\\n",
    "--chexlocalize_weight 0.4 \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
