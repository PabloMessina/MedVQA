{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 420\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220629_042239.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220629_050643.json\n",
      "   vocab_min_freq: 5\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/clip-vit-bio-clinical-bert-finetuned\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,4e-4,96,5e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 160\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 7\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220629_052724.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220629_123626.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220629_123956.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220629_055107.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220629_055159.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220629_052841.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220629_052842.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,96,5e-6\n",
      "1e-06 4 0.0004 96 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=292,3941135520930231601).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 1940625, len(set(self.report_ids)) = 215125\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|███████████████████████████████████████████| 97/97 [00:10<00:00,  8.93it/s]\n",
      " *** merging from i=0 to j=4, acc_size = 194\n",
      " *** merging from i=5 to j=6, acc_size = 264\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=292,3941135520930231601).pkl.balanced_train_data(bs=160,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 92\n",
      "len(self.val_indices) = 5762\n",
      "len(val_indices) = 5762\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 7\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=41533, len(neg_indices)=173070\n",
      "label = 1, onehot=98, len(pos_indices)=41436, len(neg_indices)=173167\n",
      "label = 2, onehot=99, len(pos_indices)=68536, len(neg_indices)=146067\n",
      "label = 3, onehot=100, len(pos_indices)=8926, len(neg_indices)=205677\n",
      "label = 4, onehot=101, len(pos_indices)=71192, len(neg_indices)=143411\n",
      "label = 5, onehot=102, len(pos_indices)=41924, len(neg_indices)=172679\n",
      "label = 6, onehot=103, len(pos_indices)=19023, len(neg_indices)=195580\n",
      "label = 7, onehot=104, len(pos_indices)=35834, len(neg_indices)=178769\n",
      "label = 8, onehot=105, len(pos_indices)=67927, len(neg_indices)=146676\n",
      "label = 9, onehot=106, len(pos_indices)=12839, len(neg_indices)=201764\n",
      "label = 10, onehot=107, len(pos_indices)=66725, len(neg_indices)=147878\n",
      "label = 11, onehot=108, len(pos_indices)=4638, len(neg_indices)=209965\n",
      "label = 12, onehot=109, len(pos_indices)=7757, len(neg_indices)=206846\n",
      "label = 13, onehot=110, len(pos_indices)=85553, len(neg_indices)=129050\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=25, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1105\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=307,157613170942256249).pkl ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 28800, len(set(self.report_ids)) = 3784\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|██████████████████████████████████████████| 91/91 [00:00<00:00, 659.40it/s]\n",
      " *** merging from i=0 to j=30, acc_size = 166\n",
      " *** merging from i=31 to j=38, acc_size = 170\n",
      " *** merging from i=39 to j=42, acc_size = 178\n",
      " *** merging from i=43 to j=45, acc_size = 161\n",
      " *** merging from i=46 to j=48, acc_size = 195\n",
      " *** merging from i=49 to j=51, acc_size = 232\n",
      " *** merging from i=52 to j=53, acc_size = 198\n",
      " *** merging from i=54 to j=55, acc_size = 214\n",
      " *** merging from i=56 to j=57, acc_size = 260\n",
      " *** merging from i=58 to j=59, acc_size = 298\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=307,157613170942256249).pkl.balanced_train_data(bs=160,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 41\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 7\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2370\n",
      "label = 1, onehot=98, len(pos_indices)=382, len(neg_indices)=3402\n",
      "label = 2, onehot=99, len(pos_indices)=667, len(neg_indices)=3117\n",
      "label = 3, onehot=100, len(pos_indices)=230, len(neg_indices)=3554\n",
      "label = 4, onehot=101, len(pos_indices)=701, len(neg_indices)=3083\n",
      "label = 5, onehot=102, len(pos_indices)=150, len(neg_indices)=3634\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=3744\n",
      "label = 7, onehot=104, len(pos_indices)=134, len(neg_indices)=3650\n",
      "label = 8, onehot=105, len(pos_indices)=360, len(neg_indices)=3424\n",
      "label = 9, onehot=106, len(pos_indices)=99, len(neg_indices)=3685\n",
      "label = 10, onehot=107, len(pos_indices)=288, len(neg_indices)=3496\n",
      "label = 11, onehot=108, len(pos_indices)=70, len(neg_indices)=3714\n",
      "label = 12, onehot=109, len(pos_indices)=113, len(neg_indices)=3671\n",
      "label = 13, onehot=110, len(pos_indices)=213, len(neg_indices)=3571\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "---- Epoch 1/100\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 12.42560, a_loss 8.65747, cD 0.00022, wmdcmp 0.00096, oracc 0.29261, orien_loss 1.22295, chxlmicf1 0.22653, chxlmacf1 0.26174, chx_loss 1.18781, chxlacc 0.47041, chxlrocaucmic 0.49393, chxlrocaucmac 0.46571, qlmicf1 0.08979, qlmacf1 0.11755, ql_loss 1.18868, gacc 0.45851, gloss 0.81057, cxr14micf1 0.10691, cxr14macf1 0.15504, cxr14_loss 1.31380, vnbgmicf1 0.14783, vnbgmacf1 0.18783, vnbg_loss 9.89169, ema 0.00000, 160.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00016, wmdcmp 0.00163, oracc 0.31338, chxlmicf1 0.27344, chxlmacf1 0.30816, chxlacc 0.47954, chxlrocaucmic 0.49253, chxlrocaucmac 0.47621, qlmicf1 0.10722, qlmacf1 0.13974, ema 0.00000, 22.66 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "---- Epoch 2/100\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 12.23223, a_loss 8.09317, cD 0.00023, wmdcmp 0.00032, oracc 0.36382, orien_loss 1.14759, chxlmicf1 0.24095, chxlmacf1 0.27309, chx_loss 1.16757, chxlacc 0.47948, chxlrocaucmic 0.50995, chxlrocaucmac 0.48575, qlmicf1 0.09732, qlmacf1 0.12267, ql_loss 1.17450, gacc 0.48220, gloss 0.77893, cxr14micf1 0.10773, cxr14macf1 0.15672, cxr14_loss 1.31041, vnbgmicf1 0.16274, vnbgmacf1 0.19976, vnbg_loss 9.13521, ema 0.01117, 117.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, oracc 0.44641, chxlmicf1 0.29067, chxlmacf1 0.32048, chxlacc 0.48875, chxlrocaucmic 0.51530, chxlrocaucmac 0.50545, qlmicf1 0.12061, qlmacf1 0.14782, ema 0.03620, 19.90 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "---- Epoch 3/100\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 11.53442, a_loss 6.27414, cD 0.03992, wmdcmp 0.00644, oracc 0.61419, orien_loss 0.88816, chxlmicf1 0.30526, chxlmacf1 0.31826, chx_loss 1.10511, chxlacc 0.52689, chxlrocaucmic 0.58623, chxlrocaucmac 0.57319, qlmicf1 0.13405, qlmacf1 0.14007, ql_loss 1.12153, gacc 0.53214, gloss 0.71446, cxr14micf1 0.12115, cxr14macf1 0.17415, cxr14_loss 1.26536, vnbgmicf1 0.21971, vnbgmacf1 0.23723, vnbg_loss 6.82970, ema 0.01248, 114.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.12326, wmdcmp 0.01988, oracc 0.81308, chxlmicf1 0.43682, chxlmacf1 0.40432, chxlacc 0.56812, chxlrocaucmic 0.63064, chxlrocaucmac 0.62976, qlmicf1 0.18861, qlmacf1 0.17880, ema 0.00000, 19.72 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-05.\n",
      "---- Epoch 4/100\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 9.68256, a_loss 3.82043, cD 0.07436, wmdcmp 0.01635, oracc 0.90443, orien_loss 0.43928, chxlmicf1 0.45933, chxlmacf1 0.41915, chx_loss 0.98538, chxlacc 0.65117, chxlrocaucmic 0.74275, chxlrocaucmac 0.72660, qlmicf1 0.25833, qlmacf1 0.18266, ql_loss 0.99867, gacc 0.64524, gloss 0.63062, cxr14micf1 0.20851, cxr14macf1 0.24694, cxr14_loss 1.14541, vnbgmicf1 0.42222, vnbgmacf1 0.33074, vnbg_loss 4.16447, ema 0.07379, 116.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.17727, wmdcmp 0.03073, oracc 0.97956, chxlmicf1 0.54655, chxlmacf1 0.50219, chxlacc 0.67458, chxlrocaucmic 0.76783, chxlrocaucmac 0.74892, qlmicf1 0.31817, qlmacf1 0.23301, ema 0.43167, 19.83 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-04.\n",
      "---- Epoch 5/100\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 7.55588, a_loss 1.85297, cD 0.37640, wmdcmp 0.06418, oracc 0.96278, orien_loss 0.16731, chxlmicf1 0.50255, chxlmacf1 0.45914, chx_loss 0.91364, chxlacc 0.69934, chxlrocaucmic 0.78659, chxlrocaucmac 0.76802, qlmicf1 0.31649, qlmacf1 0.20750, ql_loss 0.90604, gacc 0.72286, gloss 0.54902, cxr14micf1 0.29711, cxr14macf1 0.30368, cxr14_loss 1.03346, vnbgmicf1 0.49359, vnbgmacf1 0.38202, vnbg_loss 1.64816, ema 0.54625, 119.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.91744, wmdcmp 0.13733, oracc 0.99284, chxlmicf1 0.55375, chxlmacf1 0.50956, chxlacc 0.68754, chxlrocaucmic 0.78369, chxlrocaucmac 0.76282, qlmicf1 0.33963, qlmacf1 0.24551, ema 0.64253, 19.95 secs\n",
      "Adjusting learning rate of group 0 to 3.8215e-04.\n",
      "---- Epoch 6/100\n",
      "(1) Training stage (lr = 0.000382) ...\n",
      "loss 5.72727, a_loss 1.38337, cD 0.78800, wmdcmp 0.11453, oracc 0.97599, orien_loss 0.09850, chxlmicf1 0.50575, chxlmacf1 0.46173, chx_loss 0.90280, chxlacc 0.70403, chxlrocaucmic 0.79204, chxlrocaucmac 0.77350, qlmicf1 0.32332, qlmacf1 0.21245, ql_loss 0.88108, gacc 0.76792, gloss 0.50164, cxr14micf1 0.31770, cxr14macf1 0.31733, cxr14_loss 0.99179, vnbgmicf1 0.50437, vnbgmacf1 0.39383, vnbg_loss 1.01593, ema 0.64155, 119.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.03894, wmdcmp 0.14930, oracc 0.99284, chxlmicf1 0.55391, chxlmacf1 0.50903, chxlacc 0.69417, chxlrocaucmic 0.78432, chxlrocaucmac 0.76246, qlmicf1 0.34081, qlmacf1 0.24628, ema 0.65249, 20.12 secs\n",
      "Adjusting learning rate of group 0 to 3.6510e-04.\n",
      "---- Epoch 7/100\n",
      "(1) Training stage (lr = 0.000365) ...\n",
      "loss 5.43839, a_loss 1.24650, cD 0.97461, wmdcmp 0.13727, oracc 0.98053, orien_loss 0.07843, chxlmicf1 0.50863, chxlmacf1 0.46408, chx_loss 0.89734, chxlacc 0.70597, chxlrocaucmic 0.79342, chxlrocaucmac 0.77454, qlmicf1 0.32708, qlmacf1 0.21476, ql_loss 0.87073, gacc 0.78726, gloss 0.46727, cxr14micf1 0.32267, cxr14macf1 0.32288, cxr14_loss 0.99124, vnbgmicf1 0.50989, vnbgmacf1 0.39604, vnbg_loss 0.92210, ema 0.66033, 119.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13988, wmdcmp 0.16070, oracc 0.99284, chxlmicf1 0.55396, chxlmacf1 0.51047, chxlacc 0.69137, chxlrocaucmic 0.78541, chxlrocaucmac 0.76314, qlmicf1 0.33769, qlmacf1 0.24664, ema 0.66787, 20.20 secs\n",
      "Adjusting learning rate of group 0 to 3.4881e-04.\n",
      "---- Epoch 8/100\n",
      "(1) Training stage (lr = 0.000349) ...\n",
      "loss 4.91560, a_loss 1.17103, cD 1.06038, wmdcmp 0.14822, oracc 0.98223, orien_loss 0.06743, chxlmicf1 0.50989, chxlmacf1 0.46544, chx_loss 0.89501, chxlacc 0.70740, chxlrocaucmic 0.79485, chxlrocaucmac 0.77599, qlmicf1 0.32810, qlmacf1 0.21522, ql_loss 0.86493, gacc 0.79119, gloss 0.45741, cxr14micf1 0.31852, cxr14macf1 0.32122, cxr14_loss 0.98360, vnbgmicf1 0.51680, vnbgmacf1 0.40181, vnbg_loss 0.88343, ema 0.67040, 119.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17982, wmdcmp 0.16771, oracc 0.99284, chxlmicf1 0.55431, chxlmacf1 0.50941, chxlacc 0.69208, chxlrocaucmic 0.78606, chxlrocaucmac 0.76727, qlmicf1 0.34666, qlmacf1 0.25025, ema 0.69050, 20.36 secs\n",
      "Adjusting learning rate of group 0 to 3.3325e-04.\n",
      "---- Epoch 9/100\n",
      "(1) Training stage (lr = 0.000333) ...\n",
      "loss 4.90789, a_loss 1.13046, cD 1.11328, wmdcmp 0.15376, oracc 0.98533, orien_loss 0.05746, chxlmicf1 0.51160, chxlmacf1 0.46752, chx_loss 0.88962, chxlacc 0.70884, chxlrocaucmic 0.79755, chxlrocaucmac 0.77908, qlmicf1 0.33172, qlmacf1 0.21727, ql_loss 0.86272, gacc 0.79655, gloss 0.44690, cxr14micf1 0.32237, cxr14macf1 0.32161, cxr14_loss 0.98231, vnbgmicf1 0.52623, vnbgmacf1 0.41026, vnbg_loss 0.85551, ema 0.67903, 120.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26995, wmdcmp 0.17783, oracc 0.99284, chxlmicf1 0.55310, chxlmacf1 0.51032, chxlacc 0.69130, chxlrocaucmic 0.78373, chxlrocaucmac 0.76579, qlmicf1 0.34652, qlmacf1 0.25004, ema 0.68778, 20.23 secs\n",
      "Adjusting learning rate of group 0 to 3.1838e-04.\n",
      "---- Epoch 10/100\n",
      "(1) Training stage (lr = 0.000318) ...\n",
      "loss 4.83570, a_loss 1.09542, cD 1.16101, wmdcmp 0.16046, oracc 0.98634, orien_loss 0.05285, chxlmicf1 0.51279, chxlmacf1 0.46800, chx_loss 0.88759, chxlacc 0.70906, chxlrocaucmic 0.79653, chxlrocaucmac 0.77899, qlmicf1 0.33492, qlmacf1 0.21763, ql_loss 0.85809, gacc 0.80696, gloss 0.43319, cxr14micf1 0.33191, cxr14macf1 0.32885, cxr14_loss 0.97436, vnbgmicf1 0.52779, vnbgmacf1 0.41003, vnbg_loss 0.83418, ema 0.68537, 121.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32758, wmdcmp 0.18384, oracc 0.99284, chxlmicf1 0.55784, chxlmacf1 0.51297, chxlacc 0.69826, chxlrocaucmic 0.78727, chxlrocaucmac 0.76581, qlmicf1 0.34608, qlmacf1 0.24802, ema 0.68235, 19.98 secs\n",
      "Adjusting learning rate of group 0 to 3.0417e-04.\n",
      "---- Epoch 11/100\n",
      "(1) Training stage (lr = 0.000304) ...\n",
      "loss 4.57457, a_loss 1.07524, cD 1.20843, wmdcmp 0.16534, oracc 0.98671, orien_loss 0.04991, chxlmicf1 0.51464, chxlmacf1 0.46926, chx_loss 0.88677, chxlacc 0.71053, chxlrocaucmic 0.79854, chxlrocaucmac 0.77984, qlmicf1 0.33314, qlmacf1 0.21691, ql_loss 0.85866, gacc 0.80631, gloss 0.42938, cxr14micf1 0.33062, cxr14macf1 0.32563, cxr14_loss 0.97231, vnbgmicf1 0.52762, vnbgmacf1 0.40889, vnbg_loss 0.83082, ema 0.69123, 119.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26218, wmdcmp 0.17814, oracc 0.99284, chxlmicf1 0.55327, chxlmacf1 0.50834, chxlacc 0.69225, chxlrocaucmic 0.78680, chxlrocaucmac 0.76609, qlmicf1 0.34300, qlmacf1 0.24872, ema 0.69050, 20.40 secs\n",
      "Adjusting learning rate of group 0 to 2.9060e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 12/100\n",
      "(1) Training stage (lr = 0.000291) ...\n",
      "loss 4.38396, a_loss 1.05383, cD 1.23858, wmdcmp 0.16891, oracc 0.98583, orien_loss 0.05013, chxlmicf1 0.51404, chxlmacf1 0.46898, chx_loss 0.88592, chxlacc 0.71033, chxlrocaucmic 0.79735, chxlrocaucmac 0.77955, qlmicf1 0.33658, qlmacf1 0.21718, ql_loss 0.85340, gacc 0.81387, gloss 0.41818, cxr14micf1 0.33829, cxr14macf1 0.33115, cxr14_loss 0.96663, vnbgmicf1 0.53785, vnbgmacf1 0.41677, vnbg_loss 0.79716, ema 0.68919, 120.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30864, wmdcmp 0.18200, oracc 0.99284, chxlmicf1 0.55694, chxlmacf1 0.51278, chxlacc 0.69205, chxlrocaucmic 0.78761, chxlrocaucmac 0.76643, qlmicf1 0.34917, qlmacf1 0.24948, ema 0.68688, 20.04 secs\n",
      "Adjusting learning rate of group 0 to 2.7763e-04.\n",
      "---- Epoch 13/100\n",
      "(1) Training stage (lr = 0.000278) ...\n",
      "loss 4.64574, a_loss 1.04180, cD 1.25417, wmdcmp 0.17067, oracc 0.98766, orien_loss 0.04628, chxlmicf1 0.51431, chxlmacf1 0.46900, chx_loss 0.88456, chxlacc 0.71088, chxlrocaucmic 0.79887, chxlrocaucmac 0.78092, qlmicf1 0.33770, qlmacf1 0.21847, ql_loss 0.85032, gacc 0.81643, gloss 0.41480, cxr14micf1 0.32330, cxr14macf1 0.32293, cxr14_loss 0.96859, vnbgmicf1 0.53246, vnbgmacf1 0.41212, vnbg_loss 0.80172, ema 0.69959, 119.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33004, wmdcmp 0.18502, oracc 0.99284, chxlmicf1 0.55591, chxlmacf1 0.51205, chxlacc 0.69354, chxlrocaucmic 0.78774, chxlrocaucmac 0.76746, qlmicf1 0.34753, qlmacf1 0.24837, ema 0.69955, 20.35 secs\n",
      "Adjusting learning rate of group 0 to 2.6524e-04.\n",
      "---- Epoch 14/100\n",
      "(1) Training stage (lr = 0.000265) ...\n",
      "loss 4.44290, a_loss 1.02316, cD 1.27938, wmdcmp 0.17400, oracc 0.98747, orien_loss 0.04563, chxlmicf1 0.51586, chxlmacf1 0.47137, chx_loss 0.88019, chxlacc 0.71122, chxlrocaucmic 0.79979, chxlrocaucmac 0.78196, qlmicf1 0.33726, qlmacf1 0.22072, ql_loss 0.85034, gacc 0.81815, gloss 0.40798, cxr14micf1 0.34216, cxr14macf1 0.33389, cxr14_loss 0.95922, vnbgmicf1 0.53984, vnbgmacf1 0.41853, vnbg_loss 0.79004, ema 0.69810, 119.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29214, wmdcmp 0.17936, oracc 0.99284, chxlmicf1 0.55377, chxlmacf1 0.50934, chxlacc 0.69310, chxlrocaucmic 0.78685, chxlrocaucmac 0.76637, qlmicf1 0.34947, qlmacf1 0.25174, ema 0.71403, 20.31 secs\n",
      "Adjusting learning rate of group 0 to 2.5341e-04.\n",
      "---- Epoch 15/100\n",
      "(1) Training stage (lr = 0.000253) ...\n",
      "loss 4.42702, a_loss 1.01183, cD 1.31104, wmdcmp 0.17726, oracc 0.98776, orien_loss 0.04232, chxlmicf1 0.51498, chxlmacf1 0.47016, chx_loss 0.88205, chxlacc 0.71045, chxlrocaucmic 0.79823, chxlrocaucmac 0.78100, qlmicf1 0.33991, qlmacf1 0.22434, ql_loss 0.84706, gacc 0.81839, gloss 0.40874, cxr14micf1 0.34014, cxr14macf1 0.33376, cxr14_loss 0.95472, vnbgmicf1 0.54371, vnbgmacf1 0.42068, vnbg_loss 0.78207, ema 0.69966, 121.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27725, wmdcmp 0.18038, oracc 0.99284, chxlmicf1 0.55354, chxlmacf1 0.51041, chxlacc 0.69382, chxlrocaucmic 0.78786, chxlrocaucmac 0.76747, qlmicf1 0.35130, qlmacf1 0.25034, ema 0.69502, 20.41 secs\n",
      "Adjusting learning rate of group 0 to 2.4210e-04.\n",
      "---- Epoch 16/100\n",
      "(1) Training stage (lr = 0.000242) ...\n",
      "loss 4.59655, a_loss 1.00239, cD 1.31119, wmdcmp 0.17783, oracc 0.98828, orien_loss 0.04047, chxlmicf1 0.51572, chxlmacf1 0.47111, chx_loss 0.88141, chxlacc 0.71204, chxlrocaucmic 0.79914, chxlrocaucmac 0.78205, qlmicf1 0.34127, qlmacf1 0.22179, ql_loss 0.84456, gacc 0.82423, gloss 0.39967, cxr14micf1 0.33747, cxr14macf1 0.33271, cxr14_loss 0.95560, vnbgmicf1 0.54324, vnbgmacf1 0.41995, vnbg_loss 0.78099, ema 0.70378, 121.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30693, wmdcmp 0.18316, oracc 0.99284, chxlmicf1 0.55276, chxlmacf1 0.50975, chxlacc 0.69670, chxlrocaucmic 0.78703, chxlrocaucmac 0.76691, qlmicf1 0.35453, qlmacf1 0.25254, ema 0.70950, 20.09 secs\n",
      "Adjusting learning rate of group 0 to 2.3130e-04.\n",
      "---- Epoch 17/100\n",
      "(1) Training stage (lr = 0.000231) ...\n",
      "loss 4.43274, a_loss 0.99579, cD 1.34141, wmdcmp 0.18039, oracc 0.98825, orien_loss 0.03975, chxlmicf1 0.51670, chxlmacf1 0.47208, chx_loss 0.87935, chxlacc 0.71223, chxlrocaucmic 0.79983, chxlrocaucmac 0.78303, qlmicf1 0.34246, qlmacf1 0.22222, ql_loss 0.84207, gacc 0.81833, gloss 0.40566, cxr14micf1 0.33638, cxr14macf1 0.33079, cxr14_loss 0.95838, vnbgmicf1 0.54949, vnbgmacf1 0.42926, vnbg_loss 0.76717, ema 0.70133, 120.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37077, wmdcmp 0.18940, oracc 0.99284, chxlmicf1 0.54958, chxlmacf1 0.50653, chxlacc 0.69125, chxlrocaucmic 0.78588, chxlrocaucmac 0.76583, qlmicf1 0.35181, qlmacf1 0.25078, ema 0.69955, 20.14 secs\n",
      "Adjusting learning rate of group 0 to 2.2098e-04.\n",
      "---- Epoch 18/100\n",
      "(1) Training stage (lr = 0.000221) ...\n",
      "loss 4.44001, a_loss 0.98804, cD 1.34764, wmdcmp 0.18147, oracc 0.98876, orien_loss 0.03938, chxlmicf1 0.51616, chxlmacf1 0.47097, chx_loss 0.87941, chxlacc 0.71272, chxlrocaucmic 0.80063, chxlrocaucmac 0.78349, qlmicf1 0.34385, qlmacf1 0.22375, ql_loss 0.83843, gacc 0.82750, gloss 0.39113, cxr14micf1 0.33295, cxr14macf1 0.32966, cxr14_loss 0.95956, vnbgmicf1 0.54886, vnbgmacf1 0.42423, vnbg_loss 0.76330, ema 0.70522, 121.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33500, wmdcmp 0.18580, oracc 0.99284, chxlmicf1 0.54849, chxlmacf1 0.50553, chxlacc 0.68947, chxlrocaucmic 0.78629, chxlrocaucmac 0.76720, qlmicf1 0.35369, qlmacf1 0.25115, ema 0.70950, 20.51 secs\n",
      "Adjusting learning rate of group 0 to 2.1112e-04.\n",
      "---- Epoch 19/100\n",
      "(1) Training stage (lr = 0.000211) ...\n",
      "loss 4.40388, a_loss 0.97458, cD 1.37995, wmdcmp 0.18502, oracc 0.98894, orien_loss 0.03810, chxlmicf1 0.51805, chxlmacf1 0.47304, chx_loss 0.87590, chxlacc 0.71303, chxlrocaucmic 0.80181, chxlrocaucmac 0.78464, qlmicf1 0.34431, qlmacf1 0.22696, ql_loss 0.83933, gacc 0.82577, gloss 0.39670, cxr14micf1 0.33313, cxr14macf1 0.33101, cxr14_loss 0.96429, vnbgmicf1 0.55256, vnbgmacf1 0.42803, vnbg_loss 0.75296, ema 0.70618, 120.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33208, wmdcmp 0.18527, oracc 0.99284, chxlmicf1 0.55016, chxlmacf1 0.50840, chxlacc 0.68743, chxlrocaucmic 0.78746, chxlrocaucmac 0.76775, qlmicf1 0.35247, qlmacf1 0.25067, ema 0.70769, 20.23 secs\n",
      "Adjusting learning rate of group 0 to 2.0170e-04.\n",
      "---- Epoch 20/100\n",
      "(1) Training stage (lr = 0.000202) ...\n",
      "loss 4.49744, a_loss 0.97516, cD 1.38639, wmdcmp 0.18589, oracc 0.98847, orien_loss 0.03810, chxlmicf1 0.51803, chxlmacf1 0.47290, chx_loss 0.87482, chxlacc 0.71320, chxlrocaucmic 0.80206, chxlrocaucmac 0.78546, qlmicf1 0.34565, qlmacf1 0.22387, ql_loss 0.83472, gacc 0.82613, gloss 0.39577, cxr14micf1 0.33769, cxr14macf1 0.33107, cxr14_loss 0.94704, vnbgmicf1 0.55266, vnbgmacf1 0.42614, vnbg_loss 0.75486, ema 0.71021, 120.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36589, wmdcmp 0.18958, oracc 0.99284, chxlmicf1 0.55934, chxlmacf1 0.51587, chxlacc 0.70036, chxlrocaucmic 0.78931, chxlrocaucmac 0.76850, qlmicf1 0.35474, qlmacf1 0.25227, ema 0.70226, 20.46 secs\n",
      "Adjusting learning rate of group 0 to 1.9270e-04.\n",
      "---- Epoch 21/100\n",
      "(1) Training stage (lr = 0.000193) ...\n",
      "loss 4.46581, a_loss 0.96528, cD 1.40377, wmdcmp 0.18805, oracc 0.98892, orien_loss 0.03748, chxlmicf1 0.51801, chxlmacf1 0.47279, chx_loss 0.87563, chxlacc 0.71441, chxlrocaucmic 0.80127, chxlrocaucmac 0.78439, qlmicf1 0.34444, qlmacf1 0.22528, ql_loss 0.83742, gacc 0.82851, gloss 0.38862, cxr14micf1 0.34548, cxr14macf1 0.33536, cxr14_loss 0.95056, vnbgmicf1 0.55202, vnbgmacf1 0.42730, vnbg_loss 0.75072, ema 0.71353, 120.39 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34167, wmdcmp 0.18601, oracc 0.99284, chxlmicf1 0.55377, chxlmacf1 0.51014, chxlacc 0.69392, chxlrocaucmic 0.78908, chxlrocaucmac 0.76890, qlmicf1 0.35235, qlmacf1 0.25037, ema 0.70498, 20.18 secs\n",
      "Adjusting learning rate of group 0 to 1.8410e-04.\n",
      "---- Epoch 22/100\n",
      "(1) Training stage (lr = 0.000184) ...\n",
      "loss 4.47604, a_loss 0.96327, cD 1.41249, wmdcmp 0.18853, oracc 0.98969, orien_loss 0.03499, chxlmicf1 0.51758, chxlmacf1 0.47205, chx_loss 0.87614, chxlacc 0.71344, chxlrocaucmic 0.80084, chxlrocaucmac 0.78432, qlmicf1 0.34472, qlmacf1 0.22494, ql_loss 0.83829, gacc 0.82946, gloss 0.38804, cxr14micf1 0.33407, cxr14macf1 0.33092, cxr14_loss 0.96028, vnbgmicf1 0.55597, vnbgmacf1 0.42955, vnbg_loss 0.74334, ema 0.71081, 120.51 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.30901, wmdcmp 0.18301, oracc 0.99284, chxlmicf1 0.55103, chxlmacf1 0.50843, chxlacc 0.69344, chxlrocaucmic 0.78700, chxlrocaucmac 0.76926, qlmicf1 0.34900, qlmacf1 0.24997, ema 0.70317, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 1.7589e-04.\n",
      "---- Epoch 23/100\n",
      "(1) Training stage (lr = 0.000176) ...\n",
      "loss 4.29614, a_loss 0.95375, cD 1.42369, wmdcmp 0.18993, oracc 0.99001, orien_loss 0.03440, chxlmicf1 0.51893, chxlmacf1 0.47320, chx_loss 0.87310, chxlacc 0.71467, chxlrocaucmic 0.80356, chxlrocaucmac 0.78638, qlmicf1 0.34689, qlmacf1 0.22282, ql_loss 0.83087, gacc 0.82750, gloss 0.39022, cxr14micf1 0.33490, cxr14macf1 0.33341, cxr14_loss 0.95007, vnbgmicf1 0.55720, vnbgmacf1 0.43070, vnbg_loss 0.74351, ema 0.71275, 122.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38467, wmdcmp 0.18966, oracc 0.99284, chxlmicf1 0.55214, chxlmacf1 0.50829, chxlacc 0.69276, chxlrocaucmic 0.78834, chxlrocaucmac 0.76642, qlmicf1 0.35632, qlmacf1 0.25328, ema 0.71312, 20.27 secs\n",
      "Adjusting learning rate of group 0 to 1.6804e-04.\n",
      "---- Epoch 24/100\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 4.33132, a_loss 0.95580, cD 1.42250, wmdcmp 0.18960, oracc 0.98945, orien_loss 0.03558, chxlmicf1 0.51915, chxlmacf1 0.47401, chx_loss 0.87451, chxlacc 0.71445, chxlrocaucmic 0.80158, chxlrocaucmac 0.78558, qlmicf1 0.34713, qlmacf1 0.22380, ql_loss 0.83449, gacc 0.82685, gloss 0.38623, cxr14micf1 0.35195, cxr14macf1 0.33854, cxr14_loss 0.94900, vnbgmicf1 0.56055, vnbgmacf1 0.43601, vnbg_loss 0.73598, ema 0.71005, 121.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32888, wmdcmp 0.18608, oracc 0.99284, chxlmicf1 0.55195, chxlmacf1 0.50858, chxlacc 0.69089, chxlrocaucmic 0.78697, chxlrocaucmac 0.76612, qlmicf1 0.35380, qlmacf1 0.24991, ema 0.70588, 20.04 secs\n",
      "Adjusting learning rate of group 0 to 1.6054e-04.\n",
      "---- Epoch 25/100\n",
      "(1) Training stage (lr = 0.000161) ...\n",
      "loss 4.38682, a_loss 0.94651, cD 1.44879, wmdcmp 0.19243, oracc 0.99041, orien_loss 0.03360, chxlmicf1 0.51854, chxlmacf1 0.47283, chx_loss 0.87420, chxlacc 0.71425, chxlrocaucmic 0.80201, chxlrocaucmac 0.78597, qlmicf1 0.35008, qlmacf1 0.22430, ql_loss 0.82956, gacc 0.83173, gloss 0.38636, cxr14micf1 0.33616, cxr14macf1 0.33181, cxr14_loss 0.95292, vnbgmicf1 0.56004, vnbgmacf1 0.43835, vnbg_loss 0.73738, ema 0.71209, 120.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35968, wmdcmp 0.18866, oracc 0.99284, chxlmicf1 0.55295, chxlmacf1 0.50975, chxlacc 0.69255, chxlrocaucmic 0.78776, chxlrocaucmac 0.76783, qlmicf1 0.35484, qlmacf1 0.25119, ema 0.69774, 20.14 secs\n",
      "Adjusting learning rate of group 0 to 1.5338e-04.\n",
      "---- Epoch 26/100\n",
      "(1) Training stage (lr = 0.000153) ...\n",
      "loss 4.43330, a_loss 0.94217, cD 1.45791, wmdcmp 0.19399, oracc 0.99081, orien_loss 0.03247, chxlmicf1 0.51702, chxlmacf1 0.47167, chx_loss 0.87749, chxlacc 0.71330, chxlrocaucmic 0.80132, chxlrocaucmac 0.78477, qlmicf1 0.34950, qlmacf1 0.22379, ql_loss 0.83073, gacc 0.83125, gloss 0.38473, cxr14micf1 0.34128, cxr14macf1 0.33459, cxr14_loss 0.94861, vnbgmicf1 0.56657, vnbgmacf1 0.43781, vnbg_loss 0.71399, ema 0.71179, 120.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36457, wmdcmp 0.18904, oracc 0.99284, chxlmicf1 0.55367, chxlmacf1 0.51076, chxlacc 0.69279, chxlrocaucmic 0.78763, chxlrocaucmac 0.76846, qlmicf1 0.35553, qlmacf1 0.25176, ema 0.70498, 20.44 secs\n",
      "Adjusting learning rate of group 0 to 1.4653e-04.\n",
      "---- Epoch 27/100\n",
      "(1) Training stage (lr = 0.000147) ...\n",
      "loss 4.49452, a_loss 0.93996, cD 1.44807, wmdcmp 0.19304, oracc 0.99023, orien_loss 0.03294, chxlmicf1 0.51751, chxlmacf1 0.47261, chx_loss 0.87462, chxlacc 0.71410, chxlrocaucmic 0.80149, chxlrocaucmac 0.78477, qlmicf1 0.34710, qlmacf1 0.22747, ql_loss 0.83322, gacc 0.83452, gloss 0.38396, cxr14micf1 0.34756, cxr14macf1 0.33905, cxr14_loss 0.94540, vnbgmicf1 0.56071, vnbgmacf1 0.43449, vnbg_loss 0.72885, ema 0.71207, 120.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39201, wmdcmp 0.19079, oracc 0.99284, chxlmicf1 0.55726, chxlmacf1 0.51299, chxlacc 0.69775, chxlrocaucmic 0.78788, chxlrocaucmac 0.76827, qlmicf1 0.35621, qlmacf1 0.25259, ema 0.70679, 20.08 secs\n",
      "Adjusting learning rate of group 0 to 1.3999e-04.\n",
      "---- Epoch 28/100\n",
      "(1) Training stage (lr = 0.000140) ...\n",
      "loss 4.36270, a_loss 0.93319, cD 1.45889, wmdcmp 0.19372, oracc 0.99053, orien_loss 0.03178, chxlmicf1 0.52005, chxlmacf1 0.47469, chx_loss 0.87147, chxlacc 0.71603, chxlrocaucmic 0.80247, chxlrocaucmac 0.78630, qlmicf1 0.34982, qlmacf1 0.23109, ql_loss 0.82939, gacc 0.83274, gloss 0.38157, cxr14micf1 0.34687, cxr14macf1 0.33785, cxr14_loss 0.93652, vnbgmicf1 0.56479, vnbgmacf1 0.43938, vnbg_loss 0.71276, ema 0.71916, 121.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37285, wmdcmp 0.18890, oracc 0.99284, chxlmicf1 0.55510, chxlmacf1 0.51087, chxlacc 0.69526, chxlrocaucmic 0.78876, chxlrocaucmac 0.76818, qlmicf1 0.35418, qlmacf1 0.25202, ema 0.70136, 20.27 secs\n",
      "Adjusting learning rate of group 0 to 1.3375e-04.\n",
      "---- Epoch 29/100\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 4.32679, a_loss 0.93282, cD 1.47160, wmdcmp 0.19595, oracc 0.98989, orien_loss 0.03287, chxlmicf1 0.51936, chxlmacf1 0.47448, chx_loss 0.87196, chxlacc 0.71454, chxlrocaucmic 0.80286, chxlrocaucmac 0.78615, qlmicf1 0.35100, qlmacf1 0.22439, ql_loss 0.83069, gacc 0.83446, gloss 0.37693, cxr14micf1 0.34511, cxr14macf1 0.33608, cxr14_loss 0.94588, vnbgmicf1 0.56759, vnbgmacf1 0.43642, vnbg_loss 0.71683, ema 0.71371, 121.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39177, wmdcmp 0.19249, oracc 0.99284, chxlmicf1 0.55429, chxlmacf1 0.50920, chxlacc 0.69491, chxlrocaucmic 0.78916, chxlrocaucmac 0.76703, qlmicf1 0.35436, qlmacf1 0.25244, ema 0.70498, 20.22 secs\n",
      "Adjusting learning rate of group 0 to 1.2778e-04.\n",
      "---- Epoch 30/100\n",
      "(1) Training stage (lr = 0.000128) ...\n",
      "loss 4.21228, a_loss 0.93057, cD 1.47617, wmdcmp 0.19607, oracc 0.99041, orien_loss 0.03187, chxlmicf1 0.51724, chxlmacf1 0.47240, chx_loss 0.87295, chxlacc 0.71354, chxlrocaucmic 0.80238, chxlrocaucmac 0.78625, qlmicf1 0.34768, qlmacf1 0.22463, ql_loss 0.82825, gacc 0.83458, gloss 0.38603, cxr14micf1 0.34463, cxr14macf1 0.33792, cxr14_loss 0.94357, vnbgmicf1 0.56683, vnbgmacf1 0.44174, vnbg_loss 0.71808, ema 0.71577, 120.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39136, wmdcmp 0.19179, oracc 0.99284, chxlmicf1 0.55309, chxlmacf1 0.50856, chxlacc 0.69482, chxlrocaucmic 0.78872, chxlrocaucmac 0.76683, qlmicf1 0.35958, qlmacf1 0.25459, ema 0.70860, 20.35 secs\n",
      "Adjusting learning rate of group 0 to 1.2208e-04.\n",
      "---- Epoch 31/100\n",
      "(1) Training stage (lr = 0.000122) ...\n",
      "loss 4.44042, a_loss 0.92461, cD 1.49153, wmdcmp 0.19755, oracc 0.99046, orien_loss 0.03158, chxlmicf1 0.52090, chxlmacf1 0.47443, chx_loss 0.87329, chxlacc 0.71542, chxlrocaucmic 0.80262, chxlrocaucmac 0.78539, qlmicf1 0.35132, qlmacf1 0.22637, ql_loss 0.82852, gacc 0.83685, gloss 0.37750, cxr14micf1 0.34289, cxr14macf1 0.33597, cxr14_loss 0.94428, vnbgmicf1 0.56718, vnbgmacf1 0.43939, vnbg_loss 0.71104, ema 0.71136, 120.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37056, wmdcmp 0.18918, oracc 0.99284, chxlmicf1 0.55291, chxlmacf1 0.50949, chxlacc 0.69505, chxlrocaucmic 0.78634, chxlrocaucmac 0.76750, qlmicf1 0.36014, qlmacf1 0.25380, ema 0.71493, 20.29 secs\n",
      "Adjusting learning rate of group 0 to 1.1663e-04.\n",
      "---- Epoch 32/100\n",
      "(1) Training stage (lr = 0.000117) ...\n",
      "loss 4.26158, a_loss 0.92279, cD 1.49945, wmdcmp 0.19887, oracc 0.99073, orien_loss 0.02932, chxlmicf1 0.52000, chxlmacf1 0.47446, chx_loss 0.87109, chxlacc 0.71549, chxlrocaucmic 0.80361, chxlrocaucmac 0.78755, qlmicf1 0.34933, qlmacf1 0.22557, ql_loss 0.82818, gacc 0.84125, gloss 0.37072, cxr14micf1 0.35596, cxr14macf1 0.34332, cxr14_loss 0.93402, vnbgmicf1 0.57142, vnbgmacf1 0.44219, vnbg_loss 0.71440, ema 0.71481, 121.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39334, wmdcmp 0.19146, oracc 0.99284, chxlmicf1 0.55243, chxlmacf1 0.50937, chxlacc 0.69429, chxlrocaucmic 0.78779, chxlrocaucmac 0.76744, qlmicf1 0.35858, qlmacf1 0.25327, ema 0.71041, 20.23 secs\n",
      "Adjusting learning rate of group 0 to 1.1143e-04.\n",
      "---- Epoch 33/100\n",
      "(1) Training stage (lr = 0.000111) ...\n",
      "loss 4.30517, a_loss 0.91974, cD 1.49394, wmdcmp 0.19812, oracc 0.99073, orien_loss 0.03296, chxlmicf1 0.52044, chxlmacf1 0.47509, chx_loss 0.86893, chxlacc 0.71617, chxlrocaucmic 0.80339, chxlrocaucmac 0.78745, qlmicf1 0.35034, qlmacf1 0.23308, ql_loss 0.82553, gacc 0.83405, gloss 0.37694, cxr14micf1 0.34581, cxr14macf1 0.33823, cxr14_loss 0.93633, vnbgmicf1 0.57032, vnbgmacf1 0.44237, vnbg_loss 0.70630, ema 0.71678, 121.09 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.38118, wmdcmp 0.18973, oracc 0.99284, chxlmicf1 0.55184, chxlmacf1 0.50838, chxlacc 0.69341, chxlrocaucmic 0.78751, chxlrocaucmac 0.76736, qlmicf1 0.35832, qlmacf1 0.25342, ema 0.70769, 20.34 secs\n",
      "Adjusting learning rate of group 0 to 1.0646e-04.\n",
      "---- Epoch 34/100\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 4.23836, a_loss 0.91751, cD 1.50538, wmdcmp 0.20019, oracc 0.99074, orien_loss 0.02896, chxlmicf1 0.51898, chxlmacf1 0.47425, chx_loss 0.87159, chxlacc 0.71566, chxlrocaucmic 0.80343, chxlrocaucmac 0.78732, qlmicf1 0.34963, qlmacf1 0.23145, ql_loss 0.82345, gacc 0.83298, gloss 0.37914, cxr14micf1 0.35023, cxr14macf1 0.34087, cxr14_loss 0.94001, vnbgmicf1 0.57149, vnbgmacf1 0.44513, vnbg_loss 0.70162, ema 0.71745, 120.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39826, wmdcmp 0.19283, oracc 0.99284, chxlmicf1 0.55341, chxlmacf1 0.50948, chxlacc 0.69427, chxlrocaucmic 0.78814, chxlrocaucmac 0.76829, qlmicf1 0.36115, qlmacf1 0.25456, ema 0.71584, 20.09 secs\n",
      "Adjusting learning rate of group 0 to 1.0171e-04.\n",
      "---- Epoch 35/100\n",
      "(1) Training stage (lr = 0.000102) ...\n",
      "loss 4.34760, a_loss 0.91546, cD 1.50105, wmdcmp 0.19863, oracc 0.98989, orien_loss 0.03155, chxlmicf1 0.51939, chxlmacf1 0.47445, chx_loss 0.87227, chxlacc 0.71492, chxlrocaucmic 0.80242, chxlrocaucmac 0.78540, qlmicf1 0.35143, qlmacf1 0.23028, ql_loss 0.82892, gacc 0.83685, gloss 0.37228, cxr14micf1 0.34922, cxr14macf1 0.34074, cxr14_loss 0.94057, vnbgmicf1 0.57180, vnbgmacf1 0.44385, vnbg_loss 0.70227, ema 0.71886, 121.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42286, wmdcmp 0.19426, oracc 0.99284, chxlmicf1 0.54952, chxlmacf1 0.50699, chxlacc 0.68921, chxlrocaucmic 0.78859, chxlrocaucmac 0.76731, qlmicf1 0.36201, qlmacf1 0.25415, ema 0.71222, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 9.7167e-05.\n",
      "---- Epoch 36/100\n",
      "(1) Training stage (lr = 0.000097) ...\n",
      "loss 4.28958, a_loss 0.91228, cD 1.52148, wmdcmp 0.20127, oracc 0.99082, orien_loss 0.03155, chxlmicf1 0.52010, chxlmacf1 0.47476, chx_loss 0.86778, chxlacc 0.71635, chxlrocaucmic 0.80492, chxlrocaucmac 0.78893, qlmicf1 0.35142, qlmacf1 0.23334, ql_loss 0.82672, gacc 0.83149, gloss 0.37677, cxr14micf1 0.34684, cxr14macf1 0.33742, cxr14_loss 0.94080, vnbgmicf1 0.57014, vnbgmacf1 0.44016, vnbg_loss 0.70463, ema 0.71875, 122.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38295, wmdcmp 0.19069, oracc 0.99284, chxlmicf1 0.55555, chxlmacf1 0.51213, chxlacc 0.69645, chxlrocaucmic 0.78849, chxlrocaucmac 0.76901, qlmicf1 0.35530, qlmacf1 0.25228, ema 0.70588, 20.30 secs\n",
      "Adjusting learning rate of group 0 to 9.2832e-05.\n",
      "---- Epoch 37/100\n",
      "(1) Training stage (lr = 0.000093) ...\n",
      "loss 4.48230, a_loss 0.91010, cD 1.51029, wmdcmp 0.19997, oracc 0.99056, orien_loss 0.02897, chxlmicf1 0.51998, chxlmacf1 0.47416, chx_loss 0.87086, chxlacc 0.71539, chxlrocaucmic 0.80331, chxlrocaucmac 0.78662, qlmicf1 0.35371, qlmacf1 0.23009, ql_loss 0.82245, gacc 0.83976, gloss 0.37273, cxr14micf1 0.34835, cxr14macf1 0.33893, cxr14_loss 0.94366, vnbgmicf1 0.57293, vnbgmacf1 0.44716, vnbg_loss 0.70008, ema 0.71580, 121.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39363, wmdcmp 0.19184, oracc 0.99284, chxlmicf1 0.55525, chxlmacf1 0.51208, chxlacc 0.69591, chxlrocaucmic 0.78898, chxlrocaucmac 0.76865, qlmicf1 0.36009, qlmacf1 0.25405, ema 0.69774, 20.39 secs\n",
      "Adjusting learning rate of group 0 to 8.8690e-05.\n",
      "---- Epoch 38/100\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 4.35078, a_loss 0.90777, cD 1.53513, wmdcmp 0.20316, oracc 0.99059, orien_loss 0.02890, chxlmicf1 0.51878, chxlmacf1 0.47316, chx_loss 0.87143, chxlacc 0.71485, chxlrocaucmic 0.80313, chxlrocaucmac 0.78675, qlmicf1 0.35386, qlmacf1 0.22617, ql_loss 0.82384, gacc 0.84375, gloss 0.37158, cxr14micf1 0.35500, cxr14macf1 0.34255, cxr14_loss 0.93376, vnbgmicf1 0.57047, vnbgmacf1 0.44185, vnbg_loss 0.70734, ema 0.71886, 121.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40866, wmdcmp 0.19322, oracc 0.99284, chxlmicf1 0.55375, chxlmacf1 0.51022, chxlacc 0.69515, chxlrocaucmic 0.78807, chxlrocaucmac 0.76797, qlmicf1 0.36083, qlmacf1 0.25425, ema 0.71765, 20.46 secs\n",
      "Adjusting learning rate of group 0 to 8.4732e-05.\n",
      "---- Epoch 39/100\n",
      "(1) Training stage (lr = 0.000085) ...\n",
      "loss 4.24905, a_loss 0.90785, cD 1.53349, wmdcmp 0.20231, oracc 0.99095, orien_loss 0.03039, chxlmicf1 0.52018, chxlmacf1 0.47424, chx_loss 0.86957, chxlacc 0.71634, chxlrocaucmic 0.80359, chxlrocaucmac 0.78750, qlmicf1 0.35429, qlmacf1 0.22909, ql_loss 0.82367, gacc 0.83387, gloss 0.37713, cxr14micf1 0.34152, cxr14macf1 0.33673, cxr14_loss 0.94651, vnbgmicf1 0.57160, vnbgmacf1 0.44261, vnbg_loss 0.69654, ema 0.71685, 120.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42588, wmdcmp 0.19500, oracc 0.99284, chxlmicf1 0.55530, chxlmacf1 0.51153, chxlacc 0.69521, chxlrocaucmic 0.78867, chxlrocaucmac 0.76805, qlmicf1 0.35868, qlmacf1 0.25479, ema 0.70769, 20.00 secs\n",
      "Adjusting learning rate of group 0 to 8.0952e-05.\n",
      "---- Epoch 40/100\n",
      "(1) Training stage (lr = 0.000081) ...\n",
      "loss 4.18924, a_loss 0.90442, cD 1.54857, wmdcmp 0.20460, oracc 0.99059, orien_loss 0.02940, chxlmicf1 0.51888, chxlmacf1 0.47417, chx_loss 0.87061, chxlacc 0.71477, chxlrocaucmic 0.80327, chxlrocaucmac 0.78726, qlmicf1 0.35392, qlmacf1 0.23006, ql_loss 0.82110, gacc 0.83774, gloss 0.37045, cxr14micf1 0.35387, cxr14macf1 0.34194, cxr14_loss 0.93541, vnbgmicf1 0.57749, vnbgmacf1 0.44844, vnbg_loss 0.69243, ema 0.71953, 121.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41298, wmdcmp 0.19350, oracc 0.99284, chxlmicf1 0.55199, chxlmacf1 0.50905, chxlacc 0.69504, chxlrocaucmic 0.78822, chxlrocaucmac 0.76905, qlmicf1 0.35931, qlmacf1 0.25376, ema 0.70860, 20.18 secs\n",
      "Adjusting learning rate of group 0 to 7.7339e-05.\n",
      "---- Epoch 41/100\n",
      "(1) Training stage (lr = 0.000077) ...\n",
      "loss 4.28205, a_loss 0.90184, cD 1.54104, wmdcmp 0.20345, oracc 0.99072, orien_loss 0.03146, chxlmicf1 0.52069, chxlmacf1 0.47497, chx_loss 0.86889, chxlacc 0.71601, chxlrocaucmic 0.80348, chxlrocaucmac 0.78737, qlmicf1 0.35551, qlmacf1 0.23145, ql_loss 0.82197, gacc 0.83619, gloss 0.37241, cxr14micf1 0.34851, cxr14macf1 0.33888, cxr14_loss 0.94123, vnbgmicf1 0.57627, vnbgmacf1 0.44951, vnbg_loss 0.69511, ema 0.71941, 120.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42849, wmdcmp 0.19610, oracc 0.99284, chxlmicf1 0.55638, chxlmacf1 0.51295, chxlacc 0.69791, chxlrocaucmic 0.78800, chxlrocaucmac 0.76864, qlmicf1 0.35704, qlmacf1 0.25366, ema 0.70950, 20.06 secs\n",
      "Adjusting learning rate of group 0 to 7.3889e-05.\n",
      "---- Epoch 42/100\n",
      "(1) Training stage (lr = 0.000074) ...\n",
      "loss 4.24672, a_loss 0.89959, cD 1.55028, wmdcmp 0.20487, oracc 0.99117, orien_loss 0.02996, chxlmicf1 0.52098, chxlmacf1 0.47534, chx_loss 0.86809, chxlacc 0.71688, chxlrocaucmic 0.80427, chxlrocaucmac 0.78816, qlmicf1 0.35686, qlmacf1 0.23013, ql_loss 0.81971, gacc 0.83625, gloss 0.37180, cxr14micf1 0.35095, cxr14macf1 0.34277, cxr14_loss 0.93225, vnbgmicf1 0.57029, vnbgmacf1 0.44404, vnbg_loss 0.69637, ema 0.72264, 122.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41230, wmdcmp 0.19384, oracc 0.99284, chxlmicf1 0.55466, chxlmacf1 0.51080, chxlacc 0.69545, chxlrocaucmic 0.78733, chxlrocaucmac 0.76807, qlmicf1 0.35873, qlmacf1 0.25252, ema 0.71131, 20.27 secs\n",
      "Adjusting learning rate of group 0 to 7.0592e-05.\n",
      "---- Epoch 43/100\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 4.15230, a_loss 0.89959, cD 1.53751, wmdcmp 0.20364, oracc 0.99146, orien_loss 0.02841, chxlmicf1 0.51887, chxlmacf1 0.47377, chx_loss 0.87114, chxlacc 0.71561, chxlrocaucmic 0.80272, chxlrocaucmac 0.78713, qlmicf1 0.35378, qlmacf1 0.23094, ql_loss 0.81929, gacc 0.83946, gloss 0.37146, cxr14micf1 0.35464, cxr14macf1 0.34166, cxr14_loss 0.92956, vnbgmicf1 0.57862, vnbgmacf1 0.44948, vnbg_loss 0.68394, ema 0.72182, 120.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37125, wmdcmp 0.19002, oracc 0.99284, chxlmicf1 0.55175, chxlmacf1 0.50853, chxlacc 0.69356, chxlrocaucmic 0.78842, chxlrocaucmac 0.76775, qlmicf1 0.36029, qlmacf1 0.25387, ema 0.71222, 20.31 secs\n",
      "Adjusting learning rate of group 0 to 6.7442e-05.\n",
      "---- Epoch 44/100\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 4.04822, a_loss 0.89471, cD 1.56807, wmdcmp 0.20611, oracc 0.99162, orien_loss 0.02879, chxlmicf1 0.52143, chxlmacf1 0.47604, chx_loss 0.86853, chxlacc 0.71695, chxlrocaucmic 0.80507, chxlrocaucmac 0.78858, qlmicf1 0.35515, qlmacf1 0.23333, ql_loss 0.82213, gacc 0.84143, gloss 0.36569, cxr14micf1 0.34032, cxr14macf1 0.33562, cxr14_loss 0.94138, vnbgmicf1 0.57715, vnbgmacf1 0.44839, vnbg_loss 0.69521, ema 0.72365, 121.89 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.45845, wmdcmp 0.19813, oracc 0.99284, chxlmicf1 0.55367, chxlmacf1 0.51030, chxlacc 0.69531, chxlrocaucmic 0.78831, chxlrocaucmac 0.76805, qlmicf1 0.35922, qlmacf1 0.25309, ema 0.71403, 20.06 secs\n",
      "Adjusting learning rate of group 0 to 6.4433e-05.\n",
      "---- Epoch 45/100\n",
      "(1) Training stage (lr = 0.000064) ...\n",
      "loss 4.16731, a_loss 0.89819, cD 1.55988, wmdcmp 0.20573, oracc 0.99067, orien_loss 0.02926, chxlmicf1 0.52007, chxlmacf1 0.47430, chx_loss 0.87037, chxlacc 0.71507, chxlrocaucmic 0.80317, chxlrocaucmac 0.78724, qlmicf1 0.35448, qlmacf1 0.22710, ql_loss 0.82025, gacc 0.83976, gloss 0.37015, cxr14micf1 0.34441, cxr14macf1 0.33722, cxr14_loss 0.93712, vnbgmicf1 0.58125, vnbgmacf1 0.45279, vnbg_loss 0.68369, ema 0.71987, 121.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41270, wmdcmp 0.19331, oracc 0.99284, chxlmicf1 0.55019, chxlmacf1 0.50737, chxlacc 0.69257, chxlrocaucmic 0.78750, chxlrocaucmac 0.76803, qlmicf1 0.36002, qlmacf1 0.25345, ema 0.70950, 20.21 secs\n",
      "Adjusting learning rate of group 0 to 6.1558e-05.\n",
      "---- Epoch 46/100\n",
      "(1) Training stage (lr = 0.000062) ...\n",
      "loss 4.09670, a_loss 0.89598, cD 1.56058, wmdcmp 0.20571, oracc 0.99136, orien_loss 0.02730, chxlmicf1 0.52027, chxlmacf1 0.47442, chx_loss 0.86902, chxlacc 0.71627, chxlrocaucmic 0.80362, chxlrocaucmac 0.78749, qlmicf1 0.35635, qlmacf1 0.23308, ql_loss 0.81765, gacc 0.83952, gloss 0.37046, cxr14micf1 0.36204, cxr14macf1 0.34702, cxr14_loss 0.92614, vnbgmicf1 0.57213, vnbgmacf1 0.44779, vnbg_loss 0.69288, ema 0.72228, 121.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38652, wmdcmp 0.19080, oracc 0.99284, chxlmicf1 0.55267, chxlmacf1 0.50985, chxlacc 0.69330, chxlrocaucmic 0.78853, chxlrocaucmac 0.76819, qlmicf1 0.36159, qlmacf1 0.25386, ema 0.69864, 20.56 secs\n",
      "Adjusting learning rate of group 0 to 5.8811e-05.\n",
      "---- Epoch 47/100\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 4.13603, a_loss 0.89207, cD 1.57055, wmdcmp 0.20710, oracc 0.99119, orien_loss 0.02857, chxlmicf1 0.52083, chxlmacf1 0.47576, chx_loss 0.86662, chxlacc 0.71697, chxlrocaucmic 0.80478, chxlrocaucmac 0.78925, qlmicf1 0.35577, qlmacf1 0.23220, ql_loss 0.82040, gacc 0.83851, gloss 0.36705, cxr14micf1 0.34822, cxr14macf1 0.33924, cxr14_loss 0.93868, vnbgmicf1 0.57764, vnbgmacf1 0.44880, vnbg_loss 0.68506, ema 0.72344, 122.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39708, wmdcmp 0.19147, oracc 0.99284, chxlmicf1 0.55159, chxlmacf1 0.50863, chxlacc 0.69413, chxlrocaucmic 0.78877, chxlrocaucmac 0.76886, qlmicf1 0.35936, qlmacf1 0.25329, ema 0.70317, 20.35 secs\n",
      "Adjusting learning rate of group 0 to 5.6187e-05.\n",
      "---- Epoch 48/100\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 4.21317, a_loss 0.88991, cD 1.57000, wmdcmp 0.20670, oracc 0.99074, orien_loss 0.02880, chxlmicf1 0.51950, chxlmacf1 0.47390, chx_loss 0.86989, chxlacc 0.71520, chxlrocaucmic 0.80299, chxlrocaucmac 0.78707, qlmicf1 0.35380, qlmacf1 0.22890, ql_loss 0.82251, gacc 0.84458, gloss 0.36075, cxr14micf1 0.35372, cxr14macf1 0.34139, cxr14_loss 0.93339, vnbgmicf1 0.57817, vnbgmacf1 0.45212, vnbg_loss 0.68106, ema 0.72299, 122.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37670, wmdcmp 0.19068, oracc 0.99284, chxlmicf1 0.55207, chxlmacf1 0.50863, chxlacc 0.69463, chxlrocaucmic 0.78842, chxlrocaucmac 0.76836, qlmicf1 0.35947, qlmacf1 0.25393, ema 0.70950, 20.28 secs\n",
      "Adjusting learning rate of group 0 to 5.3680e-05.\n",
      "---- Epoch 49/100\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 4.23657, a_loss 0.88848, cD 1.56894, wmdcmp 0.20701, oracc 0.99161, orien_loss 0.02730, chxlmicf1 0.51989, chxlmacf1 0.47446, chx_loss 0.86851, chxlacc 0.71581, chxlrocaucmic 0.80365, chxlrocaucmac 0.78726, qlmicf1 0.35406, qlmacf1 0.23186, ql_loss 0.81898, gacc 0.84500, gloss 0.36716, cxr14micf1 0.34888, cxr14macf1 0.33922, cxr14_loss 0.94195, vnbgmicf1 0.57587, vnbgmacf1 0.44681, vnbg_loss 0.67972, ema 0.72452, 119.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42380, wmdcmp 0.19404, oracc 0.99284, chxlmicf1 0.55230, chxlmacf1 0.50943, chxlacc 0.69413, chxlrocaucmic 0.78811, chxlrocaucmac 0.76770, qlmicf1 0.35827, qlmacf1 0.25421, ema 0.71855, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 5.1285e-05.\n",
      "---- Epoch 50/100\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 4.41690, a_loss 0.89179, cD 1.57526, wmdcmp 0.20737, oracc 0.99152, orien_loss 0.02903, chxlmicf1 0.52048, chxlmacf1 0.47474, chx_loss 0.86778, chxlacc 0.71646, chxlrocaucmic 0.80385, chxlrocaucmac 0.78852, qlmicf1 0.35629, qlmacf1 0.23429, ql_loss 0.81652, gacc 0.84292, gloss 0.36732, cxr14micf1 0.34857, cxr14macf1 0.33815, cxr14_loss 0.93938, vnbgmicf1 0.58099, vnbgmacf1 0.45147, vnbg_loss 0.67808, ema 0.72372, 122.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39243, wmdcmp 0.19222, oracc 0.99284, chxlmicf1 0.55482, chxlmacf1 0.51116, chxlacc 0.69648, chxlrocaucmic 0.78806, chxlrocaucmac 0.76821, qlmicf1 0.36015, qlmacf1 0.25483, ema 0.71403, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 4.8996e-05.\n",
      "---- Epoch 51/100\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 4.06767, a_loss 0.88652, cD 1.57061, wmdcmp 0.20757, oracc 0.99121, orien_loss 0.02712, chxlmicf1 0.51944, chxlmacf1 0.47451, chx_loss 0.86871, chxlacc 0.71614, chxlrocaucmic 0.80383, chxlrocaucmac 0.78839, qlmicf1 0.35657, qlmacf1 0.22735, ql_loss 0.81875, gacc 0.84173, gloss 0.36737, cxr14micf1 0.34638, cxr14macf1 0.33878, cxr14_loss 0.93901, vnbgmicf1 0.58141, vnbgmacf1 0.45274, vnbg_loss 0.68837, ema 0.72175, 122.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41615, wmdcmp 0.19385, oracc 0.99284, chxlmicf1 0.55537, chxlmacf1 0.51167, chxlacc 0.69590, chxlrocaucmic 0.78935, chxlrocaucmac 0.76866, qlmicf1 0.36266, qlmacf1 0.25521, ema 0.71674, 20.57 secs\n",
      "Adjusting learning rate of group 0 to 4.6810e-05.\n",
      "---- Epoch 52/100\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 4.07084, a_loss 0.88939, cD 1.57400, wmdcmp 0.20744, oracc 0.99209, orien_loss 0.02639, chxlmicf1 0.52133, chxlmacf1 0.47559, chx_loss 0.86907, chxlacc 0.71668, chxlrocaucmic 0.80418, chxlrocaucmac 0.78774, qlmicf1 0.35541, qlmacf1 0.22978, ql_loss 0.82095, gacc 0.83649, gloss 0.36947, cxr14micf1 0.35040, cxr14macf1 0.34121, cxr14_loss 0.93448, vnbgmicf1 0.57806, vnbgmacf1 0.44713, vnbg_loss 0.68554, ema 0.72253, 120.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40481, wmdcmp 0.19239, oracc 0.99284, chxlmicf1 0.55193, chxlmacf1 0.50945, chxlacc 0.69339, chxlrocaucmic 0.78783, chxlrocaucmac 0.76820, qlmicf1 0.36082, qlmacf1 0.25472, ema 0.71312, 20.41 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-05.\n",
      "---- Epoch 53/100\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.09091, a_loss 0.88737, cD 1.57723, wmdcmp 0.20754, oracc 0.99100, orien_loss 0.02879, chxlmicf1 0.52027, chxlmacf1 0.47500, chx_loss 0.86862, chxlacc 0.71594, chxlrocaucmic 0.80326, chxlrocaucmac 0.78774, qlmicf1 0.35434, qlmacf1 0.23377, ql_loss 0.81737, gacc 0.84202, gloss 0.36711, cxr14micf1 0.35017, cxr14macf1 0.33998, cxr14_loss 0.93606, vnbgmicf1 0.57838, vnbgmacf1 0.45466, vnbg_loss 0.67669, ema 0.72562, 121.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40944, wmdcmp 0.19410, oracc 0.99284, chxlmicf1 0.55243, chxlmacf1 0.50983, chxlacc 0.69460, chxlrocaucmic 0.78800, chxlrocaucmac 0.76821, qlmicf1 0.36054, qlmacf1 0.25392, ema 0.71222, 20.37 secs\n",
      "Adjusting learning rate of group 0 to 4.2726e-05.\n",
      "---- Epoch 54/100\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 4.17761, a_loss 0.88903, cD 1.58274, wmdcmp 0.20816, oracc 0.99172, orien_loss 0.02727, chxlmicf1 0.51976, chxlmacf1 0.47438, chx_loss 0.86927, chxlacc 0.71569, chxlrocaucmic 0.80298, chxlrocaucmac 0.78777, qlmicf1 0.35593, qlmacf1 0.23046, ql_loss 0.81598, gacc 0.83583, gloss 0.37337, cxr14micf1 0.34865, cxr14macf1 0.34023, cxr14_loss 0.92716, vnbgmicf1 0.57684, vnbgmacf1 0.44993, vnbg_loss 0.68979, ema 0.72241, 121.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41223, wmdcmp 0.19376, oracc 0.99284, chxlmicf1 0.55001, chxlmacf1 0.50685, chxlacc 0.69360, chxlrocaucmic 0.78840, chxlrocaucmac 0.76828, qlmicf1 0.36069, qlmacf1 0.25503, ema 0.70950, 20.36 secs\n",
      "Adjusting learning rate of group 0 to 4.0819e-05.\n",
      "---- Epoch 55/100\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 4.11319, a_loss 0.88296, cD 1.58973, wmdcmp 0.20938, oracc 0.99152, orien_loss 0.02769, chxlmicf1 0.52156, chxlmacf1 0.47568, chx_loss 0.86930, chxlacc 0.71733, chxlrocaucmic 0.80508, chxlrocaucmac 0.78850, qlmicf1 0.35773, qlmacf1 0.23233, ql_loss 0.81493, gacc 0.84268, gloss 0.36573, cxr14micf1 0.35581, cxr14macf1 0.34299, cxr14_loss 0.92848, vnbgmicf1 0.58076, vnbgmacf1 0.45199, vnbg_loss 0.67344, ema 0.72697, 122.16 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.41726, wmdcmp 0.19402, oracc 0.99284, chxlmicf1 0.55445, chxlmacf1 0.51135, chxlacc 0.69578, chxlrocaucmic 0.78815, chxlrocaucmac 0.76874, qlmicf1 0.36073, qlmacf1 0.25433, ema 0.70679, 20.49 secs\n",
      "Adjusting learning rate of group 0 to 3.8998e-05.\n",
      "---- Epoch 56/100\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 4.00266, a_loss 0.88593, cD 1.58021, wmdcmp 0.20857, oracc 0.99111, orien_loss 0.02749, chxlmicf1 0.52165, chxlmacf1 0.47699, chx_loss 0.86467, chxlacc 0.71724, chxlrocaucmic 0.80580, chxlrocaucmac 0.79041, qlmicf1 0.35597, qlmacf1 0.23171, ql_loss 0.82005, gacc 0.84042, gloss 0.36926, cxr14micf1 0.35695, cxr14macf1 0.34442, cxr14_loss 0.92798, vnbgmicf1 0.57694, vnbgmacf1 0.45314, vnbg_loss 0.68430, ema 0.72811, 122.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41033, wmdcmp 0.19392, oracc 0.99284, chxlmicf1 0.55207, chxlmacf1 0.50900, chxlacc 0.69437, chxlrocaucmic 0.78902, chxlrocaucmac 0.76857, qlmicf1 0.36218, qlmacf1 0.25428, ema 0.70588, 20.27 secs\n",
      "Adjusting learning rate of group 0 to 3.7258e-05.\n",
      "---- Epoch 57/100\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 3.97724, a_loss 0.88375, cD 1.59823, wmdcmp 0.21033, oracc 0.99160, orien_loss 0.02677, chxlmicf1 0.52047, chxlmacf1 0.47486, chx_loss 0.86985, chxlacc 0.71586, chxlrocaucmic 0.80332, chxlrocaucmac 0.78708, qlmicf1 0.35505, qlmacf1 0.23227, ql_loss 0.81869, gacc 0.83958, gloss 0.37175, cxr14micf1 0.35157, cxr14macf1 0.34072, cxr14_loss 0.92863, vnbgmicf1 0.58038, vnbgmacf1 0.45136, vnbg_loss 0.67619, ema 0.72285, 122.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43626, wmdcmp 0.19610, oracc 0.99284, chxlmicf1 0.55126, chxlmacf1 0.50892, chxlacc 0.69401, chxlrocaucmic 0.78770, chxlrocaucmac 0.76843, qlmicf1 0.35956, qlmacf1 0.25479, ema 0.71041, 20.31 secs\n",
      "Adjusting learning rate of group 0 to 3.5596e-05.\n",
      "---- Epoch 58/100\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 4.22953, a_loss 0.88312, cD 1.58898, wmdcmp 0.20895, oracc 0.99145, orien_loss 0.02719, chxlmicf1 0.52061, chxlmacf1 0.47586, chx_loss 0.86737, chxlacc 0.71647, chxlrocaucmic 0.80432, chxlrocaucmac 0.78880, qlmicf1 0.35528, qlmacf1 0.23338, ql_loss 0.81719, gacc 0.83720, gloss 0.36790, cxr14micf1 0.35251, cxr14macf1 0.34207, cxr14_loss 0.93020, vnbgmicf1 0.57972, vnbgmacf1 0.45332, vnbg_loss 0.68063, ema 0.72335, 121.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41858, wmdcmp 0.19376, oracc 0.99284, chxlmicf1 0.55182, chxlmacf1 0.50775, chxlacc 0.69447, chxlrocaucmic 0.78868, chxlrocaucmac 0.76857, qlmicf1 0.36039, qlmacf1 0.25487, ema 0.70588, 20.27 secs\n",
      "Adjusting learning rate of group 0 to 3.4007e-05.\n",
      "---- Epoch 59/100\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.14046, a_loss 0.88281, cD 1.57882, wmdcmp 0.20763, oracc 0.99157, orien_loss 0.02739, chxlmicf1 0.51954, chxlmacf1 0.47400, chx_loss 0.86902, chxlacc 0.71587, chxlrocaucmic 0.80372, chxlrocaucmac 0.78779, qlmicf1 0.35585, qlmacf1 0.23025, ql_loss 0.81797, gacc 0.83649, gloss 0.36719, cxr14micf1 0.35131, cxr14macf1 0.34129, cxr14_loss 0.93950, vnbgmicf1 0.57986, vnbgmacf1 0.45357, vnbg_loss 0.68096, ema 0.72015, 121.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41287, wmdcmp 0.19404, oracc 0.99284, chxlmicf1 0.55240, chxlmacf1 0.50812, chxlacc 0.69403, chxlrocaucmic 0.78874, chxlrocaucmac 0.76870, qlmicf1 0.35898, qlmacf1 0.25356, ema 0.70950, 20.30 secs\n",
      "Adjusting learning rate of group 0 to 3.2490e-05.\n",
      "---- Epoch 60/100\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 4.06333, a_loss 0.87962, cD 1.58849, wmdcmp 0.20939, oracc 0.99159, orien_loss 0.02790, chxlmicf1 0.52071, chxlmacf1 0.47533, chx_loss 0.86694, chxlacc 0.71628, chxlrocaucmic 0.80428, chxlrocaucmac 0.78869, qlmicf1 0.35719, qlmacf1 0.23278, ql_loss 0.81543, gacc 0.84315, gloss 0.36495, cxr14micf1 0.35587, cxr14macf1 0.34366, cxr14_loss 0.92843, vnbgmicf1 0.58227, vnbgmacf1 0.45439, vnbg_loss 0.67557, ema 0.72809, 123.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42079, wmdcmp 0.19416, oracc 0.99284, chxlmicf1 0.55420, chxlmacf1 0.51074, chxlacc 0.69465, chxlrocaucmic 0.78920, chxlrocaucmac 0.76954, qlmicf1 0.36070, qlmacf1 0.25375, ema 0.71674, 20.24 secs\n",
      "Adjusting learning rate of group 0 to 3.1040e-05.\n",
      "---- Epoch 61/100\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "^C iteration 25300\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"../train_vqa.py\", line 1439, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_vqa.py\", line 1338, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_vqa.py\", line 882, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 835, in _run_once_on_dataset\n",
      "    self._fire_event(Events.ITERATION_COMPLETED)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/dataset_aware_metric.py\", line 30, in iteration_completed_handler\n",
      "    self.update(self.output_transform(output))\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/classification/multilabel_prf1.py\", line 209, in update\n",
      "    gt = gt_labels[i][j]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 100 \\\n",
    "        --batches-per-epoch 420 \\\n",
    "        --batch-size 160 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --num-workers 7 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,4e-4,96,5e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220629_123956.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220629_123626.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220629_052724.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --raw-image-encoding \"clip-vit-huggingface\" \\\n",
    "        --clip-version \"CenIA/clip-vit-bio-clinical-bert-finetuned\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 420\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220629_042239.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220629_050643.json\n",
      "   vocab_min_freq: 5\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/clip-vit-bio-clinical-bert-finetuned\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,6e-5,76,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 160\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 5\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220629_052724.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220629_123626.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220629_123956.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220629_055107.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220629_055159.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220629_052841.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220629_052842.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,6e-5,76,1e-6\n",
      "1e-06 4 6e-05 76 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=292,3941135520930231601).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 1940625, len(set(self.report_ids)) = 215125\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=292,3941135520930231601).pkl.balanced_train_data(bs=160,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 92\n",
      "len(self.val_indices) = 5762\n",
      "len(val_indices) = 5762\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 5\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=41533, len(neg_indices)=173070\n",
      "label = 1, onehot=98, len(pos_indices)=41436, len(neg_indices)=173167\n",
      "label = 2, onehot=99, len(pos_indices)=68536, len(neg_indices)=146067\n",
      "label = 3, onehot=100, len(pos_indices)=8926, len(neg_indices)=205677\n",
      "label = 4, onehot=101, len(pos_indices)=71192, len(neg_indices)=143411\n",
      "label = 5, onehot=102, len(pos_indices)=41924, len(neg_indices)=172679\n",
      "label = 6, onehot=103, len(pos_indices)=19023, len(neg_indices)=195580\n",
      "label = 7, onehot=104, len(pos_indices)=35834, len(neg_indices)=178769\n",
      "label = 8, onehot=105, len(pos_indices)=67927, len(neg_indices)=146676\n",
      "label = 9, onehot=106, len(pos_indices)=12839, len(neg_indices)=201764\n",
      "label = 10, onehot=107, len(pos_indices)=66725, len(neg_indices)=147878\n",
      "label = 11, onehot=108, len(pos_indices)=4638, len(neg_indices)=209965\n",
      "label = 12, onehot=109, len(pos_indices)=7757, len(neg_indices)=206846\n",
      "label = 13, onehot=110, len(pos_indices)=85553, len(neg_indices)=129050\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=25, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1105\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=307,157613170942256249).pkl ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 28800, len(set(self.report_ids)) = 3784\n",
      "Balanced train data loaded from /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=307,157613170942256249).pkl.balanced_train_data(bs=160,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 41\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 5\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2370\n",
      "label = 1, onehot=98, len(pos_indices)=382, len(neg_indices)=3402\n",
      "label = 2, onehot=99, len(pos_indices)=667, len(neg_indices)=3117\n",
      "label = 3, onehot=100, len(pos_indices)=230, len(neg_indices)=3554\n",
      "label = 4, onehot=101, len(pos_indices)=701, len(neg_indices)=3083\n",
      "label = 5, onehot=102, len(pos_indices)=150, len(neg_indices)=3634\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=3744\n",
      "label = 7, onehot=104, len(pos_indices)=134, len(neg_indices)=3650\n",
      "label = 8, onehot=105, len(pos_indices)=360, len(neg_indices)=3424\n",
      "label = 9, onehot=106, len(pos_indices)=99, len(neg_indices)=3685\n",
      "label = 10, onehot=107, len(pos_indices)=288, len(neg_indices)=3496\n",
      "label = 11, onehot=108, len(pos_indices)=70, len(neg_indices)=3714\n",
      "label = 12, onehot=109, len(pos_indices)=113, len(neg_indices)=3671\n",
      "label = 13, onehot=110, len(pos_indices)=213, len(neg_indices)=3571\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 7\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "checkpoint_names = ['checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "---- Epoch 1/80\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.92627, a_loss 0.88144, cD 1.58647, wmdcmp 0.20798, oracc 0.97741, orien_loss 0.06280, chxlmicf1 0.49503, chxlmacf1 0.45012, chx_loss 0.91603, chxlacc 0.69461, chxlrocaucmic 0.77978, chxlrocaucmac 0.76056, qlmicf1 0.30785, qlmacf1 0.20841, ql_loss 0.88083, gacc 0.81726, gloss 0.40880, cxr14micf1 0.30980, cxr14macf1 0.31686, cxr14_loss 0.99020, vnbgmicf1 0.52561, vnbgmacf1 0.40235, vnbg_loss 0.82262, ema 0.70055, 170.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37571, wmdcmp 0.18842, oracc 0.98627, chxlmicf1 0.53718, chxlmacf1 0.49409, chxlacc 0.68012, chxlrocaucmic 0.76919, chxlrocaucmac 0.74993, qlmicf1 0.31861, qlmacf1 0.23863, ema 0.68054, 19.84 secs\n",
      "Adjusting learning rate of group 0 to 2.7832e-06.\n",
      "---- Epoch 2/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.48093, a_loss 0.89752, cD 1.54563, wmdcmp 0.20399, oracc 0.98612, orien_loss 0.03967, chxlmicf1 0.50082, chxlmacf1 0.45756, chx_loss 0.90294, chxlacc 0.69795, chxlrocaucmic 0.78617, chxlrocaucmac 0.76941, qlmicf1 0.32008, qlmacf1 0.21036, ql_loss 0.86822, gacc 0.84238, gloss 0.36378, cxr14micf1 0.32562, cxr14macf1 0.32433, cxr14_loss 0.97024, vnbgmicf1 0.53312, vnbgmacf1 0.40988, vnbg_loss 0.79555, ema 0.70879, 139.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39123, wmdcmp 0.19081, oracc 0.99182, chxlmicf1 0.54066, chxlmacf1 0.49835, chxlacc 0.68483, chxlrocaucmic 0.77033, chxlrocaucmac 0.75335, qlmicf1 0.32539, qlmacf1 0.23984, ema 0.67964, 21.01 secs\n",
      "Adjusting learning rate of group 0 to 7.7460e-06.\n",
      "---- Epoch 3/80\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 4.18092, a_loss 0.89153, cD 1.54885, wmdcmp 0.20454, oracc 0.98858, orien_loss 0.03334, chxlmicf1 0.50473, chxlmacf1 0.46040, chx_loss 0.89602, chxlacc 0.70125, chxlrocaucmic 0.78871, chxlrocaucmac 0.77147, qlmicf1 0.32369, qlmacf1 0.21586, ql_loss 0.86242, gacc 0.87113, gloss 0.30357, cxr14micf1 0.32858, cxr14macf1 0.32654, cxr14_loss 0.96219, vnbgmicf1 0.53628, vnbgmacf1 0.41259, vnbg_loss 0.78208, ema 0.70982, 138.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40252, wmdcmp 0.19171, oracc 0.99314, chxlmicf1 0.54445, chxlmacf1 0.50114, chxlacc 0.68732, chxlrocaucmic 0.77218, chxlrocaucmac 0.75485, qlmicf1 0.32801, qlmacf1 0.24281, ema 0.69140, 24.20 secs\n",
      "Adjusting learning rate of group 0 to 2.1558e-05.\n",
      "---- Epoch 4/80\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 4.37350, a_loss 0.89632, cD 1.55061, wmdcmp 0.20492, oracc 0.98923, orien_loss 0.03010, chxlmicf1 0.50666, chxlmacf1 0.46201, chx_loss 0.89122, chxlacc 0.70307, chxlrocaucmic 0.79115, chxlrocaucmac 0.77474, qlmicf1 0.32786, qlmacf1 0.21439, ql_loss 0.85623, gacc 0.86286, gloss 0.33362, cxr14micf1 0.32968, cxr14macf1 0.32649, cxr14_loss 0.96397, vnbgmicf1 0.55120, vnbgmacf1 0.42621, vnbg_loss 0.74225, ema 0.71245, 141.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40168, wmdcmp 0.19162, oracc 0.98846, chxlmicf1 0.54624, chxlmacf1 0.50256, chxlacc 0.69009, chxlrocaucmic 0.77566, chxlrocaucmac 0.75582, qlmicf1 0.33505, qlmacf1 0.24544, ema 0.69050, 22.05 secs\n",
      "Adjusting learning rate of group 0 to 6.0000e-05.\n",
      "---- Epoch 5/80\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 4.23657, a_loss 0.90599, cD 1.53686, wmdcmp 0.20296, oracc 0.98298, orien_loss 0.04748, chxlmicf1 0.49562, chxlmacf1 0.45236, chx_loss 0.90694, chxlacc 0.69064, chxlrocaucmic 0.78127, chxlrocaucmac 0.76370, qlmicf1 0.31821, qlmacf1 0.21006, ql_loss 0.87634, gacc 0.82500, gloss 0.54270, cxr14micf1 0.32089, cxr14macf1 0.32156, cxr14_loss 0.97524, vnbgmicf1 0.52604, vnbgmacf1 0.40532, vnbg_loss 0.80169, ema 0.69824, 142.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33239, wmdcmp 0.18364, oracc 0.99138, chxlmicf1 0.54445, chxlmacf1 0.49012, chxlacc 0.69859, chxlrocaucmic 0.77348, chxlrocaucmac 0.74665, qlmicf1 0.32744, qlmacf1 0.24234, ema 0.67240, 20.30 secs\n",
      "Adjusting learning rate of group 0 to 5.6853e-05.\n",
      "---- Epoch 6/80\n",
      "(1) Training stage (lr = 0.000057) ...\n",
      "loss 4.31112, a_loss 0.89777, cD 1.54504, wmdcmp 0.20446, oracc 0.99036, orien_loss 0.02714, chxlmicf1 0.50925, chxlmacf1 0.46378, chx_loss 0.88210, chxlacc 0.70545, chxlrocaucmic 0.79274, chxlrocaucmac 0.77711, qlmicf1 0.32305, qlmacf1 0.21744, ql_loss 0.85317, gacc 0.91411, gloss 0.20949, cxr14micf1 0.33329, cxr14macf1 0.33066, cxr14_loss 0.95238, vnbgmicf1 0.56069, vnbgmacf1 0.43276, vnbg_loss 0.72274, ema 0.71092, 141.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41780, wmdcmp 0.19369, oracc 0.99328, chxlmicf1 0.53946, chxlmacf1 0.48911, chxlacc 0.69442, chxlrocaucmic 0.76558, chxlrocaucmac 0.74763, qlmicf1 0.33453, qlmacf1 0.24375, ema 0.67240, 20.38 secs\n",
      "Adjusting learning rate of group 0 to 5.3871e-05.\n",
      "---- Epoch 7/80\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 4.38764, a_loss 0.89614, cD 1.56215, wmdcmp 0.20589, oracc 0.99111, orien_loss 0.02496, chxlmicf1 0.51347, chxlmacf1 0.46860, chx_loss 0.86952, chxlacc 0.70938, chxlrocaucmic 0.79723, chxlrocaucmac 0.78310, qlmicf1 0.33141, qlmacf1 0.21793, ql_loss 0.84232, gacc 0.91673, gloss 0.20479, cxr14micf1 0.34005, cxr14macf1 0.33553, cxr14_loss 0.94025, vnbgmicf1 0.57347, vnbgmacf1 0.44076, vnbg_loss 0.69280, ema 0.71623, 141.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36769, wmdcmp 0.18901, oracc 0.99226, chxlmicf1 0.54295, chxlmacf1 0.49875, chxlacc 0.67998, chxlrocaucmic 0.77165, chxlrocaucmac 0.75243, qlmicf1 0.33850, qlmacf1 0.24470, ema 0.68326, 20.52 secs\n",
      "Adjusting learning rate of group 0 to 5.1046e-05.\n",
      "---- Epoch 8/80\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 4.40183, a_loss 0.89397, cD 1.56702, wmdcmp 0.20647, oracc 0.99169, orien_loss 0.02323, chxlmicf1 0.51755, chxlmacf1 0.47186, chx_loss 0.86041, chxlacc 0.71335, chxlrocaucmic 0.80063, chxlrocaucmac 0.78770, qlmicf1 0.33758, qlmacf1 0.22278, ql_loss 0.83277, gacc 0.92167, gloss 0.18491, cxr14micf1 0.33732, cxr14macf1 0.33697, cxr14_loss 0.93971, vnbgmicf1 0.58330, vnbgmacf1 0.45272, vnbg_loss 0.67626, ema 0.71930, 142.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39391, wmdcmp 0.19200, oracc 0.99314, chxlmicf1 0.53758, chxlmacf1 0.49077, chxlacc 0.68507, chxlrocaucmic 0.76776, chxlrocaucmac 0.74926, qlmicf1 0.33560, qlmacf1 0.24548, ema 0.68235, 20.99 secs\n",
      "Adjusting learning rate of group 0 to 4.8369e-05.\n",
      "---- Epoch 9/80\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 4.14978, a_loss 0.89166, cD 1.56341, wmdcmp 0.20622, oracc 0.99232, orien_loss 0.02131, chxlmicf1 0.52182, chxlmacf1 0.47535, chx_loss 0.84915, chxlacc 0.71810, chxlrocaucmic 0.80660, chxlrocaucmac 0.79400, qlmicf1 0.33995, qlmacf1 0.22213, ql_loss 0.82376, gacc 0.93399, gloss 0.16284, cxr14micf1 0.34505, cxr14macf1 0.34145, cxr14_loss 0.93229, vnbgmicf1 0.58615, vnbgmacf1 0.45808, vnbg_loss 0.65677, ema 0.72154, 142.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37288, wmdcmp 0.18950, oracc 0.99445, chxlmicf1 0.54980, chxlmacf1 0.50212, chxlacc 0.69408, chxlrocaucmic 0.77275, chxlrocaucmac 0.74801, qlmicf1 0.33054, qlmacf1 0.24332, ema 0.67330, 20.53 secs\n",
      "Adjusting learning rate of group 0 to 4.5832e-05.\n",
      "---- Epoch 10/80\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 4.13841, a_loss 0.88975, cD 1.56457, wmdcmp 0.20669, oracc 0.99331, orien_loss 0.01812, chxlmicf1 0.52662, chxlmacf1 0.47922, chx_loss 0.83894, chxlacc 0.72186, chxlrocaucmic 0.80978, chxlrocaucmac 0.79798, qlmicf1 0.34440, qlmacf1 0.23096, ql_loss 0.81266, gacc 0.93482, gloss 0.16208, cxr14micf1 0.34951, cxr14macf1 0.34362, cxr14_loss 0.92772, vnbgmicf1 0.60213, vnbgmacf1 0.46908, vnbg_loss 0.62312, ema 0.72459, 142.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39754, wmdcmp 0.19071, oracc 0.99372, chxlmicf1 0.54184, chxlmacf1 0.49537, chxlacc 0.70002, chxlrocaucmic 0.76668, chxlrocaucmac 0.75440, qlmicf1 0.32559, qlmacf1 0.24491, ema 0.68959, 20.80 secs\n",
      "Adjusting learning rate of group 0 to 4.3428e-05.\n",
      "---- Epoch 11/80\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 4.01814, a_loss 0.88820, cD 1.57765, wmdcmp 0.20743, oracc 0.99257, orien_loss 0.01905, chxlmicf1 0.53115, chxlmacf1 0.48394, chx_loss 0.82964, chxlacc 0.72561, chxlrocaucmic 0.81344, chxlrocaucmac 0.80230, qlmicf1 0.35047, qlmacf1 0.22684, ql_loss 0.80584, gacc 0.94167, gloss 0.14869, cxr14micf1 0.37485, cxr14macf1 0.35721, cxr14_loss 0.89700, vnbgmicf1 0.61334, vnbgmacf1 0.48600, vnbg_loss 0.60074, ema 0.72935, 143.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37466, wmdcmp 0.18974, oracc 0.99387, chxlmicf1 0.54930, chxlmacf1 0.50114, chxlacc 0.69311, chxlrocaucmic 0.77664, chxlrocaucmac 0.75104, qlmicf1 0.34628, qlmacf1 0.25025, ema 0.67783, 20.59 secs\n",
      "Adjusting learning rate of group 0 to 4.1150e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 12/80\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 4.01421, a_loss 0.88559, cD 1.57493, wmdcmp 0.20761, oracc 0.99308, orien_loss 0.01888, chxlmicf1 0.53373, chxlmacf1 0.48649, chx_loss 0.82112, chxlacc 0.72864, chxlrocaucmic 0.81603, chxlrocaucmac 0.80557, qlmicf1 0.35223, qlmacf1 0.23123, ql_loss 0.80044, gacc 0.94899, gloss 0.12843, cxr14micf1 0.37675, cxr14macf1 0.36256, cxr14_loss 0.89069, vnbgmicf1 0.62682, vnbgmacf1 0.49958, vnbg_loss 0.58298, ema 0.72880, 143.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38487, wmdcmp 0.19159, oracc 0.99343, chxlmicf1 0.55194, chxlmacf1 0.50411, chxlacc 0.69768, chxlrocaucmic 0.77748, chxlrocaucmac 0.75533, qlmicf1 0.36015, qlmacf1 0.25305, ema 0.69502, 20.66 secs\n",
      "Adjusting learning rate of group 0 to 3.8992e-05.\n",
      "---- Epoch 13/80\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 4.10079, a_loss 0.88627, cD 1.56803, wmdcmp 0.20675, oracc 0.99235, orien_loss 0.01894, chxlmicf1 0.53684, chxlmacf1 0.48903, chx_loss 0.81670, chxlacc 0.73175, chxlrocaucmic 0.81842, chxlrocaucmac 0.80765, qlmicf1 0.35914, qlmacf1 0.23414, ql_loss 0.79094, gacc 0.95000, gloss 0.13200, cxr14micf1 0.36624, cxr14macf1 0.35711, cxr14_loss 0.90591, vnbgmicf1 0.63354, vnbgmacf1 0.50520, vnbg_loss 0.56760, ema 0.72894, 144.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42201, wmdcmp 0.19362, oracc 0.99372, chxlmicf1 0.55414, chxlmacf1 0.50360, chxlacc 0.69450, chxlrocaucmic 0.78126, chxlrocaucmac 0.75689, qlmicf1 0.35252, qlmacf1 0.25303, ema 0.69683, 20.99 secs\n",
      "Adjusting learning rate of group 0 to 3.6947e-05.\n",
      "---- Epoch 14/80\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 4.09835, a_loss 0.88449, cD 1.56147, wmdcmp 0.20595, oracc 0.99344, orien_loss 0.01692, chxlmicf1 0.53994, chxlmacf1 0.49160, chx_loss 0.80602, chxlacc 0.73437, chxlrocaucmic 0.82207, chxlrocaucmac 0.81205, qlmicf1 0.36360, qlmacf1 0.23985, ql_loss 0.77815, gacc 0.95143, gloss 0.12354, cxr14micf1 0.38023, cxr14macf1 0.36704, cxr14_loss 0.88666, vnbgmicf1 0.63951, vnbgmacf1 0.51208, vnbg_loss 0.55038, ema 0.73393, 143.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40633, wmdcmp 0.19256, oracc 0.99474, chxlmicf1 0.55103, chxlmacf1 0.50316, chxlacc 0.69728, chxlrocaucmic 0.77819, chxlrocaucmac 0.75757, qlmicf1 0.35423, qlmacf1 0.25407, ema 0.68235, 20.58 secs\n",
      "Adjusting learning rate of group 0 to 3.5009e-05.\n",
      "---- Epoch 15/80\n",
      "(1) Training stage (lr = 0.000035) ...\n",
      "loss 4.09882, a_loss 0.88290, cD 1.57455, wmdcmp 0.20741, oracc 0.99416, orien_loss 0.01468, chxlmicf1 0.54502, chxlmacf1 0.49699, chx_loss 0.79565, chxlacc 0.73865, chxlrocaucmic 0.82664, chxlrocaucmac 0.81715, qlmicf1 0.36598, qlmacf1 0.23920, ql_loss 0.77375, gacc 0.95262, gloss 0.12409, cxr14micf1 0.38852, cxr14macf1 0.37250, cxr14_loss 0.87284, vnbgmicf1 0.65029, vnbgmacf1 0.52724, vnbg_loss 0.53286, ema 0.73752, 144.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38677, wmdcmp 0.19108, oracc 0.99445, chxlmicf1 0.55049, chxlmacf1 0.50474, chxlacc 0.69391, chxlrocaucmic 0.77713, chxlrocaucmac 0.75775, qlmicf1 0.34198, qlmacf1 0.25032, ema 0.68507, 20.61 secs\n",
      "Adjusting learning rate of group 0 to 3.3173e-05.\n",
      "---- Epoch 16/80\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 4.13604, a_loss 0.88219, cD 1.58723, wmdcmp 0.20813, oracc 0.99373, orien_loss 0.01442, chxlmicf1 0.54588, chxlmacf1 0.49825, chx_loss 0.79234, chxlacc 0.74015, chxlrocaucmic 0.82664, chxlrocaucmac 0.81800, qlmicf1 0.37153, qlmacf1 0.24211, ql_loss 0.76492, gacc 0.94964, gloss 0.12754, cxr14micf1 0.37372, cxr14macf1 0.36583, cxr14_loss 0.88301, vnbgmicf1 0.65639, vnbgmacf1 0.53319, vnbg_loss 0.51825, ema 0.73649, 143.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43510, wmdcmp 0.19584, oracc 0.99460, chxlmicf1 0.54981, chxlmacf1 0.50102, chxlacc 0.69312, chxlrocaucmic 0.77818, chxlrocaucmac 0.75730, qlmicf1 0.34283, qlmacf1 0.25207, ema 0.68869, 20.76 secs\n",
      "Adjusting learning rate of group 0 to 3.1433e-05.\n",
      "---- Epoch 17/80\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 4.05789, a_loss 0.87793, cD 1.58491, wmdcmp 0.20860, oracc 0.99340, orien_loss 0.01806, chxlmicf1 0.55270, chxlmacf1 0.50435, chx_loss 0.77911, chxlacc 0.74557, chxlrocaucmic 0.83265, chxlrocaucmac 0.82452, qlmicf1 0.37714, qlmacf1 0.24694, ql_loss 0.75799, gacc 0.95577, gloss 0.10937, cxr14micf1 0.39236, cxr14macf1 0.37872, cxr14_loss 0.86759, vnbgmicf1 0.67314, vnbgmacf1 0.55587, vnbg_loss 0.49657, ema 0.74274, 143.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40134, wmdcmp 0.19227, oracc 0.99387, chxlmicf1 0.55152, chxlmacf1 0.49705, chxlacc 0.71273, chxlrocaucmic 0.77918, chxlrocaucmac 0.75392, qlmicf1 0.34294, qlmacf1 0.25472, ema 0.70498, 20.83 secs\n",
      "Adjusting learning rate of group 0 to 2.9785e-05.\n",
      "---- Epoch 18/80\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 3.91422, a_loss 0.87781, cD 1.59371, wmdcmp 0.20968, oracc 0.99310, orien_loss 0.01711, chxlmicf1 0.55240, chxlmacf1 0.50426, chx_loss 0.77587, chxlacc 0.74617, chxlrocaucmic 0.83301, chxlrocaucmac 0.82568, qlmicf1 0.38036, qlmacf1 0.24977, ql_loss 0.74872, gacc 0.95845, gloss 0.10777, cxr14micf1 0.39234, cxr14macf1 0.38392, cxr14_loss 0.85921, vnbgmicf1 0.68060, vnbgmacf1 0.56387, vnbg_loss 0.47455, ema 0.74579, 146.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39724, wmdcmp 0.19144, oracc 0.99489, chxlmicf1 0.55567, chxlmacf1 0.50885, chxlacc 0.70738, chxlrocaucmic 0.77888, chxlrocaucmac 0.76279, qlmicf1 0.36154, qlmacf1 0.25793, ema 0.69593, 20.56 secs\n",
      "Adjusting learning rate of group 0 to 2.8223e-05.\n",
      "---- Epoch 19/80\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 3.87519, a_loss 0.87476, cD 1.59241, wmdcmp 0.20941, oracc 0.99399, orien_loss 0.01377, chxlmicf1 0.55808, chxlmacf1 0.50971, chx_loss 0.76460, chxlacc 0.74983, chxlrocaucmic 0.83696, chxlrocaucmac 0.83000, qlmicf1 0.38766, qlmacf1 0.24851, ql_loss 0.74114, gacc 0.95964, gloss 0.10487, cxr14micf1 0.39859, cxr14macf1 0.38519, cxr14_loss 0.84945, vnbgmicf1 0.68567, vnbgmacf1 0.57597, vnbg_loss 0.46378, ema 0.74453, 143.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38804, wmdcmp 0.19214, oracc 0.99460, chxlmicf1 0.55330, chxlmacf1 0.50398, chxlacc 0.69933, chxlrocaucmic 0.77967, chxlrocaucmac 0.75545, qlmicf1 0.36111, qlmacf1 0.25981, ema 0.68688, 20.85 secs\n",
      "Adjusting learning rate of group 0 to 2.6742e-05.\n",
      "---- Epoch 20/80\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.19930, a_loss 0.87450, cD 1.60406, wmdcmp 0.21080, oracc 0.99360, orien_loss 0.01485, chxlmicf1 0.56203, chxlmacf1 0.51290, chx_loss 0.75967, chxlacc 0.75288, chxlrocaucmic 0.83990, chxlrocaucmac 0.83250, qlmicf1 0.39142, qlmacf1 0.25548, ql_loss 0.73563, gacc 0.96488, gloss 0.09438, cxr14micf1 0.40184, cxr14macf1 0.39239, cxr14_loss 0.84236, vnbgmicf1 0.69034, vnbgmacf1 0.58676, vnbg_loss 0.45503, ema 0.74819, 143.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38387, wmdcmp 0.19054, oracc 0.99474, chxlmicf1 0.55002, chxlmacf1 0.50327, chxlacc 0.70398, chxlrocaucmic 0.77591, chxlrocaucmac 0.75810, qlmicf1 0.35210, qlmacf1 0.25768, ema 0.68054, 20.73 secs\n",
      "Adjusting learning rate of group 0 to 2.5340e-05.\n",
      "---- Epoch 21/80\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 3.99282, a_loss 0.87402, cD 1.60660, wmdcmp 0.21121, oracc 0.99401, orien_loss 0.01542, chxlmicf1 0.56231, chxlmacf1 0.51340, chx_loss 0.75637, chxlacc 0.75425, chxlrocaucmic 0.84042, chxlrocaucmac 0.83343, qlmicf1 0.39273, qlmacf1 0.25700, ql_loss 0.73287, gacc 0.96196, gloss 0.09896, cxr14micf1 0.40192, cxr14macf1 0.39128, cxr14_loss 0.84677, vnbgmicf1 0.69437, vnbgmacf1 0.59162, vnbg_loss 0.44888, ema 0.74645, 143.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40465, wmdcmp 0.19217, oracc 0.99460, chxlmicf1 0.54837, chxlmacf1 0.50208, chxlacc 0.69982, chxlrocaucmic 0.77131, chxlrocaucmac 0.75714, qlmicf1 0.35129, qlmacf1 0.25740, ema 0.69774, 21.02 secs\n",
      "Adjusting learning rate of group 0 to 2.4011e-05.\n",
      "---- Epoch 22/80\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 3.90105, a_loss 0.87201, cD 1.62149, wmdcmp 0.21273, oracc 0.99446, orien_loss 0.01262, chxlmicf1 0.56523, chxlmacf1 0.51604, chx_loss 0.74845, chxlacc 0.75638, chxlrocaucmic 0.84333, chxlrocaucmac 0.83643, qlmicf1 0.39860, qlmacf1 0.26061, ql_loss 0.72520, gacc 0.96321, gloss 0.09729, cxr14micf1 0.40076, cxr14macf1 0.39012, cxr14_loss 0.83845, vnbgmicf1 0.70483, vnbgmacf1 0.61150, vnbg_loss 0.42697, ema 0.74810, 144.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39406, wmdcmp 0.19157, oracc 0.99533, chxlmicf1 0.55587, chxlmacf1 0.50617, chxlacc 0.70579, chxlrocaucmic 0.78254, chxlrocaucmac 0.75846, qlmicf1 0.35450, qlmacf1 0.25709, ema 0.68416, 20.69 secs\n",
      "Adjusting learning rate of group 0 to 2.2752e-05.\n",
      "---- Epoch 23/80\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 3.92104, a_loss 0.86864, cD 1.61276, wmdcmp 0.21172, oracc 0.99438, orien_loss 0.01244, chxlmicf1 0.56817, chxlmacf1 0.51913, chx_loss 0.74281, chxlacc 0.75895, chxlrocaucmic 0.84585, chxlrocaucmac 0.83962, qlmicf1 0.40462, qlmacf1 0.26002, ql_loss 0.71366, gacc 0.96702, gloss 0.08954, cxr14micf1 0.40754, cxr14macf1 0.39689, cxr14_loss 0.83148, vnbgmicf1 0.71039, vnbgmacf1 0.61616, vnbg_loss 0.42459, ema 0.75449, 145.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38020, wmdcmp 0.18940, oracc 0.99474, chxlmicf1 0.55649, chxlmacf1 0.50421, chxlacc 0.71279, chxlrocaucmic 0.78214, chxlrocaucmac 0.76067, qlmicf1 0.35560, qlmacf1 0.25883, ema 0.69050, 20.59 secs\n",
      "Adjusting learning rate of group 0 to 2.1558e-05.\n",
      "---- Epoch 24/80\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.93319, a_loss 0.87054, cD 1.61086, wmdcmp 0.21216, oracc 0.99431, orien_loss 0.01345, chxlmicf1 0.57101, chxlmacf1 0.52181, chx_loss 0.73813, chxlacc 0.76162, chxlrocaucmic 0.84764, chxlrocaucmac 0.84132, qlmicf1 0.40525, qlmacf1 0.26002, ql_loss 0.71065, gacc 0.96685, gloss 0.08674, cxr14micf1 0.40840, cxr14macf1 0.40241, cxr14_loss 0.82192, vnbgmicf1 0.71824, vnbgmacf1 0.61843, vnbg_loss 0.41720, ema 0.75055, 144.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40337, wmdcmp 0.19215, oracc 0.99504, chxlmicf1 0.55676, chxlmacf1 0.50252, chxlacc 0.71461, chxlrocaucmic 0.78140, chxlrocaucmac 0.75757, qlmicf1 0.36339, qlmacf1 0.26135, ema 0.69231, 20.72 secs\n",
      "Adjusting learning rate of group 0 to 2.0428e-05.\n",
      "---- Epoch 25/80\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 3.94514, a_loss 0.86705, cD 1.62872, wmdcmp 0.21302, oracc 0.99436, orien_loss 0.01154, chxlmicf1 0.57419, chxlmacf1 0.52531, chx_loss 0.72942, chxlacc 0.76386, chxlrocaucmic 0.85039, chxlrocaucmac 0.84468, qlmicf1 0.41129, qlmacf1 0.26497, ql_loss 0.70694, gacc 0.96929, gloss 0.08075, cxr14micf1 0.40986, cxr14macf1 0.40225, cxr14_loss 0.82137, vnbgmicf1 0.72602, vnbgmacf1 0.63828, vnbg_loss 0.39753, ema 0.75641, 143.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38502, wmdcmp 0.18929, oracc 0.99504, chxlmicf1 0.55933, chxlmacf1 0.50670, chxlacc 0.72185, chxlrocaucmic 0.78413, chxlrocaucmac 0.76011, qlmicf1 0.35859, qlmacf1 0.26266, ema 0.70860, 20.82 secs\n",
      "Adjusting learning rate of group 0 to 1.9356e-05.\n",
      "---- Epoch 26/80\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 4.19902, a_loss 0.86360, cD 1.63273, wmdcmp 0.21367, oracc 0.99454, orien_loss 0.01120, chxlmicf1 0.57851, chxlmacf1 0.52989, chx_loss 0.72088, chxlacc 0.76634, chxlrocaucmic 0.85286, chxlrocaucmac 0.84747, qlmicf1 0.41642, qlmacf1 0.26844, ql_loss 0.69652, gacc 0.96988, gloss 0.07781, cxr14micf1 0.41390, cxr14macf1 0.40631, cxr14_loss 0.81854, vnbgmicf1 0.73461, vnbgmacf1 0.64597, vnbg_loss 0.38212, ema 0.75952, 144.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43090, wmdcmp 0.19485, oracc 0.99577, chxlmicf1 0.55820, chxlmacf1 0.50859, chxlacc 0.71473, chxlrocaucmic 0.78175, chxlrocaucmac 0.76191, qlmicf1 0.37204, qlmacf1 0.26411, ema 0.69683, 20.90 secs\n",
      "Adjusting learning rate of group 0 to 1.8341e-05.\n",
      "---- Epoch 27/80\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 4.08394, a_loss 0.86524, cD 1.63463, wmdcmp 0.21413, oracc 0.99479, orien_loss 0.01224, chxlmicf1 0.57864, chxlmacf1 0.52959, chx_loss 0.71987, chxlacc 0.76738, chxlrocaucmic 0.85325, chxlrocaucmac 0.84833, qlmicf1 0.41863, qlmacf1 0.26690, ql_loss 0.69195, gacc 0.97083, gloss 0.07892, cxr14micf1 0.42413, cxr14macf1 0.41915, cxr14_loss 0.79723, vnbgmicf1 0.73691, vnbgmacf1 0.65350, vnbg_loss 0.38635, ema 0.76158, 143.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40949, wmdcmp 0.19131, oracc 0.99577, chxlmicf1 0.56435, chxlmacf1 0.51147, chxlacc 0.71339, chxlrocaucmic 0.78758, chxlrocaucmac 0.76085, qlmicf1 0.36142, qlmacf1 0.26147, ema 0.69231, 20.90 secs\n",
      "Adjusting learning rate of group 0 to 1.7379e-05.\n",
      "---- Epoch 28/80\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 3.99432, a_loss 0.86710, cD 1.61672, wmdcmp 0.21245, oracc 0.99464, orien_loss 0.01143, chxlmicf1 0.58086, chxlmacf1 0.53222, chx_loss 0.71518, chxlacc 0.76889, chxlrocaucmic 0.85518, chxlrocaucmac 0.85022, qlmicf1 0.42125, qlmacf1 0.27153, ql_loss 0.69070, gacc 0.97190, gloss 0.07906, cxr14micf1 0.42508, cxr14macf1 0.42064, cxr14_loss 0.78987, vnbgmicf1 0.74457, vnbgmacf1 0.66134, vnbg_loss 0.37209, ema 0.76067, 145.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40086, wmdcmp 0.19152, oracc 0.99562, chxlmicf1 0.55853, chxlmacf1 0.50495, chxlacc 0.71902, chxlrocaucmic 0.78347, chxlrocaucmac 0.75743, qlmicf1 0.36248, qlmacf1 0.26328, ema 0.70317, 20.57 secs\n",
      "Adjusting learning rate of group 0 to 1.6468e-05.\n",
      "---- Epoch 29/80\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 4.10113, a_loss 0.86439, cD 1.62205, wmdcmp 0.21331, oracc 0.99421, orien_loss 0.01042, chxlmicf1 0.58381, chxlmacf1 0.53492, chx_loss 0.70973, chxlacc 0.77086, chxlrocaucmic 0.85692, chxlrocaucmac 0.85212, qlmicf1 0.42614, qlmacf1 0.27307, ql_loss 0.68366, gacc 0.97333, gloss 0.07173, cxr14micf1 0.42085, cxr14macf1 0.41622, cxr14_loss 0.79573, vnbgmicf1 0.74781, vnbgmacf1 0.67388, vnbg_loss 0.36851, ema 0.76193, 144.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40945, wmdcmp 0.19304, oracc 0.99504, chxlmicf1 0.56171, chxlmacf1 0.50810, chxlacc 0.72241, chxlrocaucmic 0.78595, chxlrocaucmac 0.76101, qlmicf1 0.37140, qlmacf1 0.26539, ema 0.70045, 20.83 secs\n",
      "Adjusting learning rate of group 0 to 1.5604e-05.\n",
      "---- Epoch 30/80\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.83782, a_loss 0.86673, cD 1.62068, wmdcmp 0.21214, oracc 0.99487, orien_loss 0.01067, chxlmicf1 0.58657, chxlmacf1 0.53825, chx_loss 0.70449, chxlacc 0.77286, chxlrocaucmic 0.85889, chxlrocaucmac 0.85397, qlmicf1 0.42826, qlmacf1 0.27814, ql_loss 0.67662, gacc 0.97321, gloss 0.07186, cxr14micf1 0.43023, cxr14macf1 0.42661, cxr14_loss 0.77861, vnbgmicf1 0.74789, vnbgmacf1 0.68849, vnbg_loss 0.36134, ema 0.76190, 144.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40662, wmdcmp 0.19176, oracc 0.99474, chxlmicf1 0.55869, chxlmacf1 0.50935, chxlacc 0.71798, chxlrocaucmic 0.78304, chxlrocaucmac 0.76201, qlmicf1 0.36406, qlmacf1 0.26337, ema 0.69683, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 1.4786e-05.\n",
      "---- Epoch 31/80\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 3.91595, a_loss 0.86151, cD 1.63659, wmdcmp 0.21455, oracc 0.99507, orien_loss 0.01093, chxlmicf1 0.58706, chxlmacf1 0.53866, chx_loss 0.70026, chxlacc 0.77429, chxlrocaucmic 0.86034, chxlrocaucmac 0.85532, qlmicf1 0.43033, qlmacf1 0.27827, ql_loss 0.67386, gacc 0.97446, gloss 0.06942, cxr14micf1 0.42486, cxr14macf1 0.42081, cxr14_loss 0.78644, vnbgmicf1 0.75728, vnbgmacf1 0.68825, vnbg_loss 0.35569, ema 0.76326, 145.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39009, wmdcmp 0.19070, oracc 0.99533, chxlmicf1 0.56159, chxlmacf1 0.50999, chxlacc 0.71594, chxlrocaucmic 0.78558, chxlrocaucmac 0.75834, qlmicf1 0.36181, qlmacf1 0.26148, ema 0.69412, 20.74 secs\n",
      "Adjusting learning rate of group 0 to 1.4010e-05.\n",
      "---- Epoch 32/80\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.85773, a_loss 0.86151, cD 1.63071, wmdcmp 0.21464, oracc 0.99527, orien_loss 0.00933, chxlmicf1 0.58883, chxlmacf1 0.54166, chx_loss 0.69462, chxlacc 0.77589, chxlrocaucmic 0.86192, chxlrocaucmac 0.85787, qlmicf1 0.43338, qlmacf1 0.28460, ql_loss 0.66853, gacc 0.97470, gloss 0.07248, cxr14micf1 0.43581, cxr14macf1 0.43162, cxr14_loss 0.77419, vnbgmicf1 0.76091, vnbgmacf1 0.69549, vnbg_loss 0.34731, ema 0.76658, 144.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38904, wmdcmp 0.19007, oracc 0.99445, chxlmicf1 0.56370, chxlmacf1 0.51057, chxlacc 0.72279, chxlrocaucmic 0.78751, chxlrocaucmac 0.76212, qlmicf1 0.36677, qlmacf1 0.26122, ema 0.69321, 21.31 secs\n",
      "Adjusting learning rate of group 0 to 1.3275e-05.\n",
      "---- Epoch 33/80\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 3.78516, a_loss 0.85958, cD 1.62627, wmdcmp 0.21302, oracc 0.99482, orien_loss 0.00930, chxlmicf1 0.59181, chxlmacf1 0.54348, chx_loss 0.69073, chxlacc 0.77710, chxlrocaucmic 0.86399, chxlrocaucmac 0.85933, qlmicf1 0.43484, qlmacf1 0.28471, ql_loss 0.66301, gacc 0.97315, gloss 0.06956, cxr14micf1 0.43358, cxr14macf1 0.42912, cxr14_loss 0.77463, vnbgmicf1 0.76627, vnbgmacf1 0.70405, vnbg_loss 0.33874, ema 0.76664, 144.94 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.41380, wmdcmp 0.19261, oracc 0.99518, chxlmicf1 0.56281, chxlmacf1 0.50895, chxlacc 0.72633, chxlrocaucmic 0.78513, chxlrocaucmac 0.75880, qlmicf1 0.36871, qlmacf1 0.26630, ema 0.69321, 20.59 secs\n",
      "Adjusting learning rate of group 0 to 1.2579e-05.\n",
      "---- Epoch 34/80\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 3.85145, a_loss 0.85934, cD 1.62609, wmdcmp 0.21388, oracc 0.99541, orien_loss 0.00901, chxlmicf1 0.59326, chxlmacf1 0.54461, chx_loss 0.68814, chxlacc 0.77886, chxlrocaucmic 0.86452, chxlrocaucmac 0.86041, qlmicf1 0.43655, qlmacf1 0.28470, ql_loss 0.66111, gacc 0.97667, gloss 0.06383, cxr14micf1 0.43953, cxr14macf1 0.43705, cxr14_loss 0.76035, vnbgmicf1 0.76987, vnbgmacf1 0.70994, vnbg_loss 0.33729, ema 0.76868, 145.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40373, wmdcmp 0.19193, oracc 0.99474, chxlmicf1 0.55850, chxlmacf1 0.50433, chxlacc 0.72746, chxlrocaucmic 0.78588, chxlrocaucmac 0.76054, qlmicf1 0.36924, qlmacf1 0.26382, ema 0.68688, 20.87 secs\n",
      "Adjusting learning rate of group 0 to 1.1919e-05.\n",
      "---- Epoch 35/80\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 3.87045, a_loss 0.85675, cD 1.64076, wmdcmp 0.21448, oracc 0.99487, orien_loss 0.00905, chxlmicf1 0.59479, chxlmacf1 0.54685, chx_loss 0.68291, chxlacc 0.78062, chxlrocaucmic 0.86595, chxlrocaucmac 0.86241, qlmicf1 0.44046, qlmacf1 0.28423, ql_loss 0.65302, gacc 0.97732, gloss 0.05990, cxr14micf1 0.43385, cxr14macf1 0.43198, cxr14_loss 0.76091, vnbgmicf1 0.77191, vnbgmacf1 0.71111, vnbg_loss 0.33315, ema 0.77163, 146.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40635, wmdcmp 0.19231, oracc 0.99547, chxlmicf1 0.56130, chxlmacf1 0.50600, chxlacc 0.72213, chxlrocaucmic 0.78790, chxlrocaucmac 0.75937, qlmicf1 0.37634, qlmacf1 0.26719, ema 0.68869, 21.07 secs\n",
      "Adjusting learning rate of group 0 to 1.1294e-05.\n",
      "---- Epoch 36/80\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 4.02542, a_loss 0.85753, cD 1.63593, wmdcmp 0.21492, oracc 0.99472, orien_loss 0.00991, chxlmicf1 0.59797, chxlmacf1 0.54982, chx_loss 0.67848, chxlacc 0.78219, chxlrocaucmic 0.86742, chxlrocaucmac 0.86348, qlmicf1 0.43868, qlmacf1 0.28544, ql_loss 0.65388, gacc 0.97774, gloss 0.06253, cxr14micf1 0.44540, cxr14macf1 0.44491, cxr14_loss 0.75276, vnbgmicf1 0.77773, vnbgmacf1 0.71451, vnbg_loss 0.32556, ema 0.76930, 144.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40444, wmdcmp 0.19273, oracc 0.99445, chxlmicf1 0.56172, chxlmacf1 0.50807, chxlacc 0.72409, chxlrocaucmic 0.78675, chxlrocaucmac 0.76057, qlmicf1 0.36967, qlmacf1 0.26597, ema 0.70498, 20.81 secs\n",
      "Adjusting learning rate of group 0 to 1.0702e-05.\n",
      "---- Epoch 37/80\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 3.84171, a_loss 0.85721, cD 1.63986, wmdcmp 0.21466, oracc 0.99530, orien_loss 0.00997, chxlmicf1 0.59843, chxlmacf1 0.55192, chx_loss 0.67420, chxlacc 0.78275, chxlrocaucmic 0.86846, chxlrocaucmac 0.86485, qlmicf1 0.44342, qlmacf1 0.29091, ql_loss 0.64365, gacc 0.97774, gloss 0.06117, cxr14micf1 0.43748, cxr14macf1 0.43541, cxr14_loss 0.75670, vnbgmicf1 0.77719, vnbgmacf1 0.71989, vnbg_loss 0.32146, ema 0.77143, 145.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40584, wmdcmp 0.19233, oracc 0.99489, chxlmicf1 0.56455, chxlmacf1 0.50903, chxlacc 0.72571, chxlrocaucmic 0.79074, chxlrocaucmac 0.76219, qlmicf1 0.38062, qlmacf1 0.26990, ema 0.69050, 21.00 secs\n",
      "Adjusting learning rate of group 0 to 1.0140e-05.\n",
      "---- Epoch 38/80\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.67929, a_loss 0.85838, cD 1.63904, wmdcmp 0.21461, oracc 0.99542, orien_loss 0.01016, chxlmicf1 0.60195, chxlmacf1 0.55548, chx_loss 0.67009, chxlacc 0.78488, chxlrocaucmic 0.87013, chxlrocaucmac 0.86658, qlmicf1 0.44422, qlmacf1 0.29182, ql_loss 0.64340, gacc 0.97958, gloss 0.05633, cxr14micf1 0.44396, cxr14macf1 0.44544, cxr14_loss 0.75576, vnbgmicf1 0.78556, vnbgmacf1 0.73190, vnbg_loss 0.31608, ema 0.77104, 145.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39044, wmdcmp 0.19021, oracc 0.99518, chxlmicf1 0.56738, chxlmacf1 0.50910, chxlacc 0.72749, chxlrocaucmic 0.79410, chxlrocaucmac 0.76103, qlmicf1 0.37496, qlmacf1 0.26662, ema 0.69683, 20.61 secs\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "---- Epoch 39/80\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.86850, a_loss 0.85671, cD 1.62748, wmdcmp 0.21319, oracc 0.99503, orien_loss 0.00926, chxlmicf1 0.60269, chxlmacf1 0.55488, chx_loss 0.66796, chxlacc 0.78551, chxlrocaucmic 0.87136, chxlrocaucmac 0.86755, qlmicf1 0.44655, qlmacf1 0.29448, ql_loss 0.63891, gacc 0.97827, gloss 0.05836, cxr14micf1 0.44599, cxr14macf1 0.44519, cxr14_loss 0.75101, vnbgmicf1 0.78495, vnbgmacf1 0.73752, vnbg_loss 0.31412, ema 0.77452, 144.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40345, wmdcmp 0.19168, oracc 0.99504, chxlmicf1 0.56845, chxlmacf1 0.51465, chxlacc 0.72745, chxlrocaucmic 0.79174, chxlrocaucmac 0.76388, qlmicf1 0.37243, qlmacf1 0.26560, ema 0.69050, 20.97 secs\n",
      "Adjusting learning rate of group 0 to 9.1047e-06.\n",
      "---- Epoch 40/80\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.69552, a_loss 0.85566, cD 1.65117, wmdcmp 0.21588, oracc 0.99521, orien_loss 0.00807, chxlmicf1 0.60575, chxlmacf1 0.55952, chx_loss 0.65933, chxlacc 0.78797, chxlrocaucmic 0.87344, chxlrocaucmac 0.87014, qlmicf1 0.44777, qlmacf1 0.29562, ql_loss 0.63739, gacc 0.97869, gloss 0.05591, cxr14micf1 0.44551, cxr14macf1 0.44609, cxr14_loss 0.74529, vnbgmicf1 0.78935, vnbgmacf1 0.75034, vnbg_loss 0.30730, ema 0.77404, 145.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42083, wmdcmp 0.19427, oracc 0.99577, chxlmicf1 0.56946, chxlmacf1 0.51461, chxlacc 0.73196, chxlrocaucmic 0.79369, chxlrocaucmac 0.76259, qlmicf1 0.37724, qlmacf1 0.26764, ema 0.69502, 21.15 secs\n",
      "Adjusting learning rate of group 0 to 8.6272e-06.\n",
      "---- Epoch 41/80\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.88766, a_loss 0.85351, cD 1.64185, wmdcmp 0.21518, oracc 0.99570, orien_loss 0.00819, chxlmicf1 0.60609, chxlmacf1 0.56002, chx_loss 0.65869, chxlacc 0.78829, chxlrocaucmic 0.87374, chxlrocaucmac 0.87005, qlmicf1 0.44975, qlmacf1 0.29637, ql_loss 0.63360, gacc 0.97917, gloss 0.05619, cxr14micf1 0.44506, cxr14macf1 0.44452, cxr14_loss 0.74484, vnbgmicf1 0.79162, vnbgmacf1 0.75109, vnbg_loss 0.30746, ema 0.77344, 144.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40394, wmdcmp 0.19220, oracc 0.99606, chxlmicf1 0.56958, chxlmacf1 0.51191, chxlacc 0.72983, chxlrocaucmic 0.79446, chxlrocaucmac 0.76079, qlmicf1 0.37664, qlmacf1 0.27003, ema 0.70317, 21.10 secs\n",
      "Adjusting learning rate of group 0 to 8.1747e-06.\n",
      "---- Epoch 42/80\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 3.87671, a_loss 0.85398, cD 1.64432, wmdcmp 0.21530, oracc 0.99521, orien_loss 0.00781, chxlmicf1 0.60770, chxlmacf1 0.56131, chx_loss 0.65527, chxlacc 0.78919, chxlrocaucmic 0.87502, chxlrocaucmac 0.87177, qlmicf1 0.44969, qlmacf1 0.29961, ql_loss 0.63115, gacc 0.98131, gloss 0.05153, cxr14micf1 0.45130, cxr14macf1 0.45116, cxr14_loss 0.73398, vnbgmicf1 0.79288, vnbgmacf1 0.75487, vnbg_loss 0.30273, ema 0.77617, 145.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41002, wmdcmp 0.19286, oracc 0.99620, chxlmicf1 0.56737, chxlmacf1 0.50754, chxlacc 0.73190, chxlrocaucmic 0.78976, chxlrocaucmac 0.75680, qlmicf1 0.37877, qlmacf1 0.26803, ema 0.69321, 20.83 secs\n",
      "Adjusting learning rate of group 0 to 7.7460e-06.\n",
      "---- Epoch 43/80\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 3.57864, a_loss 0.85299, cD 1.64332, wmdcmp 0.21525, oracc 0.99530, orien_loss 0.00818, chxlmicf1 0.60881, chxlmacf1 0.56300, chx_loss 0.65343, chxlacc 0.79062, chxlrocaucmic 0.87573, chxlrocaucmac 0.87238, qlmicf1 0.45274, qlmacf1 0.29773, ql_loss 0.62575, gacc 0.98173, gloss 0.05168, cxr14micf1 0.44796, cxr14macf1 0.45025, cxr14_loss 0.73452, vnbgmicf1 0.79526, vnbgmacf1 0.74993, vnbg_loss 0.30116, ema 0.77406, 145.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39671, wmdcmp 0.19084, oracc 0.99606, chxlmicf1 0.56378, chxlmacf1 0.50684, chxlacc 0.73049, chxlrocaucmic 0.79014, chxlrocaucmac 0.76059, qlmicf1 0.37482, qlmacf1 0.26796, ema 0.68959, 20.75 secs\n",
      "Adjusting learning rate of group 0 to 7.3397e-06.\n",
      "---- Epoch 44/80\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.69697, a_loss 0.85445, cD 1.65198, wmdcmp 0.21577, oracc 0.99515, orien_loss 0.00897, chxlmicf1 0.61194, chxlmacf1 0.56750, chx_loss 0.64720, chxlacc 0.79245, chxlrocaucmic 0.87690, chxlrocaucmac 0.87368, qlmicf1 0.45156, qlmacf1 0.30345, ql_loss 0.62879, gacc 0.98024, gloss 0.05501, cxr14micf1 0.45740, cxr14macf1 0.45472, cxr14_loss 0.72466, vnbgmicf1 0.79707, vnbgmacf1 0.75556, vnbg_loss 0.29310, ema 0.78198, 145.08 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.40382, wmdcmp 0.19173, oracc 0.99635, chxlmicf1 0.56751, chxlmacf1 0.50991, chxlacc 0.73268, chxlrocaucmic 0.79131, chxlrocaucmac 0.75882, qlmicf1 0.37632, qlmacf1 0.26823, ema 0.69955, 20.78 secs\n",
      "Adjusting learning rate of group 0 to 6.9548e-06.\n",
      "---- Epoch 45/80\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.83960, a_loss 0.85415, cD 1.64535, wmdcmp 0.21516, oracc 0.99569, orien_loss 0.00794, chxlmicf1 0.61012, chxlmacf1 0.56539, chx_loss 0.64667, chxlacc 0.79134, chxlrocaucmic 0.87726, chxlrocaucmac 0.87393, qlmicf1 0.45393, qlmacf1 0.29995, ql_loss 0.62292, gacc 0.98054, gloss 0.05202, cxr14micf1 0.45705, cxr14macf1 0.45689, cxr14_loss 0.72739, vnbgmicf1 0.80221, vnbgmacf1 0.76549, vnbg_loss 0.28805, ema 0.77864, 144.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39392, wmdcmp 0.19105, oracc 0.99620, chxlmicf1 0.56175, chxlmacf1 0.50209, chxlacc 0.72938, chxlrocaucmic 0.79091, chxlrocaucmac 0.75754, qlmicf1 0.37983, qlmacf1 0.26766, ema 0.70045, 20.97 secs\n",
      "Adjusting learning rate of group 0 to 6.5900e-06.\n",
      "---- Epoch 46/80\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.77952, a_loss 0.85514, cD 1.65139, wmdcmp 0.21592, oracc 0.99549, orien_loss 0.00837, chxlmicf1 0.61155, chxlmacf1 0.56672, chx_loss 0.64525, chxlacc 0.79302, chxlrocaucmic 0.87804, chxlrocaucmac 0.87493, qlmicf1 0.45381, qlmacf1 0.30220, ql_loss 0.61920, gacc 0.98065, gloss 0.05207, cxr14micf1 0.44670, cxr14macf1 0.45004, cxr14_loss 0.74177, vnbgmicf1 0.80289, vnbgmacf1 0.76727, vnbg_loss 0.29319, ema 0.77571, 145.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40814, wmdcmp 0.19239, oracc 0.99635, chxlmicf1 0.56728, chxlmacf1 0.50605, chxlacc 0.73286, chxlrocaucmic 0.79216, chxlrocaucmac 0.75738, qlmicf1 0.38121, qlmacf1 0.27029, ema 0.68235, 20.82 secs\n",
      "Adjusting learning rate of group 0 to 6.2444e-06.\n",
      "---- Epoch 47/80\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.56271, a_loss 0.85160, cD 1.64329, wmdcmp 0.21544, oracc 0.99559, orien_loss 0.00798, chxlmicf1 0.61241, chxlmacf1 0.56742, chx_loss 0.64164, chxlacc 0.79376, chxlrocaucmic 0.87905, chxlrocaucmac 0.87624, qlmicf1 0.45626, qlmacf1 0.30481, ql_loss 0.61698, gacc 0.98179, gloss 0.05039, cxr14micf1 0.45571, cxr14macf1 0.46024, cxr14_loss 0.71997, vnbgmicf1 0.80473, vnbgmacf1 0.76630, vnbg_loss 0.28696, ema 0.77679, 148.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41022, wmdcmp 0.19252, oracc 0.99650, chxlmicf1 0.56419, chxlmacf1 0.50244, chxlacc 0.73313, chxlrocaucmic 0.79155, chxlrocaucmac 0.75746, qlmicf1 0.37827, qlmacf1 0.26835, ema 0.69140, 20.86 secs\n",
      "Adjusting learning rate of group 0 to 5.9169e-06.\n",
      "---- Epoch 48/80\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.72443, a_loss 0.85216, cD 1.65284, wmdcmp 0.21579, oracc 0.99522, orien_loss 0.00824, chxlmicf1 0.61583, chxlmacf1 0.57114, chx_loss 0.63935, chxlacc 0.79521, chxlrocaucmic 0.88030, chxlrocaucmac 0.87692, qlmicf1 0.45776, qlmacf1 0.30627, ql_loss 0.61623, gacc 0.98071, gloss 0.05322, cxr14micf1 0.45487, cxr14macf1 0.45633, cxr14_loss 0.72252, vnbgmicf1 0.80966, vnbgmacf1 0.77203, vnbg_loss 0.28014, ema 0.78187, 154.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40396, wmdcmp 0.19267, oracc 0.99635, chxlmicf1 0.56711, chxlmacf1 0.50650, chxlacc 0.73722, chxlrocaucmic 0.79334, chxlrocaucmac 0.75933, qlmicf1 0.38597, qlmacf1 0.27222, ema 0.69593, 24.09 secs\n",
      "Adjusting learning rate of group 0 to 5.6065e-06.\n",
      "---- Epoch 49/80\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 3.73866, a_loss 0.85258, cD 1.65376, wmdcmp 0.21628, oracc 0.99540, orien_loss 0.00777, chxlmicf1 0.61607, chxlmacf1 0.57245, chx_loss 0.63468, chxlacc 0.79621, chxlrocaucmic 0.88103, chxlrocaucmac 0.87793, qlmicf1 0.45879, qlmacf1 0.30755, ql_loss 0.61279, gacc 0.98202, gloss 0.05219, cxr14micf1 0.45993, cxr14macf1 0.46295, cxr14_loss 0.71642, vnbgmicf1 0.80878, vnbgmacf1 0.76862, vnbg_loss 0.27741, ema 0.78267, 166.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37949, wmdcmp 0.18978, oracc 0.99533, chxlmicf1 0.56664, chxlmacf1 0.50520, chxlacc 0.73150, chxlrocaucmic 0.79144, chxlrocaucmac 0.75664, qlmicf1 0.37849, qlmacf1 0.26801, ema 0.68597, 23.61 secs\n",
      "Adjusting learning rate of group 0 to 5.3125e-06.\n",
      "---- Epoch 50/80\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.92496, a_loss 0.85006, cD 1.65800, wmdcmp 0.21694, oracc 0.99531, orien_loss 0.00808, chxlmicf1 0.61810, chxlmacf1 0.57405, chx_loss 0.63242, chxlacc 0.79690, chxlrocaucmic 0.88190, chxlrocaucmac 0.87884, qlmicf1 0.45911, qlmacf1 0.30910, ql_loss 0.61125, gacc 0.98339, gloss 0.04984, cxr14micf1 0.46185, cxr14macf1 0.46414, cxr14_loss 0.71177, vnbgmicf1 0.80707, vnbgmacf1 0.76693, vnbg_loss 0.28111, ema 0.77898, 169.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40132, wmdcmp 0.19183, oracc 0.99606, chxlmicf1 0.56684, chxlmacf1 0.50607, chxlacc 0.73325, chxlrocaucmic 0.79499, chxlrocaucmac 0.75961, qlmicf1 0.37927, qlmacf1 0.26858, ema 0.70860, 25.81 secs\n",
      "Adjusting learning rate of group 0 to 5.0339e-06.\n",
      "---- Epoch 51/80\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.69610, a_loss 0.84964, cD 1.65935, wmdcmp 0.21726, oracc 0.99547, orien_loss 0.00771, chxlmicf1 0.61785, chxlmacf1 0.57346, chx_loss 0.63141, chxlacc 0.79701, chxlrocaucmic 0.88229, chxlrocaucmac 0.87921, qlmicf1 0.45992, qlmacf1 0.30700, ql_loss 0.60868, gacc 0.98173, gloss 0.05282, cxr14micf1 0.46382, cxr14macf1 0.46573, cxr14_loss 0.71191, vnbgmicf1 0.80912, vnbgmacf1 0.77257, vnbg_loss 0.27781, ema 0.77800, 170.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41162, wmdcmp 0.19220, oracc 0.99591, chxlmicf1 0.56489, chxlmacf1 0.50310, chxlacc 0.73386, chxlrocaucmic 0.79066, chxlrocaucmac 0.75628, qlmicf1 0.38205, qlmacf1 0.27040, ema 0.69231, 27.25 secs\n",
      "Adjusting learning rate of group 0 to 4.7699e-06.\n",
      "---- Epoch 52/80\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.71246, a_loss 0.85183, cD 1.66466, wmdcmp 0.21807, oracc 0.99570, orien_loss 0.00795, chxlmicf1 0.61948, chxlmacf1 0.57679, chx_loss 0.62923, chxlacc 0.79841, chxlrocaucmic 0.88284, chxlrocaucmac 0.87992, qlmicf1 0.46272, qlmacf1 0.30793, ql_loss 0.60294, gacc 0.98185, gloss 0.04915, cxr14micf1 0.46486, cxr14macf1 0.46820, cxr14_loss 0.70261, vnbgmicf1 0.81386, vnbgmacf1 0.78091, vnbg_loss 0.27299, ema 0.78198, 171.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40012, wmdcmp 0.19102, oracc 0.99591, chxlmicf1 0.56246, chxlmacf1 0.50170, chxlacc 0.73438, chxlrocaucmic 0.79006, chxlrocaucmac 0.75496, qlmicf1 0.38065, qlmacf1 0.26771, ema 0.69683, 27.39 secs\n",
      "Adjusting learning rate of group 0 to 4.5197e-06.\n",
      "---- Epoch 53/80\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.81494, a_loss 0.85209, cD 1.64617, wmdcmp 0.21528, oracc 0.99492, orien_loss 0.00816, chxlmicf1 0.62020, chxlmacf1 0.57678, chx_loss 0.62786, chxlacc 0.79854, chxlrocaucmic 0.88340, chxlrocaucmac 0.88050, qlmicf1 0.46230, qlmacf1 0.31069, ql_loss 0.60312, gacc 0.98298, gloss 0.05050, cxr14micf1 0.46703, cxr14macf1 0.46918, cxr14_loss 0.69945, vnbgmicf1 0.81047, vnbgmacf1 0.77866, vnbg_loss 0.27690, ema 0.78283, 173.67 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38713, wmdcmp 0.19020, oracc 0.99591, chxlmicf1 0.56694, chxlmacf1 0.50335, chxlacc 0.73702, chxlrocaucmic 0.79258, chxlrocaucmac 0.75564, qlmicf1 0.38450, qlmacf1 0.27013, ema 0.70407, 27.90 secs\n",
      "Adjusting learning rate of group 0 to 4.2826e-06.\n",
      "---- Epoch 54/80\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.75784, a_loss 0.84906, cD 1.65899, wmdcmp 0.21672, oracc 0.99506, orien_loss 0.00771, chxlmicf1 0.62056, chxlmacf1 0.57737, chx_loss 0.62389, chxlacc 0.79876, chxlrocaucmic 0.88393, chxlrocaucmac 0.88105, qlmicf1 0.46302, qlmacf1 0.31569, ql_loss 0.60428, gacc 0.98244, gloss 0.04760, cxr14micf1 0.46880, cxr14macf1 0.47067, cxr14_loss 0.70236, vnbgmicf1 0.81996, vnbgmacf1 0.79310, vnbg_loss 0.26795, ema 0.78322, 172.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41348, wmdcmp 0.19320, oracc 0.99620, chxlmicf1 0.56847, chxlmacf1 0.50667, chxlacc 0.74149, chxlrocaucmic 0.79393, chxlrocaucmac 0.75817, qlmicf1 0.38358, qlmacf1 0.26871, ema 0.69321, 25.88 secs\n",
      "Adjusting learning rate of group 0 to 4.0580e-06.\n",
      "---- Epoch 55/80\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.62448, a_loss 0.84730, cD 1.66522, wmdcmp 0.21784, oracc 0.99544, orien_loss 0.00870, chxlmicf1 0.62220, chxlmacf1 0.57949, chx_loss 0.62354, chxlacc 0.80042, chxlrocaucmic 0.88467, chxlrocaucmac 0.88158, qlmicf1 0.46412, qlmacf1 0.31616, ql_loss 0.60129, gacc 0.98315, gloss 0.04751, cxr14micf1 0.46516, cxr14macf1 0.46736, cxr14_loss 0.70034, vnbgmicf1 0.81620, vnbgmacf1 0.78884, vnbg_loss 0.26716, ema 0.78120, 171.61 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.39006, wmdcmp 0.18992, oracc 0.99606, chxlmicf1 0.56590, chxlmacf1 0.50469, chxlacc 0.73461, chxlrocaucmic 0.79305, chxlrocaucmac 0.75692, qlmicf1 0.38083, qlmacf1 0.26989, ema 0.68597, 24.39 secs\n",
      "Adjusting learning rate of group 0 to 3.8452e-06.\n",
      "---- Epoch 56/80\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.58753, a_loss 0.84783, cD 1.67005, wmdcmp 0.21825, oracc 0.99564, orien_loss 0.00837, chxlmicf1 0.62203, chxlmacf1 0.57883, chx_loss 0.62187, chxlacc 0.79999, chxlrocaucmic 0.88458, chxlrocaucmac 0.88168, qlmicf1 0.46312, qlmacf1 0.31607, ql_loss 0.60190, gacc 0.98232, gloss 0.04959, cxr14micf1 0.46906, cxr14macf1 0.47278, cxr14_loss 0.69471, vnbgmicf1 0.81894, vnbgmacf1 0.79110, vnbg_loss 0.26678, ema 0.78285, 171.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40630, wmdcmp 0.19211, oracc 0.99606, chxlmicf1 0.56555, chxlmacf1 0.50442, chxlacc 0.73686, chxlrocaucmic 0.79449, chxlrocaucmac 0.75903, qlmicf1 0.38505, qlmacf1 0.26961, ema 0.70769, 25.89 secs\n",
      "Adjusting learning rate of group 0 to 3.6435e-06.\n",
      "---- Epoch 57/80\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.76042, a_loss 0.84946, cD 1.66650, wmdcmp 0.21806, oracc 0.99590, orien_loss 0.00697, chxlmicf1 0.62330, chxlmacf1 0.58104, chx_loss 0.62062, chxlacc 0.80079, chxlrocaucmic 0.88567, chxlrocaucmac 0.88256, qlmicf1 0.46518, qlmacf1 0.31450, ql_loss 0.59832, gacc 0.98196, gloss 0.05109, cxr14micf1 0.47304, cxr14macf1 0.47435, cxr14_loss 0.69684, vnbgmicf1 0.81698, vnbgmacf1 0.77893, vnbg_loss 0.26978, ema 0.78400, 168.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39046, wmdcmp 0.18979, oracc 0.99606, chxlmicf1 0.56488, chxlmacf1 0.50148, chxlacc 0.73842, chxlrocaucmic 0.79308, chxlrocaucmac 0.75656, qlmicf1 0.38173, qlmacf1 0.27112, ema 0.70317, 26.63 secs\n",
      "Adjusting learning rate of group 0 to 3.4524e-06.\n",
      "---- Epoch 58/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.81191, a_loss 0.84741, cD 1.65092, wmdcmp 0.21614, oracc 0.99567, orien_loss 0.00724, chxlmicf1 0.62362, chxlmacf1 0.58076, chx_loss 0.61826, chxlacc 0.80135, chxlrocaucmic 0.88587, chxlrocaucmac 0.88341, qlmicf1 0.46496, qlmacf1 0.31514, ql_loss 0.60055, gacc 0.98476, gloss 0.04572, cxr14micf1 0.47133, cxr14macf1 0.47326, cxr14_loss 0.70005, vnbgmicf1 0.82036, vnbgmacf1 0.79122, vnbg_loss 0.27433, ema 0.78239, 171.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39471, wmdcmp 0.19033, oracc 0.99620, chxlmicf1 0.56548, chxlmacf1 0.50382, chxlacc 0.73638, chxlrocaucmic 0.79372, chxlrocaucmac 0.75689, qlmicf1 0.38472, qlmacf1 0.27044, ema 0.68416, 25.74 secs\n",
      "Adjusting learning rate of group 0 to 3.2714e-06.\n",
      "---- Epoch 59/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.62117, a_loss 0.84832, cD 1.66848, wmdcmp 0.21799, oracc 0.99555, orien_loss 0.00748, chxlmicf1 0.62681, chxlmacf1 0.58486, chx_loss 0.61487, chxlacc 0.80369, chxlrocaucmic 0.88722, chxlrocaucmac 0.88425, qlmicf1 0.46576, qlmacf1 0.31499, ql_loss 0.59463, gacc 0.98339, gloss 0.04383, cxr14micf1 0.46720, cxr14macf1 0.47284, cxr14_loss 0.69669, vnbgmicf1 0.82315, vnbgmacf1 0.79125, vnbg_loss 0.26350, ema 0.78324, 173.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41911, wmdcmp 0.19342, oracc 0.99635, chxlmicf1 0.56626, chxlmacf1 0.50264, chxlacc 0.73866, chxlrocaucmic 0.79179, chxlrocaucmac 0.75425, qlmicf1 0.38092, qlmacf1 0.26939, ema 0.68869, 25.25 secs\n",
      "Adjusting learning rate of group 0 to 3.0998e-06.\n",
      "---- Epoch 60/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.68998, a_loss 0.84858, cD 1.67231, wmdcmp 0.21894, oracc 0.99565, orien_loss 0.00750, chxlmicf1 0.62595, chxlmacf1 0.58367, chx_loss 0.61518, chxlacc 0.80305, chxlrocaucmic 0.88678, chxlrocaucmac 0.88415, qlmicf1 0.46662, qlmacf1 0.31798, ql_loss 0.59499, gacc 0.98315, gloss 0.04208, cxr14micf1 0.47174, cxr14macf1 0.47546, cxr14_loss 0.69586, vnbgmicf1 0.81827, vnbgmacf1 0.79388, vnbg_loss 0.26883, ema 0.77942, 169.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40640, wmdcmp 0.19249, oracc 0.99635, chxlmicf1 0.57024, chxlmacf1 0.50886, chxlacc 0.73950, chxlrocaucmic 0.79422, chxlrocaucmac 0.75707, qlmicf1 0.38429, qlmacf1 0.26952, ema 0.70317, 26.02 secs\n",
      "Adjusting learning rate of group 0 to 2.9372e-06.\n",
      "---- Epoch 61/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.70415, a_loss 0.84765, cD 1.66103, wmdcmp 0.21683, oracc 0.99545, orien_loss 0.00873, chxlmicf1 0.62616, chxlmacf1 0.58439, chx_loss 0.61381, chxlacc 0.80272, chxlrocaucmic 0.88724, chxlrocaucmac 0.88425, qlmicf1 0.46719, qlmacf1 0.31667, ql_loss 0.59479, gacc 0.98357, gloss 0.04541, cxr14micf1 0.47152, cxr14macf1 0.47781, cxr14_loss 0.69366, vnbgmicf1 0.82000, vnbgmacf1 0.78964, vnbg_loss 0.26438, ema 0.78379, 170.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40220, wmdcmp 0.19189, oracc 0.99635, chxlmicf1 0.56664, chxlmacf1 0.50441, chxlacc 0.74070, chxlrocaucmic 0.79235, chxlrocaucmac 0.75564, qlmicf1 0.38593, qlmacf1 0.27119, ema 0.68959, 25.90 secs\n",
      "Adjusting learning rate of group 0 to 2.7832e-06.\n",
      "---- Epoch 62/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.55801, a_loss 0.84815, cD 1.65528, wmdcmp 0.21638, oracc 0.99569, orien_loss 0.00748, chxlmicf1 0.62778, chxlmacf1 0.58707, chx_loss 0.60968, chxlacc 0.80446, chxlrocaucmic 0.88867, chxlrocaucmac 0.88562, qlmicf1 0.46891, qlmacf1 0.31826, ql_loss 0.59103, gacc 0.98470, gloss 0.04234, cxr14micf1 0.47160, cxr14macf1 0.47772, cxr14_loss 0.69320, vnbgmicf1 0.82676, vnbgmacf1 0.80095, vnbg_loss 0.25982, ema 0.78432, 169.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39062, wmdcmp 0.19087, oracc 0.99606, chxlmicf1 0.56630, chxlmacf1 0.50368, chxlacc 0.73975, chxlrocaucmic 0.79202, chxlrocaucmac 0.75451, qlmicf1 0.38137, qlmacf1 0.26917, ema 0.69140, 26.33 secs\n",
      "Adjusting learning rate of group 0 to 2.6372e-06.\n",
      "---- Epoch 63/80\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.60328, a_loss 0.84993, cD 1.65598, wmdcmp 0.21675, oracc 0.99519, orien_loss 0.00751, chxlmicf1 0.62854, chxlmacf1 0.58723, chx_loss 0.60846, chxlacc 0.80417, chxlrocaucmic 0.88841, chxlrocaucmac 0.88584, qlmicf1 0.46932, qlmacf1 0.32216, ql_loss 0.58943, gacc 0.98583, gloss 0.04123, cxr14micf1 0.47413, cxr14macf1 0.47656, cxr14_loss 0.69157, vnbgmicf1 0.82477, vnbgmacf1 0.80232, vnbg_loss 0.26327, ema 0.78677, 170.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38834, wmdcmp 0.19001, oracc 0.99606, chxlmicf1 0.57192, chxlmacf1 0.50846, chxlacc 0.74052, chxlrocaucmic 0.79530, chxlrocaucmac 0.75571, qlmicf1 0.38853, qlmacf1 0.27152, ema 0.69774, 25.20 secs\n",
      "Adjusting learning rate of group 0 to 2.4989e-06.\n",
      "---- Epoch 64/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.58199, a_loss 0.84904, cD 1.66978, wmdcmp 0.21781, oracc 0.99560, orien_loss 0.00809, chxlmicf1 0.62758, chxlmacf1 0.58594, chx_loss 0.61033, chxlacc 0.80414, chxlrocaucmic 0.88840, chxlrocaucmac 0.88555, qlmicf1 0.46953, qlmacf1 0.32535, ql_loss 0.58974, gacc 0.98440, gloss 0.04226, cxr14micf1 0.47663, cxr14macf1 0.48209, cxr14_loss 0.68237, vnbgmicf1 0.82194, vnbgmacf1 0.79678, vnbg_loss 0.26359, ema 0.78638, 172.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39639, wmdcmp 0.19150, oracc 0.99650, chxlmicf1 0.56887, chxlmacf1 0.50632, chxlacc 0.73900, chxlrocaucmic 0.79384, chxlrocaucmac 0.75555, qlmicf1 0.38632, qlmacf1 0.26953, ema 0.68778, 26.13 secs\n",
      "Adjusting learning rate of group 0 to 2.3678e-06.\n",
      "---- Epoch 65/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.68938, a_loss 0.84529, cD 1.66371, wmdcmp 0.21794, oracc 0.99537, orien_loss 0.00706, chxlmicf1 0.62831, chxlmacf1 0.58636, chx_loss 0.60940, chxlacc 0.80489, chxlrocaucmic 0.88851, chxlrocaucmac 0.88599, qlmicf1 0.47088, qlmacf1 0.31901, ql_loss 0.58835, gacc 0.98470, gloss 0.04252, cxr14micf1 0.46935, cxr14macf1 0.47271, cxr14_loss 0.69071, vnbgmicf1 0.82335, vnbgmacf1 0.80557, vnbg_loss 0.25405, ema 0.78844, 168.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39849, wmdcmp 0.19202, oracc 0.99591, chxlmicf1 0.57097, chxlmacf1 0.50442, chxlacc 0.74284, chxlrocaucmic 0.79412, chxlrocaucmac 0.75405, qlmicf1 0.38635, qlmacf1 0.26905, ema 0.69502, 26.14 secs\n",
      "Adjusting learning rate of group 0 to 2.2436e-06.\n",
      "---- Epoch 66/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.70434, a_loss 0.84827, cD 1.65301, wmdcmp 0.21628, oracc 0.99557, orien_loss 0.00686, chxlmicf1 0.62995, chxlmacf1 0.58862, chx_loss 0.60596, chxlacc 0.80549, chxlrocaucmic 0.88945, chxlrocaucmac 0.88659, qlmicf1 0.47031, qlmacf1 0.32202, ql_loss 0.58798, gacc 0.98494, gloss 0.04398, cxr14micf1 0.47790, cxr14macf1 0.48166, cxr14_loss 0.67862, vnbgmicf1 0.83038, vnbgmacf1 0.80765, vnbg_loss 0.25705, ema 0.78716, 168.38 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.40348, wmdcmp 0.19189, oracc 0.99650, chxlmicf1 0.57099, chxlmacf1 0.50543, chxlacc 0.74046, chxlrocaucmic 0.79459, chxlrocaucmac 0.75414, qlmicf1 0.38576, qlmacf1 0.27186, ema 0.68778, 26.21 secs\n",
      "Adjusting learning rate of group 0 to 2.1260e-06.\n",
      "---- Epoch 67/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.61545, a_loss 0.84889, cD 1.64859, wmdcmp 0.21546, oracc 0.99519, orien_loss 0.00783, chxlmicf1 0.62858, chxlmacf1 0.58753, chx_loss 0.60777, chxlacc 0.80478, chxlrocaucmic 0.88905, chxlrocaucmac 0.88645, qlmicf1 0.47050, qlmacf1 0.32317, ql_loss 0.58608, gacc 0.98565, gloss 0.04075, cxr14micf1 0.47680, cxr14macf1 0.48453, cxr14_loss 0.67892, vnbgmicf1 0.82764, vnbgmacf1 0.79973, vnbg_loss 0.25800, ema 0.78450, 170.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39258, wmdcmp 0.19106, oracc 0.99635, chxlmicf1 0.56931, chxlmacf1 0.50354, chxlacc 0.73986, chxlrocaucmic 0.79336, chxlrocaucmac 0.75448, qlmicf1 0.38874, qlmacf1 0.27044, ema 0.70588, 25.38 secs\n",
      "Adjusting learning rate of group 0 to 2.0145e-06.\n",
      "---- Epoch 68/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.70753, a_loss 0.84810, cD 1.64986, wmdcmp 0.21634, oracc 0.99536, orien_loss 0.00683, chxlmicf1 0.62891, chxlmacf1 0.58859, chx_loss 0.60404, chxlacc 0.80579, chxlrocaucmic 0.89008, chxlrocaucmac 0.88749, qlmicf1 0.47070, qlmacf1 0.31927, ql_loss 0.58860, gacc 0.98488, gloss 0.04669, cxr14micf1 0.47349, cxr14macf1 0.47876, cxr14_loss 0.68890, vnbgmicf1 0.82746, vnbgmacf1 0.80554, vnbg_loss 0.25420, ema 0.79045, 169.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40113, wmdcmp 0.19196, oracc 0.99606, chxlmicf1 0.56744, chxlmacf1 0.50265, chxlacc 0.74202, chxlrocaucmic 0.79265, chxlrocaucmac 0.75238, qlmicf1 0.38266, qlmacf1 0.26910, ema 0.69502, 25.94 secs\n",
      "Adjusting learning rate of group 0 to 1.9088e-06.\n",
      "---- Epoch 69/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.67868, a_loss 0.84717, cD 1.66501, wmdcmp 0.21769, oracc 0.99542, orien_loss 0.00731, chxlmicf1 0.63072, chxlmacf1 0.59050, chx_loss 0.60497, chxlacc 0.80651, chxlrocaucmic 0.88965, chxlrocaucmac 0.88660, qlmicf1 0.47115, qlmacf1 0.32195, ql_loss 0.58700, gacc 0.98518, gloss 0.04271, cxr14micf1 0.47222, cxr14macf1 0.47704, cxr14_loss 0.68696, vnbgmicf1 0.83216, vnbgmacf1 0.80938, vnbg_loss 0.24753, ema 0.78981, 168.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40266, wmdcmp 0.19175, oracc 0.99635, chxlmicf1 0.57131, chxlmacf1 0.50733, chxlacc 0.74228, chxlrocaucmic 0.79527, chxlrocaucmac 0.75684, qlmicf1 0.39039, qlmacf1 0.27124, ema 0.70045, 26.42 secs\n",
      "Adjusting learning rate of group 0 to 1.8087e-06.\n",
      "---- Epoch 70/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.59422, a_loss 0.84687, cD 1.66031, wmdcmp 0.21709, oracc 0.99560, orien_loss 0.00674, chxlmicf1 0.63155, chxlmacf1 0.59109, chx_loss 0.60295, chxlacc 0.80696, chxlrocaucmic 0.89068, chxlrocaucmac 0.88814, qlmicf1 0.47341, qlmacf1 0.32197, ql_loss 0.58434, gacc 0.98292, gloss 0.04621, cxr14micf1 0.47718, cxr14macf1 0.48242, cxr14_loss 0.68244, vnbgmicf1 0.82855, vnbgmacf1 0.80387, vnbg_loss 0.25644, ema 0.78858, 169.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40952, wmdcmp 0.19221, oracc 0.99620, chxlmicf1 0.57188, chxlmacf1 0.50956, chxlacc 0.74116, chxlrocaucmic 0.79460, chxlrocaucmac 0.75669, qlmicf1 0.38663, qlmacf1 0.27119, ema 0.70407, 25.78 secs\n",
      "Adjusting learning rate of group 0 to 1.7138e-06.\n",
      "---- Epoch 71/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.90803, a_loss 0.84600, cD 1.66540, wmdcmp 0.21811, oracc 0.99570, orien_loss 0.00612, chxlmicf1 0.63363, chxlmacf1 0.59322, chx_loss 0.59954, chxlacc 0.80778, chxlrocaucmic 0.89121, chxlrocaucmac 0.88854, qlmicf1 0.47331, qlmacf1 0.32857, ql_loss 0.58337, gacc 0.98464, gloss 0.04270, cxr14micf1 0.47330, cxr14macf1 0.48030, cxr14_loss 0.68334, vnbgmicf1 0.83112, vnbgmacf1 0.80639, vnbg_loss 0.25259, ema 0.79004, 173.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39886, wmdcmp 0.19185, oracc 0.99650, chxlmicf1 0.56839, chxlmacf1 0.50295, chxlacc 0.73922, chxlrocaucmic 0.79394, chxlrocaucmac 0.75448, qlmicf1 0.38617, qlmacf1 0.27139, ema 0.69050, 24.37 secs\n",
      "Adjusting learning rate of group 0 to 1.6239e-06.\n",
      "---- Epoch 72/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.59779, a_loss 0.84807, cD 1.64806, wmdcmp 0.21610, oracc 0.99552, orien_loss 0.00791, chxlmicf1 0.63283, chxlmacf1 0.59179, chx_loss 0.59947, chxlacc 0.80771, chxlrocaucmic 0.89183, chxlrocaucmac 0.88900, qlmicf1 0.47202, qlmacf1 0.32244, ql_loss 0.58128, gacc 0.98554, gloss 0.04340, cxr14micf1 0.47551, cxr14macf1 0.47895, cxr14_loss 0.68134, vnbgmicf1 0.83264, vnbgmacf1 0.81018, vnbg_loss 0.24988, ema 0.78793, 169.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38944, wmdcmp 0.19068, oracc 0.99635, chxlmicf1 0.57116, chxlmacf1 0.50608, chxlacc 0.74200, chxlrocaucmic 0.79512, chxlrocaucmac 0.75499, qlmicf1 0.39009, qlmacf1 0.27141, ema 0.69412, 25.67 secs\n",
      "Adjusting learning rate of group 0 to 1.5388e-06.\n",
      "---- Epoch 73/80\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.67998, a_loss 0.84541, cD 1.68524, wmdcmp 0.21923, oracc 0.99527, orien_loss 0.00772, chxlmicf1 0.63167, chxlmacf1 0.59163, chx_loss 0.60183, chxlacc 0.80747, chxlrocaucmic 0.89082, chxlrocaucmac 0.88837, qlmicf1 0.47366, qlmacf1 0.32750, ql_loss 0.58167, gacc 0.98476, gloss 0.04165, cxr14micf1 0.48020, cxr14macf1 0.48566, cxr14_loss 0.67586, vnbgmicf1 0.83085, vnbgmacf1 0.81077, vnbg_loss 0.25128, ema 0.79119, 171.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40431, wmdcmp 0.19196, oracc 0.99635, chxlmicf1 0.57053, chxlmacf1 0.50624, chxlacc 0.74283, chxlrocaucmic 0.79369, chxlrocaucmac 0.75438, qlmicf1 0.38839, qlmacf1 0.27159, ema 0.68778, 27.96 secs\n",
      "Adjusting learning rate of group 0 to 1.4581e-06.\n",
      "---- Epoch 74/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.52946, a_loss 0.84470, cD 1.65431, wmdcmp 0.21755, oracc 0.99537, orien_loss 0.00770, chxlmicf1 0.63446, chxlmacf1 0.59485, chx_loss 0.59825, chxlacc 0.80843, chxlrocaucmic 0.89158, chxlrocaucmac 0.88880, qlmicf1 0.47478, qlmacf1 0.32400, ql_loss 0.58200, gacc 0.98381, gloss 0.04422, cxr14micf1 0.47639, cxr14macf1 0.48033, cxr14_loss 0.67662, vnbgmicf1 0.83172, vnbgmacf1 0.80531, vnbg_loss 0.25135, ema 0.78933, 172.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39421, wmdcmp 0.19064, oracc 0.99606, chxlmicf1 0.56927, chxlmacf1 0.50360, chxlacc 0.74127, chxlrocaucmic 0.79460, chxlrocaucmac 0.75462, qlmicf1 0.39032, qlmacf1 0.27175, ema 0.70136, 26.34 secs\n",
      "Adjusting learning rate of group 0 to 1.3816e-06.\n",
      "---- Epoch 75/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.65335, a_loss 0.84686, cD 1.65235, wmdcmp 0.21640, oracc 0.99575, orien_loss 0.00685, chxlmicf1 0.63532, chxlmacf1 0.59523, chx_loss 0.59663, chxlacc 0.80900, chxlrocaucmic 0.89235, chxlrocaucmac 0.88944, qlmicf1 0.47425, qlmacf1 0.32663, ql_loss 0.58012, gacc 0.98732, gloss 0.03783, cxr14micf1 0.47834, cxr14macf1 0.48307, cxr14_loss 0.68047, vnbgmicf1 0.82850, vnbgmacf1 0.81270, vnbg_loss 0.25509, ema 0.78926, 170.42 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39591, wmdcmp 0.19102, oracc 0.99635, chxlmicf1 0.57027, chxlmacf1 0.50405, chxlacc 0.74425, chxlrocaucmic 0.79379, chxlrocaucmac 0.75368, qlmicf1 0.39241, qlmacf1 0.27380, ema 0.69955, 25.68 secs\n",
      "Adjusting learning rate of group 0 to 1.3091e-06.\n",
      "---- Epoch 76/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.58680, a_loss 0.84243, cD 1.68081, wmdcmp 0.21924, oracc 0.99580, orien_loss 0.00623, chxlmicf1 0.63352, chxlmacf1 0.59295, chx_loss 0.59811, chxlacc 0.80799, chxlrocaucmic 0.89197, chxlrocaucmac 0.88926, qlmicf1 0.47306, qlmacf1 0.32565, ql_loss 0.58313, gacc 0.98649, gloss 0.04000, cxr14micf1 0.48207, cxr14macf1 0.48711, cxr14_loss 0.66747, vnbgmicf1 0.83435, vnbgmacf1 0.81574, vnbg_loss 0.24816, ema 0.78929, 170.17 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37421, wmdcmp 0.18904, oracc 0.99606, chxlmicf1 0.57113, chxlmacf1 0.50699, chxlacc 0.74369, chxlrocaucmic 0.79560, chxlrocaucmac 0.75752, qlmicf1 0.38884, qlmacf1 0.27269, ema 0.71041, 25.61 secs\n",
      "Adjusting learning rate of group 0 to 1.2405e-06.\n",
      "---- Epoch 77/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.44672, a_loss 0.84566, cD 1.68317, wmdcmp 0.21959, oracc 0.99549, orien_loss 0.00746, chxlmicf1 0.63272, chxlmacf1 0.59263, chx_loss 0.59982, chxlacc 0.80781, chxlrocaucmic 0.89117, chxlrocaucmac 0.88866, qlmicf1 0.47304, qlmacf1 0.32357, ql_loss 0.58172, gacc 0.98399, gloss 0.04348, cxr14micf1 0.47968, cxr14macf1 0.48394, cxr14_loss 0.67643, vnbgmicf1 0.83000, vnbgmacf1 0.80461, vnbg_loss 0.25288, ema 0.78812, 171.01 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.39964, wmdcmp 0.19102, oracc 0.99620, chxlmicf1 0.57076, chxlmacf1 0.50702, chxlacc 0.74151, chxlrocaucmic 0.79505, chxlrocaucmac 0.75680, qlmicf1 0.38550, qlmacf1 0.27129, ema 0.69050, 25.84 secs\n",
      "Adjusting learning rate of group 0 to 1.1754e-06.\n",
      "---- Epoch 78/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.66446, a_loss 0.84537, cD 1.66838, wmdcmp 0.21820, oracc 0.99570, orien_loss 0.00655, chxlmicf1 0.63496, chxlmacf1 0.59468, chx_loss 0.59617, chxlacc 0.80924, chxlrocaucmic 0.89288, chxlrocaucmac 0.89024, qlmicf1 0.47614, qlmacf1 0.32869, ql_loss 0.57607, gacc 0.98548, gloss 0.04305, cxr14micf1 0.47832, cxr14macf1 0.48527, cxr14_loss 0.67672, vnbgmicf1 0.83436, vnbgmacf1 0.81681, vnbg_loss 0.24759, ema 0.78993, 168.17 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40025, wmdcmp 0.19145, oracc 0.99635, chxlmicf1 0.56969, chxlmacf1 0.50389, chxlacc 0.74202, chxlrocaucmic 0.79465, chxlrocaucmac 0.75440, qlmicf1 0.38681, qlmacf1 0.27195, ema 0.69593, 27.04 secs\n",
      "Adjusting learning rate of group 0 to 1.1138e-06.\n",
      "---- Epoch 79/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.75274, a_loss 0.84701, cD 1.67405, wmdcmp 0.21842, oracc 0.99552, orien_loss 0.00726, chxlmicf1 0.63405, chxlmacf1 0.59329, chx_loss 0.59863, chxlacc 0.80831, chxlrocaucmic 0.89176, chxlrocaucmac 0.88911, qlmicf1 0.47343, qlmacf1 0.32482, ql_loss 0.57910, gacc 0.98512, gloss 0.04105, cxr14micf1 0.47421, cxr14macf1 0.48076, cxr14_loss 0.67795, vnbgmicf1 0.83322, vnbgmacf1 0.81251, vnbg_loss 0.25512, ema 0.78803, 168.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40764, wmdcmp 0.19208, oracc 0.99533, chxlmicf1 0.56951, chxlmacf1 0.50523, chxlacc 0.74141, chxlrocaucmic 0.79542, chxlrocaucmac 0.75520, qlmicf1 0.39106, qlmacf1 0.27313, ema 0.69321, 26.40 secs\n",
      "Adjusting learning rate of group 0 to 1.0554e-06.\n",
      "---- Epoch 80/80\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.45312, a_loss 0.84771, cD 1.67360, wmdcmp 0.21822, oracc 0.99547, orien_loss 0.00652, chxlmicf1 0.63477, chxlmacf1 0.59502, chx_loss 0.59598, chxlacc 0.80926, chxlrocaucmic 0.89302, chxlrocaucmac 0.89007, qlmicf1 0.47480, qlmacf1 0.32675, ql_loss 0.58053, gacc 0.98530, gloss 0.04314, cxr14micf1 0.48384, cxr14macf1 0.48966, cxr14_loss 0.67086, vnbgmicf1 0.83232, vnbgmacf1 0.80991, vnbg_loss 0.25095, ema 0.78970, 171.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40472, wmdcmp 0.19229, oracc 0.99591, chxlmicf1 0.56788, chxlmacf1 0.50214, chxlacc 0.74124, chxlrocaucmic 0.79344, chxlrocaucmac 0.75272, qlmicf1 0.38763, qlmacf1 0.27095, ema 0.69593, 25.33 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\" \\\n",
    "        --epochs 80 \\\n",
    "        --batches-per-epoch 420 \\\n",
    "        --batch-size 160 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --num-workers 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,6e-5,76,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220629_050643.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220629_042239.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220629_055159.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220629_055107.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220629_052842.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220629_052841.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220629_123956.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220629_123626.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220629_052724.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --raw-image-encoding \"clip-vit-huggingface\" \\\n",
    "        --clip-version \"CenIA/clip-vit-bio-clinical-bert-finetuned\" \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 400\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220629_042239.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220629_050643.json\n",
      "   vocab_min_freq: 5\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: clip-vit-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: CenIA/clip-vit-bio-clinical-bert-finetuned\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,4e-4,96,5e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   n_val_examples_per_question: 10\n",
      "   min_train_examples_per_question: 100\n",
      "   batch_size: 200\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 5\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220629_052724.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\n",
      "   balanced_split: True\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   n_healthy_per_question: 2\n",
      "   n_unhealthy_per_question: 3\n",
      "   n_positive_per_chexpert_label: 7\n",
      "   min_question_count: 100\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220629_123626.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220629_123956.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   iuxray_train_with_all: True\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220629_055107.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220629_055159.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220629_052841.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220629_052842.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,4e-4,96,5e-6\n",
      "1e-06 4 0.0004 96 5e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=292,3941135520930231601).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 200\n",
      "len(self.report_ids) = 1940625, len(set(self.report_ids)) = 215125\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|███████████████████████████████████████████| 97/97 [00:11<00:00,  8.74it/s]\n",
      " *** merging from i=0 to j=5, acc_size = 305\n",
      " *** merging from i=6 to j=7, acc_size = 383\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=292,3941135520930231601).pkl.balanced_train_data(bs=200,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 91\n",
      "len(self.val_indices) = 5762\n",
      "len(val_indices) = 5762\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 5\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=41533, len(neg_indices)=173070\n",
      "label = 1, onehot=98, len(pos_indices)=41436, len(neg_indices)=173167\n",
      "label = 2, onehot=99, len(pos_indices)=68536, len(neg_indices)=146067\n",
      "label = 3, onehot=100, len(pos_indices)=8926, len(neg_indices)=205677\n",
      "label = 4, onehot=101, len(pos_indices)=71192, len(neg_indices)=143411\n",
      "label = 5, onehot=102, len(pos_indices)=41924, len(neg_indices)=172679\n",
      "label = 6, onehot=103, len(pos_indices)=19023, len(neg_indices)=195580\n",
      "label = 7, onehot=104, len(pos_indices)=35834, len(neg_indices)=178769\n",
      "label = 8, onehot=105, len(pos_indices)=67927, len(neg_indices)=146676\n",
      "label = 9, onehot=106, len(pos_indices)=12839, len(neg_indices)=201764\n",
      "label = 10, onehot=107, len(pos_indices)=66725, len(neg_indices)=147878\n",
      "label = 11, onehot=108, len(pos_indices)=4638, len(neg_indices)=209965\n",
      "label = 12, onehot=109, len(pos_indices)=7757, len(neg_indices)=206846\n",
      "label = 13, onehot=110, len(pos_indices)=85553, len(neg_indices)=129050\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=25, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1105\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=307,157613170942256249).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 200\n",
      "len(self.report_ids) = 28800, len(set(self.report_ids)) = 3784\n",
      "Computing balanced datasets from scratch ...\n",
      "self.imbalance_reduction_coef = 0.5\n",
      "100%|██████████████████████████████████████████| 91/91 [00:00<00:00, 633.98it/s]\n",
      " *** merging from i=0 to j=33, acc_size = 209\n",
      " *** merging from i=34 to j=40, acc_size = 213\n",
      " *** merging from i=41 to j=45, acc_size = 253\n",
      " *** merging from i=46 to j=49, acc_size = 263\n",
      " *** merging from i=50 to j=52, acc_size = 263\n",
      " *** merging from i=53 to j=54, acc_size = 204\n",
      " *** merging from i=55 to j=56, acc_size = 228\n",
      " *** merging from i=57 to j=58, acc_size = 288\n",
      " *** merging from i=59 to j=60, acc_size = 324\n",
      " *** merging from i=61 to j=62, acc_size = 368\n",
      " *** merging from i=63 to j=64, acc_size = 404\n",
      "Balanced train data saved to /home/pamessina/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(hash=307,157613170942256249).pkl.balanced_train_data(bs=200,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 37\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 5\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2370\n",
      "label = 1, onehot=98, len(pos_indices)=382, len(neg_indices)=3402\n",
      "label = 2, onehot=99, len(pos_indices)=667, len(neg_indices)=3117\n",
      "label = 3, onehot=100, len(pos_indices)=230, len(neg_indices)=3554\n",
      "label = 4, onehot=101, len(pos_indices)=701, len(neg_indices)=3083\n",
      "label = 5, onehot=102, len(pos_indices)=150, len(neg_indices)=3634\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=3744\n",
      "label = 7, onehot=104, len(pos_indices)=134, len(neg_indices)=3650\n",
      "label = 8, onehot=105, len(pos_indices)=360, len(neg_indices)=3424\n",
      "label = 9, onehot=106, len(pos_indices)=99, len(neg_indices)=3685\n",
      "label = 10, onehot=107, len(pos_indices)=288, len(neg_indices)=3496\n",
      "label = 11, onehot=108, len(pos_indices)=70, len(neg_indices)=3714\n",
      "label = 12, onehot=109, len(pos_indices)=113, len(neg_indices)=3671\n",
      "label = 13, onehot=110, len(pos_indices)=213, len(neg_indices)=3571\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 4\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "checkpoint_folder_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\n",
      "metadata saved to /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/metadata.json\n",
      "checkpoint_names = ['checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt\n",
      "Skip loading parameter: question_encoder.weight, required shape: torch.Size([111, 128]), loaded shape: torch.Size([154, 128])\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "---- Epoch 1/100\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.36719, a_loss 2.59489, cD 0.76051, wmdcmp 0.10764, oracc 0.99553, orien_loss 0.00291, chxlmicf1 0.65983, chxlmacf1 0.62717, chx_loss 0.54041, chxlacc 0.82950, chxlrocaucmic 0.90915, chxlrocaucmac 0.90679, qlmicf1 0.47347, qlmacf1 0.32174, ql_loss 0.58629, ema 0.00668, 149.45 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.14505, wmdcmp 0.02576, oracc 0.99606, chxlmicf1 0.57198, chxlmacf1 0.50700, chxlacc 0.74365, chxlrocaucmic 0.79510, chxlrocaucmac 0.75555, qlmicf1 0.38310, qlmacf1 0.26924, ema 0.00090, 20.21 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-06.\n",
      "---- Epoch 2/100\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.46706, a_loss 2.11422, cD 0.78172, wmdcmp 0.11556, oracc 0.99548, orien_loss 0.00355, chxlmicf1 0.66111, chxlmacf1 0.62865, chx_loss 0.53913, chxlacc 0.82957, chxlrocaucmic 0.90951, chxlrocaucmac 0.90693, qlmicf1 0.47318, qlmacf1 0.32315, ql_loss 0.58479, ema 0.07451, 138.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.12970, wmdcmp 0.02592, oracc 0.99606, chxlmicf1 0.57165, chxlmacf1 0.50544, chxlacc 0.74374, chxlrocaucmic 0.79559, chxlrocaucmac 0.75601, qlmicf1 0.38821, qlmacf1 0.27229, ema 0.15385, 20.17 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "---- Epoch 3/100\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 2.67859, a_loss 1.69994, cD 0.86828, wmdcmp 0.12950, oracc 0.99583, orien_loss 0.00290, chxlmicf1 0.66196, chxlmacf1 0.62951, chx_loss 0.53726, chxlacc 0.83047, chxlrocaucmic 0.91035, chxlrocaucmac 0.90786, qlmicf1 0.47309, qlmacf1 0.32151, ql_loss 0.58406, ema 0.43897, 141.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.19771, wmdcmp 0.03432, oracc 0.99606, chxlmicf1 0.57173, chxlmacf1 0.50718, chxlacc 0.74423, chxlrocaucmic 0.79545, chxlrocaucmac 0.75524, qlmicf1 0.38551, qlmacf1 0.27103, ema 0.59819, 19.81 secs\n",
      "Adjusting learning rate of group 0 to 8.9443e-05.\n",
      "---- Epoch 4/100\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 4.13837, a_loss 1.47513, cD 1.12637, wmdcmp 0.15552, oracc 0.99579, orien_loss 0.00284, chxlmicf1 0.66139, chxlmacf1 0.62877, chx_loss 0.53799, chxlacc 0.83015, chxlrocaucmic 0.91000, chxlrocaucmac 0.90717, qlmicf1 0.47349, qlmacf1 0.32622, ql_loss 0.58327, ema 0.70503, 142.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.93900, wmdcmp 0.13275, oracc 0.99562, chxlmicf1 0.57077, chxlmacf1 0.50571, chxlacc 0.74346, chxlrocaucmic 0.79598, chxlrocaucmac 0.75555, qlmicf1 0.38933, qlmacf1 0.27354, ema 0.67873, 20.43 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-04.\n",
      "---- Epoch 5/100\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 1.44565, a_loss 1.36973, cD 1.37568, wmdcmp 0.18398, oracc 0.99553, orien_loss 0.00332, chxlmicf1 0.66134, chxlmacf1 0.62919, chx_loss 0.53742, chxlacc 0.83017, chxlrocaucmic 0.90983, chxlrocaucmac 0.90685, qlmicf1 0.47234, qlmacf1 0.32184, ql_loss 0.58143, ema 0.75897, 142.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25766, wmdcmp 0.17363, oracc 0.99547, chxlmicf1 0.57128, chxlmacf1 0.50453, chxlacc 0.74321, chxlrocaucmic 0.79439, chxlrocaucmac 0.75264, qlmicf1 0.38785, qlmacf1 0.27119, ema 0.67602, 20.67 secs\n",
      "Adjusting learning rate of group 0 to 3.8215e-04.\n",
      "---- Epoch 6/100\n",
      "(1) Training stage (lr = 0.000382) ...\n",
      "loss 1.42265, a_loss 1.31059, cD 1.51049, wmdcmp 0.20080, oracc 0.99513, orien_loss 0.00279, chxlmicf1 0.66076, chxlmacf1 0.62910, chx_loss 0.53487, chxlacc 0.82970, chxlrocaucmic 0.91002, chxlrocaucmac 0.90683, qlmicf1 0.47180, qlmacf1 0.31941, ql_loss 0.57956, ema 0.77976, 144.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30754, wmdcmp 0.18011, oracc 0.99606, chxlmicf1 0.57086, chxlmacf1 0.50349, chxlacc 0.74268, chxlrocaucmic 0.79378, chxlrocaucmac 0.75113, qlmicf1 0.38849, qlmacf1 0.27114, ema 0.67873, 20.78 secs\n",
      "Adjusting learning rate of group 0 to 3.6510e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 7/100\n",
      "(1) Training stage (lr = 0.000365) ...\n",
      "loss 3.68959, a_loss 1.28960, cD 1.54644, wmdcmp 0.20445, oracc 0.99557, orien_loss 0.00284, chxlmicf1 0.66195, chxlmacf1 0.63054, chx_loss 0.53323, chxlacc 0.83105, chxlrocaucmic 0.91077, chxlrocaucmac 0.90738, qlmicf1 0.47313, qlmacf1 0.31873, ql_loss 0.57547, ema 0.78914, 144.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34458, wmdcmp 0.18441, oracc 0.99606, chxlmicf1 0.56883, chxlmacf1 0.50221, chxlacc 0.74114, chxlrocaucmic 0.79351, chxlrocaucmac 0.75295, qlmicf1 0.39124, qlmacf1 0.27135, ema 0.67783, 20.47 secs\n",
      "Adjusting learning rate of group 0 to 3.4881e-04.\n",
      "---- Epoch 8/100\n",
      "(1) Training stage (lr = 0.000349) ...\n",
      "loss 1.39469, a_loss 1.27251, cD 1.58516, wmdcmp 0.20883, oracc 0.99525, orien_loss 0.00274, chxlmicf1 0.66146, chxlmacf1 0.63031, chx_loss 0.53190, chxlacc 0.83079, chxlrocaucmic 0.91079, chxlrocaucmac 0.90751, qlmicf1 0.47522, qlmacf1 0.32222, ql_loss 0.57127, ema 0.79330, 143.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36108, wmdcmp 0.18665, oracc 0.99577, chxlmicf1 0.56811, chxlmacf1 0.49965, chxlacc 0.74447, chxlrocaucmic 0.79402, chxlrocaucmac 0.75195, qlmicf1 0.39200, qlmacf1 0.27102, ema 0.70226, 20.51 secs\n",
      "Adjusting learning rate of group 0 to 3.3325e-04.\n",
      "---- Epoch 9/100\n",
      "(1) Training stage (lr = 0.000333) ...\n",
      "loss 3.61494, a_loss 1.26349, cD 1.59511, wmdcmp 0.21075, oracc 0.99552, orien_loss 0.00288, chxlmicf1 0.66280, chxlmacf1 0.63128, chx_loss 0.53106, chxlacc 0.83102, chxlrocaucmic 0.91087, chxlrocaucmac 0.90749, qlmicf1 0.47547, qlmacf1 0.31929, ql_loss 0.56873, ema 0.79611, 143.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30353, wmdcmp 0.17945, oracc 0.99562, chxlmicf1 0.56948, chxlmacf1 0.50113, chxlacc 0.74354, chxlrocaucmic 0.79240, chxlrocaucmac 0.74950, qlmicf1 0.39385, qlmacf1 0.27365, ema 0.69502, 20.68 secs\n",
      "Adjusting learning rate of group 0 to 3.1838e-04.\n",
      "---- Epoch 10/100\n",
      "(1) Training stage (lr = 0.000318) ...\n",
      "loss 0.28769, a_loss 1.25784, cD 1.62704, wmdcmp 0.21418, oracc 0.99539, orien_loss 0.00251, chxlmicf1 0.66335, chxlmacf1 0.63214, chx_loss 0.52917, chxlacc 0.83177, chxlrocaucmic 0.91144, chxlrocaucmac 0.90804, qlmicf1 0.47603, qlmacf1 0.32196, ql_loss 0.56856, ema 0.79563, 143.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24078, wmdcmp 0.17438, oracc 0.99591, chxlmicf1 0.56447, chxlmacf1 0.49833, chxlacc 0.74206, chxlrocaucmic 0.79222, chxlrocaucmac 0.75109, qlmicf1 0.39341, qlmacf1 0.27427, ema 0.69231, 20.77 secs\n",
      "Adjusting learning rate of group 0 to 3.0417e-04.\n",
      "---- Epoch 11/100\n",
      "(1) Training stage (lr = 0.000304) ...\n",
      "loss 1.34135, a_loss 1.23625, cD 1.66287, wmdcmp 0.21785, oracc 0.99544, orien_loss 0.00295, chxlmicf1 0.66313, chxlmacf1 0.63272, chx_loss 0.53087, chxlacc 0.83103, chxlrocaucmic 0.91101, chxlrocaucmac 0.90759, qlmicf1 0.47645, qlmacf1 0.32120, ql_loss 0.56698, ema 0.80185, 143.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36681, wmdcmp 0.18844, oracc 0.99606, chxlmicf1 0.56841, chxlmacf1 0.50088, chxlacc 0.74356, chxlrocaucmic 0.79308, chxlrocaucmac 0.75067, qlmicf1 0.39254, qlmacf1 0.27415, ema 0.68959, 20.36 secs\n",
      "Adjusting learning rate of group 0 to 2.9060e-04.\n",
      "---- Epoch 12/100\n",
      "(1) Training stage (lr = 0.000291) ...\n",
      "loss 3.55427, a_loss 1.23930, cD 1.68519, wmdcmp 0.22053, oracc 0.99554, orien_loss 0.00271, chxlmicf1 0.66148, chxlmacf1 0.62972, chx_loss 0.53351, chxlacc 0.83074, chxlrocaucmic 0.91051, chxlrocaucmac 0.90705, qlmicf1 0.47562, qlmacf1 0.32093, ql_loss 0.56726, ema 0.79937, 143.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31916, wmdcmp 0.18260, oracc 0.99562, chxlmicf1 0.56721, chxlmacf1 0.50171, chxlacc 0.74287, chxlrocaucmic 0.79200, chxlrocaucmac 0.75138, qlmicf1 0.38927, qlmacf1 0.27185, ema 0.68054, 20.67 secs\n",
      "Adjusting learning rate of group 0 to 2.7763e-04.\n",
      "---- Epoch 13/100\n",
      "(1) Training stage (lr = 0.000278) ...\n",
      "loss 1.36161, a_loss 1.22841, cD 1.68762, wmdcmp 0.22132, oracc 0.99603, orien_loss 0.00268, chxlmicf1 0.66238, chxlmacf1 0.63055, chx_loss 0.53094, chxlacc 0.83156, chxlrocaucmic 0.91120, chxlrocaucmac 0.90798, qlmicf1 0.47676, qlmacf1 0.32484, ql_loss 0.56588, ema 0.80281, 143.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36053, wmdcmp 0.18582, oracc 0.99547, chxlmicf1 0.56661, chxlmacf1 0.50025, chxlacc 0.74273, chxlrocaucmic 0.79254, chxlrocaucmac 0.75062, qlmicf1 0.38850, qlmacf1 0.27245, ema 0.68054, 20.73 secs\n",
      "Adjusting learning rate of group 0 to 2.6524e-04.\n",
      "---- Epoch 14/100\n",
      "(1) Training stage (lr = 0.000265) ...\n",
      "loss 3.74116, a_loss 1.22350, cD 1.69770, wmdcmp 0.22243, oracc 0.99532, orien_loss 0.00321, chxlmicf1 0.66267, chxlmacf1 0.63169, chx_loss 0.53061, chxlacc 0.83100, chxlrocaucmic 0.91073, chxlrocaucmac 0.90753, qlmicf1 0.47577, qlmacf1 0.32328, ql_loss 0.56515, ema 0.80538, 144.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38189, wmdcmp 0.18871, oracc 0.99577, chxlmicf1 0.56895, chxlmacf1 0.50377, chxlacc 0.74311, chxlrocaucmic 0.79199, chxlrocaucmac 0.75164, qlmicf1 0.39067, qlmacf1 0.27115, ema 0.67964, 22.13 secs\n",
      "Adjusting learning rate of group 0 to 2.5341e-04.\n",
      "---- Epoch 15/100\n",
      "(1) Training stage (lr = 0.000253) ...\n",
      "loss 3.53054, a_loss 1.21975, cD 1.70829, wmdcmp 0.22415, oracc 0.99523, orien_loss 0.00297, chxlmicf1 0.66335, chxlmacf1 0.63173, chx_loss 0.53083, chxlacc 0.83177, chxlrocaucmic 0.91122, chxlrocaucmac 0.90796, qlmicf1 0.47701, qlmacf1 0.32318, ql_loss 0.56462, ema 0.80349, 145.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37058, wmdcmp 0.18782, oracc 0.99577, chxlmicf1 0.56588, chxlmacf1 0.49953, chxlacc 0.74166, chxlrocaucmic 0.79149, chxlrocaucmac 0.74940, qlmicf1 0.38762, qlmacf1 0.27226, ema 0.68145, 20.61 secs\n",
      "Adjusting learning rate of group 0 to 2.4210e-04.\n",
      "---- Epoch 16/100\n",
      "(1) Training stage (lr = 0.000242) ...\n",
      "loss 1.72894, a_loss 1.21061, cD 1.71226, wmdcmp 0.22447, oracc 0.99543, orien_loss 0.00254, chxlmicf1 0.66501, chxlmacf1 0.63314, chx_loss 0.52952, chxlacc 0.83243, chxlrocaucmic 0.91177, chxlrocaucmac 0.90840, qlmicf1 0.47780, qlmacf1 0.32381, ql_loss 0.56078, ema 0.80254, 145.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34972, wmdcmp 0.18606, oracc 0.99591, chxlmicf1 0.56512, chxlmacf1 0.49774, chxlacc 0.73994, chxlrocaucmic 0.79171, chxlrocaucmac 0.75027, qlmicf1 0.38698, qlmacf1 0.27015, ema 0.68597, 20.80 secs\n",
      "Adjusting learning rate of group 0 to 2.3130e-04.\n",
      "---- Epoch 17/100\n",
      "(1) Training stage (lr = 0.000231) ...\n",
      "loss 3.61031, a_loss 1.20769, cD 1.74034, wmdcmp 0.22689, oracc 0.99582, orien_loss 0.00316, chxlmicf1 0.66237, chxlmacf1 0.63102, chx_loss 0.53000, chxlacc 0.83149, chxlrocaucmic 0.91146, chxlrocaucmac 0.90808, qlmicf1 0.47768, qlmacf1 0.32803, ql_loss 0.56070, ema 0.80603, 144.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32077, wmdcmp 0.18205, oracc 0.99577, chxlmicf1 0.56818, chxlmacf1 0.50255, chxlacc 0.74298, chxlrocaucmic 0.79197, chxlrocaucmac 0.75018, qlmicf1 0.39254, qlmacf1 0.27229, ema 0.69231, 20.79 secs\n",
      "Adjusting learning rate of group 0 to 2.2098e-04.\n",
      "---- Epoch 18/100\n",
      "(1) Training stage (lr = 0.000221) ...\n",
      "loss 1.36671, a_loss 1.20302, cD 1.75475, wmdcmp 0.22850, oracc 0.99558, orien_loss 0.00284, chxlmicf1 0.66354, chxlmacf1 0.63178, chx_loss 0.52981, chxlacc 0.83143, chxlrocaucmic 0.91111, chxlrocaucmac 0.90784, qlmicf1 0.47857, qlmacf1 0.32187, ql_loss 0.56086, ema 0.80815, 145.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35309, wmdcmp 0.18668, oracc 0.99591, chxlmicf1 0.56557, chxlmacf1 0.49828, chxlacc 0.74272, chxlrocaucmic 0.79155, chxlrocaucmac 0.75000, qlmicf1 0.39018, qlmacf1 0.27392, ema 0.69502, 20.42 secs\n",
      "Adjusting learning rate of group 0 to 2.1112e-04.\n",
      "---- Epoch 19/100\n",
      "(1) Training stage (lr = 0.000211) ...\n",
      "loss 1.44716, a_loss 1.19208, cD 1.76687, wmdcmp 0.22957, oracc 0.99504, orien_loss 0.00319, chxlmicf1 0.66419, chxlmacf1 0.63268, chx_loss 0.52789, chxlacc 0.83225, chxlrocaucmic 0.91190, chxlrocaucmac 0.90868, qlmicf1 0.47920, qlmacf1 0.32632, ql_loss 0.55924, ema 0.80927, 145.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37424, wmdcmp 0.19010, oracc 0.99591, chxlmicf1 0.56773, chxlmacf1 0.49849, chxlacc 0.74352, chxlrocaucmic 0.79172, chxlrocaucmac 0.74918, qlmicf1 0.39561, qlmacf1 0.27351, ema 0.68688, 20.90 secs\n",
      "Adjusting learning rate of group 0 to 2.0170e-04.\n",
      "---- Epoch 20/100\n",
      "(1) Training stage (lr = 0.000202) ...\n",
      "loss 3.60112, a_loss 1.18997, cD 1.77543, wmdcmp 0.23102, oracc 0.99540, orien_loss 0.00293, chxlmicf1 0.66156, chxlmacf1 0.62958, chx_loss 0.53321, chxlacc 0.83059, chxlrocaucmic 0.91052, chxlrocaucmac 0.90732, qlmicf1 0.47713, qlmacf1 0.32574, ql_loss 0.56037, ema 0.80822, 144.92 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.36531, wmdcmp 0.18794, oracc 0.99562, chxlmicf1 0.56786, chxlmacf1 0.50187, chxlacc 0.74451, chxlrocaucmic 0.79226, chxlrocaucmac 0.75075, qlmicf1 0.38931, qlmacf1 0.27106, ema 0.67330, 20.61 secs\n",
      "Adjusting learning rate of group 0 to 1.9270e-04.\n",
      "---- Epoch 21/100\n",
      "(1) Training stage (lr = 0.000193) ...\n",
      "loss 1.28622, a_loss 1.18179, cD 1.79576, wmdcmp 0.23351, oracc 0.99565, orien_loss 0.00316, chxlmicf1 0.66471, chxlmacf1 0.63363, chx_loss 0.52820, chxlacc 0.83239, chxlrocaucmic 0.91154, chxlrocaucmac 0.90846, qlmicf1 0.48027, qlmacf1 0.32456, ql_loss 0.55730, ema 0.80622, 143.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33964, wmdcmp 0.18283, oracc 0.99547, chxlmicf1 0.56720, chxlmacf1 0.50081, chxlacc 0.74214, chxlrocaucmic 0.79322, chxlrocaucmac 0.75159, qlmicf1 0.39076, qlmacf1 0.27217, ema 0.67149, 20.90 secs\n",
      "Adjusting learning rate of group 0 to 1.8410e-04.\n",
      "---- Epoch 22/100\n",
      "(1) Training stage (lr = 0.000184) ...\n",
      "loss 3.56582, a_loss 1.18622, cD 1.79298, wmdcmp 0.23292, oracc 0.99557, orien_loss 0.00220, chxlmicf1 0.66261, chxlmacf1 0.63131, chx_loss 0.53226, chxlacc 0.83123, chxlrocaucmic 0.91071, chxlrocaucmac 0.90735, qlmicf1 0.47827, qlmacf1 0.32860, ql_loss 0.55792, ema 0.80389, 144.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40281, wmdcmp 0.19171, oracc 0.99591, chxlmicf1 0.56915, chxlmacf1 0.50319, chxlacc 0.74349, chxlrocaucmic 0.79245, chxlrocaucmac 0.75024, qlmicf1 0.38828, qlmacf1 0.27290, ema 0.68145, 20.23 secs\n",
      "Adjusting learning rate of group 0 to 1.7589e-04.\n",
      "---- Epoch 23/100\n",
      "(1) Training stage (lr = 0.000176) ...\n",
      "loss 0.31056, a_loss 1.18067, cD 1.80262, wmdcmp 0.23410, oracc 0.99553, orien_loss 0.00276, chxlmicf1 0.66404, chxlmacf1 0.63306, chx_loss 0.52815, chxlacc 0.83240, chxlrocaucmic 0.91177, chxlrocaucmac 0.90856, qlmicf1 0.47921, qlmacf1 0.32877, ql_loss 0.55637, ema 0.80723, 145.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38791, wmdcmp 0.18909, oracc 0.99562, chxlmicf1 0.56649, chxlmacf1 0.49888, chxlacc 0.74304, chxlrocaucmic 0.79232, chxlrocaucmac 0.74920, qlmicf1 0.39010, qlmacf1 0.27060, ema 0.68326, 20.88 secs\n",
      "Adjusting learning rate of group 0 to 1.6804e-04.\n",
      "---- Epoch 24/100\n",
      "(1) Training stage (lr = 0.000168) ...\n",
      "loss 1.28450, a_loss 1.16758, cD 1.81027, wmdcmp 0.23426, oracc 0.99539, orien_loss 0.00323, chxlmicf1 0.66249, chxlmacf1 0.63159, chx_loss 0.53140, chxlacc 0.83122, chxlrocaucmic 0.91130, chxlrocaucmac 0.90784, qlmicf1 0.47879, qlmacf1 0.33151, ql_loss 0.55850, ema 0.80965, 142.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39386, wmdcmp 0.19030, oracc 0.99562, chxlmicf1 0.56599, chxlmacf1 0.49912, chxlacc 0.74333, chxlrocaucmic 0.79130, chxlrocaucmac 0.74930, qlmicf1 0.39161, qlmacf1 0.27249, ema 0.67873, 20.54 secs\n",
      "Adjusting learning rate of group 0 to 1.6054e-04.\n",
      "---- Epoch 25/100\n",
      "(1) Training stage (lr = 0.000161) ...\n",
      "loss 3.55344, a_loss 1.17327, cD 1.83368, wmdcmp 0.23743, oracc 0.99558, orien_loss 0.00308, chxlmicf1 0.66362, chxlmacf1 0.63243, chx_loss 0.52802, chxlacc 0.83165, chxlrocaucmic 0.91144, chxlrocaucmac 0.90806, qlmicf1 0.47907, qlmacf1 0.32922, ql_loss 0.55747, ema 0.81226, 143.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39509, wmdcmp 0.19020, oracc 0.99620, chxlmicf1 0.56774, chxlmacf1 0.50006, chxlacc 0.74145, chxlrocaucmic 0.79213, chxlrocaucmac 0.74966, qlmicf1 0.39143, qlmacf1 0.27146, ema 0.69050, 20.80 secs\n",
      "Adjusting learning rate of group 0 to 1.5338e-04.\n",
      "---- Epoch 26/100\n",
      "(1) Training stage (lr = 0.000153) ...\n",
      "loss 1.29283, a_loss 1.16342, cD 1.83885, wmdcmp 0.23738, oracc 0.99528, orien_loss 0.00290, chxlmicf1 0.66408, chxlmacf1 0.63294, chx_loss 0.52730, chxlacc 0.83208, chxlrocaucmic 0.91218, chxlrocaucmac 0.90903, qlmicf1 0.47906, qlmacf1 0.32828, ql_loss 0.55814, ema 0.81419, 144.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43930, wmdcmp 0.19406, oracc 0.99591, chxlmicf1 0.56745, chxlmacf1 0.50164, chxlacc 0.74358, chxlrocaucmic 0.79151, chxlrocaucmac 0.75142, qlmicf1 0.39391, qlmacf1 0.27191, ema 0.67783, 20.74 secs\n",
      "Adjusting learning rate of group 0 to 1.4653e-04.\n",
      "---- Epoch 27/100\n",
      "(1) Training stage (lr = 0.000147) ...\n",
      "loss 3.47930, a_loss 1.16467, cD 1.85372, wmdcmp 0.23972, oracc 0.99583, orien_loss 0.00243, chxlmicf1 0.66388, chxlmacf1 0.63313, chx_loss 0.52822, chxlacc 0.83173, chxlrocaucmic 0.91142, chxlrocaucmac 0.90810, qlmicf1 0.47911, qlmacf1 0.32797, ql_loss 0.56043, ema 0.81321, 144.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38013, wmdcmp 0.19019, oracc 0.99562, chxlmicf1 0.56823, chxlmacf1 0.50142, chxlacc 0.74447, chxlrocaucmic 0.79116, chxlrocaucmac 0.74974, qlmicf1 0.39303, qlmacf1 0.27218, ema 0.70045, 20.33 secs\n",
      "Adjusting learning rate of group 0 to 1.3999e-04.\n",
      "---- Epoch 28/100\n",
      "(1) Training stage (lr = 0.000140) ...\n",
      "loss 3.57490, a_loss 1.16133, cD 1.85619, wmdcmp 0.23956, oracc 0.99564, orien_loss 0.00279, chxlmicf1 0.66399, chxlmacf1 0.63166, chx_loss 0.52996, chxlacc 0.83197, chxlrocaucmic 0.91142, chxlrocaucmac 0.90834, qlmicf1 0.47942, qlmacf1 0.32852, ql_loss 0.55864, ema 0.81459, 143.27 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41449, wmdcmp 0.19368, oracc 0.99577, chxlmicf1 0.56412, chxlmacf1 0.49689, chxlacc 0.74065, chxlrocaucmic 0.79040, chxlrocaucmac 0.74828, qlmicf1 0.39044, qlmacf1 0.27270, ema 0.69774, 20.70 secs\n",
      "Adjusting learning rate of group 0 to 1.3375e-04.\n",
      "---- Epoch 29/100\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 1.37098, a_loss 1.15525, cD 1.86565, wmdcmp 0.24074, oracc 0.99569, orien_loss 0.00272, chxlmicf1 0.66408, chxlmacf1 0.63371, chx_loss 0.52807, chxlacc 0.83223, chxlrocaucmic 0.91191, chxlrocaucmac 0.90857, qlmicf1 0.47978, qlmacf1 0.33000, ql_loss 0.55403, ema 0.81508, 143.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41118, wmdcmp 0.19289, oracc 0.99591, chxlmicf1 0.56879, chxlmacf1 0.49962, chxlacc 0.74343, chxlrocaucmic 0.79348, chxlrocaucmac 0.75067, qlmicf1 0.39451, qlmacf1 0.27278, ema 0.68597, 20.75 secs\n",
      "Adjusting learning rate of group 0 to 1.2778e-04.\n",
      "---- Epoch 30/100\n",
      "(1) Training stage (lr = 0.000128) ...\n",
      "loss 3.46524, a_loss 1.15947, cD 1.86895, wmdcmp 0.24157, oracc 0.99577, orien_loss 0.00211, chxlmicf1 0.66350, chxlmacf1 0.63290, chx_loss 0.52732, chxlacc 0.83195, chxlrocaucmic 0.91182, chxlrocaucmac 0.90837, qlmicf1 0.48028, qlmacf1 0.33214, ql_loss 0.55562, ema 0.81541, 143.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36409, wmdcmp 0.18859, oracc 0.99577, chxlmicf1 0.56839, chxlmacf1 0.50120, chxlacc 0.74412, chxlrocaucmic 0.79116, chxlrocaucmac 0.74940, qlmicf1 0.39211, qlmacf1 0.27237, ema 0.67602, 20.41 secs\n",
      "Adjusting learning rate of group 0 to 1.2208e-04.\n",
      "---- Epoch 31/100\n",
      "(1) Training stage (lr = 0.000122) ...\n",
      "loss 1.28078, a_loss 1.15572, cD 1.87984, wmdcmp 0.24287, oracc 0.99550, orien_loss 0.00347, chxlmicf1 0.66240, chxlmacf1 0.63060, chx_loss 0.53047, chxlacc 0.83075, chxlrocaucmic 0.91102, chxlrocaucmac 0.90773, qlmicf1 0.47976, qlmacf1 0.33011, ql_loss 0.55640, ema 0.81158, 143.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38816, wmdcmp 0.18957, oracc 0.99606, chxlmicf1 0.56644, chxlmacf1 0.49935, chxlacc 0.74359, chxlrocaucmic 0.79102, chxlrocaucmac 0.74979, qlmicf1 0.38831, qlmacf1 0.27066, ema 0.69412, 20.55 secs\n",
      "Adjusting learning rate of group 0 to 1.1663e-04.\n",
      "---- Epoch 32/100\n",
      "(1) Training stage (lr = 0.000117) ...\n",
      "loss 1.33589, a_loss 1.14998, cD 1.89044, wmdcmp 0.24326, oracc 0.99547, orien_loss 0.00305, chxlmicf1 0.66389, chxlmacf1 0.63222, chx_loss 0.52743, chxlacc 0.83219, chxlrocaucmic 0.91192, chxlrocaucmac 0.90867, qlmicf1 0.48043, qlmacf1 0.33046, ql_loss 0.55487, ema 0.81430, 143.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38957, wmdcmp 0.19003, oracc 0.99591, chxlmicf1 0.56575, chxlmacf1 0.49931, chxlacc 0.74210, chxlrocaucmic 0.79220, chxlrocaucmac 0.75071, qlmicf1 0.39272, qlmacf1 0.27209, ema 0.68959, 20.87 secs\n",
      "Adjusting learning rate of group 0 to 1.1143e-04.\n",
      "---- Epoch 33/100\n",
      "(1) Training stage (lr = 0.000111) ...\n",
      "loss 3.51846, a_loss 1.14881, cD 1.88493, wmdcmp 0.24282, oracc 0.99541, orien_loss 0.00262, chxlmicf1 0.66403, chxlmacf1 0.63329, chx_loss 0.52908, chxlacc 0.83214, chxlrocaucmic 0.91156, chxlrocaucmac 0.90814, qlmicf1 0.47918, qlmacf1 0.33054, ql_loss 0.55734, ema 0.81478, 143.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43082, wmdcmp 0.19409, oracc 0.99620, chxlmicf1 0.56922, chxlmacf1 0.50167, chxlacc 0.74486, chxlrocaucmic 0.79270, chxlrocaucmac 0.75069, qlmicf1 0.39254, qlmacf1 0.27196, ema 0.67783, 20.39 secs\n",
      "Adjusting learning rate of group 0 to 1.0646e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 34/100\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 1.33580, a_loss 1.14232, cD 1.89275, wmdcmp 0.24373, oracc 0.99559, orien_loss 0.00295, chxlmicf1 0.66457, chxlmacf1 0.63383, chx_loss 0.52703, chxlacc 0.83260, chxlrocaucmic 0.91228, chxlrocaucmac 0.90878, qlmicf1 0.48056, qlmacf1 0.33241, ql_loss 0.55491, ema 0.81359, 143.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41261, wmdcmp 0.19235, oracc 0.99606, chxlmicf1 0.56510, chxlmacf1 0.49712, chxlacc 0.74235, chxlrocaucmic 0.79111, chxlrocaucmac 0.74843, qlmicf1 0.39013, qlmacf1 0.27168, ema 0.69593, 20.83 secs\n",
      "Adjusting learning rate of group 0 to 1.0171e-04.\n",
      "---- Epoch 35/100\n",
      "(1) Training stage (lr = 0.000102) ...\n",
      "loss 3.30544, a_loss 1.14454, cD 1.90214, wmdcmp 0.24463, oracc 0.99552, orien_loss 0.00294, chxlmicf1 0.66442, chxlmacf1 0.63358, chx_loss 0.52741, chxlacc 0.83209, chxlrocaucmic 0.91172, chxlrocaucmac 0.90842, qlmicf1 0.47965, qlmacf1 0.32730, ql_loss 0.55554, ema 0.81712, 143.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40713, wmdcmp 0.19075, oracc 0.99606, chxlmicf1 0.56529, chxlmacf1 0.49851, chxlacc 0.74285, chxlrocaucmic 0.79069, chxlrocaucmac 0.74939, qlmicf1 0.39193, qlmacf1 0.27191, ema 0.67964, 20.40 secs\n",
      "Adjusting learning rate of group 0 to 9.7167e-05.\n",
      "---- Epoch 36/100\n",
      "(1) Training stage (lr = 0.000097) ...\n",
      "loss 0.25693, a_loss 1.14159, cD 1.92540, wmdcmp 0.24783, oracc 0.99582, orien_loss 0.00203, chxlmicf1 0.66498, chxlmacf1 0.63359, chx_loss 0.52658, chxlacc 0.83259, chxlrocaucmic 0.91216, chxlrocaucmac 0.90889, qlmicf1 0.48156, qlmacf1 0.33101, ql_loss 0.55391, ema 0.81554, 145.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.44199, wmdcmp 0.19608, oracc 0.99620, chxlmicf1 0.56901, chxlmacf1 0.50117, chxlacc 0.74500, chxlrocaucmic 0.79336, chxlrocaucmac 0.75044, qlmicf1 0.39298, qlmacf1 0.27290, ema 0.66968, 20.29 secs\n",
      "Adjusting learning rate of group 0 to 9.2832e-05.\n",
      "---- Epoch 37/100\n",
      "(1) Training stage (lr = 0.000093) ...\n",
      "loss 1.39340, a_loss 1.13458, cD 1.90441, wmdcmp 0.24495, oracc 0.99560, orien_loss 0.00323, chxlmicf1 0.66399, chxlmacf1 0.63286, chx_loss 0.53020, chxlacc 0.83166, chxlrocaucmic 0.91135, chxlrocaucmac 0.90807, qlmicf1 0.48020, qlmacf1 0.32802, ql_loss 0.55695, ema 0.81403, 142.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38447, wmdcmp 0.18980, oracc 0.99606, chxlmicf1 0.56635, chxlmacf1 0.49984, chxlacc 0.74166, chxlrocaucmic 0.79230, chxlrocaucmac 0.75001, qlmicf1 0.39301, qlmacf1 0.27246, ema 0.69231, 20.78 secs\n",
      "Adjusting learning rate of group 0 to 8.8690e-05.\n",
      "---- Epoch 38/100\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 3.41728, a_loss 1.13929, cD 1.93531, wmdcmp 0.24783, oracc 0.99523, orien_loss 0.00272, chxlmicf1 0.66276, chxlmacf1 0.63090, chx_loss 0.52985, chxlacc 0.83163, chxlrocaucmic 0.91131, chxlrocaucmac 0.90791, qlmicf1 0.48067, qlmacf1 0.33291, ql_loss 0.55418, ema 0.81418, 144.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38059, wmdcmp 0.18984, oracc 0.99591, chxlmicf1 0.56724, chxlmacf1 0.50030, chxlacc 0.74178, chxlrocaucmic 0.79195, chxlrocaucmac 0.74962, qlmicf1 0.38980, qlmacf1 0.27153, ema 0.69050, 20.82 secs\n",
      "Adjusting learning rate of group 0 to 8.4732e-05.\n",
      "---- Epoch 39/100\n",
      "(1) Training stage (lr = 0.000085) ...\n",
      "loss 1.34581, a_loss 1.13072, cD 1.93060, wmdcmp 0.24836, oracc 0.99558, orien_loss 0.00225, chxlmicf1 0.66465, chxlmacf1 0.63315, chx_loss 0.52763, chxlacc 0.83230, chxlrocaucmic 0.91194, chxlrocaucmac 0.90899, qlmicf1 0.48081, qlmacf1 0.33164, ql_loss 0.55391, ema 0.81714, 144.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41120, wmdcmp 0.19285, oracc 0.99606, chxlmicf1 0.56844, chxlmacf1 0.50047, chxlacc 0.74322, chxlrocaucmic 0.79229, chxlrocaucmac 0.74961, qlmicf1 0.39410, qlmacf1 0.27337, ema 0.68235, 20.86 secs\n",
      "Adjusting learning rate of group 0 to 8.0952e-05.\n",
      "---- Epoch 40/100\n",
      "(1) Training stage (lr = 0.000081) ...\n",
      "loss 3.47747, a_loss 1.13381, cD 1.94417, wmdcmp 0.24884, oracc 0.99562, orien_loss 0.00261, chxlmicf1 0.66410, chxlmacf1 0.63320, chx_loss 0.52934, chxlacc 0.83206, chxlrocaucmic 0.91142, chxlrocaucmac 0.90820, qlmicf1 0.47976, qlmacf1 0.33118, ql_loss 0.55423, ema 0.81465, 134.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40519, wmdcmp 0.19292, oracc 0.99562, chxlmicf1 0.56910, chxlmacf1 0.50172, chxlacc 0.74449, chxlrocaucmic 0.79242, chxlrocaucmac 0.75028, qlmicf1 0.39060, qlmacf1 0.27389, ema 0.69050, 19.36 secs\n",
      "Adjusting learning rate of group 0 to 7.7339e-05.\n",
      "---- Epoch 41/100\n",
      "(1) Training stage (lr = 0.000077) ...\n",
      "loss 3.30498, a_loss 1.13495, cD 1.92538, wmdcmp 0.24697, oracc 0.99579, orien_loss 0.00321, chxlmicf1 0.66374, chxlmacf1 0.63220, chx_loss 0.52955, chxlacc 0.83176, chxlrocaucmic 0.91147, chxlrocaucmac 0.90808, qlmicf1 0.48003, qlmacf1 0.33174, ql_loss 0.55435, ema 0.81586, 134.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.44919, wmdcmp 0.19670, oracc 0.99591, chxlmicf1 0.56859, chxlmacf1 0.50106, chxlacc 0.74333, chxlrocaucmic 0.79216, chxlrocaucmac 0.74951, qlmicf1 0.39217, qlmacf1 0.27176, ema 0.67602, 19.33 secs\n",
      "Adjusting learning rate of group 0 to 7.3889e-05.\n",
      "---- Epoch 42/100\n",
      "(1) Training stage (lr = 0.000074) ...\n",
      "loss 1.34904, a_loss 1.12461, cD 1.94842, wmdcmp 0.24982, oracc 0.99553, orien_loss 0.00285, chxlmicf1 0.66352, chxlmacf1 0.63262, chx_loss 0.52779, chxlacc 0.83208, chxlrocaucmic 0.91191, chxlrocaucmac 0.90869, qlmicf1 0.48181, qlmacf1 0.33269, ql_loss 0.55254, ema 0.82076, 134.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40820, wmdcmp 0.19244, oracc 0.99577, chxlmicf1 0.56788, chxlmacf1 0.50004, chxlacc 0.74262, chxlrocaucmic 0.79297, chxlrocaucmac 0.75108, qlmicf1 0.39342, qlmacf1 0.27284, ema 0.67964, 19.40 secs\n",
      "Adjusting learning rate of group 0 to 7.0592e-05.\n",
      "---- Epoch 43/100\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 3.41211, a_loss 1.13463, cD 1.93594, wmdcmp 0.24846, oracc 0.99568, orien_loss 0.00250, chxlmicf1 0.66327, chxlmacf1 0.63253, chx_loss 0.52975, chxlacc 0.83210, chxlrocaucmic 0.91170, chxlrocaucmac 0.90824, qlmicf1 0.48106, qlmacf1 0.33237, ql_loss 0.55312, ema 0.81758, 134.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40397, wmdcmp 0.19168, oracc 0.99591, chxlmicf1 0.56585, chxlmacf1 0.49864, chxlacc 0.74262, chxlrocaucmic 0.79237, chxlrocaucmac 0.75027, qlmicf1 0.39369, qlmacf1 0.27263, ema 0.69683, 19.67 secs\n",
      "Adjusting learning rate of group 0 to 6.7442e-05.\n",
      "---- Epoch 44/100\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 1.26130, a_loss 1.12904, cD 1.94732, wmdcmp 0.24956, oracc 0.99543, orien_loss 0.00288, chxlmicf1 0.66374, chxlmacf1 0.63254, chx_loss 0.53021, chxlacc 0.83167, chxlrocaucmic 0.91143, chxlrocaucmac 0.90820, qlmicf1 0.48006, qlmacf1 0.33035, ql_loss 0.55484, ema 0.82291, 135.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39862, wmdcmp 0.19239, oracc 0.99606, chxlmicf1 0.56808, chxlmacf1 0.50084, chxlacc 0.74273, chxlrocaucmic 0.79270, chxlrocaucmac 0.75159, qlmicf1 0.39016, qlmacf1 0.27077, ema 0.68054, 19.49 secs\n",
      "Adjusting learning rate of group 0 to 6.4433e-05.\n",
      "---- Epoch 45/100\n",
      "(1) Training stage (lr = 0.000064) ...\n",
      "loss 1.31561, a_loss 1.12232, cD 1.95123, wmdcmp 0.25058, oracc 0.99597, orien_loss 0.00198, chxlmicf1 0.66389, chxlmacf1 0.63303, chx_loss 0.52777, chxlacc 0.83209, chxlrocaucmic 0.91189, chxlrocaucmac 0.90840, qlmicf1 0.48025, qlmacf1 0.33087, ql_loss 0.55263, ema 0.81649, 133.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38765, wmdcmp 0.19095, oracc 0.99591, chxlmicf1 0.56504, chxlmacf1 0.49789, chxlacc 0.74229, chxlrocaucmic 0.79128, chxlrocaucmac 0.74837, qlmicf1 0.39765, qlmacf1 0.27456, ema 0.69140, 19.65 secs\n",
      "Adjusting learning rate of group 0 to 6.1558e-05.\n",
      "---- Epoch 46/100\n",
      "(1) Training stage (lr = 0.000062) ...\n",
      "loss 3.36056, a_loss 1.12267, cD 1.97076, wmdcmp 0.25240, oracc 0.99562, orien_loss 0.00281, chxlmicf1 0.66508, chxlmacf1 0.63480, chx_loss 0.52781, chxlacc 0.83252, chxlrocaucmic 0.91194, chxlrocaucmac 0.90869, qlmicf1 0.47991, qlmacf1 0.33060, ql_loss 0.55643, ema 0.81465, 134.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40051, wmdcmp 0.19207, oracc 0.99591, chxlmicf1 0.56650, chxlmacf1 0.49829, chxlacc 0.74395, chxlrocaucmic 0.79248, chxlrocaucmac 0.75062, qlmicf1 0.39244, qlmacf1 0.27347, ema 0.68054, 19.88 secs\n",
      "Adjusting learning rate of group 0 to 5.8811e-05.\n",
      "---- Epoch 47/100\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 1.31691, a_loss 1.12360, cD 1.95200, wmdcmp 0.25037, oracc 0.99545, orien_loss 0.00223, chxlmicf1 0.66595, chxlmacf1 0.63498, chx_loss 0.52623, chxlacc 0.83313, chxlrocaucmic 0.91258, chxlrocaucmac 0.90908, qlmicf1 0.48178, qlmacf1 0.33388, ql_loss 0.55157, ema 0.82032, 134.70 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.39885, wmdcmp 0.19188, oracc 0.99577, chxlmicf1 0.56653, chxlmacf1 0.50004, chxlacc 0.74265, chxlrocaucmic 0.79268, chxlrocaucmac 0.75006, qlmicf1 0.39662, qlmacf1 0.27281, ema 0.68235, 19.66 secs\n",
      "Adjusting learning rate of group 0 to 5.6187e-05.\n",
      "---- Epoch 48/100\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 3.28536, a_loss 1.12642, cD 1.96336, wmdcmp 0.25131, oracc 0.99560, orien_loss 0.00254, chxlmicf1 0.66439, chxlmacf1 0.63371, chx_loss 0.52764, chxlacc 0.83229, chxlrocaucmic 0.91172, chxlrocaucmac 0.90838, qlmicf1 0.48077, qlmacf1 0.32975, ql_loss 0.55305, ema 0.81791, 134.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40629, wmdcmp 0.19156, oracc 0.99591, chxlmicf1 0.56892, chxlmacf1 0.50273, chxlacc 0.74374, chxlrocaucmic 0.79298, chxlrocaucmac 0.75059, qlmicf1 0.39208, qlmacf1 0.27259, ema 0.68235, 19.31 secs\n",
      "Adjusting learning rate of group 0 to 5.3680e-05.\n",
      "---- Epoch 49/100\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.28146, a_loss 1.12680, cD 1.96554, wmdcmp 0.25128, oracc 0.99564, orien_loss 0.00292, chxlmicf1 0.66449, chxlmacf1 0.63293, chx_loss 0.52662, chxlacc 0.83240, chxlrocaucmic 0.91182, chxlrocaucmac 0.90864, qlmicf1 0.48135, qlmacf1 0.33190, ql_loss 0.55296, ema 0.81889, 134.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39510, wmdcmp 0.19127, oracc 0.99577, chxlmicf1 0.56916, chxlmacf1 0.50177, chxlacc 0.74431, chxlrocaucmic 0.79411, chxlrocaucmac 0.75230, qlmicf1 0.39458, qlmacf1 0.27314, ema 0.69412, 19.62 secs\n",
      "Adjusting learning rate of group 0 to 5.1285e-05.\n",
      "---- Epoch 50/100\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 1.34241, a_loss 1.11656, cD 1.95956, wmdcmp 0.25044, oracc 0.99597, orien_loss 0.00298, chxlmicf1 0.66384, chxlmacf1 0.63414, chx_loss 0.52891, chxlacc 0.83210, chxlrocaucmic 0.91150, chxlrocaucmac 0.90796, qlmicf1 0.48034, qlmacf1 0.33323, ql_loss 0.55422, ema 0.81231, 133.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39276, wmdcmp 0.19106, oracc 0.99620, chxlmicf1 0.57015, chxlmacf1 0.50099, chxlacc 0.74494, chxlrocaucmic 0.79377, chxlrocaucmac 0.75167, qlmicf1 0.39517, qlmacf1 0.27443, ema 0.68869, 19.79 secs\n",
      "Adjusting learning rate of group 0 to 4.8996e-05.\n",
      "---- Epoch 51/100\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 3.36406, a_loss 1.12054, cD 1.98910, wmdcmp 0.25413, oracc 0.99559, orien_loss 0.00231, chxlmicf1 0.66555, chxlmacf1 0.63388, chx_loss 0.52774, chxlacc 0.83260, chxlrocaucmic 0.91179, chxlrocaucmac 0.90846, qlmicf1 0.48158, qlmacf1 0.33348, ql_loss 0.55256, ema 0.81658, 136.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41353, wmdcmp 0.19370, oracc 0.99606, chxlmicf1 0.56647, chxlmacf1 0.49939, chxlacc 0.74173, chxlrocaucmic 0.79147, chxlrocaucmac 0.75016, qlmicf1 0.39284, qlmacf1 0.27144, ema 0.67873, 19.50 secs\n",
      "Adjusting learning rate of group 0 to 4.6810e-05.\n",
      "---- Epoch 52/100\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 1.33545, a_loss 1.11468, cD 1.97943, wmdcmp 0.25347, oracc 0.99524, orien_loss 0.00325, chxlmicf1 0.66420, chxlmacf1 0.63335, chx_loss 0.52730, chxlacc 0.83246, chxlrocaucmic 0.91215, chxlrocaucmac 0.90889, qlmicf1 0.48061, qlmacf1 0.33371, ql_loss 0.55294, ema 0.82127, 133.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38720, wmdcmp 0.18932, oracc 0.99620, chxlmicf1 0.56645, chxlmacf1 0.49999, chxlacc 0.74240, chxlrocaucmic 0.79210, chxlrocaucmac 0.74990, qlmicf1 0.39327, qlmacf1 0.27148, ema 0.68688, 19.39 secs\n",
      "Adjusting learning rate of group 0 to 4.4721e-05.\n",
      "---- Epoch 53/100\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 3.44254, a_loss 1.11908, cD 1.98675, wmdcmp 0.25364, oracc 0.99566, orien_loss 0.00317, chxlmicf1 0.66415, chxlmacf1 0.63246, chx_loss 0.53071, chxlacc 0.83195, chxlrocaucmic 0.91170, chxlrocaucmac 0.90824, qlmicf1 0.48067, qlmacf1 0.33523, ql_loss 0.55277, ema 0.81530, 134.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40863, wmdcmp 0.19287, oracc 0.99591, chxlmicf1 0.56756, chxlmacf1 0.49884, chxlacc 0.74322, chxlrocaucmic 0.79185, chxlrocaucmac 0.74974, qlmicf1 0.39453, qlmacf1 0.27265, ema 0.67692, 19.60 secs\n",
      "Adjusting learning rate of group 0 to 4.2726e-05.\n",
      "---- Epoch 54/100\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 3.32244, a_loss 1.11448, cD 1.97491, wmdcmp 0.25240, oracc 0.99552, orien_loss 0.00301, chxlmicf1 0.66382, chxlmacf1 0.63326, chx_loss 0.52754, chxlacc 0.83205, chxlrocaucmic 0.91158, chxlrocaucmac 0.90838, qlmicf1 0.48103, qlmacf1 0.33343, ql_loss 0.55434, ema 0.81749, 134.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41311, wmdcmp 0.19262, oracc 0.99591, chxlmicf1 0.56834, chxlmacf1 0.50095, chxlacc 0.74418, chxlrocaucmic 0.79332, chxlrocaucmac 0.75079, qlmicf1 0.39237, qlmacf1 0.27258, ema 0.68869, 19.45 secs\n",
      "Adjusting learning rate of group 0 to 4.0819e-05.\n",
      "---- Epoch 55/100\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 1.25938, a_loss 1.11073, cD 2.00195, wmdcmp 0.25554, oracc 0.99567, orien_loss 0.00247, chxlmicf1 0.66409, chxlmacf1 0.63280, chx_loss 0.52953, chxlacc 0.83211, chxlrocaucmic 0.91163, chxlrocaucmac 0.90826, qlmicf1 0.48170, qlmacf1 0.33146, ql_loss 0.55202, ema 0.81668, 134.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40425, wmdcmp 0.19151, oracc 0.99562, chxlmicf1 0.56669, chxlmacf1 0.49950, chxlacc 0.74237, chxlrocaucmic 0.79207, chxlrocaucmac 0.74907, qlmicf1 0.39250, qlmacf1 0.27146, ema 0.68235, 19.62 secs\n",
      "Adjusting learning rate of group 0 to 3.8998e-05.\n",
      "---- Epoch 56/100\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 3.26671, a_loss 1.11601, cD 2.00288, wmdcmp 0.25588, oracc 0.99518, orien_loss 0.00239, chxlmicf1 0.66501, chxlmacf1 0.63396, chx_loss 0.52614, chxlacc 0.83291, chxlrocaucmic 0.91243, chxlrocaucmac 0.90947, qlmicf1 0.48121, qlmacf1 0.32879, ql_loss 0.55155, ema 0.82158, 134.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38394, wmdcmp 0.19036, oracc 0.99606, chxlmicf1 0.56841, chxlmacf1 0.50193, chxlacc 0.74341, chxlrocaucmic 0.79254, chxlrocaucmac 0.75046, qlmicf1 0.39046, qlmacf1 0.27104, ema 0.68778, 19.65 secs\n",
      "Adjusting learning rate of group 0 to 3.7258e-05.\n",
      "---- Epoch 57/100\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 1.28893, a_loss 1.11754, cD 1.99519, wmdcmp 0.25472, oracc 0.99572, orien_loss 0.00303, chxlmicf1 0.66392, chxlmacf1 0.63376, chx_loss 0.52909, chxlacc 0.83185, chxlrocaucmic 0.91153, chxlrocaucmac 0.90806, qlmicf1 0.48064, qlmacf1 0.32998, ql_loss 0.55390, ema 0.81937, 133.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41218, wmdcmp 0.19244, oracc 0.99620, chxlmicf1 0.56899, chxlmacf1 0.50160, chxlacc 0.74333, chxlrocaucmic 0.79293, chxlrocaucmac 0.75109, qlmicf1 0.39424, qlmacf1 0.27232, ema 0.69050, 19.50 secs\n",
      "Adjusting learning rate of group 0 to 3.5596e-05.\n",
      "---- Epoch 58/100\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 1.34191, a_loss 1.10911, cD 1.99381, wmdcmp 0.25493, oracc 0.99574, orien_loss 0.00328, chxlmicf1 0.66512, chxlmacf1 0.63472, chx_loss 0.52662, chxlacc 0.83287, chxlrocaucmic 0.91223, chxlrocaucmac 0.90870, qlmicf1 0.48181, qlmacf1 0.33190, ql_loss 0.55081, ema 0.81873, 135.27 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39869, wmdcmp 0.19137, oracc 0.99606, chxlmicf1 0.56810, chxlmacf1 0.50067, chxlacc 0.74281, chxlrocaucmic 0.79234, chxlrocaucmac 0.74997, qlmicf1 0.39554, qlmacf1 0.27405, ema 0.69321, 19.56 secs\n",
      "Adjusting learning rate of group 0 to 3.4007e-05.\n",
      "---- Epoch 59/100\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 3.34883, a_loss 1.11055, cD 2.00589, wmdcmp 0.25596, oracc 0.99572, orien_loss 0.00269, chxlmicf1 0.66337, chxlmacf1 0.63239, chx_loss 0.52742, chxlacc 0.83175, chxlrocaucmic 0.91169, chxlrocaucmac 0.90836, qlmicf1 0.48114, qlmacf1 0.32900, ql_loss 0.55306, ema 0.82000, 134.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42406, wmdcmp 0.19476, oracc 0.99577, chxlmicf1 0.56730, chxlmacf1 0.49907, chxlacc 0.74333, chxlrocaucmic 0.79108, chxlrocaucmac 0.74757, qlmicf1 0.39147, qlmacf1 0.27272, ema 0.68235, 19.22 secs\n",
      "Adjusting learning rate of group 0 to 3.2490e-05.\n",
      "---- Epoch 60/100\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.38898, a_loss 1.10897, cD 1.99835, wmdcmp 0.25523, oracc 0.99573, orien_loss 0.00237, chxlmicf1 0.66395, chxlmacf1 0.63433, chx_loss 0.52758, chxlacc 0.83248, chxlrocaucmic 0.91223, chxlrocaucmac 0.90873, qlmicf1 0.48079, qlmacf1 0.33319, ql_loss 0.55206, ema 0.81830, 134.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39156, wmdcmp 0.19151, oracc 0.99606, chxlmicf1 0.56763, chxlmacf1 0.49994, chxlacc 0.74276, chxlrocaucmic 0.79216, chxlrocaucmac 0.74912, qlmicf1 0.39397, qlmacf1 0.27293, ema 0.68959, 19.60 secs\n",
      "Adjusting learning rate of group 0 to 3.1040e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 61/100\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 3.33724, a_loss 1.11691, cD 1.99984, wmdcmp 0.25536, oracc 0.99574, orien_loss 0.00246, chxlmicf1 0.66400, chxlmacf1 0.63292, chx_loss 0.52824, chxlacc 0.83220, chxlrocaucmic 0.91172, chxlrocaucmac 0.90832, qlmicf1 0.48098, qlmacf1 0.33250, ql_loss 0.55426, ema 0.82486, 134.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40869, wmdcmp 0.19371, oracc 0.99577, chxlmicf1 0.56928, chxlmacf1 0.50199, chxlacc 0.74315, chxlrocaucmic 0.79288, chxlrocaucmac 0.74986, qlmicf1 0.39318, qlmacf1 0.27157, ema 0.68688, 19.59 secs\n",
      "Adjusting learning rate of group 0 to 2.9655e-05.\n",
      "---- Epoch 62/100\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.27336, a_loss 1.11085, cD 1.99792, wmdcmp 0.25498, oracc 0.99558, orien_loss 0.00211, chxlmicf1 0.66412, chxlmacf1 0.63228, chx_loss 0.52853, chxlacc 0.83210, chxlrocaucmic 0.91209, chxlrocaucmac 0.90878, qlmicf1 0.48058, qlmacf1 0.33314, ql_loss 0.55510, ema 0.82242, 133.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40961, wmdcmp 0.19364, oracc 0.99591, chxlmicf1 0.56761, chxlmacf1 0.49878, chxlacc 0.74264, chxlrocaucmic 0.79248, chxlrocaucmac 0.74970, qlmicf1 0.39254, qlmacf1 0.27143, ema 0.69321, 19.31 secs\n",
      "Adjusting learning rate of group 0 to 2.8332e-05.\n",
      "---- Epoch 63/100\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 1.35696, a_loss 1.10284, cD 1.98923, wmdcmp 0.25484, oracc 0.99577, orien_loss 0.00250, chxlmicf1 0.66396, chxlmacf1 0.63293, chx_loss 0.52853, chxlacc 0.83207, chxlrocaucmic 0.91155, chxlrocaucmac 0.90812, qlmicf1 0.47995, qlmacf1 0.33204, ql_loss 0.55471, ema 0.81882, 134.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41191, wmdcmp 0.19264, oracc 0.99606, chxlmicf1 0.56704, chxlmacf1 0.49967, chxlacc 0.74206, chxlrocaucmic 0.79173, chxlrocaucmac 0.74950, qlmicf1 0.39216, qlmacf1 0.27114, ema 0.68416, 19.46 secs\n",
      "Adjusting learning rate of group 0 to 2.7068e-05.\n",
      "---- Epoch 64/100\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.41552, a_loss 1.11190, cD 2.01669, wmdcmp 0.25706, oracc 0.99581, orien_loss 0.00289, chxlmicf1 0.66444, chxlmacf1 0.63370, chx_loss 0.52693, chxlacc 0.83237, chxlrocaucmic 0.91207, chxlrocaucmac 0.90873, qlmicf1 0.48070, qlmacf1 0.33338, ql_loss 0.55251, ema 0.82120, 134.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41336, wmdcmp 0.19283, oracc 0.99591, chxlmicf1 0.56630, chxlmacf1 0.49930, chxlacc 0.74212, chxlrocaucmic 0.79222, chxlrocaucmac 0.74983, qlmicf1 0.39568, qlmacf1 0.27351, ema 0.68869, 19.43 secs\n",
      "Adjusting learning rate of group 0 to 2.5860e-05.\n",
      "---- Epoch 65/100\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 1.41090, a_loss 1.10400, cD 2.00614, wmdcmp 0.25600, oracc 0.99530, orien_loss 0.00275, chxlmicf1 0.66401, chxlmacf1 0.63356, chx_loss 0.52669, chxlacc 0.83234, chxlrocaucmic 0.91194, chxlrocaucmac 0.90863, qlmicf1 0.48153, qlmacf1 0.32932, ql_loss 0.55242, ema 0.82065, 134.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38312, wmdcmp 0.18980, oracc 0.99606, chxlmicf1 0.56831, chxlmacf1 0.50123, chxlacc 0.74296, chxlrocaucmic 0.79303, chxlrocaucmac 0.75059, qlmicf1 0.39613, qlmacf1 0.27445, ema 0.70045, 19.38 secs\n",
      "Adjusting learning rate of group 0 to 2.4706e-05.\n",
      "---- Epoch 66/100\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 3.47901, a_loss 1.11261, cD 2.01450, wmdcmp 0.25715, oracc 0.99574, orien_loss 0.00233, chxlmicf1 0.66280, chxlmacf1 0.63241, chx_loss 0.53065, chxlacc 0.83135, chxlrocaucmic 0.91134, chxlrocaucmac 0.90792, qlmicf1 0.48132, qlmacf1 0.33292, ql_loss 0.55208, ema 0.81609, 135.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40305, wmdcmp 0.19190, oracc 0.99577, chxlmicf1 0.56806, chxlmacf1 0.50183, chxlacc 0.74322, chxlrocaucmic 0.79154, chxlrocaucmac 0.74869, qlmicf1 0.39491, qlmacf1 0.27232, ema 0.68597, 19.61 secs\n",
      "Adjusting learning rate of group 0 to 2.3604e-05.\n",
      "---- Epoch 67/100\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 3.28932, a_loss 1.10784, cD 2.00250, wmdcmp 0.25527, oracc 0.99535, orien_loss 0.00285, chxlmicf1 0.66370, chxlmacf1 0.63211, chx_loss 0.52656, chxlacc 0.83192, chxlrocaucmic 0.91173, chxlrocaucmac 0.90863, qlmicf1 0.48095, qlmacf1 0.33227, ql_loss 0.55273, ema 0.82100, 134.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41502, wmdcmp 0.19267, oracc 0.99606, chxlmicf1 0.56856, chxlmacf1 0.50025, chxlacc 0.74360, chxlrocaucmic 0.79202, chxlrocaucmac 0.74953, qlmicf1 0.39411, qlmacf1 0.27320, ema 0.67873, 19.49 secs\n",
      "Adjusting learning rate of group 0 to 2.2551e-05.\n",
      "---- Epoch 68/100\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 1.28044, a_loss 1.10378, cD 2.01826, wmdcmp 0.25739, oracc 0.99544, orien_loss 0.00266, chxlmicf1 0.66564, chxlmacf1 0.63523, chx_loss 0.52541, chxlacc 0.83306, chxlrocaucmic 0.91223, chxlrocaucmac 0.90891, qlmicf1 0.48223, qlmacf1 0.33318, ql_loss 0.55110, ema 0.82219, 134.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40869, wmdcmp 0.19180, oracc 0.99533, chxlmicf1 0.56706, chxlmacf1 0.49904, chxlacc 0.74208, chxlrocaucmic 0.79246, chxlrocaucmac 0.74971, qlmicf1 0.39387, qlmacf1 0.27190, ema 0.68054, 19.57 secs\n",
      "Adjusting learning rate of group 0 to 2.1544e-05.\n",
      "---- Epoch 69/100\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.34583, a_loss 1.11046, cD 2.00591, wmdcmp 0.25604, oracc 0.99524, orien_loss 0.00270, chxlmicf1 0.66533, chxlmacf1 0.63474, chx_loss 0.52660, chxlacc 0.83303, chxlrocaucmic 0.91244, chxlrocaucmac 0.90905, qlmicf1 0.48219, qlmacf1 0.33502, ql_loss 0.55023, ema 0.82378, 134.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42465, wmdcmp 0.19452, oracc 0.99620, chxlmicf1 0.56683, chxlmacf1 0.49914, chxlacc 0.74216, chxlrocaucmic 0.79160, chxlrocaucmac 0.74973, qlmicf1 0.39304, qlmacf1 0.27236, ema 0.68959, 19.45 secs\n",
      "Adjusting learning rate of group 0 to 2.0583e-05.\n",
      "---- Epoch 70/100\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 1.27520, a_loss 1.10765, cD 2.01355, wmdcmp 0.25714, oracc 0.99559, orien_loss 0.00285, chxlmicf1 0.66389, chxlmacf1 0.63272, chx_loss 0.52762, chxlacc 0.83168, chxlrocaucmic 0.91180, chxlrocaucmac 0.90868, qlmicf1 0.48131, qlmacf1 0.33286, ql_loss 0.55360, ema 0.81989, 133.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40431, wmdcmp 0.19213, oracc 0.99606, chxlmicf1 0.56622, chxlmacf1 0.49853, chxlacc 0.74300, chxlrocaucmic 0.79253, chxlrocaucmac 0.75069, qlmicf1 0.39353, qlmacf1 0.27226, ema 0.68235, 19.37 secs\n",
      "Adjusting learning rate of group 0 to 1.9665e-05.\n",
      "---- Epoch 71/100\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 1.33801, a_loss 1.10381, cD 2.02188, wmdcmp 0.25713, oracc 0.99522, orien_loss 0.00282, chxlmicf1 0.66474, chxlmacf1 0.63317, chx_loss 0.52880, chxlacc 0.83260, chxlrocaucmic 0.91205, chxlrocaucmac 0.90870, qlmicf1 0.48161, qlmacf1 0.33198, ql_loss 0.55456, ema 0.81946, 134.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40134, wmdcmp 0.19160, oracc 0.99620, chxlmicf1 0.56638, chxlmacf1 0.49881, chxlacc 0.74262, chxlrocaucmic 0.79265, chxlrocaucmac 0.75055, qlmicf1 0.39373, qlmacf1 0.27376, ema 0.68235, 19.60 secs\n",
      "Adjusting learning rate of group 0 to 1.8787e-05.\n",
      "---- Epoch 72/100\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 3.47714, a_loss 1.10627, cD 2.00390, wmdcmp 0.25518, oracc 0.99528, orien_loss 0.00300, chxlmicf1 0.66386, chxlmacf1 0.63260, chx_loss 0.52834, chxlacc 0.83212, chxlrocaucmic 0.91166, chxlrocaucmac 0.90849, qlmicf1 0.48110, qlmacf1 0.33179, ql_loss 0.55310, ema 0.82151, 134.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40984, wmdcmp 0.19327, oracc 0.99577, chxlmicf1 0.56714, chxlmacf1 0.49996, chxlacc 0.74322, chxlrocaucmic 0.79249, chxlrocaucmac 0.74969, qlmicf1 0.39202, qlmacf1 0.27364, ema 0.68054, 19.37 secs\n",
      "Adjusting learning rate of group 0 to 1.7949e-05.\n",
      "---- Epoch 73/100\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 1.42268, a_loss 1.10288, cD 2.01243, wmdcmp 0.25682, oracc 0.99557, orien_loss 0.00239, chxlmicf1 0.66468, chxlmacf1 0.63412, chx_loss 0.52602, chxlacc 0.83267, chxlrocaucmic 0.91225, chxlrocaucmac 0.90906, qlmicf1 0.48156, qlmacf1 0.33321, ql_loss 0.55046, ema 0.82208, 136.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40955, wmdcmp 0.19265, oracc 0.99591, chxlmicf1 0.56531, chxlmacf1 0.49834, chxlacc 0.74127, chxlrocaucmic 0.79227, chxlrocaucmac 0.74890, qlmicf1 0.39348, qlmacf1 0.27254, ema 0.69412, 19.46 secs\n",
      "Adjusting learning rate of group 0 to 1.7148e-05.\n",
      "---- Epoch 74/100\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 3.33649, a_loss 1.10732, cD 2.02198, wmdcmp 0.25744, oracc 0.99544, orien_loss 0.00261, chxlmicf1 0.66405, chxlmacf1 0.63256, chx_loss 0.53059, chxlacc 0.83220, chxlrocaucmic 0.91165, chxlrocaucmac 0.90822, qlmicf1 0.48114, qlmacf1 0.33394, ql_loss 0.55156, ema 0.82000, 134.97 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.43730, wmdcmp 0.19556, oracc 0.99547, chxlmicf1 0.56868, chxlmacf1 0.50173, chxlacc 0.74399, chxlrocaucmic 0.79318, chxlrocaucmac 0.75097, qlmicf1 0.39388, qlmacf1 0.27266, ema 0.68326, 19.39 secs\n",
      "Adjusting learning rate of group 0 to 1.6383e-05.\n",
      "---- Epoch 75/100\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.28448, a_loss 1.10754, cD 2.01403, wmdcmp 0.25714, oracc 0.99537, orien_loss 0.00266, chxlmicf1 0.66489, chxlmacf1 0.63479, chx_loss 0.52651, chxlacc 0.83271, chxlrocaucmic 0.91219, chxlrocaucmac 0.90872, qlmicf1 0.48197, qlmacf1 0.33088, ql_loss 0.55218, ema 0.82198, 134.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40523, wmdcmp 0.19213, oracc 0.99591, chxlmicf1 0.56932, chxlmacf1 0.50085, chxlacc 0.74367, chxlrocaucmic 0.79308, chxlrocaucmac 0.74981, qlmicf1 0.39284, qlmacf1 0.27301, ema 0.69774, 19.50 secs\n",
      "Adjusting learning rate of group 0 to 1.5652e-05.\n",
      "---- Epoch 76/100\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 1.32405, a_loss 1.09883, cD 2.01290, wmdcmp 0.25660, oracc 0.99587, orien_loss 0.00281, chxlmicf1 0.66440, chxlmacf1 0.63300, chx_loss 0.52817, chxlacc 0.83189, chxlrocaucmic 0.91181, chxlrocaucmac 0.90850, qlmicf1 0.48107, qlmacf1 0.33397, ql_loss 0.55294, ema 0.82073, 134.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40875, wmdcmp 0.19187, oracc 0.99606, chxlmicf1 0.57008, chxlmacf1 0.50237, chxlacc 0.74436, chxlrocaucmic 0.79348, chxlrocaucmac 0.75153, qlmicf1 0.39630, qlmacf1 0.27310, ema 0.68326, 19.50 secs\n",
      "Adjusting learning rate of group 0 to 1.4953e-05.\n",
      "---- Epoch 77/100\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 3.33924, a_loss 1.10872, cD 2.01961, wmdcmp 0.25707, oracc 0.99543, orien_loss 0.00227, chxlmicf1 0.66446, chxlmacf1 0.63357, chx_loss 0.52801, chxlacc 0.83231, chxlrocaucmic 0.91191, chxlrocaucmac 0.90856, qlmicf1 0.48129, qlmacf1 0.33222, ql_loss 0.55166, ema 0.81940, 134.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42966, wmdcmp 0.19515, oracc 0.99591, chxlmicf1 0.56647, chxlmacf1 0.50027, chxlacc 0.74188, chxlrocaucmic 0.79132, chxlrocaucmac 0.74888, qlmicf1 0.39431, qlmacf1 0.27358, ema 0.69231, 19.73 secs\n",
      "Adjusting learning rate of group 0 to 1.4286e-05.\n",
      "---- Epoch 78/100\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.35106, a_loss 1.09954, cD 2.02740, wmdcmp 0.25837, oracc 0.99575, orien_loss 0.00327, chxlmicf1 0.66339, chxlmacf1 0.63266, chx_loss 0.52803, chxlacc 0.83169, chxlrocaucmic 0.91174, chxlrocaucmac 0.90850, qlmicf1 0.48152, qlmacf1 0.33385, ql_loss 0.55269, ema 0.82270, 134.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39651, wmdcmp 0.19145, oracc 0.99577, chxlmicf1 0.56618, chxlmacf1 0.49847, chxlacc 0.74212, chxlrocaucmic 0.79240, chxlrocaucmac 0.75077, qlmicf1 0.39535, qlmacf1 0.27357, ema 0.69231, 19.54 secs\n",
      "Adjusting learning rate of group 0 to 1.3649e-05.\n",
      "---- Epoch 79/100\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.37859, a_loss 1.10497, cD 2.03336, wmdcmp 0.25880, oracc 0.99575, orien_loss 0.00277, chxlmicf1 0.66321, chxlmacf1 0.63145, chx_loss 0.53037, chxlacc 0.83171, chxlrocaucmic 0.91138, chxlrocaucmac 0.90808, qlmicf1 0.47982, qlmacf1 0.32956, ql_loss 0.55756, ema 0.82022, 134.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37459, wmdcmp 0.18920, oracc 0.99606, chxlmicf1 0.56704, chxlmacf1 0.49830, chxlacc 0.74183, chxlrocaucmic 0.79159, chxlrocaucmac 0.74892, qlmicf1 0.39377, qlmacf1 0.27314, ema 0.68869, 19.52 secs\n",
      "Adjusting learning rate of group 0 to 1.3040e-05.\n",
      "---- Epoch 80/100\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 3.35319, a_loss 1.10213, cD 2.02668, wmdcmp 0.25767, oracc 0.99531, orien_loss 0.00279, chxlmicf1 0.66350, chxlmacf1 0.63284, chx_loss 0.52867, chxlacc 0.83138, chxlrocaucmic 0.91142, chxlrocaucmac 0.90807, qlmicf1 0.47985, qlmacf1 0.33315, ql_loss 0.55255, ema 0.82381, 136.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43282, wmdcmp 0.19507, oracc 0.99606, chxlmicf1 0.56907, chxlmacf1 0.50321, chxlacc 0.74377, chxlrocaucmic 0.79290, chxlrocaucmac 0.75137, qlmicf1 0.39407, qlmacf1 0.27444, ema 0.69140, 19.31 secs\n",
      "Adjusting learning rate of group 0 to 1.2458e-05.\n",
      "---- Epoch 81/100\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 1.16723, a_loss 1.09744, cD 2.03905, wmdcmp 0.25909, oracc 0.99563, orien_loss 0.00263, chxlmicf1 0.66349, chxlmacf1 0.63177, chx_loss 0.52919, chxlacc 0.83187, chxlrocaucmic 0.91164, chxlrocaucmac 0.90843, qlmicf1 0.48061, qlmacf1 0.33152, ql_loss 0.55095, ema 0.82322, 134.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41473, wmdcmp 0.19308, oracc 0.99606, chxlmicf1 0.57027, chxlmacf1 0.50385, chxlacc 0.74427, chxlrocaucmic 0.79368, chxlrocaucmac 0.75195, qlmicf1 0.39303, qlmacf1 0.27480, ema 0.68869, 19.33 secs\n",
      "Adjusting learning rate of group 0 to 1.1902e-05.\n",
      "---- Epoch 82/100\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 3.20627, a_loss 1.10668, cD 2.03553, wmdcmp 0.25926, oracc 0.99568, orien_loss 0.00280, chxlmicf1 0.66428, chxlmacf1 0.63381, chx_loss 0.52668, chxlacc 0.83220, chxlrocaucmic 0.91192, chxlrocaucmac 0.90879, qlmicf1 0.48168, qlmacf1 0.33446, ql_loss 0.55046, ema 0.82030, 134.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41452, wmdcmp 0.19311, oracc 0.99591, chxlmicf1 0.56740, chxlmacf1 0.49875, chxlacc 0.74362, chxlrocaucmic 0.79229, chxlrocaucmac 0.75035, qlmicf1 0.39463, qlmacf1 0.27289, ema 0.69412, 19.54 secs\n",
      "Adjusting learning rate of group 0 to 1.1371e-05.\n",
      "---- Epoch 83/100\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.32350, a_loss 1.10427, cD 2.02791, wmdcmp 0.25833, oracc 0.99580, orien_loss 0.00265, chxlmicf1 0.66488, chxlmacf1 0.63314, chx_loss 0.52859, chxlacc 0.83228, chxlrocaucmic 0.91186, chxlrocaucmac 0.90828, qlmicf1 0.48072, qlmacf1 0.33031, ql_loss 0.55469, ema 0.82139, 134.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40620, wmdcmp 0.19248, oracc 0.99591, chxlmicf1 0.56827, chxlmacf1 0.50093, chxlacc 0.74312, chxlrocaucmic 0.79229, chxlrocaucmac 0.75064, qlmicf1 0.39007, qlmacf1 0.27140, ema 0.68597, 19.57 secs\n",
      "Adjusting learning rate of group 0 to 1.0864e-05.\n",
      "---- Epoch 84/100\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.32242, a_loss 1.09879, cD 2.04099, wmdcmp 0.25925, oracc 0.99583, orien_loss 0.00261, chxlmicf1 0.66392, chxlmacf1 0.63232, chx_loss 0.52838, chxlacc 0.83227, chxlrocaucmic 0.91192, chxlrocaucmac 0.90849, qlmicf1 0.48111, qlmacf1 0.33200, ql_loss 0.55194, ema 0.81916, 134.39 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41668, wmdcmp 0.19399, oracc 0.99620, chxlmicf1 0.56738, chxlmacf1 0.50097, chxlacc 0.74303, chxlrocaucmic 0.79176, chxlrocaucmac 0.74928, qlmicf1 0.39363, qlmacf1 0.27249, ema 0.69050, 19.71 secs\n",
      "Adjusting learning rate of group 0 to 1.0379e-05.\n",
      "---- Epoch 85/100\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 3.41388, a_loss 1.10123, cD 2.02675, wmdcmp 0.25839, oracc 0.99530, orien_loss 0.00234, chxlmicf1 0.66342, chxlmacf1 0.63147, chx_loss 0.53055, chxlacc 0.83178, chxlrocaucmic 0.91135, chxlrocaucmac 0.90804, qlmicf1 0.48046, qlmacf1 0.33375, ql_loss 0.55383, ema 0.81805, 134.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40689, wmdcmp 0.19267, oracc 0.99620, chxlmicf1 0.56738, chxlmacf1 0.49999, chxlacc 0.74308, chxlrocaucmic 0.79350, chxlrocaucmac 0.75233, qlmicf1 0.39350, qlmacf1 0.27228, ema 0.69050, 19.33 secs\n",
      "Adjusting learning rate of group 0 to 9.9158e-06.\n",
      "---- Epoch 86/100\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.30230, a_loss 1.09884, cD 2.02045, wmdcmp 0.25707, oracc 0.99546, orien_loss 0.00312, chxlmicf1 0.66553, chxlmacf1 0.63521, chx_loss 0.52579, chxlacc 0.83268, chxlrocaucmic 0.91245, chxlrocaucmac 0.90914, qlmicf1 0.48269, qlmacf1 0.33381, ql_loss 0.54933, ema 0.82086, 134.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39881, wmdcmp 0.19142, oracc 0.99606, chxlmicf1 0.56817, chxlmacf1 0.50142, chxlacc 0.74277, chxlrocaucmic 0.79204, chxlrocaucmac 0.74985, qlmicf1 0.39319, qlmacf1 0.27350, ema 0.68507, 19.57 secs\n",
      "Adjusting learning rate of group 0 to 9.4734e-06.\n",
      "---- Epoch 87/100\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.34136, a_loss 1.10216, cD 2.03455, wmdcmp 0.25974, oracc 0.99555, orien_loss 0.00272, chxlmicf1 0.66366, chxlmacf1 0.63168, chx_loss 0.52978, chxlacc 0.83126, chxlrocaucmic 0.91109, chxlrocaucmac 0.90792, qlmicf1 0.48043, qlmacf1 0.33217, ql_loss 0.55262, ema 0.81755, 134.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42445, wmdcmp 0.19486, oracc 0.99577, chxlmicf1 0.56876, chxlmacf1 0.50212, chxlacc 0.74439, chxlrocaucmic 0.79397, chxlrocaucmac 0.75230, qlmicf1 0.39468, qlmacf1 0.27302, ema 0.69050, 19.64 secs\n",
      "Adjusting learning rate of group 0 to 9.0507e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 88/100\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.26479, a_loss 1.10022, cD 2.03075, wmdcmp 0.25832, oracc 0.99574, orien_loss 0.00231, chxlmicf1 0.66357, chxlmacf1 0.63228, chx_loss 0.52774, chxlacc 0.83196, chxlrocaucmic 0.91199, chxlrocaucmac 0.90889, qlmicf1 0.48129, qlmacf1 0.33207, ql_loss 0.55156, ema 0.82299, 136.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40582, wmdcmp 0.19337, oracc 0.99562, chxlmicf1 0.56830, chxlmacf1 0.50157, chxlacc 0.74272, chxlrocaucmic 0.79231, chxlrocaucmac 0.74989, qlmicf1 0.39549, qlmacf1 0.27387, ema 0.67783, 19.61 secs\n",
      "Adjusting learning rate of group 0 to 8.6468e-06.\n",
      "---- Epoch 89/100\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.35586, a_loss 1.09827, cD 2.02167, wmdcmp 0.25736, oracc 0.99603, orien_loss 0.00236, chxlmicf1 0.66317, chxlmacf1 0.63254, chx_loss 0.53134, chxlacc 0.83145, chxlrocaucmic 0.91082, chxlrocaucmac 0.90766, qlmicf1 0.48138, qlmacf1 0.33181, ql_loss 0.55256, ema 0.82046, 134.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39324, wmdcmp 0.19134, oracc 0.99620, chxlmicf1 0.56900, chxlmacf1 0.50126, chxlacc 0.74344, chxlrocaucmic 0.79273, chxlrocaucmac 0.74993, qlmicf1 0.39316, qlmacf1 0.27202, ema 0.69050, 19.45 secs\n",
      "Adjusting learning rate of group 0 to 8.2610e-06.\n",
      "---- Epoch 90/100\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "^C iteration 35820\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"../train_vqa.py\", line 1439, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_vqa.py\", line 1338, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_vqa.py\", line 882, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 505, in step_fn\n",
      "    output = step_fn__mimiccxr_iuxray(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 164, in step_fn__mimiccxr_iuxray\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vqa/open_ended_vqa.py\", line 469, in forward\n",
      "    pred_answers = self.answer_decoder.teacher_forcing_decoding(local_feat, global_feat, question_vectors, answers, device)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vqa/transformer_answer_decoder.py\", line 85, in teacher_forcing_decoding\n",
      "    tgt_mask = self.generate_square_subsequent_mask(max_answer_length).to(device)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/\" \\\n",
    "        --epochs 100 \\\n",
    "        --batches-per-epoch 400 \\\n",
    "        --batch-size 200 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --num-workers 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,4e-4,96,5e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --iuxray-train-with-all \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220629_050643.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220629_042239.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220629_055159.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220629_055107.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220629_052842.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220629_052841.pkl\" \\\n",
    "        --balanced-split \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220629_123956.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220629_123626.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220629_052724.pkl\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --raw-image-encoding \"clip-vit-huggingface\" \\\n",
    "        --clip-version \"CenIA/clip-vit-bio-clinical-bert-finetuned\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.evaluation.plots import plot_train_val_curves\n",
    "from medvqa.utils.constants import MetricNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_train_val_curves('/home/pamessina/medvqa-workspace/models/vqa/20220824_112420_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metrics_logs.csv',\n",
    "                 [MetricNames.WMEDCOMP, MetricNames.CIDER_D, MetricNames.EXACTMATCH_ANSWER,\n",
    "                  MetricNames.CHXLABELMACROAVGF1, MetricNames.CHXLABELMICROAVGF1,\n",
    "                  MetricNames.CHXLABELACC,\n",
    "                  MetricNames.CHXLABEL_ROCAUC_MACRO, MetricNames.CHXLABEL_ROCAUC_MICRO,                  \n",
    "                  MetricNames.QLABELS_MACROAVGF1, MetricNames.QLABELS_MICROAVGF1,\n",
    "                  MetricNames.ORIENACC, MetricNames.GENDER_ACC,\n",
    "                  MetricNames.CXR14MACROAVGF1, MetricNames.CXR14MICROAVGF1,\n",
    "                  MetricNames.VINBIGMACROAVGF1, MetricNames.VINBIGMICROAVGF1,\n",
    "                 ],\n",
    "                 ['Weighted Medical Completeness (QA)', 'cider-D (QA)', 'Exact Match (QA)',\n",
    "                  'Chexpert-F1 (Macro Avg)', 'Chexpert-F1 (Micro Avg)',\n",
    "                  'Chexpert Acc',\n",
    "                  'Chexpert ROC-AUC (Macro Avg)', 'Chexpert ROC-AUC (Micro Avg)',                  \n",
    "                  'Questions-F1 (Macro Avg)', 'Questions-F1 (Micro Avg)',\n",
    "                  'Orientation Acc', 'Gender Acc',\n",
    "                  'CXR14-F1 (Macro Avg)', 'CXR14-F1 (Micro Avg)',\n",
    "                  'VinBig-F1 (Macro Avg)', 'VinBig-F1 (Micro Avg)',                  \n",
    "                 ],\n",
    "                 single_plot_figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Report-level Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: 0\n",
      "   batch_size: 70\n",
      "   device: GPU\n",
      "   num_workers: 4\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 14\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 70\n",
      "len(self.report_ids) = 31831, len(set(self.report_ids)) = 3239\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 31831, len(set(self.report_ids)) = 3239\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 31831\n",
      "len(dataloader) = 455\n",
      "Evaluating model ...\n",
      "oracc 0.99424, chxlmicf1 0.55682, chxlmacf1 0.46741, chxlacc 0.67923, chxlrocaucmic 0.78686, chxlrocaucmac 0.74104, qlmacf1 0.20527, 267.46 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3239, len(gt_reports)=3239\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3239 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3239 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=804, chunk_size=804\n",
      "chunk: i=1, b=804, e=1608, chunk_size=804\n",
      "chunk: i=2, b=1608, e=2412, chunk_size=804\n",
      "chunk: i=3, b=2412, e=3216, chunk_size=804\n",
      "\t#### process 1: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_153224_0.9165960406135589_0.csv --output_path /data/labeler-output_20220831_153224_0.9165960406135589_0.csv\n",
      "\t#### process 2: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_153224_0.9165960406135589_1.csv --output_path /data/labeler-output_20220831_153224_0.9165960406135589_1.csv\n",
      "\t#### process 3: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_153224_0.9165960406135589_2.csv --output_path /data/labeler-output_20220831_153224_0.9165960406135589_2.csv\n",
      "\t#### process 4: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_153224_0.9165960406135589_3.csv --output_path /data/labeler-output_20220831_153224_0.9165960406135589_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 724.9621617794037\n",
      "\t**** process 2 finished, elapsed time = 724.9622745513916\n",
      "\t**** process 3 finished, elapsed time = 724.9623012542725\n",
      "\t**** process 4 finished, elapsed time = 724.9623239040375\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 70 \\\n",
    "        --num-workers 4 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: chexpert-labels\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: 0\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 4\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 14\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_51_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5818.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 100\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 458\n",
      "Evaluating model ...\n",
      "oracc 0.99375, chxlmicf1 0.52888, chxlmacf1 0.44534, chxlacc 0.67067, chxlrocaucmic 0.78209, chxlrocaucmac 0.73378, qlmacf1 0.18771, 335.95 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3269, len(gt_reports)=3269\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=198, chunk_size=198\n",
      "chunk: i=1, b=198, e=396, chunk_size=198\n",
      "chunk: i=2, b=396, e=594, chunk_size=198\n",
      "chunk: i=3, b=594, e=792, chunk_size=197\n",
      "\t#### process 1: running chexpert labeler over 198 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_155212_0.17099623309654588_0.csv --output_path /data/labeler-output_20220831_155212_0.17099623309654588_0.csv\n",
      "\t#### process 2: running chexpert labeler over 198 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_155212_0.17099623309654588_1.csv --output_path /data/labeler-output_20220831_155212_0.17099623309654588_1.csv\n",
      "\t#### process 3: running chexpert labeler over 198 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_155212_0.17099623309654588_2.csv --output_path /data/labeler-output_20220831_155212_0.17099623309654588_2.csv\n",
      "\t#### process 4: running chexpert labeler over 197 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_155212_0.17099623309654588_3.csv --output_path /data/labeler-output_20220831_155212_0.17099623309654588_3.csv\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 169.90902042388916\n",
      "\t**** process 2 finished, elapsed time = 169.9091672897339\n",
      "\t**** process 3 finished, elapsed time = 169.90921759605408\n",
      "\t**** process 4 finished, elapsed time = 169.90926718711853\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_133309_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"chexpert-labels\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 4 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: 0\n",
      "   batch_size: 70\n",
      "   device: GPU\n",
      "   num_workers: 4\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 14\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 70\n",
      "len(self.report_ids) = 31831, len(set(self.report_ids)) = 3239\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 31831, len(set(self.report_ids)) = 3239\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 31831\n",
      "len(dataloader) = 455\n",
      "Evaluating model ...\n",
      "oracc 0.99705, chxlmicf1 0.59587, chxlmacf1 0.47302, chxlacc 0.75042, chxlrocaucmic 0.81775, chxlrocaucmac 0.73599, qlmacf1 0.22164, 265.81 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3239, len(gt_reports)=3239\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3239 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3239 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=804, chunk_size=804\n",
      "chunk: i=1, b=804, e=1608, chunk_size=804\n",
      "chunk: i=2, b=1608, e=2412, chunk_size=804\n",
      "chunk: i=3, b=2412, e=3216, chunk_size=804\n",
      "\t#### process 1: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_160108_0.1264454967722749_0.csv --output_path /data/labeler-output_20220831_160108_0.1264454967722749_0.csv\n",
      "\t#### process 2: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_160108_0.1264454967722749_1.csv --output_path /data/labeler-output_20220831_160108_0.1264454967722749_1.csv\n",
      "\t#### process 3: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_160108_0.1264454967722749_2.csv --output_path /data/labeler-output_20220831_160108_0.1264454967722749_2.csv\n",
      "\t#### process 4: running chexpert labeler over 804 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_160108_0.1264454967722749_3.csv --output_path /data/labeler-output_20220831_160108_0.1264454967722749_3.csv\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 712.5902464389801\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "\t**** process 2 finished, elapsed time = 723.6599643230438\n",
      "\t**** process 3 finished, elapsed time = 723.6600654125214\n",
      "\t**** process 4 finished, elapsed time = 723.660133600235\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 70 \\\n",
    "        --num-workers 4 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: chexpert-labels\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: 0\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 4\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 14\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 100\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 458\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57128, chxlmacf1 0.45484, chxlacc 0.74623, chxlrocaucmic 0.81297, chxlrocaucmac 0.72960, qlmacf1 0.20228, 285.76 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3269, len(gt_reports)=3269\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=234, chunk_size=234\n",
      "chunk: i=1, b=234, e=468, chunk_size=234\n",
      "chunk: i=2, b=468, e=702, chunk_size=234\n",
      "chunk: i=3, b=702, e=936, chunk_size=234\n",
      "\t#### process 1: running chexpert labeler over 234 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_161935_0.730771650829506_0.csv --output_path /data/labeler-output_20220831_161935_0.730771650829506_0.csv\n",
      "\t#### process 2: running chexpert labeler over 234 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_161935_0.730771650829506_1.csv --output_path /data/labeler-output_20220831_161935_0.730771650829506_1.csv\n",
      "\t#### process 3: running chexpert labeler over 234 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_161935_0.730771650829506_2.csv --output_path /data/labeler-output_20220831_161935_0.730771650829506_2.csv\n",
      "\t#### process 4: running chexpert labeler over 234 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_161935_0.730771650829506_3.csv --output_path /data/labeler-output_20220831_161935_0.730771650829506_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 192.42373418807983\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 2 finished, elapsed time = 193.2884669303894\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 3 finished, elapsed time = 195.04814791679382\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 4 finished, elapsed time = 196.36380887031555\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"chexpert-labels\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 4 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: 0\n",
      "   batch_size: 70\n",
      "   device: GPU\n",
      "   num_workers: 4\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 14\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_65_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5911.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/checkpoint_65_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5911.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/checkpoint_65_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5911.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 70\n",
      "len(self.report_ids) = 31831, len(set(self.report_ids)) = 3239\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 31831, len(set(self.report_ids)) = 3239\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 31831\n",
      "len(dataloader) = 455\n",
      "Evaluating model ...\n",
      "oracc 0.99675, chxlmicf1 0.59563, chxlmacf1 0.46550, chxlacc 0.75171, chxlrocaucmic 0.81634, chxlrocaucmac 0.72850, qlmacf1 0.22138, 267.32 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3239, len(gt_reports)=3239\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3239 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3239 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=805, chunk_size=805\n",
      "chunk: i=1, b=805, e=1610, chunk_size=805\n",
      "chunk: i=2, b=1610, e=2415, chunk_size=805\n",
      "chunk: i=3, b=2415, e=3220, chunk_size=802\n",
      "\t#### process 1: running chexpert labeler over 805 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_162855_0.37942289123315187_0.csv --output_path /data/labeler-output_20220831_162855_0.37942289123315187_0.csv\n",
      "\t#### process 2: running chexpert labeler over 805 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_162855_0.37942289123315187_1.csv --output_path /data/labeler-output_20220831_162855_0.37942289123315187_1.csv\n",
      "\t#### process 3: running chexpert labeler over 805 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_162855_0.37942289123315187_2.csv --output_path /data/labeler-output_20220831_162855_0.37942289123315187_2.csv\n",
      "\t#### process 4: running chexpert labeler over 802 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_162855_0.37942289123315187_3.csv --output_path /data/labeler-output_20220831_162855_0.37942289123315187_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 564.4659469127655\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 2 finished, elapsed time = 573.9556975364685\n",
      "\t**** process 3 finished, elapsed time = 573.9558155536652\n",
      "\t**** process 4 finished, elapsed time = 573.955881357193\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 70 \\\n",
    "        --num-workers 4 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\n",
      "   eval_mode: chexpert-labels\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: 0\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 4\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 14\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_65_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5911.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/checkpoint_65_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5911.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/checkpoint_65_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5911.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 100\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 458\n",
      "Evaluating model ...\n",
      "oracc 0.99638, chxlmicf1 0.57058, chxlmacf1 0.44681, chxlacc 0.74715, chxlrocaucmic 0.81184, chxlrocaucmac 0.72221, qlmacf1 0.20216, 94.33 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3269, len(gt_reports)=3269\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=245, chunk_size=245\n",
      "chunk: i=1, b=245, e=490, chunk_size=245\n",
      "chunk: i=2, b=490, e=735, chunk_size=245\n",
      "chunk: i=3, b=735, e=980, chunk_size=243\n",
      "\t#### process 1: running chexpert labeler over 245 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_164057_0.6051733846812116_0.csv --output_path /data/labeler-output_20220831_164057_0.6051733846812116_0.csv\n",
      "\t#### process 2: running chexpert labeler over 245 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_164057_0.6051733846812116_1.csv --output_path /data/labeler-output_20220831_164057_0.6051733846812116_1.csv\n",
      "\t#### process 3: running chexpert labeler over 245 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_164057_0.6051733846812116_2.csv --output_path /data/labeler-output_20220831_164057_0.6051733846812116_2.csv\n",
      "\t#### process 4: running chexpert labeler over 243 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20220831_164057_0.6051733846812116_3.csv --output_path /data/labeler-output_20220831_164057_0.6051733846812116_3.csv\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "\t**** process 1 finished, elapsed time = 116.54743313789368\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 2 finished, elapsed time = 120.25203561782837\n",
      "\t**** process 3 finished, elapsed time = 120.61487936973572\n",
      "\t**** process 4 finished, elapsed time = 120.6150062084198\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_204940_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"chexpert-labels\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 4 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
