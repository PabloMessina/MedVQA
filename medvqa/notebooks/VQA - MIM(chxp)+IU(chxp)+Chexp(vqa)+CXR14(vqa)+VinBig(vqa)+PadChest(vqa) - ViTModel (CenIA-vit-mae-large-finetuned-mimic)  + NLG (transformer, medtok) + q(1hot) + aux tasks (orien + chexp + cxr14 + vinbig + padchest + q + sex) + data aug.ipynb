{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 100\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface-large\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-large-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,5e-4,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 150\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "Downloading: 100%|██████████████████████████████| 765/765 [00:00<00:00, 412kB/s]\n",
      "Downloading: 100%|█████████████████████████| 1.13G/1.13G [00:52<00:00, 23.1MB/s]\n",
      "Ignore freezing parameter: pooler.dense.weight\n",
      "Ignore freezing parameter: pooler.dense.bias\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-large-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,5e-4,32,1e-6\n",
      "1e-06 8 0.0005 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [224, 224], use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 150\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=287,3559006002065882738).pkl\n",
      "\tlen(question_datasets) = 92\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 150\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=283,2750089748417475840).pkl\n",
      "\tlen(question_datasets) = 42\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading CXR14 labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1442: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 129804.64it/s]\n",
      "Done. Example answer: <s> aortic atheromatosis , aortic elongation </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 134539.04it/s]\n",
      "Done. Example answer: <s> </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 73679.87it/s]\n",
      "Done. Example answer: <s> nsg tube loc gastric chamber central venous catheter via subclavian vein loc central loc left loc subclavian vein normal </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc cardiac </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:32,  5.96it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184417_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184417_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184417_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 12.07095, a_loss 8.70172, cD 0.00018, wmdcmp 0.00203, ema 0.00000, oracc 0.24954, orien_loss 1.18076, qlmicf1 0.09369, qlmacf1 0.09837, ql_loss 1.12915, chxlmicf1 0.18126, chxlmacf1 0.22886, chx_loss 1.10228, chxlacc 0.48223, chxlrocaucmic 0.49209, chxlrocaucmac 0.51483, gacc 0.46495, gloss 0.70207, cxr14micf1 0.04674, cxr14macf1 0.10036, cxr14_loss 1.24219, vnbgmicf1 0.10376, vnbgmacf1 0.13158, vnbg_loss 9.85317, b1 0.00035, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01642, padchxlmicf1 0.00866, padchxlzmacf1 0.03346, padchxlzmicf1 0.02973, padchxl_loss 0.95435, padchxlz_loss 1.04093, 101.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00016, wmdcmp 0.00235, ema 0.00000, oracc 0.39299, qlmicf1 0.10562, qlmacf1 0.10664, chxlmicf1 0.20775, chxlmacf1 0.24746, chxlacc 0.48323, chxlrocaucmic 0.49743, chxlrocaucmac 0.51545, 35.03 secs\n",
      "Adjusting learning rate of group 0 to 2.1746e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 9.81562, a_loss 8.53890, cD 0.00010, wmdcmp 0.00237, ema 0.00000, oracc 0.41929, orien_loss 1.13229, qlmicf1 0.09708, qlmacf1 0.09947, ql_loss 1.12776, chxlmicf1 0.19741, chxlmacf1 0.24437, chx_loss 1.10044, chxlacc 0.48727, chxlrocaucmic 0.49729, chxlrocaucmac 0.51958, gacc 0.46314, gloss 0.69681, cxr14micf1 0.04890, cxr14macf1 0.10657, cxr14_loss 1.24248, vnbgmicf1 0.09994, vnbgmacf1 0.12748, vnbg_loss 9.64688, b1 0.00037, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01588, padchxlmicf1 0.00816, padchxlzmacf1 0.03059, padchxlzmicf1 0.03002, padchxl_loss 0.94637, padchxlz_loss 1.01201, 76.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00017, wmdcmp 0.00184, ema 0.00000, oracc 0.56185, qlmicf1 0.10996, qlmacf1 0.10958, chxlmicf1 0.22663, chxlmacf1 0.26050, chxlacc 0.48689, chxlrocaucmic 0.50499, chxlrocaucmac 0.51684, 36.15 secs\n",
      "Adjusting learning rate of group 0 to 4.7287e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 11.36616, a_loss 8.15310, cD 0.00020, wmdcmp 0.00096, ema 0.02314, oracc 0.67944, orien_loss 1.04580, qlmicf1 0.10563, qlmacf1 0.10423, ql_loss 1.12698, chxlmicf1 0.21477, chxlmacf1 0.25871, chx_loss 1.10022, chxlacc 0.49496, chxlrocaucmic 0.50570, chxlrocaucmac 0.52692, gacc 0.57143, gloss 0.68714, cxr14micf1 0.05920, cxr14macf1 0.11750, cxr14_loss 1.23961, vnbgmicf1 0.10649, vnbgmacf1 0.13554, vnbg_loss 9.12455, b1 0.00057, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01572, padchxlmicf1 0.00826, padchxlzmacf1 0.03094, padchxlzmicf1 0.02958, padchxl_loss 0.93867, padchxlz_loss 1.02137, 71.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00035, ema 0.03581, oracc 0.70085, qlmicf1 0.12519, qlmacf1 0.11493, chxlmicf1 0.26354, chxlmacf1 0.28571, chxlacc 0.49892, chxlrocaucmic 0.51882, chxlrocaucmac 0.52679, 34.21 secs\n",
      "Adjusting learning rate of group 0 to 1.0283e-05.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 10.73410, a_loss 7.23729, cD 0.00000, wmdcmp 0.00001, ema 0.04286, oracc 0.69039, orien_loss 0.90635, qlmicf1 0.12719, qlmacf1 0.11183, ql_loss 1.12297, chxlmicf1 0.24946, chxlmacf1 0.29033, chx_loss 1.09609, chxlacc 0.50614, chxlrocaucmic 0.52251, chxlrocaucmac 0.54205, gacc 0.54210, gloss 0.68065, cxr14micf1 0.07203, cxr14macf1 0.12591, cxr14_loss 1.23996, vnbgmicf1 0.10308, vnbgmacf1 0.12856, vnbg_loss 7.94006, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01599, padchxlmicf1 0.00957, padchxlzmacf1 0.03183, padchxlzmicf1 0.02952, padchxl_loss 0.92858, padchxlz_loss 1.01128, 73.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.66040, qlmicf1 0.15234, qlmacf1 0.12194, chxlmicf1 0.31813, chxlmacf1 0.32258, chxlacc 0.52560, chxlrocaucmic 0.55302, chxlrocaucmac 0.54666, 34.50 secs\n",
      "Adjusting learning rate of group 0 to 2.2361e-05.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 9.27372, a_loss 6.18485, cD 0.00293, wmdcmp 0.00049, ema 0.04357, oracc 0.72028, orien_loss 0.73279, qlmicf1 0.16444, qlmacf1 0.11935, ql_loss 1.11189, chxlmicf1 0.29842, chxlmacf1 0.32530, chx_loss 1.09624, chxlacc 0.53384, chxlrocaucmic 0.57229, chxlrocaucmac 0.57403, gacc 0.56229, gloss 0.66616, cxr14micf1 0.08079, cxr14macf1 0.14219, cxr14_loss 1.23773, vnbgmicf1 0.11602, vnbgmacf1 0.14794, vnbg_loss 6.74687, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01587, padchxlmicf1 0.01492, padchxlzmacf1 0.03190, padchxlzmicf1 0.03559, padchxl_loss 0.90891, padchxlz_loss 0.98962, 73.22 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.04299, wmdcmp 0.00686, ema 0.01253, oracc 0.81891, qlmicf1 0.21057, qlmacf1 0.13153, chxlmicf1 0.34243, chxlmacf1 0.34658, chxlacc 0.53780, chxlrocaucmic 0.59699, chxlrocaucmac 0.58533, 34.93 secs\n",
      "Adjusting learning rate of group 0 to 4.8625e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 7.63468, a_loss 5.08082, cD 0.06708, wmdcmp 0.01220, ema 0.02419, oracc 0.81416, orien_loss 0.54112, qlmicf1 0.24015, qlmacf1 0.13319, ql_loss 1.08188, chxlmicf1 0.34892, chxlmacf1 0.35060, chx_loss 1.08983, chxlacc 0.55731, chxlrocaucmic 0.63132, chxlrocaucmac 0.61341, gacc 0.64627, gloss 0.64293, cxr14micf1 0.11171, cxr14macf1 0.17580, cxr14_loss 1.23560, vnbgmicf1 0.17035, vnbgmacf1 0.18756, vnbg_loss 5.54660, b1 0.00144, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01992, padchxlmicf1 0.04039, padchxlzmacf1 0.03403, padchxlzmicf1 0.05781, padchxl_loss 0.84743, padchxlz_loss 0.92874, 74.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.08981, wmdcmp 0.01449, ema 0.00000, oracc 0.90475, qlmicf1 0.26428, qlmacf1 0.14225, chxlmicf1 0.39581, chxlmacf1 0.36522, chxlacc 0.57440, chxlrocaucmic 0.64685, chxlrocaucmac 0.61255, 34.52 secs\n",
      "Adjusting learning rate of group 0 to 1.0574e-04.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 6.14466, a_loss 3.94394, cD 0.07222, wmdcmp 0.01477, ema 0.02419, oracc 0.87935, orien_loss 0.37369, qlmicf1 0.24813, qlmacf1 0.14649, ql_loss 1.06940, chxlmicf1 0.37753, chxlmacf1 0.36144, chx_loss 1.06989, chxlacc 0.57219, chxlrocaucmic 0.65307, chxlrocaucmac 0.62242, gacc 0.70952, gloss 0.58765, cxr14micf1 0.13558, cxr14macf1 0.19116, cxr14_loss 1.22705, vnbgmicf1 0.21759, vnbgmacf1 0.21283, vnbg_loss 4.29118, b1 0.01455, b2 0.00222, b3 0.00000, b4 0.00000, padchxlmacf1 0.02316, padchxlmicf1 0.06156, padchxlzmacf1 0.03846, padchxlzmicf1 0.06687, padchxl_loss 0.75794, padchxlz_loss 0.87791, 75.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.13773, wmdcmp 0.02417, ema 0.03581, oracc 0.95296, qlmicf1 0.25626, qlmacf1 0.15567, chxlmicf1 0.41224, chxlmacf1 0.37212, chxlacc 0.57882, chxlrocaucmic 0.65522, chxlrocaucmac 0.61830, 35.05 secs\n",
      "Adjusting learning rate of group 0 to 2.2993e-04.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000230) ...\n",
      "loss 4.23484, a_loss 3.08366, cD 0.09804, wmdcmp 0.02307, ema 0.03585, oracc 0.93622, orien_loss 0.21721, qlmicf1 0.23247, qlmacf1 0.15062, ql_loss 1.05013, chxlmicf1 0.39211, chxlmacf1 0.36669, chx_loss 1.05700, chxlacc 0.57738, chxlrocaucmic 0.66371, chxlrocaucmac 0.63408, gacc 0.80370, gloss 0.49759, cxr14micf1 0.17032, cxr14macf1 0.21539, cxr14_loss 1.20578, vnbgmicf1 0.22409, vnbgmacf1 0.22694, vnbg_loss 3.43542, b1 0.06423, b2 0.04144, b3 0.02998, b4 0.02224, padchxlmacf1 0.03001, padchxlmicf1 0.07072, padchxlzmacf1 0.04913, padchxlzmicf1 0.07746, padchxl_loss 0.69728, padchxlz_loss 0.83549, 73.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.13773, wmdcmp 0.02417, ema 0.14593, oracc 0.96754, qlmicf1 0.22599, qlmacf1 0.15850, chxlmicf1 0.43338, chxlmacf1 0.38017, chxlacc 0.58537, chxlrocaucmic 0.67132, chxlrocaucmac 0.64055, 35.09 secs\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000500) ...\n",
      "loss 3.06499, a_loss 2.39258, cD 0.20799, wmdcmp 0.04053, ema 0.20038, oracc 0.96042, orien_loss 0.11938, qlmicf1 0.21754, qlmacf1 0.15614, ql_loss 1.04197, chxlmicf1 0.40086, chxlmacf1 0.37388, chx_loss 1.04675, chxlacc 0.59504, chxlrocaucmic 0.67928, chxlrocaucmac 0.65434, gacc 0.82549, gloss 0.41805, cxr14micf1 0.14678, cxr14macf1 0.19801, cxr14_loss 1.20290, vnbgmicf1 0.21383, vnbgmacf1 0.22496, vnbg_loss 2.77086, b1 0.16474, b2 0.09941, b3 0.06525, b4 0.04199, padchxlmacf1 0.03459, padchxlmicf1 0.06952, padchxlzmacf1 0.05724, padchxlzmicf1 0.06981, padchxl_loss 0.67689, padchxlz_loss 0.78879, 76.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.19518, wmdcmp 0.04038, ema 0.48433, oracc 0.97766, qlmicf1 0.22605, qlmacf1 0.16392, chxlmicf1 0.45734, chxlmacf1 0.39668, chxlacc 0.60790, chxlrocaucmic 0.71652, chxlrocaucmac 0.66013, 35.67 secs\n",
      "Adjusting learning rate of group 0 to 4.1174e-04.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000412) ...\n",
      "loss 6.58905, a_loss 1.87797, cD 0.39363, wmdcmp 0.06345, ema 0.37981, oracc 0.96721, orien_loss 0.08490, qlmicf1 0.23196, qlmacf1 0.16080, ql_loss 1.03238, chxlmicf1 0.41803, chxlmacf1 0.38681, chx_loss 1.02595, chxlacc 0.60911, chxlrocaucmic 0.69419, chxlrocaucmac 0.67216, gacc 0.87029, gloss 0.32125, cxr14micf1 0.18117, cxr14macf1 0.22348, cxr14_loss 1.18089, vnbgmicf1 0.31137, vnbgmacf1 0.27331, vnbg_loss 2.06569, b1 0.30786, b2 0.20187, b3 0.13122, b4 0.08727, padchxlmacf1 0.03716, padchxlmicf1 0.07739, padchxlzmacf1 0.05621, padchxlzmicf1 0.08646, padchxl_loss 0.65180, padchxlz_loss 0.75983, 74.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.25046, wmdcmp 0.04492, ema 0.51477, oracc 0.97930, qlmicf1 0.24252, qlmacf1 0.17258, chxlmicf1 0.45024, chxlmacf1 0.40023, chxlacc 0.62824, chxlrocaucmic 0.70267, chxlrocaucmac 0.67575, 35.14 secs\n",
      "Adjusting learning rate of group 0 to 3.3907e-04.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000339) ...\n",
      "loss 6.23505, a_loss 1.68355, cD 0.52631, wmdcmp 0.08136, ema 0.45014, oracc 0.97091, orien_loss 0.07097, qlmicf1 0.23714, qlmacf1 0.16517, ql_loss 1.02584, chxlmicf1 0.42253, chxlmacf1 0.39106, chx_loss 1.01876, chxlacc 0.61963, chxlrocaucmic 0.70349, chxlrocaucmac 0.68389, gacc 0.89371, gloss 0.27975, cxr14micf1 0.19850, cxr14macf1 0.23405, cxr14_loss 1.16201, vnbgmicf1 0.36957, vnbgmacf1 0.28450, vnbg_loss 1.71293, b1 0.28006, b2 0.18087, b3 0.11422, b4 0.07389, padchxlmacf1 0.03909, padchxlmicf1 0.08977, padchxlzmacf1 0.05740, padchxlzmicf1 0.09019, padchxl_loss 0.61603, padchxlz_loss 0.75371, 76.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.50440, wmdcmp 0.07395, ema 0.53626, oracc 0.97883, qlmicf1 0.24428, qlmacf1 0.17672, chxlmicf1 0.47060, chxlmacf1 0.41315, chxlacc 0.61909, chxlrocaucmic 0.72630, chxlrocaucmac 0.67680, 34.40 secs\n",
      "Adjusting learning rate of group 0 to 2.7922e-04.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000279) ...\n",
      "loss 5.97966, a_loss 1.57451, cD 0.62737, wmdcmp 0.09147, ema 0.47101, oracc 0.97234, orien_loss 0.07467, qlmicf1 0.24229, qlmacf1 0.16786, ql_loss 1.00993, chxlmicf1 0.42736, chxlmacf1 0.39435, chx_loss 1.01109, chxlacc 0.62496, chxlrocaucmic 0.70667, chxlrocaucmac 0.68559, gacc 0.89922, gloss 0.25881, cxr14micf1 0.20541, cxr14macf1 0.24122, cxr14_loss 1.15051, vnbgmicf1 0.38293, vnbgmacf1 0.30466, vnbg_loss 1.52876, b1 0.31705, b2 0.21398, b3 0.14572, b4 0.10438, padchxlmacf1 0.04121, padchxlmicf1 0.09633, padchxlzmacf1 0.06113, padchxlzmicf1 0.09795, padchxl_loss 0.61685, padchxlz_loss 0.75338, 76.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.64304, wmdcmp 0.09397, ema 0.55327, oracc 0.97789, qlmicf1 0.25391, qlmacf1 0.17879, chxlmicf1 0.46286, chxlmacf1 0.41162, chxlacc 0.60754, chxlrocaucmic 0.71912, chxlrocaucmac 0.67388, 35.58 secs\n",
      "Adjusting learning rate of group 0 to 2.2993e-04.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000230) ...\n",
      "loss 3.93436, a_loss 1.48315, cD 0.71273, wmdcmp 0.10268, ema 0.49371, oracc 0.97245, orien_loss 0.06341, qlmicf1 0.25362, qlmacf1 0.17095, ql_loss 1.00969, chxlmicf1 0.43296, chxlmacf1 0.39700, chx_loss 1.00968, chxlacc 0.62716, chxlrocaucmic 0.71022, chxlrocaucmac 0.68933, gacc 0.90229, gloss 0.25008, cxr14micf1 0.20612, cxr14macf1 0.23934, cxr14_loss 1.15961, vnbgmicf1 0.41531, vnbgmacf1 0.31454, vnbg_loss 1.39657, b1 0.35047, b2 0.24487, b3 0.16866, b4 0.11999, padchxlmacf1 0.04285, padchxlmicf1 0.09493, padchxlzmacf1 0.06087, padchxlzmicf1 0.09853, padchxl_loss 0.61639, padchxlz_loss 0.76503, 73.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.68928, wmdcmp 0.10015, ema 0.56132, oracc 0.97954, qlmicf1 0.25958, qlmacf1 0.18082, chxlmicf1 0.46191, chxlmacf1 0.41145, chxlacc 0.63636, chxlrocaucmic 0.71415, chxlrocaucmac 0.68627, 34.85 secs\n",
      "Adjusting learning rate of group 0 to 1.8935e-04.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 3.76830, a_loss 1.46806, cD 0.74828, wmdcmp 0.10708, ema 0.51130, oracc 0.97582, orien_loss 0.06209, qlmicf1 0.24830, qlmacf1 0.17033, ql_loss 1.00828, chxlmicf1 0.42556, chxlmacf1 0.39398, chx_loss 1.01285, chxlacc 0.62797, chxlrocaucmic 0.70982, chxlrocaucmac 0.68976, gacc 0.90552, gloss 0.24582, cxr14micf1 0.21219, cxr14macf1 0.24346, cxr14_loss 1.14357, vnbgmicf1 0.42562, vnbgmacf1 0.32323, vnbg_loss 1.34608, b1 0.37132, b2 0.26298, b3 0.18260, b4 0.12950, padchxlmacf1 0.04546, padchxlmicf1 0.10630, padchxlzmacf1 0.06650, padchxlzmicf1 0.11368, padchxl_loss 0.61806, padchxlz_loss 0.74215, 78.89 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.76373, wmdcmp 0.11091, ema 0.57296, oracc 0.98119, qlmicf1 0.26804, qlmacf1 0.18303, chxlmicf1 0.46842, chxlmacf1 0.41659, chxlacc 0.64111, chxlrocaucmic 0.72079, chxlrocaucmac 0.68964, 35.42 secs\n",
      "Adjusting learning rate of group 0 to 1.5592e-04.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000156) ...\n",
      "loss 3.75065, a_loss 1.42421, cD 0.77488, wmdcmp 0.10929, ema 0.51971, oracc 0.97555, orien_loss 0.05589, qlmicf1 0.25347, qlmacf1 0.17029, ql_loss 1.00429, chxlmicf1 0.43556, chxlmacf1 0.40031, chx_loss 1.00158, chxlacc 0.63251, chxlrocaucmic 0.71327, chxlrocaucmac 0.69426, gacc 0.91581, gloss 0.22498, cxr14micf1 0.21156, cxr14macf1 0.24511, cxr14_loss 1.15080, vnbgmicf1 0.42474, vnbgmacf1 0.32098, vnbg_loss 1.30115, b1 0.40206, b2 0.28392, b3 0.19471, b4 0.13428, padchxlmacf1 0.04289, padchxlmicf1 0.09973, padchxlzmacf1 0.06163, padchxlzmicf1 0.10214, padchxl_loss 0.57475, padchxlz_loss 0.73387, 74.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.82510, wmdcmp 0.11750, ema 0.58281, oracc 0.98260, qlmicf1 0.26146, qlmacf1 0.18161, chxlmicf1 0.46636, chxlmacf1 0.41354, chxlacc 0.63414, chxlrocaucmic 0.72189, chxlrocaucmac 0.68644, 35.97 secs\n",
      "Adjusting learning rate of group 0 to 1.2840e-04.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000128) ...\n",
      "loss 2.12461, a_loss 1.37138, cD 0.81090, wmdcmp 0.11428, ema 0.51962, oracc 0.97649, orien_loss 0.05572, qlmicf1 0.25345, qlmacf1 0.17219, ql_loss 1.00032, chxlmicf1 0.43573, chxlmacf1 0.39987, chx_loss 0.99995, chxlacc 0.63289, chxlrocaucmic 0.71449, chxlrocaucmac 0.69507, gacc 0.91543, gloss 0.21245, cxr14micf1 0.21846, cxr14macf1 0.24944, cxr14_loss 1.13783, vnbgmicf1 0.43521, vnbgmacf1 0.32414, vnbg_loss 1.24613, b1 0.38636, b2 0.27766, b3 0.19421, b4 0.13786, padchxlmacf1 0.04401, padchxlmicf1 0.10184, padchxlzmacf1 0.06699, padchxlzmicf1 0.10829, padchxl_loss 0.62143, padchxlz_loss 0.76741, 76.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.89915, wmdcmp 0.12550, ema 0.58639, oracc 0.98024, qlmicf1 0.26880, qlmacf1 0.18309, chxlmicf1 0.46370, chxlmacf1 0.41369, chxlacc 0.64051, chxlrocaucmic 0.71661, chxlrocaucmac 0.68842, 35.77 secs\n",
      "Adjusting learning rate of group 0 to 1.0574e-04.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 5.39678, a_loss 1.38853, cD 0.85268, wmdcmp 0.11858, ema 0.53903, oracc 0.97406, orien_loss 0.06147, qlmicf1 0.26040, qlmacf1 0.17335, ql_loss 0.99454, chxlmicf1 0.43426, chxlmacf1 0.39990, chx_loss 1.00713, chxlacc 0.63093, chxlrocaucmic 0.71350, chxlrocaucmac 0.69304, gacc 0.92076, gloss 0.21582, cxr14micf1 0.22291, cxr14macf1 0.24833, cxr14_loss 1.13152, vnbgmicf1 0.43420, vnbgmacf1 0.32108, vnbg_loss 1.25659, b1 0.39415, b2 0.28358, b3 0.19835, b4 0.13820, padchxlmacf1 0.04729, padchxlmicf1 0.09617, padchxlzmacf1 0.05943, padchxlzmicf1 0.09632, padchxl_loss 0.58798, padchxlz_loss 0.74361, 75.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.92408, wmdcmp 0.13066, ema 0.60788, oracc 0.98189, qlmicf1 0.26447, qlmacf1 0.18201, chxlmicf1 0.46600, chxlmacf1 0.41579, chxlacc 0.63169, chxlrocaucmic 0.72187, chxlrocaucmac 0.69209, 35.43 secs\n",
      "Adjusting learning rate of group 0 to 8.7073e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000087) ...\n",
      "loss 1.28001, a_loss 1.35438, cD 0.85389, wmdcmp 0.11865, ema 0.53467, oracc 0.97627, orien_loss 0.05286, qlmicf1 0.25815, qlmacf1 0.17284, ql_loss 1.00289, chxlmicf1 0.43687, chxlmacf1 0.40073, chx_loss 0.99849, chxlacc 0.63527, chxlrocaucmic 0.71528, chxlrocaucmac 0.69762, gacc 0.91039, gloss 0.22863, cxr14micf1 0.22403, cxr14macf1 0.25422, cxr14_loss 1.13169, vnbgmicf1 0.43169, vnbgmacf1 0.31995, vnbg_loss 1.23640, b1 0.40406, b2 0.29290, b3 0.20803, b4 0.14744, padchxlmacf1 0.04527, padchxlmicf1 0.10877, padchxlzmacf1 0.06115, padchxlzmicf1 0.10346, padchxl_loss 0.60091, padchxlz_loss 0.75247, 75.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.99555, wmdcmp 0.14097, ema 0.60072, oracc 0.98071, qlmicf1 0.25972, qlmacf1 0.18269, chxlmicf1 0.47149, chxlmacf1 0.41768, chxlacc 0.63365, chxlrocaucmic 0.72903, chxlrocaucmac 0.68947, 34.88 secs\n",
      "Adjusting learning rate of group 0 to 7.1704e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000072) ...\n",
      "loss 1.60666, a_loss 1.37374, cD 0.87363, wmdcmp 0.12307, ema 0.54329, oracc 0.97586, orien_loss 0.05634, qlmicf1 0.25716, qlmacf1 0.17370, ql_loss 1.00124, chxlmicf1 0.44095, chxlmacf1 0.40546, chx_loss 0.99880, chxlacc 0.63795, chxlrocaucmic 0.71914, chxlrocaucmac 0.70028, gacc 0.91943, gloss 0.20902, cxr14micf1 0.22930, cxr14macf1 0.25755, cxr14_loss 1.12416, vnbgmicf1 0.42569, vnbgmacf1 0.31728, vnbg_loss 1.21982, b1 0.41077, b2 0.29720, b3 0.21301, b4 0.15181, padchxlmacf1 0.04686, padchxlmicf1 0.10095, padchxlzmacf1 0.06312, padchxlzmicf1 0.10044, padchxl_loss 0.58528, padchxlz_loss 0.72817, 76.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.94386, wmdcmp 0.13350, ema 0.60877, oracc 0.98307, qlmicf1 0.26181, qlmacf1 0.18211, chxlmicf1 0.46656, chxlmacf1 0.41525, chxlacc 0.63816, chxlrocaucmic 0.72101, chxlrocaucmac 0.68861, 35.01 secs\n",
      "Adjusting learning rate of group 0 to 5.9047e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 2.04589, a_loss 1.31717, cD 0.89526, wmdcmp 0.12409, ema 0.54076, oracc 0.97336, orien_loss 0.05813, qlmicf1 0.25793, qlmacf1 0.17209, ql_loss 0.99086, chxlmicf1 0.44004, chxlmacf1 0.40388, chx_loss 0.99821, chxlacc 0.63709, chxlrocaucmic 0.71807, chxlrocaucmac 0.69921, gacc 0.92190, gloss 0.20535, cxr14micf1 0.22577, cxr14macf1 0.25492, cxr14_loss 1.12602, vnbgmicf1 0.43087, vnbgmacf1 0.32043, vnbg_loss 1.22555, b1 0.41516, b2 0.30600, b3 0.22066, b4 0.15742, padchxlmacf1 0.04907, padchxlmicf1 0.09856, padchxlzmacf1 0.06366, padchxlzmicf1 0.10373, padchxl_loss 0.61076, padchxlz_loss 0.75367, 74.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.98243, wmdcmp 0.13868, ema 0.61146, oracc 0.98071, qlmicf1 0.27319, qlmacf1 0.18437, chxlmicf1 0.47268, chxlmacf1 0.41881, chxlacc 0.63634, chxlrocaucmic 0.72836, chxlrocaucmac 0.69091, 35.72 secs\n",
      "Adjusting learning rate of group 0 to 4.8625e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 2.28817, a_loss 1.31436, cD 0.89665, wmdcmp 0.12471, ema 0.55533, oracc 0.97648, orien_loss 0.05776, qlmicf1 0.26213, qlmacf1 0.17377, ql_loss 1.00114, chxlmicf1 0.43811, chxlmacf1 0.40370, chx_loss 0.99930, chxlacc 0.63875, chxlrocaucmic 0.71567, chxlrocaucmac 0.69937, gacc 0.91695, gloss 0.22244, cxr14micf1 0.24110, cxr14macf1 0.26428, cxr14_loss 1.12168, vnbgmicf1 0.43173, vnbgmacf1 0.31891, vnbg_loss 1.20504, b1 0.41068, b2 0.29764, b3 0.21171, b4 0.15002, padchxlmacf1 0.04761, padchxlmicf1 0.10986, padchxlzmacf1 0.06387, padchxlzmicf1 0.10613, padchxl_loss 0.57055, padchxlz_loss 0.72268, 76.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00241, wmdcmp 0.14022, ema 0.59534, oracc 0.98236, qlmicf1 0.26857, qlmacf1 0.18398, chxlmicf1 0.46932, chxlmacf1 0.41733, chxlacc 0.63731, chxlrocaucmic 0.72525, chxlrocaucmac 0.69333, 35.37 secs\n",
      "Adjusting learning rate of group 0 to 4.0042e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 5.38853, a_loss 1.34463, cD 0.91104, wmdcmp 0.12552, ema 0.54164, oracc 0.97410, orien_loss 0.05834, qlmicf1 0.26382, qlmacf1 0.17481, ql_loss 0.99629, chxlmicf1 0.44023, chxlmacf1 0.40491, chx_loss 0.99869, chxlacc 0.63474, chxlrocaucmic 0.71621, chxlrocaucmac 0.69785, gacc 0.92627, gloss 0.20126, cxr14micf1 0.22945, cxr14macf1 0.25665, cxr14_loss 1.14329, vnbgmicf1 0.44253, vnbgmacf1 0.33258, vnbg_loss 1.19017, b1 0.41709, b2 0.30258, b3 0.21400, b4 0.15039, padchxlmacf1 0.04832, padchxlmicf1 0.10351, padchxlzmacf1 0.06882, padchxlzmicf1 0.10979, padchxl_loss 0.59523, padchxlz_loss 0.72769, 75.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.00387, wmdcmp 0.14222, ema 0.60251, oracc 0.98119, qlmicf1 0.27549, qlmacf1 0.18542, chxlmicf1 0.47223, chxlmacf1 0.42212, chxlacc 0.63809, chxlrocaucmic 0.72687, chxlrocaucmac 0.69728, 35.55 secs\n",
      "Adjusting learning rate of group 0 to 3.2974e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 5.44353, a_loss 1.29803, cD 0.90864, wmdcmp 0.12877, ema 0.55924, oracc 0.97484, orien_loss 0.05898, qlmicf1 0.26245, qlmacf1 0.17347, ql_loss 0.98802, chxlmicf1 0.43856, chxlmacf1 0.40427, chx_loss 0.99968, chxlacc 0.63553, chxlrocaucmic 0.71364, chxlrocaucmac 0.69610, gacc 0.92648, gloss 0.19859, cxr14micf1 0.23250, cxr14macf1 0.26038, cxr14_loss 1.12190, vnbgmicf1 0.43378, vnbgmacf1 0.32397, vnbg_loss 1.18510, b1 0.45095, b2 0.33397, b3 0.24633, b4 0.18511, padchxlmacf1 0.04593, padchxlmicf1 0.10666, padchxlzmacf1 0.06774, padchxlzmicf1 0.10517, padchxl_loss 0.58119, padchxlz_loss 0.73045, 74.60 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.01744, wmdcmp 0.14308, ema 0.60430, oracc 0.98307, qlmicf1 0.27140, qlmacf1 0.18380, chxlmicf1 0.47028, chxlmacf1 0.41717, chxlacc 0.63915, chxlrocaucmic 0.72665, chxlrocaucmac 0.69358, 35.02 secs\n",
      "Adjusting learning rate of group 0 to 2.7154e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.40411, a_loss 1.32716, cD 0.92851, wmdcmp 0.12937, ema 0.55121, oracc 0.97611, orien_loss 0.05348, qlmicf1 0.26463, qlmacf1 0.17570, ql_loss 1.00051, chxlmicf1 0.44014, chxlmacf1 0.40426, chx_loss 0.99652, chxlacc 0.63741, chxlrocaucmic 0.71839, chxlrocaucmac 0.70133, gacc 0.92000, gloss 0.21354, cxr14micf1 0.22403, cxr14macf1 0.25325, cxr14_loss 1.13689, vnbgmicf1 0.43641, vnbgmacf1 0.32959, vnbg_loss 1.18642, b1 0.42524, b2 0.30792, b3 0.21629, b4 0.15398, padchxlmacf1 0.04918, padchxlmicf1 0.10659, padchxlzmacf1 0.06344, padchxlzmicf1 0.09712, padchxl_loss 0.60839, padchxlz_loss 0.76692, 77.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05527, wmdcmp 0.14758, ema 0.61415, oracc 0.98354, qlmicf1 0.27140, qlmacf1 0.18468, chxlmicf1 0.47403, chxlmacf1 0.41988, chxlacc 0.63931, chxlrocaucmic 0.72919, chxlrocaucmac 0.69306, 35.50 secs\n",
      "Adjusting learning rate of group 0 to 2.2361e-05.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.15761, a_loss 1.33062, cD 0.95084, wmdcmp 0.13232, ema 0.54444, oracc 0.97518, orien_loss 0.05475, qlmicf1 0.26589, qlmacf1 0.17705, ql_loss 0.99227, chxlmicf1 0.43807, chxlmacf1 0.40248, chx_loss 0.99818, chxlacc 0.63593, chxlrocaucmic 0.71705, chxlrocaucmac 0.69736, gacc 0.93078, gloss 0.17943, cxr14micf1 0.21550, cxr14macf1 0.24742, cxr14_loss 1.13791, vnbgmicf1 0.43116, vnbgmacf1 0.32499, vnbg_loss 1.18740, b1 0.43890, b2 0.32929, b3 0.23926, b4 0.17621, padchxlmacf1 0.04790, padchxlmicf1 0.10700, padchxlzmacf1 0.06930, padchxlzmicf1 0.10637, padchxl_loss 0.58015, padchxlz_loss 0.75207, 74.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.04825, wmdcmp 0.14653, ema 0.59534, oracc 0.98071, qlmicf1 0.27284, qlmacf1 0.18515, chxlmicf1 0.47073, chxlmacf1 0.41717, chxlacc 0.64274, chxlrocaucmic 0.72725, chxlrocaucmac 0.69417, 34.98 secs\n",
      "Adjusting learning rate of group 0 to 1.8414e-05.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 1.57600, a_loss 1.30609, cD 0.94607, wmdcmp 0.13126, ema 0.54857, oracc 0.97626, orien_loss 0.05505, qlmicf1 0.26430, qlmacf1 0.17675, ql_loss 0.99096, chxlmicf1 0.44240, chxlmacf1 0.40527, chx_loss 0.99684, chxlacc 0.63805, chxlrocaucmic 0.71886, chxlrocaucmac 0.69990, gacc 0.91848, gloss 0.20490, cxr14micf1 0.22937, cxr14macf1 0.25671, cxr14_loss 1.10824, vnbgmicf1 0.44505, vnbgmacf1 0.33602, vnbg_loss 1.16636, b1 0.40576, b2 0.29860, b3 0.21787, b4 0.15954, padchxlmacf1 0.04861, padchxlmicf1 0.10100, padchxlzmacf1 0.06508, padchxlzmicf1 0.10009, padchxl_loss 0.61598, padchxlz_loss 0.76470, 76.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.06824, wmdcmp 0.14852, ema 0.61325, oracc 0.98213, qlmicf1 0.27062, qlmacf1 0.18485, chxlmicf1 0.47289, chxlmacf1 0.42054, chxlacc 0.63843, chxlrocaucmic 0.72748, chxlrocaucmac 0.69553, 35.18 secs\n",
      "Adjusting learning rate of group 0 to 1.5163e-05.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 2.15722, a_loss 1.27904, cD 0.94773, wmdcmp 0.13226, ema 0.55867, oracc 0.97395, orien_loss 0.05839, qlmicf1 0.26670, qlmacf1 0.17666, ql_loss 0.99891, chxlmicf1 0.43726, chxlmacf1 0.40329, chx_loss 0.99842, chxlacc 0.63634, chxlrocaucmic 0.71454, chxlrocaucmac 0.69736, gacc 0.93029, gloss 0.19730, cxr14micf1 0.22993, cxr14macf1 0.25139, cxr14_loss 1.12239, vnbgmicf1 0.43900, vnbgmacf1 0.33100, vnbg_loss 1.15581, b1 0.43440, b2 0.32218, b3 0.23666, b4 0.17600, padchxlmacf1 0.05101, padchxlmicf1 0.11283, padchxlzmacf1 0.06441, padchxlzmicf1 0.11054, padchxl_loss 0.55457, padchxlz_loss 0.72102, 74.60 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.04994, wmdcmp 0.14679, ema 0.61952, oracc 0.98166, qlmicf1 0.27162, qlmacf1 0.18539, chxlmicf1 0.47174, chxlmacf1 0.41923, chxlacc 0.63925, chxlrocaucmic 0.72716, chxlrocaucmac 0.69292, 35.49 secs\n",
      "Adjusting learning rate of group 0 to 1.2487e-05.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 2.13145, a_loss 1.32537, cD 0.96418, wmdcmp 0.13263, ema 0.57140, oracc 0.97445, orien_loss 0.05550, qlmicf1 0.26628, qlmacf1 0.17759, ql_loss 0.98716, chxlmicf1 0.44450, chxlmacf1 0.40864, chx_loss 0.99419, chxlacc 0.64025, chxlrocaucmic 0.72280, chxlrocaucmac 0.70254, gacc 0.92552, gloss 0.19941, cxr14micf1 0.22616, cxr14macf1 0.25433, cxr14_loss 1.12783, vnbgmicf1 0.44170, vnbgmacf1 0.32955, vnbg_loss 1.15415, b1 0.42203, b2 0.31572, b3 0.23611, b4 0.17724, padchxlmacf1 0.04936, padchxlmicf1 0.10767, padchxlzmacf1 0.06991, padchxlzmicf1 0.11422, padchxl_loss 0.60321, padchxlz_loss 0.76893, 76.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.06136, wmdcmp 0.14788, ema 0.60430, oracc 0.98236, qlmicf1 0.27163, qlmacf1 0.18517, chxlmicf1 0.47334, chxlmacf1 0.42030, chxlacc 0.63959, chxlrocaucmic 0.72787, chxlrocaucmac 0.69274, 35.77 secs\n",
      "Adjusting learning rate of group 0 to 1.0283e-05.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 1.38632, a_loss 1.28766, cD 0.92431, wmdcmp 0.12942, ema 0.55667, oracc 0.97636, orien_loss 0.04924, qlmicf1 0.26252, qlmacf1 0.17417, ql_loss 0.99127, chxlmicf1 0.44340, chxlmacf1 0.40726, chx_loss 0.99346, chxlacc 0.63978, chxlrocaucmic 0.71881, chxlrocaucmac 0.69938, gacc 0.92627, gloss 0.20186, cxr14micf1 0.23071, cxr14macf1 0.25848, cxr14_loss 1.11747, vnbgmicf1 0.43788, vnbgmacf1 0.32738, vnbg_loss 1.16105, b1 0.43692, b2 0.32202, b3 0.23371, b4 0.17154, padchxlmacf1 0.04690, padchxlmicf1 0.10878, padchxlzmacf1 0.06487, padchxlzmicf1 0.10583, padchxl_loss 0.54321, padchxlz_loss 0.69770, 75.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07972, wmdcmp 0.14987, ema 0.61683, oracc 0.98119, qlmicf1 0.27398, qlmacf1 0.18594, chxlmicf1 0.47398, chxlmacf1 0.42117, chxlacc 0.64171, chxlrocaucmic 0.72754, chxlrocaucmac 0.69429, 35.61 secs\n",
      "Adjusting learning rate of group 0 to 8.4678e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.31008, a_loss 1.27907, cD 0.94802, wmdcmp 0.13139, ema 0.55838, oracc 0.97327, orien_loss 0.05668, qlmicf1 0.26431, qlmacf1 0.17467, ql_loss 1.00107, chxlmicf1 0.44128, chxlmacf1 0.40494, chx_loss 0.99931, chxlacc 0.63885, chxlrocaucmic 0.71766, chxlrocaucmac 0.69772, gacc 0.92343, gloss 0.20013, cxr14micf1 0.21922, cxr14macf1 0.25058, cxr14_loss 1.13440, vnbgmicf1 0.43642, vnbgmacf1 0.32964, vnbg_loss 1.16632, b1 0.44111, b2 0.32756, b3 0.23944, b4 0.17426, padchxlmacf1 0.04717, padchxlmicf1 0.10756, padchxlzmacf1 0.06957, padchxlzmicf1 0.11556, padchxl_loss 0.58011, padchxlz_loss 0.73643, 75.16 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07359, wmdcmp 0.14958, ema 0.60788, oracc 0.98236, qlmicf1 0.27052, qlmacf1 0.18556, chxlmicf1 0.47236, chxlmacf1 0.42065, chxlacc 0.64091, chxlrocaucmic 0.72510, chxlrocaucmac 0.69200, 34.57 secs\n",
      "Adjusting learning rate of group 0 to 6.9731e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.37515, a_loss 1.31259, cD 0.95230, wmdcmp 0.13202, ema 0.55391, oracc 0.97503, orien_loss 0.05310, qlmicf1 0.26461, qlmacf1 0.17496, ql_loss 0.98966, chxlmicf1 0.43101, chxlmacf1 0.39866, chx_loss 1.00492, chxlacc 0.63482, chxlrocaucmic 0.71116, chxlrocaucmac 0.69252, gacc 0.92222, gloss 0.20552, cxr14micf1 0.22512, cxr14macf1 0.25603, cxr14_loss 1.11919, vnbgmicf1 0.44281, vnbgmacf1 0.32792, vnbg_loss 1.17283, b1 0.43322, b2 0.32267, b3 0.23906, b4 0.18079, padchxlmacf1 0.04756, padchxlmicf1 0.10077, padchxlzmacf1 0.06315, padchxlzmicf1 0.10411, padchxl_loss 0.60504, padchxlz_loss 0.75466, 76.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08283, wmdcmp 0.15057, ema 0.61594, oracc 0.98142, qlmicf1 0.27070, qlmacf1 0.18496, chxlmicf1 0.46942, chxlmacf1 0.41898, chxlacc 0.63642, chxlrocaucmic 0.72570, chxlrocaucmac 0.69256, 36.15 secs\n",
      "Adjusting learning rate of group 0 to 5.7423e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.05634, a_loss 1.29179, cD 0.93789, wmdcmp 0.12910, ema 0.55333, oracc 0.97725, orien_loss 0.05117, qlmicf1 0.26514, qlmacf1 0.17563, ql_loss 0.98404, chxlmicf1 0.43864, chxlmacf1 0.40400, chx_loss 0.99506, chxlacc 0.63734, chxlrocaucmic 0.71713, chxlrocaucmac 0.70125, gacc 0.92686, gloss 0.20141, cxr14micf1 0.22486, cxr14macf1 0.25374, cxr14_loss 1.12826, vnbgmicf1 0.42764, vnbgmacf1 0.31856, vnbg_loss 1.19641, b1 0.44402, b2 0.33508, b3 0.24653, b4 0.18402, padchxlmacf1 0.04950, padchxlmicf1 0.11117, padchxlzmacf1 0.06958, padchxlzmicf1 0.12085, padchxl_loss 0.59078, padchxlz_loss 0.72908, 74.44 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.08924, wmdcmp 0.15150, ema 0.61235, oracc 0.98260, qlmicf1 0.27050, qlmacf1 0.18488, chxlmicf1 0.47512, chxlmacf1 0.42224, chxlacc 0.63869, chxlrocaucmic 0.72911, chxlrocaucmac 0.69356, 35.37 secs\n",
      "Adjusting learning rate of group 0 to 4.7287e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 5.33852, a_loss 1.28220, cD 0.95952, wmdcmp 0.13225, ema 0.56076, oracc 0.97789, orien_loss 0.04654, qlmicf1 0.26232, qlmacf1 0.17471, ql_loss 0.99042, chxlmicf1 0.44473, chxlmacf1 0.40759, chx_loss 0.99181, chxlacc 0.63802, chxlrocaucmic 0.72275, chxlrocaucmac 0.70011, gacc 0.92495, gloss 0.19734, cxr14micf1 0.23504, cxr14macf1 0.25804, cxr14_loss 1.11062, vnbgmicf1 0.43132, vnbgmacf1 0.32136, vnbg_loss 1.17822, b1 0.43003, b2 0.32163, b3 0.23725, b4 0.17398, padchxlmacf1 0.04707, padchxlmicf1 0.10558, padchxlzmacf1 0.06590, padchxlzmicf1 0.10997, padchxl_loss 0.58763, padchxlz_loss 0.74145, 76.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08291, wmdcmp 0.15070, ema 0.60609, oracc 0.98307, qlmicf1 0.27144, qlmacf1 0.18498, chxlmicf1 0.47021, chxlmacf1 0.41943, chxlacc 0.63688, chxlrocaucmic 0.72648, chxlrocaucmac 0.69376, 35.36 secs\n",
      "Adjusting learning rate of group 0 to 3.8940e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.31412, a_loss 1.32467, cD 0.95069, wmdcmp 0.13241, ema 0.55778, oracc 0.97504, orien_loss 0.05479, qlmicf1 0.26206, qlmacf1 0.17545, ql_loss 0.99617, chxlmicf1 0.43609, chxlmacf1 0.40186, chx_loss 0.99759, chxlacc 0.63425, chxlrocaucmic 0.71558, chxlrocaucmac 0.70056, gacc 0.92762, gloss 0.19304, cxr14micf1 0.22693, cxr14macf1 0.25745, cxr14_loss 1.11716, vnbgmicf1 0.44382, vnbgmacf1 0.33686, vnbg_loss 1.15265, b1 0.45210, b2 0.33533, b3 0.24323, b4 0.17820, padchxlmacf1 0.05141, padchxlmicf1 0.11671, padchxlzmacf1 0.07078, padchxlzmicf1 0.12103, padchxl_loss 0.58035, padchxlz_loss 0.74522, 74.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05968, wmdcmp 0.14751, ema 0.62131, oracc 0.98142, qlmicf1 0.27190, qlmacf1 0.18589, chxlmicf1 0.47197, chxlmacf1 0.42016, chxlacc 0.64020, chxlrocaucmic 0.72615, chxlrocaucmac 0.69264, 35.96 secs\n",
      "Adjusting learning rate of group 0 to 3.2067e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 5.35086, a_loss 1.31679, cD 0.94937, wmdcmp 0.13091, ema 0.55710, oracc 0.97825, orien_loss 0.05128, qlmicf1 0.26216, qlmacf1 0.17450, ql_loss 0.99464, chxlmicf1 0.43601, chxlmacf1 0.40073, chx_loss 1.00170, chxlacc 0.63715, chxlrocaucmic 0.71740, chxlrocaucmac 0.69949, gacc 0.92667, gloss 0.19519, cxr14micf1 0.23690, cxr14macf1 0.26196, cxr14_loss 1.11583, vnbgmicf1 0.45324, vnbgmacf1 0.33961, vnbg_loss 1.15566, b1 0.45545, b2 0.33613, b3 0.24290, b4 0.17611, padchxlmacf1 0.04908, padchxlmicf1 0.10961, padchxlzmacf1 0.06791, padchxlzmicf1 0.12251, padchxl_loss 0.57623, padchxlz_loss 0.71712, 75.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08308, wmdcmp 0.15096, ema 0.61504, oracc 0.97977, qlmicf1 0.27441, qlmacf1 0.18585, chxlmicf1 0.47104, chxlmacf1 0.41948, chxlacc 0.63944, chxlrocaucmic 0.72515, chxlrocaucmac 0.69143, 35.12 secs\n",
      "Adjusting learning rate of group 0 to 2.6407e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.17130, a_loss 1.27956, cD 0.95632, wmdcmp 0.13204, ema 0.56552, oracc 0.97718, orien_loss 0.05060, qlmicf1 0.26677, qlmacf1 0.17596, ql_loss 0.99692, chxlmicf1 0.44057, chxlmacf1 0.40623, chx_loss 0.99392, chxlacc 0.63897, chxlrocaucmic 0.71813, chxlrocaucmac 0.70095, gacc 0.92514, gloss 0.20466, cxr14micf1 0.21824, cxr14macf1 0.24976, cxr14_loss 1.13771, vnbgmicf1 0.44785, vnbgmacf1 0.34061, vnbg_loss 1.16874, b1 0.45515, b2 0.33802, b3 0.24818, b4 0.18336, padchxlmacf1 0.05249, padchxlmicf1 0.11614, padchxlzmacf1 0.06809, padchxlzmicf1 0.11865, padchxl_loss 0.58672, padchxlz_loss 0.71840, 74.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07267, wmdcmp 0.14963, ema 0.60251, oracc 0.98119, qlmicf1 0.27206, qlmacf1 0.18607, chxlmicf1 0.47181, chxlmacf1 0.41986, chxlacc 0.63855, chxlrocaucmic 0.72735, chxlrocaucmac 0.69421, 35.99 secs\n",
      "Adjusting learning rate of group 0 to 2.1746e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.51629, a_loss 1.30529, cD 0.97682, wmdcmp 0.13422, ema 0.55130, oracc 0.97702, orien_loss 0.05338, qlmicf1 0.26094, qlmacf1 0.17459, ql_loss 0.99258, chxlmicf1 0.44159, chxlmacf1 0.40461, chx_loss 0.99161, chxlacc 0.63838, chxlrocaucmic 0.71859, chxlrocaucmac 0.70032, gacc 0.92381, gloss 0.19670, cxr14micf1 0.23406, cxr14macf1 0.25766, cxr14_loss 1.12157, vnbgmicf1 0.43734, vnbgmacf1 0.32631, vnbg_loss 1.16825, b1 0.44328, b2 0.32844, b3 0.23926, b4 0.17771, padchxlmacf1 0.05525, padchxlmicf1 0.11411, padchxlzmacf1 0.07054, padchxlzmicf1 0.11475, padchxl_loss 0.57503, padchxlz_loss 0.73824, 74.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07539, wmdcmp 0.15011, ema 0.61683, oracc 0.98119, qlmicf1 0.27042, qlmacf1 0.18421, chxlmicf1 0.47056, chxlmacf1 0.41916, chxlacc 0.63927, chxlrocaucmic 0.72648, chxlrocaucmac 0.69345, 35.00 secs\n",
      "Adjusting learning rate of group 0 to 1.7907e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.23239, a_loss 1.30551, cD 0.93402, wmdcmp 0.12935, ema 0.54638, oracc 0.97550, orien_loss 0.05550, qlmicf1 0.26230, qlmacf1 0.17363, ql_loss 0.99923, chxlmicf1 0.43129, chxlmacf1 0.39974, chx_loss 1.00166, chxlacc 0.63715, chxlrocaucmic 0.71191, chxlrocaucmac 0.69555, gacc 0.92686, gloss 0.20019, cxr14micf1 0.22555, cxr14macf1 0.25343, cxr14_loss 1.12812, vnbgmicf1 0.43402, vnbgmacf1 0.32641, vnbg_loss 1.16141, b1 0.42999, b2 0.31713, b3 0.23362, b4 0.17562, padchxlmacf1 0.04994, padchxlmicf1 0.10896, padchxlzmacf1 0.06891, padchxlzmicf1 0.11197, padchxl_loss 0.58235, padchxlz_loss 0.75883, 77.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08047, wmdcmp 0.15055, ema 0.61415, oracc 0.98142, qlmicf1 0.27074, qlmacf1 0.18484, chxlmicf1 0.47223, chxlmacf1 0.42029, chxlacc 0.63718, chxlrocaucmic 0.72804, chxlrocaucmac 0.69322, 35.96 secs\n",
      "Adjusting learning rate of group 0 to 1.4746e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.07722, a_loss 1.27302, cD 0.98039, wmdcmp 0.13404, ema 0.56714, oracc 0.97707, orien_loss 0.05102, qlmicf1 0.26372, qlmacf1 0.17570, ql_loss 0.98604, chxlmicf1 0.44106, chxlmacf1 0.40562, chx_loss 0.99228, chxlacc 0.63666, chxlrocaucmic 0.71905, chxlrocaucmac 0.70286, gacc 0.91638, gloss 0.21711, cxr14micf1 0.22666, cxr14macf1 0.25444, cxr14_loss 1.12496, vnbgmicf1 0.44168, vnbgmacf1 0.33013, vnbg_loss 1.13550, b1 0.43694, b2 0.32505, b3 0.23919, b4 0.17624, padchxlmacf1 0.04575, padchxlmicf1 0.10677, padchxlzmacf1 0.06169, padchxlzmicf1 0.10305, padchxl_loss 0.58112, padchxlz_loss 0.74306, 74.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07807, wmdcmp 0.15021, ema 0.62668, oracc 0.98283, qlmicf1 0.27099, qlmacf1 0.18518, chxlmicf1 0.46957, chxlmacf1 0.41800, chxlacc 0.63701, chxlrocaucmic 0.72679, chxlrocaucmac 0.69285, 35.60 secs\n",
      "Adjusting learning rate of group 0 to 1.2143e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.94831, a_loss 1.31087, cD 0.95859, wmdcmp 0.13166, ema 0.56174, oracc 0.97686, orien_loss 0.05232, qlmicf1 0.26617, qlmacf1 0.17564, ql_loss 0.98669, chxlmicf1 0.44066, chxlmacf1 0.40474, chx_loss 0.99443, chxlacc 0.63843, chxlrocaucmic 0.71974, chxlrocaucmac 0.69973, gacc 0.92819, gloss 0.19021, cxr14micf1 0.23315, cxr14macf1 0.25788, cxr14_loss 1.12034, vnbgmicf1 0.44786, vnbgmacf1 0.33686, vnbg_loss 1.16877, b1 0.43326, b2 0.31711, b3 0.22672, b4 0.16362, padchxlmacf1 0.04549, padchxlmicf1 0.10471, padchxlzmacf1 0.06766, padchxlzmicf1 0.11715, padchxl_loss 0.58495, padchxlz_loss 0.72970, 76.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08511, wmdcmp 0.15068, ema 0.60967, oracc 0.98377, qlmicf1 0.27234, qlmacf1 0.18531, chxlmicf1 0.47418, chxlmacf1 0.42214, chxlacc 0.64052, chxlrocaucmic 0.72905, chxlrocaucmac 0.69424, 34.91 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 100 \\\n",
    "        --batch-size 150 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,5e-4,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface-large\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-large-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 320\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface-large\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-large-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,9e-5,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 40\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184417_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-large-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,9e-5,32,1e-6\n",
      "1e-06 8 9e-05 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [224, 224], use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 40\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,3569879183697185499).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 40\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,1659353335112272599).pkl\n",
      "\tlen(question_datasets) = 59\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading CXR14 labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1442: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:01<00:00, 106773.94it/s]\n",
      "Done. Example answer: <s> aortic atheromatosis , lobar atelectasis , fibrotic band , hemidiaphragm elevation </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 112717.17it/s]\n",
      "Done. Example answer: <s> </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 62931.88it/s]\n",
      "Done. Example answer: <s> chronic changes loc retrocardiac , hilar enlargement loc hilar loc right </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc hemithorax , loc left </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:36,  5.30it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223910_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223910_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_39_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.4989.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184417_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_39_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.4989.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223910_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m23) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.98799, a_loss 1.21626, cD 1.08018, wmdcmp 0.14363, ema 0.55687, oracc 0.97683, orien_loss 0.05482, qlmicf1 0.28072, qlmacf1 0.17703, ql_loss 0.82793, chxlmicf1 0.45187, chxlmacf1 0.40827, chx_loss 0.98250, chxlacc 0.66068, chxlrocaucmic 0.72989, chxlrocaucmac 0.70643, gacc 0.91987, gloss 0.20426, cxr14micf1 0.23046, cxr14macf1 0.26062, cxr14_loss 1.11545, vnbgmicf1 0.42754, vnbgmacf1 0.32727, vnbg_loss 1.08714, b1 0.41786, b2 0.31525, b3 0.23648, b4 0.17937, padchxlmacf1 0.05070, padchxlmicf1 0.11457, padchxlzmacf1 0.06784, padchxlzmicf1 0.11152, padchxl_loss 0.37823, padchxlz_loss 0.52257, 167.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09484, wmdcmp 0.15334, ema 0.63115, oracc 0.98186, qlmicf1 0.29450, qlmacf1 0.18834, chxlmicf1 0.48204, chxlmacf1 0.42064, chxlacc 0.66679, chxlrocaucmic 0.73844, chxlrocaucmac 0.70049, 36.51 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.39351, a_loss 1.31508, cD 0.89597, wmdcmp 0.12248, ema 0.56644, oracc 0.97690, orien_loss 0.04926, qlmicf1 0.30608, qlmacf1 0.18372, ql_loss 0.81922, chxlmicf1 0.45340, chxlmacf1 0.40799, chx_loss 0.98120, chxlacc 0.66626, chxlrocaucmic 0.73098, chxlrocaucmac 0.70472, gacc 0.92320, gloss 0.20045, cxr14micf1 0.23765, cxr14macf1 0.26458, cxr14_loss 1.10929, vnbgmicf1 0.47259, vnbgmacf1 0.34075, vnbg_loss 1.04444, b1 0.43727, b2 0.32179, b3 0.23192, b4 0.16800, padchxlmacf1 0.04884, padchxlmicf1 0.11831, padchxlzmacf1 0.06949, padchxlzmicf1 0.12201, padchxl_loss 0.36335, padchxlz_loss 0.49285, 154.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08041, wmdcmp 0.15153, ema 0.63563, oracc 0.98468, qlmicf1 0.31760, qlmacf1 0.19232, chxlmicf1 0.48842, chxlmacf1 0.42475, chxlacc 0.66921, chxlrocaucmic 0.74617, chxlrocaucmac 0.70404, 36.89 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.29570, a_loss 1.31128, cD 0.95214, wmdcmp 0.12963, ema 0.56379, oracc 0.97830, orien_loss 0.04474, qlmicf1 0.30683, qlmacf1 0.18127, ql_loss 0.81222, chxlmicf1 0.45499, chxlmacf1 0.41054, chx_loss 0.97639, chxlacc 0.66439, chxlrocaucmic 0.73534, chxlrocaucmac 0.70828, gacc 0.93153, gloss 0.18057, cxr14micf1 0.26278, cxr14macf1 0.27518, cxr14_loss 1.10837, vnbgmicf1 0.46704, vnbgmacf1 0.33860, vnbg_loss 1.02420, b1 0.44761, b2 0.33357, b3 0.24683, b4 0.18440, padchxlmacf1 0.05132, padchxlmicf1 0.12408, padchxlzmacf1 0.06846, padchxlzmicf1 0.12491, padchxl_loss 0.35248, padchxlz_loss 0.48891, 154.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09380, wmdcmp 0.15307, ema 0.63026, oracc 0.98492, qlmicf1 0.33056, qlmacf1 0.19289, chxlmicf1 0.47958, chxlmacf1 0.42275, chxlacc 0.67401, chxlrocaucmic 0.73569, chxlrocaucmac 0.70732, 37.32 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.89148, a_loss 1.30446, cD 0.93069, wmdcmp 0.12680, ema 0.56143, oracc 0.98138, orien_loss 0.04248, qlmicf1 0.32045, qlmacf1 0.18018, ql_loss 0.80756, chxlmicf1 0.45806, chxlmacf1 0.41537, chx_loss 0.97633, chxlacc 0.66215, chxlrocaucmic 0.73532, chxlrocaucmac 0.71197, gacc 0.92522, gloss 0.18446, cxr14micf1 0.22977, cxr14macf1 0.25835, cxr14_loss 1.12248, vnbgmicf1 0.47306, vnbgmacf1 0.34343, vnbg_loss 1.02065, b1 0.42876, b2 0.31908, b3 0.23407, b4 0.17282, padchxlmacf1 0.05410, padchxlmicf1 0.13801, padchxlzmacf1 0.07209, padchxlzmicf1 0.14150, padchxl_loss 0.33255, padchxlz_loss 0.47910, 155.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08404, wmdcmp 0.15224, ema 0.63832, oracc 0.98421, qlmicf1 0.33967, qlmacf1 0.19450, chxlmicf1 0.48570, chxlmacf1 0.42822, chxlacc 0.66181, chxlrocaucmic 0.74519, chxlrocaucmac 0.70989, 37.83 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 5.11665, a_loss 1.29249, cD 0.93433, wmdcmp 0.13008, ema 0.56300, oracc 0.98028, orien_loss 0.04482, qlmicf1 0.33155, qlmacf1 0.17912, ql_loss 0.79981, chxlmicf1 0.45736, chxlmacf1 0.41576, chx_loss 0.96994, chxlacc 0.66175, chxlrocaucmic 0.73778, chxlrocaucmac 0.71438, gacc 0.93671, gloss 0.17795, cxr14micf1 0.25788, cxr14macf1 0.27388, cxr14_loss 1.09537, vnbgmicf1 0.47863, vnbgmacf1 0.34471, vnbg_loss 1.00471, b1 0.43751, b2 0.32489, b3 0.23525, b4 0.17029, padchxlmacf1 0.04991, padchxlmicf1 0.13471, padchxlzmacf1 0.06801, padchxlzmicf1 0.13875, padchxl_loss 0.34553, padchxlz_loss 0.47992, 154.67 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09009, wmdcmp 0.15287, ema 0.62757, oracc 0.98492, qlmicf1 0.36152, qlmacf1 0.19287, chxlmicf1 0.49108, chxlmacf1 0.43412, chxlacc 0.65758, chxlrocaucmic 0.75260, chxlrocaucmac 0.71450, 37.22 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 5.47517, a_loss 1.31547, cD 0.93173, wmdcmp 0.12846, ema 0.56892, oracc 0.98180, orien_loss 0.03535, qlmicf1 0.33495, qlmacf1 0.18337, ql_loss 0.80661, chxlmicf1 0.45385, chxlmacf1 0.41475, chx_loss 0.96867, chxlacc 0.65533, chxlrocaucmic 0.73344, chxlrocaucmac 0.71349, gacc 0.93581, gloss 0.17843, cxr14micf1 0.24162, cxr14macf1 0.26189, cxr14_loss 1.10816, vnbgmicf1 0.51167, vnbgmacf1 0.36536, vnbg_loss 0.95882, b1 0.43433, b2 0.32503, b3 0.24143, b4 0.18043, padchxlmacf1 0.05461, padchxlmicf1 0.15087, padchxlzmacf1 0.06863, padchxlzmicf1 0.14785, padchxl_loss 0.34052, padchxlz_loss 0.47168, 154.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07341, wmdcmp 0.15061, ema 0.63384, oracc 0.98492, qlmicf1 0.36557, qlmacf1 0.19194, chxlmicf1 0.48083, chxlmacf1 0.43015, chxlacc 0.66926, chxlrocaucmic 0.73688, chxlrocaucmac 0.71911, 37.34 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 1.71417, a_loss 1.29579, cD 0.94839, wmdcmp 0.12943, ema 0.56368, oracc 0.97671, orien_loss 0.04502, qlmicf1 0.33225, qlmacf1 0.17786, ql_loss 0.80548, chxlmicf1 0.45450, chxlmacf1 0.41333, chx_loss 0.97869, chxlacc 0.65322, chxlrocaucmic 0.73038, chxlrocaucmac 0.70754, gacc 0.88616, gloss 0.39049, cxr14micf1 0.23919, cxr14macf1 0.26156, cxr14_loss 1.11858, vnbgmicf1 0.48579, vnbgmacf1 0.35034, vnbg_loss 1.01758, b1 0.42486, b2 0.31227, b3 0.23078, b4 0.17099, padchxlmacf1 0.04369, padchxlmicf1 0.13264, padchxlzmacf1 0.06399, padchxlzmicf1 0.13941, padchxl_loss 0.33313, padchxlz_loss 0.45901, 155.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.05858, wmdcmp 0.15044, ema 0.64548, oracc 0.98303, qlmicf1 0.34369, qlmacf1 0.18768, chxlmicf1 0.50047, chxlmacf1 0.43727, chxlacc 0.63582, chxlrocaucmic 0.77596, chxlrocaucmac 0.71943, 37.48 secs\n",
      "Adjusting learning rate of group 0 to 9.0000e-05.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 5.12023, a_loss 1.29503, cD 0.93956, wmdcmp 0.12954, ema 0.56329, oracc 0.97786, orien_loss 0.05623, qlmicf1 0.34074, qlmacf1 0.18059, ql_loss 0.80100, chxlmicf1 0.46196, chxlmacf1 0.42120, chx_loss 0.96363, chxlacc 0.66097, chxlrocaucmic 0.74054, chxlrocaucmac 0.71978, gacc 0.93806, gloss 0.17230, cxr14micf1 0.25054, cxr14macf1 0.26304, cxr14_loss 1.09758, vnbgmicf1 0.51095, vnbgmacf1 0.36900, vnbg_loss 0.93332, b1 0.43681, b2 0.32668, b3 0.24619, b4 0.18805, padchxlmacf1 0.04409, padchxlmicf1 0.14784, padchxlzmacf1 0.06751, padchxlzmicf1 0.15453, padchxl_loss 0.32701, padchxlz_loss 0.46750, 155.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08636, wmdcmp 0.15555, ema 0.62578, oracc 0.98327, qlmicf1 0.33083, qlmacf1 0.18870, chxlmicf1 0.47573, chxlmacf1 0.43712, chxlacc 0.63461, chxlrocaucmic 0.73840, chxlrocaucmac 0.72743, 37.30 secs\n",
      "Adjusting learning rate of group 0 to 7.8194e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000078) ...\n",
      "loss 1.83774, a_loss 1.27882, cD 0.94996, wmdcmp 0.13126, ema 0.57388, oracc 0.97847, orien_loss 0.04116, qlmicf1 0.34972, qlmacf1 0.18586, ql_loss 0.79358, chxlmicf1 0.46835, chxlmacf1 0.42768, chx_loss 0.95045, chxlacc 0.66697, chxlrocaucmic 0.74958, chxlrocaucmac 0.72830, gacc 0.94955, gloss 0.13666, cxr14micf1 0.25631, cxr14macf1 0.27359, cxr14_loss 1.08946, vnbgmicf1 0.50630, vnbgmacf1 0.36737, vnbg_loss 0.93311, b1 0.43589, b2 0.32703, b3 0.24230, b4 0.17997, padchxlmacf1 0.05039, padchxlmicf1 0.16359, padchxlzmacf1 0.07402, padchxlzmicf1 0.17023, padchxl_loss 0.32034, padchxlz_loss 0.44786, 155.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.10944, wmdcmp 0.15615, ema 0.64637, oracc 0.98586, qlmicf1 0.36890, qlmacf1 0.19440, chxlmicf1 0.50167, chxlmacf1 0.44860, chxlacc 0.65265, chxlrocaucmic 0.76806, chxlrocaucmac 0.73195, 37.34 secs\n",
      "Adjusting learning rate of group 0 to 6.7936e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 5.23606, a_loss 1.28790, cD 0.95711, wmdcmp 0.13122, ema 0.58378, oracc 0.98153, orien_loss 0.03467, qlmicf1 0.35827, qlmacf1 0.19048, ql_loss 0.78390, chxlmicf1 0.47670, chxlmacf1 0.43445, chx_loss 0.93920, chxlacc 0.67386, chxlrocaucmic 0.75819, chxlrocaucmac 0.73882, gacc 0.95180, gloss 0.12867, cxr14micf1 0.25825, cxr14macf1 0.26914, cxr14_loss 1.08693, vnbgmicf1 0.52959, vnbgmacf1 0.38857, vnbg_loss 0.88472, b1 0.43444, b2 0.32902, b3 0.24593, b4 0.18530, padchxlmacf1 0.05370, padchxlmicf1 0.15338, padchxlzmacf1 0.07637, padchxlzmicf1 0.17303, padchxl_loss 0.34439, padchxlz_loss 0.45674, 155.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14000, wmdcmp 0.16140, ema 0.66428, oracc 0.98633, qlmicf1 0.39431, qlmacf1 0.19861, chxlmicf1 0.51167, chxlmacf1 0.45132, chxlacc 0.68681, chxlrocaucmic 0.77011, chxlrocaucmac 0.73697, 37.49 secs\n",
      "Adjusting learning rate of group 0 to 5.9024e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 1.69849, a_loss 1.25885, cD 0.99160, wmdcmp 0.13392, ema 0.59417, oracc 0.98085, orien_loss 0.04074, qlmicf1 0.36271, qlmacf1 0.19267, ql_loss 0.78081, chxlmicf1 0.48336, chxlmacf1 0.44143, chx_loss 0.92662, chxlacc 0.67981, chxlrocaucmic 0.76654, chxlrocaucmac 0.74559, gacc 0.95536, gloss 0.12282, cxr14micf1 0.30716, cxr14macf1 0.30576, cxr14_loss 1.03586, vnbgmicf1 0.53452, vnbgmacf1 0.39807, vnbg_loss 0.85435, b1 0.47252, b2 0.35304, b3 0.25669, b4 0.18730, padchxlmacf1 0.05311, padchxlmicf1 0.16125, padchxlzmacf1 0.07246, padchxlzmicf1 0.17813, padchxl_loss 0.32403, padchxlz_loss 0.44015, 154.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.11964, wmdcmp 0.15895, ema 0.65622, oracc 0.98633, qlmicf1 0.38637, qlmacf1 0.20327, chxlmicf1 0.51049, chxlmacf1 0.45196, chxlacc 0.69518, chxlrocaucmic 0.76752, chxlrocaucmac 0.74511, 37.58 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 2.00222, a_loss 1.26449, cD 0.99403, wmdcmp 0.13569, ema 0.57838, oracc 0.98245, orien_loss 0.03708, qlmicf1 0.37018, qlmacf1 0.19928, ql_loss 0.77905, chxlmicf1 0.48919, chxlmacf1 0.44662, chx_loss 0.91616, chxlacc 0.68379, chxlrocaucmic 0.76904, chxlrocaucmac 0.74919, gacc 0.96059, gloss 0.09701, cxr14micf1 0.31567, cxr14macf1 0.30406, cxr14_loss 1.02666, vnbgmicf1 0.54082, vnbgmacf1 0.40470, vnbg_loss 0.84671, b1 0.43323, b2 0.32743, b3 0.24753, b4 0.18682, padchxlmacf1 0.05389, padchxlmicf1 0.16314, padchxlzmacf1 0.07406, padchxlzmicf1 0.18253, padchxl_loss 0.31746, padchxlz_loss 0.44123, 155.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.09447, wmdcmp 0.15894, ema 0.65801, oracc 0.98704, qlmicf1 0.36047, qlmacf1 0.20097, chxlmicf1 0.50202, chxlmacf1 0.45324, chxlacc 0.67037, chxlrocaucmic 0.76644, chxlrocaucmac 0.74490, 36.90 secs\n",
      "Adjusting learning rate of group 0 to 4.4555e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 2.60327, a_loss 1.27023, cD 0.96789, wmdcmp 0.13237, ema 0.59630, oracc 0.98005, orien_loss 0.03434, qlmicf1 0.36799, qlmacf1 0.19726, ql_loss 0.76890, chxlmicf1 0.48471, chxlmacf1 0.44259, chx_loss 0.92572, chxlacc 0.68490, chxlrocaucmic 0.76998, chxlrocaucmac 0.74869, gacc 0.95759, gloss 0.10823, cxr14micf1 0.30779, cxr14macf1 0.30538, cxr14_loss 0.99937, vnbgmicf1 0.53057, vnbgmacf1 0.39360, vnbg_loss 0.84402, b1 0.42685, b2 0.31686, b3 0.23150, b4 0.16844, padchxlmacf1 0.05330, padchxlmicf1 0.15111, padchxlzmacf1 0.07029, padchxlzmicf1 0.16156, padchxl_loss 0.32810, padchxlz_loss 0.45148, 155.20 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.15272, wmdcmp 0.16396, ema 0.66070, oracc 0.98657, qlmicf1 0.38534, qlmacf1 0.20772, chxlmicf1 0.51316, chxlmacf1 0.45616, chxlacc 0.67017, chxlrocaucmic 0.78324, chxlrocaucmac 0.74615, 37.76 secs\n",
      "Adjusting learning rate of group 0 to 3.8710e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 1.64465, a_loss 1.24904, cD 1.02885, wmdcmp 0.13911, ema 0.59764, oracc 0.98509, orien_loss 0.02556, qlmicf1 0.36992, qlmacf1 0.19762, ql_loss 0.76650, chxlmicf1 0.48893, chxlmacf1 0.44688, chx_loss 0.91448, chxlacc 0.68707, chxlrocaucmic 0.77323, chxlrocaucmac 0.75359, gacc 0.96409, gloss 0.09534, cxr14micf1 0.30577, cxr14macf1 0.30435, cxr14_loss 1.02726, vnbgmicf1 0.54854, vnbgmacf1 0.39613, vnbg_loss 0.79644, b1 0.46480, b2 0.35078, b3 0.26314, b4 0.19710, padchxlmacf1 0.05219, padchxlmicf1 0.16153, padchxlzmacf1 0.06928, padchxlzmicf1 0.16734, padchxl_loss 0.29645, padchxlz_loss 0.42772, 155.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17602, wmdcmp 0.16569, ema 0.66428, oracc 0.98539, qlmicf1 0.36710, qlmacf1 0.20430, chxlmicf1 0.50069, chxlmacf1 0.45103, chxlacc 0.68225, chxlrocaucmic 0.76366, chxlrocaucmac 0.74838, 37.60 secs\n",
      "Adjusting learning rate of group 0 to 3.3632e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 1.18032, a_loss 1.24511, cD 1.02338, wmdcmp 0.13846, ema 0.59271, oracc 0.98158, orien_loss 0.03668, qlmicf1 0.37044, qlmacf1 0.20305, ql_loss 0.76512, chxlmicf1 0.49337, chxlmacf1 0.45066, chx_loss 0.91144, chxlacc 0.68907, chxlrocaucmic 0.77566, chxlrocaucmac 0.75626, gacc 0.96562, gloss 0.08511, cxr14micf1 0.31311, cxr14macf1 0.30675, cxr14_loss 1.00815, vnbgmicf1 0.54745, vnbgmacf1 0.41814, vnbg_loss 0.80376, b1 0.46653, b2 0.35377, b3 0.26663, b4 0.20288, padchxlmacf1 0.06478, padchxlmicf1 0.17800, padchxlzmacf1 0.08140, padchxlzmicf1 0.18832, padchxl_loss 0.32192, padchxlz_loss 0.44888, 156.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13761, wmdcmp 0.15978, ema 0.67323, oracc 0.98539, qlmicf1 0.38546, qlmacf1 0.20767, chxlmicf1 0.50997, chxlmacf1 0.45469, chxlacc 0.69788, chxlrocaucmic 0.76962, chxlrocaucmac 0.74810, 36.91 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.69491, a_loss 1.23825, cD 1.01674, wmdcmp 0.13841, ema 0.60011, oracc 0.98149, orien_loss 0.02340, qlmicf1 0.37230, qlmacf1 0.20148, ql_loss 0.76714, chxlmicf1 0.49676, chxlmacf1 0.45355, chx_loss 0.90293, chxlacc 0.69386, chxlrocaucmic 0.77861, chxlrocaucmac 0.76157, gacc 0.97050, gloss 0.08337, cxr14micf1 0.29360, cxr14macf1 0.29974, cxr14_loss 1.01212, vnbgmicf1 0.56333, vnbgmacf1 0.41287, vnbg_loss 0.78156, b1 0.48117, b2 0.36031, b3 0.26849, b4 0.20076, padchxlmacf1 0.05673, padchxlmicf1 0.16766, padchxlzmacf1 0.07375, padchxlzmicf1 0.16523, padchxl_loss 0.31345, padchxlz_loss 0.43134, 155.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.13693, wmdcmp 0.16291, ema 0.68308, oracc 0.98539, qlmicf1 0.37691, qlmacf1 0.20838, chxlmicf1 0.50787, chxlmacf1 0.45544, chxlacc 0.67618, chxlrocaucmic 0.77579, chxlrocaucmac 0.74809, 37.50 secs\n",
      "Adjusting learning rate of group 0 to 2.5387e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "cD 1.12979, wmdcmp 0.16164, ema 0.67234, oracc 0.98586, qlmicf1 0.38097, qlmacf1 0.20947, chxlmicf1 0.52096, chxlmacf1 0.46407, chxlacc 0.67515, chxlrocaucmic 0.79050, chxlrocaucmac 0.75226, 36.95 secs\n",
      "Adjusting learning rate of group 0 to 2.2057e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.34447, a_loss 1.24767, cD 1.01745, wmdcmp 0.13803, ema 0.59414, oracc 0.98253, orien_loss 0.03153, qlmicf1 0.37596, qlmacf1 0.20657, ql_loss 0.75906, chxlmicf1 0.50004, chxlmacf1 0.45679, chx_loss 0.89406, chxlacc 0.69500, chxlrocaucmic 0.78252, chxlrocaucmac 0.76316, gacc 0.96429, gloss 0.09289, cxr14micf1 0.30675, cxr14macf1 0.30818, cxr14_loss 0.99989, vnbgmicf1 0.55875, vnbgmacf1 0.41698, vnbg_loss 0.78679, b1 0.46176, b2 0.34951, b3 0.26156, b4 0.19425, padchxlmacf1 0.05480, padchxlmicf1 0.17220, padchxlzmacf1 0.07984, padchxlzmicf1 0.18564, padchxl_loss 0.31889, padchxlz_loss 0.45482, 155.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15634, wmdcmp 0.16450, ema 0.65712, oracc 0.98680, qlmicf1 0.38795, qlmacf1 0.21048, chxlmicf1 0.50809, chxlmacf1 0.45849, chxlacc 0.68393, chxlrocaucmic 0.77381, chxlrocaucmac 0.75377, 37.47 secs\n",
      "Adjusting learning rate of group 0 to 1.9163e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.85075, a_loss 1.23411, cD 1.03931, wmdcmp 0.14105, ema 0.59809, oracc 0.98241, orien_loss 0.03321, qlmicf1 0.37845, qlmacf1 0.20898, ql_loss 0.75725, chxlmicf1 0.49829, chxlmacf1 0.45649, chx_loss 0.90048, chxlacc 0.69420, chxlrocaucmic 0.78077, chxlrocaucmac 0.76533, gacc 0.97455, gloss 0.06920, cxr14micf1 0.28918, cxr14macf1 0.29788, cxr14_loss 1.01642, vnbgmicf1 0.56379, vnbgmacf1 0.42552, vnbg_loss 0.77228, b1 0.48358, b2 0.36689, b3 0.27192, b4 0.19909, padchxlmacf1 0.06529, padchxlmicf1 0.18376, padchxlzmacf1 0.08674, padchxlzmicf1 0.19416, padchxl_loss 0.31806, padchxlz_loss 0.45878, 155.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14183, wmdcmp 0.16183, ema 0.67592, oracc 0.98657, qlmicf1 0.39518, qlmacf1 0.21086, chxlmicf1 0.52815, chxlmacf1 0.46018, chxlacc 0.70346, chxlrocaucmic 0.79289, chxlrocaucmac 0.75176, 37.31 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.39014, a_loss 1.24183, cD 1.01569, wmdcmp 0.13891, ema 0.59966, oracc 0.98109, orien_loss 0.04094, qlmicf1 0.37867, qlmacf1 0.20858, ql_loss 0.75943, chxlmicf1 0.50157, chxlmacf1 0.45882, chx_loss 0.88919, chxlacc 0.69906, chxlrocaucmic 0.78681, chxlrocaucmac 0.76984, gacc 0.97072, gloss 0.08146, cxr14micf1 0.29890, cxr14macf1 0.30075, cxr14_loss 1.00651, vnbgmicf1 0.55728, vnbgmacf1 0.41211, vnbg_loss 0.77385, b1 0.46159, b2 0.35025, b3 0.26420, b4 0.19905, padchxlmacf1 0.06254, padchxlmicf1 0.17416, padchxlzmacf1 0.07183, padchxlzmicf1 0.17330, padchxl_loss 0.31447, padchxlz_loss 0.43871, 154.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15044, wmdcmp 0.16375, ema 0.67413, oracc 0.98586, qlmicf1 0.39598, qlmacf1 0.21295, chxlmicf1 0.52557, chxlmacf1 0.46594, chxlacc 0.69899, chxlrocaucmic 0.78833, chxlrocaucmac 0.75581, 37.64 secs\n",
      "Adjusting learning rate of group 0 to 1.4465e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.71203, a_loss 1.22294, cD 1.03590, wmdcmp 0.14146, ema 0.60807, oracc 0.98290, orien_loss 0.03052, qlmicf1 0.38171, qlmacf1 0.20951, ql_loss 0.74315, chxlmicf1 0.50319, chxlmacf1 0.45966, chx_loss 0.88957, chxlacc 0.70009, chxlrocaucmic 0.78669, chxlrocaucmac 0.76921, gacc 0.96892, gloss 0.07670, cxr14micf1 0.32759, cxr14macf1 0.31861, cxr14_loss 0.98550, vnbgmicf1 0.56791, vnbgmacf1 0.41772, vnbg_loss 0.77242, b1 0.44698, b2 0.33176, b3 0.24260, b4 0.17560, padchxlmacf1 0.06327, padchxlmicf1 0.17593, padchxlzmacf1 0.07787, padchxlzmicf1 0.19548, padchxl_loss 0.29990, padchxlz_loss 0.43631, 154.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15827, wmdcmp 0.16394, ema 0.67681, oracc 0.98657, qlmicf1 0.39232, qlmacf1 0.21172, chxlmicf1 0.51717, chxlmacf1 0.46222, chxlacc 0.68903, chxlrocaucmic 0.78163, chxlrocaucmac 0.75372, 37.57 secs\n",
      "Adjusting learning rate of group 0 to 1.2568e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.16904, a_loss 1.23212, cD 1.03559, wmdcmp 0.13975, ema 0.61704, oracc 0.98143, orien_loss 0.03769, qlmicf1 0.38482, qlmacf1 0.20958, ql_loss 0.75648, chxlmicf1 0.50335, chxlmacf1 0.46167, chx_loss 0.88403, chxlacc 0.70265, chxlrocaucmic 0.78981, chxlrocaucmac 0.77326, gacc 0.97210, gloss 0.08351, cxr14micf1 0.32084, cxr14macf1 0.31334, cxr14_loss 0.99635, vnbgmicf1 0.56537, vnbgmacf1 0.42486, vnbg_loss 0.76243, b1 0.47054, b2 0.35383, b3 0.26188, b4 0.19026, padchxlmacf1 0.06693, padchxlmicf1 0.17713, padchxlzmacf1 0.07791, padchxlzmicf1 0.18010, padchxl_loss 0.31092, padchxlz_loss 0.44969, 155.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18138, wmdcmp 0.16547, ema 0.68756, oracc 0.98610, qlmicf1 0.39552, qlmacf1 0.21330, chxlmicf1 0.53436, chxlmacf1 0.46448, chxlacc 0.71193, chxlrocaucmic 0.79647, chxlrocaucmac 0.75575, 37.42 secs\n",
      "Adjusting learning rate of group 0 to 1.0919e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 5.03008, a_loss 1.23485, cD 1.04118, wmdcmp 0.14202, ema 0.59977, oracc 0.98341, orien_loss 0.03131, qlmicf1 0.38279, qlmacf1 0.20928, ql_loss 0.74977, chxlmicf1 0.51170, chxlmacf1 0.46565, chx_loss 0.87706, chxlacc 0.70536, chxlrocaucmic 0.79336, chxlrocaucmac 0.77393, gacc 0.97522, gloss 0.06030, cxr14micf1 0.33273, cxr14macf1 0.32492, cxr14_loss 0.97118, vnbgmicf1 0.55921, vnbgmacf1 0.41487, vnbg_loss 0.76312, b1 0.45330, b2 0.34985, b3 0.26813, b4 0.20453, padchxlmacf1 0.06659, padchxlmicf1 0.18113, padchxlzmacf1 0.08177, padchxlzmicf1 0.19180, padchxl_loss 0.32482, padchxlz_loss 0.45189, 154.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16204, wmdcmp 0.16414, ema 0.68218, oracc 0.98751, qlmicf1 0.39190, qlmacf1 0.21212, chxlmicf1 0.51734, chxlmacf1 0.45941, chxlacc 0.69417, chxlrocaucmic 0.78357, chxlrocaucmac 0.75299, 37.55 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.80388, a_loss 1.22673, cD 1.02705, wmdcmp 0.13754, ema 0.60762, oracc 0.98265, orien_loss 0.02709, qlmicf1 0.38317, qlmacf1 0.21088, ql_loss 0.75018, chxlmicf1 0.50773, chxlmacf1 0.46310, chx_loss 0.88024, chxlacc 0.70460, chxlrocaucmic 0.79078, chxlrocaucmac 0.77238, gacc 0.97410, gloss 0.07196, cxr14micf1 0.33474, cxr14macf1 0.32729, cxr14_loss 0.97441, vnbgmicf1 0.55352, vnbgmacf1 0.40994, vnbg_loss 0.75319, b1 0.46511, b2 0.35823, b3 0.26900, b4 0.20210, padchxlmacf1 0.06373, padchxlmicf1 0.17604, padchxlzmacf1 0.07279, padchxlzmicf1 0.17743, padchxl_loss 0.31908, padchxlz_loss 0.43153, 155.03 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.14923, wmdcmp 0.16325, ema 0.68039, oracc 0.98563, qlmicf1 0.40137, qlmacf1 0.21586, chxlmicf1 0.52423, chxlmacf1 0.46257, chxlacc 0.70522, chxlrocaucmic 0.78566, chxlrocaucmac 0.75561, 37.60 secs\n",
      "Adjusting learning rate of group 0 to 8.2424e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 4.87379, a_loss 1.22946, cD 1.02877, wmdcmp 0.14108, ema 0.62140, oracc 0.98265, orien_loss 0.02802, qlmicf1 0.38456, qlmacf1 0.21175, ql_loss 0.74914, chxlmicf1 0.50770, chxlmacf1 0.46451, chx_loss 0.88309, chxlacc 0.70473, chxlrocaucmic 0.79253, chxlrocaucmac 0.77481, gacc 0.97793, gloss 0.06393, cxr14micf1 0.32853, cxr14macf1 0.32138, cxr14_loss 0.97649, vnbgmicf1 0.56488, vnbgmacf1 0.41916, vnbg_loss 0.73973, b1 0.43427, b2 0.32468, b3 0.24336, b4 0.18400, padchxlmacf1 0.06142, padchxlmicf1 0.17634, padchxlzmacf1 0.08144, padchxlzmicf1 0.17885, padchxl_loss 0.31040, padchxlz_loss 0.43062, 155.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15360, wmdcmp 0.16373, ema 0.68935, oracc 0.98610, qlmicf1 0.39299, qlmacf1 0.21367, chxlmicf1 0.52366, chxlmacf1 0.46464, chxlacc 0.69484, chxlrocaucmic 0.78885, chxlrocaucmac 0.75633, 37.26 secs\n",
      "Adjusting learning rate of group 0 to 7.1611e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.21574, a_loss 1.21942, cD 1.02313, wmdcmp 0.13944, ema 0.61603, oracc 0.98483, orien_loss 0.02424, qlmicf1 0.38962, qlmacf1 0.21605, ql_loss 0.74948, chxlmicf1 0.51099, chxlmacf1 0.46619, chx_loss 0.87500, chxlacc 0.70539, chxlrocaucmic 0.79425, chxlrocaucmac 0.77533, gacc 0.98041, gloss 0.05833, cxr14micf1 0.34403, cxr14macf1 0.32752, cxr14_loss 0.95194, vnbgmicf1 0.57176, vnbgmacf1 0.43158, vnbg_loss 0.74164, b1 0.45863, b2 0.34757, b3 0.26142, b4 0.19567, padchxlmacf1 0.06080, padchxlmicf1 0.17100, padchxlzmacf1 0.07729, padchxlzmicf1 0.17265, padchxl_loss 0.30498, padchxlz_loss 0.44423, 155.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18049, wmdcmp 0.16579, ema 0.68577, oracc 0.98680, qlmicf1 0.40052, qlmacf1 0.21512, chxlmicf1 0.53153, chxlmacf1 0.46333, chxlacc 0.70651, chxlrocaucmic 0.79583, chxlrocaucmac 0.75482, 37.78 secs\n",
      "Adjusting learning rate of group 0 to 6.2217e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.94464, a_loss 1.22374, cD 1.00664, wmdcmp 0.13746, ema 0.61256, oracc 0.98483, orien_loss 0.02609, qlmicf1 0.38374, qlmacf1 0.21380, ql_loss 0.75230, chxlmicf1 0.50920, chxlmacf1 0.46596, chx_loss 0.87786, chxlacc 0.70332, chxlrocaucmic 0.79392, chxlrocaucmac 0.77568, gacc 0.97411, gloss 0.07056, cxr14micf1 0.31335, cxr14macf1 0.31590, cxr14_loss 0.98694, vnbgmicf1 0.58128, vnbgmacf1 0.43945, vnbg_loss 0.73464, b1 0.45138, b2 0.34198, b3 0.25741, b4 0.19401, padchxlmacf1 0.06360, padchxlmicf1 0.18034, padchxlzmacf1 0.07498, padchxlzmicf1 0.17499, padchxl_loss 0.32352, padchxlz_loss 0.43032, 155.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15305, wmdcmp 0.16341, ema 0.66517, oracc 0.98680, qlmicf1 0.39612, qlmacf1 0.21466, chxlmicf1 0.52282, chxlmacf1 0.46452, chxlacc 0.69848, chxlrocaucmic 0.78589, chxlrocaucmac 0.75771, 37.24 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.43586, a_loss 1.21333, cD 1.01796, wmdcmp 0.13887, ema 0.61087, oracc 0.98204, orien_loss 0.03590, qlmicf1 0.38703, qlmacf1 0.21568, ql_loss 0.74967, chxlmicf1 0.50766, chxlmacf1 0.46482, chx_loss 0.88345, chxlacc 0.70541, chxlrocaucmic 0.79112, chxlrocaucmac 0.77432, gacc 0.97748, gloss 0.05530, cxr14micf1 0.31810, cxr14macf1 0.31339, cxr14_loss 0.99723, vnbgmicf1 0.57214, vnbgmacf1 0.41371, vnbg_loss 0.73125, b1 0.46641, b2 0.35289, b3 0.26416, b4 0.19879, padchxlmacf1 0.06266, padchxlmicf1 0.19540, padchxlzmacf1 0.07574, padchxlzmicf1 0.18954, padchxl_loss 0.29266, padchxlz_loss 0.41003, 152.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16514, wmdcmp 0.16507, ema 0.67592, oracc 0.98657, qlmicf1 0.40140, qlmacf1 0.21501, chxlmicf1 0.53254, chxlmacf1 0.46809, chxlacc 0.70096, chxlrocaucmic 0.79839, chxlrocaucmac 0.75722, 35.61 secs\n",
      "Adjusting learning rate of group 0 to 4.6965e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.88269, a_loss 1.23296, cD 1.04102, wmdcmp 0.14345, ema 0.61554, oracc 0.98601, orien_loss 0.02696, qlmicf1 0.38320, qlmacf1 0.21087, ql_loss 0.74963, chxlmicf1 0.51441, chxlmacf1 0.46969, chx_loss 0.87007, chxlacc 0.70926, chxlrocaucmic 0.79752, chxlrocaucmac 0.78122, gacc 0.97432, gloss 0.05921, cxr14micf1 0.32758, cxr14macf1 0.31791, cxr14_loss 0.97715, vnbgmicf1 0.56802, vnbgmacf1 0.42379, vnbg_loss 0.73740, b1 0.45142, b2 0.34468, b3 0.26234, b4 0.19822, padchxlmacf1 0.06098, padchxlmicf1 0.17694, padchxlzmacf1 0.07890, padchxlzmicf1 0.19303, padchxl_loss 0.29887, padchxlz_loss 0.41889, 152.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16942, wmdcmp 0.16492, ema 0.66338, oracc 0.98657, qlmicf1 0.40325, qlmacf1 0.21425, chxlmicf1 0.53516, chxlmacf1 0.46791, chxlacc 0.70687, chxlrocaucmic 0.79891, chxlrocaucmac 0.75830, 35.98 secs\n",
      "Adjusting learning rate of group 0 to 4.0804e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.64395, a_loss 1.22567, cD 1.04619, wmdcmp 0.14177, ema 0.62119, oracc 0.98511, orien_loss 0.02212, qlmicf1 0.38684, qlmacf1 0.21400, ql_loss 0.74591, chxlmicf1 0.51461, chxlmacf1 0.47056, chx_loss 0.87404, chxlacc 0.70860, chxlrocaucmic 0.79679, chxlrocaucmac 0.77806, gacc 0.97254, gloss 0.07776, cxr14micf1 0.33212, cxr14macf1 0.32385, cxr14_loss 0.95878, vnbgmicf1 0.56988, vnbgmacf1 0.42220, vnbg_loss 0.71313, b1 0.44315, b2 0.33552, b3 0.24852, b4 0.18652, padchxlmacf1 0.06709, padchxlmicf1 0.19034, padchxlzmacf1 0.08281, padchxlzmicf1 0.18893, padchxl_loss 0.30613, padchxlz_loss 0.43350, 153.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16600, wmdcmp 0.16496, ema 0.67055, oracc 0.98728, qlmicf1 0.39161, qlmacf1 0.21438, chxlmicf1 0.52560, chxlmacf1 0.46533, chxlacc 0.69089, chxlrocaucmic 0.79354, chxlrocaucmac 0.75724, 36.66 secs\n",
      "Adjusting learning rate of group 0 to 3.5451e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.98827, a_loss 1.22605, cD 1.00572, wmdcmp 0.13729, ema 0.62725, oracc 0.98404, orien_loss 0.03182, qlmicf1 0.38925, qlmacf1 0.21727, ql_loss 0.74817, chxlmicf1 0.51124, chxlmacf1 0.46841, chx_loss 0.87277, chxlacc 0.70689, chxlrocaucmic 0.79409, chxlrocaucmac 0.77857, gacc 0.97387, gloss 0.07014, cxr14micf1 0.32281, cxr14macf1 0.31770, cxr14_loss 0.98503, vnbgmicf1 0.56873, vnbgmacf1 0.42919, vnbg_loss 0.75120, b1 0.48079, b2 0.36779, b3 0.27621, b4 0.21024, padchxlmacf1 0.06734, padchxlmicf1 0.18349, padchxlzmacf1 0.07792, padchxlzmicf1 0.19158, padchxl_loss 0.29255, padchxlz_loss 0.41578, 153.53 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.16878, wmdcmp 0.16514, ema 0.67234, oracc 0.98657, qlmicf1 0.39950, qlmacf1 0.21634, chxlmicf1 0.52147, chxlmacf1 0.46404, chxlacc 0.69745, chxlrocaucmic 0.78713, chxlrocaucmac 0.75956, 36.86 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.66280, a_loss 1.20740, cD 1.03754, wmdcmp 0.13981, ema 0.61928, oracc 0.98438, orien_loss 0.03019, qlmicf1 0.39077, qlmacf1 0.21604, ql_loss 0.74367, chxlmicf1 0.51070, chxlmacf1 0.46484, chx_loss 0.87771, chxlacc 0.70807, chxlrocaucmic 0.79306, chxlrocaucmac 0.77422, gacc 0.97500, gloss 0.06062, cxr14micf1 0.32351, cxr14macf1 0.31734, cxr14_loss 0.96941, vnbgmicf1 0.56332, vnbgmacf1 0.41841, vnbg_loss 0.73679, b1 0.45409, b2 0.34767, b3 0.26304, b4 0.20025, padchxlmacf1 0.06375, padchxlmicf1 0.17881, padchxlzmacf1 0.07704, padchxlzmicf1 0.18702, padchxl_loss 0.30595, padchxlz_loss 0.43791, 154.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16619, wmdcmp 0.16453, ema 0.68845, oracc 0.98704, qlmicf1 0.39489, qlmacf1 0.21533, chxlmicf1 0.52134, chxlmacf1 0.46425, chxlacc 0.68976, chxlrocaucmic 0.78815, chxlrocaucmac 0.75773, 36.88 secs\n",
      "Adjusting learning rate of group 0 to 2.6760e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.05596, a_loss 1.22897, cD 1.04097, wmdcmp 0.14194, ema 0.62061, oracc 0.98184, orien_loss 0.03264, qlmicf1 0.38947, qlmacf1 0.21687, ql_loss 0.74597, chxlmicf1 0.51139, chxlmacf1 0.46861, chx_loss 0.87008, chxlacc 0.70798, chxlrocaucmic 0.79511, chxlrocaucmac 0.77893, gacc 0.97635, gloss 0.06707, cxr14micf1 0.31297, cxr14macf1 0.31493, cxr14_loss 0.99370, vnbgmicf1 0.57197, vnbgmacf1 0.42529, vnbg_loss 0.71202, b1 0.45836, b2 0.35272, b3 0.26475, b4 0.19640, padchxlmacf1 0.06367, padchxlmicf1 0.17882, padchxlzmacf1 0.08668, padchxlzmicf1 0.18824, padchxl_loss 0.30074, padchxlz_loss 0.44236, 153.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17177, wmdcmp 0.16552, ema 0.67771, oracc 0.98704, qlmicf1 0.40529, qlmacf1 0.21741, chxlmicf1 0.52618, chxlmacf1 0.46694, chxlacc 0.69722, chxlrocaucmic 0.79158, chxlrocaucmac 0.76048, 36.97 secs\n",
      "Adjusting learning rate of group 0 to 2.3250e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.63566, a_loss 1.22609, cD 1.01906, wmdcmp 0.13861, ema 0.61592, oracc 0.98693, orien_loss 0.02707, qlmicf1 0.38948, qlmacf1 0.21834, ql_loss 0.75118, chxlmicf1 0.51021, chxlmacf1 0.46745, chx_loss 0.87562, chxlacc 0.70553, chxlrocaucmic 0.79150, chxlrocaucmac 0.77590, gacc 0.97746, gloss 0.06131, cxr14micf1 0.30981, cxr14macf1 0.31185, cxr14_loss 0.99053, vnbgmicf1 0.56628, vnbgmacf1 0.42558, vnbg_loss 0.72782, b1 0.47848, b2 0.36353, b3 0.27188, b4 0.20124, padchxlmacf1 0.07442, padchxlmicf1 0.19205, padchxlzmacf1 0.07765, padchxlzmicf1 0.18788, padchxl_loss 0.30760, padchxlz_loss 0.43229, 154.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16627, wmdcmp 0.16440, ema 0.68218, oracc 0.98704, qlmicf1 0.39811, qlmacf1 0.21661, chxlmicf1 0.52752, chxlmacf1 0.46665, chxlacc 0.69742, chxlrocaucmic 0.79399, chxlrocaucmac 0.75936, 36.85 secs\n",
      "Adjusting learning rate of group 0 to 2.0200e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.70121, a_loss 1.22582, cD 1.03671, wmdcmp 0.14157, ema 0.61689, oracc 0.98521, orien_loss 0.02579, qlmicf1 0.38715, qlmacf1 0.21422, ql_loss 0.74405, chxlmicf1 0.51469, chxlmacf1 0.47084, chx_loss 0.86914, chxlacc 0.70843, chxlrocaucmic 0.79700, chxlrocaucmac 0.77873, gacc 0.97455, gloss 0.06798, cxr14micf1 0.32190, cxr14macf1 0.31720, cxr14_loss 0.97717, vnbgmicf1 0.57037, vnbgmacf1 0.42792, vnbg_loss 0.71947, b1 0.45624, b2 0.34363, b3 0.25830, b4 0.19529, padchxlmacf1 0.06360, padchxlmicf1 0.17619, padchxlzmacf1 0.08126, padchxlzmicf1 0.17624, padchxl_loss 0.30994, padchxlz_loss 0.44010, 154.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18217, wmdcmp 0.16646, ema 0.67323, oracc 0.98751, qlmicf1 0.39671, qlmacf1 0.21635, chxlmicf1 0.52758, chxlmacf1 0.46710, chxlacc 0.70062, chxlrocaucmic 0.79156, chxlrocaucmac 0.75918, 36.92 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.18488, a_loss 1.22159, cD 1.05559, wmdcmp 0.14335, ema 0.62253, oracc 0.98411, orien_loss 0.02446, qlmicf1 0.38876, qlmacf1 0.21575, ql_loss 0.74479, chxlmicf1 0.51144, chxlmacf1 0.46695, chx_loss 0.87247, chxlacc 0.70807, chxlrocaucmic 0.79489, chxlrocaucmac 0.77690, gacc 0.97902, gloss 0.05522, cxr14micf1 0.34408, cxr14macf1 0.33028, cxr14_loss 0.93903, vnbgmicf1 0.57788, vnbgmacf1 0.42719, vnbg_loss 0.70351, b1 0.46823, b2 0.35186, b3 0.26154, b4 0.19354, padchxlmacf1 0.06328, padchxlmicf1 0.18614, padchxlzmacf1 0.07666, padchxlzmicf1 0.17823, padchxl_loss 0.29274, padchxlz_loss 0.41687, 153.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17529, wmdcmp 0.16524, ema 0.67234, oracc 0.98680, qlmicf1 0.40124, qlmacf1 0.21613, chxlmicf1 0.53295, chxlmacf1 0.46646, chxlacc 0.70629, chxlrocaucmic 0.79667, chxlrocaucmac 0.75966, 36.94 secs\n",
      "Adjusting learning rate of group 0 to 1.5248e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.76518, a_loss 1.23060, cD 1.03016, wmdcmp 0.14103, ema 0.60743, oracc 0.98206, orien_loss 0.02717, qlmicf1 0.39036, qlmacf1 0.21468, ql_loss 0.74434, chxlmicf1 0.51644, chxlmacf1 0.46961, chx_loss 0.87755, chxlacc 0.71009, chxlrocaucmic 0.79556, chxlrocaucmac 0.77695, gacc 0.97750, gloss 0.06456, cxr14micf1 0.31063, cxr14macf1 0.31293, cxr14_loss 0.96652, vnbgmicf1 0.57307, vnbgmacf1 0.43050, vnbg_loss 0.72019, b1 0.48707, b2 0.37161, b3 0.28017, b4 0.21084, padchxlmacf1 0.06685, padchxlmicf1 0.17647, padchxlzmacf1 0.07405, padchxlzmicf1 0.17734, padchxl_loss 0.31971, padchxlz_loss 0.45103, 154.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16113, wmdcmp 0.16432, ema 0.68487, oracc 0.98680, qlmicf1 0.40059, qlmacf1 0.21761, chxlmicf1 0.52692, chxlmacf1 0.46615, chxlacc 0.70085, chxlrocaucmic 0.79120, chxlrocaucmac 0.75909, 36.75 secs\n",
      "Adjusting learning rate of group 0 to 1.3248e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.30162, a_loss 1.22724, cD 1.01574, wmdcmp 0.13736, ema 0.61570, oracc 0.98254, orien_loss 0.03040, qlmicf1 0.38512, qlmacf1 0.21416, ql_loss 0.74993, chxlmicf1 0.51344, chxlmacf1 0.46919, chx_loss 0.87272, chxlacc 0.71001, chxlrocaucmic 0.79790, chxlrocaucmac 0.77801, gacc 0.97522, gloss 0.06537, cxr14micf1 0.33186, cxr14macf1 0.32326, cxr14_loss 0.96889, vnbgmicf1 0.55928, vnbgmacf1 0.41747, vnbg_loss 0.74986, b1 0.48279, b2 0.36838, b3 0.27883, b4 0.21108, padchxlmacf1 0.07105, padchxlmicf1 0.19510, padchxlzmacf1 0.07795, padchxlzmicf1 0.18582, padchxl_loss 0.28617, padchxlz_loss 0.41474, 154.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.17514, wmdcmp 0.16611, ema 0.68308, oracc 0.98657, qlmicf1 0.40131, qlmacf1 0.21738, chxlmicf1 0.53090, chxlmacf1 0.46846, chxlacc 0.70049, chxlrocaucmic 0.79648, chxlrocaucmac 0.76002, 36.67 secs\n",
      "Adjusting learning rate of group 0 to 1.1510e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.64848, a_loss 1.21338, cD 1.02633, wmdcmp 0.13855, ema 0.61883, oracc 0.98327, orien_loss 0.02934, qlmicf1 0.38791, qlmacf1 0.21397, ql_loss 0.74847, chxlmicf1 0.51716, chxlmacf1 0.47131, chx_loss 0.87237, chxlacc 0.70864, chxlrocaucmic 0.79800, chxlrocaucmac 0.77910, gacc 0.97928, gloss 0.06757, cxr14micf1 0.34177, cxr14macf1 0.32688, cxr14_loss 0.95895, vnbgmicf1 0.57597, vnbgmacf1 0.43386, vnbg_loss 0.71621, b1 0.48982, b2 0.37923, b3 0.29295, b4 0.22839, padchxlmacf1 0.06928, padchxlmicf1 0.18981, padchxlzmacf1 0.08317, padchxlzmicf1 0.19361, padchxl_loss 0.31500, padchxlz_loss 0.44727, 154.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15598, wmdcmp 0.16360, ema 0.69024, oracc 0.98680, qlmicf1 0.39688, qlmacf1 0.21526, chxlmicf1 0.52708, chxlmacf1 0.46625, chxlacc 0.69677, chxlrocaucmic 0.79320, chxlrocaucmac 0.75860, 37.06 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184417_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 320 \\\n",
    "        --batch-size 40 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,9e-5,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface-large\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-large-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 320\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface-large\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-large-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,9e-5,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 40\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.0\n",
      "   vinbig_weight: 0.0\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.5\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   padchest_weight: 0.0\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223910_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-large-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,9e-5,32,1e-6\n",
      "1e-06 8 9e-05 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [224, 224], use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 40\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,3569879183697185499).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 40\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,1659353335112272599).pkl\n",
      "\tlen(question_datasets) = 59\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 5\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.5, 0.1, 0.08, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_124556_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_124556_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_40_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5474.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223910_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_40_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5474.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_124556_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.67562, a_loss 1.50457, cD 1.12461, wmdcmp 0.15094, ema 0.64328, oracc 0.99018, orien_loss 0.01222, qlmicf1 0.39132, qlmacf1 0.21485, ql_loss 0.75683, chxlmicf1 0.51610, chxlmacf1 0.46802, chx_loss 0.87010, chxlacc 0.70589, chxlrocaucmic 0.79536, chxlrocaucmac 0.77613, gacc 0.98142, gloss 0.05112, 154.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18811, wmdcmp 0.16623, ema 0.67950, oracc 0.98868, qlmicf1 0.39681, qlmacf1 0.21602, chxlmicf1 0.52112, chxlmacf1 0.45926, chxlacc 0.69133, chxlrocaucmic 0.78975, chxlrocaucmac 0.75038, 35.11 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.89106, a_loss 1.61095, cD 1.03444, wmdcmp 0.14052, ema 0.64434, oracc 0.98603, orien_loss 0.01713, qlmicf1 0.38991, qlmacf1 0.21955, ql_loss 0.75593, chxlmicf1 0.51461, chxlmacf1 0.46790, chx_loss 0.86586, chxlacc 0.70519, chxlrocaucmic 0.79467, chxlrocaucmac 0.77621, gacc 0.97842, gloss 0.06455, 150.28 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.18835, wmdcmp 0.16707, ema 0.68218, oracc 0.98868, qlmicf1 0.39573, qlmacf1 0.21618, chxlmicf1 0.52764, chxlmacf1 0.45847, chxlacc 0.70429, chxlrocaucmic 0.79315, chxlrocaucmac 0.75138, 35.36 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.01495, a_loss 1.60668, cD 1.03261, wmdcmp 0.14136, ema 0.65969, oracc 0.98548, orien_loss 0.01749, qlmicf1 0.38770, qlmacf1 0.21551, ql_loss 0.76148, chxlmicf1 0.51589, chxlmacf1 0.46866, chx_loss 0.87097, chxlacc 0.70690, chxlrocaucmic 0.79485, chxlrocaucmac 0.77648, gacc 0.98074, gloss 0.05835, 150.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18972, wmdcmp 0.16800, ema 0.68218, oracc 0.98868, qlmicf1 0.39620, qlmacf1 0.21477, chxlmicf1 0.52122, chxlmacf1 0.45755, chxlacc 0.69724, chxlrocaucmic 0.78784, chxlrocaucmac 0.75066, 35.35 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.05541, a_loss 1.60769, cD 1.01704, wmdcmp 0.13977, ema 0.64891, oracc 0.98727, orien_loss 0.01339, qlmicf1 0.38830, qlmacf1 0.21994, ql_loss 0.75907, chxlmicf1 0.51564, chxlmacf1 0.46783, chx_loss 0.87101, chxlacc 0.70744, chxlrocaucmic 0.79320, chxlrocaucmac 0.77426, gacc 0.97804, gloss 0.06671, 150.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18000, wmdcmp 0.16666, ema 0.67234, oracc 0.98915, qlmicf1 0.38924, qlmacf1 0.21508, chxlmicf1 0.52220, chxlmacf1 0.46142, chxlacc 0.69012, chxlrocaucmic 0.79015, chxlrocaucmac 0.75158, 35.33 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 5.04599, a_loss 1.61423, cD 1.03590, wmdcmp 0.14167, ema 0.65031, oracc 0.98676, orien_loss 0.01460, qlmicf1 0.38886, qlmacf1 0.22182, ql_loss 0.75882, chxlmicf1 0.51888, chxlmacf1 0.47126, chx_loss 0.86540, chxlacc 0.70780, chxlrocaucmic 0.79364, chxlrocaucmac 0.77745, gacc 0.97770, gloss 0.06358, 150.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18973, wmdcmp 0.16841, ema 0.66070, oracc 0.98915, qlmicf1 0.39001, qlmacf1 0.21737, chxlmicf1 0.52458, chxlmacf1 0.46151, chxlacc 0.69368, chxlrocaucmic 0.79069, chxlrocaucmac 0.75063, 35.34 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.62828, a_loss 1.60174, cD 1.04786, wmdcmp 0.14252, ema 0.64312, oracc 0.98675, orien_loss 0.02018, qlmicf1 0.38640, qlmacf1 0.21986, ql_loss 0.76515, chxlmicf1 0.51262, chxlmacf1 0.46598, chx_loss 0.87646, chxlacc 0.70415, chxlrocaucmic 0.79106, chxlrocaucmac 0.77452, gacc 0.97500, gloss 0.06894, 151.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.21396, wmdcmp 0.17061, ema 0.66517, oracc 0.98868, qlmicf1 0.38515, qlmacf1 0.21210, chxlmicf1 0.52786, chxlmacf1 0.46142, chxlacc 0.69164, chxlrocaucmic 0.79730, chxlrocaucmac 0.74923, 35.44 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.83829, a_loss 1.59556, cD 1.02866, wmdcmp 0.14089, ema 0.64332, oracc 0.98851, orien_loss 0.01439, qlmicf1 0.38108, qlmacf1 0.21807, ql_loss 0.76410, chxlmicf1 0.50994, chxlmacf1 0.46382, chx_loss 0.88117, chxlacc 0.70265, chxlrocaucmic 0.78952, chxlrocaucmac 0.77126, gacc 0.96385, gloss 0.10143, 150.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25166, wmdcmp 0.17282, ema 0.65801, oracc 0.98703, qlmicf1 0.41322, qlmacf1 0.22016, chxlmicf1 0.52276, chxlmacf1 0.46138, chxlacc 0.70011, chxlrocaucmic 0.78527, chxlrocaucmac 0.74832, 35.30 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 4.96210, a_loss 1.61088, cD 1.03722, wmdcmp 0.14130, ema 0.63969, oracc 0.98572, orien_loss 0.02411, qlmicf1 0.37620, qlmacf1 0.21821, ql_loss 0.76606, chxlmicf1 0.50573, chxlmacf1 0.45830, chx_loss 0.88747, chxlacc 0.69940, chxlrocaucmic 0.78430, chxlrocaucmac 0.76562, gacc 0.95169, gloss 0.13845, 151.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22345, wmdcmp 0.16763, ema 0.66786, oracc 0.98845, qlmicf1 0.39596, qlmacf1 0.21624, chxlmicf1 0.51332, chxlmacf1 0.45417, chxlacc 0.68313, chxlrocaucmic 0.78100, chxlrocaucmac 0.74115, 35.32 secs\n",
      "Adjusting learning rate of group 0 to 9.0000e-05.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 4.02070, a_loss 1.60543, cD 1.06788, wmdcmp 0.14489, ema 0.62940, oracc 0.98371, orien_loss 0.02618, qlmicf1 0.37568, qlmacf1 0.21220, ql_loss 0.77612, chxlmicf1 0.50015, chxlmacf1 0.45315, chx_loss 0.89383, chxlacc 0.69419, chxlrocaucmic 0.78029, chxlrocaucmac 0.75981, gacc 0.93801, gloss 0.17739, 151.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18739, wmdcmp 0.16821, ema 0.64816, oracc 0.98797, qlmicf1 0.37510, qlmacf1 0.21416, chxlmicf1 0.50794, chxlmacf1 0.44985, chxlacc 0.69582, chxlrocaucmic 0.76954, chxlrocaucmac 0.74393, 35.35 secs\n",
      "Adjusting learning rate of group 0 to 7.8194e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000078) ...\n",
      "loss 1.39104, a_loss 1.58742, cD 1.06107, wmdcmp 0.14482, ema 0.63292, oracc 0.98482, orien_loss 0.02372, qlmicf1 0.37353, qlmacf1 0.21394, ql_loss 0.77261, chxlmicf1 0.50347, chxlmacf1 0.45605, chx_loss 0.89397, chxlacc 0.69626, chxlrocaucmic 0.78122, chxlrocaucmac 0.76003, gacc 0.94932, gloss 0.14873, 151.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.18600, wmdcmp 0.16957, ema 0.65085, oracc 0.98868, qlmicf1 0.39889, qlmacf1 0.22054, chxlmicf1 0.52876, chxlmacf1 0.45659, chxlacc 0.71224, chxlrocaucmic 0.79031, chxlrocaucmac 0.74922, 36.22 secs\n",
      "Adjusting learning rate of group 0 to 6.7936e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 5.04953, a_loss 1.56931, cD 1.07921, wmdcmp 0.14696, ema 0.63703, oracc 0.98542, orien_loss 0.02881, qlmicf1 0.38429, qlmacf1 0.21706, ql_loss 0.76389, chxlmicf1 0.51409, chxlmacf1 0.46676, chx_loss 0.87486, chxlacc 0.70653, chxlrocaucmic 0.79059, chxlrocaucmac 0.77318, gacc 0.96149, gloss 0.09964, 152.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24426, wmdcmp 0.17260, ema 0.67413, oracc 0.98750, qlmicf1 0.38738, qlmacf1 0.21389, chxlmicf1 0.53750, chxlmacf1 0.46186, chxlacc 0.70571, chxlrocaucmic 0.80246, chxlrocaucmac 0.75225, 37.88 secs\n",
      "Adjusting learning rate of group 0 to 5.9024e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 4.85359, a_loss 1.58011, cD 1.08548, wmdcmp 0.14778, ema 0.64230, oracc 0.98565, orien_loss 0.02409, qlmicf1 0.38088, qlmacf1 0.22392, ql_loss 0.75799, chxlmicf1 0.51303, chxlmacf1 0.46503, chx_loss 0.87652, chxlacc 0.70558, chxlrocaucmic 0.78999, chxlrocaucmac 0.77286, gacc 0.96318, gloss 0.08574, 155.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27367, wmdcmp 0.17633, ema 0.67323, oracc 0.98774, qlmicf1 0.39288, qlmacf1 0.21619, chxlmicf1 0.52280, chxlmacf1 0.46324, chxlacc 0.69406, chxlrocaucmic 0.78885, chxlrocaucmac 0.75450, 37.66 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 1.74149, a_loss 1.54369, cD 1.10050, wmdcmp 0.14887, ema 0.65124, oracc 0.98630, orien_loss 0.02009, qlmicf1 0.38752, qlmacf1 0.22274, ql_loss 0.75353, chxlmicf1 0.51549, chxlmacf1 0.46835, chx_loss 0.87286, chxlacc 0.70658, chxlrocaucmic 0.79392, chxlrocaucmac 0.77674, gacc 0.97264, gloss 0.07948, 155.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27758, wmdcmp 0.17644, ema 0.68129, oracc 0.98845, qlmicf1 0.41110, qlmacf1 0.22303, chxlmicf1 0.52288, chxlmacf1 0.45929, chxlacc 0.71229, chxlrocaucmic 0.78103, chxlrocaucmac 0.75624, 37.37 secs\n",
      "Adjusting learning rate of group 0 to 4.4555e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.45441, a_loss 1.55162, cD 1.10915, wmdcmp 0.14990, ema 0.64891, oracc 0.98663, orien_loss 0.01867, qlmicf1 0.39216, qlmacf1 0.22638, ql_loss 0.75884, chxlmicf1 0.51778, chxlmacf1 0.46935, chx_loss 0.87177, chxlacc 0.71015, chxlrocaucmic 0.79511, chxlrocaucmac 0.77773, gacc 0.96791, gloss 0.08603, 154.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26862, wmdcmp 0.17474, ema 0.67144, oracc 0.98680, qlmicf1 0.39023, qlmacf1 0.22175, chxlmicf1 0.53349, chxlmacf1 0.45995, chxlacc 0.69620, chxlrocaucmic 0.80463, chxlrocaucmac 0.75486, 35.82 secs\n",
      "Adjusting learning rate of group 0 to 3.8710e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000039) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.77184, a_loss 1.54859, cD 1.10779, wmdcmp 0.15050, ema 0.66415, oracc 0.98549, orien_loss 0.01838, qlmicf1 0.39196, qlmacf1 0.22439, ql_loss 0.75188, chxlmicf1 0.52274, chxlmacf1 0.47499, chx_loss 0.85440, chxlacc 0.71433, chxlrocaucmic 0.80122, chxlrocaucmac 0.78414, gacc 0.96815, gloss 0.08332, 152.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26970, wmdcmp 0.17725, ema 0.68935, oracc 0.98656, qlmicf1 0.43886, qlmacf1 0.23064, chxlmicf1 0.54482, chxlmacf1 0.46376, chxlacc 0.73399, chxlrocaucmic 0.80344, chxlrocaucmac 0.75892, 36.19 secs\n",
      "Adjusting learning rate of group 0 to 3.3632e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 1.19958, a_loss 1.54752, cD 1.10156, wmdcmp 0.15063, ema 0.66594, oracc 0.98781, orien_loss 0.01333, qlmicf1 0.39418, qlmacf1 0.22707, ql_loss 0.74820, chxlmicf1 0.52622, chxlmacf1 0.47776, chx_loss 0.85206, chxlacc 0.71666, chxlrocaucmic 0.80180, chxlrocaucmac 0.78580, gacc 0.97027, gloss 0.08228, 152.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27278, wmdcmp 0.17665, ema 0.67860, oracc 0.98821, qlmicf1 0.40319, qlmacf1 0.22606, chxlmicf1 0.53375, chxlmacf1 0.46663, chxlacc 0.70766, chxlrocaucmic 0.79736, chxlrocaucmac 0.75683, 35.46 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.09275, a_loss 1.53950, cD 1.10046, wmdcmp 0.14968, ema 0.65761, oracc 0.98668, orien_loss 0.01891, qlmicf1 0.39733, qlmacf1 0.22759, ql_loss 0.74102, chxlmicf1 0.52511, chxlmacf1 0.47657, chx_loss 0.85252, chxlacc 0.71556, chxlrocaucmic 0.80300, chxlrocaucmac 0.78529, gacc 0.97128, gloss 0.08399, 149.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25906, wmdcmp 0.17520, ema 0.67323, oracc 0.98868, qlmicf1 0.39720, qlmacf1 0.22461, chxlmicf1 0.52496, chxlmacf1 0.46657, chxlacc 0.70183, chxlrocaucmic 0.79275, chxlrocaucmac 0.76015, 35.31 secs\n",
      "Adjusting learning rate of group 0 to 2.5387e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 4.43106, a_loss 1.54363, cD 1.11981, wmdcmp 0.15167, ema 0.65896, oracc 0.98773, orien_loss 0.01355, qlmicf1 0.39475, qlmacf1 0.23184, ql_loss 0.74441, chxlmicf1 0.52586, chxlmacf1 0.47905, chx_loss 0.85291, chxlacc 0.71767, chxlrocaucmic 0.80376, chxlrocaucmac 0.78712, gacc 0.97399, gloss 0.06736, 149.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23946, wmdcmp 0.17305, ema 0.67860, oracc 0.98868, qlmicf1 0.40482, qlmacf1 0.22321, chxlmicf1 0.54438, chxlmacf1 0.47009, chxlacc 0.72034, chxlrocaucmic 0.80747, chxlrocaucmac 0.76309, 35.37 secs\n",
      "Adjusting learning rate of group 0 to 2.2057e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.93736, a_loss 1.52430, cD 1.12880, wmdcmp 0.15344, ema 0.66484, oracc 0.98563, orien_loss 0.01366, qlmicf1 0.39652, qlmacf1 0.23012, ql_loss 0.73477, chxlmicf1 0.52837, chxlmacf1 0.47993, chx_loss 0.84666, chxlacc 0.72016, chxlrocaucmic 0.80557, chxlrocaucmac 0.79038, gacc 0.98041, gloss 0.05487, 149.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23618, wmdcmp 0.17388, ema 0.68397, oracc 0.98821, qlmicf1 0.39407, qlmacf1 0.22525, chxlmicf1 0.53010, chxlmacf1 0.46999, chxlacc 0.70549, chxlrocaucmic 0.79571, chxlrocaucmac 0.76374, 35.46 secs\n",
      "Adjusting learning rate of group 0 to 1.9163e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.73479, a_loss 1.52365, cD 1.11499, wmdcmp 0.15205, ema 0.67795, oracc 0.98820, orien_loss 0.01233, qlmicf1 0.39949, qlmacf1 0.23284, ql_loss 0.73872, chxlmicf1 0.53134, chxlmacf1 0.48506, chx_loss 0.84170, chxlacc 0.72140, chxlrocaucmic 0.80731, chxlrocaucmac 0.79295, gacc 0.97736, gloss 0.05889, 149.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23755, wmdcmp 0.17420, ema 0.68845, oracc 0.98845, qlmicf1 0.39195, qlmacf1 0.22531, chxlmicf1 0.53289, chxlmacf1 0.46996, chxlacc 0.69987, chxlrocaucmic 0.79979, chxlrocaucmac 0.76206, 35.29 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 4.44860, a_loss 1.52473, cD 1.12068, wmdcmp 0.15287, ema 0.66797, oracc 0.98819, orien_loss 0.01433, qlmicf1 0.40376, qlmacf1 0.23288, ql_loss 0.73403, chxlmicf1 0.53316, chxlmacf1 0.48352, chx_loss 0.83898, chxlacc 0.72501, chxlrocaucmic 0.80995, chxlrocaucmac 0.79536, gacc 0.97804, gloss 0.05538, 150.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24979, wmdcmp 0.17454, ema 0.69472, oracc 0.98845, qlmicf1 0.41511, qlmacf1 0.22859, chxlmicf1 0.54205, chxlmacf1 0.47172, chxlacc 0.71801, chxlrocaucmic 0.80644, chxlrocaucmac 0.76383, 35.42 secs\n",
      "Adjusting learning rate of group 0 to 1.4465e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.61288, a_loss 1.53066, cD 1.12620, wmdcmp 0.15247, ema 0.67075, oracc 0.98764, orien_loss 0.01426, qlmicf1 0.40449, qlmacf1 0.23454, ql_loss 0.73243, chxlmicf1 0.53628, chxlmacf1 0.48647, chx_loss 0.83011, chxlacc 0.72618, chxlrocaucmic 0.81203, chxlrocaucmac 0.79709, gacc 0.98048, gloss 0.05876, 151.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27032, wmdcmp 0.17659, ema 0.68308, oracc 0.98892, qlmicf1 0.40339, qlmacf1 0.22850, chxlmicf1 0.54124, chxlmacf1 0.46990, chxlacc 0.72495, chxlrocaucmic 0.80334, chxlrocaucmac 0.76412, 35.46 secs\n",
      "Adjusting learning rate of group 0 to 1.2568e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.16097, a_loss 1.52038, cD 1.12609, wmdcmp 0.15228, ema 0.67981, oracc 0.98786, orien_loss 0.01586, qlmicf1 0.40454, qlmacf1 0.23619, ql_loss 0.73563, chxlmicf1 0.53753, chxlmacf1 0.48807, chx_loss 0.82938, chxlacc 0.72711, chxlrocaucmic 0.81270, chxlrocaucmac 0.79600, gacc 0.98041, gloss 0.05603, 152.44 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25865, wmdcmp 0.17583, ema 0.68845, oracc 0.98915, qlmicf1 0.40050, qlmacf1 0.22881, chxlmicf1 0.54437, chxlmacf1 0.47282, chxlacc 0.72036, chxlrocaucmic 0.80856, chxlrocaucmac 0.76577, 35.46 secs\n",
      "Adjusting learning rate of group 0 to 1.0919e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 4.27870, a_loss 1.53115, cD 1.11518, wmdcmp 0.15175, ema 0.67406, oracc 0.98804, orien_loss 0.01443, qlmicf1 0.40841, qlmacf1 0.23650, ql_loss 0.73153, chxlmicf1 0.53925, chxlmacf1 0.49042, chx_loss 0.82656, chxlacc 0.72796, chxlrocaucmic 0.81386, chxlrocaucmac 0.79859, gacc 0.97872, gloss 0.05967, 150.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26087, wmdcmp 0.17572, ema 0.68308, oracc 0.98915, qlmicf1 0.40156, qlmacf1 0.22697, chxlmicf1 0.54100, chxlmacf1 0.47341, chxlacc 0.71384, chxlrocaucmic 0.80734, chxlrocaucmac 0.76708, 35.38 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.54435, a_loss 1.52894, cD 1.11060, wmdcmp 0.15200, ema 0.66981, oracc 0.98764, orien_loss 0.01528, qlmicf1 0.40425, qlmacf1 0.23569, ql_loss 0.73062, chxlmicf1 0.53728, chxlmacf1 0.48726, chx_loss 0.82751, chxlacc 0.72833, chxlrocaucmic 0.81473, chxlrocaucmac 0.79817, gacc 0.98750, gloss 0.04138, 150.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26449, wmdcmp 0.17597, ema 0.69472, oracc 0.98868, qlmicf1 0.40465, qlmacf1 0.22612, chxlmicf1 0.54161, chxlmacf1 0.47384, chxlacc 0.71375, chxlrocaucmic 0.80522, chxlrocaucmac 0.76284, 35.35 secs\n",
      "Adjusting learning rate of group 0 to 8.2424e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.66077, a_loss 1.50778, cD 1.13330, wmdcmp 0.15403, ema 0.67950, oracc 0.98877, orien_loss 0.01114, qlmicf1 0.40938, qlmacf1 0.23783, ql_loss 0.72849, chxlmicf1 0.54231, chxlmacf1 0.49333, chx_loss 0.82300, chxlacc 0.72891, chxlrocaucmic 0.81513, chxlrocaucmac 0.79983, gacc 0.98176, gloss 0.05071, 149.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26943, wmdcmp 0.17646, ema 0.69382, oracc 0.98821, qlmicf1 0.39929, qlmacf1 0.22762, chxlmicf1 0.53939, chxlmacf1 0.47563, chxlacc 0.71536, chxlrocaucmic 0.80303, chxlrocaucmac 0.76847, 35.40 secs\n",
      "Adjusting learning rate of group 0 to 7.1611e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.06671, a_loss 1.51575, cD 1.12445, wmdcmp 0.15277, ema 0.67578, oracc 0.98764, orien_loss 0.01457, qlmicf1 0.40557, qlmacf1 0.23641, ql_loss 0.73001, chxlmicf1 0.53786, chxlmacf1 0.49019, chx_loss 0.82457, chxlacc 0.72794, chxlrocaucmic 0.81329, chxlrocaucmac 0.79847, gacc 0.98953, gloss 0.03440, 151.24 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.25793, wmdcmp 0.17517, ema 0.69382, oracc 0.98797, qlmicf1 0.40979, qlmacf1 0.23204, chxlmicf1 0.54097, chxlmacf1 0.47260, chxlacc 0.71786, chxlrocaucmic 0.80521, chxlrocaucmac 0.76608, 35.42 secs\n",
      "Adjusting learning rate of group 0 to 6.2217e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.63646, a_loss 1.53259, cD 1.15244, wmdcmp 0.15577, ema 0.67594, oracc 0.98681, orien_loss 0.01475, qlmicf1 0.40660, qlmacf1 0.23801, ql_loss 0.72991, chxlmicf1 0.54203, chxlmacf1 0.49109, chx_loss 0.82375, chxlacc 0.72944, chxlrocaucmic 0.81596, chxlrocaucmac 0.80040, gacc 0.98493, gloss 0.04334, 150.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25041, wmdcmp 0.17464, ema 0.69114, oracc 0.98868, qlmicf1 0.40515, qlmacf1 0.23142, chxlmicf1 0.54322, chxlmacf1 0.47456, chxlacc 0.71527, chxlrocaucmic 0.80837, chxlrocaucmac 0.76770, 35.42 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.07885, a_loss 1.51788, cD 1.15792, wmdcmp 0.15540, ema 0.67328, oracc 0.98818, orien_loss 0.01469, qlmicf1 0.40958, qlmacf1 0.23786, ql_loss 0.72636, chxlmicf1 0.54234, chxlmacf1 0.49142, chx_loss 0.82280, chxlacc 0.73174, chxlrocaucmic 0.81583, chxlrocaucmac 0.80028, gacc 0.98682, gloss 0.04232, 150.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.24728, wmdcmp 0.17507, ema 0.69561, oracc 0.98915, qlmicf1 0.40694, qlmacf1 0.22889, chxlmicf1 0.53801, chxlmacf1 0.47547, chxlacc 0.71383, chxlrocaucmic 0.80156, chxlrocaucmac 0.76763, 35.43 secs\n",
      "Adjusting learning rate of group 0 to 4.6965e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.02999, a_loss 1.52081, cD 1.14450, wmdcmp 0.15418, ema 0.68152, oracc 0.98898, orien_loss 0.01358, qlmicf1 0.40623, qlmacf1 0.24233, ql_loss 0.73244, chxlmicf1 0.54146, chxlmacf1 0.49326, chx_loss 0.82131, chxlacc 0.73076, chxlrocaucmic 0.81632, chxlrocaucmac 0.80129, gacc 0.98345, gloss 0.05086, 151.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28382, wmdcmp 0.17831, ema 0.69024, oracc 0.98821, qlmicf1 0.39984, qlmacf1 0.22901, chxlmicf1 0.53888, chxlmacf1 0.47284, chxlacc 0.71576, chxlrocaucmic 0.80275, chxlrocaucmac 0.76479, 35.33 secs\n",
      "Adjusting learning rate of group 0 to 4.0804e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.67614, a_loss 1.51720, cD 1.14000, wmdcmp 0.15384, ema 0.67327, oracc 0.98778, orien_loss 0.01403, qlmicf1 0.40645, qlmacf1 0.23778, ql_loss 0.72738, chxlmicf1 0.54125, chxlmacf1 0.49416, chx_loss 0.82253, chxlacc 0.72988, chxlrocaucmic 0.81561, chxlrocaucmac 0.80119, gacc 0.98716, gloss 0.04497, 151.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27222, wmdcmp 0.17660, ema 0.68577, oracc 0.98915, qlmicf1 0.41425, qlmacf1 0.23025, chxlmicf1 0.54231, chxlmacf1 0.47405, chxlacc 0.72075, chxlrocaucmic 0.80611, chxlrocaucmac 0.76642, 35.49 secs\n",
      "Adjusting learning rate of group 0 to 3.5451e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.72687, a_loss 1.52113, cD 1.15793, wmdcmp 0.15674, ema 0.67750, oracc 0.98868, orien_loss 0.01024, qlmicf1 0.40885, qlmacf1 0.23856, ql_loss 0.72612, chxlmicf1 0.54373, chxlmacf1 0.49385, chx_loss 0.82062, chxlacc 0.73219, chxlrocaucmic 0.81881, chxlrocaucmac 0.80378, gacc 0.98514, gloss 0.04888, 151.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26388, wmdcmp 0.17598, ema 0.69293, oracc 0.98868, qlmicf1 0.39765, qlmacf1 0.23066, chxlmicf1 0.53962, chxlmacf1 0.47385, chxlacc 0.71342, chxlrocaucmic 0.80441, chxlrocaucmac 0.76678, 35.40 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.61517, a_loss 1.50496, cD 1.13371, wmdcmp 0.15305, ema 0.68463, oracc 0.98763, orien_loss 0.01226, qlmicf1 0.41323, qlmacf1 0.24232, ql_loss 0.72477, chxlmicf1 0.54203, chxlmacf1 0.49380, chx_loss 0.81731, chxlacc 0.73235, chxlrocaucmic 0.81792, chxlrocaucmac 0.80319, gacc 0.98547, gloss 0.04441, 151.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26466, wmdcmp 0.17608, ema 0.68487, oracc 0.98868, qlmicf1 0.40754, qlmacf1 0.23139, chxlmicf1 0.54388, chxlmacf1 0.47366, chxlacc 0.72057, chxlrocaucmic 0.80779, chxlrocaucmac 0.76617, 35.40 secs\n",
      "Adjusting learning rate of group 0 to 2.6760e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.25542, a_loss 1.51964, cD 1.15826, wmdcmp 0.15676, ema 0.67734, oracc 0.98716, orien_loss 0.01394, qlmicf1 0.41114, qlmacf1 0.24037, ql_loss 0.72683, chxlmicf1 0.54091, chxlmacf1 0.49304, chx_loss 0.82142, chxlacc 0.72989, chxlrocaucmic 0.81867, chxlrocaucmac 0.80383, gacc 0.98615, gloss 0.03945, 151.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27787, wmdcmp 0.17766, ema 0.69114, oracc 0.98892, qlmicf1 0.40504, qlmacf1 0.23114, chxlmicf1 0.54350, chxlmacf1 0.47595, chxlacc 0.71770, chxlrocaucmic 0.80712, chxlrocaucmac 0.76729, 35.39 secs\n",
      "Adjusting learning rate of group 0 to 2.3250e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.56316, a_loss 1.52616, cD 1.15768, wmdcmp 0.15605, ema 0.67626, oracc 0.98683, orien_loss 0.01434, qlmicf1 0.40899, qlmacf1 0.24009, ql_loss 0.72437, chxlmicf1 0.54270, chxlmacf1 0.49365, chx_loss 0.82284, chxlacc 0.73084, chxlrocaucmic 0.81623, chxlrocaucmac 0.80073, gacc 0.98493, gloss 0.04101, 151.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26161, wmdcmp 0.17622, ema 0.68666, oracc 0.98915, qlmicf1 0.40478, qlmacf1 0.23168, chxlmicf1 0.54233, chxlmacf1 0.47372, chxlacc 0.71763, chxlrocaucmic 0.80839, chxlrocaucmac 0.76744, 35.52 secs\n",
      "Adjusting learning rate of group 0 to 2.0200e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.09205, a_loss 1.50564, cD 1.11953, wmdcmp 0.15154, ema 0.67640, oracc 0.98873, orien_loss 0.01436, qlmicf1 0.40662, qlmacf1 0.24138, ql_loss 0.72293, chxlmicf1 0.54363, chxlmacf1 0.49366, chx_loss 0.81834, chxlacc 0.73165, chxlrocaucmic 0.81650, chxlrocaucmac 0.80199, gacc 0.98209, gloss 0.06012, 151.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.25915, wmdcmp 0.17615, ema 0.68666, oracc 0.98915, qlmicf1 0.40786, qlmacf1 0.23200, chxlmicf1 0.54633, chxlmacf1 0.47515, chxlacc 0.72359, chxlrocaucmic 0.80830, chxlrocaucmac 0.76746, 35.38 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.24388, a_loss 1.51642, cD 1.13801, wmdcmp 0.15459, ema 0.69328, oracc 0.98899, orien_loss 0.01291, qlmicf1 0.41276, qlmacf1 0.24199, ql_loss 0.72604, chxlmicf1 0.54192, chxlmacf1 0.49399, chx_loss 0.82053, chxlacc 0.73109, chxlrocaucmic 0.81749, chxlrocaucmac 0.80303, gacc 0.98716, gloss 0.03630, 151.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29905, wmdcmp 0.17991, ema 0.69561, oracc 0.98915, qlmicf1 0.41001, qlmacf1 0.23203, chxlmicf1 0.54421, chxlmacf1 0.47563, chxlacc 0.72062, chxlrocaucmic 0.80803, chxlrocaucmac 0.76879, 35.27 secs\n",
      "Adjusting learning rate of group 0 to 1.5248e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.87128, a_loss 1.53065, cD 1.13659, wmdcmp 0.15510, ema 0.68302, oracc 0.98517, orien_loss 0.01939, qlmicf1 0.41534, qlmacf1 0.24064, ql_loss 0.72102, chxlmicf1 0.54065, chxlmacf1 0.48919, chx_loss 0.81530, chxlacc 0.73225, chxlrocaucmic 0.81682, chxlrocaucmac 0.80182, gacc 0.98446, gloss 0.05235, 151.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28217, wmdcmp 0.17709, ema 0.70278, oracc 0.98868, qlmicf1 0.40759, qlmacf1 0.23170, chxlmicf1 0.54466, chxlmacf1 0.47420, chxlacc 0.71845, chxlrocaucmic 0.80996, chxlrocaucmac 0.76820, 35.42 secs\n",
      "Adjusting learning rate of group 0 to 1.3248e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.55045, a_loss 1.50166, cD 1.14386, wmdcmp 0.15458, ema 0.68447, oracc 0.98780, orien_loss 0.01256, qlmicf1 0.40896, qlmacf1 0.23820, ql_loss 0.72390, chxlmicf1 0.54141, chxlmacf1 0.49269, chx_loss 0.82083, chxlacc 0.73199, chxlrocaucmic 0.81868, chxlrocaucmac 0.80410, gacc 0.98784, gloss 0.03684, 150.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27312, wmdcmp 0.17713, ema 0.68397, oracc 0.98868, qlmicf1 0.40992, qlmacf1 0.23073, chxlmicf1 0.54332, chxlmacf1 0.47504, chxlacc 0.72093, chxlrocaucmic 0.80675, chxlrocaucmac 0.76818, 35.30 secs\n",
      "Adjusting learning rate of group 0 to 1.1510e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.34435, a_loss 1.52143, cD 1.14078, wmdcmp 0.15434, ema 0.68078, oracc 0.98691, orien_loss 0.01417, qlmicf1 0.40729, qlmacf1 0.24045, ql_loss 0.72121, chxlmicf1 0.54333, chxlmacf1 0.49466, chx_loss 0.81899, chxlacc 0.73321, chxlrocaucmic 0.81823, chxlrocaucmac 0.80339, gacc 0.98682, gloss 0.04132, 151.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26062, wmdcmp 0.17494, ema 0.69114, oracc 0.98892, qlmicf1 0.40981, qlmacf1 0.23119, chxlmicf1 0.54440, chxlmacf1 0.47525, chxlacc 0.72003, chxlrocaucmic 0.80728, chxlrocaucmac 0.76708, 35.42 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223910_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-large-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 320 \\\n",
    "        --batch-size 40 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,9e-5,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.5 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0 \\\n",
    "        --vinbig-weight 0 \\\n",
    "        --padchest-weight 0 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface-large\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-large-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
