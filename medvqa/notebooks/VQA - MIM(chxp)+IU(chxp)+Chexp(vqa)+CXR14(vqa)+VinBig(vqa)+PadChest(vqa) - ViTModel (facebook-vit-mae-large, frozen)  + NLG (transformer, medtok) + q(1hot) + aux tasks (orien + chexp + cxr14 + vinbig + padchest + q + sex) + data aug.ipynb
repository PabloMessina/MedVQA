{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 50\n",
      "   batches_per_epoch: 200\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface-large\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: facebook/vit-mae-large\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,5,4e-4,45,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 150\n",
      "   iters_to_accumulate: 5\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-large were not used when initializing ViTModel: ['decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.mask_token', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.0.output.dense.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-large and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Ignore freezing parameter: pooler.dense.weight\n",
      "Ignore freezing parameter: pooler.dense.bias\n",
      "  self.global_feat_size = 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-large+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,5,4e-4,45,1e-6\n",
      "1e-06 5 0.0004 45 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [224, 224], use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 150\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=287,3559006002065882738).pkl\n",
      "\tlen(question_datasets) = 92\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 150\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=283,2750089748417475840).pkl\n",
      "\tlen(question_datasets) = 42\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading CXR14 labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1440: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 125675.11it/s]\n",
      "Done. Example answer: <s> alveolar pattern , interstitial pattern </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 131999.19it/s]\n",
      "Done. Example answer: <s> </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 71437.30it/s]\n",
      "Done. Example answer: <s> normal </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc right , loc basal </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:25,  7.43it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230107_205007_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-large+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230107_205007_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-large+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230107_205007_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-large+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 11.98398, a_loss 8.64748, cD 0.00026, wmdcmp 0.00122, ema 0.00000, oracc 0.48483, orien_loss 1.16028, qlmicf1 0.11170, qlmacf1 0.08978, ql_loss 1.13553, chxlmicf1 0.23391, chxlmacf1 0.23700, chx_loss 1.10048, chxlacc 0.40032, chxlrocaucmic 0.46429, chxlrocaucmac 0.49132, gacc 0.50560, gloss 0.69267, cxr14micf1 0.10625, cxr14macf1 0.11209, cxr14_loss 1.24081, vnbgmicf1 0.11050, vnbgmacf1 0.14501, vnbg_loss 9.80889, b1 0.00025, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01353, padchxlmicf1 0.00711, padchxlzmacf1 0.02757, padchxlzmicf1 0.02260, padchxl_loss 0.95789, padchxlz_loss 1.02988, 167.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00018, wmdcmp 0.00188, ema 0.00000, oracc 0.65339, qlmicf1 0.11929, qlmacf1 0.09467, chxlmicf1 0.25883, chxlmacf1 0.25223, chxlacc 0.41176, chxlrocaucmic 0.47034, chxlrocaucmac 0.49573, 41.41 secs\n",
      "Adjusting learning rate of group 0 to 3.3145e-06.\n",
      "\u001b[1m---- Epoch 2/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 11.53772, a_loss 8.54377, cD 0.00022, wmdcmp 0.00140, ema 0.00000, oracc 0.51605, orien_loss 1.12136, qlmicf1 0.11378, qlmacf1 0.09153, ql_loss 1.13218, chxlmicf1 0.22105, chxlmacf1 0.23493, chx_loss 1.09976, chxlacc 0.41440, chxlrocaucmic 0.46840, chxlrocaucmac 0.49330, gacc 0.52038, gloss 0.69220, cxr14micf1 0.10198, cxr14macf1 0.11131, cxr14_loss 1.24197, vnbgmicf1 0.10935, vnbgmacf1 0.14304, vnbg_loss 9.65863, b1 0.00028, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01295, padchxlmicf1 0.00738, padchxlzmacf1 0.02792, padchxlzmicf1 0.02309, padchxl_loss 0.95612, padchxlz_loss 1.02811, 139.48 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 0.00012, wmdcmp 0.00228, ema 0.00000, oracc 0.63666, qlmicf1 0.12093, qlmacf1 0.09600, chxlmicf1 0.22900, chxlmacf1 0.24399, chxlacc 0.42802, chxlrocaucmic 0.47111, chxlrocaucmac 0.49791, 39.79 secs\n",
      "Adjusting learning rate of group 0 to 1.0986e-05.\n",
      "\u001b[1m---- Epoch 3/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 11.57130, a_loss 8.19974, cD 0.00045, wmdcmp 0.00102, ema 0.00542, oracc 0.64252, orien_loss 1.01425, qlmicf1 0.11791, qlmacf1 0.09842, ql_loss 1.12900, chxlmicf1 0.18542, chxlmacf1 0.22726, chx_loss 1.09980, chxlacc 0.45070, chxlrocaucmic 0.47221, chxlrocaucmac 0.49936, gacc 0.56870, gloss 0.68629, cxr14micf1 0.07964, cxr14macf1 0.11383, cxr14_loss 1.23889, vnbgmicf1 0.11815, vnbgmacf1 0.14870, vnbg_loss 9.17176, b1 0.00045, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01241, padchxlmicf1 0.00737, padchxlzmacf1 0.02763, padchxlzmicf1 0.02325, padchxl_loss 0.94608, padchxlz_loss 1.01686, 134.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00013, ema 0.03402, oracc 0.63336, qlmicf1 0.13043, qlmacf1 0.10628, chxlmicf1 0.18977, chxlmacf1 0.23916, chxlacc 0.47657, chxlrocaucmic 0.47986, chxlrocaucmac 0.51336, 34.62 secs\n",
      "Adjusting learning rate of group 0 to 3.6411e-05.\n",
      "\u001b[1m---- Epoch 4/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 10.50335, a_loss 7.04054, cD 0.00011, wmdcmp 0.00002, ema 0.04302, oracc 0.66880, orien_loss 0.82076, qlmicf1 0.17959, qlmacf1 0.11941, ql_loss 1.11707, chxlmicf1 0.16724, chxlmacf1 0.26149, chx_loss 1.09953, chxlacc 0.53088, chxlrocaucmic 0.49606, chxlrocaucmac 0.52765, gacc 0.55117, gloss 0.68484, cxr14micf1 0.08058, cxr14macf1 0.13335, cxr14_loss 1.23782, vnbgmicf1 0.12756, vnbgmacf1 0.15711, vnbg_loss 7.68436, b1 0.00000, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01306, padchxlmicf1 0.00921, padchxlzmacf1 0.02872, padchxlzmicf1 0.02766, padchxl_loss 0.90787, padchxlz_loss 0.99944, 131.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00000, ema 0.03581, oracc 0.63973, qlmicf1 0.23561, qlmacf1 0.12292, chxlmicf1 0.17087, chxlmacf1 0.26776, chxlacc 0.56459, chxlrocaucmic 0.50955, chxlrocaucmac 0.55412, 33.95 secs\n",
      "Adjusting learning rate of group 0 to 1.2068e-04.\n",
      "\u001b[1m---- Epoch 5/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000121) ...\n",
      "loss 8.78367, a_loss 5.35517, cD 0.03404, wmdcmp 0.00601, ema 0.03310, oracc 0.72223, orien_loss 0.62160, qlmicf1 0.24560, qlmacf1 0.12880, ql_loss 1.09048, chxlmicf1 0.24168, chxlmacf1 0.30721, chx_loss 1.09468, chxlacc 0.56051, chxlrocaucmic 0.56439, chxlrocaucmac 0.57593, gacc 0.55005, gloss 0.67771, cxr14micf1 0.13570, cxr14macf1 0.19224, cxr14_loss 1.23175, vnbgmicf1 0.16864, vnbgmacf1 0.19002, vnbg_loss 5.80375, b1 0.00001, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01690, padchxlmicf1 0.04461, padchxlzmacf1 0.03069, padchxlzmicf1 0.04943, padchxl_loss 0.79421, padchxlz_loss 0.91507, 132.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.09185, wmdcmp 0.01425, ema 0.00000, oracc 0.77828, qlmicf1 0.24508, qlmacf1 0.13697, chxlmicf1 0.34452, chxlmacf1 0.34850, chxlacc 0.55851, chxlrocaucmic 0.61755, chxlrocaucmac 0.59575, 33.62 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-04.\n",
      "\u001b[1m---- Epoch 6/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 8.73566, a_loss 3.61819, cD 0.07134, wmdcmp 0.01649, ema 0.02444, oracc 0.83533, orien_loss 0.42922, qlmicf1 0.24757, qlmacf1 0.14663, ql_loss 1.06654, chxlmicf1 0.34228, chxlmacf1 0.35023, chx_loss 1.07291, chxlacc 0.57893, chxlrocaucmic 0.63689, chxlrocaucmac 0.61821, gacc 0.64039, gloss 0.65111, cxr14micf1 0.16128, cxr14macf1 0.21028, cxr14_loss 1.21909, vnbgmicf1 0.21891, vnbgmacf1 0.22052, vnbg_loss 3.91500, b1 0.03892, b2 0.02150, b3 0.01335, b4 0.00948, padchxlmacf1 0.02321, padchxlmicf1 0.06020, padchxlzmacf1 0.03970, padchxlzmicf1 0.06365, padchxl_loss 0.69977, padchxlz_loss 0.82152, 132.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.03194, wmdcmp 0.01758, ema 0.03581, oracc 0.90504, qlmicf1 0.23429, qlmacf1 0.15444, chxlmicf1 0.41605, chxlmacf1 0.37123, chxlacc 0.58108, chxlrocaucmic 0.67121, chxlrocaucmac 0.62446, 33.47 secs\n",
      "Adjusting learning rate of group 0 to 3.5014e-04.\n",
      "\u001b[1m---- Epoch 7/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000350) ...\n",
      "loss 6.84478, a_loss 2.71614, cD 0.12580, wmdcmp 0.02868, ema 0.05448, oracc 0.90308, orien_loss 0.27452, qlmicf1 0.24103, qlmacf1 0.15297, ql_loss 1.04963, chxlmicf1 0.37127, chxlmacf1 0.36395, chx_loss 1.05588, chxlacc 0.58940, chxlrocaucmic 0.65938, chxlrocaucmac 0.63855, gacc 0.69419, gloss 0.60903, cxr14micf1 0.16423, cxr14macf1 0.21077, cxr14_loss 1.20066, vnbgmicf1 0.24792, vnbgmacf1 0.23077, vnbg_loss 3.00405, b1 0.09581, b2 0.06192, b3 0.04359, b4 0.03154, padchxlmacf1 0.02777, padchxlmicf1 0.07781, padchxlzmacf1 0.04466, padchxlzmicf1 0.07896, padchxl_loss 0.67784, padchxlz_loss 0.80372, 133.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.13744, wmdcmp 0.02272, ema 0.17905, oracc 0.93874, qlmicf1 0.25814, qlmacf1 0.16312, chxlmicf1 0.40824, chxlmacf1 0.37541, chxlacc 0.59069, chxlrocaucmic 0.66501, chxlrocaucmac 0.63435, 33.77 secs\n",
      "Adjusting learning rate of group 0 to 3.0649e-04.\n",
      "\u001b[1m---- Epoch 8/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000306) ...\n",
      "loss 5.91251, a_loss 2.34193, cD 0.23681, wmdcmp 0.04272, ema 0.17419, oracc 0.93023, orien_loss 0.20496, qlmicf1 0.23907, qlmacf1 0.15636, ql_loss 1.03943, chxlmicf1 0.38169, chxlmacf1 0.37054, chx_loss 1.05026, chxlacc 0.59951, chxlrocaucmic 0.66864, chxlrocaucmac 0.64882, gacc 0.77695, gloss 0.55307, cxr14micf1 0.16647, cxr14macf1 0.21385, cxr14_loss 1.19252, vnbgmicf1 0.28467, vnbgmacf1 0.24833, vnbg_loss 2.64473, b1 0.09876, b2 0.05328, b3 0.03307, b4 0.02163, padchxlmacf1 0.03114, padchxlmicf1 0.07887, padchxlzmacf1 0.04813, padchxlzmicf1 0.08282, padchxl_loss 0.65338, padchxlz_loss 0.79398, 133.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.04930, wmdcmp 0.02066, ema 0.48075, oracc 0.94392, qlmicf1 0.25807, qlmacf1 0.16648, chxlmicf1 0.40103, chxlmacf1 0.37538, chxlacc 0.59956, chxlrocaucmic 0.66622, chxlrocaucmac 0.64668, 35.08 secs\n",
      "Adjusting learning rate of group 0 to 2.6828e-04.\n",
      "\u001b[1m---- Epoch 9/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000268) ...\n",
      "loss 6.43223, a_loss 2.04039, cD 0.31388, wmdcmp 0.05254, ema 0.33199, oracc 0.94080, orien_loss 0.16980, qlmicf1 0.23684, qlmacf1 0.15786, ql_loss 1.03826, chxlmicf1 0.38936, chxlmacf1 0.37397, chx_loss 1.04485, chxlacc 0.60417, chxlrocaucmic 0.67509, chxlrocaucmac 0.65688, gacc 0.79720, gloss 0.50580, cxr14micf1 0.19002, cxr14macf1 0.23259, cxr14_loss 1.17315, vnbgmicf1 0.30842, vnbgmacf1 0.26053, vnbg_loss 2.32328, b1 0.24372, b2 0.15377, b3 0.09803, b4 0.06314, padchxlmacf1 0.03240, padchxlmicf1 0.08573, padchxlzmacf1 0.05212, padchxlzmicf1 0.09132, padchxl_loss 0.64809, padchxlz_loss 0.77117, 134.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.14204, wmdcmp 0.03017, ema 0.54521, oracc 0.95170, qlmicf1 0.23893, qlmacf1 0.16581, chxlmicf1 0.44152, chxlmacf1 0.38768, chxlacc 0.60498, chxlrocaucmic 0.69547, chxlrocaucmac 0.65265, 34.66 secs\n",
      "Adjusting learning rate of group 0 to 2.3484e-04.\n",
      "\u001b[1m---- Epoch 10/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000235) ...\n",
      "loss 2.69470, a_loss 1.87900, cD 0.37816, wmdcmp 0.06112, ema 0.40365, oracc 0.94586, orien_loss 0.15409, qlmicf1 0.24398, qlmacf1 0.16014, ql_loss 1.03561, chxlmicf1 0.39974, chxlmacf1 0.37876, chx_loss 1.04005, chxlacc 0.60990, chxlrocaucmic 0.68237, chxlrocaucmac 0.66262, gacc 0.81571, gloss 0.46898, cxr14micf1 0.18671, cxr14macf1 0.22876, cxr14_loss 1.17364, vnbgmicf1 0.30933, vnbgmacf1 0.26241, vnbg_loss 2.01954, b1 0.30707, b2 0.20241, b3 0.13428, b4 0.09224, padchxlmacf1 0.03429, padchxlmicf1 0.08611, padchxlzmacf1 0.05211, padchxlzmicf1 0.09310, padchxl_loss 0.64817, padchxlz_loss 0.80097, 133.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.16503, wmdcmp 0.03325, ema 0.58550, oracc 0.95712, qlmicf1 0.24740, qlmacf1 0.16881, chxlmicf1 0.43988, chxlmacf1 0.38583, chxlacc 0.62034, chxlrocaucmic 0.69297, chxlrocaucmac 0.65343, 33.96 secs\n",
      "Adjusting learning rate of group 0 to 2.0556e-04.\n",
      "\u001b[1m---- Epoch 11/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000206) ...\n",
      "loss 2.54161, a_loss 1.75899, cD 0.42191, wmdcmp 0.06694, ema 0.44614, oracc 0.94728, orien_loss 0.14620, qlmicf1 0.24642, qlmacf1 0.16183, ql_loss 1.03418, chxlmicf1 0.40578, chxlmacf1 0.38241, chx_loss 1.03842, chxlacc 0.61120, chxlrocaucmic 0.68904, chxlrocaucmac 0.66908, gacc 0.81758, gloss 0.44851, cxr14micf1 0.18953, cxr14macf1 0.23308, cxr14_loss 1.17033, vnbgmicf1 0.33450, vnbgmacf1 0.27449, vnbg_loss 1.80535, b1 0.32739, b2 0.22238, b3 0.15063, b4 0.10558, padchxlmacf1 0.03403, padchxlmicf1 0.09647, padchxlzmacf1 0.05455, padchxlzmicf1 0.10280, padchxl_loss 0.64234, padchxlz_loss 0.75993, 134.19 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.21209, wmdcmp 0.04073, ema 0.59445, oracc 0.96230, qlmicf1 0.25545, qlmacf1 0.17198, chxlmicf1 0.45049, chxlmacf1 0.39597, chxlacc 0.61691, chxlrocaucmic 0.70447, chxlrocaucmac 0.66214, 33.81 secs\n",
      "Adjusting learning rate of group 0 to 1.7994e-04.\n",
      "\u001b[1m---- Epoch 12/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000180) ...\n",
      "loss 6.30945, a_loss 1.68282, cD 0.46558, wmdcmp 0.07242, ema 0.46561, oracc 0.95064, orien_loss 0.13535, qlmicf1 0.24193, qlmacf1 0.16125, ql_loss 1.03299, chxlmicf1 0.41232, chxlmacf1 0.38558, chx_loss 1.03113, chxlacc 0.61706, chxlrocaucmic 0.69189, chxlrocaucmac 0.67287, gacc 0.82838, gloss 0.42486, cxr14micf1 0.19314, cxr14macf1 0.23448, cxr14_loss 1.17118, vnbgmicf1 0.34729, vnbgmacf1 0.28219, vnbg_loss 1.66865, b1 0.33622, b2 0.22890, b3 0.15070, b4 0.10427, padchxlmacf1 0.03697, padchxlmicf1 0.09428, padchxlzmacf1 0.05693, padchxlzmicf1 0.09989, padchxl_loss 0.64530, padchxlz_loss 0.78231, 133.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.23757, wmdcmp 0.04333, ema 0.58908, oracc 0.96254, qlmicf1 0.25290, qlmacf1 0.17309, chxlmicf1 0.44929, chxlmacf1 0.39575, chxlacc 0.62297, chxlrocaucmic 0.69935, chxlrocaucmac 0.66212, 33.79 secs\n",
      "Adjusting learning rate of group 0 to 1.5751e-04.\n",
      "\u001b[1m---- Epoch 13/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000158) ...\n",
      "loss 1.55593, a_loss 1.62806, cD 0.49683, wmdcmp 0.07605, ema 0.48398, oracc 0.95570, orien_loss 0.12047, qlmicf1 0.24598, qlmacf1 0.16249, ql_loss 1.02402, chxlmicf1 0.40903, chxlmacf1 0.38441, chx_loss 1.03467, chxlacc 0.61817, chxlrocaucmic 0.69369, chxlrocaucmac 0.67429, gacc 0.83198, gloss 0.41767, cxr14micf1 0.20145, cxr14macf1 0.24089, cxr14_loss 1.16229, vnbgmicf1 0.36079, vnbgmacf1 0.28556, vnbg_loss 1.58158, b1 0.36778, b2 0.25683, b3 0.17572, b4 0.12423, padchxlmacf1 0.03774, padchxlmicf1 0.09744, padchxlzmacf1 0.05574, padchxlzmicf1 0.10164, padchxl_loss 0.62825, padchxlz_loss 0.75075, 133.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.27946, wmdcmp 0.04901, ema 0.61862, oracc 0.96254, qlmicf1 0.25519, qlmacf1 0.17297, chxlmicf1 0.44915, chxlmacf1 0.39838, chxlacc 0.60958, chxlrocaucmic 0.70377, chxlrocaucmac 0.66466, 33.59 secs\n",
      "Adjusting learning rate of group 0 to 1.3787e-04.\n",
      "\u001b[1m---- Epoch 14/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000138) ...\n",
      "loss 2.32593, a_loss 1.59105, cD 0.52231, wmdcmp 0.07813, ema 0.49554, oracc 0.95637, orien_loss 0.11697, qlmicf1 0.24759, qlmacf1 0.16382, ql_loss 1.02456, chxlmicf1 0.41766, chxlmacf1 0.38921, chx_loss 1.02671, chxlacc 0.61899, chxlrocaucmic 0.69685, chxlrocaucmac 0.67764, gacc 0.83505, gloss 0.40400, cxr14micf1 0.20474, cxr14macf1 0.24032, cxr14_loss 1.15477, vnbgmicf1 0.36071, vnbgmacf1 0.28615, vnbg_loss 1.52733, b1 0.34274, b2 0.23991, b3 0.16653, b4 0.12036, padchxlmacf1 0.03846, padchxlmicf1 0.10185, padchxlzmacf1 0.05844, padchxlzmicf1 0.10633, padchxl_loss 0.62681, padchxlz_loss 0.77201, 134.42 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37278, wmdcmp 0.05826, ema 0.59176, oracc 0.96607, qlmicf1 0.25766, qlmacf1 0.17269, chxlmicf1 0.44633, chxlmacf1 0.39621, chxlacc 0.62434, chxlrocaucmic 0.70020, chxlrocaucmac 0.66580, 33.45 secs\n",
      "Adjusting learning rate of group 0 to 1.2068e-04.\n",
      "\u001b[1m---- Epoch 15/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000121) ...\n",
      "loss 1.79739, a_loss 1.54281, cD 0.54694, wmdcmp 0.08246, ema 0.50371, oracc 0.95644, orien_loss 0.11532, qlmicf1 0.24929, qlmacf1 0.16470, ql_loss 1.01979, chxlmicf1 0.42097, chxlmacf1 0.39040, chx_loss 1.02595, chxlacc 0.62165, chxlrocaucmic 0.69822, chxlrocaucmac 0.67795, gacc 0.84193, gloss 0.39417, cxr14micf1 0.19564, cxr14macf1 0.23339, cxr14_loss 1.15783, vnbgmicf1 0.35280, vnbgmacf1 0.28237, vnbg_loss 1.50193, b1 0.36092, b2 0.25503, b3 0.17483, b4 0.12195, padchxlmacf1 0.04016, padchxlmicf1 0.10117, padchxlzmacf1 0.06031, padchxlzmicf1 0.10682, padchxl_loss 0.64268, padchxlz_loss 0.77859, 134.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.40391, wmdcmp 0.06435, ema 0.62310, oracc 0.96513, qlmicf1 0.25786, qlmacf1 0.17405, chxlmicf1 0.44857, chxlmacf1 0.39887, chxlacc 0.61910, chxlrocaucmic 0.70232, chxlrocaucmac 0.66557, 33.78 secs\n",
      "Adjusting learning rate of group 0 to 1.0564e-04.\n",
      "\u001b[1m---- Epoch 16/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 1.78387, a_loss 1.54033, cD 0.58934, wmdcmp 0.08689, ema 0.50249, oracc 0.95775, orien_loss 0.11487, qlmicf1 0.24707, qlmacf1 0.16410, ql_loss 1.02742, chxlmicf1 0.41667, chxlmacf1 0.38851, chx_loss 1.02673, chxlacc 0.62050, chxlrocaucmic 0.69819, chxlrocaucmac 0.67894, gacc 0.84467, gloss 0.38804, cxr14micf1 0.19638, cxr14macf1 0.23452, cxr14_loss 1.16127, vnbgmicf1 0.35975, vnbgmacf1 0.28474, vnbg_loss 1.47736, b1 0.38266, b2 0.27392, b3 0.19469, b4 0.14177, padchxlmacf1 0.03725, padchxlmicf1 0.09595, padchxlzmacf1 0.05929, padchxlzmicf1 0.10378, padchxl_loss 0.63033, padchxlz_loss 0.77472, 133.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.42701, wmdcmp 0.06629, ema 0.60430, oracc 0.96348, qlmicf1 0.25990, qlmacf1 0.17521, chxlmicf1 0.45405, chxlmacf1 0.40190, chxlacc 0.62015, chxlrocaucmic 0.71107, chxlrocaucmac 0.66866, 33.22 secs\n",
      "Adjusting learning rate of group 0 to 9.2470e-05.\n",
      "\u001b[1m---- Epoch 17/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000092) ...\n",
      "loss 5.90228, a_loss 1.53057, cD 0.59967, wmdcmp 0.08749, ema 0.51487, oracc 0.95685, orien_loss 0.11316, qlmicf1 0.25016, qlmacf1 0.16653, ql_loss 1.02448, chxlmicf1 0.41962, chxlmacf1 0.38988, chx_loss 1.02439, chxlacc 0.62298, chxlrocaucmic 0.69985, chxlrocaucmac 0.67944, gacc 0.84286, gloss 0.38326, cxr14micf1 0.20101, cxr14macf1 0.23675, cxr14_loss 1.16274, vnbgmicf1 0.36773, vnbgmacf1 0.28988, vnbg_loss 1.44556, b1 0.38236, b2 0.27157, b3 0.18739, b4 0.13400, padchxlmacf1 0.03994, padchxlmicf1 0.10327, padchxlzmacf1 0.05852, padchxlzmicf1 0.10586, padchxl_loss 0.62641, padchxlz_loss 0.76686, 134.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.45405, wmdcmp 0.06976, ema 0.61683, oracc 0.96795, qlmicf1 0.26101, qlmacf1 0.17528, chxlmicf1 0.45508, chxlmacf1 0.40252, chxlacc 0.62589, chxlrocaucmic 0.71035, chxlrocaucmac 0.67051, 33.43 secs\n",
      "Adjusting learning rate of group 0 to 8.0943e-05.\n",
      "\u001b[1m---- Epoch 18/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000081) ...\n",
      "loss 5.90520, a_loss 1.51033, cD 0.62342, wmdcmp 0.09067, ema 0.51458, oracc 0.95974, orien_loss 0.10831, qlmicf1 0.25026, qlmacf1 0.16558, ql_loss 1.02294, chxlmicf1 0.42213, chxlmacf1 0.39144, chx_loss 1.02363, chxlacc 0.62325, chxlrocaucmic 0.70151, chxlrocaucmac 0.68088, gacc 0.84589, gloss 0.37826, cxr14micf1 0.20888, cxr14macf1 0.24235, cxr14_loss 1.15051, vnbgmicf1 0.37275, vnbgmacf1 0.29158, vnbg_loss 1.41586, b1 0.38144, b2 0.27392, b3 0.19211, b4 0.13568, padchxlmacf1 0.04029, padchxlmicf1 0.10352, padchxlzmacf1 0.05940, padchxlzmicf1 0.10566, padchxl_loss 0.62978, padchxlz_loss 0.76316, 134.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.49000, wmdcmp 0.07375, ema 0.61952, oracc 0.96843, qlmicf1 0.26029, qlmacf1 0.17579, chxlmicf1 0.45852, chxlmacf1 0.40634, chxlacc 0.61829, chxlrocaucmic 0.71597, chxlrocaucmac 0.67387, 33.72 secs\n",
      "Adjusting learning rate of group 0 to 7.0852e-05.\n",
      "\u001b[1m---- Epoch 19/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 3.76765, a_loss 1.49942, cD 0.63637, wmdcmp 0.09265, ema 0.51420, oracc 0.96081, orien_loss 0.10663, qlmicf1 0.25456, qlmacf1 0.16735, ql_loss 1.01707, chxlmicf1 0.42850, chxlmacf1 0.39438, chx_loss 1.01867, chxlacc 0.62681, chxlrocaucmic 0.70594, chxlrocaucmac 0.68576, gacc 0.84943, gloss 0.37192, cxr14micf1 0.21521, cxr14macf1 0.24709, cxr14_loss 1.15181, vnbgmicf1 0.38256, vnbgmacf1 0.30100, vnbg_loss 1.37901, b1 0.39083, b2 0.28311, b3 0.20342, b4 0.14783, padchxlmacf1 0.04051, padchxlmicf1 0.10058, padchxlzmacf1 0.05887, padchxlzmicf1 0.10621, padchxl_loss 0.63158, padchxlz_loss 0.76778, 134.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.48001, wmdcmp 0.07238, ema 0.61862, oracc 0.96631, qlmicf1 0.26097, qlmacf1 0.17565, chxlmicf1 0.45717, chxlmacf1 0.40359, chxlacc 0.62361, chxlrocaucmic 0.71519, chxlrocaucmac 0.67320, 33.42 secs\n",
      "Adjusting learning rate of group 0 to 6.2020e-05.\n",
      "\u001b[1m---- Epoch 20/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000062) ...\n",
      "loss 2.34451, a_loss 1.47145, cD 0.65230, wmdcmp 0.09500, ema 0.52489, oracc 0.95828, orien_loss 0.11114, qlmicf1 0.25385, qlmacf1 0.16682, ql_loss 1.01747, chxlmicf1 0.41932, chxlmacf1 0.38962, chx_loss 1.02301, chxlacc 0.62188, chxlrocaucmic 0.70027, chxlrocaucmac 0.68009, gacc 0.85800, gloss 0.36525, cxr14micf1 0.20734, cxr14macf1 0.24309, cxr14_loss 1.15729, vnbgmicf1 0.36856, vnbgmacf1 0.29174, vnbg_loss 1.39520, b1 0.39536, b2 0.28537, b3 0.20393, b4 0.14807, padchxlmacf1 0.04064, padchxlmicf1 0.10345, padchxlzmacf1 0.06272, padchxlzmicf1 0.10749, padchxl_loss 0.62058, padchxlz_loss 0.75937, 133.47 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.48697, wmdcmp 0.07416, ema 0.61594, oracc 0.96866, qlmicf1 0.26181, qlmacf1 0.17655, chxlmicf1 0.45537, chxlmacf1 0.40375, chxlacc 0.61949, chxlrocaucmic 0.71357, chxlrocaucmac 0.67247, 33.45 secs\n",
      "Adjusting learning rate of group 0 to 5.4288e-05.\n",
      "\u001b[1m---- Epoch 21/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 1.32598, a_loss 1.46796, cD 0.66244, wmdcmp 0.09568, ema 0.51367, oracc 0.96069, orien_loss 0.10525, qlmicf1 0.25289, qlmacf1 0.16616, ql_loss 1.02269, chxlmicf1 0.41924, chxlmacf1 0.39013, chx_loss 1.02625, chxlacc 0.62300, chxlrocaucmic 0.69902, chxlrocaucmac 0.68021, gacc 0.85285, gloss 0.36841, cxr14micf1 0.19900, cxr14macf1 0.23770, cxr14_loss 1.15508, vnbgmicf1 0.38832, vnbgmacf1 0.30107, vnbg_loss 1.37653, b1 0.38983, b2 0.28196, b3 0.19919, b4 0.14206, padchxlmacf1 0.04007, padchxlmicf1 0.09978, padchxlzmacf1 0.05992, padchxlzmicf1 0.10534, padchxl_loss 0.62458, padchxlz_loss 0.77500, 134.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.49028, wmdcmp 0.07540, ema 0.62131, oracc 0.96960, qlmicf1 0.26344, qlmacf1 0.17786, chxlmicf1 0.45623, chxlmacf1 0.40559, chxlacc 0.62008, chxlrocaucmic 0.71190, chxlrocaucmac 0.67481, 33.56 secs\n",
      "Adjusting learning rate of group 0 to 4.7521e-05.\n",
      "\u001b[1m---- Epoch 22/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 2.21759, a_loss 1.45032, cD 0.67376, wmdcmp 0.09686, ema 0.52710, oracc 0.95935, orien_loss 0.10482, qlmicf1 0.25151, qlmacf1 0.16602, ql_loss 1.02068, chxlmicf1 0.42490, chxlmacf1 0.39268, chx_loss 1.01963, chxlacc 0.62640, chxlrocaucmic 0.70206, chxlrocaucmac 0.68346, gacc 0.84295, gloss 0.37652, cxr14micf1 0.20816, cxr14macf1 0.24475, cxr14_loss 1.14962, vnbgmicf1 0.37928, vnbgmacf1 0.29877, vnbg_loss 1.35669, b1 0.39443, b2 0.28608, b3 0.20207, b4 0.14372, padchxlmacf1 0.04215, padchxlmicf1 0.10713, padchxlzmacf1 0.06172, padchxlzmicf1 0.11246, padchxl_loss 0.62009, padchxlz_loss 0.76280, 134.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.49687, wmdcmp 0.07572, ema 0.61683, oracc 0.96795, qlmicf1 0.26117, qlmacf1 0.17692, chxlmicf1 0.45720, chxlmacf1 0.40475, chxlacc 0.62211, chxlrocaucmic 0.71370, chxlrocaucmac 0.67311, 33.40 secs\n",
      "Adjusting learning rate of group 0 to 4.1597e-05.\n",
      "\u001b[1m---- Epoch 23/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 5.80345, a_loss 1.45337, cD 0.68898, wmdcmp 0.09894, ema 0.52926, oracc 0.96009, orien_loss 0.10148, qlmicf1 0.25092, qlmacf1 0.16682, ql_loss 1.02060, chxlmicf1 0.42684, chxlmacf1 0.39388, chx_loss 1.01870, chxlacc 0.62621, chxlrocaucmic 0.70434, chxlrocaucmac 0.68385, gacc 0.84812, gloss 0.36664, cxr14micf1 0.21092, cxr14macf1 0.24530, cxr14_loss 1.14934, vnbgmicf1 0.37544, vnbgmacf1 0.29881, vnbg_loss 1.34735, b1 0.40211, b2 0.29337, b3 0.20977, b4 0.15074, padchxlmacf1 0.04114, padchxlmicf1 0.10370, padchxlzmacf1 0.06177, padchxlzmicf1 0.11065, padchxl_loss 0.60401, padchxlz_loss 0.75857, 134.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.52281, wmdcmp 0.07843, ema 0.61415, oracc 0.97031, qlmicf1 0.26253, qlmacf1 0.17797, chxlmicf1 0.45701, chxlmacf1 0.40541, chxlacc 0.62294, chxlrocaucmic 0.71277, chxlrocaucmac 0.67312, 33.34 secs\n",
      "Adjusting learning rate of group 0 to 3.6411e-05.\n",
      "\u001b[1m---- Epoch 24/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 5.75510, a_loss 1.46958, cD 0.68943, wmdcmp 0.09878, ema 0.52899, oracc 0.96053, orien_loss 0.10176, qlmicf1 0.25519, qlmacf1 0.16821, ql_loss 1.01407, chxlmicf1 0.42768, chxlmacf1 0.39417, chx_loss 1.01956, chxlacc 0.62604, chxlrocaucmic 0.70244, chxlrocaucmac 0.68350, gacc 0.85575, gloss 0.36077, cxr14micf1 0.20156, cxr14macf1 0.23781, cxr14_loss 1.15419, vnbgmicf1 0.39480, vnbgmacf1 0.30344, vnbg_loss 1.33435, b1 0.40316, b2 0.28796, b3 0.20153, b4 0.14373, padchxlmacf1 0.04283, padchxlmicf1 0.10612, padchxlzmacf1 0.06181, padchxlzmicf1 0.10959, padchxl_loss 0.63131, padchxlz_loss 0.74734, 134.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.52765, wmdcmp 0.07918, ema 0.61504, oracc 0.96654, qlmicf1 0.26585, qlmacf1 0.17770, chxlmicf1 0.45804, chxlmacf1 0.40592, chxlacc 0.62488, chxlrocaucmic 0.71472, chxlrocaucmac 0.67627, 33.31 secs\n",
      "Adjusting learning rate of group 0 to 3.1872e-05.\n",
      "\u001b[1m---- Epoch 25/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 1.87346, a_loss 1.42591, cD 0.69781, wmdcmp 0.10023, ema 0.52262, oracc 0.96027, orien_loss 0.10118, qlmicf1 0.25263, qlmacf1 0.16669, ql_loss 1.01000, chxlmicf1 0.42551, chxlmacf1 0.39268, chx_loss 1.02024, chxlacc 0.62351, chxlrocaucmic 0.70124, chxlrocaucmac 0.68132, gacc 0.85276, gloss 0.35973, cxr14micf1 0.21705, cxr14macf1 0.24922, cxr14_loss 1.13952, vnbgmicf1 0.39449, vnbgmacf1 0.30658, vnbg_loss 1.34215, b1 0.41060, b2 0.30145, b3 0.21637, b4 0.15762, padchxlmacf1 0.04198, padchxlmicf1 0.10687, padchxlzmacf1 0.06248, padchxlzmicf1 0.11614, padchxl_loss 0.61934, padchxlz_loss 0.76308, 133.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.54181, wmdcmp 0.08112, ema 0.62220, oracc 0.97220, qlmicf1 0.26506, qlmacf1 0.17681, chxlmicf1 0.45265, chxlmacf1 0.40304, chxlacc 0.62676, chxlrocaucmic 0.70958, chxlrocaucmac 0.67536, 33.42 secs\n",
      "Adjusting learning rate of group 0 to 2.7899e-05.\n",
      "\u001b[1m---- Epoch 26/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 2.22861, a_loss 1.44150, cD 0.69662, wmdcmp 0.10038, ema 0.52940, oracc 0.95856, orien_loss 0.10267, qlmicf1 0.25281, qlmacf1 0.16724, ql_loss 1.01585, chxlmicf1 0.42900, chxlmacf1 0.39453, chx_loss 1.01844, chxlacc 0.62772, chxlrocaucmic 0.70465, chxlrocaucmac 0.68449, gacc 0.85082, gloss 0.35604, cxr14micf1 0.20854, cxr14macf1 0.24465, cxr14_loss 1.15537, vnbgmicf1 0.38490, vnbgmacf1 0.29873, vnbg_loss 1.34155, b1 0.42040, b2 0.30668, b3 0.21798, b4 0.15855, padchxlmacf1 0.04151, padchxlmicf1 0.10630, padchxlzmacf1 0.06045, padchxlzmicf1 0.11526, padchxl_loss 0.62459, padchxlz_loss 0.77496, 134.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.55158, wmdcmp 0.08212, ema 0.61862, oracc 0.96819, qlmicf1 0.26430, qlmacf1 0.17774, chxlmicf1 0.45658, chxlmacf1 0.40549, chxlacc 0.62240, chxlrocaucmic 0.71364, chxlrocaucmac 0.67365, 33.44 secs\n",
      "Adjusting learning rate of group 0 to 2.4421e-05.\n",
      "\u001b[1m---- Epoch 27/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.66274, a_loss 1.43441, cD 0.70758, wmdcmp 0.10117, ema 0.52791, oracc 0.96002, orien_loss 0.10059, qlmicf1 0.25408, qlmacf1 0.16709, ql_loss 1.01619, chxlmicf1 0.43102, chxlmacf1 0.39642, chx_loss 1.01707, chxlacc 0.62795, chxlrocaucmic 0.70554, chxlrocaucmac 0.68787, gacc 0.85239, gloss 0.35602, cxr14micf1 0.20953, cxr14macf1 0.24301, cxr14_loss 1.15386, vnbgmicf1 0.39013, vnbgmacf1 0.30163, vnbg_loss 1.32039, b1 0.39596, b2 0.28637, b3 0.20161, b4 0.14197, padchxlmacf1 0.04184, padchxlmicf1 0.10579, padchxlzmacf1 0.06208, padchxlzmicf1 0.10851, padchxl_loss 0.62048, padchxlz_loss 0.75720, 134.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.54929, wmdcmp 0.08227, ema 0.61773, oracc 0.96937, qlmicf1 0.26508, qlmacf1 0.17731, chxlmicf1 0.45512, chxlmacf1 0.40275, chxlacc 0.62702, chxlrocaucmic 0.71206, chxlrocaucmac 0.67449, 33.43 secs\n",
      "Adjusting learning rate of group 0 to 2.1377e-05.\n",
      "\u001b[1m---- Epoch 28/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 2.23795, a_loss 1.41571, cD 0.71232, wmdcmp 0.10149, ema 0.52705, oracc 0.96044, orien_loss 0.09959, qlmicf1 0.25405, qlmacf1 0.16736, ql_loss 1.01768, chxlmicf1 0.42150, chxlmacf1 0.39159, chx_loss 1.02112, chxlacc 0.62508, chxlrocaucmic 0.70009, chxlrocaucmac 0.68049, gacc 0.85034, gloss 0.36156, cxr14micf1 0.21660, cxr14macf1 0.24859, cxr14_loss 1.14050, vnbgmicf1 0.40045, vnbgmacf1 0.30580, vnbg_loss 1.32819, b1 0.39939, b2 0.28989, b3 0.20652, b4 0.14872, padchxlmacf1 0.04137, padchxlmicf1 0.10184, padchxlzmacf1 0.05809, padchxlzmicf1 0.10391, padchxl_loss 0.61914, padchxlz_loss 0.77170, 134.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.56587, wmdcmp 0.08401, ema 0.63832, oracc 0.96866, qlmicf1 0.26196, qlmacf1 0.17710, chxlmicf1 0.45445, chxlmacf1 0.40337, chxlacc 0.62545, chxlrocaucmic 0.71041, chxlrocaucmac 0.67389, 33.49 secs\n",
      "Adjusting learning rate of group 0 to 1.8712e-05.\n",
      "\u001b[1m---- Epoch 29/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 5.56101, a_loss 1.44925, cD 0.70980, wmdcmp 0.10096, ema 0.52599, oracc 0.96162, orien_loss 0.09896, qlmicf1 0.25338, qlmacf1 0.16887, ql_loss 1.02007, chxlmicf1 0.43014, chxlmacf1 0.39554, chx_loss 1.01803, chxlacc 0.62840, chxlrocaucmic 0.70398, chxlrocaucmac 0.68574, gacc 0.85343, gloss 0.35664, cxr14micf1 0.21165, cxr14macf1 0.24509, cxr14_loss 1.15070, vnbgmicf1 0.38961, vnbgmacf1 0.30324, vnbg_loss 1.32754, b1 0.40778, b2 0.29648, b3 0.21266, b4 0.15529, padchxlmacf1 0.04265, padchxlmicf1 0.10473, padchxlzmacf1 0.06239, padchxlzmicf1 0.11126, padchxl_loss 0.63133, padchxlz_loss 0.76273, 134.56 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.57978, wmdcmp 0.08661, ema 0.61952, oracc 0.96866, qlmicf1 0.26402, qlmacf1 0.17823, chxlmicf1 0.45671, chxlmacf1 0.40560, chxlacc 0.62602, chxlrocaucmic 0.71320, chxlrocaucmac 0.67473, 33.35 secs\n",
      "Adjusting learning rate of group 0 to 1.6379e-05.\n",
      "\u001b[1m---- Epoch 30/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 3.39753, a_loss 1.42251, cD 0.72019, wmdcmp 0.10341, ema 0.52964, oracc 0.95934, orien_loss 0.10001, qlmicf1 0.25412, qlmacf1 0.16825, ql_loss 1.01538, chxlmicf1 0.43315, chxlmacf1 0.39708, chx_loss 1.01228, chxlacc 0.62832, chxlrocaucmic 0.70678, chxlrocaucmac 0.68745, gacc 0.84810, gloss 0.35890, cxr14micf1 0.20570, cxr14macf1 0.24076, cxr14_loss 1.14505, vnbgmicf1 0.40499, vnbgmacf1 0.31121, vnbg_loss 1.30880, b1 0.40291, b2 0.29311, b3 0.20919, b4 0.15123, padchxlmacf1 0.04234, padchxlmicf1 0.10881, padchxlzmacf1 0.06456, padchxlzmicf1 0.11433, padchxl_loss 0.62020, padchxlz_loss 0.76768, 133.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57943, wmdcmp 0.08684, ema 0.61325, oracc 0.96960, qlmicf1 0.26671, qlmacf1 0.17827, chxlmicf1 0.45504, chxlmacf1 0.40458, chxlacc 0.62423, chxlrocaucmic 0.71200, chxlrocaucmac 0.67413, 34.71 secs\n",
      "Adjusting learning rate of group 0 to 1.4337e-05.\n",
      "\u001b[1m---- Epoch 31/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.50596, a_loss 1.41654, cD 0.70830, wmdcmp 0.10137, ema 0.53171, oracc 0.96224, orien_loss 0.09462, qlmicf1 0.25275, qlmacf1 0.16645, ql_loss 1.01807, chxlmicf1 0.43214, chxlmacf1 0.39688, chx_loss 1.01577, chxlacc 0.62927, chxlrocaucmic 0.70567, chxlrocaucmac 0.68661, gacc 0.85362, gloss 0.35642, cxr14micf1 0.21690, cxr14macf1 0.24899, cxr14_loss 1.14145, vnbgmicf1 0.37946, vnbgmacf1 0.29983, vnbg_loss 1.32389, b1 0.43068, b2 0.31519, b3 0.22275, b4 0.15787, padchxlmacf1 0.04373, padchxlmicf1 0.10807, padchxlzmacf1 0.06345, padchxlzmicf1 0.11128, padchxl_loss 0.62786, padchxlz_loss 0.77022, 135.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57393, wmdcmp 0.08662, ema 0.62220, oracc 0.96937, qlmicf1 0.26620, qlmacf1 0.17738, chxlmicf1 0.45950, chxlmacf1 0.40792, chxlacc 0.62658, chxlrocaucmic 0.71500, chxlrocaucmac 0.67697, 33.59 secs\n",
      "Adjusting learning rate of group 0 to 1.2550e-05.\n",
      "\u001b[1m---- Epoch 32/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 5.35698, a_loss 1.42666, cD 0.70844, wmdcmp 0.10164, ema 0.52739, oracc 0.96105, orien_loss 0.09863, qlmicf1 0.25497, qlmacf1 0.16824, ql_loss 1.01150, chxlmicf1 0.42682, chxlmacf1 0.39490, chx_loss 1.01964, chxlacc 0.62630, chxlrocaucmic 0.70235, chxlrocaucmac 0.68219, gacc 0.85739, gloss 0.35657, cxr14micf1 0.21961, cxr14macf1 0.24981, cxr14_loss 1.14516, vnbgmicf1 0.39939, vnbgmacf1 0.31186, vnbg_loss 1.30979, b1 0.40025, b2 0.29325, b3 0.21087, b4 0.15339, padchxlmacf1 0.04147, padchxlmicf1 0.10337, padchxlzmacf1 0.06333, padchxlzmicf1 0.11331, padchxl_loss 0.62100, padchxlz_loss 0.75539, 133.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.58530, wmdcmp 0.08722, ema 0.61325, oracc 0.96913, qlmicf1 0.26732, qlmacf1 0.17825, chxlmicf1 0.45700, chxlmacf1 0.40638, chxlacc 0.62416, chxlrocaucmic 0.71333, chxlrocaucmac 0.67536, 33.34 secs\n",
      "Adjusting learning rate of group 0 to 1.0986e-05.\n",
      "\u001b[1m---- Epoch 33/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.87403, a_loss 1.42389, cD 0.70988, wmdcmp 0.10170, ema 0.53520, oracc 0.96276, orien_loss 0.09824, qlmicf1 0.25372, qlmacf1 0.16775, ql_loss 1.01657, chxlmicf1 0.43342, chxlmacf1 0.39729, chx_loss 1.01666, chxlacc 0.62816, chxlrocaucmic 0.70642, chxlrocaucmac 0.68733, gacc 0.85610, gloss 0.35220, cxr14micf1 0.20929, cxr14macf1 0.24310, cxr14_loss 1.15008, vnbgmicf1 0.39664, vnbgmacf1 0.30228, vnbg_loss 1.31429, b1 0.42921, b2 0.31434, b3 0.22440, b4 0.16186, padchxlmacf1 0.04302, padchxlmicf1 0.10840, padchxlzmacf1 0.06392, padchxlzmicf1 0.11124, padchxl_loss 0.61672, padchxlz_loss 0.78721, 134.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57939, wmdcmp 0.08769, ema 0.62578, oracc 0.97078, qlmicf1 0.26456, qlmacf1 0.17773, chxlmicf1 0.45800, chxlmacf1 0.40670, chxlacc 0.62575, chxlrocaucmic 0.71309, chxlrocaucmac 0.67697, 33.46 secs\n",
      "Adjusting learning rate of group 0 to 9.6161e-06.\n",
      "\u001b[1m---- Epoch 34/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.32415, a_loss 1.41913, cD 0.72310, wmdcmp 0.10310, ema 0.53400, oracc 0.96238, orien_loss 0.09805, qlmicf1 0.25360, qlmacf1 0.16798, ql_loss 1.01328, chxlmicf1 0.42590, chxlmacf1 0.39376, chx_loss 1.01746, chxlacc 0.62823, chxlrocaucmic 0.70396, chxlrocaucmac 0.68571, gacc 0.85720, gloss 0.34975, cxr14micf1 0.21184, cxr14macf1 0.24664, cxr14_loss 1.14475, vnbgmicf1 0.39434, vnbgmacf1 0.30112, vnbg_loss 1.31402, b1 0.42194, b2 0.30854, b3 0.21924, b4 0.15612, padchxlmacf1 0.04264, padchxlmicf1 0.10757, padchxlzmacf1 0.06112, padchxlzmicf1 0.10918, padchxl_loss 0.61923, padchxlz_loss 0.74400, 135.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.58342, wmdcmp 0.08763, ema 0.61415, oracc 0.96984, qlmicf1 0.26760, qlmacf1 0.17844, chxlmicf1 0.45967, chxlmacf1 0.40738, chxlacc 0.62730, chxlrocaucmic 0.71581, chxlrocaucmac 0.67618, 33.53 secs\n",
      "Adjusting learning rate of group 0 to 8.4174e-06.\n",
      "\u001b[1m---- Epoch 35/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 5.59940, a_loss 1.41794, cD 0.73424, wmdcmp 0.10429, ema 0.52777, oracc 0.96288, orien_loss 0.09886, qlmicf1 0.25666, qlmacf1 0.16842, ql_loss 1.01315, chxlmicf1 0.43421, chxlmacf1 0.39666, chx_loss 1.01590, chxlacc 0.63008, chxlrocaucmic 0.70666, chxlrocaucmac 0.68650, gacc 0.86390, gloss 0.34390, cxr14micf1 0.21368, cxr14macf1 0.24721, cxr14_loss 1.14769, vnbgmicf1 0.40098, vnbgmacf1 0.30446, vnbg_loss 1.31675, b1 0.41728, b2 0.30642, b3 0.22129, b4 0.16317, padchxlmacf1 0.04219, padchxlmicf1 0.10728, padchxlzmacf1 0.06519, padchxlzmicf1 0.12175, padchxl_loss 0.60940, padchxlz_loss 0.73559, 135.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59711, wmdcmp 0.08898, ema 0.62489, oracc 0.96937, qlmicf1 0.26759, qlmacf1 0.17853, chxlmicf1 0.45904, chxlmacf1 0.40744, chxlacc 0.62694, chxlrocaucmic 0.71527, chxlrocaucmac 0.67635, 33.44 secs\n",
      "Adjusting learning rate of group 0 to 7.3681e-06.\n",
      "\u001b[1m---- Epoch 36/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 1.25770, a_loss 1.40908, cD 0.72378, wmdcmp 0.10308, ema 0.53242, oracc 0.96244, orien_loss 0.09691, qlmicf1 0.25566, qlmacf1 0.16845, ql_loss 1.01332, chxlmicf1 0.42389, chxlmacf1 0.39313, chx_loss 1.01700, chxlacc 0.62958, chxlrocaucmic 0.70401, chxlrocaucmac 0.68546, gacc 0.85565, gloss 0.35120, cxr14micf1 0.21459, cxr14macf1 0.24828, cxr14_loss 1.13991, vnbgmicf1 0.38194, vnbgmacf1 0.29997, vnbg_loss 1.31311, b1 0.43595, b2 0.32152, b3 0.23486, b4 0.17213, padchxlmacf1 0.04132, padchxlmicf1 0.10326, padchxlzmacf1 0.05976, padchxlzmicf1 0.10665, padchxl_loss 0.61534, padchxlz_loss 0.77358, 134.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59615, wmdcmp 0.08914, ema 0.61594, oracc 0.96890, qlmicf1 0.26582, qlmacf1 0.17894, chxlmicf1 0.45907, chxlmacf1 0.40775, chxlacc 0.62459, chxlrocaucmic 0.71559, chxlrocaucmac 0.67586, 33.50 secs\n",
      "Adjusting learning rate of group 0 to 6.4496e-06.\n",
      "\u001b[1m---- Epoch 37/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.20103, a_loss 1.41632, cD 0.71923, wmdcmp 0.10333, ema 0.53482, oracc 0.95999, orien_loss 0.10175, qlmicf1 0.25440, qlmacf1 0.16822, ql_loss 1.01574, chxlmicf1 0.43444, chxlmacf1 0.39710, chx_loss 1.01442, chxlacc 0.62997, chxlrocaucmic 0.70755, chxlrocaucmac 0.68759, gacc 0.85771, gloss 0.35548, cxr14micf1 0.20559, cxr14macf1 0.23960, cxr14_loss 1.15969, vnbgmicf1 0.41414, vnbgmacf1 0.30807, vnbg_loss 1.30574, b1 0.41927, b2 0.30917, b3 0.22409, b4 0.16478, padchxlmacf1 0.04202, padchxlmicf1 0.11052, padchxlzmacf1 0.06428, padchxlzmicf1 0.11885, padchxl_loss 0.60342, padchxlz_loss 0.75055, 134.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59497, wmdcmp 0.08995, ema 0.62757, oracc 0.96725, qlmicf1 0.26885, qlmacf1 0.17821, chxlmicf1 0.45805, chxlmacf1 0.40682, chxlacc 0.62591, chxlrocaucmic 0.71414, chxlrocaucmac 0.67498, 33.84 secs\n",
      "Adjusting learning rate of group 0 to 5.6455e-06.\n",
      "\u001b[1m---- Epoch 38/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.65470, a_loss 1.40549, cD 0.71447, wmdcmp 0.10186, ema 0.53881, oracc 0.96088, orien_loss 0.09665, qlmicf1 0.25734, qlmacf1 0.16845, ql_loss 1.01481, chxlmicf1 0.42545, chxlmacf1 0.39354, chx_loss 1.01680, chxlacc 0.62838, chxlrocaucmic 0.70341, chxlrocaucmac 0.68326, gacc 0.85614, gloss 0.35433, cxr14micf1 0.20670, cxr14macf1 0.24198, cxr14_loss 1.15235, vnbgmicf1 0.39043, vnbgmacf1 0.30141, vnbg_loss 1.31283, b1 0.42178, b2 0.30642, b3 0.21650, b4 0.15644, padchxlmacf1 0.04154, padchxlmicf1 0.10176, padchxlzmacf1 0.06038, padchxlzmicf1 0.10530, padchxl_loss 0.60955, padchxlz_loss 0.76392, 132.13 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.59091, wmdcmp 0.08894, ema 0.62310, oracc 0.96795, qlmicf1 0.26577, qlmacf1 0.17824, chxlmicf1 0.45620, chxlmacf1 0.40524, chxlacc 0.62614, chxlrocaucmic 0.71289, chxlrocaucmac 0.67503, 33.56 secs\n",
      "Adjusting learning rate of group 0 to 4.9418e-06.\n",
      "\u001b[1m---- Epoch 39/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.73575, a_loss 1.40554, cD 0.72608, wmdcmp 0.10410, ema 0.53496, oracc 0.96094, orien_loss 0.09894, qlmicf1 0.25482, qlmacf1 0.16794, ql_loss 1.01550, chxlmicf1 0.42668, chxlmacf1 0.39453, chx_loss 1.01736, chxlacc 0.62821, chxlrocaucmic 0.70508, chxlrocaucmac 0.68683, gacc 0.85229, gloss 0.35460, cxr14micf1 0.21888, cxr14macf1 0.25130, cxr14_loss 1.14242, vnbgmicf1 0.39260, vnbgmacf1 0.30099, vnbg_loss 1.32359, b1 0.42202, b2 0.30985, b3 0.22214, b4 0.15986, padchxlmacf1 0.04360, padchxlmicf1 0.10904, padchxlzmacf1 0.06414, padchxlzmicf1 0.10915, padchxl_loss 0.60979, padchxlz_loss 0.76166, 134.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59239, wmdcmp 0.08891, ema 0.62757, oracc 0.97008, qlmicf1 0.26701, qlmacf1 0.17894, chxlmicf1 0.45591, chxlmacf1 0.40543, chxlacc 0.62532, chxlrocaucmic 0.71412, chxlrocaucmac 0.67552, 33.45 secs\n",
      "Adjusting learning rate of group 0 to 4.3257e-06.\n",
      "\u001b[1m---- Epoch 40/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.56424, a_loss 1.41778, cD 0.73725, wmdcmp 0.10458, ema 0.53439, oracc 0.96126, orien_loss 0.09921, qlmicf1 0.25414, qlmacf1 0.16818, ql_loss 1.01625, chxlmicf1 0.42723, chxlmacf1 0.39506, chx_loss 1.01549, chxlacc 0.62768, chxlrocaucmic 0.70392, chxlrocaucmac 0.68514, gacc 0.85790, gloss 0.34935, cxr14micf1 0.20807, cxr14macf1 0.24211, cxr14_loss 1.15095, vnbgmicf1 0.40059, vnbgmacf1 0.30620, vnbg_loss 1.31343, b1 0.41668, b2 0.30520, b3 0.21934, b4 0.16127, padchxlmacf1 0.04243, padchxlmicf1 0.10754, padchxlzmacf1 0.06200, padchxlzmicf1 0.10893, padchxl_loss 0.62373, padchxlz_loss 0.76488, 134.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59069, wmdcmp 0.08931, ema 0.61862, oracc 0.96984, qlmicf1 0.26504, qlmacf1 0.17727, chxlmicf1 0.45723, chxlmacf1 0.40582, chxlacc 0.62521, chxlrocaucmic 0.71344, chxlrocaucmac 0.67517, 33.61 secs\n",
      "Adjusting learning rate of group 0 to 3.7865e-06.\n",
      "\u001b[1m---- Epoch 41/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 5.57031, a_loss 1.40992, cD 0.72732, wmdcmp 0.10431, ema 0.53583, oracc 0.96178, orien_loss 0.09669, qlmicf1 0.25439, qlmacf1 0.16867, ql_loss 1.01644, chxlmicf1 0.43118, chxlmacf1 0.39618, chx_loss 1.01288, chxlacc 0.62819, chxlrocaucmic 0.70654, chxlrocaucmac 0.68788, gacc 0.85217, gloss 0.36033, cxr14micf1 0.22172, cxr14macf1 0.25255, cxr14_loss 1.13354, vnbgmicf1 0.38155, vnbgmacf1 0.29379, vnbg_loss 1.30697, b1 0.42291, b2 0.31027, b3 0.22312, b4 0.16396, padchxlmacf1 0.04438, padchxlmicf1 0.10839, padchxlzmacf1 0.06158, padchxlzmicf1 0.10759, padchxl_loss 0.62200, padchxlz_loss 0.75491, 135.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.58499, wmdcmp 0.08835, ema 0.62399, oracc 0.97172, qlmicf1 0.26483, qlmacf1 0.17792, chxlmicf1 0.45972, chxlmacf1 0.40869, chxlacc 0.62681, chxlrocaucmic 0.71502, chxlrocaucmac 0.67648, 33.46 secs\n",
      "Adjusting learning rate of group 0 to 3.3145e-06.\n",
      "\u001b[1m---- Epoch 42/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.97905, a_loss 1.42093, cD 0.71449, wmdcmp 0.10203, ema 0.53295, oracc 0.96331, orien_loss 0.09879, qlmicf1 0.25622, qlmacf1 0.16887, ql_loss 1.01009, chxlmicf1 0.42583, chxlmacf1 0.39292, chx_loss 1.02038, chxlacc 0.62842, chxlrocaucmic 0.70426, chxlrocaucmac 0.68399, gacc 0.85762, gloss 0.34985, cxr14micf1 0.22117, cxr14macf1 0.24894, cxr14_loss 1.14632, vnbgmicf1 0.39918, vnbgmacf1 0.30093, vnbg_loss 1.31373, b1 0.41980, b2 0.30617, b3 0.21991, b4 0.15856, padchxlmacf1 0.04193, padchxlmicf1 0.10438, padchxlzmacf1 0.06061, padchxlzmicf1 0.10807, padchxl_loss 0.61406, padchxlz_loss 0.76135, 134.17 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59835, wmdcmp 0.08960, ema 0.62578, oracc 0.97078, qlmicf1 0.26684, qlmacf1 0.17825, chxlmicf1 0.45698, chxlmacf1 0.40632, chxlacc 0.62483, chxlrocaucmic 0.71360, chxlrocaucmac 0.67530, 33.30 secs\n",
      "Adjusting learning rate of group 0 to 2.9013e-06.\n",
      "\u001b[1m---- Epoch 43/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.14878, a_loss 1.41425, cD 0.73285, wmdcmp 0.10526, ema 0.53554, oracc 0.96179, orien_loss 0.09646, qlmicf1 0.25356, qlmacf1 0.16737, ql_loss 1.01914, chxlmicf1 0.42920, chxlmacf1 0.39361, chx_loss 1.01857, chxlacc 0.62664, chxlrocaucmic 0.70389, chxlrocaucmac 0.68318, gacc 0.86000, gloss 0.34859, cxr14micf1 0.22439, cxr14macf1 0.25507, cxr14_loss 1.13635, vnbgmicf1 0.39320, vnbgmacf1 0.30500, vnbg_loss 1.31825, b1 0.41617, b2 0.30516, b3 0.21798, b4 0.15760, padchxlmacf1 0.04177, padchxlmicf1 0.10106, padchxlzmacf1 0.06414, padchxlzmicf1 0.10867, padchxl_loss 0.62081, padchxlz_loss 0.77526, 133.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59432, wmdcmp 0.08919, ema 0.61325, oracc 0.97078, qlmicf1 0.26825, qlmacf1 0.17857, chxlmicf1 0.45932, chxlmacf1 0.40865, chxlacc 0.62720, chxlrocaucmic 0.71532, chxlrocaucmac 0.67800, 33.50 secs\n",
      "Adjusting learning rate of group 0 to 2.5396e-06.\n",
      "\u001b[1m---- Epoch 44/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.33530, a_loss 1.41529, cD 0.72010, wmdcmp 0.10312, ema 0.52614, oracc 0.96195, orien_loss 0.09651, qlmicf1 0.25398, qlmacf1 0.16818, ql_loss 1.01785, chxlmicf1 0.42289, chxlmacf1 0.39193, chx_loss 1.01976, chxlacc 0.62885, chxlrocaucmic 0.70327, chxlrocaucmac 0.68239, gacc 0.85333, gloss 0.35481, cxr14micf1 0.21111, cxr14macf1 0.24530, cxr14_loss 1.14585, vnbgmicf1 0.37354, vnbgmacf1 0.29453, vnbg_loss 1.32190, b1 0.41796, b2 0.30617, b3 0.21914, b4 0.15988, padchxlmacf1 0.04310, padchxlmicf1 0.10556, padchxlzmacf1 0.06311, padchxlzmicf1 0.10645, padchxl_loss 0.61290, padchxlz_loss 0.75920, 133.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59609, wmdcmp 0.08956, ema 0.62041, oracc 0.96960, qlmicf1 0.26674, qlmacf1 0.17900, chxlmicf1 0.45539, chxlmacf1 0.40490, chxlacc 0.62418, chxlrocaucmic 0.71303, chxlrocaucmac 0.67541, 33.49 secs\n",
      "Adjusting learning rate of group 0 to 2.2230e-06.\n",
      "\u001b[1m---- Epoch 45/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.24230, a_loss 1.39379, cD 0.73237, wmdcmp 0.10408, ema 0.53252, oracc 0.96089, orien_loss 0.09866, qlmicf1 0.25376, qlmacf1 0.16824, ql_loss 1.01629, chxlmicf1 0.43230, chxlmacf1 0.39612, chx_loss 1.01550, chxlacc 0.62960, chxlrocaucmic 0.70607, chxlrocaucmac 0.68649, gacc 0.85724, gloss 0.34716, cxr14micf1 0.21008, cxr14macf1 0.24508, cxr14_loss 1.15091, vnbgmicf1 0.40643, vnbgmacf1 0.30996, vnbg_loss 1.31207, b1 0.42998, b2 0.31879, b3 0.23164, b4 0.17050, padchxlmacf1 0.04450, padchxlmicf1 0.10196, padchxlzmacf1 0.06353, padchxlzmicf1 0.11120, padchxl_loss 0.61681, padchxlz_loss 0.76704, 133.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60122, wmdcmp 0.09018, ema 0.62936, oracc 0.97008, qlmicf1 0.26727, qlmacf1 0.17886, chxlmicf1 0.45861, chxlmacf1 0.40795, chxlacc 0.62620, chxlrocaucmic 0.71364, chxlrocaucmac 0.67673, 33.48 secs\n",
      "Adjusting learning rate of group 0 to 1.9459e-06.\n",
      "\u001b[1m---- Epoch 46/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.71928, a_loss 1.41661, cD 0.73030, wmdcmp 0.10413, ema 0.52777, oracc 0.96233, orien_loss 0.09635, qlmicf1 0.25499, qlmacf1 0.16843, ql_loss 1.01468, chxlmicf1 0.43060, chxlmacf1 0.39675, chx_loss 1.01521, chxlacc 0.62763, chxlrocaucmic 0.70563, chxlrocaucmac 0.68673, gacc 0.85729, gloss 0.34832, cxr14micf1 0.22248, cxr14macf1 0.25024, cxr14_loss 1.14025, vnbgmicf1 0.40155, vnbgmacf1 0.30694, vnbg_loss 1.31862, b1 0.40924, b2 0.29645, b3 0.20803, b4 0.14817, padchxlmacf1 0.04187, padchxlmicf1 0.10756, padchxlzmacf1 0.06123, padchxlzmicf1 0.11195, padchxl_loss 0.60682, padchxlz_loss 0.75421, 134.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60169, wmdcmp 0.09042, ema 0.62578, oracc 0.96866, qlmicf1 0.26744, qlmacf1 0.17859, chxlmicf1 0.45638, chxlmacf1 0.40518, chxlacc 0.62540, chxlrocaucmic 0.71293, chxlrocaucmac 0.67505, 33.42 secs\n",
      "Adjusting learning rate of group 0 to 1.7033e-06.\n",
      "\u001b[1m---- Epoch 47/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.62207, a_loss 1.42654, cD 0.73374, wmdcmp 0.10433, ema 0.53290, oracc 0.96246, orien_loss 0.10081, qlmicf1 0.25732, qlmacf1 0.16846, ql_loss 1.01312, chxlmicf1 0.43161, chxlmacf1 0.39563, chx_loss 1.01617, chxlacc 0.62938, chxlrocaucmic 0.70694, chxlrocaucmac 0.68712, gacc 0.85353, gloss 0.35898, cxr14micf1 0.21641, cxr14macf1 0.24601, cxr14_loss 1.14707, vnbgmicf1 0.39545, vnbgmacf1 0.30976, vnbg_loss 1.30133, b1 0.41346, b2 0.30016, b3 0.21194, b4 0.15209, padchxlmacf1 0.04161, padchxlmicf1 0.10546, padchxlzmacf1 0.06399, padchxlzmicf1 0.11287, padchxl_loss 0.61514, padchxlz_loss 0.75497, 134.57 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.59316, wmdcmp 0.08914, ema 0.62131, oracc 0.96819, qlmicf1 0.26693, qlmacf1 0.17815, chxlmicf1 0.45719, chxlmacf1 0.40625, chxlacc 0.62601, chxlrocaucmic 0.71460, chxlrocaucmac 0.67604, 33.33 secs\n",
      "Adjusting learning rate of group 0 to 1.4910e-06.\n",
      "\u001b[1m---- Epoch 48/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.81538, a_loss 1.39363, cD 0.74038, wmdcmp 0.10570, ema 0.52910, oracc 0.96272, orien_loss 0.09469, qlmicf1 0.25473, qlmacf1 0.16847, ql_loss 1.01524, chxlmicf1 0.43286, chxlmacf1 0.39685, chx_loss 1.01386, chxlacc 0.62915, chxlrocaucmic 0.70661, chxlrocaucmac 0.68669, gacc 0.86010, gloss 0.34712, cxr14micf1 0.21175, cxr14macf1 0.24562, cxr14_loss 1.14643, vnbgmicf1 0.40326, vnbgmacf1 0.30507, vnbg_loss 1.31699, b1 0.42314, b2 0.30995, b3 0.22238, b4 0.16010, padchxlmacf1 0.04272, padchxlmicf1 0.10297, padchxlzmacf1 0.05958, padchxlzmicf1 0.10543, padchxl_loss 0.61104, padchxlz_loss 0.73876, 133.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60862, wmdcmp 0.09145, ema 0.63295, oracc 0.97149, qlmicf1 0.26680, qlmacf1 0.17859, chxlmicf1 0.45690, chxlmacf1 0.40598, chxlacc 0.62506, chxlrocaucmic 0.71577, chxlrocaucmac 0.67862, 33.47 secs\n",
      "Adjusting learning rate of group 0 to 1.3051e-06.\n",
      "\u001b[1m---- Epoch 49/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.09841, a_loss 1.40930, cD 0.73754, wmdcmp 0.10502, ema 0.53516, oracc 0.96222, orien_loss 0.10248, qlmicf1 0.25410, qlmacf1 0.16680, ql_loss 1.01363, chxlmicf1 0.42424, chxlmacf1 0.39293, chx_loss 1.01827, chxlacc 0.62837, chxlrocaucmic 0.70386, chxlrocaucmac 0.68482, gacc 0.86116, gloss 0.35194, cxr14micf1 0.20815, cxr14macf1 0.24440, cxr14_loss 1.15120, vnbgmicf1 0.40897, vnbgmacf1 0.30758, vnbg_loss 1.29349, b1 0.40381, b2 0.29693, b3 0.21421, b4 0.15716, padchxlmacf1 0.04267, padchxlmicf1 0.10530, padchxlzmacf1 0.06507, padchxlzmicf1 0.12014, padchxl_loss 0.60972, padchxlz_loss 0.74993, 134.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60548, wmdcmp 0.09081, ema 0.62041, oracc 0.97149, qlmicf1 0.26575, qlmacf1 0.17882, chxlmicf1 0.45650, chxlmacf1 0.40519, chxlacc 0.62550, chxlrocaucmic 0.71248, chxlrocaucmac 0.67581, 33.45 secs\n",
      "Adjusting learning rate of group 0 to 1.1424e-06.\n",
      "\u001b[1m---- Epoch 50/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.70957, a_loss 1.41168, cD 0.74346, wmdcmp 0.10591, ema 0.52844, oracc 0.96251, orien_loss 0.09574, qlmicf1 0.25458, qlmacf1 0.16693, ql_loss 1.01198, chxlmicf1 0.42707, chxlmacf1 0.39452, chx_loss 1.01637, chxlacc 0.62794, chxlrocaucmic 0.70333, chxlrocaucmac 0.68388, gacc 0.85521, gloss 0.35467, cxr14micf1 0.21350, cxr14macf1 0.24625, cxr14_loss 1.14789, vnbgmicf1 0.38503, vnbgmacf1 0.29754, vnbg_loss 1.33063, b1 0.42208, b2 0.30760, b3 0.21640, b4 0.15509, padchxlmacf1 0.04267, padchxlmicf1 0.10715, padchxlzmacf1 0.06285, padchxlzmicf1 0.11500, padchxl_loss 0.62214, padchxlz_loss 0.75002, 134.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60109, wmdcmp 0.08991, ema 0.63115, oracc 0.97031, qlmicf1 0.26679, qlmacf1 0.17857, chxlmicf1 0.45863, chxlmacf1 0.40815, chxlacc 0.62686, chxlrocaucmic 0.71532, chxlrocaucmac 0.67836, 33.39 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 50 \\\n",
    "        --batches-per-epoch 200 \\\n",
    "        --batch-size 150 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 5 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,5,4e-4,45,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface-large\" \\\n",
    "        --huggingface-model-name \"facebook/vit-mae-large\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --freeze-image-encoder \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
