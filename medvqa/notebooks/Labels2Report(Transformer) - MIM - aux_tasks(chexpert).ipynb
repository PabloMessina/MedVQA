{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   labels_hidden_dim: 256\n",
      "   embedding_dim: 256\n",
      "   transf_dec_hidden_dim: 256\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   dropout_prob: 0\n",
      "   vocab_min_freq: 10\n",
      "   use_medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,5,4e-4,10,1e-6,4e-5,8,1e-6\n",
      "   iters_to_accumulate: 2\n",
      "   override_lr: False\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   batch_size: 150\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   train_mimiccxr: True\n",
      "   mimiccxr_weight: 1.0\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: balanced_chexpert_labels_batchwise\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   save: True\n",
      "   use_gender: False\n",
      "   use_chexpert: True\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   use_chest_imagenome: False\n",
      "   debug: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "chexpert_range: (0, 14)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mCreating instance of Labels2ReportModel ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,5,4e-4,10,1e-6,4e-5,8,1e-6\n",
      "1e-06 5 0.0004 10 1e-06 4e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 4e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "227835it [00:06, 36245.74it/s]\n",
      "max_idx_count = 377110\n",
      "actual_idx_count = 227835\n",
      "** NOTE: 149275 images were skipped because they were not in the allowed DICOM IDs\n",
      "len(self.train_indices) = 222758\n",
      "len(self.val_indices) = 1808\n",
      "Loading CheXpert labels...\n",
      "Balanced sampling mode: balanced_chexpert_labels_batchwise\n",
      "Regrouping indices by CheXpert labels for balanced sampling...\n",
      "100%|████████████████████████████████| 222758/222758 [00:03<00:00, 63159.93it/s]\n",
      "Label: Lung Opacity              , # images: 73723 (other: 149035)\n",
      "Label: Pneumonia                 , # images: 37343 (other: 185415)\n",
      "Label: Atelectasis               , # images: 69679 (other: 153079)\n",
      "Label: Cardiomegaly              , # images: 71657 (other: 151101)\n",
      "Label: No Finding                , # images: 43943 (other: 178815)\n",
      "Label: Enlarged Cardiomediastinum, # images: 43215 (other: 179543)\n",
      "Label: Fracture                  , # images: 8414 (other: 214344)\n",
      "Label: Pleural Effusion          , # images: 68498 (other: 154260)\n",
      "Label: Consolidation             , # images: 19790 (other: 202968)\n",
      "Label: Pleural Other             , # images: 4944 (other: 217814)\n",
      "Label: Support Devices           , # images: 87915 (other: 134843)\n",
      "Label: Edema                     , # images: 42623 (other: 180135)\n",
      "Label: Lung Lesion               , # images: 9668 (other: 213090)\n",
      "Label: Pneumothorax              , # images: 13071 (other: 209687)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 10.53920, cD 0.00012, wmdcmp 0.00490, report_loss 8.53646, chxlaucmic 0.41651, chxlaucmac 0.40152, chxlprcaucmic 0.19111, chxlprcaucmac 0.22292, chx_loss 1.91848, 120.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00008, wmdcmp 0.00775, chxlaucmic 0.42368, chxlaucmac 0.39417, chxlprcaucmic 0.16190, chxlprcaucmac 0.18889, 10.11 secs\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 10.34458, cD 0.00037, wmdcmp 0.00611, report_loss 8.20344, chxlaucmic 0.42483, chxlaucmac 0.40798, chxlprcaucmic 0.19404, chxlprcaucmac 0.22593, chx_loss 1.91225, 114.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00000, wmdcmp 0.00568, chxlaucmic 0.43537, chxlaucmac 0.39992, chxlprcaucmic 0.16532, chxlprcaucmac 0.19210, 8.35 secs\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 9.85449, cD 0.00013, wmdcmp 0.00107, report_loss 7.06696, chxlaucmic 0.45370, chxlaucmac 0.43374, chxlprcaucmic 0.20545, chxlprcaucmac 0.23629, chx_loss 1.89626, 84.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00040, wmdcmp 0.00055, chxlaucmic 0.48333, chxlaucmac 0.43972, chxlprcaucmic 0.18226, chxlprcaucmac 0.21059, 7.99 secs\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 8.29632, cD 0.00292, wmdcmp 0.00700, report_loss 5.47340, chxlaucmic 0.55783, chxlaucmac 0.51808, chxlprcaucmic 0.25558, chxlprcaucmac 0.27215, chx_loss 1.85016, 85.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00003, wmdcmp 0.00915, chxlaucmic 0.65192, chxlaucmac 0.55832, chxlprcaucmic 0.30500, chxlprcaucmac 0.30468, 9.40 secs\n",
      "\u001b[1m---- Epoch 5/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000121) ...\n",
      "loss 6.71063, cD 0.13715, wmdcmp 0.06336, report_loss 4.25779, chxlaucmic 0.80015, chxlaucmac 0.72635, chxlprcaucmic 0.63004, chxlprcaucmac 0.44714, chx_loss 1.71918, 90.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00713, wmdcmp 0.04099, chxlaucmic 0.92659, chxlaucmac 0.85668, chxlprcaucmic 0.87976, chxlprcaucmac 0.67861, 8.05 secs\n",
      "\u001b[1m---- Epoch 6/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 5.37634, cD 0.61879, wmdcmp 0.13494, report_loss 3.24873, chxlaucmic 0.99180, chxlaucmac 0.98966, chxlprcaucmic 0.98368, chxlprcaucmac 0.95475, chx_loss 1.10053, 91.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.25876, wmdcmp 0.10484, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.71 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000220) ...\n",
      "loss 3.63384, cD 0.85548, wmdcmp 0.16889, report_loss 2.82182, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.46990, 91.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.27457, wmdcmp 0.11555, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.76 secs\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000121) ...\n",
      "loss 3.08471, cD 0.94561, wmdcmp 0.18186, report_loss 2.69853, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.31479, 89.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35034, wmdcmp 0.12103, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.31 secs\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000066) ...\n",
      "loss 3.09296, cD 0.98181, wmdcmp 0.18766, report_loss 2.64764, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.25967, 89.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32824, wmdcmp 0.11918, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.91 secs\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 3.09383, cD 1.00163, wmdcmp 0.19136, report_loss 2.62301, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.23590, 88.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32580, wmdcmp 0.12066, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.99 secs\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 2.25098, cD 1.01391, wmdcmp 0.19290, report_loss 2.60649, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.22322, 89.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32984, wmdcmp 0.12099, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.10 secs\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 2.79502, cD 1.02277, wmdcmp 0.19414, report_loss 2.60363, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.21643, 88.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32393, wmdcmp 0.12074, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.07 secs\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 2.64049, cD 1.02882, wmdcmp 0.19563, report_loss 2.59393, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.21270, 88.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32657, wmdcmp 0.12053, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.93 secs\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.86569, cD 1.02565, wmdcmp 0.19414, report_loss 2.60000, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.21066, 88.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32666, wmdcmp 0.12055, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.02 secs\n",
      "\u001b[1m---- Epoch 15/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.79620, cD 1.03395, wmdcmp 0.19631, report_loss 2.58613, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.20921, 87.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32868, wmdcmp 0.12071, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.01 secs\n",
      "\u001b[1m---- Epoch 16/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.86547, cD 1.03540, wmdcmp 0.19560, report_loss 2.59017, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.20935, 87.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.32799, wmdcmp 0.12061, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.95 secs\n",
      "\u001b[1m---- Epoch 17/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.07839, cD 1.03092, wmdcmp 0.19544, report_loss 2.58700, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.19973, 86.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33648, wmdcmp 0.12135, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.92 secs\n",
      "\u001b[1m---- Epoch 18/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.28465, cD 1.04630, wmdcmp 0.19871, report_loss 2.56597, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.18659, 86.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33854, wmdcmp 0.12227, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.96 secs\n",
      "\u001b[1m---- Epoch 19/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.74622, cD 1.05777, wmdcmp 0.19914, report_loss 2.56420, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.17871, 87.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37611, wmdcmp 0.12185, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.06 secs\n",
      "\u001b[1m---- Epoch 20/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.65251, cD 1.05804, wmdcmp 0.19999, report_loss 2.55031, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.17430, 86.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33756, wmdcmp 0.12256, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.98 secs\n",
      "\u001b[1m---- Epoch 21/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.75483, cD 1.05924, wmdcmp 0.19935, report_loss 2.55226, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.17188, 86.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34280, wmdcmp 0.12154, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.10 secs\n",
      "\u001b[1m---- Epoch 22/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.67124, cD 1.06788, wmdcmp 0.20132, report_loss 2.54510, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.17007, 86.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34482, wmdcmp 0.12139, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.06 secs\n",
      "\u001b[1m---- Epoch 23/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.65022, cD 1.06032, wmdcmp 0.19993, report_loss 2.54679, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.16937, 86.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34543, wmdcmp 0.12152, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.95 secs\n",
      "\u001b[1m---- Epoch 24/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.98686, cD 1.05716, wmdcmp 0.19960, report_loss 2.54817, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.16869, 86.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34481, wmdcmp 0.12193, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.00 secs\n",
      "\u001b[1m---- Epoch 25/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 2.10171, cD 1.06694, wmdcmp 0.20057, report_loss 2.54089, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.16047, 86.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37733, wmdcmp 0.12194, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.95 secs\n",
      "\u001b[1m---- Epoch 26/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.74679, cD 1.08025, wmdcmp 0.20253, report_loss 2.52489, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.14817, 85.30 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35248, wmdcmp 0.12354, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.01 secs\n",
      "\u001b[1m---- Epoch 27/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.65788, cD 1.08325, wmdcmp 0.20353, report_loss 2.51555, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.14179, 85.97 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33230, wmdcmp 0.11805, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 7.91 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 28/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.62658, cD 1.08059, wmdcmp 0.20356, report_loss 2.51388, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.13774, 86.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33065, wmdcmp 0.11704, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.24 secs\n",
      "\u001b[1m---- Epoch 29/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.59325, cD 1.09525, wmdcmp 0.20531, report_loss 2.50581, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.13569, 86.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34592, wmdcmp 0.11818, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.02 secs\n",
      "\u001b[1m---- Epoch 30/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.64226, cD 1.09601, wmdcmp 0.20510, report_loss 2.50169, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.13447, 85.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34483, wmdcmp 0.11853, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.21 secs\n",
      "\u001b[1m---- Epoch 31/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.83566, cD 1.08959, wmdcmp 0.20435, report_loss 2.51496, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.13358, 87.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34329, wmdcmp 0.11822, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.25 secs\n",
      "\u001b[1m---- Epoch 32/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.08611, cD 1.09793, wmdcmp 0.20543, report_loss 2.50610, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.13295, 91.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34440, wmdcmp 0.11824, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.61 secs\n",
      "\u001b[1m---- Epoch 33/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 2.64580, cD 1.09475, wmdcmp 0.20496, report_loss 2.49736, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.12634, 93.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39335, wmdcmp 0.12480, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.72 secs\n",
      "\u001b[1m---- Epoch 34/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.64294, cD 1.10537, wmdcmp 0.20690, report_loss 2.48717, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.11603, 96.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34512, wmdcmp 0.11909, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.67 secs\n",
      "\u001b[1m---- Epoch 35/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.67773, cD 1.11316, wmdcmp 0.20794, report_loss 2.47702, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.11077, 98.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35952, wmdcmp 0.11983, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.78 secs\n",
      "\u001b[1m---- Epoch 36/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.58578, cD 1.11894, wmdcmp 0.20884, report_loss 2.47201, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.10708, 99.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35133, wmdcmp 0.11863, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 9.02 secs\n",
      "\u001b[1m---- Epoch 37/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.62287, cD 1.12443, wmdcmp 0.20868, report_loss 2.46965, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.10568, 99.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35567, wmdcmp 0.11878, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 8.82 secs\n",
      "\u001b[1m---- Epoch 38/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.83149, cD 1.12870, wmdcmp 0.20975, report_loss 2.46401, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.10415, 98.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35160, wmdcmp 0.11875, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 9.10 secs\n",
      "\u001b[1m---- Epoch 39/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.09628, cD 1.12020, wmdcmp 0.20900, report_loss 2.46759, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.10378, 102.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35242, wmdcmp 0.11836, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 9.06 secs\n",
      "\u001b[1m---- Epoch 40/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.60934, cD 1.11752, wmdcmp 0.20945, report_loss 2.46909, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.10344, 107.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35545, wmdcmp 0.11970, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 9.03 secs\n",
      "\u001b[1m---- Epoch 41/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 2.42833, cD 1.12632, wmdcmp 0.20917, report_loss 2.46085, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.09737, 109.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.36471, wmdcmp 0.12102, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 9.64 secs\n",
      "\u001b[1m---- Epoch 42/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.56303, cD 1.13720, wmdcmp 0.21094, report_loss 2.44818, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.08977, 109.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35093, wmdcmp 0.11824, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 10.02 secs\n",
      "\u001b[1m---- Epoch 43/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "^C iteration 12800\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_labels2report.py\", line 730, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_labels2report.py\", line 624, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_labels2report.py\", line 427, in train_model\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1069, in _run_once_on_dataset_as_gen\n",
      "    self._fire_event(Events.ITERATION_COMPLETED)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 425, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/dataset_aware_metric.py\", line 30, in iteration_completed_handler\n",
      "    self.update(self.output_transform(output))\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/medical/med_completeness/__init__.py\", line 281, in update\n",
      "    score = self.score(gt_s, pred_s)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/medical/med_completeness/__init__.py\", line 205, in score\n",
      "    w = self.ids2weight[k].get(key, 0)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!/home/pamessina/venv2/bin/python ../train_labels2report.py \\\n",
    "    --epochs 80 \\\n",
    "    --batches-per-epoch 300 \\\n",
    "    --batch-size 150 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 2 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-decay-and-cyclic-decay-args \"1e-6,5,4e-4,10,1e-6,4e-5,8,1e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"any_single\" \\\n",
    "    --mimiccxr-balanced-sampling-mode \"balanced_chexpert_labels_batchwise\" \\\n",
    "    --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "    --use-chexpert \\\n",
    "    --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "    --use-medical-tokenization \\\n",
    "    --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "    --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 37\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   labels_hidden_dim: 256\n",
      "   embedding_dim: 256\n",
      "   transf_dec_hidden_dim: 256\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   dropout_prob: 0\n",
      "   vocab_min_freq: 10\n",
      "   use_medical_tokenization: False\n",
      "   medical_terms_frequency_filename: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,4,4e-4,8,5e-6,2e-4,8,5e-6\n",
      "   iters_to_accumulate: 2\n",
      "   override_lr: True\n",
      "   binary_loss_name: bce\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   batch_size: 150\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   train_mimiccxr: False\n",
      "   mimiccxr_weight: 1\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   save: True\n",
      "   use_gender: False\n",
      "   use_chexpert: False\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   use_chest_imagenome: False\n",
      "   debug: False\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mCreating instance of Labels2ReportModel ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,4,4e-4,8,5e-6,2e-4,8,5e-6\n",
      "1e-06 4 0.0004 8 5e-06 0.0002 8 5e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0002\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "227835it [00:10, 21613.70it/s]\n",
      "max_idx_count = 377110\n",
      "actual_idx_count = 227835\n",
      "** NOTE: 149275 images were skipped because they were not in the allowed DICOM IDs\n",
      "len(self.train_indices) = 222758\n",
      "len(self.val_indices) = 1808\n",
      "Loading CheXpert labels...\n",
      "Balanced sampling mode: balanced_chexpert_labels_batchwise\n",
      "Regrouping indices by CheXpert labels for balanced sampling...\n",
      "100%|████████████████████████████████| 222758/222758 [00:05<00:00, 44508.50it/s]\n",
      "Label: Lung Opacity              , # images: 73723 (other: 149035)\n",
      "Label: Pneumonia                 , # images: 37343 (other: 185415)\n",
      "Label: Atelectasis               , # images: 69679 (other: 153079)\n",
      "Label: Cardiomegaly              , # images: 71657 (other: 151101)\n",
      "Label: No Finding                , # images: 43943 (other: 178815)\n",
      "Label: Enlarged Cardiomediastinum, # images: 43215 (other: 179543)\n",
      "Label: Fracture                  , # images: 8414 (other: 214344)\n",
      "Label: Pleural Effusion          , # images: 68498 (other: 154260)\n",
      "Label: Consolidation             , # images: 19790 (other: 202968)\n",
      "Label: Pleural Other             , # images: 4944 (other: 217814)\n",
      "Label: Support Devices           , # images: 87915 (other: 134843)\n",
      "Label: Edema                     , # images: 42623 (other: 180135)\n",
      "Label: Lung Lesion               , # images: 9668 (other: 213090)\n",
      "Label: Pneumothorax              , # images: 13071 (other: 209687)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_33_chxlauc+chxlprcauc+cD+wmdcmp=0.7030.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)/checkpoint_33_chxlauc+chxlprcauc+cD+wmdcmp=0.7030.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 34/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.72235, cD 1.10938, wmdcmp 0.20682, report_loss 2.48318, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.11952, 107.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35062, wmdcmp 0.11951, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 9.22 secs\n",
      "\u001b[1m---- Epoch 35/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.61942, cD 1.11033, wmdcmp 0.20719, report_loss 2.49001, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.11862, 117.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35487, wmdcmp 0.11994, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 10.74 secs\n",
      "\u001b[1m---- Epoch 36/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 2.88647, cD 1.11260, wmdcmp 0.20726, report_loss 2.48130, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.11365, 128.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34240, wmdcmp 0.11695, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 12.07 secs\n",
      "\u001b[1m---- Epoch 37/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 2.03670, cD 1.11401, wmdcmp 0.20768, report_loss 2.47231, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.09615, 121.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34644, wmdcmp 0.11866, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 10.38 secs\n",
      "\u001b[1m---- Epoch 38/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.48754, cD 1.15084, wmdcmp 0.21307, report_loss 2.41563, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.05362, 120.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38012, wmdcmp 0.12723, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 11.57 secs\n",
      "\u001b[1m---- Epoch 39/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000231) ...\n",
      "loss 2.37184, cD 1.20711, wmdcmp 0.22127, report_loss 2.35280, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.02889, 124.47 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.36732, wmdcmp 0.12127, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 13.97 secs\n",
      "\u001b[1m---- Epoch 40/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 2.48142, cD 1.22190, wmdcmp 0.22411, report_loss 2.32162, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.02201, 145.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38768, wmdcmp 0.12790, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 13.22 secs\n",
      "\u001b[1m---- Epoch 41/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000077) ...\n",
      "loss 2.27707, cD 1.24601, wmdcmp 0.22740, report_loss 2.29449, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01901, 152.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38483, wmdcmp 0.12484, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 14.25 secs\n",
      "\u001b[1m---- Epoch 42/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 2.24222, cD 1.24246, wmdcmp 0.22772, report_loss 2.28944, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01749, 149.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39633, wmdcmp 0.12845, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 13.83 secs\n",
      "\u001b[1m---- Epoch 43/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 2.51592, cD 1.25175, wmdcmp 0.22808, report_loss 2.28689, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01663, 151.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37220, wmdcmp 0.12506, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 12.94 secs\n",
      "\u001b[1m---- Epoch 44/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 1.73493, cD 1.25761, wmdcmp 0.22949, report_loss 2.28389, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01607, 165.39 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38154, wmdcmp 0.12792, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 17.10 secs\n",
      "\u001b[1m---- Epoch 45/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.26986, cD 1.25971, wmdcmp 0.22929, report_loss 2.28202, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01571, 175.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37043, wmdcmp 0.12448, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 14.27 secs\n",
      "\u001b[1m---- Epoch 46/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.29014, cD 1.26374, wmdcmp 0.23055, report_loss 2.27155, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01555, 170.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38960, wmdcmp 0.12480, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 15.70 secs\n",
      "\u001b[1m---- Epoch 47/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.33890, cD 1.25680, wmdcmp 0.22936, report_loss 2.27859, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01312, 169.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38959, wmdcmp 0.12827, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 14.62 secs\n",
      "\u001b[1m---- Epoch 48/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000118) ...\n",
      "loss 2.17979, cD 1.28323, wmdcmp 0.23263, report_loss 2.25231, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.01008, 193.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.40758, wmdcmp 0.12681, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 15.25 secs\n",
      "\u001b[1m---- Epoch 49/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 2.22403, cD 1.28342, wmdcmp 0.23250, report_loss 2.24849, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00882, 162.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38542, wmdcmp 0.12384, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 13.96 secs\n",
      "\u001b[1m---- Epoch 50/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 2.44687, cD 1.28666, wmdcmp 0.23418, report_loss 2.24101, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00815, 169.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.46738, wmdcmp 0.13100, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 21.23 secs\n",
      "\u001b[1m---- Epoch 51/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 1.64083, cD 1.29693, wmdcmp 0.23578, report_loss 2.23405, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00779, 197.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38418, wmdcmp 0.12433, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 20.43 secs\n",
      "\u001b[1m---- Epoch 52/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.24989, cD 1.29243, wmdcmp 0.23486, report_loss 2.23497, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00754, 180.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39983, wmdcmp 0.12570, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 16.36 secs\n",
      "\u001b[1m---- Epoch 53/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.17606, cD 1.29508, wmdcmp 0.23562, report_loss 2.22975, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00741, 172.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.40418, wmdcmp 0.12616, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 15.21 secs\n",
      "\u001b[1m---- Epoch 54/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.34377, cD 1.28978, wmdcmp 0.23463, report_loss 2.23044, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00736, 189.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39645, wmdcmp 0.12589, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 20.23 secs\n",
      "\u001b[1m---- Epoch 55/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.19202, cD 1.29522, wmdcmp 0.23530, report_loss 2.23558, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00619, 178.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.42182, wmdcmp 0.13429, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 14.81 secs\n",
      "\u001b[1m---- Epoch 56/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000118) ...\n",
      "loss 2.28338, cD 1.30192, wmdcmp 0.23663, report_loss 2.21656, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00486, 152.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.46724, wmdcmp 0.13443, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 20.71 secs\n",
      "\u001b[1m---- Epoch 57/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 2.39752, cD 1.31595, wmdcmp 0.23806, report_loss 2.20947, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00426, 179.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.43432, wmdcmp 0.13047, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 17.18 secs\n",
      "\u001b[1m---- Epoch 58/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 1.70837, cD 1.31572, wmdcmp 0.23953, report_loss 2.19978, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00393, 181.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.42129, wmdcmp 0.12629, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 18.31 secs\n",
      "\u001b[1m---- Epoch 59/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.16431, cD 1.33347, wmdcmp 0.24058, report_loss 2.19404, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00377, 203.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38851, wmdcmp 0.12592, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 18.12 secs\n",
      "\u001b[1m---- Epoch 60/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.29046, cD 1.33028, wmdcmp 0.24097, report_loss 2.19273, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00365, 217.47 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 0.40364, wmdcmp 0.12833, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 24.67 secs\n",
      "\u001b[1m---- Epoch 61/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.23890, cD 1.32512, wmdcmp 0.23914, report_loss 2.19320, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00358, 205.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.43572, wmdcmp 0.12886, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 16.46 secs\n",
      "\u001b[1m---- Epoch 62/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.24030, cD 1.33280, wmdcmp 0.24084, report_loss 2.19243, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00356, 175.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.38860, wmdcmp 0.12553, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 17.32 secs\n",
      "\u001b[1m---- Epoch 63/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 2.28054, cD 1.32917, wmdcmp 0.23996, report_loss 2.19709, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00303, 194.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.45443, wmdcmp 0.13147, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 17.28 secs\n",
      "\u001b[1m---- Epoch 64/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000118) ...\n",
      "loss 2.44458, cD 1.34842, wmdcmp 0.24336, report_loss 2.18223, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00239, 208.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.40905, wmdcmp 0.12714, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 20.96 secs\n",
      "\u001b[1m---- Epoch 65/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000070) ...\n",
      "loss 1.65535, cD 1.35264, wmdcmp 0.24335, report_loss 2.17425, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00211, 165.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37976, wmdcmp 0.12321, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 14.94 secs\n",
      "\u001b[1m---- Epoch 66/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000041) ...\n",
      "loss 2.18669, cD 1.35706, wmdcmp 0.24442, report_loss 2.17102, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00197, 176.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.40629, wmdcmp 0.12910, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 15.57 secs\n",
      "\u001b[1m---- Epoch 67/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 2.13753, cD 1.35771, wmdcmp 0.24394, report_loss 2.16749, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00187, 189.17 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.41964, wmdcmp 0.13326, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 16.40 secs\n",
      "\u001b[1m---- Epoch 68/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.27301, cD 1.35611, wmdcmp 0.24462, report_loss 2.16806, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00183, 182.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39723, wmdcmp 0.12681, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 17.67 secs\n",
      "\u001b[1m---- Epoch 69/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 2.23160, cD 1.35908, wmdcmp 0.24469, report_loss 2.16292, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00179, 157.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39993, wmdcmp 0.12787, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 14.03 secs\n",
      "\u001b[1m---- Epoch 70/70\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.10110, cD 1.36212, wmdcmp 0.24583, report_loss 2.16401, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, chx_loss 0.00179, 175.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.39983, wmdcmp 0.12778, chxlaucmic 1.00000, chxlaucmac 1.00000, chxlprcaucmic 1.00000, chxlprcaucmac 1.00000, 17.92 secs\n"
     ]
    }
   ],
   "source": [
    "!/home/pamessina/venv2/bin/python ../train_labels2report.py \\\n",
    "    --checkpoint-folder \"models/report_gen/20230418_215832_mim_Labels2ReportModel(transf,14->14)\" \\\n",
    "    --epochs 37 \\\n",
    "    --batches-per-epoch 300 \\\n",
    "    --batch-size 150 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 2 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-decay-and-cyclic-decay-args \"1e-6,4,4e-4,8,5e-6,2e-4,8,5e-6\" \\\n",
    "    --override-lr \\\n",
    "    --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
