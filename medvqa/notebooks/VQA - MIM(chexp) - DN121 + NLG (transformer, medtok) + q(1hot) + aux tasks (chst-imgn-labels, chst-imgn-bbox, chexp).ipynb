{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,6,2e-4,54,2e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 100\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [256, 256]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   mimiccxr_weight_chexpert_mode: 1.0\n",
      "   iuxray_weight_chexpert_mode: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_weight_chest_imagenome_mode: 1\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   mimiccxr_include_mined_questions_mode: True\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   mimiccxr_include_chest_imagenome_mode: False\n",
      "   chest_imagenome_labels_filename: imageId2labels(min_freq=100).pkl\n",
      "   chest_imagenome_label_names_filename: labels(min_freq=100).pkl\n",
      "   iuxray_include_chexpert_mode: False\n",
      "   iuxray_include_mined_questions_mode: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   use_medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230201_080625_mim+mim(chex)+mim(chst-imgn)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0,1.0_medtok_chx_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: None\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   chexpert_mode: None\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_chest_imagenome: True\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   classify_questions: False\n",
      "   n_mined_questions: 97\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[34mComputing one-hot question offsets\u001b[0m\n",
      "one_hot_question_offsets = {'0': 0, '1': 0, '2': 97, '3': 97, '4': 97}\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,6,2e-4,54,2e-6\n",
      "1e-06 6 0.0002 54 2e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "train_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "val_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=97\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 100\n",
      "len(self.report_ids) = 2153951, len(set(self.report_ids)) = 211703\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl.balanced_train_data(bs=100,imb_redu_coef=0.5).pkl\n",
      "\tlen(question_datasets) = 93\n",
      "len(self.val_indices) = 17722\n",
      "len(val_indices) = 3336\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "    label = 0, onehot=0, len(pos_indices)=40447, len(neg_indices)=169548\n",
      "    label = 1, onehot=1, len(pos_indices)=41277, len(neg_indices)=168718\n",
      "    label = 2, onehot=2, len(pos_indices)=67917, len(neg_indices)=142078\n",
      "    label = 3, onehot=3, len(pos_indices)=9072, len(neg_indices)=200923\n",
      "    label = 4, onehot=4, len(pos_indices)=70004, len(neg_indices)=139991\n",
      "    label = 5, onehot=5, len(pos_indices)=40951, len(neg_indices)=169044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label = 6, onehot=6, len(pos_indices)=18752, len(neg_indices)=191243\n",
      "    label = 7, onehot=7, len(pos_indices)=35212, len(neg_indices)=174783\n",
      "    label = 8, onehot=8, len(pos_indices)=66549, len(neg_indices)=143446\n",
      "    label = 9, onehot=9, len(pos_indices)=12644, len(neg_indices)=197351\n",
      "    label = 10, onehot=10, len(pos_indices)=65149, len(neg_indices)=144846\n",
      "    label = 11, onehot=11, len(pos_indices)=4669, len(neg_indices)=205326\n",
      "    label = 12, onehot=12, len(pos_indices)=8015, len(neg_indices)=201980\n",
      "    label = 13, onehot=13, len(pos_indices)=84236, len(neg_indices)=125759\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "    label = 0, onehot=0, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 1, onehot=1, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 2, onehot=2, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 3, onehot=3, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 4, onehot=4, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 5, onehot=5, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 6, onehot=6, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 7, onehot=7, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 8, onehot=8, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 9, onehot=9, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 10, onehot=10, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 11, onehot=11, len(pos_indices)=40, len(neg_indices)=40\n",
      "    label = 12, onehot=12, len(pos_indices)=34, len(neg_indices)=40\n",
      "    label = 13, onehot=13, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1114\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 2\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 1.0]\n",
      "merged_dataset_name = mim+mim(chex)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230203_160851_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230203_160851_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_46_chf1+chf1+chf1+chf1+cD+ema+wmmp=0.4312.pt', 'checkpoint_63_chf1+chf1+chf1+chf1+cD+ema+wmmp=0.4274.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230201_080625_mim+mim(chex)+mim(chst-imgn)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0,1.0_medtok_chx_amp/checkpoint_46_chf1+chf1+chf1+chf1+cD+ema+wmmp=0.4312.pt\n",
      "Skip loading parameter: question_encoder.weight, required shape: torch.Size([111, 128]), loaded shape: torch.Size([738, 128])\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230203_160851_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.98243, a_loss 2.68612, cD 0.28887, wmdcmp 0.04165, ema 0.01973, chxlmicf1 0.56293, chxlmacf1 0.51577, chx_loss 0.76816, chxlacc 0.73955, chxlrocaucmic 0.83021, chxlrocaucmac 0.82501, chestimglmacf1 0.16620, chestimglmicf1 0.29675, chestimgl_loss 0.51708, chestimgl_acc 0.85496, chestimglrocaucmic 0.91468, chestimglrocaucmac 0.91222, chestimgbbiou 0.51928, chestimgbbmae 0.20166, 317.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.04516, wmdcmp 0.00816, ema 0.00090, chxlmicf1 0.53281, chxlmacf1 0.46251, chxlacc 0.71839, chxlrocaucmic 0.79721, chxlrocaucmac 0.75202, chestimglmacf1 0.13819, chestimglmicf1 0.26466, chestimgl_acc 0.85376, chestimglrocaucmic 0.88384, chestimglrocaucmac 0.78023, chestimgbbiou 0.51853, chestimgbbmae 0.20310, 46.71 secs\n",
      "Adjusting learning rate of group 0 to 2.4183e-06.\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.14626, a_loss 2.21655, cD 0.56719, wmdcmp 0.08061, ema 0.04787, chxlmicf1 0.56632, chxlmacf1 0.51955, chx_loss 0.77037, chxlacc 0.74560, chxlrocaucmic 0.83177, chxlrocaucmac 0.82409, chestimglmacf1 0.17641, chestimglmicf1 0.31785, chestimgl_loss 0.50961, chestimgl_acc 0.86820, chestimglrocaucmic 0.91977, chestimglrocaucmac 0.91230, chestimgbbiou 0.52275, chestimgbbmae 0.20029, 314.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.04741, wmdcmp 0.01404, ema 0.13106, chxlmicf1 0.53528, chxlmacf1 0.46256, chxlacc 0.72162, chxlrocaucmic 0.80011, chxlrocaucmac 0.75246, chestimglmacf1 0.14109, chestimglmicf1 0.29182, chestimgl_acc 0.87263, chestimglrocaucmic 0.89386, chestimglrocaucmac 0.78129, chestimgbbiou 0.52633, chestimgbbmae 0.19874, 46.22 secs\n",
      "Adjusting learning rate of group 0 to 5.8480e-06.\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.76522, a_loss 1.84114, cD 0.76487, wmdcmp 0.11165, ema 0.18087, chxlmicf1 0.56649, chxlmacf1 0.51990, chx_loss 0.77057, chxlacc 0.74455, chxlrocaucmic 0.83129, chxlrocaucmac 0.82357, chestimglmacf1 0.19146, chestimglmicf1 0.33763, chestimgl_loss 0.50881, chestimgl_acc 0.87796, chestimglrocaucmic 0.92498, chestimglrocaucmac 0.91246, chestimgbbiou 0.54022, chestimgbbmae 0.19162, 314.17 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.04870, wmdcmp 0.01483, ema 0.31957, chxlmicf1 0.53619, chxlmacf1 0.46185, chxlacc 0.72372, chxlrocaucmic 0.79713, chxlrocaucmac 0.75038, chestimglmacf1 0.14135, chestimglmicf1 0.29463, chestimgl_acc 0.87734, chestimglrocaucmic 0.89429, chestimglrocaucmac 0.78175, chestimgbbiou 0.55787, chestimgbbmae 0.18280, 46.65 secs\n",
      "Adjusting learning rate of group 0 to 1.4142e-05.\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.31161, a_loss 1.66263, cD 0.85734, wmdcmp 0.12067, ema 0.37733, chxlmicf1 0.56697, chxlmacf1 0.52025, chx_loss 0.76707, chxlacc 0.74615, chxlrocaucmic 0.83277, chxlrocaucmac 0.82441, chestimglmacf1 0.19252, chestimglmicf1 0.33842, chestimgl_loss 0.50680, chestimgl_acc 0.87933, chestimglrocaucmic 0.92557, chestimglrocaucmac 0.91183, chestimgbbiou 0.61068, chestimgbbmae 0.15837, 315.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.06904, wmdcmp 0.01772, ema 0.49372, chxlmicf1 0.53592, chxlmacf1 0.45820, chxlacc 0.72284, chxlrocaucmic 0.79966, chxlrocaucmac 0.74907, chestimglmacf1 0.14286, chestimglmicf1 0.29881, chestimgl_acc 0.87904, chestimglrocaucmic 0.89575, chestimglrocaucmac 0.78235, chestimgbbiou 0.68183, chestimgbbmae 0.12567, 47.08 secs\n",
      "Adjusting learning rate of group 0 to 3.4200e-05.\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.09826, a_loss 1.53367, cD 0.92458, wmdcmp 0.12793, ema 0.51887, chxlmicf1 0.56640, chxlmacf1 0.51930, chx_loss 0.76659, chxlacc 0.74558, chxlrocaucmic 0.83245, chxlrocaucmac 0.82410, chestimglmacf1 0.19201, chestimglmicf1 0.33724, chestimgl_loss 0.50575, chestimgl_acc 0.87886, chestimglrocaucmic 0.92578, chestimglrocaucmac 0.91136, chestimgbbiou 0.76795, chestimgbbmae 0.08736, 315.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.11497, wmdcmp 0.02173, ema 0.58528, chxlmicf1 0.53003, chxlmacf1 0.46138, chxlacc 0.72008, chxlrocaucmic 0.78967, chxlrocaucmac 0.74860, chestimglmacf1 0.14114, chestimglmicf1 0.28566, chestimgl_acc 0.87441, chestimglrocaucmic 0.88990, chestimglrocaucmac 0.77566, chestimgbbiou 0.80232, chestimgbbmae 0.07313, 46.56 secs\n",
      "Adjusting learning rate of group 0 to 8.2704e-05.\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000083) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.19097, a_loss 1.45859, cD 0.97478, wmdcmp 0.13322, ema 0.58253, chxlmicf1 0.56423, chxlmacf1 0.51728, chx_loss 0.76960, chxlacc 0.74224, chxlrocaucmic 0.83060, chxlrocaucmac 0.82264, chestimglmacf1 0.18742, chestimglmicf1 0.33197, chestimgl_loss 0.51305, chestimgl_acc 0.87632, chestimglrocaucmic 0.92337, chestimglrocaucmac 0.90821, chestimgbbiou 0.83385, chestimgbbmae 0.05984, 315.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.30138, wmdcmp 0.04296, ema 0.63465, chxlmicf1 0.52764, chxlmacf1 0.45257, chxlacc 0.71427, chxlrocaucmic 0.79045, chxlrocaucmac 0.73983, chestimglmacf1 0.14107, chestimglmicf1 0.27269, chestimgl_acc 0.86076, chestimglrocaucmic 0.88775, chestimglrocaucmac 0.77339, chestimgbbiou 0.82993, chestimgbbmae 0.06163, 46.54 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 4.02461, a_loss 1.40339, cD 1.05700, wmdcmp 0.14110, ema 0.65107, chxlmicf1 0.54999, chxlmacf1 0.50147, chx_loss 0.80159, chxlacc 0.73109, chxlrocaucmic 0.81904, chxlrocaucmac 0.80954, chestimglmacf1 0.16928, chestimglmicf1 0.30486, chestimgl_loss 0.55007, chestimgl_acc 0.86682, chestimglrocaucmic 0.91496, chestimglrocaucmac 0.89315, chestimgbbiou 0.84714, chestimgbbmae 0.05378, 314.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.56634, wmdcmp 0.07524, ema 0.65530, chxlmicf1 0.50539, chxlmacf1 0.43842, chxlacc 0.69905, chxlrocaucmic 0.76659, chxlrocaucmac 0.73984, chestimglmacf1 0.13446, chestimglmicf1 0.25984, chestimgl_acc 0.87372, chestimglrocaucmic 0.87766, chestimglrocaucmac 0.76136, chestimgbbiou 0.81000, chestimgbbmae 0.06953, 46.97 secs\n",
      "Adjusting learning rate of group 0 to 1.8365e-04.\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000184) ...\n",
      "loss 4.06528, a_loss 1.36230, cD 1.17540, wmdcmp 0.15541, ema 0.66880, chxlmicf1 0.54883, chxlmacf1 0.50049, chx_loss 0.80221, chxlacc 0.73130, chxlrocaucmic 0.81824, chxlrocaucmac 0.80856, chestimglmacf1 0.16803, chestimglmicf1 0.30241, chestimgl_loss 0.55318, chestimgl_acc 0.86614, chestimglrocaucmic 0.91396, chestimglrocaucmac 0.89167, chestimgbbiou 0.83779, chestimgbbmae 0.05770, 316.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.77957, wmdcmp 0.10579, ema 0.67145, chxlmicf1 0.53950, chxlmacf1 0.46310, chxlacc 0.72921, chxlrocaucmic 0.79414, chxlrocaucmac 0.74303, chestimglmacf1 0.13894, chestimglmicf1 0.27196, chestimgl_acc 0.86347, chestimglrocaucmic 0.88519, chestimglrocaucmac 0.77328, chestimgbbiou 0.83307, chestimgbbmae 0.05976, 47.84 secs\n",
      "Adjusting learning rate of group 0 to 1.6864e-04.\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000169) ...\n",
      "loss 4.24780, a_loss 1.34702, cD 1.21095, wmdcmp 0.16084, ema 0.68040, chxlmicf1 0.55692, chxlmacf1 0.50902, chx_loss 0.78959, chxlacc 0.73663, chxlrocaucmic 0.82446, chxlrocaucmac 0.81477, chestimglmacf1 0.17159, chestimglmicf1 0.31004, chestimgl_loss 0.54367, chestimgl_acc 0.86824, chestimglrocaucmic 0.91678, chestimglrocaucmac 0.89560, chestimgbbiou 0.85216, chestimgbbmae 0.05121, 314.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.86759, wmdcmp 0.11886, ema 0.67774, chxlmicf1 0.54106, chxlmacf1 0.46384, chxlacc 0.73445, chxlrocaucmic 0.79968, chxlrocaucmac 0.74817, chestimglmacf1 0.14467, chestimglmicf1 0.29355, chestimgl_acc 0.87806, chestimglrocaucmic 0.89347, chestimglrocaucmac 0.77898, chestimgbbiou 0.83425, chestimgbbmae 0.05982, 46.94 secs\n",
      "Adjusting learning rate of group 0 to 1.5485e-04.\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 3.80870, a_loss 1.33352, cD 1.24466, wmdcmp 0.16497, ema 0.69147, chxlmicf1 0.56224, chxlmacf1 0.51412, chx_loss 0.78019, chxlacc 0.73953, chxlrocaucmic 0.82694, chxlrocaucmac 0.81808, chestimglmacf1 0.17523, chestimglmicf1 0.31691, chestimgl_loss 0.53700, chestimgl_acc 0.86987, chestimglrocaucmic 0.91833, chestimglrocaucmac 0.89858, chestimgbbiou 0.85382, chestimgbbmae 0.05094, 314.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.95952, wmdcmp 0.13364, ema 0.67325, chxlmicf1 0.53059, chxlmacf1 0.45462, chxlacc 0.70693, chxlrocaucmic 0.79163, chxlrocaucmac 0.73730, chestimglmacf1 0.14245, chestimglmicf1 0.25911, chestimgl_acc 0.85241, chestimglrocaucmic 0.88041, chestimglrocaucmac 0.77228, chestimgbbiou 0.84034, chestimgbbmae 0.05745, 46.65 secs\n",
      "Adjusting learning rate of group 0 to 1.4219e-04.\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000142) ...\n",
      "loss 3.88698, a_loss 1.31590, cD 1.29226, wmdcmp 0.17120, ema 0.69840, chxlmicf1 0.56347, chxlmacf1 0.51621, chx_loss 0.77282, chxlacc 0.74234, chxlrocaucmic 0.82913, chxlrocaucmac 0.82092, chestimglmacf1 0.17836, chestimglmicf1 0.31952, chestimgl_loss 0.53095, chestimgl_acc 0.87125, chestimglrocaucmic 0.91957, chestimglrocaucmac 0.90117, chestimgbbiou 0.85044, chestimgbbmae 0.05347, 314.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.99566, wmdcmp 0.13980, ema 0.66876, chxlmicf1 0.49861, chxlmacf1 0.44949, chxlacc 0.68071, chxlrocaucmic 0.76057, chxlrocaucmac 0.74309, chestimglmacf1 0.13961, chestimglmicf1 0.25583, chestimgl_acc 0.85926, chestimglrocaucmic 0.87887, chestimglrocaucmac 0.77418, chestimgbbiou 0.83747, chestimgbbmae 0.05842, 47.03 secs\n",
      "Adjusting learning rate of group 0 to 1.3057e-04.\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000131) ...\n",
      "loss 3.71594, a_loss 1.30271, cD 1.32467, wmdcmp 0.17606, ema 0.70267, chxlmicf1 0.56713, chxlmacf1 0.52088, chx_loss 0.76259, chxlacc 0.74615, chxlrocaucmic 0.83328, chxlrocaucmac 0.82541, chestimglmacf1 0.18014, chestimglmicf1 0.32418, chestimgl_loss 0.52184, chestimgl_acc 0.87329, chestimglrocaucmic 0.92122, chestimglrocaucmac 0.90468, chestimgbbiou 0.84487, chestimgbbmae 0.05502, 314.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.07955, wmdcmp 0.14961, ema 0.68223, chxlmicf1 0.53183, chxlmacf1 0.45211, chxlacc 0.72475, chxlrocaucmic 0.79789, chxlrocaucmac 0.74075, chestimglmacf1 0.13908, chestimglmicf1 0.27128, chestimgl_acc 0.86340, chestimglrocaucmic 0.88673, chestimglrocaucmac 0.77597, chestimgbbiou 0.84033, chestimgbbmae 0.05714, 47.00 secs\n",
      "Adjusting learning rate of group 0 to 1.1990e-04.\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000120) ...\n",
      "loss 3.75057, a_loss 1.29362, cD 1.34764, wmdcmp 0.17799, ema 0.71073, chxlmicf1 0.57263, chxlmacf1 0.52635, chx_loss 0.75193, chxlacc 0.74997, chxlrocaucmic 0.83632, chxlrocaucmac 0.82802, chestimglmacf1 0.18398, chestimglmicf1 0.33042, chestimgl_loss 0.51709, chestimgl_acc 0.87472, chestimglrocaucmic 0.92266, chestimglrocaucmac 0.90677, chestimgbbiou 0.85323, chestimgbbmae 0.05128, 314.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.15443, wmdcmp 0.16077, ema 0.69390, chxlmicf1 0.54829, chxlmacf1 0.45391, chxlacc 0.74417, chxlrocaucmic 0.80499, chxlrocaucmac 0.74282, chestimglmacf1 0.14031, chestimglmicf1 0.29746, chestimgl_acc 0.88328, chestimglrocaucmic 0.89168, chestimglrocaucmac 0.77734, chestimgbbiou 0.83784, chestimgbbmae 0.05842, 46.79 secs\n",
      "Adjusting learning rate of group 0 to 1.1010e-04.\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000110) ...\n",
      "loss 3.77974, a_loss 1.29262, cD 1.35400, wmdcmp 0.17965, ema 0.71853, chxlmicf1 0.57717, chxlmacf1 0.53181, chx_loss 0.74059, chxlacc 0.75378, chxlrocaucmic 0.84002, chxlrocaucmac 0.83241, chestimglmacf1 0.18447, chestimglmicf1 0.33392, chestimgl_loss 0.51222, chestimgl_acc 0.87610, chestimglrocaucmic 0.92403, chestimglrocaucmac 0.90841, chestimgbbiou 0.85529, chestimgbbmae 0.05018, 314.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16073, wmdcmp 0.15916, ema 0.65799, chxlmicf1 0.53321, chxlmacf1 0.44559, chxlacc 0.72498, chxlrocaucmic 0.79590, chxlrocaucmac 0.73389, chestimglmacf1 0.13641, chestimglmicf1 0.27534, chestimgl_acc 0.86857, chestimglrocaucmic 0.88405, chestimglrocaucmac 0.75897, chestimgbbiou 0.83623, chestimgbbmae 0.05918, 46.50 secs\n",
      "Adjusting learning rate of group 0 to 1.0110e-04.\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000101) ...\n",
      "loss 3.55223, a_loss 1.28234, cD 1.36777, wmdcmp 0.18132, ema 0.71707, chxlmicf1 0.58369, chxlmacf1 0.54228, chx_loss 0.72601, chxlacc 0.75824, chxlrocaucmic 0.84515, chxlrocaucmac 0.83759, chestimglmacf1 0.18808, chestimglmicf1 0.33675, chestimgl_loss 0.50382, chestimgl_acc 0.87705, chestimglrocaucmic 0.92537, chestimglrocaucmac 0.91118, chestimgbbiou 0.85486, chestimgbbmae 0.05098, 311.06 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.16647, wmdcmp 0.16239, ema 0.68492, chxlmicf1 0.52568, chxlmacf1 0.45827, chxlacc 0.71761, chxlrocaucmic 0.78819, chxlrocaucmac 0.74521, chestimglmacf1 0.13905, chestimglmicf1 0.27667, chestimgl_acc 0.87287, chestimglrocaucmic 0.88794, chestimglrocaucmac 0.76984, chestimgbbiou 0.83922, chestimgbbmae 0.05793, 47.13 secs\n",
      "Adjusting learning rate of group 0 to 9.2832e-05.\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000093) ...\n",
      "loss 3.41855, a_loss 1.27504, cD 1.37650, wmdcmp 0.18210, ema 0.72360, chxlmicf1 0.58355, chxlmacf1 0.54166, chx_loss 0.72297, chxlacc 0.76063, chxlrocaucmic 0.84684, chxlrocaucmac 0.83901, chestimglmacf1 0.19280, chestimglmicf1 0.33982, chestimgl_loss 0.49728, chestimgl_acc 0.87953, chestimglrocaucmic 0.92696, chestimglrocaucmac 0.91347, chestimgbbiou 0.85659, chestimgbbmae 0.04988, 314.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23312, wmdcmp 0.16837, ema 0.67325, chxlmicf1 0.53560, chxlmacf1 0.45201, chxlacc 0.72685, chxlrocaucmic 0.79304, chxlrocaucmac 0.74154, chestimglmacf1 0.14092, chestimglmicf1 0.28005, chestimgl_acc 0.87727, chestimglrocaucmic 0.88708, chestimglrocaucmac 0.77262, chestimgbbiou 0.83145, chestimgbbmae 0.06071, 46.84 secs\n",
      "Adjusting learning rate of group 0 to 8.5243e-05.\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000085) ...\n",
      "loss 3.83754, a_loss 1.27355, cD 1.40137, wmdcmp 0.18469, ema 0.72160, chxlmicf1 0.58773, chxlmacf1 0.54939, chx_loss 0.71320, chxlacc 0.76421, chxlrocaucmic 0.85044, chxlrocaucmac 0.84197, chestimglmacf1 0.19402, chestimglmicf1 0.34270, chestimgl_loss 0.49206, chestimgl_acc 0.88024, chestimglrocaucmic 0.92790, chestimglrocaucmac 0.91512, chestimgbbiou 0.84560, chestimgbbmae 0.05510, 315.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.22827, wmdcmp 0.16817, ema 0.69031, chxlmicf1 0.54159, chxlmacf1 0.45824, chxlacc 0.73583, chxlrocaucmic 0.79408, chxlrocaucmac 0.73997, chestimglmacf1 0.14122, chestimglmicf1 0.28070, chestimgl_acc 0.87726, chestimglrocaucmic 0.88644, chestimglrocaucmac 0.76858, chestimgbbiou 0.84165, chestimgbbmae 0.05688, 46.86 secs\n",
      "Adjusting learning rate of group 0 to 7.8275e-05.\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000078) ...\n",
      "loss 3.61178, a_loss 1.26636, cD 1.40088, wmdcmp 0.18564, ema 0.72667, chxlmicf1 0.58939, chxlmacf1 0.54942, chx_loss 0.70505, chxlacc 0.76587, chxlrocaucmic 0.85279, chxlrocaucmac 0.84533, chestimglmacf1 0.19617, chestimglmicf1 0.34584, chestimgl_loss 0.48554, chestimgl_acc 0.88220, chestimglrocaucmic 0.92950, chestimglrocaucmac 0.91732, chestimgbbiou 0.86051, chestimgbbmae 0.04863, 315.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26704, wmdcmp 0.17262, ema 0.67594, chxlmicf1 0.54380, chxlmacf1 0.44958, chxlacc 0.72637, chxlrocaucmic 0.80272, chxlrocaucmac 0.73315, chestimglmacf1 0.13576, chestimglmicf1 0.28397, chestimgl_acc 0.86382, chestimglrocaucmic 0.89116, chestimglrocaucmac 0.77349, chestimgbbiou 0.83190, chestimgbbmae 0.06065, 47.04 secs\n",
      "Adjusting learning rate of group 0 to 7.1876e-05.\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000072) ...\n",
      "loss 3.71640, a_loss 1.26044, cD 1.41890, wmdcmp 0.18762, ema 0.73507, chxlmicf1 0.59468, chxlmacf1 0.55913, chx_loss 0.69152, chxlacc 0.77056, chxlrocaucmic 0.85610, chxlrocaucmac 0.84783, chestimglmacf1 0.19927, chestimglmicf1 0.34750, chestimgl_loss 0.48155, chestimgl_acc 0.88286, chestimglrocaucmic 0.93007, chestimglrocaucmac 0.91878, chestimgbbiou 0.86212, chestimgbbmae 0.04767, 315.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.27140, wmdcmp 0.17381, ema 0.68671, chxlmicf1 0.53398, chxlmacf1 0.44471, chxlacc 0.73008, chxlrocaucmic 0.79420, chxlrocaucmac 0.73643, chestimglmacf1 0.14131, chestimglmicf1 0.28556, chestimgl_acc 0.87988, chestimglrocaucmic 0.88929, chestimglrocaucmac 0.77568, chestimgbbiou 0.83852, chestimgbbmae 0.05806, 47.37 secs\n",
      "Adjusting learning rate of group 0 to 6.6001e-05.\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000066) ...\n",
      "loss 3.53385, a_loss 1.25717, cD 1.42151, wmdcmp 0.18728, ema 0.73467, chxlmicf1 0.60062, chxlmacf1 0.56717, chx_loss 0.68028, chxlacc 0.77427, chxlrocaucmic 0.86008, chxlrocaucmac 0.85173, chestimglmacf1 0.20310, chestimglmicf1 0.35291, chestimgl_loss 0.47540, chestimgl_acc 0.88416, chestimglrocaucmic 0.93153, chestimglrocaucmac 0.92103, chestimgbbiou 0.85565, chestimgbbmae 0.05056, 317.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29257, wmdcmp 0.17595, ema 0.68133, chxlmicf1 0.54349, chxlmacf1 0.44798, chxlacc 0.74825, chxlrocaucmic 0.79902, chxlrocaucmac 0.73986, chestimglmacf1 0.14179, chestimglmicf1 0.28895, chestimgl_acc 0.88555, chestimglrocaucmic 0.88958, chestimglrocaucmac 0.77316, chestimgbbiou 0.83390, chestimgbbmae 0.05974, 46.97 secs\n",
      "Adjusting learning rate of group 0 to 6.0605e-05.\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 3.60913, a_loss 1.25529, cD 1.41391, wmdcmp 0.18639, ema 0.74440, chxlmicf1 0.60405, chxlmacf1 0.57345, chx_loss 0.67005, chxlacc 0.77743, chxlrocaucmic 0.86303, chxlrocaucmac 0.85408, chestimglmacf1 0.20240, chestimglmicf1 0.35077, chestimgl_loss 0.47370, chestimgl_acc 0.88412, chestimglrocaucmic 0.93155, chestimglrocaucmac 0.92107, chestimgbbiou 0.84835, chestimgbbmae 0.05379, 315.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30794, wmdcmp 0.17792, ema 0.68043, chxlmicf1 0.54807, chxlmacf1 0.45341, chxlacc 0.73989, chxlrocaucmic 0.80575, chxlrocaucmac 0.74003, chestimglmacf1 0.14136, chestimglmicf1 0.29403, chestimgl_acc 0.87878, chestimglrocaucmic 0.89313, chestimglrocaucmac 0.77280, chestimgbbiou 0.84007, chestimgbbmae 0.05738, 46.75 secs\n",
      "Adjusting learning rate of group 0 to 5.5651e-05.\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 3.45052, a_loss 1.24847, cD 1.43733, wmdcmp 0.18960, ema 0.74253, chxlmicf1 0.60964, chxlmacf1 0.58027, chx_loss 0.66128, chxlacc 0.77963, chxlrocaucmic 0.86569, chxlrocaucmac 0.85746, chestimglmacf1 0.20750, chestimglmicf1 0.35766, chestimgl_loss 0.46832, chestimgl_acc 0.88550, chestimglrocaucmic 0.93301, chestimglrocaucmac 0.92352, chestimgbbiou 0.85554, chestimgbbmae 0.05089, 314.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29111, wmdcmp 0.17681, ema 0.68133, chxlmicf1 0.54466, chxlmacf1 0.45014, chxlacc 0.75127, chxlrocaucmic 0.80000, chxlrocaucmac 0.74303, chestimglmacf1 0.14420, chestimglmicf1 0.29576, chestimgl_acc 0.89072, chestimglrocaucmic 0.89062, chestimglrocaucmac 0.77528, chestimgbbiou 0.84311, chestimgbbmae 0.05631, 47.14 secs\n",
      "Adjusting learning rate of group 0 to 5.1102e-05.\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 3.49598, a_loss 1.25668, cD 1.42979, wmdcmp 0.18924, ema 0.74827, chxlmicf1 0.61306, chxlmacf1 0.58786, chx_loss 0.65210, chxlacc 0.78262, chxlrocaucmic 0.86802, chxlrocaucmac 0.85803, chestimglmacf1 0.20930, chestimglmicf1 0.35904, chestimgl_loss 0.46301, chestimgl_acc 0.88671, chestimglrocaucmic 0.93421, chestimglrocaucmac 0.92496, chestimgbbiou 0.85380, chestimgbbmae 0.05151, 313.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30434, wmdcmp 0.17834, ema 0.69031, chxlmicf1 0.54786, chxlmacf1 0.45382, chxlacc 0.74401, chxlrocaucmic 0.80303, chxlrocaucmac 0.74090, chestimglmacf1 0.14024, chestimglmicf1 0.29242, chestimgl_acc 0.87816, chestimglrocaucmic 0.89192, chestimglrocaucmac 0.77619, chestimgbbiou 0.84246, chestimgbbmae 0.05644, 46.91 secs\n",
      "Adjusting learning rate of group 0 to 4.6925e-05.\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000047) ...\n",
      "loss 3.48950, a_loss 1.24635, cD 1.44399, wmdcmp 0.19180, ema 0.75067, chxlmicf1 0.61156, chxlmacf1 0.58811, chx_loss 0.64698, chxlacc 0.78330, chxlrocaucmic 0.86941, chxlrocaucmac 0.86019, chestimglmacf1 0.21058, chestimglmicf1 0.35891, chestimgl_loss 0.45926, chestimgl_acc 0.88761, chestimglrocaucmic 0.93458, chestimglrocaucmac 0.92495, chestimgbbiou 0.86017, chestimgbbmae 0.04856, 314.18 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29433, wmdcmp 0.17662, ema 0.67145, chxlmicf1 0.54684, chxlmacf1 0.44519, chxlacc 0.74698, chxlrocaucmic 0.80314, chxlrocaucmac 0.73766, chestimglmacf1 0.13982, chestimglmicf1 0.30199, chestimgl_acc 0.88547, chestimglrocaucmic 0.89105, chestimglrocaucmac 0.76598, chestimgbbiou 0.84399, chestimgbbmae 0.05592, 46.77 secs\n",
      "Adjusting learning rate of group 0 to 4.3089e-05.\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.28860, a_loss 1.23799, cD 1.44686, wmdcmp 0.19086, ema 0.75713, chxlmicf1 0.61530, chxlmacf1 0.59434, chx_loss 0.63616, chxlacc 0.78650, chxlrocaucmic 0.87272, chxlrocaucmac 0.86278, chestimglmacf1 0.21491, chestimglmicf1 0.36336, chestimgl_loss 0.45530, chestimgl_acc 0.88905, chestimglrocaucmic 0.93572, chestimglrocaucmac 0.92722, chestimgbbiou 0.84336, chestimgbbmae 0.05613, 315.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28157, wmdcmp 0.17599, ema 0.67415, chxlmicf1 0.55318, chxlmacf1 0.44676, chxlacc 0.75547, chxlrocaucmic 0.80821, chxlrocaucmac 0.74051, chestimglmacf1 0.13957, chestimglmicf1 0.30480, chestimgl_acc 0.88792, chestimglrocaucmic 0.89307, chestimglrocaucmac 0.77131, chestimgbbiou 0.83839, chestimgbbmae 0.05803, 46.70 secs\n",
      "Adjusting learning rate of group 0 to 3.9566e-05.\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 3.45952, a_loss 1.23850, cD 1.44726, wmdcmp 0.19154, ema 0.75913, chxlmicf1 0.62071, chxlmacf1 0.60226, chx_loss 0.62835, chxlacc 0.78928, chxlrocaucmic 0.87478, chxlrocaucmac 0.86505, chestimglmacf1 0.21550, chestimglmicf1 0.36541, chestimgl_loss 0.45250, chestimgl_acc 0.88947, chestimglrocaucmic 0.93654, chestimglrocaucmac 0.92809, chestimgbbiou 0.83707, chestimgbbmae 0.05922, 313.05 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29460, wmdcmp 0.17657, ema 0.68223, chxlmicf1 0.54759, chxlmacf1 0.44198, chxlacc 0.75509, chxlrocaucmic 0.80210, chxlrocaucmac 0.74138, chestimglmacf1 0.14073, chestimglmicf1 0.29949, chestimgl_acc 0.89226, chestimglrocaucmic 0.89102, chestimglrocaucmac 0.77467, chestimgbbiou 0.84247, chestimgbbmae 0.05650, 46.84 secs\n",
      "Adjusting learning rate of group 0 to 3.6332e-05.\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 3.62966, a_loss 1.23824, cD 1.47223, wmdcmp 0.19384, ema 0.76187, chxlmicf1 0.62210, chxlmacf1 0.60453, chx_loss 0.62402, chxlacc 0.79033, chxlrocaucmic 0.87599, chxlrocaucmac 0.86530, chestimglmacf1 0.21881, chestimglmicf1 0.36607, chestimgl_loss 0.44944, chestimgl_acc 0.88965, chestimglrocaucmic 0.93661, chestimglrocaucmac 0.92880, chestimgbbiou 0.85185, chestimgbbmae 0.05166, 314.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33969, wmdcmp 0.18128, ema 0.66338, chxlmicf1 0.55373, chxlmacf1 0.44794, chxlacc 0.75758, chxlrocaucmic 0.80523, chxlrocaucmac 0.73931, chestimglmacf1 0.14193, chestimglmicf1 0.30448, chestimgl_acc 0.89019, chestimglrocaucmic 0.89275, chestimglrocaucmac 0.77128, chestimgbbiou 0.84131, chestimgbbmae 0.05691, 47.12 secs\n",
      "Adjusting learning rate of group 0 to 3.3362e-05.\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 3.43483, a_loss 1.23619, cD 1.46118, wmdcmp 0.19290, ema 0.76000, chxlmicf1 0.62568, chxlmacf1 0.61062, chx_loss 0.61346, chxlacc 0.79335, chxlrocaucmic 0.87876, chxlrocaucmac 0.86825, chestimglmacf1 0.21606, chestimglmicf1 0.36737, chestimgl_loss 0.44515, chestimgl_acc 0.89048, chestimglrocaucmic 0.93726, chestimglrocaucmac 0.92973, chestimgbbiou 0.83739, chestimgbbmae 0.05866, 314.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34891, wmdcmp 0.18197, ema 0.67056, chxlmicf1 0.55471, chxlmacf1 0.44847, chxlacc 0.75809, chxlrocaucmic 0.80557, chxlrocaucmac 0.73963, chestimglmacf1 0.14345, chestimglmicf1 0.30514, chestimgl_acc 0.89251, chestimglrocaucmic 0.89263, chestimglrocaucmac 0.77222, chestimgbbiou 0.83114, chestimgbbmae 0.06058, 46.35 secs\n",
      "Adjusting learning rate of group 0 to 3.0635e-05.\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 3.54120, a_loss 1.23531, cD 1.45758, wmdcmp 0.19307, ema 0.76360, chxlmicf1 0.62905, chxlmacf1 0.61502, chx_loss 0.61215, chxlacc 0.79510, chxlrocaucmic 0.87992, chxlrocaucmac 0.86919, chestimglmacf1 0.21869, chestimglmicf1 0.37008, chestimgl_loss 0.44450, chestimgl_acc 0.89104, chestimglrocaucmic 0.93825, chestimglrocaucmac 0.93008, chestimgbbiou 0.85088, chestimgbbmae 0.05225, 314.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32041, wmdcmp 0.18032, ema 0.67235, chxlmicf1 0.55284, chxlmacf1 0.44350, chxlacc 0.75690, chxlrocaucmic 0.80822, chxlrocaucmac 0.73945, chestimglmacf1 0.13986, chestimglmicf1 0.30411, chestimgl_acc 0.88915, chestimglrocaucmic 0.89308, chestimglrocaucmac 0.77360, chestimgbbiou 0.84465, chestimgbbmae 0.05577, 47.03 secs\n",
      "Adjusting learning rate of group 0 to 2.8131e-05.\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 3.48207, a_loss 1.23092, cD 1.46868, wmdcmp 0.19367, ema 0.77067, chxlmicf1 0.63079, chxlmacf1 0.62207, chx_loss 0.60088, chxlacc 0.79799, chxlrocaucmic 0.88311, chxlrocaucmac 0.87139, chestimglmacf1 0.22037, chestimglmicf1 0.37011, chestimgl_loss 0.44035, chestimgl_acc 0.89178, chestimglrocaucmic 0.93884, chestimglrocaucmac 0.93127, chestimgbbiou 0.85323, chestimgbbmae 0.05103, 315.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34471, wmdcmp 0.18211, ema 0.68402, chxlmicf1 0.55432, chxlmacf1 0.44360, chxlacc 0.76347, chxlrocaucmic 0.80851, chxlrocaucmac 0.73966, chestimglmacf1 0.14127, chestimglmicf1 0.30443, chestimgl_acc 0.89454, chestimglrocaucmic 0.89176, chestimglrocaucmac 0.77240, chestimgbbiou 0.84555, chestimgbbmae 0.05537, 46.51 secs\n",
      "Adjusting learning rate of group 0 to 2.5831e-05.\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 3.43631, a_loss 1.23212, cD 1.46257, wmdcmp 0.19238, ema 0.76420, chxlmicf1 0.63169, chxlmacf1 0.62227, chx_loss 0.60028, chxlacc 0.79850, chxlrocaucmic 0.88346, chxlrocaucmac 0.87167, chestimglmacf1 0.22174, chestimglmicf1 0.37085, chestimgl_loss 0.43806, chestimgl_acc 0.89225, chestimglrocaucmic 0.93892, chestimglrocaucmac 0.93164, chestimgbbiou 0.84795, chestimgbbmae 0.05373, 314.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32539, wmdcmp 0.18110, ema 0.66786, chxlmicf1 0.55439, chxlmacf1 0.44323, chxlacc 0.75716, chxlrocaucmic 0.80776, chxlrocaucmac 0.73433, chestimglmacf1 0.14132, chestimglmicf1 0.31189, chestimgl_acc 0.89272, chestimglrocaucmic 0.89358, chestimglrocaucmac 0.76931, chestimgbbiou 0.83767, chestimgbbmae 0.05832, 46.37 secs\n",
      "Adjusting learning rate of group 0 to 2.3719e-05.\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 3.38375, a_loss 1.22816, cD 1.48030, wmdcmp 0.19502, ema 0.77187, chxlmicf1 0.63236, chxlmacf1 0.62410, chx_loss 0.59594, chxlacc 0.79901, chxlrocaucmic 0.88377, chxlrocaucmac 0.87223, chestimglmacf1 0.22381, chestimglmicf1 0.37386, chestimgl_loss 0.43451, chestimgl_acc 0.89325, chestimglrocaucmic 0.93981, chestimglrocaucmac 0.93292, chestimgbbiou 0.85222, chestimgbbmae 0.05169, 314.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33968, wmdcmp 0.18202, ema 0.67145, chxlmicf1 0.55363, chxlmacf1 0.44744, chxlacc 0.75483, chxlrocaucmic 0.80687, chxlrocaucmac 0.73637, chestimglmacf1 0.14278, chestimglmicf1 0.30695, chestimgl_acc 0.89110, chestimglrocaucmic 0.89411, chestimglrocaucmac 0.77100, chestimgbbiou 0.84589, chestimgbbmae 0.05528, 46.97 secs\n",
      "Adjusting learning rate of group 0 to 2.1780e-05.\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 3.40580, a_loss 1.23518, cD 1.46178, wmdcmp 0.19328, ema 0.76787, chxlmicf1 0.63334, chxlmacf1 0.62715, chx_loss 0.59137, chxlacc 0.79938, chxlrocaucmic 0.88493, chxlrocaucmac 0.87310, chestimglmacf1 0.22086, chestimglmicf1 0.37174, chestimgl_loss 0.43649, chestimgl_acc 0.89279, chestimglrocaucmic 0.93934, chestimglrocaucmac 0.93168, chestimgbbiou 0.84063, chestimgbbmae 0.05619, 314.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34524, wmdcmp 0.18314, ema 0.67864, chxlmicf1 0.55590, chxlmacf1 0.44744, chxlacc 0.75888, chxlrocaucmic 0.81028, chxlrocaucmac 0.73985, chestimglmacf1 0.14233, chestimglmicf1 0.30817, chestimgl_acc 0.89325, chestimglrocaucmic 0.89412, chestimglrocaucmac 0.77202, chestimgbbiou 0.84330, chestimgbbmae 0.05614, 46.83 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 3.45870, a_loss 1.22498, cD 1.46508, wmdcmp 0.19354, ema 0.76993, chxlmicf1 0.63818, chxlmacf1 0.63477, chx_loss 0.58188, chxlacc 0.80259, chxlrocaucmic 0.88796, chxlrocaucmac 0.87609, chestimglmacf1 0.22624, chestimglmicf1 0.37431, chestimgl_loss 0.43194, chestimgl_acc 0.89351, chestimglrocaucmic 0.94032, chestimglrocaucmac 0.93348, chestimgbbiou 0.83507, chestimgbbmae 0.05841, 312.79 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.34589, wmdcmp 0.18329, ema 0.66966, chxlmicf1 0.55804, chxlmacf1 0.44694, chxlacc 0.76228, chxlrocaucmic 0.81033, chxlrocaucmac 0.73777, chestimglmacf1 0.14211, chestimglmicf1 0.30864, chestimgl_acc 0.89287, chestimglrocaucmic 0.89447, chestimglrocaucmac 0.77221, chestimgbbiou 0.84473, chestimgbbmae 0.05561, 46.99 secs\n",
      "Adjusting learning rate of group 0 to 1.8365e-05.\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 3.49788, a_loss 1.22759, cD 1.47928, wmdcmp 0.19476, ema 0.78113, chxlmicf1 0.64073, chxlmacf1 0.63919, chx_loss 0.57815, chxlacc 0.80468, chxlrocaucmic 0.88917, chxlrocaucmac 0.87696, chestimglmacf1 0.22788, chestimglmicf1 0.37850, chestimgl_loss 0.42899, chestimgl_acc 0.89430, chestimglrocaucmic 0.94120, chestimglrocaucmac 0.93420, chestimgbbiou 0.84383, chestimgbbmae 0.05513, 314.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33784, wmdcmp 0.18251, ema 0.67235, chxlmicf1 0.55345, chxlmacf1 0.44168, chxlacc 0.75820, chxlrocaucmic 0.80707, chxlrocaucmac 0.73545, chestimglmacf1 0.14033, chestimglmicf1 0.30697, chestimgl_acc 0.89237, chestimglrocaucmic 0.89248, chestimglrocaucmac 0.76866, chestimgbbiou 0.84147, chestimgbbmae 0.05688, 46.75 secs\n",
      "Adjusting learning rate of group 0 to 1.6864e-05.\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 3.43770, a_loss 1.22465, cD 1.48550, wmdcmp 0.19544, ema 0.77773, chxlmicf1 0.64111, chxlmacf1 0.64184, chx_loss 0.57605, chxlacc 0.80505, chxlrocaucmic 0.88967, chxlrocaucmac 0.87696, chestimglmacf1 0.22627, chestimglmicf1 0.37767, chestimgl_loss 0.42780, chestimgl_acc 0.89443, chestimglrocaucmic 0.94109, chestimglrocaucmac 0.93425, chestimgbbiou 0.84076, chestimgbbmae 0.05687, 315.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34407, wmdcmp 0.18223, ema 0.66876, chxlmicf1 0.55790, chxlmacf1 0.44610, chxlacc 0.76161, chxlrocaucmic 0.81064, chxlrocaucmac 0.73875, chestimglmacf1 0.14317, chestimglmicf1 0.31692, chestimgl_acc 0.89544, chestimglrocaucmic 0.89457, chestimglrocaucmac 0.77200, chestimgbbiou 0.84594, chestimgbbmae 0.05517, 46.72 secs\n",
      "Adjusting learning rate of group 0 to 1.5485e-05.\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 3.36564, a_loss 1.22495, cD 1.47811, wmdcmp 0.19530, ema 0.77920, chxlmicf1 0.64157, chxlmacf1 0.64068, chx_loss 0.57386, chxlacc 0.80531, chxlrocaucmic 0.89005, chxlrocaucmac 0.87748, chestimglmacf1 0.22696, chestimglmicf1 0.37910, chestimgl_loss 0.42498, chestimgl_acc 0.89512, chestimglrocaucmic 0.94161, chestimglrocaucmac 0.93486, chestimgbbiou 0.85338, chestimgbbmae 0.05136, 315.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35335, wmdcmp 0.18364, ema 0.66786, chxlmicf1 0.55824, chxlmacf1 0.44692, chxlacc 0.76413, chxlrocaucmic 0.80964, chxlrocaucmac 0.73749, chestimglmacf1 0.14201, chestimglmicf1 0.31227, chestimgl_acc 0.89512, chestimglrocaucmic 0.89389, chestimglrocaucmac 0.77186, chestimgbbiou 0.84477, chestimgbbmae 0.05562, 46.79 secs\n",
      "Adjusting learning rate of group 0 to 1.4219e-05.\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.19262, a_loss 1.22410, cD 1.47773, wmdcmp 0.19563, ema 0.78160, chxlmicf1 0.64546, chxlmacf1 0.64751, chx_loss 0.56754, chxlacc 0.80784, chxlrocaucmic 0.89194, chxlrocaucmac 0.87910, chestimglmacf1 0.23023, chestimglmicf1 0.37869, chestimgl_loss 0.42640, chestimgl_acc 0.89525, chestimglrocaucmic 0.94179, chestimglrocaucmac 0.93511, chestimgbbiou 0.85065, chestimgbbmae 0.05259, 313.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36381, wmdcmp 0.18526, ema 0.67145, chxlmicf1 0.56167, chxlmacf1 0.44665, chxlacc 0.76300, chxlrocaucmic 0.81064, chxlrocaucmac 0.73894, chestimglmacf1 0.14248, chestimglmicf1 0.31469, chestimgl_acc 0.89422, chestimglrocaucmic 0.89512, chestimglrocaucmac 0.77068, chestimgbbiou 0.84096, chestimgbbmae 0.05705, 46.93 secs\n",
      "Adjusting learning rate of group 0 to 1.3057e-05.\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 3.36427, a_loss 1.22046, cD 1.49507, wmdcmp 0.19710, ema 0.77800, chxlmicf1 0.64387, chxlmacf1 0.64652, chx_loss 0.56899, chxlacc 0.80683, chxlrocaucmic 0.89109, chxlrocaucmac 0.87763, chestimglmacf1 0.22780, chestimglmicf1 0.37831, chestimgl_loss 0.42587, chestimgl_acc 0.89482, chestimglrocaucmic 0.94156, chestimglrocaucmac 0.93445, chestimgbbiou 0.85061, chestimgbbmae 0.05243, 315.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38081, wmdcmp 0.18708, ema 0.66697, chxlmicf1 0.55813, chxlmacf1 0.44513, chxlacc 0.76401, chxlrocaucmic 0.80874, chxlrocaucmac 0.73937, chestimglmacf1 0.14272, chestimglmicf1 0.30908, chestimgl_acc 0.89614, chestimglrocaucmic 0.89294, chestimglrocaucmac 0.77187, chestimgbbiou 0.84645, chestimgbbmae 0.05506, 46.62 secs\n",
      "Adjusting learning rate of group 0 to 1.1990e-05.\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "   iteration 11825\r"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230201_080625_mim+mim(chex)+mim(chst-imgn)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0,1.0_medtok_chx_amp\" \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,6,2e-4,54,2e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-include-mined-questions-mode \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --classify-chest-imagenome \\\n",
    "        --chest-imagenome-label-names-filename \"labels(min_freq=100).pkl\" \\\n",
    "        --chest-imagenome-labels-filename \"imageId2labels(min_freq=100).pkl\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --n-mined-questions 97 \\\n",
    "        --balanced-dataloading \\\n",
    "        --use-medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
