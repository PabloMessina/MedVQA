{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18051194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1200\n",
      "   max_images_per_batch: 25\n",
      "   max_phrases_per_batch: 400\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 5.0\n",
      "   checkpoint_folder: models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: siglip-huggingface\n",
      "   huggingface_model_name: google/siglip-base-patch16-224\n",
      "   num_regions: 196\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 14\n",
      "   regions_height: 14\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: film_layers_plus_sigmoid_attention_and_custom_classifier\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: 256\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 2.0\n",
      "   phrase_classifier_loss_weight: 2.0\n",
      "   foreground_loss_weight: 1.5\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: True\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [224, 224]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_fact_based_pos_neg_facts(hash=1360,3939902508813076616).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\n",
      "   chexpert_class_phrase_embeddings_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 2.5\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 6.0\n",
      "   vinbig_weight: 1.5\n",
      "   chexlocalize_weight: 0.4\n",
      "   chexpert_weight: 0.5\n",
      "   iuxray_weight: 0.5\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: True\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: True\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: True\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: True\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: True\n",
      "   use_cxrlt2024_custom_labels: True\n",
      "   use_cxrlt2024_official_labels: True\n",
      "   use_all_cxrlt2024_official_labels_for_training: True\n",
      "   vinbig_training_data_mode: all\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_official_training_labels_for_fact_classification(n_train=240529,n_val=18342,pf=0.03).pkl\n",
      "   cxrlt2024_do_balanced_sampling: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: siglip-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.5\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating CheXLocalize Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    len(_augmented_mask_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.4\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loding class_phrase_embeddings_filepath and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl...\n",
      "class_phrase_embeddings.shape = (10, 128)\n",
      "len(class_phrases) = 10\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t airspace opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t support devices seen\n",
      "Compute phrase grounding masks and labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without masks: 216/902\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 902\n",
      "batch_size = 25\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating CheXpert Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    len(_augmented_mask_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.4\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train_visualCheXbert.csv\n",
      "len(df_train_visualchexbert) = 223414\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/valid.csv\n",
      "len(df_valid) = 234\n",
      "len(df) = 223648\n",
      "Loading images\n",
      "Loading chexpert labels\n",
      "Loading test set\n",
      "len(self.test_image_paths) = 668\n",
      "self.test_labels.shape = (668, 14)\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl...\n",
      "phrase_embeddings.shape = (14, 128)\n",
      "len(phrases) = 14\n",
      "\t no findings\n",
      "\t enlarged cardiomediastinum seen\n",
      "\t cardiomegaly seen\n",
      "\t lung lesion seen\n",
      "\t lung opacity seen\n",
      "\t edema seen\n",
      "\t consolidation seen\n",
      "\t pneumonia seen\n",
      "\t atelectasis seen\n",
      "\t pneumothorax seen\n",
      "\t pleural effusion seen\n",
      "\t other pleural abnormality seen\n",
      "\t fracture seen\n",
      "\t support devices seen\n",
      "len(all_image_paths) = 224316\n",
      "all_labels.shape = (224316, 14)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 224316\n",
      "No labels: 3246\n",
      "Pneumothorax: 25357\n",
      "Pleural Other: 26334\n",
      "Lung Lesion: 31042\n",
      "No Finding: 35673\n",
      "Pneumonia: 52248\n",
      "Fracture: 61696\n",
      "Edema: 94500\n",
      "Pleural Effusion: 103837\n",
      "Consolidation: 107297\n",
      "Cardiomegaly: 122164\n",
      "Atelectasis: 124182\n",
      "Support Devices: 136382\n",
      "Enlarged Cardiomediastinum: 144377\n",
      "Lung Opacity: 151937\n",
      "Group sizes: [61397, 30579, 25357, 21626, 18526, 17225, 11525, 11092, 10885, 7083, 4085, 3246, 1170, 347, 173]\n",
      "  len(indices) = 61397, weight = 4024.1406302660666\n",
      "  len(indices) = 30579, weight = 3308.1179132413095\n",
      "  len(indices) = 25357, weight = 3131.4217784165476\n",
      "  len(indices) = 21626, weight = 2986.2821261955132\n",
      "  len(indices) = 18526, weight = 2849.5564265118087\n",
      "  len(indices) = 17225, weight = 2786.68263628706\n",
      "  len(indices) = 11525, weight = 2456.265254834705\n",
      "  len(indices) = 11092, weight = 2426.215857884437\n",
      "  len(indices) = 10885, weight = 2411.5238383991996\n",
      "  len(indices) = 7083, weight = 2092.3117139635237\n",
      "  len(indices) = 4085, weight = 1726.3245386288693\n",
      "  len(indices) = 3246, weight = 1587.0568876515586\n",
      "  len(indices) = 1170, weight = 1058.8042504564921\n",
      "  len(indices) = 347, weight = 600.9534388852762\n",
      "  len(indices) = 173, weight = 410.9393870934724\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    len(_augmented_mask_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.4\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "len(phrases) = 28\n",
      "\t aortic enlargement seen\n",
      "\t atelectasis seen\n",
      "\t calcification seen\n",
      "\t cardiomegaly seen\n",
      "\t clavicle fracture seen\n",
      "\t consolidation seen\n",
      "\t edema seen\n",
      "\t emphysema seen\n",
      "\t enlarged pulmonary artery seen\n",
      "\t interstitial lung disease seen\n",
      "\t infiltration seen\n",
      "\t lung opacity seen\n",
      "\t lung cavity seen\n",
      "\t lung cyst seen\n",
      "\t mediastinal shift seen\n",
      "\t nodule/mass seen\n",
      "\t pleural effusion seen\n",
      "\t pleural thickening seen\n",
      "\t pneumothorax seen\n",
      "\t pulmonary fibrosis seen\n",
      "\t rib fracture seen\n",
      "\t other lesion seen\n",
      "\t copd seen\n",
      "\t lung tumor seen\n",
      "\t pneumonia seen\n",
      "\t tuberculosis seen\n",
      "\t other disease seen\n",
      "\t no abnormalities seen\n",
      "Compute phrase grounding masks and labels\n",
      "self.phrase_grounding_masks.shape = (18000, 22, 196)\n",
      "self.phrase_classification_labels.shape = (18000, 22)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 6\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'No finding']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(actual_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "Generating train dataset and dataloader\n",
      "len(train_indices) = 18000\n",
      "No labels: 0\n",
      "Edema: 13\n",
      "Clavicle fracture: 29\n",
      "Lung cyst: 35\n",
      "COPD: 37\n",
      "Lung cavity: 60\n",
      "Emphysema: 84\n",
      "Rib fracture: 101\n",
      "Pneumothorax: 114\n",
      "Enlarged PA: 139\n",
      "Mediastinal shift: 170\n",
      "Atelectasis: 273\n",
      "Lung tumor: 371\n",
      "Consolidation: 449\n",
      "ILD: 618\n",
      "Calcification: 652\n",
      "Infiltration: 671\n",
      "Tuberculosis: 914\n",
      "Nodule/Mass: 1017\n",
      "Pleural effusion: 1149\n",
      "Pneumonia: 1163\n",
      "Other lesion: 1248\n",
      "Lung Opacity: 1415\n",
      "Pulmonary fibrosis: 1838\n",
      "Pleural thickening: 2179\n",
      "Cardiomegaly: 2625\n",
      "Aortic enlargement: 3318\n",
      "Other disease: 4945\n",
      "No finding: 12652\n",
      "Group sizes: [12529, 891, 444, 428, 364, 344, 307, 283, 273, 267, 245, 236, 206, 193, 170, 138, 127, 100, 99, 90, 56, 54, 49, 34, 73]\n",
      "  len(indices) = 12529, weight = 2522.6672479595745\n",
      "  len(indices) = 891, weight = 940.9850359649141\n",
      "  len(indices) = 444, weight = 680.1755171156125\n",
      "  len(indices) = 428, weight = 667.9638591411331\n",
      "  len(indices) = 364, weight = 615.8160380252455\n",
      "  len(indices) = 344, weight = 598.2811252947056\n",
      "  len(indices) = 307, weight = 563.9888635691133\n",
      "  len(indices) = 283, weight = 540.2796339164162\n",
      "  len(indices) = 273, weight = 530.0166624211873\n",
      "  len(indices) = 267, weight = 523.7422583945496\n",
      "  len(indices) = 245, weight = 499.93058392418243\n",
      "  len(indices) = 236, weight = 489.7963928535281\n",
      "  len(indices) = 206, weight = 454.1360559561945\n",
      "  len(indices) = 193, weight = 437.6702522239849\n",
      "  len(indices) = 170, weight = 406.7687016278156\n",
      "  len(indices) = 138, weight = 359.20170201154343\n",
      "  len(indices) = 127, weight = 341.33933626931963\n",
      "  len(indices) = 100, weight = 293.26529386579296\n",
      "  len(indices) = 99, weight = 291.34941227248714\n",
      "  len(indices) = 90, weight = 273.5936736738282\n",
      "  len(indices) = 56, weight = 195.85520038280242\n",
      "  len(indices) = 54, weight = 190.5945663000252\n",
      "  len(indices) = 49, weight = 177.00354049310113\n",
      "  len(indices) = 34, weight = 131.67512839151652\n",
      "  len(indices) = 73, weight = 237.15649291307946\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    len(_augmented_mask_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.4\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "len(cxrlt2024_train_dicom_ids) = 258871\n",
      "len(cxrlt2024_dev_dicom_ids) = 39293\n",
      "len(forbidden_train_dicom_ids) = 40220\n",
      "\u001b[1m\u001b[35mPreparing CXR-LT-2024 challenge datasets and dataloaders for training/testing...\u001b[0m\n",
      "Using image size mode: small_256x256\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"train\"]) = 145680\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"dev\"]) = 39352\n",
      "Total number of images: 184650\n",
      "\u001b[1mBuilding cxrlt2024 train phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 2, len(indices) = 38366\n",
      "num_phrases = 1, len(indices) = 89231\n",
      "num_phrases = 3, len(indices) = 12488\n",
      "num_phrases = 4, len(indices) = 3658\n",
      "num_phrases = 11, len(indices) = 97\n",
      "num_phrases = 6, len(indices) = 281\n",
      "num_phrases = 5, len(indices) = 937\n",
      "num_phrases = 20, len(indices) = 97\n",
      "num_phrases = 7, len(indices) = 52\n",
      "num_phrases = 16, len(indices) = 48\n",
      "num_phrases = 17, len(indices) = 26\n",
      "num_phrases = 10, len(indices) = 2\n",
      "num_phrases = 8, len(indices) = 13\n",
      "num_phrases = 12, len(indices) = 2\n",
      "\u001b[1mBuilding cxrlt2024 dev phrase classifier dataloader...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_phrases = 2, len(indices) = 7030\n",
      "num_phrases = 1, len(indices) = 29823\n",
      "num_phrases = 3, len(indices) = 1393\n",
      "num_phrases = 12, len(indices) = 77\n",
      "num_phrases = 6, len(indices) = 25\n",
      "num_phrases = 8, len(indices) = 34\n",
      "num_phrases = 14, len(indices) = 74\n",
      "num_phrases = 11, len(indices) = 124\n",
      "num_phrases = 16, len(indices) = 53\n",
      "num_phrases = 4, len(indices) = 294\n",
      "num_phrases = 15, len(indices) = 51\n",
      "num_phrases = 10, len(indices) = 77\n",
      "num_phrases = 9, len(indices) = 32\n",
      "num_phrases = 7, len(indices) = 36\n",
      "num_phrases = 13, len(indices) = 92\n",
      "num_phrases = 20, len(indices) = 54\n",
      "num_phrases = 5, len(indices) = 54\n",
      "num_phrases = 18, len(indices) = 7\n",
      "num_phrases = 17, len(indices) = 18\n",
      "num_phrases = 19, len(indices) = 4\n",
      "\u001b[1mBuilding cxrlt2024 train/val dataloader for fact classifier using official labels...\u001b[0m\n",
      "len(dicom_ids) = 258871\n",
      "len(train_indices) = 240529\n",
      "len(val_indices) = 18342\n",
      "labels.shape = (258871, 40)\n",
      "class_embeddings.shape = (40, 128)\n",
      "\u001b[93m\u001b[1mUsing all CXR-LT-2024 official labels for training the fact classifier\u001b[0m\n",
      "len(train_indices) = 258871\n",
      "len(val_indices) = 0\n",
      "\u001b[93m707 train indices removed due to forbidden_train_dicom_ids\u001b[0m\n",
      "\u001b[93mBalanced sampling is enabled for CXR-LT-2024 fact classifier training\u001b[0m\n",
      "Lobar Atelectasis: 129\n",
      "Clavicle Fracture: 167\n",
      "Round(ed) Atelectasis: 171\n",
      "Azygos Lobe: 198\n",
      "Pneumoperitoneum: 515\n",
      "Pleural Other: 614\n",
      "Hydropneumothorax: 645\n",
      "Pneumomediastinum: 704\n",
      "Infarction: 725\n",
      "Kyphosis: 777\n",
      "Pulmonary Hypertension: 900\n",
      "Fibrosis: 1168\n",
      "Pulmonary Embolism: 1628\n",
      "Subcutaneous Emphysema: 2045\n",
      "Tuberculosis: 2074\n",
      "Lung Lesion: 2324\n",
      "Fissure: 2799\n",
      "Granuloma: 2959\n",
      "Pleural Thickening: 3262\n",
      "Tortuous Aorta: 3328\n",
      "Adenopathy: 3403\n",
      "Emphysema: 3650\n",
      "Hernia: 3976\n",
      "Calcification of the Aorta: 4231\n",
      "Mass: 5267\n",
      "Nodule: 7512\n",
      "Rib Fracture: 8901\n",
      "Infiltration: 10064\n",
      "Fracture: 11542\n",
      "Pneumothorax: 13822\n",
      "No labels: 13915\n",
      "Consolidation: 15317\n",
      "Enlarged Cardiomediastinum: 29540\n",
      "Normal: 34205\n",
      "Edema: 37140\n",
      "Pneumonia: 46530\n",
      "Atelectasis: 65148\n",
      "Pleural Effusion: 66132\n",
      "Cardiomegaly: 74542\n",
      "Lung Opacity: 77197\n",
      "Support Devices: 85689\n",
      "Group sizes: [34205, 24884, 24150, 22748, 19196, 14441, 13915, 10656, 9421, 9182, 8327, 8127, 7090, 5005, 3785, 3748, 3497, 3382, 3033, 2881, 2809, 2734, 2637, 2532, 2132, 2007, 1892, 1721, 1434, 1133, 875, 770, 718, 666, 641, 610, 515, 198, 171, 167, 129]\n",
      "  len(indices) = 34205, weight = 3416.968505575188\n",
      "  len(indices) = 24884, weight = 3114.0105584213015\n",
      "  len(indices) = 24150, weight = 3086.458645767619\n",
      "  len(indices) = 22748, weight = 3031.91054482965\n",
      "  len(indices) = 19196, weight = 2880.5738366725595\n",
      "  len(indices) = 14441, weight = 2638.3021770753585\n",
      "  len(indices) = 13915, weight = 2607.758881815128\n",
      "  len(indices) = 10656, weight = 2395.0126251246966\n",
      "  len(indices) = 9421, weight = 2300.838171256539\n",
      "  len(indices) = 9182, weight = 2281.5095060487456\n",
      "  len(indices) = 8327, weight = 2208.9773218632636\n",
      "  len(indices) = 8127, weight = 2191.1782895085344\n",
      "  len(indices) = 7090, weight = 2093.0111715585585\n",
      "  len(indices) = 5005, weight = 1855.94882572346\n",
      "  len(indices) = 3785, weight = 1679.251257544058\n",
      "  len(indices) = 3748, weight = 1673.2516585085702\n",
      "  len(indices) = 3497, weight = 1631.322863020584\n",
      "  len(indices) = 3382, weight = 1611.3495036813902\n",
      "  len(indices) = 3033, weight = 1547.4236900442331\n",
      "  len(indices) = 2881, weight = 1517.8434442395078\n",
      "  len(indices) = 2809, weight = 1503.4220704576376\n",
      "  len(indices) = 2734, weight = 1488.1026745697216\n",
      "  len(indices) = 2637, weight = 1467.8167780082722\n",
      "  len(indices) = 2532, weight = 1445.2202972163147\n",
      "  len(indices) = 2132, weight = 1352.1621707070422\n",
      "  len(indices) = 2007, weight = 1320.4375035117398\n",
      "  len(indices) = 1892, weight = 1289.9374456380835\n",
      "  len(indices) = 1721, weight = 1241.9610975177739\n",
      "  len(indices) = 1434, weight = 1152.9443664750534\n",
      "  len(indices) = 1133, weight = 1044.4216372805452\n",
      "  len(indices) = 875, weight = 933.4740610250955\n",
      "  len(indices) = 770, weight = 881.6194889606477\n",
      "  len(indices) = 718, weight = 854.086901505717\n",
      "  len(indices) = 666, weight = 825.1296008730636\n",
      "  len(indices) = 641, weight = 810.6474536669926\n",
      "  len(indices) = 610, weight = 792.1375053617213\n",
      "  len(indices) = 515, weight = 731.0500738870246\n",
      "  len(indices) = 198, weight = 444.08258972130596\n",
      "  len(indices) = 171, weight = 408.1638922480593\n",
      "  len(indices) = 167, weight = 402.55283205217046\n",
      "  len(indices) = 129, weight = 344.6530550389792\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (596408, 128)\n",
      "Using image size mode: small_256x256\n",
      "227835it [00:01, 189576.42it/s]\n",
      "Total number of images: 258164\n",
      "len(train_indices) = 258164\n",
      "avg_facts_per_image = 436.5657372832773\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 8\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 32271\n",
      "\u001b[1m\u001b[35mPreparing Chest Imagenome dataset and dataloader for training...\u001b[0m\n",
      "Loading bbox_phrase_embeddings and bbox_phrases from /mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl...\n",
      "bbox_phrase_embeddings.shape = (36, 128)\n",
      "len(bbox_phrases) = 36\n",
      "\t right lung\n",
      "\t right upper lung zone\n",
      "\t right mid lung zone\n",
      "\t right lower lung zone\n",
      "\t right hilar structures\n",
      "\t right apical zone\n",
      "\t right costophrenic angle\n",
      "\t right cardiophrenic angle\n",
      "\t right hemidiaphragm\n",
      "\t left lung\n",
      "\t left upper lung zone\n",
      "\t left mid lung zone\n",
      "\t left lower lung zone\n",
      "\t left hilar structures\n",
      "\t left apical zone\n",
      "\t left costophrenic angle\n",
      "\t left hemidiaphragm\n",
      "\t trachea\n",
      "\t spine\n",
      "\t right clavicle\n",
      "\t left clavicle\n",
      "\t aortic arch\n",
      "\t mediastinum\n",
      "\t upper mediastinum\n",
      "\t svc\n",
      "\t cardiac silhouette\n",
      "\t left cardiac silhouette\n",
      "\t right cardiac silhouette\n",
      "\t cavoatrial junction\n",
      "\t right atrium\n",
      "\t descending aorta\n",
      "\t carina\n",
      "\t left upper abdomen\n",
      "\t right upper abdomen\n",
      "\t abdomen\n",
      "\t left cardiophrenic angle\n",
      "Using image size mode: small_256x256\n",
      "\u001b[1mLoading precomputed bbox_coords_and_presence_and_mask from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/bbox_coords_and_presence_and_mask(14,14,243310).pkl...\u001b[0m\n",
      "File size: 1903416582 bytes (1858805.26 KB, 1815.24 MB, 1.77 GB)\n",
      "227835it [00:00, 228137.37it/s]\n",
      "Total number of images: 165768\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mCreating IU X-Ray Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    len(_augmented_mask_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.4\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[1mPreparing data for training/testing...\u001b[0m\n",
      "fact_embeddings.shape = (2331, 128)\n",
      "Number of invalid images removed: 111\n",
      "avg_facts_per_image = 2327.3329256692487\n",
      "train_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train dataloader...\u001b[0m\n",
      "len(self.train_dataloader) = 920\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 32271\n",
      "len(mimiccxr_trainer.train_chest_imagenome_dataloader) = 15070\n",
      "len(mimiccxr_trainer.cxrlt2024_official_train_dataloader) = 100000000000000000\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_train_dataloader) = 5821\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_dev_dataloader) = 327\n",
      "len(vinbig_trainer.train_dataloader) = 71428571428571429\n",
      "len(chexlocalize_trainer.train_dataloader) = 37\n",
      "len(chexpert_trainer.train_dataloader) = 40000000000000000\n",
      "len(iuxray_trainer.train_dataloader) = 920\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [2.5, 1.0, 3.0, 3.0, 1.5, 0.4, 0.5, 0.5]\n",
      "merged_dataset_name = mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_189_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6336.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m15) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/checkpoint_189_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6336.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m16) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m17) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 190/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.03710, mimfg_att_reg_loss 0.16699, mimfg_phrcls_loss 2.04592, mimfg_prc_auc 0.78226, cibg_att_sup_loss 0.45191, cibg_segmask_iou 0.39176, vbg_phrcls_loss 1.63546, vbg_prc_auc 0.61584, vbg_att_reg_loss 0.08356, vbg_att_sup_loss 0.37454, vbg_segmask_iou 0.20764, cl_att_sup_loss 0.36843, cl_segmask_iou 0.37105, cl_phrcls_loss 1.20770, cl_phrase_acc 0.94337, chxp_att_reg_loss 0.18112, chxp_phrcls_loss 2.59420, chxp_prc_auc 0.69223, iufg_att_reg_loss 0.20421, iufg_phrcls_loss 2.86992, iufg_prc_auc 0.51299, cxrlt2024c_att_reg_loss 0.19565, cxrlt2024c_phrcls_loss 2.13188, cxrlt2024c_prc_auc 0.66992, cxrlt2024o_att_reg_loss 0.18495, cxrlt2024o_phrcls_loss 1.68608, cxrlt2024o_prc_auc 0.17458, 309.25 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.17301, cxrlt2024c_phrcls_loss 1.28514, cxrlt2024c_prc_auc 0.62572, 211.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_190_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6214.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 191/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.97858, mimfg_att_reg_loss 0.16769, mimfg_phrcls_loss 2.05116, mimfg_prc_auc 0.78534, cibg_att_sup_loss 0.42781, cibg_segmask_iou 0.40406, vbg_phrcls_loss 1.60320, vbg_prc_auc 0.63043, vbg_att_reg_loss 0.07790, vbg_att_sup_loss 0.36141, vbg_segmask_iou 0.20554, cl_att_sup_loss 0.31959, cl_segmask_iou 0.36388, cl_phrcls_loss 1.01717, cl_phrase_acc 0.96019, chxp_att_reg_loss 0.17054, chxp_phrcls_loss 2.50125, chxp_prc_auc 0.73030, iufg_att_reg_loss 0.18683, iufg_phrcls_loss 2.70132, iufg_prc_auc 0.56566, cxrlt2024c_att_reg_loss 0.18325, cxrlt2024c_phrcls_loss 2.03539, cxrlt2024c_prc_auc 0.68948, cxrlt2024o_att_reg_loss 0.18249, cxrlt2024o_phrcls_loss 1.65955, cxrlt2024o_prc_auc 0.18738, 369.49 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15656, cxrlt2024c_phrcls_loss 1.26737, cxrlt2024c_prc_auc 0.63461, 266.99 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_191_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6304.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 192/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.94972, mimfg_att_reg_loss 0.16515, mimfg_phrcls_loss 2.00421, mimfg_prc_auc 0.79053, cibg_att_sup_loss 0.42287, cibg_segmask_iou 0.40684, vbg_phrcls_loss 1.50061, vbg_prc_auc 0.69991, vbg_att_reg_loss 0.07048, vbg_att_sup_loss 0.35028, vbg_segmask_iou 0.20667, cl_att_sup_loss 0.30478, cl_segmask_iou 0.36874, cl_phrcls_loss 0.95805, cl_phrase_acc 0.96513, chxp_att_reg_loss 0.16844, chxp_phrcls_loss 2.47168, chxp_prc_auc 0.72030, iufg_att_reg_loss 0.18942, iufg_phrcls_loss 2.77325, iufg_prc_auc 0.57037, cxrlt2024c_att_reg_loss 0.18791, cxrlt2024c_phrcls_loss 2.02150, cxrlt2024c_prc_auc 0.70193, cxrlt2024o_att_reg_loss 0.18210, cxrlt2024o_phrcls_loss 1.65674, cxrlt2024o_prc_auc 0.20192, 383.30 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15784, cxrlt2024c_phrcls_loss 1.23764, cxrlt2024c_prc_auc 0.63682, 252.46 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_192_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6333.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 193/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.94356, mimfg_att_reg_loss 0.16593, mimfg_phrcls_loss 2.01201, mimfg_prc_auc 0.78669, cibg_att_sup_loss 0.42358, cibg_segmask_iou 0.40799, vbg_phrcls_loss 1.48391, vbg_prc_auc 0.69012, vbg_att_reg_loss 0.06772, vbg_att_sup_loss 0.33794, vbg_segmask_iou 0.21203, cl_att_sup_loss 0.28679, cl_segmask_iou 0.37472, cl_phrcls_loss 0.83401, cl_phrase_acc 0.97174, chxp_att_reg_loss 0.17127, chxp_phrcls_loss 2.54590, chxp_prc_auc 0.71481, iufg_att_reg_loss 0.20325, iufg_phrcls_loss 2.84234, iufg_prc_auc 0.56972, cxrlt2024c_att_reg_loss 0.18551, cxrlt2024c_phrcls_loss 2.00765, cxrlt2024c_prc_auc 0.71879, cxrlt2024o_att_reg_loss 0.18115, cxrlt2024o_phrcls_loss 1.64811, cxrlt2024o_prc_auc 0.20165, 377.86 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15936, cxrlt2024c_phrcls_loss 1.23785, cxrlt2024c_prc_auc 0.63794, 254.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_193_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6341.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 194/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.92272, mimfg_att_reg_loss 0.16442, mimfg_phrcls_loss 1.98894, mimfg_prc_auc 0.79508, cibg_att_sup_loss 0.41835, cibg_segmask_iou 0.41100, vbg_phrcls_loss 1.45828, vbg_prc_auc 0.71315, vbg_att_reg_loss 0.06724, vbg_att_sup_loss 0.32341, vbg_segmask_iou 0.20777, cl_att_sup_loss 0.29473, cl_segmask_iou 0.37403, cl_phrcls_loss 0.84305, cl_phrase_acc 0.97363, chxp_att_reg_loss 0.16828, chxp_phrcls_loss 2.46422, chxp_prc_auc 0.72861, iufg_att_reg_loss 0.18453, iufg_phrcls_loss 2.70056, iufg_prc_auc 0.55412, cxrlt2024c_att_reg_loss 0.18522, cxrlt2024c_phrcls_loss 1.99720, cxrlt2024c_prc_auc 0.71888, cxrlt2024o_att_reg_loss 0.18070, cxrlt2024o_phrcls_loss 1.65158, cxrlt2024o_prc_auc 0.19963, 382.85 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15892, cxrlt2024c_phrcls_loss 1.23648, cxrlt2024c_prc_auc 0.63858, 257.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_194_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6348.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 195/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.03263, mimfg_att_reg_loss 0.16535, mimfg_phrcls_loss 2.03411, mimfg_prc_auc 0.78374, cibg_att_sup_loss 0.45725, cibg_segmask_iou 0.39061, vbg_phrcls_loss 1.66896, vbg_prc_auc 0.58412, vbg_att_reg_loss 0.08608, vbg_att_sup_loss 0.38866, vbg_segmask_iou 0.20848, cl_att_sup_loss 0.36702, cl_segmask_iou 0.37033, cl_phrcls_loss 1.24074, cl_phrase_acc 0.93970, chxp_att_reg_loss 0.18038, chxp_phrcls_loss 2.60257, chxp_prc_auc 0.69490, iufg_att_reg_loss 0.19959, iufg_phrcls_loss 2.84151, iufg_prc_auc 0.54280, cxrlt2024c_att_reg_loss 0.17956, cxrlt2024c_phrcls_loss 2.09131, cxrlt2024c_prc_auc 0.66477, cxrlt2024o_att_reg_loss 0.18739, cxrlt2024o_phrcls_loss 1.69748, cxrlt2024o_prc_auc 0.17185, 373.33 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16658, cxrlt2024c_phrcls_loss 1.34780, cxrlt2024c_prc_auc 0.61245, 258.92 secs\n",
      "\u001b[1m---- Epoch 196/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.00453, mimfg_att_reg_loss 0.16385, mimfg_phrcls_loss 2.02168, mimfg_prc_auc 0.78826, cibg_att_sup_loss 0.43645, cibg_segmask_iou 0.39977, vbg_phrcls_loss 1.61797, vbg_prc_auc 0.64391, vbg_att_reg_loss 0.07873, vbg_att_sup_loss 0.36620, vbg_segmask_iou 0.21011, cl_att_sup_loss 0.33855, cl_segmask_iou 0.36956, cl_phrcls_loss 1.14044, cl_phrase_acc 0.94872, chxp_att_reg_loss 0.17867, chxp_phrcls_loss 2.61707, chxp_prc_auc 0.69919, iufg_att_reg_loss 0.19249, iufg_phrcls_loss 2.70363, iufg_prc_auc 0.56555, cxrlt2024c_att_reg_loss 0.18008, cxrlt2024c_phrcls_loss 2.08381, cxrlt2024c_prc_auc 0.67940, cxrlt2024o_att_reg_loss 0.18837, cxrlt2024o_phrcls_loss 1.69462, cxrlt2024o_prc_auc 0.18588, 376.86 secs\n",
      "(2) Validation stage ...\n",
      "loss 1.95164, mimfg_att_reg_loss 0.16473, mimfg_phrcls_loss 2.00749, mimfg_prc_auc 0.79226, cibg_att_sup_loss 0.42718, cibg_segmask_iou 0.41065, vbg_phrcls_loss 1.53927, vbg_prc_auc 0.67799, vbg_att_reg_loss 0.07264, vbg_att_sup_loss 0.34305, vbg_segmask_iou 0.20915, cl_att_sup_loss 0.30812, cl_segmask_iou 0.37825, cl_phrcls_loss 0.94988, cl_phrase_acc 0.96332, chxp_att_reg_loss 0.17118, chxp_phrcls_loss 2.50262, chxp_prc_auc 0.71646, iufg_att_reg_loss 0.19319, iufg_phrcls_loss 2.74329, iufg_prc_auc 0.56444, cxrlt2024c_att_reg_loss 0.17271, cxrlt2024c_phrcls_loss 2.02008, cxrlt2024c_prc_auc 0.66874, cxrlt2024o_att_reg_loss 0.18097, cxrlt2024o_phrcls_loss 1.66069, cxrlt2024o_prc_auc 0.19433, 382.03 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16694, cxrlt2024c_phrcls_loss 1.25272, cxrlt2024c_prc_auc 0.63254, 259.55 secs\n",
      "\u001b[1m---- Epoch 198/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.91836, mimfg_att_reg_loss 0.16602, mimfg_phrcls_loss 2.01593, mimfg_prc_auc 0.78924, cibg_att_sup_loss 0.41765, cibg_segmask_iou 0.41312, vbg_phrcls_loss 1.47135, vbg_prc_auc 0.71945, vbg_att_reg_loss 0.07168, vbg_att_sup_loss 0.32132, vbg_segmask_iou 0.21595, cl_att_sup_loss 0.28499, cl_segmask_iou 0.37261, cl_phrcls_loss 0.86031, cl_phrase_acc 0.97059, chxp_att_reg_loss 0.16974, chxp_phrcls_loss 2.49020, chxp_prc_auc 0.71839, iufg_att_reg_loss 0.19679, iufg_phrcls_loss 2.73362, iufg_prc_auc 0.56849, cxrlt2024c_att_reg_loss 0.16683, cxrlt2024c_phrcls_loss 1.94104, cxrlt2024c_prc_auc 0.69055, cxrlt2024o_att_reg_loss 0.18037, cxrlt2024o_phrcls_loss 1.66472, cxrlt2024o_prc_auc 0.19537, 380.75 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16259, cxrlt2024c_phrcls_loss 1.25509, cxrlt2024c_prc_auc 0.63483, 260.55 secs\n",
      "\u001b[1m---- Epoch 199/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.91746, mimfg_att_reg_loss 0.16239, mimfg_phrcls_loss 1.99918, mimfg_prc_auc 0.79196, cibg_att_sup_loss 0.41914, cibg_segmask_iou 0.41442, vbg_phrcls_loss 1.43721, vbg_prc_auc 0.71080, vbg_att_reg_loss 0.06547, vbg_att_sup_loss 0.32055, vbg_segmask_iou 0.21371, cl_att_sup_loss 0.28798, cl_segmask_iou 0.37425, cl_phrcls_loss 0.83810, cl_phrase_acc 0.97027, chxp_att_reg_loss 0.16881, chxp_phrcls_loss 2.51824, chxp_prc_auc 0.71473, iufg_att_reg_loss 0.19541, iufg_phrcls_loss 2.77442, iufg_prc_auc 0.57558, cxrlt2024c_att_reg_loss 0.17046, cxrlt2024c_phrcls_loss 1.99837, cxrlt2024c_prc_auc 0.67106, cxrlt2024o_att_reg_loss 0.18124, cxrlt2024o_phrcls_loss 1.63712, cxrlt2024o_prc_auc 0.21005, 379.77 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16214, cxrlt2024c_phrcls_loss 1.25271, cxrlt2024c_prc_auc 0.63527, 262.80 secs\n",
      "\u001b[1m---- Epoch 200/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.05458, mimfg_att_reg_loss 0.16889, mimfg_phrcls_loss 2.07220, mimfg_prc_auc 0.77740, cibg_att_sup_loss 0.45241, cibg_segmask_iou 0.39314, vbg_phrcls_loss 1.66588, vbg_prc_auc 0.59699, vbg_att_reg_loss 0.08373, vbg_att_sup_loss 0.38175, vbg_segmask_iou 0.20424, cl_att_sup_loss 0.37792, cl_segmask_iou 0.35997, cl_phrcls_loss 1.28287, cl_phrase_acc 0.94086, chxp_att_reg_loss 0.17928, chxp_phrcls_loss 2.62636, chxp_prc_auc 0.69365, iufg_att_reg_loss 0.20782, iufg_phrcls_loss 2.89330, iufg_prc_auc 0.52791, cxrlt2024c_att_reg_loss 0.17941, cxrlt2024c_phrcls_loss 2.11679, cxrlt2024c_prc_auc 0.65861, cxrlt2024o_att_reg_loss 0.18946, cxrlt2024o_phrcls_loss 1.71487, cxrlt2024o_prc_auc 0.16773, 372.53 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16846, cxrlt2024c_phrcls_loss 1.30665, cxrlt2024c_prc_auc 0.61731, 255.78 secs\n",
      "\u001b[1m---- Epoch 201/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.01452, mimfg_att_reg_loss 0.17135, mimfg_phrcls_loss 2.09235, mimfg_prc_auc 0.77703, cibg_att_sup_loss 0.43948, cibg_segmask_iou 0.40063, vbg_phrcls_loss 1.62126, vbg_prc_auc 0.63442, vbg_att_reg_loss 0.07859, vbg_att_sup_loss 0.36030, vbg_segmask_iou 0.20837, cl_att_sup_loss 0.32945, cl_segmask_iou 0.37362, cl_phrcls_loss 1.06373, cl_phrase_acc 0.95599, chxp_att_reg_loss 0.17218, chxp_phrcls_loss 2.54612, chxp_prc_auc 0.70163, iufg_att_reg_loss 0.19466, iufg_phrcls_loss 2.81996, iufg_prc_auc 0.54493, cxrlt2024c_att_reg_loss 0.17702, cxrlt2024c_phrcls_loss 2.06556, cxrlt2024c_prc_auc 0.66258, cxrlt2024o_att_reg_loss 0.18722, cxrlt2024o_phrcls_loss 1.69373, cxrlt2024o_prc_auc 0.18422, 381.29 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15721, cxrlt2024c_phrcls_loss 1.25601, cxrlt2024c_prc_auc 0.63003, 261.41 secs\n",
      "\u001b[1m---- Epoch 202/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.94877, mimfg_att_reg_loss 0.16221, mimfg_phrcls_loss 1.98941, mimfg_prc_auc 0.79547, cibg_att_sup_loss 0.42023, cibg_segmask_iou 0.40947, vbg_phrcls_loss 1.52246, vbg_prc_auc 0.70644, vbg_att_reg_loss 0.07602, vbg_att_sup_loss 0.34018, vbg_segmask_iou 0.21528, cl_att_sup_loss 0.30274, cl_segmask_iou 0.37276, cl_phrcls_loss 0.94905, cl_phrase_acc 0.96586, chxp_att_reg_loss 0.16951, chxp_phrcls_loss 2.48979, chxp_prc_auc 0.71858, iufg_att_reg_loss 0.20083, iufg_phrcls_loss 2.77853, iufg_prc_auc 0.55881, cxrlt2024c_att_reg_loss 0.17768, cxrlt2024c_phrcls_loss 2.03887, cxrlt2024c_prc_auc 0.69823, cxrlt2024o_att_reg_loss 0.18058, cxrlt2024o_phrcls_loss 1.64874, cxrlt2024o_prc_auc 0.19358, 377.10 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15711, cxrlt2024c_phrcls_loss 1.24565, cxrlt2024c_prc_auc 0.63389, 273.47 secs\n",
      "\u001b[1m---- Epoch 203/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.91921, mimfg_att_reg_loss 0.16413, mimfg_phrcls_loss 1.99781, mimfg_prc_auc 0.79261, cibg_att_sup_loss 0.41991, cibg_segmask_iou 0.41271, vbg_phrcls_loss 1.47746, vbg_prc_auc 0.70982, vbg_att_reg_loss 0.06893, vbg_att_sup_loss 0.32794, vbg_segmask_iou 0.21655, cl_att_sup_loss 0.28618, cl_segmask_iou 0.38087, cl_phrcls_loss 0.88291, cl_phrase_acc 0.96901, chxp_att_reg_loss 0.17008, chxp_phrcls_loss 2.53859, chxp_prc_auc 0.71078, iufg_att_reg_loss 0.18300, iufg_phrcls_loss 2.61777, iufg_prc_auc 0.59902, cxrlt2024c_att_reg_loss 0.16905, cxrlt2024c_phrcls_loss 1.96788, cxrlt2024c_prc_auc 0.67931, cxrlt2024o_att_reg_loss 0.18216, cxrlt2024o_phrcls_loss 1.66118, cxrlt2024o_prc_auc 0.19788, 379.55 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15803, cxrlt2024c_phrcls_loss 1.24359, cxrlt2024c_prc_auc 0.63559, 260.66 secs\n",
      "\u001b[1m---- Epoch 204/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.91947, mimfg_att_reg_loss 0.16544, mimfg_phrcls_loss 2.00718, mimfg_prc_auc 0.79161, cibg_att_sup_loss 0.42066, cibg_segmask_iou 0.41547, vbg_phrcls_loss 1.44116, vbg_prc_auc 0.72392, vbg_att_reg_loss 0.06615, vbg_att_sup_loss 0.32226, vbg_segmask_iou 0.21921, cl_att_sup_loss 0.27436, cl_segmask_iou 0.37298, cl_phrcls_loss 0.83697, cl_phrase_acc 0.97101, chxp_att_reg_loss 0.16240, chxp_phrcls_loss 2.44131, chxp_prc_auc 0.73620, iufg_att_reg_loss 0.19434, iufg_phrcls_loss 2.75612, iufg_prc_auc 0.56400, cxrlt2024c_att_reg_loss 0.17286, cxrlt2024c_phrcls_loss 1.99251, cxrlt2024c_prc_auc 0.69417, cxrlt2024o_att_reg_loss 0.18132, cxrlt2024o_phrcls_loss 1.65220, cxrlt2024o_prc_auc 0.19904, 382.90 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15731, cxrlt2024c_phrcls_loss 1.24463, cxrlt2024c_prc_auc 0.63585, 269.03 secs\n",
      "\u001b[1m---- Epoch 205/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.02831, mimfg_att_reg_loss 0.16468, mimfg_phrcls_loss 2.05564, mimfg_prc_auc 0.78053, cibg_att_sup_loss 0.44284, cibg_segmask_iou 0.39795, vbg_phrcls_loss 1.66153, vbg_prc_auc 0.59966, vbg_att_reg_loss 0.08608, vbg_att_sup_loss 0.37756, vbg_segmask_iou 0.20398, cl_att_sup_loss 0.35790, cl_segmask_iou 0.37227, cl_phrcls_loss 1.21343, cl_phrase_acc 0.93959, chxp_att_reg_loss 0.17679, chxp_phrcls_loss 2.63427, chxp_prc_auc 0.67307, iufg_att_reg_loss 0.20179, iufg_phrcls_loss 2.85103, iufg_prc_auc 0.51877, cxrlt2024c_att_reg_loss 0.17730, cxrlt2024c_phrcls_loss 2.06305, cxrlt2024c_prc_auc 0.65988, cxrlt2024o_att_reg_loss 0.18666, cxrlt2024o_phrcls_loss 1.70545, cxrlt2024o_prc_auc 0.17454, 376.26 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.16437, cxrlt2024c_phrcls_loss 1.29310, cxrlt2024c_prc_auc 0.61265, 256.60 secs\n",
      "\u001b[1m---- Epoch 206/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.98807, mimfg_att_reg_loss 0.16588, mimfg_phrcls_loss 2.04870, mimfg_prc_auc 0.78434, cibg_att_sup_loss 0.43511, cibg_segmask_iou 0.39992, vbg_phrcls_loss 1.58124, vbg_prc_auc 0.65376, vbg_att_reg_loss 0.07351, vbg_att_sup_loss 0.36008, vbg_segmask_iou 0.21450, cl_att_sup_loss 0.32055, cl_segmask_iou 0.36647, cl_phrcls_loss 1.09618, cl_phrase_acc 0.95273, chxp_att_reg_loss 0.17978, chxp_phrcls_loss 2.62774, chxp_prc_auc 0.68867, iufg_att_reg_loss 0.18316, iufg_phrcls_loss 2.62881, iufg_prc_auc 0.56588, cxrlt2024c_att_reg_loss 0.17751, cxrlt2024c_phrcls_loss 2.05362, cxrlt2024c_prc_auc 0.66498, cxrlt2024o_att_reg_loss 0.18521, cxrlt2024o_phrcls_loss 1.67816, cxrlt2024o_prc_auc 0.18773, 374.76 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cxrlt2024c_att_reg_loss 0.16581, cxrlt2024c_phrcls_loss 1.25722, cxrlt2024c_prc_auc 0.62600, 255.40 secs\n",
      "\u001b[1m---- Epoch 207/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.96953, mimfg_att_reg_loss 0.16766, mimfg_phrcls_loss 2.05248, mimfg_prc_auc 0.78022, cibg_att_sup_loss 0.41821, cibg_segmask_iou 0.40863, vbg_phrcls_loss 1.51386, vbg_prc_auc 0.69504, vbg_att_reg_loss 0.07409, vbg_att_sup_loss 0.33892, vbg_segmask_iou 0.21259, cl_att_sup_loss 0.28354, cl_segmask_iou 0.37790, cl_phrcls_loss 0.92247, cl_phrase_acc 0.96919, chxp_att_reg_loss 0.16978, chxp_phrcls_loss 2.53146, chxp_prc_auc 0.70447, iufg_att_reg_loss 0.20412, iufg_phrcls_loss 2.87435, iufg_prc_auc 0.53907, cxrlt2024c_att_reg_loss 0.18643, cxrlt2024c_phrcls_loss 2.02949, cxrlt2024c_prc_auc 0.69516, cxrlt2024o_att_reg_loss 0.18233, cxrlt2024o_phrcls_loss 1.66856, cxrlt2024o_prc_auc 0.19855, 377.26 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15889, cxrlt2024c_phrcls_loss 1.24683, cxrlt2024c_prc_auc 0.63187, 261.41 secs\n",
      "\u001b[1m---- Epoch 208/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.93960, mimfg_att_reg_loss 0.16102, mimfg_phrcls_loss 1.97302, mimfg_prc_auc 0.80090, cibg_att_sup_loss 0.41813, cibg_segmask_iou 0.41220, vbg_phrcls_loss 1.43022, vbg_prc_auc 0.73012, vbg_att_reg_loss 0.06749, vbg_att_sup_loss 0.31532, vbg_segmask_iou 0.21512, cl_att_sup_loss 0.27993, cl_segmask_iou 0.38051, cl_phrcls_loss 0.84522, cl_phrase_acc 0.97454, chxp_att_reg_loss 0.17259, chxp_phrcls_loss 2.53025, chxp_prc_auc 0.71554, iufg_att_reg_loss 0.19665, iufg_phrcls_loss 2.69955, iufg_prc_auc 0.57125, cxrlt2024c_att_reg_loss 0.20337, cxrlt2024c_phrcls_loss 2.08609, cxrlt2024c_prc_auc 0.71432, cxrlt2024o_att_reg_loss 0.17982, cxrlt2024o_phrcls_loss 1.64236, cxrlt2024o_prc_auc 0.20267, 376.05 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15768, cxrlt2024c_phrcls_loss 1.24026, cxrlt2024c_prc_auc 0.63344, 274.32 secs\n",
      "\u001b[1m---- Epoch 209/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.94942, mimfg_att_reg_loss 0.16384, mimfg_phrcls_loss 1.98868, mimfg_prc_auc 0.79372, cibg_att_sup_loss 0.40288, cibg_segmask_iou 0.41510, vbg_phrcls_loss 1.42253, vbg_prc_auc 0.74753, vbg_att_reg_loss 0.06764, vbg_att_sup_loss 0.31506, vbg_segmask_iou 0.21335, cl_att_sup_loss 0.27331, cl_segmask_iou 0.37189, cl_phrcls_loss 0.83217, cl_phrase_acc 0.97470, chxp_att_reg_loss 0.16970, chxp_phrcls_loss 2.48734, chxp_prc_auc 0.71943, iufg_att_reg_loss 0.18563, iufg_phrcls_loss 2.61062, iufg_prc_auc 0.58807, cxrlt2024c_att_reg_loss 0.21185, cxrlt2024c_phrcls_loss 2.12185, cxrlt2024c_prc_auc 0.72318, cxrlt2024o_att_reg_loss 0.18104, cxrlt2024o_phrcls_loss 1.65317, cxrlt2024o_prc_auc 0.20265, 377.87 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15799, cxrlt2024c_phrcls_loss 1.23774, cxrlt2024c_prc_auc 0.63424, 257.38 secs\n",
      "\u001b[1m---- Epoch 210/289\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "   iteration 24075\r"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \"models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1200 \\\n",
    "--max_images_per_batch 25 \\\n",
    "--max_phrases_per_batch 400 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 5.0 \\\n",
    "--raw_image_encoding \"siglip-huggingface\" \\\n",
    "--huggingface_model_name \"google/siglip-base-patch16-224\" \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--image_size 224 224 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 196 \\\n",
    "--regions_width 14 \\\n",
    "--regions_height 14 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"film_layers_plus_sigmoid_attention_and_custom_classifier\" \\\n",
    "--visual_feature_proj_size 256 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_attention_regularization_loss \\\n",
    "--attention_supervision_loss_weight 2.0 \\\n",
    "--phrase_classifier_loss_weight 2.0 \\\n",
    "--foreground_loss_weight 1.5 \\\n",
    "--use_cxrlt2024_challenge_split \\\n",
    "--cxrlt2024_do_balanced_sampling \\\n",
    "--use_cxrlt2024_official_labels \\\n",
    "--use_all_cxrlt2024_official_labels_for_training \\\n",
    "--cxrlt2024_official_training_labels_for_fact_classification_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_official_training_labels_for_fact_classification(n_train=240529,n_val=18342,pf=0.03).pkl\" \\\n",
    "--use_cxrlt2024_custom_labels \\\n",
    "--cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_fact_based_pos_neg_facts(hash=1360,3939902508813076616).pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--use_chest_imagenome_for_train \\\n",
    "--chest_imagenome_bbox_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chest_imagenome/bbox_phrase_embeddings(hash=333,1643894111267724539).pkl\" \\\n",
    "--use_vinbig_for_train \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings(hash=325,2238524744738711392).pkl\" \\\n",
    "--vinbig_training_data_mode \"all\" \\\n",
    "--use_chexlocalize_for_train \\\n",
    "--chexlocalize_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexlocalize/class_phrase_embeddings(hash=528,2353352898845085012).pkl\" \\\n",
    "--use_chexpert_for_train \\\n",
    "--chexpert_class_phrase_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/chexpert/class_phrase_embeddings(hash=592,2793798096738783992).pkl\" \\\n",
    "--use_iuxray_for_train \\\n",
    "--iuxray_image_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/iuxray/image_id_to_pos_neg_facts(hash=450,1832071235913899237).pkl\" \\\n",
    "--cxrlt2024_weight 6.0 \\\n",
    "--mimiccxr_facts_weight 2.5 \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--iuxray_weight 0.5 \\\n",
    "--vinbig_weight 1.5 \\\n",
    "--chexpert_weight 0.5 \\\n",
    "--chexlocalize_weight 0.4 \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1973afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 3\n",
      "   batches_per_epoch: 20\n",
      "   max_images_per_batch: 25\n",
      "   max_phrases_per_batch: 400\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 5.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: siglip-huggingface\n",
      "   huggingface_model_name: google/siglip-base-patch16-224\n",
      "   num_regions: 196\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 14\n",
      "   regions_height: 14\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: film_layers_plus_sigmoid_attention_and_custom_classifier\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: 256\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-08\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-8,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 10\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 2.0\n",
      "   phrase_classifier_loss_weight: 2.0\n",
      "   foreground_loss_weight: 1.5\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: True\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: False\n",
      "   image_size: [224, 224]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: True\n",
      "   mimiccxr_facts_weight: 2.5\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 6.0\n",
      "   vinbig_weight: 1.5\n",
      "   chexlocalize_weight: 0.4\n",
      "   chexpert_weight: 0.5\n",
      "   iuxray_weight: 0.5\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: True\n",
      "   use_cxrlt2024_custom_labels: True\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: True\n",
      "   save: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: small_256x256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: siglip-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-8,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-08 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.5\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 10, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    len(_augmented_mask_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.4\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using segmentation mask aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "len(cxrlt2024_train_dicom_ids) = 258871\n",
      "len(cxrlt2024_dev_dicom_ids) = 39293\n",
      "len(forbidden_train_dicom_ids) = 40220\n",
      "\u001b[1m\u001b[35mPreparing CXR-LT-2024 challenge datasets and dataloaders for training/testing...\u001b[0m\n",
      "Using image size mode: small_256x256\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"train\"]) = 145680\n",
      "len(cxrlt2024_dicom_id_to_pos_neg_facts[\"dev\"]) = 39352\n",
      "Total number of images: 184650\n",
      "\u001b[1mBuilding cxrlt2024 train phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 2, len(indices) = 38366\n",
      "num_phrases = 1, len(indices) = 89231\n",
      "num_phrases = 3, len(indices) = 12488\n",
      "num_phrases = 4, len(indices) = 3658\n",
      "num_phrases = 11, len(indices) = 97\n",
      "num_phrases = 6, len(indices) = 281\n",
      "num_phrases = 5, len(indices) = 937\n",
      "num_phrases = 20, len(indices) = 97\n",
      "num_phrases = 7, len(indices) = 52\n",
      "num_phrases = 16, len(indices) = 48\n",
      "num_phrases = 17, len(indices) = 26\n",
      "num_phrases = 10, len(indices) = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_phrases = 8, len(indices) = 13\n",
      "num_phrases = 12, len(indices) = 2\n",
      "\u001b[1mBuilding cxrlt2024 dev phrase classifier dataloader...\u001b[0m\n",
      "num_phrases = 2, len(indices) = 7030\n",
      "num_phrases = 1, len(indices) = 29823\n",
      "num_phrases = 3, len(indices) = 1393\n",
      "num_phrases = 12, len(indices) = 77\n",
      "num_phrases = 6, len(indices) = 25\n",
      "num_phrases = 8, len(indices) = 34\n",
      "num_phrases = 14, len(indices) = 74\n",
      "num_phrases = 11, len(indices) = 124\n",
      "num_phrases = 16, len(indices) = 53\n",
      "num_phrases = 4, len(indices) = 294\n",
      "num_phrases = 15, len(indices) = 51\n",
      "num_phrases = 10, len(indices) = 77\n",
      "num_phrases = 9, len(indices) = 32\n",
      "num_phrases = 7, len(indices) = 36\n",
      "num_phrases = 13, len(indices) = 92\n",
      "num_phrases = 20, len(indices) = 54\n",
      "num_phrases = 5, len(indices) = 54\n",
      "num_phrases = 18, len(indices) = 7\n",
      "num_phrases = 17, len(indices) = 18\n",
      "num_phrases = 19, len(indices) = 4\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_train_dataloader) = 5821\n",
      "len(mimiccxr_trainer.cxrlt2024_custom_dev_dataloader) = 327\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [6.0]\n",
      "merged_dataset_name = cxrlt2024(GPT4)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_274_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6444.pt', 'checkpoint_189_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6336.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)/checkpoint_274_chss+chss+chuc+ciss+ciou+clss+clcc+clou+cxss+cxss+cxuc+cxuc+iuss+iuss+iuuc+miss+miss+miuc+vbss+vbuc+vbou=0.6444.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/3\u001b[0m\n",
      "(1) Training stage (lr = 0.000000) ...\n",
      "loss 2.08183, cxrlt2024c_att_reg_loss 0.17474, cxrlt2024c_phrcls_loss 1.90709, cxrlt2024c_prc_auc 0.76243, 4.61 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15554, cxrlt2024c_phrcls_loss 1.22307, cxrlt2024c_prc_auc 0.64829, 99.96 secs\n",
      "\u001b[1m---- Epoch 2/3\u001b[0m\n",
      "(1) Training stage (lr = 0.000000) ...\n",
      "loss 1.98859, cxrlt2024c_att_reg_loss 0.16591, cxrlt2024c_phrcls_loss 1.82268, cxrlt2024c_prc_auc 0.83258, 3.77 secs\n",
      "(2) Validation stage ...\n",
      "cxrlt2024c_att_reg_loss 0.15552, cxrlt2024c_phrcls_loss 1.22323, cxrlt2024c_prc_auc 0.64831, 100.57 secs\n",
      "\u001b[1m---- Epoch 3/3\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.07216, cxrlt2024c_att_reg_loss 0.18204, cxrlt2024c_phrcls_loss 1.89012, cxrlt2024c_prc_auc 0.79128, 4.03 secs\n",
      "(2) Validation stage ...\n",
      "^C iteration 300\n",
      "Exception ignored in: <function _releaseLock at 0x7fb35c62ecb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20240830_183246_mim-facts+chst-img-anat+cxrlt2024(Off)+cxrlt2024(GPT4)+vinbig+chexloc+chxp+iuxray_PhraseGrounder(google-siglip-base-p16-224,FiLM_SigmoidAttention,128,256,256,256,1,256-128)\" \\\n",
    "--epochs 3 \\\n",
    "--batches_per_epoch 20 \\\n",
    "--max_images_per_batch 25 \\\n",
    "--max_phrases_per_batch 400 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 5.0 \\\n",
    "--raw_image_encoding \"siglip-huggingface\" \\\n",
    "--huggingface_model_name \"google/siglip-base-patch16-224\" \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--image_size 224 224 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 196 \\\n",
    "--regions_width 14 \\\n",
    "--regions_height 14 \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"film_layers_plus_sigmoid_attention_and_custom_classifier\" \\\n",
    "--visual_feature_proj_size 256 \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 10 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-8 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-8,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_attention_regularization_loss \\\n",
    "--attention_supervision_loss_weight 2.0 \\\n",
    "--phrase_classifier_loss_weight 2.0 \\\n",
    "--foreground_loss_weight 1.5 \\\n",
    "--use_cxrlt2024_challenge_split \\\n",
    "--cxrlt2024_do_balanced_sampling \\\n",
    "--use_cxrlt2024_custom_labels \\\n",
    "--cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxrlt2024_integrated_nli_queries_for_fact_classification.pkl\" \\\n",
    "--mimiccxr_exclude_noisy_images \\\n",
    "--cxrlt2024_weight 6.0 \\\n",
    "--mimiccxr_facts_weight 2.5 \\\n",
    "--chest_imagenome_anatlocs_weight 1.0 \\\n",
    "--iuxray_weight 0.5 \\\n",
    "--vinbig_weight 1.5 \\\n",
    "--chexpert_weight 0.5 \\\n",
    "--chexlocalize_weight 0.4 \\\n",
    "--no_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de452b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58961"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x*y for x,y in [\n",
    "(2, 7030),\n",
    "(1, 29823),\n",
    "(3, 1393),\n",
    "(12,77),\n",
    "(6, 25),\n",
    "(8, 34),\n",
    "(14,74),\n",
    "(11,124),\n",
    "(16,53),\n",
    "(4, 294),\n",
    "(15,51),\n",
    "(10,77),\n",
    "(9, 32),\n",
    "(7, 36),\n",
    "(13,92),\n",
    "(20,54),\n",
    "(5, 54),\n",
    "(18,7),\n",
    "(17,18),\n",
    "(19,4),\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
