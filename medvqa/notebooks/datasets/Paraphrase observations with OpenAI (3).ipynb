{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab94131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 17:44:00,410 - \u001b[1;32mINFO\u001b[1;0m - Loading facts metadata from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\n",
      "100%|███████████████████████████████| 578733/578733 [00:03<00:00, 176059.13it/s]\n",
      "2023-07-12 17:44:09,032 - \u001b[1;32mINFO\u001b[1;0m - Found 771124 unique observations\n",
      "2023-07-12 17:44:11,448 - \u001b[1;32mINFO\u001b[1;0m - Filtering observations to those with at least 2 words\n",
      "2023-07-12 17:44:12,197 - \u001b[1;32mINFO\u001b[1;0m - Found 769122 observations with at least 2 words\n",
      "2023-07-12 17:44:12,197 - \u001b[1;32mINFO\u001b[1;0m - Filtering observations to the 2-th of every 4 sentences\n",
      "2023-07-12 17:44:12,430 - \u001b[1;32mINFO\u001b[1;0m - Found 192280 observations that are the 2-th of every 4 sentences\n",
      "2023-07-12 17:44:12,430 - \u001b[1;32mINFO\u001b[1;0m - Sampling 15000 equally spaced sentences\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to paraphrase: 15000\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to paraphrase:\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 1. CT 2\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 1667. likely a pericardial drain\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 3334. chronic anterior wedge deformity\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 5000. patient received the top of catheter\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 6667. resolved bilateral parenchymal opacities\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 8333. small loculated right effusion has decreased\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 10000. increased opacity projecting over the lower spine\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 11666. similar appearance of bibasilar opacities on the right\n",
      "2023-07-12 17:44:12,439 - \u001b[1;32mINFO\u001b[1;0m - 13333. continuous improvement in opacification of the right lower lobe\n",
      "2023-07-12 17:44:12,440 - \u001b[1;32mINFO\u001b[1;0m - 15000. area of consolidation in the left mid lung at the fourth left anterior rib level is more dense and larger in size than any corresponding opacities in this region on the recent CT scan\n",
      "2023-07-12 17:44:12,491 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230712_174412.jsonl\n",
      "2023-07-12 17:44:12,491 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230712_174412.jsonl\n",
      "2023-07-12 17:44:13,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-12 17:44:13,647 - \u001b[1;32mINFO\u001b[1;0m - Starting request #50\n",
      "2023-07-12 17:44:13,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-12 17:44:15,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #150\n",
      "2023-07-12 17:44:36,246 - \u001b[1;32mINFO\u001b[1;0m - Starting request #200\n",
      "2023-07-12 17:44:44,357 - \u001b[1;33mWARNING\u001b[1;0m - Request 142 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e174ebf77d4e1bebcdeda69a23ffb514 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:44:56,838 - \u001b[1;32mINFO\u001b[1;0m - Starting request #249\n",
      "2023-07-12 17:45:17,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #299\n",
      "2023-07-12 17:45:29,090 - \u001b[1;33mWARNING\u001b[1;0m - Request 252 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a004187ef642202b10dce504f528fba8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:45:38,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #348\n",
      "2023-07-12 17:45:58,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #398\n",
      "2023-07-12 17:46:19,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #448\n",
      "2023-07-12 17:46:26,265 - \u001b[1;33mWARNING\u001b[1;0m - Request 391 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c2ad35b2b4633d5fbac291281a63f99a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:46:39,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #497\n",
      "2023-07-12 17:47:00,522 - \u001b[1;32mINFO\u001b[1;0m - Starting request #547\n",
      "2023-07-12 17:47:21,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #597\n",
      "2023-07-12 17:47:41,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #647\n",
      "2023-07-12 17:48:02,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #697\n",
      "2023-07-12 17:48:15,722 - \u001b[1;33mWARNING\u001b[1;0m - Request 656 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0209b3bc2dbca493caa30ac37193ec93 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:48:23,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #746\n",
      "2023-07-12 17:48:35,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 703 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50e4bc756293a83f451809e67f80aaf5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:48:43,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #795\n",
      "2023-07-12 17:49:04,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #845\n",
      "2023-07-12 17:49:16,877 - \u001b[1;33mWARNING\u001b[1;0m - Request 802 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ce99211c8d1fc5c1cc1f08945ef78f9f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:49:24,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #894\n",
      "2023-07-12 17:49:45,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #944\n",
      "2023-07-12 17:50:01,763 - \u001b[1;33mWARNING\u001b[1;0m - Request 910 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c9be8ab553aa7fad355175cbd7bad5c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:50:06,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #993\n",
      "2023-07-12 17:50:26,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1043\n",
      "2023-07-12 17:50:35,793 - \u001b[1;33mWARNING\u001b[1;0m - Request 990 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 377d420279d0e02da8cff5a3832542ef in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:50:47,496 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1092\n",
      "2023-07-12 17:50:47,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 1020 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae16df8e39e83aa36aabc52b3f0b4331 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:51:08,144 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1141\n",
      "2023-07-12 17:51:28,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1191\n",
      "2023-07-12 17:51:49,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1241\n",
      "2023-07-12 17:52:10,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1291\n",
      "2023-07-12 17:52:11,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 1199 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 26c65f03e2861684dd8f565d2ad216bb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:52:30,771 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 17:52:51,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1390\n",
      "2023-07-12 17:53:12,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1440\n",
      "2023-07-12 17:53:32,760 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1490\n",
      "2023-07-12 17:53:34,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1421 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d61733345aa28e78324cc012e98f2f97 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:53:53,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1539\n",
      "2023-07-12 17:54:14,091 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1589\n",
      "2023-07-12 17:54:34,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1639\n",
      "2023-07-12 17:54:55,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1689\n",
      "2023-07-12 17:55:00,570 - \u001b[1;33mWARNING\u001b[1;0m - Request 1628 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b5ceef7a3563bc9710f1ae7e8e982a47 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:55:16,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1738\n",
      "2023-07-12 17:55:29,791 - \u001b[1;33mWARNING\u001b[1;0m - Request 1699 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a2f21dd968d665ccaab781ceebe3abcb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:55:36,740 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1787\n",
      "2023-07-12 17:55:57,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1837\n",
      "2023-07-12 17:56:18,093 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1887\n",
      "2023-07-12 17:56:38,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1937\n",
      "2023-07-12 17:56:45,141 - \u001b[1;33mWARNING\u001b[1;0m - Request 1879 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f6c286f34ec8c768208ae7b27b66340d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:56:59,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1986\n",
      "2023-07-12 17:57:20,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2036\n",
      "2023-07-12 17:57:40,794 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2086\n",
      "2023-07-12 17:57:51,834 - \u001b[1;33mWARNING\u001b[1;0m - Request 1802 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11108758607fa82baa225b4ee2f2b3df in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:58:01,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2135\n",
      "2023-07-12 17:58:22,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2185\n",
      "2023-07-12 17:58:26,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 2121 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7dd1f567683672cc775ee8523d14d2a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 17:58:42,825 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2234\n",
      "2023-07-12 17:59:03,509 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2284\n",
      "2023-07-12 17:59:24,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2334\n",
      "2023-07-12 17:59:24,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1613 failed with Exception \n",
      "2023-07-12 17:59:44,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2383\n",
      "2023-07-12 18:00:05,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2433\n",
      "2023-07-12 18:00:15,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 2384 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b54b152ff6d43db33d2b63a6387ac99 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:00:20,526 - \u001b[1;33mWARNING\u001b[1;0m - Request 2396 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 59f83d1e4f245e8592a1388d81b66d62 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:00:26,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2481\n",
      "2023-07-12 18:00:46,933 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2531\n",
      "2023-07-12 18:01:07,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2581\n",
      "2023-07-12 18:01:28,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2631\n",
      "2023-07-12 18:01:49,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2681\n",
      "2023-07-12 18:02:00,309 - \u001b[1;33mWARNING\u001b[1;0m - Request 2635 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a8e32d1c3fadd1bcb0b869644a119fa5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:02:01,048 - \u001b[1;33mWARNING\u001b[1;0m - Request 2637 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 28cc7e675e5e5181b603092a251ed10c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:02:09,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2729\n",
      "2023-07-12 18:02:30,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2779\n",
      "2023-07-12 18:02:51,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2829\n",
      "2023-07-12 18:03:11,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2879\n",
      "2023-07-12 18:03:32,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2929\n",
      "2023-07-12 18:03:53,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2979\n",
      "2023-07-12 18:04:13,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3029\n",
      "2023-07-12 18:04:34,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3079\n",
      "2023-07-12 18:04:36,390 - \u001b[1;33mWARNING\u001b[1;0m - Request 3010 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db2c405f05f1ebe954e7095dd777735a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:04:55,331 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3128\n",
      "2023-07-12 18:05:01,958 - \u001b[1;33mWARNING\u001b[1;0m - Request 3072 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ac8f6106f0b4916f97236b20ecfd12f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:05:16,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3177\n",
      "2023-07-12 18:05:35,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 3151 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8984db1555f9c467002e353efb739179 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:05:36,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3226\n",
      "2023-07-12 18:05:53,301 - \u001b[1;33mWARNING\u001b[1;0m - Request 3194 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9c918ba05a4f5b9c7ab54f6b6ff8e6ac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 18:05:57,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3275\n",
      "2023-07-12 18:06:18,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3325\n",
      "2023-07-12 18:06:38,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3375\n",
      "2023-07-12 18:06:59,555 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3425\n",
      "2023-07-12 18:07:20,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3475\n",
      "2023-07-12 18:07:40,981 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3525\n",
      "2023-07-12 18:08:01,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3575\n",
      "2023-07-12 18:08:22,372 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3625\n",
      "2023-07-12 18:08:43,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3675\n",
      "2023-07-12 18:09:03,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3725\n",
      "2023-07-12 18:09:24,544 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3775\n",
      "2023-07-12 18:09:45,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3825\n",
      "2023-07-12 18:10:05,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3875\n",
      "2023-07-12 18:10:26,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3925\n",
      "2023-07-12 18:10:47,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3975\n",
      "2023-07-12 18:11:02,387 - \u001b[1;33mWARNING\u001b[1;0m - Request 3938 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c1d008e7cab93951f0f1b1ace788f19 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:11:08,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4024\n",
      "2023-07-12 18:11:28,845 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4074\n",
      "2023-07-12 18:11:49,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4124\n",
      "2023-07-12 18:12:10,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4174\n",
      "2023-07-12 18:12:31,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4224\n",
      "2023-07-12 18:12:38,970 - \u001b[1;33mWARNING\u001b[1;0m - Request 4170 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e887d44fc76fdd34402e29df52cdd79 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:12:51,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4273\n",
      "2023-07-12 18:13:12,420 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4323\n",
      "2023-07-12 18:13:24,012 - \u001b[1;33mWARNING\u001b[1;0m - Request 4278 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4013f20aaba1cf9735154dbd87aefd4f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:13:33,159 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4372\n",
      "2023-07-12 18:13:53,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4422\n",
      "2023-07-12 18:14:02,669 - \u001b[1;33mWARNING\u001b[1;0m - Request 4370 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 01ca0028b0f353e0941879ac4f01a56d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:14:14,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4471\n",
      "2023-07-12 18:14:35,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4521\n",
      "2023-07-12 18:14:56,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4571\n",
      "2023-07-12 18:15:13,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 4539 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9bd42328236b4e16fb535c83c53b24d8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:15:16,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4620\n",
      "2023-07-12 18:15:26,715 - \u001b[1;33mWARNING\u001b[1;0m - Request 4572 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0496ae15ab3406166326df74e1c63439 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:15:29,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 4578 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ab561d90bb370b205836fdb7a8815625 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:15:37,504 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4668\n",
      "2023-07-12 18:15:58,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4718\n",
      "2023-07-12 18:16:10,733 - \u001b[1;33mWARNING\u001b[1;0m - Request 4675 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b0979e31ffcfe6cf37ea5ead1454bc2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:16:18,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4767\n",
      "2023-07-12 18:16:30,546 - \u001b[1;33mWARNING\u001b[1;0m - Request 4723 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 30b659344d51ffbc0c20f01333b947c2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:16:39,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4816\n",
      "2023-07-12 18:17:00,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4866\n",
      "2023-07-12 18:17:21,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4916\n",
      "2023-07-12 18:17:41,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4966\n",
      "2023-07-12 18:18:02,668 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5016\n",
      "2023-07-12 18:18:23,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5066\n",
      "2023-07-12 18:18:44,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5116\n",
      "2023-07-12 18:19:04,866 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5166\n",
      "2023-07-12 18:19:25,602 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5216\n",
      "2023-07-12 18:19:46,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5266\n",
      "2023-07-12 18:20:07,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5316\n",
      "2023-07-12 18:20:26,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 5289 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae668b4bea88dccac4a576cec333d9bc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:20:27,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5365\n",
      "2023-07-12 18:20:35,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 5311 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c66f1c3a6786ec4dbacbc0a1bcde7e78 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:20:48,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5414\n",
      "2023-07-12 18:21:09,280 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5464\n",
      "2023-07-12 18:21:30,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5514\n",
      "2023-07-12 18:21:50,796 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5564\n",
      "2023-07-12 18:22:11,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5614\n",
      "2023-07-12 18:22:13,151 - \u001b[1;33mWARNING\u001b[1;0m - Request 5545 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 81fcd140c0b9c83d09b3fa9e39cbce35 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:22:32,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5663\n",
      "2023-07-12 18:22:32,682 - \u001b[1;33mWARNING\u001b[1;0m - Request 5592 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2a11b1a829f1f825b682f9921ae58768 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 18:22:38,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 5607 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f067407582c4d2e6a75cd01ba8bc566 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:22:53,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5711\n",
      "2023-07-12 18:23:13,810 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5761\n",
      "2023-07-12 18:23:34,545 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5811\n",
      "2023-07-12 18:23:54,496 - \u001b[1;33mWARNING\u001b[1;0m - Request 5786 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40f600d4a8deafaadfdbb00d2b41cdca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:23:55,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5786\n",
      "2023-07-12 18:24:00,721 - \u001b[1;33mWARNING\u001b[1;0m - Request 5801 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1be5cae590a9c42b5564e6a2217b0ceb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:24:16,020 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5909\n",
      "2023-07-12 18:24:36,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5959\n",
      "2023-07-12 18:24:36,803 - \u001b[1;33mWARNING\u001b[1;0m - Request 5886 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d5646280562b88f4f6ca8c762e3b25f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:24:57,544 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6008\n",
      "2023-07-12 18:25:18,291 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6058\n",
      "2023-07-12 18:25:27,870 - \u001b[1;33mWARNING\u001b[1;0m - Request 6008 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5078208cb5453d6ae0d66dd4d9f2feb1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:25:39,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6107\n",
      "2023-07-12 18:25:59,801 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6157\n",
      "2023-07-12 18:26:20,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6207\n",
      "2023-07-12 18:26:41,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6257\n",
      "2023-07-12 18:27:02,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6307\n",
      "2023-07-12 18:27:22,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6357\n",
      "2023-07-12 18:27:43,588 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6407\n",
      "2023-07-12 18:27:47,740 - \u001b[1;33mWARNING\u001b[1;0m - Request 6344 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3fccb9ef2d6ccd664ccb8e8ae5d7432c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:28:04,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6456\n",
      "2023-07-12 18:28:15,498 - \u001b[1;33mWARNING\u001b[1;0m - Request 6411 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e847e6035daa28474e5bd0f28185c866 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:28:25,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6505\n",
      "2023-07-12 18:28:33,892 - \u001b[1;33mWARNING\u001b[1;0m - Request 6454 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97ba6a5f369a3cfaf1e8f7be38a21c99 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:28:45,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6554\n",
      "2023-07-12 18:29:06,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6604\n",
      "2023-07-12 18:29:27,372 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6654\n",
      "2023-07-12 18:29:48,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6704\n",
      "2023-07-12 18:30:08,904 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6754\n",
      "2023-07-12 18:30:26,691 - \u001b[1;33mWARNING\u001b[1;0m - Request 6724 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5f2b60d09e27cf95b65fe087b07bb2f8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:30:29,684 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6803\n",
      "2023-07-12 18:30:50,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6853\n",
      "2023-07-12 18:31:00,759 - \u001b[1;33mWARNING\u001b[1;0m - Request 6805 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f32b4fe23b4524b34603fdb7e1cacf5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:31:11,232 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6902\n",
      "2023-07-12 18:31:31,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6952\n",
      "2023-07-12 18:31:52,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7002\n",
      "2023-07-12 18:32:13,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7052\n",
      "2023-07-12 18:32:34,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7102\n",
      "2023-07-12 18:32:55,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7152\n",
      "2023-07-12 18:33:15,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7202\n",
      "2023-07-12 18:33:36,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7252\n",
      "2023-07-12 18:33:57,410 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7302\n",
      "2023-07-12 18:34:18,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7352\n",
      "2023-07-12 18:34:38,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7402\n",
      "2023-07-12 18:34:49,748 - \u001b[1;33mWARNING\u001b[1;0m - Request 7355 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e1d6339dcb1e43845f732003b8fe3f90 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:34:51,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 7360 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d331e92f9d75a761fb53417ff98744b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:34:59,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7450\n",
      "2023-07-12 18:35:20,482 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7500\n",
      "2023-07-12 18:35:41,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7550\n",
      "2023-07-12 18:36:02,059 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7600\n",
      "2023-07-12 18:36:04,930 - \u001b[1;33mWARNING\u001b[1;0m - Request 7534 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 526aa0dc29a285ac860901a60ef297ab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:36:22,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7649\n",
      "2023-07-12 18:36:43,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7699\n",
      "2023-07-12 18:36:44,438 - \u001b[1;33mWARNING\u001b[1;0m - Request 7628 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bf93daf5fec877cd47f17f725d08d8d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 18:37:04,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7748\n",
      "2023-07-12 18:37:09,376 - \u001b[1;33mWARNING\u001b[1;0m - Request 7688 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fa1b074b287cee11c760ed1bea20cb36 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:37:25,188 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7797\n",
      "2023-07-12 18:37:45,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7847\n",
      "2023-07-12 18:38:06,733 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7897\n",
      "2023-07-12 18:38:27,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7947\n",
      "2023-07-12 18:38:48,333 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7997\n",
      "2023-07-12 18:39:09,132 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8047\n",
      "2023-07-12 18:39:29,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8097\n",
      "2023-07-12 18:39:50,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8147\n",
      "2023-07-12 18:40:11,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8197\n",
      "2023-07-12 18:40:32,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8247\n",
      "2023-07-12 18:40:37,179 - \u001b[1;33mWARNING\u001b[1;0m - Request 8186 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dfcfa1395b18fca825367958efc507cd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:40:53,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8296\n",
      "2023-07-12 18:40:56,780 - \u001b[1;33mWARNING\u001b[1;0m - Request 8233 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f0d5c6eebaaf342b860bcc9712e01e0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:41:13,832 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8345\n",
      "2023-07-12 18:41:34,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8395\n",
      "2023-07-12 18:41:43,241 - \u001b[1;33mWARNING\u001b[1;0m - Request 8343 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 06d589e96dd9fafb709df9513ba20e26 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:41:55,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8444\n",
      "2023-07-12 18:42:16,258 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8494\n",
      "2023-07-12 18:42:37,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8544\n",
      "2023-07-12 18:42:41,588 - \u001b[1;33mWARNING\u001b[1;0m - Request 8482 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9fd6cb97499ca6336353a047b7f3bf53 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:42:57,853 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8593\n",
      "2023-07-12 18:43:18,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8643\n",
      "2023-07-12 18:43:39,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8693\n",
      "2023-07-12 18:44:00,218 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8743\n",
      "2023-07-12 18:44:21,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8793\n",
      "2023-07-12 18:44:41,839 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8843\n",
      "2023-07-12 18:45:02,667 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8893\n",
      "2023-07-12 18:45:23,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8943\n",
      "2023-07-12 18:45:44,262 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8993\n",
      "2023-07-12 18:46:05,054 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9043\n",
      "2023-07-12 18:46:23,338 - \u001b[1;33mWARNING\u001b[1;0m - Request 9014 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b48406017a9b499512d9ea56a315193 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:46:25,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9092\n",
      "2023-07-12 18:46:42,450 - \u001b[1;33mWARNING\u001b[1;0m - Request 9060 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f397cd0c9809eb0fccb5c414208bc064 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:46:43,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 9063 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1fe99c3dabb98f5c6b77eb8f686bb0fd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:46:46,666 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9140\n",
      "2023-07-12 18:47:07,484 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9190\n",
      "2023-07-12 18:47:28,294 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9240\n",
      "2023-07-12 18:47:49,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9290\n",
      "2023-07-12 18:48:09,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9340\n",
      "2023-07-12 18:48:30,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9390\n",
      "2023-07-12 18:48:43,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 9347 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76f225ae12b12fab7021aaf19f88acb7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:48:51,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9439\n",
      "2023-07-12 18:49:12,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9489\n",
      "2023-07-12 18:49:13,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 9419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db4764bcf5510ff8b3a7be845f162812 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:49:24,250 - \u001b[1;33mWARNING\u001b[1;0m - Request 9445 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b0ec6470734f8036f3ca893eeae6588 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:49:33,167 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9537\n",
      "2023-07-12 18:49:53,987 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9587\n",
      "2023-07-12 18:50:14,818 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9637\n",
      "2023-07-12 18:50:35,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9687\n",
      "2023-07-12 18:50:56,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9737\n",
      "2023-07-12 18:51:05,463 - \u001b[1;33mWARNING\u001b[1;0m - Request 9686 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d5cbcda38c2101924f3d429b8b235d4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:51:17,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9786\n",
      "2023-07-12 18:51:38,044 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9836\n",
      "2023-07-12 18:51:43,306 - \u001b[1;33mWARNING\u001b[1;0m - Request 9776 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 418099408fa1c7959a86744e2fabf456 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:51:58,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9885\n",
      "2023-07-12 18:52:19,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 18:52:40,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9985\n",
      "2023-07-12 18:53:01,347 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10035\n",
      "2023-07-12 18:53:22,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10085\n",
      "2023-07-12 18:53:42,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10135\n",
      "2023-07-12 18:53:46,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 10071 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f03eb2efae2d274c2c3b4e429d0d0ab4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:54:03,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10184\n",
      "2023-07-12 18:54:09,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 10127 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID df3a0aba23b3d51dce6131501b99138d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:54:24,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10233\n",
      "2023-07-12 18:54:45,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10283\n",
      "2023-07-12 18:55:00,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9601 failed with Exception \n",
      "2023-07-12 18:55:06,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10332\n",
      "2023-07-12 18:55:27,117 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10382\n",
      "2023-07-12 18:55:47,940 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10432\n",
      "2023-07-12 18:56:08,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10482\n",
      "2023-07-12 18:56:29,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10532\n",
      "2023-07-12 18:56:50,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10582\n",
      "2023-07-12 18:57:08,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9906 failed with Exception \n",
      "2023-07-12 18:57:11,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10631\n",
      "2023-07-12 18:57:32,119 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10681\n",
      "2023-07-12 18:57:38,980 - \u001b[1;33mWARNING\u001b[1;0m - Request 10626 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 742c8f64f6eae44fd404baca981893a3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 18:57:52,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10730\n",
      "2023-07-12 18:58:13,748 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10780\n",
      "2023-07-12 18:58:23,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10088 failed with Exception \n",
      "2023-07-12 18:58:34,574 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10829\n",
      "2023-07-12 18:58:55,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10879\n",
      "2023-07-12 18:59:16,283 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10929\n",
      "2023-07-12 18:59:37,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10979\n",
      "2023-07-12 18:59:57,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11029\n",
      "2023-07-12 19:00:18,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11079\n",
      "2023-07-12 19:00:27,020 - \u001b[1;33mWARNING\u001b[1;0m - Request 11026 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3684ee0c27592ae52c5c2433ecce057 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:00:39,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11128\n",
      "2023-07-12 19:01:00,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11178\n",
      "2023-07-12 19:01:21,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11228\n",
      "2023-07-12 19:01:42,227 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11278\n",
      "2023-07-12 19:01:56,542 - \u001b[1;33mWARNING\u001b[1;0m - Request 10875 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 778c22944e5f13338f1bcce921140606 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:01:58,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 11244 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9223bef88cabfbd54b5728c30c53c507 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:02:03,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11326\n",
      "2023-07-12 19:02:23,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11376\n",
      "2023-07-12 19:02:44,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11426\n",
      "2023-07-12 19:03:05,645 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11476\n",
      "2023-07-12 19:03:26,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11526\n",
      "2023-07-12 19:03:36,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10833 failed with Exception \n",
      "2023-07-12 19:03:47,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11575\n",
      "2023-07-12 19:04:05,142 - \u001b[1;33mWARNING\u001b[1;0m - Request 11546 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 153646f8ceed3992d7fddfb82a02fb20 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:04:08,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11624\n",
      "2023-07-12 19:04:13,897 - \u001b[1;33mWARNING\u001b[1;0m - Request 11566 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 929e70dcdbe21a07e70f8ed2260dbb89 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:04:20,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 10937 failed with Exception \n",
      "2023-07-12 19:04:29,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11672\n",
      "2023-07-12 19:04:40,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10985 failed with Exception \n",
      "2023-07-12 19:04:43,012 - \u001b[1;33mWARNING\u001b[1;0m - Request 11635 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3d8cc72c67a78ddc6d35b02f8b1ac9fb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:04:49,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11720\n",
      "2023-07-12 19:05:10,822 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11770\n",
      "2023-07-12 19:05:31,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11820\n",
      "2023-07-12 19:05:52,532 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11870\n",
      "2023-07-12 19:06:13,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11920\n",
      "2023-07-12 19:06:34,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11970\n",
      "2023-07-12 19:06:55,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12020\n",
      "2023-07-12 19:07:15,992 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12070\n",
      "2023-07-12 19:07:36,855 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12120\n",
      "2023-07-12 19:07:57,722 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12170\n",
      "2023-07-12 19:08:18,613 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12220\n",
      "2023-07-12 19:08:39,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12270\n",
      "2023-07-12 19:09:00,364 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12320\n",
      "2023-07-12 19:09:10,203 - \u001b[1;33mWARNING\u001b[1;0m - Request 12271 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 37fb7116f9088512998e4f2c20c0962d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:09:21,239 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12369\n",
      "2023-07-12 19:09:41,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 12345 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d34e464faf450224d9e618887b4ec31 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 19:09:42,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12345\n",
      "2023-07-12 19:10:03,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12468\n",
      "2023-07-12 19:10:23,920 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12518\n",
      "2023-07-12 19:10:38,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 12481 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f3e702015b30a76f68ee8640bc9705c0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:10:44,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12567\n",
      "2023-07-12 19:11:05,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12617\n",
      "2023-07-12 19:11:26,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12667\n",
      "2023-07-12 19:11:40,060 - \u001b[1;33mWARNING\u001b[1;0m - Request 12627 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56a4a8900321d391e5f6b581c4cd381b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:11:47,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12716\n",
      "2023-07-12 19:12:00,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 12677 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9977ae2125c8a238443c9897703a3ab6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:12:08,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12765\n",
      "2023-07-12 19:12:29,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12815\n",
      "2023-07-12 19:12:50,156 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12865\n",
      "2023-07-12 19:12:53,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 12800 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6844fbc967cdb78e7410787d4dc50a68 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:13:11,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12914\n",
      "2023-07-12 19:13:31,937 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12964\n",
      "2023-07-12 19:13:40,207 - \u001b[1;33mWARNING\u001b[1;0m - Request 12911 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d1b3123f5fb4893dd7620bd3743fa1c7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:13:52,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13013\n",
      "2023-07-12 19:14:13,757 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13063\n",
      "2023-07-12 19:14:34,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13113\n",
      "2023-07-12 19:14:55,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13163\n",
      "2023-07-12 19:15:16,486 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13213\n",
      "2023-07-12 19:15:37,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13263\n",
      "2023-07-12 19:15:39,190 - \u001b[1;33mWARNING\u001b[1;0m - Request 13195 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e151efadd16b6544062f2447329a306f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:15:57,576 - \u001b[1;33mWARNING\u001b[1;0m - Request 13239 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f2b985a13e854350a9c6fe6cee173a2d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:15:58,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13239\n",
      "2023-07-12 19:16:19,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13361\n",
      "2023-07-12 19:16:40,111 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13411\n",
      "2023-07-12 19:17:01,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13461\n",
      "2023-07-12 19:17:21,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13511\n",
      "2023-07-12 19:17:42,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13561\n",
      "2023-07-12 19:18:03,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13611\n",
      "2023-07-12 19:18:24,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13661\n",
      "2023-07-12 19:18:39,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 12982 failed with Exception \n",
      "2023-07-12 19:18:45,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13710\n",
      "2023-07-12 19:19:06,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13760\n",
      "2023-07-12 19:19:27,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13810\n",
      "2023-07-12 19:19:48,521 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13860\n",
      "2023-07-12 19:19:59,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 13172 failed with Exception \n",
      "2023-07-12 19:20:09,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13909\n",
      "2023-07-12 19:20:30,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13959\n",
      "2023-07-12 19:20:51,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14009\n",
      "2023-07-12 19:21:12,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14059\n",
      "2023-07-12 19:21:33,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14109\n",
      "2023-07-12 19:21:54,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14159\n",
      "2023-07-12 19:22:15,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14209\n",
      "2023-07-12 19:22:36,210 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14259\n",
      "2023-07-12 19:22:57,184 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14309\n",
      "2023-07-12 19:23:18,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14359\n",
      "2023-07-12 19:23:39,160 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14409\n",
      "2023-07-12 19:24:00,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14459\n",
      "2023-07-12 19:24:21,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14509\n",
      "2023-07-12 19:24:42,176 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14559\n",
      "2023-07-12 19:25:03,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14609\n",
      "2023-07-12 19:25:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 13901 failed with Exception \n",
      "2023-07-12 19:25:09,027 - \u001b[1;33mWARNING\u001b[1;0m - Request 14551 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d8201cc3b7bc0e74edb92f2067a2df74 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:25:24,200 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14657\n",
      "2023-07-12 19:25:45,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14707\n",
      "2023-07-12 19:26:06,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14757\n",
      "2023-07-12 19:26:27,329 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14807\n",
      "2023-07-12 19:26:48,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14857\n",
      "2023-07-12 19:27:09,526 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14907\n",
      "2023-07-12 19:27:30,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14957\n",
      "2023-07-12 19:27:53,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 14940 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f368346dce44961f8e94b8b5ccfe44a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-12 19:28:16,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 14354 failed with Exception \n",
      "2023-07-12 19:28:20,165 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230712_174412.jsonl\n",
      "2023-07-12 19:28:20,169 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230712_174412.jsonl\n",
      "2023-07-12 19:28:20,552 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"right PIC.\" Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,552 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...r request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 281, \"completion_tokens\": 28, \"total_tokens\": 309}}, {\"observation\": \"right PIC\"}] for sentence \"right PIC\": Could not parse output: I'm sorry, but I'm not sure what you mean by \"right PIC.\" Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,552 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need a complete sentence describing a fact from a chest X-ray report in order to provide the paraphrases. Could you please provide a full sentence?\n",
      "2023-07-12 19:28:20,552 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...tence?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 35, \"total_tokens\": 317}}, {\"observation\": \"slightly more\"}] for sentence \"slightly more\": Could not parse output: I'm sorry, but I need a complete sentence describing a fact from a chest X-ray report in order to provide the paraphrases. Could you please provide a full sentence?\n",
      "2023-07-12 19:28:20,552 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"CT 2\". Could you please provide more information or clarify your request?\n",
      "2023-07-12 19:28:20,553 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...y your request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 29, \"total_tokens\": 311}}, {\"observation\": \"CT 2\"}] for sentence \"CT 2\": Could not parse output: I'm sorry, but I'm not sure what you mean by \"CT 2\". Could you please provide more information or clarify your request?\n",
      "2023-07-12 19:28:20,556 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"line is removed\". Could you please provide more information or clarify your request?\n",
      "2023-07-12 19:28:20,556 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...est?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 29, \"total_tokens\": 311}}, {\"observation\": \"line is removed\"}] for sentence \"line is removed\": Could not parse output: I'm sorry, but I'm not sure what you mean by \"line is removed\". Could you please provide more information or clarify your request?\n",
      "2023-07-12 19:28:20,556 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information to generate the paraphrases. Could you please provide the specific fact from the chest X-ray report that you would like me to paraphrase?\n",
      "2023-07-12 19:28:20,556 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...ase?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 281, \"completion_tokens\": 37, \"total_tokens\": 318}}, {\"observation\": \"patient history\"}] for sentence \"patient history\": Could not parse output: I'm sorry, but I need more information to generate the paraphrases. Could you please provide the specific fact from the chest X-ray report that you would like me to paraphrase?\n",
      "2023-07-12 19:28:20,558 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can only provide paraphrases for the given sentence describing a fact from a chest X-ray report. If you have a specific sentence or fact you would like me to paraphrase, please provide it and I'll be happy to assist you.\n",
      "2023-07-12 19:28:20,558 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...ou.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 281, \"completion_tokens\": 53, \"total_tokens\": 334}}, {\"observation\": \"outside material\"}] for sentence \"outside material\": Could not parse output: I'm sorry, but I can only provide paraphrases for the given sentence describing a fact from a chest X-ray report. If you have a specific sentence or fact you would like me to paraphrase, please provide it and I'll be happy to assist you.\n",
      "2023-07-12 19:28:20,559 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need a specific sentence describing a fact from a chest X-ray report in order to provide the paraphrases. Could you please provide a sentence?\n",
      "2023-07-12 19:28:20,559 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...e?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 281, \"completion_tokens\": 34, \"total_tokens\": 315}}, {\"observation\": \"different patient\"}] for sentence \"different patient\": Could not parse output: I'm sorry, but I need a specific sentence describing a fact from a chest X-ray report in order to provide the paraphrases. Could you please provide a sentence?\n",
      "2023-07-12 19:28:20,560 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...]\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 220, \"total_tokens\": 502}}, {\"observation\": \"similar to before\"}] for sentence \"similar to before\": Could not parse output: benign calcification\n",
      "[\n",
      "\"non-malignant calcification\",\n",
      "\"non-cancerous calcification\",\n",
      "\"harmless calcification\",\n",
      "\"innocuous calcification\",\n",
      "\"benign calcified lesion\",\n",
      "\"non-threatening calcification\",\n",
      "\"not indicative of cancer calcification\",\n",
      "\"safe calcification\",\n",
      "\"non-dangerous calcification\",\n",
      "\"non-metastatic calcification\"\n",
      "]\n",
      "\n",
      "osteoporosis\n",
      "[\n",
      "\"decreased bone density\",\n",
      "\"brittle bones\",\n",
      "\"low bone mass\",\n",
      "\"thinning of the bones\",\n",
      "\"weakening of the bones\",\n",
      "\"porous bones\",\n",
      "\"fragile bones\",\n",
      "\"reduced bone strength\",\n",
      "\"loss of bone density\",\n",
      "\"degenerative bone disease\"\n",
      "]\n",
      "\n",
      "no osteoporosis\n",
      "[\n",
      "\"normal bone density\",\n",
      "\"healthy bones\",\n",
      "\"adequate bone mass\",\n",
      "\"strong bones\",\n",
      "\"normal bone strength\",\n",
      "\"no signs of osteoporosis\",\n",
      "\"absence of osteoporosis\",\n",
      "\"no evidence of bone thinning\",\n",
      "\"no indication of bone weakening\",\n",
      "\"no osteoporotic changes\",\n",
      "\"no degenerative bone disease\"\n",
      "]\n",
      "2023-07-12 19:28:20,561 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: Sure! Here is a more expanded list of paraphrases for the given examples:\n",
      "\n",
      "1. Benign Calcification:\n",
      "- Non-cancerous calcification\n",
      "- Harmless calcification\n",
      "- Innocuous calcification\n",
      "- Benign calcified lesion\n",
      "- Non-malignant calcification\n",
      "- Non-threatening calcification\n",
      "- Not indicative of cancer calcification\n",
      "- Safe calcification\n",
      "- Non-dangerous calcification\n",
      "- Non-metastatic calcification\n",
      "- Non-neoplastic calcification\n",
      "\n",
      "2. Osteoporosis:\n",
      "- Decreased bone density\n",
      "- Brittle bones\n",
      "- Low bone mass\n",
      "- Thinning of the bones\n",
      "- Weakening of the bones\n",
      "- Porous bones\n",
      "- Fragile bones\n",
      "- Reduced bone strength\n",
      "- Loss of bone density\n",
      "- Degenerative bone disease\n",
      "- Bone demineralization\n",
      "\n",
      "3. No Osteoporosis:\n",
      "- Normal bone density\n",
      "- Healthy bones\n",
      "- Adequate bone mass\n",
      "- Strong bones\n",
      "- Normal bone strength\n",
      "- No signs of osteoporosis\n",
      "- Absence of osteoporosis\n",
      "- No evidence of bone thinning\n",
      "- No indication of bone weakening\n",
      "- No osteoporotic changes\n",
      "- No degenerative bone disease\n",
      "\n",
      "Please note that these are just a few examples, and there can be many more variations and synonyms for each term.\n",
      "2023-07-12 19:28:20,562 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 281, \"completion_tokens\": 272, \"total_tokens\": 553}}, {\"observation\": \"complete expansion\"}] for sentence \"complete expansion\": Could not parse output: Sure! Here is a more expanded list of paraphrases for the given examples:\n",
      "\n",
      "1. Benign Calcification:\n",
      "- Non-cancerous calcification\n",
      "- Harmless calcification\n",
      "- Innocuous calcification\n",
      "- Benign calcified lesion\n",
      "- Non-malignant calcification\n",
      "- Non-threatening calcification\n",
      "- Not indicative of cancer calcification\n",
      "- Safe calcification\n",
      "- Non-dangerous calcification\n",
      "- Non-metastatic calcification\n",
      "- Non-neoplastic calcification\n",
      "\n",
      "2. Osteoporosis:\n",
      "- Decreased bone density\n",
      "- Brittle bones\n",
      "- Low bone mass\n",
      "- Thinning of the bones\n",
      "- Weakening of the bones\n",
      "- Porous bones\n",
      "- Fragile bones\n",
      "- Reduced bone strength\n",
      "- Loss of bone density\n",
      "- Degenerative bone disease\n",
      "- Bone demineralization\n",
      "\n",
      "3. No Osteoporosis:\n",
      "- Normal bone density\n",
      "- Healthy bones\n",
      "- Adequate bone mass\n",
      "- Strong bones\n",
      "- Normal bone strength\n",
      "- No signs of osteoporosis\n",
      "- Absence of osteoporosis\n",
      "- No evidence of bone thinning\n",
      "- No indication of bone weakening\n",
      "- No osteoporotic changes\n",
      "- No degenerative bone disease\n",
      "\n",
      "Please note that these are just a few examples, and there can be many more variations and synonyms for each term.\n",
      "2023-07-12 19:28:20,563 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"comparison to 00:46\". Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,563 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 285, \"completion_tokens\": 32, \"total_tokens\": 317}}, {\"observation\": \"comparison to 00:46\"}] for sentence \"comparison to 00:46\": Could not parse output: I'm sorry, but I don't understand what you mean by \"comparison to 00:46\". Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,564 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"comparison to 11:51\". Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,564 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 285, \"completion_tokens\": 32, \"total_tokens\": 317}}, {\"observation\": \"comparison to 11:51\"}] for sentence \"comparison to 11:51\": Could not parse output: I'm sorry, but I don't understand what you mean by \"comparison to 11:51\". Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,564 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I don't understand what you mean by \"comparison with :44\". Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,564 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 283, \"completion_tokens\": 30, \"total_tokens\": 313}}, {\"observation\": \"comparison with :44\"}] for sentence \"comparison with :44\": Could not parse output: I'm sorry, but I don't understand what you mean by \"comparison with :44\". Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,564 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"in similar position.\" Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,564 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 29, \"total_tokens\": 311}}, {\"observation\": \"in similar position\"}] for sentence \"in similar position\": Could not parse output: I'm sorry, but I'm not sure what you mean by \"in similar position.\" Could you please provide more context or clarify your request?\n",
      "2023-07-12 19:28:20,570 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS..., \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 283, \"completion_tokens\": 66, \"total_tokens\": 349}}, {\"observation\": \"document re-expansion\"}] for sentence \"document re-expansion\": Could not parse output: The task is to generate a diverse set of paraphrases for a given sentence describing a fact from a chest X-ray report. The paraphrases should cover a wide range of terminology, synonyms, and abbreviations commonly used by radiologists to express the same idea. The output should be in the form of a JSON array of strings.\n",
      "2023-07-12 19:28:20,571 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm unable to assist with your request as the input sentence is missing. Could you please provide the sentence describing the fact from a chest X-ray report?\n",
      "2023-07-12 19:28:20,571 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS..., \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 283, \"completion_tokens\": 36, \"total_tokens\": 319}}, {\"observation\": \"line has been removed\"}] for sentence \"line has been removed\": Could not parse output: I'm sorry, but I'm unable to assist with your request as the input sentence is missing. Could you please provide the sentence describing the fact from a chest X-ray report?\n",
      "2023-07-12 19:28:20,573 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...\"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 280, \"total_tokens\": 562}}, {\"observation\": \"changes more extensive\"}] for sentence \"changes more extensive\": Could not parse output: I apologize for the confusion. Here are some additional paraphrases for the given examples:\n",
      "\n",
      "For \"benign calcification\":\n",
      "- \"non-malignant calcified area\"\n",
      "- \"harmless calcified spot\"\n",
      "- \"innocuous calcified region\"\n",
      "- \"benign calcified deposit\"\n",
      "- \"non-cancerous calcified mass\"\n",
      "- \"not indicative of malignancy calcification\"\n",
      "- \"safe calcified lesion\"\n",
      "- \"non-threatening calcified area\"\n",
      "- \"non-metastatic calcified spot\"\n",
      "\n",
      "For \"osteoporosis\":\n",
      "- \"decreased bone density condition\"\n",
      "- \"brittle bones disease\"\n",
      "- \"low bone mass syndrome\"\n",
      "- \"thinning of the bones disorder\"\n",
      "- \"weakening of the bones condition\"\n",
      "- \"porous bones condition\"\n",
      "- \"fragile bones syndrome\"\n",
      "- \"reduced bone strength disorder\"\n",
      "- \"loss of bone density condition\"\n",
      "- \"degenerative bone disease characterized by decreased bone density\"\n",
      "\n",
      "For \"no osteoporosis\":\n",
      "- \"normal bone density condition\"\n",
      "- \"healthy bones without osteoporosis\"\n",
      "- \"adequate bone mass without signs of osteoporosis\"\n",
      "- \"strong bones with no indication of osteoporosis\"\n",
      "- \"normal bone strength without osteoporotic changes\"\n",
      "- \"no evidence of bone thinning or weakening\"\n",
      "- \"absence of degenerative bone disease like osteoporosis\"\n",
      "2023-07-12 19:28:20,584 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information to provide a response. Could you please provide the specific fact from the chest X-ray report that you would like me to paraphrase?\n",
      "2023-07-12 19:28:20,585 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 284, \"completion_tokens\": 36, \"total_tokens\": 320}}, {\"observation\": \"radiographs under clip #\"}] for sentence \"radiographs under clip #\": Could not parse output: I'm sorry, but I need more information to provide a response. Could you please provide the specific fact from the chest X-ray report that you would like me to paraphrase?\n",
      "2023-07-12 19:28:20,598 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...sh_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 282, \"completion_tokens\": 245, \"total_tokens\": 527}}, {\"observation\": \"better inspirational effort\"}] for sentence \"better inspirational effort\": Could not parse output: I apologize for the previous response. Here are some alternative paraphrases for the given examples:\n",
      "\n",
      "1. Benign calcification:\n",
      "- Non-cancerous calcification\n",
      "- Harmless calcification\n",
      "- Innocuous calcification\n",
      "- Benign calcified lesion\n",
      "- Non-malignant calcification\n",
      "- Non-threatening calcification\n",
      "- Not indicative of cancer calcification\n",
      "- Safe calcification\n",
      "- Non-dangerous calcification\n",
      "- Non-metastatic calcification\n",
      "\n",
      "2. Osteoporosis:\n",
      "- Decreased bone density\n",
      "- Brittle bones\n",
      "- Low bone mass\n",
      "- Thinning of the bones\n",
      "- Weakening of the bones\n",
      "- Porous bones\n",
      "- Fragile bones\n",
      "- Reduced bone strength\n",
      "- Loss of bone density\n",
      "- Degenerative bone disease\n",
      "\n",
      "3. No osteoporosis:\n",
      "- Normal bone density\n",
      "- Healthy bones\n",
      "- Adequate bone mass\n",
      "- Strong bones\n",
      "- Normal bone strength\n",
      "- No signs of osteoporosis\n",
      "- Absence of osteoporosis\n",
      "- No evidence of bone thinning\n",
      "- No indication of bone weakening\n",
      "- No osteoporotic changes\n",
      "- No degenerative bone disease\n",
      "\n",
      "I hope these paraphrases better meet your expectations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 19:28:20,609 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can't assist with that request.\n",
      "2023-07-12 19:28:20,610 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...sh_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 285, \"completion_tokens\": 13, \"total_tokens\": 298}}, {\"observation\": \"selected images of a neck CT\"}] for sentence \"selected images of a neck CT\": Could not parse output: I'm sorry, but I can't assist with that request.\n",
      "2023-07-12 19:28:20,620 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information in order to provide a complete assessment of the findings. Could you please provide the specific fact from the chest X-ray report that you would like me to paraphrase?\n",
      "2023-07-12 19:28:20,620 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS..._reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 283, \"completion_tokens\": 42, \"total_tokens\": 325}}, {\"observation\": \"complete assessment of finding\"}] for sentence \"complete assessment of finding\": Could not parse output: I'm sorry, but I need more information in order to provide a complete assessment of the findings. Could you please provide the specific fact from the chest X-ray report that you would like me to paraphrase?\n",
      "2023-07-12 19:28:20,640 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information to provide a response. Could you please provide the specific finding from the chest X-ray report?\n",
      "2023-07-12 19:28:20,640 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...eason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 285, \"completion_tokens\": 28, \"total_tokens\": 313}}, {\"observation\": \"finding #2 reported by telephone\"}] for sentence \"finding #2 reported by telephone\": Could not parse output: I'm sorry, but I need more information to provide a response. Could you please provide the specific finding from the chest X-ray report?\n",
      "2023-07-12 19:28:20,658 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can only generate paraphrases for chest X-ray reports. If you have a chest X-ray report, please provide the sentence describing a fact from it and I'll be happy to help you paraphrase it.\n",
      "2023-07-12 19:28:20,658 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...son\": \"stop\"}], \"usage\": {\"prompt_tokens\": 287, \"completion_tokens\": 47, \"total_tokens\": 334}}, {\"observation\": \"chest CT report from 1 day earlier\"}] for sentence \"chest CT report from 1 day earlier\": Could not parse output: I'm sorry, but I can only generate paraphrases for chest X-ray reports. If you have a chest X-ray report, please provide the sentence describing a fact from it and I'll be happy to help you paraphrase it.\n",
      "2023-07-12 19:28:20,675 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...on\": \"stop\"}], \"usage\": {\"prompt_tokens\": 287, \"completion_tokens\": 86, \"total_tokens\": 373}}, {\"observation\": \"pulmonary edema developed between [\"}] for sentence \"pulmonary edema developed between [\": Could not parse output: \"fluid accumulation in the lungs\",\n",
      "\"fluid in the lungs\",\n",
      "\"excess fluid in the pulmonary system\",\n",
      "\"pulmonary congestion\",\n",
      "\"fluid overload in the lungs\",\n",
      "\"pulmonary fluid buildup\",\n",
      "\"accumulation of fluid in the pulmonary parenchyma\",\n",
      "\"pulmonary interstitial edema\",\n",
      "\"fluid infiltration in the lungs\",\n",
      "\"pulmonary edematous changes\",\n",
      "\"fluid-filled lungs\"\n",
      "]\n",
      "2023-07-12 19:28:20,703 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS... \"stop\"}], \"usage\": {\"prompt_tokens\": 285, \"completion_tokens\": 240, \"total_tokens\": 525}}, {\"observation\": \"emphasis on inspiration may be helpful\"}] for sentence \"emphasis on inspiration may be helpful\": Could not parse output: benign calcification\n",
      "[\n",
      "\"non-cancerous calcification\",\n",
      "\"harmless calcification\",\n",
      "\"innocuous calcification\",\n",
      "\"benign calcified lesion\",\n",
      "\"non-malignant calcification\",\n",
      "\"non-threatening calcification\",\n",
      "\"not indicative of cancer calcification\",\n",
      "\"safe calcification\",\n",
      "\"non-dangerous calcification\",\n",
      "\"non-metastatic calcification\",\n",
      "\"calcification without malignancy\"\n",
      "]\n",
      "\n",
      "osteoporosis\n",
      "[\n",
      "\"decreased bone density\",\n",
      "\"brittle bones\",\n",
      "\"low bone mass\",\n",
      "\"thinning of the bones\",\n",
      "\"weakening of the bones\",\n",
      "\"porous bones\",\n",
      "\"fragile bones\",\n",
      "\"reduced bone strength\",\n",
      "\"loss of bone density\",\n",
      "\"degenerative bone disease\",\n",
      "\"demineralization of bones\"\n",
      "]\n",
      "\n",
      "no osteoporosis\n",
      "[\n",
      "\"normal bone density\",\n",
      "\"healthy bones\",\n",
      "\"adequate bone mass\",\n",
      "\"strong bones\",\n",
      "\"normal bone strength\",\n",
      "\"no signs of osteoporosis\",\n",
      "\"absence of osteoporosis\",\n",
      "\"no evidence of bone thinning\",\n",
      "\"no indication of bone weakening\",\n",
      "\"no osteoporotic changes\",\n",
      "\"no degenerative bone disease\",\n",
      "\"intact bone density\"\n",
      "]\n",
      "2023-07-12 19:28:20,751 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I cannot access or compare specific chest radiographs as I am a language model AI and do not have access to external data. However, I can help you with any questions or provide information related to chest X-ray reports.\n",
      "2023-07-12 19:28:20,751 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...top\"}], \"usage\": {\"prompt_tokens\": 289, \"completion_tokens\": 49, \"total_tokens\": 338}}, {\"observation\": \"comparison with chest radiographs at 16:37\"}] for sentence \"comparison with chest radiographs at 16:37\": Could not parse output: I'm sorry, but I cannot access or compare specific chest radiographs as I am a language model AI and do not have access to external data. However, I can help you with any questions or provide information related to chest X-ray reports.\n",
      "2023-07-12 19:28:20,752 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...top\"}], \"usage\": {\"prompt_tokens\": 290, \"completion_tokens\": 18, \"total_tokens\": 308}}, {\"observation\": \"findings reported by telephone at 11:57 AM\"}] for sentence \"findings reported by telephone at 11:57 AM\": Could not parse output: {\n",
      "  \"findings\": \"reported by telephone at 11:57 AM\"\n",
      "}\n",
      "2023-07-12 19:28:20,779 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I need more information to generate the paraphrases. Could you please provide the sentence describing the fact from the chest X-ray report?\n",
      "2023-07-12 19:28:20,779 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...p\"}], \"usage\": {\"prompt_tokens\": 287, \"completion_tokens\": 31, \"total_tokens\": 318}}, {\"observation\": \"dictated report assigned to this clip number\"}] for sentence \"dictated report assigned to this clip number\": Could not parse output: I'm sorry, but I need more information to generate the paraphrases. Could you please provide the sentence describing the fact from the chest X-ray report?\n",
      "2023-07-12 19:28:20,812 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a sentence describing a fact from a chest X-ray report, output a JS...], \"usage\": {\"prompt_tokens\": 285, \"completion_tokens\": 300, \"total_tokens\": 585}}, {\"observation\": \"recommend repeat with more optimized technique\"}] for sentence \"recommend repeat with more optimized technique\": Could not parse output: Sure! Here's an optimized technique to generate a diverse range of paraphrases for the given fact from a chest X-ray report:\n",
      "\n",
      "1. Create a dictionary of synonyms, abbreviations, and alternative terms for the key medical terms used in the fact. For example, for \"benign calcification,\" you can include synonyms like \"non-cancerous calcification,\" \"harmless calcification,\" and abbreviations like \"benign calcified lesion.\"\n",
      "\n",
      "2. Iterate through each term in the dictionary and generate paraphrases by combining it with other terms in the dictionary. This will help create variations in the phrasing and terminology used. For example, combining \"non-cancerous\" with \"calcification\" can give you \"non-cancerous calcified lesion.\"\n",
      "\n",
      "3. Add additional variations by using adjectives or phrases that convey similar meanings. For example, for \"osteoporosis,\" you can include phrases like \"decreased bone density,\" \"brittle bones,\" and \"thinning of the bones.\"\n",
      "\n",
      "4. Include negations or opposite terms to cover both positive and negative statements. For example, for \"no osteoporosis,\" you can include phrases like \"normal bone density,\" \"healthy bones,\" and \"no signs of osteoporosis.\"\n",
      "\n",
      "5. Combine all the generated paraphrases into a JSON array and return it as the output.\n",
      "\n",
      "Here's an example implementation in Python:\n",
      "\n",
      "```python\n",
      "import itertools\n",
      "import json\n",
      "\n",
      "def generate_paraphrases(fact):\n",
      "    paraphrases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-12 19:28:21,438 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\r\n",
      "2023-07-12 19:28:21,445 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 14972 of 15000 API responses.\r\n",
      "                    28 of 15000 API responses could not be processed.\r\n",
      "                    Saving paraphrased observations to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/paraphrase_observations_with_openai.py \\\n",
    "    --integrated_fact_metadata_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\" \\\n",
    "    --min_num_words_per_sentence 2 \\\n",
    "    --offset 0 \\\n",
    "    --num_sentences 15000 \\\n",
    "    --sample_equally_spaced_sentences \\\n",
    "    --process_kth_of_every_n_sentences 2 4 \\\n",
    "    --max_requests_per_minute 3000 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 300 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__two-or-more-words__part3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e42f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 12:32:44,231 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14965 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\n",
      "2023-07-20 12:32:44,402 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14971 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\n",
      "2023-07-20 12:32:44,522 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14972 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\n",
      "2023-07-20 12:32:44,687 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14993 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\n",
      "2023-07-20 12:32:44,687 - \u001b[1;32mINFO\u001b[1;0m - Loading facts metadata from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\n",
      "100%|███████████████████████████████| 578733/578733 [00:03<00:00, 161988.99it/s]\n",
      "2023-07-20 12:32:53,509 - \u001b[1;32mINFO\u001b[1;0m - Found 711223 unique observations\n",
      "2023-07-20 12:32:53,509 - \u001b[1;32mINFO\u001b[1;0m - Filtering observations to those with at least 2 words\n",
      "2023-07-20 12:32:54,220 - \u001b[1;32mINFO\u001b[1;0m - Found 709221 observations with at least 2 words\n",
      "2023-07-20 12:32:54,220 - \u001b[1;32mINFO\u001b[1;0m - Loading clusters from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/clusters(100,100297669,1315702).pkl\n",
      "2023-07-20 12:32:54,293 - \u001b[1;32mINFO\u001b[1;0m - Loading sentence embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxr_bert_sentence_embeddings(1605733,71051120).pkl\n",
      "2023-07-20 12:32:56,561 - \u001b[1;32mINFO\u001b[1;0m - Found 100 clusters\n",
      "2023-07-20 12:32:57,946 - \u001b[1;32mINFO\u001b[1;0m - Selected 50000 observations from 100 clusters\n",
      "2023-07-20 12:32:57,946 - \u001b[1;32mINFO\u001b[1;0m - Filtering observations to the 2-th of every 5 sentences\n",
      "2023-07-20 12:32:57,959 - \u001b[1;32mINFO\u001b[1;0m - Found 10000 observations that are the 2-th of every 5 sentences\n",
      "2023-07-20 12:32:57,959 - \u001b[1;33mWARNING\u001b[1;0m - Requested 100000 sentences but only 10000 are available. Using 10000 instead.\n",
      "2023-07-20 12:32:57,959 - \u001b[1;32mINFO\u001b[1;0m - Collecting the first 10000 sentence from the 0-th sentence\n",
      "2023-07-20 12:32:57,962 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to paraphrase: 10000\n",
      "2023-07-20 12:32:57,962 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to paraphrase:\n",
      "2023-07-20 12:32:57,962 - \u001b[1;32mINFO\u001b[1;0m - 1. 2 BBs\n",
      "2023-07-20 12:32:57,962 - \u001b[1;32mINFO\u001b[1;0m - 1112. worsening perihilar edema\n",
      "2023-07-20 12:32:57,962 - \u001b[1;32mINFO\u001b[1;0m - 2223. pneumonia has not fully cleared\n",
      "2023-07-20 12:32:57,962 - \u001b[1;32mINFO\u001b[1;0m - 3334. deviation of the trachea to the left\n",
      "2023-07-20 12:32:57,963 - \u001b[1;32mINFO\u001b[1;0m - 4445. focus of pneumonia in the right mid lung\n",
      "2023-07-20 12:32:57,963 - \u001b[1;32mINFO\u001b[1;0m - 5556. improved right basilar nodular opacification\n",
      "2023-07-20 12:32:57,963 - \u001b[1;32mINFO\u001b[1;0m - 6667. pleural effusion involving much of the left lung\n",
      "2023-07-20 12:32:57,963 - \u001b[1;32mINFO\u001b[1;0m - 7778. Swan-Ganz catheter ends 3 cm beyond standard placement\n",
      "2023-07-20 12:32:57,963 - \u001b[1;32mINFO\u001b[1;0m - 8889. dense area of opacification in the region of the minor fissure\n",
      "2023-07-20 12:32:57,963 - \u001b[1;32mINFO\u001b[1;0m - 10000. suggestion of either thyroid or other mass or hematoma from the separation of the presumed internal jugular portion of the pacer lead from the midline trachea\n",
      "2023-07-20 12:32:58,511 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230720_123258.jsonl\n",
      "2023-07-20 12:32:58,511 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_123258.jsonl\n",
      "2023-07-20 12:32:59,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-20 12:32:59,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #50\n",
      "2023-07-20 12:32:59,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-20 12:33:12,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #150\n",
      "2023-07-20 12:33:29,582 - \u001b[1;33mWARNING\u001b[1;0m - Request 20 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f823fcd3b31949a08c848b3a21577492 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:33:29,590 - \u001b[1;33mWARNING\u001b[1;0m - Request 66 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03b46aeac0d0baee5469d09a19849a3f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:33:34,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 133 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID caa09b0a2bfcb0fd2af041e2dff7d032 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:33:36,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #197\n",
      "2023-07-20 12:33:41,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 148 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9053ceb912aa8820dfbd8cacd7d354a9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:34:00,915 - \u001b[1;32mINFO\u001b[1;0m - Starting request #246\n",
      "2023-07-20 12:34:25,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #296\n",
      "2023-07-20 12:34:49,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #346\n",
      "2023-07-20 12:35:04,648 - \u001b[1;33mWARNING\u001b[1;0m - Request 315 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9a65177a6707e93715b7a773955695db in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:35:13,819 - \u001b[1;32mINFO\u001b[1;0m - Starting request #395\n",
      "2023-07-20 12:35:15,368 - \u001b[1;33mWARNING\u001b[1;0m - Request 337 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1d2088545d8516474e31f0962826aa1f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:35:38,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #444\n",
      "2023-07-20 12:36:02,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #494\n",
      "2023-07-20 12:36:17,163 - \u001b[1;33mWARNING\u001b[1;0m - Request 462 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6a5cde53003a34cfd81e1cf16c93f57f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:36:26,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #543\n",
      "2023-07-20 12:36:50,167 - \u001b[1;33mWARNING\u001b[1;0m - Request 529 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a182c92931fd4f7a02753e077b9efb66 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:36:51,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #529\n",
      "2023-07-20 12:37:07,686 - \u001b[1;33mWARNING\u001b[1;0m - Request 565 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 095c2e31ac8d74025cd29ab2e6721458 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 12:37:15,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #641\n",
      "2023-07-20 12:37:39,754 - \u001b[1;32mINFO\u001b[1;0m - Starting request #691\n",
      "2023-07-20 12:38:04,087 - \u001b[1;32mINFO\u001b[1;0m - Starting request #741\n",
      "2023-07-20 12:38:28,417 - \u001b[1;32mINFO\u001b[1;0m - Starting request #791\n",
      "2023-07-20 12:38:48,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 220 failed with Exception \n",
      "2023-07-20 12:38:52,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #840\n",
      "2023-07-20 12:39:15,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 825 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1b0db84da0982a627ad775d84e2575f1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:39:17,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #889\n",
      "2023-07-20 12:39:41,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #939\n",
      "2023-07-20 12:39:48,315 - \u001b[1;33mWARNING\u001b[1;0m - Request 891 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9e1367f695eefacba06b33cecf9aed27 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:40:05,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #988\n",
      "2023-07-20 12:40:30,148 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1038\n",
      "2023-07-20 12:40:32,130 - \u001b[1;33mWARNING\u001b[1;0m - Request 980 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8ee259283c0ed6f00a721fcc7d3db57c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:40:39,899 - \u001b[1;33mWARNING\u001b[1;0m - Request 996 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8eae1300c6e31b871be8f0a8d3e84863 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:40:54,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1086\n",
      "2023-07-20 12:41:04,252 - \u001b[1;33mWARNING\u001b[1;0m - Request 1045 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4005723e08fbec3906ae65ca2efa67d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:41:18,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1135\n",
      "2023-07-20 12:41:23,243 - \u001b[1;33mWARNING\u001b[1;0m - Request 1083 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e69578546cdea6e2a13f44be821d4db4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:41:39,818 - \u001b[1;33mWARNING\u001b[1;0m - Request 1116 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b91d18cecbfeb5a1e58e4639598de9a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:41:43,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1183\n",
      "2023-07-20 12:42:07,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1233\n",
      "2023-07-20 12:42:13,422 - \u001b[1;33mWARNING\u001b[1;0m - Request 1183 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7761cda9c21e90d6b72ebf80b4475ee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:42:22,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 1202 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 60e1043b1d142a74193f6828c4f1e3c7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:42:31,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1281\n",
      "2023-07-20 12:42:33,633 - \u001b[1;33mWARNING\u001b[1;0m - Request 1224 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 23e75185e795912db9734cc47a317724 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:42:56,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1330\n",
      "2023-07-20 12:43:20,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1380\n",
      "2023-07-20 12:43:45,014 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1430\n",
      "2023-07-20 12:44:07,429 - \u001b[1;33mWARNING\u001b[1;0m - Request 1414 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fb16c0425a60fb4d0ea809347cdccdab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:44:09,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1479\n",
      "2023-07-20 12:44:09,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 1419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7c19049856f47beb0b5e7d1f005e04c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:44:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 910 failed with Exception \n",
      "2023-07-20 12:44:33,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1527\n",
      "2023-07-20 12:44:58,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1577\n",
      "2023-07-20 12:45:22,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1627\n",
      "2023-07-20 12:45:28,811 - \u001b[1;33mWARNING\u001b[1;0m - Request 1578 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7c23b8db02136d25de3e6d0fececbc4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:45:46,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1676\n",
      "2023-07-20 12:46:04,898 - \u001b[1;33mWARNING\u001b[1;0m - Request 1651 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 36e7c123786de0cf8784c82047755036 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:46:11,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1725\n",
      "2023-07-20 12:46:14,854 - \u001b[1;33mWARNING\u001b[1;0m - Request 1671 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b84101c5c0db1fbc36067c5e790dcfa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:46:35,605 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1774\n",
      "2023-07-20 12:46:59,966 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1824\n",
      "2023-07-20 12:47:17,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 1799 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c58c0a619d76cb50c7b877cfd064c4e2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:47:24,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 12:47:48,756 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1923\n",
      "2023-07-20 12:47:50,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1318 failed with Exception \n",
      "2023-07-20 12:47:56,538 - \u001b[1;33mWARNING\u001b[1;0m - Request 1877 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99eb03a8e00c621787327b5902fe1cf9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:48:13,136 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1971\n",
      "2023-07-20 12:48:20,419 - \u001b[1;33mWARNING\u001b[1;0m - Request 1926 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 353e1d883bc7d871e76b79a0b59f4876 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:48:37,517 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2020\n",
      "2023-07-20 12:48:39,961 - \u001b[1;33mWARNING\u001b[1;0m - Request 1938 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c55d5327ececde005caec503a2e207c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:48:57,123 - \u001b[1;33mWARNING\u001b[1;0m - Request 1996 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 322030e6de1ef61855819e9e5ac4b9ef in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:48:58,968 - \u001b[1;33mWARNING\u001b[1;0m - Request 2002 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 13f0e28d35c0193dc155b6ed741e14a1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:49:01,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2067\n",
      "2023-07-20 12:49:26,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2117\n",
      "2023-07-20 12:49:36,511 - \u001b[1;33mWARNING\u001b[1;0m - Request 2076 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 164dc2fb4ae3d5b039b27ce9762a17b7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:49:41,848 - \u001b[1;33mWARNING\u001b[1;0m - Request 1918 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 02a201acfc69f3ada41888a55dab1813 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:49:50,470 - \u001b[1;33mWARNING\u001b[1;0m - Request 1988 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b97c0e318de2a56a9a27d6606a9cd205 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:49:50,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2165\n",
      "2023-07-20 12:49:59,444 - \u001b[1;33mWARNING\u001b[1;0m - Request 2123 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 92288a02cf897473e84eb58b3f3cb8c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:50:05,350 - \u001b[1;33mWARNING\u001b[1;0m - Request 2133 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d4da4c45ef3d77675f68b056e0619cdf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:50:08,442 - \u001b[1;33mWARNING\u001b[1;0m - Request 2140 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 694d42add81f72ede611ad366d0b8c17 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:50:15,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2211\n",
      "2023-07-20 12:50:21,607 - \u001b[1;33mWARNING\u001b[1;0m - Request 1988 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID efe70e24026f3032476796d69400bf87 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:50:39,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2260\n",
      "2023-07-20 12:51:03,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2310\n",
      "2023-07-20 12:51:08,888 - \u001b[1;33mWARNING\u001b[1;0m - Request 2257 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2118ee24f35afe33648e2fb318d30317 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:51:19,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 2279 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 74b0d84602384851f2e329f0559ffff2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:51:28,288 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2358\n",
      "2023-07-20 12:51:52,682 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2408\n",
      "2023-07-20 12:51:57,550 - \u001b[1;33mWARNING\u001b[1;0m - Request 2356 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3f1ce83129216cb1c10cf93e12e107cb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:52:01,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 2364 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62721ab38f21d2ac3c503d27fc733979 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:52:08,527 - \u001b[1;33mWARNING\u001b[1;0m - Request 2378 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ea3850242ed27006479f5e94b132338a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:52:17,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2455\n",
      "2023-07-20 12:52:41,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2505\n",
      "2023-07-20 12:53:05,872 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2555\n",
      "2023-07-20 12:53:12,198 - \u001b[1;33mWARNING\u001b[1;0m - Request 2506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 88a779e92a5bfbcbeead65c4cfd7a420 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:53:30,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 12:53:34,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 2551 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f3c0b8e13959810d2c52a75030749eb2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:53:54,662 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2653\n",
      "2023-07-20 12:54:19,063 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2703\n",
      "2023-07-20 12:54:43,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2753\n",
      "2023-07-20 12:55:07,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2803\n",
      "2023-07-20 12:55:20,519 - \u001b[1;33mWARNING\u001b[1;0m - Request 2767 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b39a87407183d1b9db13ca9668c98bfa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:55:32,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2852\n",
      "2023-07-20 12:55:45,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 2819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8af4fe22a0fc0fb47d31ee7a9b095f5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:55:56,722 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2901\n",
      "2023-07-20 12:56:02,518 - \u001b[1;33mWARNING\u001b[1;0m - Request 2852 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e850e04667dbc132215dfce0a5501d12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:56:05,926 - \u001b[1;33mWARNING\u001b[1;0m - Request 2859 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bb533f1c1eca969cc20fde629c2ff405 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:56:21,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2949\n",
      "2023-07-20 12:56:40,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2381 failed with Exception \n",
      "2023-07-20 12:56:45,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2998\n",
      "2023-07-20 12:57:09,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3048\n",
      "2023-07-20 12:57:34,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3098\n",
      "2023-07-20 12:57:58,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3148\n",
      "2023-07-20 12:58:23,216 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3198\n",
      "2023-07-20 12:58:30,506 - \u001b[1;33mWARNING\u001b[1;0m - Request 3151 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69164a1e9c53971a8625af0535bbec4c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 12:58:41,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2624 failed with Exception \n",
      "2023-07-20 12:58:47,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3246\n",
      "2023-07-20 12:59:12,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3296\n",
      "2023-07-20 12:59:36,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3346\n",
      "2023-07-20 12:59:43,248 - \u001b[1;33mWARNING\u001b[1;0m - Request 3298 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af19a8ae187e6e2bc1f75193ab5218dc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:00:00,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3395\n",
      "2023-07-20 13:00:18,458 - \u001b[1;33mWARNING\u001b[1;0m - Request 3369 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5fd632d0bd187baca9c9ad2725d6c0d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:00:25,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3444\n",
      "2023-07-20 13:00:49,814 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3494\n",
      "2023-07-20 13:00:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2901 failed with Exception \n",
      "2023-07-20 13:00:59,044 - \u001b[1;33mWARNING\u001b[1;0m - Request 3451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 90f6982808eef0d993c45af98321077e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:01:14,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3542\n",
      "2023-07-20 13:01:33,708 - \u001b[1;33mWARNING\u001b[1;0m - Request 3520 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f389ac465c134d66e3bb4143b6017b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:01:38,684 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3591\n",
      "2023-07-20 13:01:59,144 - \u001b[1;33mWARNING\u001b[1;0m - Request 3572 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56a941bf4916e988182a7de39feba3ad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:02:03,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3640\n",
      "2023-07-20 13:02:27,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3690\n",
      "2023-07-20 13:02:51,995 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3740\n",
      "2023-07-20 13:02:55,343 - \u001b[1;33mWARNING\u001b[1;0m - Request 3685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8717011f1427fbe072406095d3491778 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:03:16,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3789\n",
      "2023-07-20 13:03:26,120 - \u001b[1;33mWARNING\u001b[1;0m - Request 3747 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 08fdbce27c3f6f5738eac85c13915d9a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:03:34,414 - \u001b[1;33mWARNING\u001b[1;0m - Request 3764 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 83c7b007cb2df1a118a33d45dc07727e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:03:40,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3837\n",
      "2023-07-20 13:03:41,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 3779 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 44e6c3669bf7e0e1a719422a52feabba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:04:05,317 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3886\n",
      "2023-07-20 13:04:29,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3936\n",
      "2023-07-20 13:04:50,272 - \u001b[1;33mWARNING\u001b[1;0m - Request 3966 failed with error {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}\n",
      "2023-07-20 13:04:54,207 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:04:59,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 3936 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae20935fe14f497dad47f268bf120d77 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:05:18,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4034\n",
      "2023-07-20 13:05:24,413 - \u001b[1;33mWARNING\u001b[1;0m - Request 3985 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b618a1c36f42e2bfca733c9c166fc101 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:05:43,092 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4083\n",
      "2023-07-20 13:06:07,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4133\n",
      "2023-07-20 13:06:31,453 - \u001b[1;33mWARNING\u001b[1;0m - Request 4175 failed with error {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}\n",
      "2023-07-20 13:06:31,992 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4175\n",
      "2023-07-20 13:06:56,452 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4232\n",
      "2023-07-20 13:07:12,469 - \u001b[1;33mWARNING\u001b[1;0m - Request 4203 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ea7b6f62e8557c7738f291929b208339 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:07:20,892 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4281\n",
      "2023-07-20 13:07:29,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 4238 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c9dbdbb952539b8e0b4fc54b13bace6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:07:45,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4330\n",
      "2023-07-20 13:07:54,112 - \u001b[1;33mWARNING\u001b[1;0m - Request 4287 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c2dd2d9abc97089f5d6d2244c78626c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:08:07,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 4314 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a11ac0c1d9f95e71762afbcafbbdc5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:08:09,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4378\n",
      "2023-07-20 13:08:34,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4428\n",
      "2023-07-20 13:08:58,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4478\n",
      "2023-07-20 13:09:01,728 - \u001b[1;33mWARNING\u001b[1;0m - Request 4422 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d4158f0e84807f931f52b6f523404b74 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:09:23,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4527\n",
      "2023-07-20 13:09:43,113 - \u001b[1;33mWARNING\u001b[1;0m - Request 4506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd991cfa153a6c4f0ec052874cbb6c23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:09:47,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4576\n",
      "2023-07-20 13:09:50,191 - \u001b[1;33mWARNING\u001b[1;0m - Request 4518 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 21c88587eff7bcf3a9fb1deedf6d1c34 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:10:12,060 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4625\n",
      "2023-07-20 13:10:17,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 4575 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b360dc6e7ea755ac7f67ee24f2cdfba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:10:36,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4674\n",
      "2023-07-20 13:10:50,575 - \u001b[1;33mWARNING\u001b[1;0m - Request 4641 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f8c480c503ca6c4f557cc8f1ab58ef71 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:10:57,440 - \u001b[1;33mWARNING\u001b[1;0m - Request 4655 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d47df56827aaec1acf1ce0ddfda4274 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:11:00,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4722\n",
      "2023-07-20 13:11:25,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4772\n",
      "2023-07-20 13:11:37,561 - \u001b[1;33mWARNING\u001b[1;0m - Request 4735 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fbc3d858f7736f4bfeda1416c0ca3945 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:11:49,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4821\n",
      "2023-07-20 13:12:14,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4871\n",
      "2023-07-20 13:12:38,815 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4921\n",
      "2023-07-20 13:13:03,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4971\n",
      "2023-07-20 13:13:16,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 4937 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19e23c33cca8628dc9bae5b25535562e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:13:23,712 - \u001b[1;33mWARNING\u001b[1;0m - Request 4951 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0de866388c1507917332a04b91e87efe in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:13:27,770 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5019\n",
      "2023-07-20 13:13:50,174 - \u001b[1;33mWARNING\u001b[1;0m - Request 5004 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f99eafeb9f1d03f9769b53e2d47f3c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:13:52,245 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5068\n",
      "2023-07-20 13:14:15,605 - \u001b[1;33mWARNING\u001b[1;0m - Request 5055 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09024890f54b848f46fe2b9856a21889 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:14:16,719 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5117\n",
      "2023-07-20 13:14:19,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 5063 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f015a4c554aa2dd5f15f2ce07dd7b91 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:14:41,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5166\n",
      "2023-07-20 13:14:51,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 5125 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 43c5465c689425a12d1b94344aec9fb7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:14:53,758 - \u001b[1;33mWARNING\u001b[1;0m - Request 5130 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cac3b5c1e2abbee722ae7b65f5ffdc52 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:15:05,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5214\n",
      "2023-07-20 13:15:11,871 - \u001b[1;33mWARNING\u001b[1;0m - Request 5167 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0cdfa5705e7c02b4717a94a7321cbae8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:15:30,146 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5263\n",
      "2023-07-20 13:15:54,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5313\n",
      "2023-07-20 13:16:19,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5363\n",
      "2023-07-20 13:16:26,330 - \u001b[1;33mWARNING\u001b[1;0m - Request 5316 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a13c19bac0a352cc7c52f49b37877c69 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:16:33,187 - \u001b[1;33mWARNING\u001b[1;0m - Request 5330 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cedeace1af6733294a862137392552ff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:16:43,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5411\n",
      "2023-07-20 13:16:52,782 - \u001b[1;33mWARNING\u001b[1;0m - Request 5370 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c723ee8c85eb23d418be3cef341d75fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:17:08,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5460\n",
      "2023-07-20 13:17:32,552 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5510\n",
      "2023-07-20 13:17:39,259 - \u001b[1;33mWARNING\u001b[1;0m - Request 5462 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a56669a7f738ab357fc8f9a0eb2903ff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:17:57,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5559\n",
      "2023-07-20 13:18:09,131 - \u001b[1;33mWARNING\u001b[1;0m - Request 5523 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a287ffe35148e6f1d3ac6538b3da2ff6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:18:21,503 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5608\n",
      "2023-07-20 13:18:45,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5658\n",
      "2023-07-20 13:19:10,448 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5708\n",
      "2023-07-20 13:19:16,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 5658 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c2110a14c2e125de0f6270c8a21aa067 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:19:34,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5757\n",
      "2023-07-20 13:19:58,775 - \u001b[1;33mWARNING\u001b[1;0m - Request 5744 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 70598c74ad66564b227089d11d2306dd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:19:59,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5744\n",
      "2023-07-20 13:20:04,855 - \u001b[1;33mWARNING\u001b[1;0m - Request 5735 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-20 13:20:06,092 - \u001b[1;33mWARNING\u001b[1;0m - Request 5738 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-20 13:20:08,832 - \u001b[1;33mWARNING\u001b[1;0m - Request 5743 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-20 13:20:10,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 5746 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-20 13:20:11,180 - \u001b[1;33mWARNING\u001b[1;0m - Request 5748 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-07-20 13:20:16,533 - \u001b[1;33mWARNING\u001b[1;0m - Request 5606 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c6fa920c642c1b273ef6d0dd55d314a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:20:23,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5850\n",
      "2023-07-20 13:20:25,822 - \u001b[1;33mWARNING\u001b[1;0m - Request 5842 failed with error {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}\n",
      "2023-07-20 13:20:40,438 - \u001b[1;33mWARNING\u001b[1;0m - Request 5825 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2cd9ba52fa90bdcbee412d321d9024af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:20:48,452 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5898\n",
      "2023-07-20 13:21:02,501 - \u001b[1;33mWARNING\u001b[1;0m - Request 5866 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 61d26a1f5ff008c2ae65300cd1422ad4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:21:12,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5947\n",
      "2023-07-20 13:21:19,635 - \u001b[1;33mWARNING\u001b[1;0m - Request 5900 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 209f9ce93507dd57b000af95da7bb47a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:21:30,404 - \u001b[1;33mWARNING\u001b[1;0m - Request 5922 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f36b90f7ba86a643f796834c2c8600bf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:21:37,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5995\n",
      "2023-07-20 13:21:40,201 - \u001b[1;33mWARNING\u001b[1;0m - Request 5941 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a0e9fbaa05f5c47db00efbc975a7cde in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:21:42,174 - \u001b[1;33mWARNING\u001b[1;0m - Request 5945 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4cf6e381368c77e6c2cb97482fea2f6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:21:47,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 5956 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ea1eadd5e2bc7d45f60a8e7e19220070 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:22:01,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6042\n",
      "2023-07-20 13:22:18,036 - \u001b[1;33mWARNING\u001b[1;0m - Request 6068 failed with error {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}\n",
      "2023-07-20 13:22:20,600 - \u001b[1;33mWARNING\u001b[1;0m - Request 6018 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ee47cd294c681f930abf5bcde4c4d96a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:22:26,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6090\n",
      "2023-07-20 13:22:48,309 - \u001b[1;33mWARNING\u001b[1;0m - Request 6075 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3619d306c590116fae242397d3fe8f32 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:22:50,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6139\n",
      "2023-07-20 13:23:15,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6189\n",
      "2023-07-20 13:23:39,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6239\n",
      "2023-07-20 13:24:02,301 - \u001b[1;33mWARNING\u001b[1;0m - Request 6223 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7596097ac3254d5430d3e570e1fa209f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:24:04,441 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6288\n",
      "2023-07-20 13:24:08,191 - \u001b[1;33mWARNING\u001b[1;0m - Request 6235 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 597ae989003915e1a3519a2cb06a858f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:24:28,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6337\n",
      "2023-07-20 13:24:53,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6387\n",
      "2023-07-20 13:25:17,325 - \u001b[1;33mWARNING\u001b[1;0m - Request 6374 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c60f5745db5eece5208f758f9c0e293 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:25:17,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6374\n",
      "2023-07-20 13:25:22,902 - \u001b[1;33mWARNING\u001b[1;0m - Request 6385 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4866789ff19aff277ef3f1f54ee09a60 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:25:39,773 - \u001b[1;33mWARNING\u001b[1;0m - Request 6419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 810806617ea311b3f13ebbb899b87f10 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:25:42,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6484\n",
      "2023-07-20 13:26:07,010 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6534\n",
      "2023-07-20 13:26:18,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 6496 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8538c9bdde897dd89ab48c07bc217c82 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:26:31,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6583\n",
      "2023-07-20 13:26:56,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6633\n",
      "2023-07-20 13:27:02,242 - \u001b[1;33mWARNING\u001b[1;0m - Request 6584 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9bb676caa1aa3a710cd93258b9a6b646 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:27:20,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6682\n",
      "2023-07-20 13:27:34,118 - \u001b[1;33mWARNING\u001b[1;0m - Request 6648 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 27904091d4afe388a46ceaa0b07d31e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:27:43,447 - \u001b[1;33mWARNING\u001b[1;0m - Request 6667 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0bf31deaa49d087dddfd075565c24dc0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:27:45,101 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6730\n",
      "2023-07-20 13:28:03,573 - \u001b[1;33mWARNING\u001b[1;0m - Request 6708 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3bba853d326ae1cac9f56e057c70c93a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:28:09,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6779\n",
      "2023-07-20 13:28:21,739 - \u001b[1;33mWARNING\u001b[1;0m - Request 6743 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 44e01340eaff9b798f2f59c437ff3987 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:28:34,154 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6828\n",
      "2023-07-20 13:28:55,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 6809 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 07e6da86d7529e2ecc33b484c653f0ef in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:28:58,672 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6877\n",
      "2023-07-20 13:29:23,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6927\n",
      "2023-07-20 13:29:38,678 - \u001b[1;33mWARNING\u001b[1;0m - Request 6897 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 49c3805c45c3bc16f7bee3b36e750a54 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:29:47,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6976\n",
      "2023-07-20 13:30:12,231 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7026\n",
      "2023-07-20 13:30:14,554 - \u001b[1;33mWARNING\u001b[1;0m - Request 6969 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 34cf81e5ea5e8410492df349e732c40e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:30:36,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7075\n",
      "2023-07-20 13:30:38,509 - \u001b[1;33mWARNING\u001b[1;0m - Request 7018 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 995c06fba33a4f5087e5e0d70061a5f0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:31:01,282 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7124\n",
      "2023-07-20 13:31:25,194 - \u001b[1;33mWARNING\u001b[1;0m - Request 7018 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d8d46af786ca38c6b1c84bd42fe3166c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:31:25,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7018\n",
      "2023-07-20 13:31:29,543 - \u001b[1;33mWARNING\u001b[1;0m - Request 7120 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b2d44e1e4528a3eaa327edd88be6a0b0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:31:50,337 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7222\n",
      "2023-07-20 13:31:52,109 - \u001b[1;33mWARNING\u001b[1;0m - Request 7166 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4300df3c528a65a71d402aafb42826f6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:32:14,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7271\n",
      "2023-07-20 13:32:39,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7321\n",
      "2023-07-20 13:32:40,650 - \u001b[1;33mWARNING\u001b[1;0m - Request 7262 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 507e24d9536fc53ae7a1789cd2f4c119 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:33:03,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7370\n",
      "2023-07-20 13:33:03,941 - \u001b[1;33mWARNING\u001b[1;0m - Request 7309 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 39bfa2facb93c08b324524a81bccb40a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:33:05,199 - \u001b[1;33mWARNING\u001b[1;0m - Request 7312 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1046bd7ead653b6f1e995a32a8b8a241 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:33:28,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7418\n",
      "2023-07-20 13:33:43,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 7388 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d82def02a575e1725cc3156d7c4c9701 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:33:53,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7467\n",
      "2023-07-20 13:34:09,973 - \u001b[1;33mWARNING\u001b[1;0m - Request 7441 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 773acfde6b1fc07e3c1d3bbffddebe8e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:34:15,569 - \u001b[1;33mWARNING\u001b[1;0m - Request 7451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0c9074dbd50545baf1d1a99c92f9864b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:34:17,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7515\n",
      "2023-07-20 13:34:42,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7565\n",
      "2023-07-20 13:34:42,361 - \u001b[1;33mWARNING\u001b[1;0m - Request 7505 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 974f7b73ae1da71ddabdbba5014e548d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:34:54,053 - \u001b[1;33mWARNING\u001b[1;0m - Request 7527 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ba208e77683bc54d94b7194c26704e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:35:06,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7613\n",
      "2023-07-20 13:35:27,003 - \u001b[1;33mWARNING\u001b[1;0m - Request 7593 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50a9dec0a43fa1bef60cbe0d41c45b6e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:35:31,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7662\n",
      "2023-07-20 13:35:55,714 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7712\n",
      "2023-07-20 13:35:59,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 7658 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a1fe59ae4857163df2dbe1844e2e5a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:36:20,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7761\n",
      "2023-07-20 13:36:44,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7811\n",
      "2023-07-20 13:37:04,952 - \u001b[1;33mWARNING\u001b[1;0m - Request 7739 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 875de3ee53ed1f56c7887537652cd620 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:37:09,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7860\n",
      "2023-07-20 13:37:20,935 - \u001b[1;33mWARNING\u001b[1;0m - Request 7823 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b07f692306721bec5d81b11e54f727e7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:37:33,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7909\n",
      "2023-07-20 13:37:39,670 - \u001b[1;33mWARNING\u001b[1;0m - Request 7860 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f09bb234f92a65879fe19c05841b51e0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:37:58,526 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7958\n",
      "2023-07-20 13:38:23,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8008\n",
      "2023-07-20 13:38:47,651 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8058\n",
      "2023-07-20 13:38:55,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 8011 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d282b18af6f573e4b850cc72147df697 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:38:59,691 - \u001b[1;33mWARNING\u001b[1;0m - Request 8021 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 39516d4e267a1b96d0a4c93a233ddde7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:39:09,839 - \u001b[1;33mWARNING\u001b[1;0m - Request 8040 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cd9d07816d68cdbb1b5ebd55230b0885 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:39:12,218 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8105\n",
      "2023-07-20 13:39:36,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8155\n",
      "2023-07-20 13:39:40,457 - \u001b[1;33mWARNING\u001b[1;0m - Request 8102 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d176286c74fda72abbc4578a79055c2b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:40:01,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8204\n",
      "2023-07-20 13:40:25,942 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8254\n",
      "2023-07-20 13:40:39,923 - \u001b[1;33mWARNING\u001b[1;0m - Request 8221 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b96041ef83118b4522c28ae3c76995c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:40:46,813 - \u001b[1;33mWARNING\u001b[1;0m - Request 8235 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dfcc6ee5154dba2a89b05757d0469952 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:40:50,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8302\n",
      "2023-07-20 13:41:14,543 - \u001b[1;33mWARNING\u001b[1;0m - Request 8290 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 511e77210b28b38294ee1b0f47476fcb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:41:15,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8290\n",
      "2023-07-20 13:41:37,433 - \u001b[1;33mWARNING\u001b[1;0m - Request 8336 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9be2349cfd00cb63bd579a1bfe6016d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:41:39,644 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8400\n",
      "2023-07-20 13:41:49,209 - \u001b[1;33mWARNING\u001b[1;0m - Request 8359 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 21d3051145b422dcd2d920ff5f62551f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:42:04,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8449\n",
      "2023-07-20 13:42:07,889 - \u001b[1;33mWARNING\u001b[1;0m - Request 8397 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a730cf8434bd793eca8d122050060ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:42:28,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8498\n",
      "2023-07-20 13:42:53,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8548\n",
      "2023-07-20 13:43:04,423 - \u001b[1;33mWARNING\u001b[1;0m - Request 8509 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c16e56f40f3d90a1452f54e41686505 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:43:09,355 - \u001b[1;33mWARNING\u001b[1;0m - Request 8519 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 57aa952d9e1d0bc0cecff4b6bc0ab8ea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:43:17,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8596\n",
      "2023-07-20 13:43:18,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 8538 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a7dd680469829d545a9b98479616488 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:43:21,851 - \u001b[1;33mWARNING\u001b[1;0m - Request 8544 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 053755fa898bfaecee8ab5dce59c7026 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:43:25,568 - \u001b[1;33mWARNING\u001b[1;0m - Request 8552 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a362e6c166e13a598eed2788cd5d99d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:43:42,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8643\n",
      "2023-07-20 13:44:07,137 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8693\n",
      "2023-07-20 13:44:31,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8743\n",
      "2023-07-20 13:44:56,353 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8793\n",
      "2023-07-20 13:45:07,837 - \u001b[1;33mWARNING\u001b[1;0m - Request 8755 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b0a906cbed226145eb32076160759766 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:45:20,959 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8842\n",
      "2023-07-20 13:45:44,992 - \u001b[1;33mWARNING\u001b[1;0m - Request 8829 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c64b0a26280ba1cbd120ac0b24c473a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:45:45,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8829\n",
      "2023-07-20 13:46:10,167 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8941\n",
      "2023-07-20 13:46:34,799 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8991\n",
      "2023-07-20 13:46:59,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9041\n",
      "2023-07-20 13:47:04,510 - \u001b[1;33mWARNING\u001b[1;0m - Request 8990 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5402204711dca0a7f14c319f1155028c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:47:24,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9090\n",
      "2023-07-20 13:47:39,482 - \u001b[1;33mWARNING\u001b[1;0m - Request 9060 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e65a3e3516b985c5785ea68499c2c308 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:47:48,661 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9139\n",
      "2023-07-20 13:48:13,290 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9189\n",
      "2023-07-20 13:48:15,420 - \u001b[1;33mWARNING\u001b[1;0m - Request 9132 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5f98b53cd617bb3bd952919c4a30b11 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:48:18,378 - \u001b[1;33mWARNING\u001b[1;0m - Request 9138 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 529e478c97ffcbf79c211c723f779cc8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:48:37,931 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9237\n",
      "2023-07-20 13:49:02,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9287\n",
      "2023-07-20 13:49:27,219 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9337\n",
      "2023-07-20 13:49:32,292 - \u001b[1;33mWARNING\u001b[1;0m - Request 9286 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a6b2d1c5beb7205d125fa63aefeec55 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:49:51,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9386\n",
      "2023-07-20 13:50:16,545 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9436\n",
      "2023-07-20 13:50:41,210 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9486\n",
      "2023-07-20 13:50:56,617 - \u001b[1;33mWARNING\u001b[1;0m - Request 9456 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID de1204e86e3badc2faff5972ae2bd7e9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:51:05,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9535\n",
      "2023-07-20 13:51:20,069 - \u001b[1;33mWARNING\u001b[1;0m - Request 9503 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6883fb595e1846274887435a2c9e1c2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:51:22,262 - \u001b[1;33mWARNING\u001b[1;0m - Request 9508 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0265321b47c5362f6890bb60fd78f96a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:51:30,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9583\n",
      "2023-07-20 13:51:31,147 - \u001b[1;33mWARNING\u001b[1;0m - Request 9525 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b058cad0cc26ec620654c773d78116fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:51:55,248 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9632\n",
      "2023-07-20 13:52:06,195 - \u001b[1;33mWARNING\u001b[1;0m - Request 9593 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aea96a6fa4d2d627854f2526d91b0fd0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:52:19,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9681\n",
      "2023-07-20 13:52:44,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9731\n",
      "2023-07-20 13:53:00,541 - \u001b[1;33mWARNING\u001b[1;0m - Request 9702 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e559e875a5edcf9a73673a315134c017 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:53:09,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9780\n",
      "2023-07-20 13:53:22,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 9746 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bcc21b4e5943b98396742199ca8bbaca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:53:28,295 - \u001b[1;33mWARNING\u001b[1;0m - Request 9758 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5f341a53b319534330c64f2d146168a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:53:28,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 9759 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b3cb262c5730b573946ce20ba09efa27 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:53:34,122 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9827\n",
      "2023-07-20 13:53:50,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 9801 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3b016b3d6efd08551ce59ed0457e7ee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:53:58,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9876\n",
      "2023-07-20 13:54:11,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 9841 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2e4ce57d3a175d8f57668b141af106d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:54:12,256 - \u001b[1;33mWARNING\u001b[1;0m - Request 9843 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b025831da6b206f141cc102c42a3b47e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 13:54:23,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 13:54:48,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9974\n",
      "2023-07-20 13:55:19,524 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_123258.jsonl\n",
      "2023-07-20 13:55:19,527 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_123258.jsonl\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/utils/openai_api.py\", line 141, in run_common_boilerplate_for_api_requests\n",
      "    parsed_output = parse_openai_output(text)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/notebooks/../../scripts/mimiccxr/paraphrase_observations_with_openai.py\", line 97, in parse_openai_model_output\n",
      "    assert match, f\"Could not parse output: {text}\"\n",
      "AssertionError: Could not parse output: The tip of the IJ (internal jugular) vein was visualized.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/notebooks/../../scripts/mimiccxr/paraphrase_observations_with_openai.py\", line 253, in <module>\n",
      "    run_common_boilerplate_for_api_requests(\n",
      "  File \"/home/pamessina/medvqa/medvqa/utils/openai_api.py\", line 150, in run_common_boilerplate_for_api_requests\n",
      "    logger.error(f\"Error parsing response {api_response_string} for sentence \\\"{metadata['sentence']}\\\": {e}\")\n",
      "KeyError: 'sentence'\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/paraphrase_observations_with_openai.py \\\n",
    "--integrated_fact_metadata_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\" \\\n",
    "--preprocessed_sentences_to_skip_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "--precomputed_sentence_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxr_bert_sentence_embeddings(1605733,71051120).pkl\" \\\n",
    "--precomputed_clusters_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/clusters(100,100297669,1315702).pkl\" \\\n",
    "--num_sentences_per_cluster 500 \\\n",
    "--min_num_words_per_sentence 2 \\\n",
    "--offset 0 \\\n",
    "--num_sentences 100000 \\\n",
    "--process_kth_of_every_n_sentences 2 5 \\\n",
    "--max_requests_per_minute 3000 \\\n",
    "--max_tokens_per_minute 80000 \\\n",
    "--max_tokens_per_request 512 \\\n",
    "--temperature 0.5 \\\n",
    "--logging_level \"INFO\" \\\n",
    "--api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "--openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "--alias \"__two-or-more-words_cluster-balanced_3of5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa675f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 14:23:21,839 - \u001b[1;32mINFO\u001b[1;0m - API responses already exist at /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_123258.jsonl. Skipping API requests.\n",
      "2023-07-20 14:23:21,839 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_123258.jsonl\n",
      "2023-07-20 14:23:22,100 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...ein was visualized.\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 133, \"completion_tokens\": 16, \"total_tokens\": 149}}, {\"query\": \"IJ tip\"}] for query \"IJ tip\": Could not parse output: The tip of the IJ (internal jugular) vein was visualized.\n",
      "2023-07-20 14:23:22,100 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"at 02:16\". Could you please provide more context or clarify your request?\n",
      "2023-07-20 14:23:22,100 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...ify your request?\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 136, \"completion_tokens\": 31, \"total_tokens\": 167}}, {\"query\": \"at 02:16\"}] for query \"at 02:16\": Could not parse output: I'm sorry, but I'm not sure what you mean by \"at 02:16\". Could you please provide more context or clarify your request?\n",
      "2023-07-20 14:23:22,105 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ... consultation\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 134, \"completion_tokens\": 183, \"total_tokens\": 317}}, {\"query\": \"calling Dr.\"}] for query \"calling Dr.\": Could not parse output: \"paraphrase 1\": Requesting the presence of Dr.\n",
      "\"paraphrase 2\": Paging Dr.\n",
      "\"paraphrase 3\": Contacting Dr.\n",
      "\"paraphrase 4\": Getting in touch with Dr.\n",
      "\"paraphrase 5\": Notifying Dr.\n",
      "\"paraphrase 6\": Reaching out to Dr.\n",
      "\"paraphrase 7\": Seeking the attention of Dr.\n",
      "\"paraphrase 8\": Contacting the doctor on call\n",
      "\"paraphrase 9\": Requesting the assistance of a physician\n",
      "\"paraphrase 10\": Urgently requiring medical expertise\n",
      "\"paraphrase 11\": Needing immediate attention from a doctor\n",
      "\"paraphrase 12\": Requesting the presence of a medical professional\n",
      "\"paraphrase 13\": Contacting the healthcare provider\n",
      "\"paraphrase 14\": Urgently seeking medical consultation\n",
      "2023-07-20 14:23:22,127 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...wed\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 134, \"completion_tokens\": 77, \"total_tokens\": 211}}, {\"query\": \"previous imaging noted\"}] for query \"previous imaging noted\": Could not parse output: prior imaging revealed\n",
      "previous radiological examination showed\n",
      "imaging study conducted previously demonstrated\n",
      "prior imaging examination indicated\n",
      "previous imaging study revealed\n",
      "imaging performed earlier showed\n",
      "previous radiographic evaluation demonstrated\n",
      "prior imaging study indicated\n",
      "previous imaging findings showed\n",
      "imaging conducted previously revealed\n",
      "prior radiological examination indicated\n",
      "previous imaging study demonstrated\n",
      "imaging performed earlier indicated\n",
      "prior radiographic evaluation showed\n",
      "2023-07-20 14:23:22,182 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...inish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 136, \"completion_tokens\": 115, \"total_tokens\": 251}}, {\"query\": \"compatible device for pH probe\"}] for query \"compatible device for pH probe\": Could not parse output: 1. Suitable device for pH probe\n",
      "2. Appropriate equipment for pH probe\n",
      "3. Recommended device for pH probe\n",
      "4. Compatible instrument for pH probe\n",
      "5. Proper device for pH probe\n",
      "6. Adequate equipment for pH probe\n",
      "7. Recommended apparatus for pH probe\n",
      "8. Compatible tool for pH probe\n",
      "9. Appropriate device for measuring pH\n",
      "10. Proper equipment for pH measurement\n",
      "11. Recommended instrument for pH testing\n",
      "12. Suitable device for pH monitoring\n",
      "13. Compatible tool for pH analysis\n",
      "14. Appropriate equipment for pH sensing\n",
      "2023-07-20 14:23:22,322 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...n\": \"stop\"}], \"usage\": {\"prompt_tokens\": 138, \"completion_tokens\": 158, \"total_tokens\": 296}}, {\"query\": \"multiple prior plain films dating back to\"}] for query \"multiple prior plain films dating back to\": Could not parse output: several previous chest X-rays over a period of time\n",
      "numerous prior plain radiographs conducted in the past\n",
      "multiple past X-ray images taken at different times\n",
      "a series of prior chest X-rays performed at various intervals\n",
      "several previous radiographic examinations of the chest\n",
      "numerous prior plain film studies conducted in the past\n",
      "multiple prior X-rays performed on different occasions\n",
      "a collection of past chest X-rays taken at different points in time\n",
      "several prior radiographs of the chest conducted over time\n",
      "numerous previous plain film studies performed in the past\n",
      "multiple prior X-ray images taken on separate occasions\n",
      "a series of past chest X-rays performed at various time points\n",
      "several previous radiographic examinations of the chest conducted over time\n",
      "numerous prior plain film studies conducted at different intervals\n",
      "2023-07-20 14:23:22,629 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 9994 of 10000 API responses.\n",
      "                    6 of 10000 API responses could not be processed.\n",
      "                    Saving processed texts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/paraphrase_observations_with_openai.py \\\n",
    "--api_responses_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_123258.jsonl\" \\\n",
    "--integrated_fact_metadata_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\" \\\n",
    "--preprocessed_sentences_to_skip_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "--precomputed_sentence_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxr_bert_sentence_embeddings(1605733,71051120).pkl\" \\\n",
    "--precomputed_clusters_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/clusters(100,100297669,1315702).pkl\" \\\n",
    "--num_sentences_per_cluster 500 \\\n",
    "--min_num_words_per_sentence 2 \\\n",
    "--offset 0 \\\n",
    "--num_sentences 100000 \\\n",
    "--process_kth_of_every_n_sentences 2 5 \\\n",
    "--max_requests_per_minute 3000 \\\n",
    "--max_tokens_per_minute 80000 \\\n",
    "--max_tokens_per_request 512 \\\n",
    "--temperature 0.5 \\\n",
    "--logging_level \"INFO\" \\\n",
    "--api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "--openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "--alias \"__two-or-more-words_cluster-balanced_3of5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c1c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5386cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2df86fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9994"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "015b0c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'query': 'interval progression of parenchymal opacities in the right lung'},\n",
       " 'parsed_response': ['Development of lung opacities has increased over time in the right lung',\n",
       "  'The right lung shows an increase in parenchymal opacities over a period of time',\n",
       "  'Progressive opacities in the right lung parenchyma',\n",
       "  'Increasing density of lung opacities observed in the right lung',\n",
       "  'Sequential changes in the right lung parenchymal opacities',\n",
       "  'The right lung demonstrates a worsening of parenchymal opacities',\n",
       "  'Evolution of pulmonary opacities in the right lung',\n",
       "  'Progressive infiltration of the right lung parenchyma',\n",
       "  'Interval worsening of opacities in the right lung',\n",
       "  'The right lung exhibits a progression of parenchymal opacities',\n",
       "  'Advancement of pulmonary infiltrates in the right lung',\n",
       "  'Incremental increase in parenchymal opacities in the right lung',\n",
       "  'Serial changes in the right lung parenchymal opacities',\n",
       "  'The right lung shows a gradual increase in opacities']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04faf48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 14:39:12,165 - \u001b[1;32mINFO\u001b[1;0m - Loaded 10 already paraphrased sentences from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\n",
      "2023-07-20 14:39:12,293 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14965 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\n",
      "2023-07-20 14:39:12,467 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14971 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\n",
      "2023-07-20 14:39:12,590 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14972 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\n",
      "2023-07-20 14:39:12,755 - \u001b[1;32mINFO\u001b[1;0m - Loaded 14993 paraphrased sentences to skip from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\n",
      "2023-07-20 14:39:12,756 - \u001b[1;32mINFO\u001b[1;0m - Loading facts metadata from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\n",
      "100%|███████████████████████████████| 578733/578733 [00:03<00:00, 155175.56it/s]\n",
      "2023-07-20 14:39:21,917 - \u001b[1;32mINFO\u001b[1;0m - Found 711223 unique observations\n",
      "2023-07-20 14:39:21,918 - \u001b[1;32mINFO\u001b[1;0m - Filtering observations to those with at least 2 words\n",
      "2023-07-20 14:39:22,641 - \u001b[1;32mINFO\u001b[1;0m - Found 709221 observations with at least 2 words\n",
      "2023-07-20 14:39:22,641 - \u001b[1;32mINFO\u001b[1;0m - Loading clusters from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/clusters(100,100297669,1315702).pkl\n",
      "2023-07-20 14:39:22,721 - \u001b[1;32mINFO\u001b[1;0m - Loading sentence embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxr_bert_sentence_embeddings(1605733,71051120).pkl\n",
      "2023-07-20 14:39:25,020 - \u001b[1;32mINFO\u001b[1;0m - Found 100 clusters\n",
      "2023-07-20 14:39:26,442 - \u001b[1;32mINFO\u001b[1;0m - Selected 50000 observations from 100 clusters\n",
      "2023-07-20 14:39:26,442 - \u001b[1;32mINFO\u001b[1;0m - Filtering observations to the 3-th of every 5 sentences\n",
      "2023-07-20 14:39:26,456 - \u001b[1;32mINFO\u001b[1;0m - Found 10000 observations that are the 3-th of every 5 sentences\n",
      "2023-07-20 14:39:26,456 - \u001b[1;33mWARNING\u001b[1;0m - Requested 100000 sentences but only 10000 are available. Using 10000 instead.\n",
      "2023-07-20 14:39:26,456 - \u001b[1;32mINFO\u001b[1;0m - Collecting the first 10000 sentence from the 0-th sentence\n",
      "2023-07-20 14:39:26,459 - \u001b[1;32mINFO\u001b[1;0m - Total number of sentences to paraphrase: 9990\n",
      "2023-07-20 14:39:26,459 - \u001b[1;32mINFO\u001b[1;0m - Example sentences to paraphrase:\n",
      "2023-07-20 14:39:26,459 - \u001b[1;32mINFO\u001b[1;0m - 1. known CF\n",
      "2023-07-20 14:39:26,459 - \u001b[1;32mINFO\u001b[1;0m - 1110. acute mitral regurgitation\n",
      "2023-07-20 14:39:26,459 - \u001b[1;32mINFO\u001b[1;0m - 2220. presence of a hydropneumothorax\n",
      "2023-07-20 14:39:26,459 - \u001b[1;32mINFO\u001b[1;0m - 3330. early area of aspiration pneumonitis\n",
      "2023-07-20 14:39:26,460 - \u001b[1;32mINFO\u001b[1;0m - 4440. healed left posterior sixth rib fracture\n",
      "2023-07-20 14:39:26,460 - \u001b[1;32mINFO\u001b[1;0m - 5550. increase in mild pulmonary venous congestion\n",
      "2023-07-20 14:39:26,460 - \u001b[1;32mINFO\u001b[1;0m - 6660. poorly characterized old overlying rib fractures\n",
      "2023-07-20 14:39:26,460 - \u001b[1;32mINFO\u001b[1;0m - 7770. aerated parenchyma trapped between loculated effusions\n",
      "2023-07-20 14:39:26,460 - \u001b[1;32mINFO\u001b[1;0m - 8880. difficult to exclude a very small pleural effusion on the left\n",
      "2023-07-20 14:39:26,460 - \u001b[1;32mINFO\u001b[1;0m - 9990. left internal jugular catheter continues to abut the expected location of the lateral wall of the superior vena cava near the junction with the brachiocephalic vein\n",
      "2023-07-20 14:39:27,005 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230720_143927.jsonl\n",
      "2023-07-20 14:39:27,005 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_143927.jsonl\n",
      "2023-07-20 14:39:27,570 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-07-20 14:39:27,700 - \u001b[1;32mINFO\u001b[1;0m - Starting request #50\n",
      "2023-07-20 14:39:27,830 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-07-20 14:39:40,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #150\n",
      "2023-07-20 14:39:57,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 2 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6acb41266dbe55dd70f13e734ecebf0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:39:57,821 - \u001b[1;33mWARNING\u001b[1;0m - Request 4 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6626e403fcb1005c5a5e90b680e1284a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:39:57,876 - \u001b[1;33mWARNING\u001b[1;0m - Request 21 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d1d6c2c07e13189d53c9e5fe6d1f678 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:39:58,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 112 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 30a1e8c3fdc5d05b356d3bfc84c9714a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:40:05,158 - \u001b[1;32mINFO\u001b[1;0m - Starting request #196\n",
      "2023-07-20 14:40:14,963 - \u001b[1;33mWARNING\u001b[1;0m - Request 158 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 66a3a4532f9cc1057581308f2ec3f343 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:40:16,425 - \u001b[1;33mWARNING\u001b[1;0m - Request 161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a11d4a499ce0c4957d392447514a309 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:40:18,369 - \u001b[1;33mWARNING\u001b[1;0m - Request 165 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 463a9b40b9a24c8f66b371c36a725dde in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:40:29,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #243\n",
      "2023-07-20 14:40:30,031 - \u001b[1;33mWARNING\u001b[1;0m - Request 112 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff80faf687fedbe86982eef6253a9b4a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:40:53,741 - \u001b[1;32mINFO\u001b[1;0m - Starting request #292\n",
      "2023-07-20 14:41:18,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #342\n",
      "2023-07-20 14:41:39,512 - \u001b[1;33mWARNING\u001b[1;0m - Request 324 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cd66e836f46caeda5b1af07273d1c685 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 14:41:42,352 - \u001b[1;32mINFO\u001b[1;0m - Starting request #391\n",
      "2023-07-20 14:41:50,722 - \u001b[1;33mWARNING\u001b[1;0m - Request 347 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 334ed66d16c1cc46235db13949508f14 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:41:53,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 353 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1aab8fa5829f890e7b8e984c27dcde6d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:42:06,664 - \u001b[1;32mINFO\u001b[1;0m - Starting request #439\n",
      "2023-07-20 14:42:30,977 - \u001b[1;32mINFO\u001b[1;0m - Starting request #489\n",
      "2023-07-20 14:42:37,416 - \u001b[1;33mWARNING\u001b[1;0m - Request 438 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd46467d9411575c3d08436abfa325ab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:42:55,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #538\n",
      "2023-07-20 14:43:01,749 - \u001b[1;33mWARNING\u001b[1;0m - Request 490 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f56f7d4313a638ebf4234351a44f4a3e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:43:14,317 - \u001b[1;33mWARNING\u001b[1;0m - Request 515 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 704ed3f371e0865a4a19be797b1a83da in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:43:19,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #586\n",
      "2023-07-20 14:43:43,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #636\n",
      "2023-07-20 14:43:48,382 - \u001b[1;33mWARNING\u001b[1;0m - Request 583 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID baf197525e37e756a471c97cd821aa9a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:43:55,665 - \u001b[1;33mWARNING\u001b[1;0m - Request 598 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2fb6f4c2be11d85bc2fed6c027033dfd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:44:08,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #684\n",
      "2023-07-20 14:44:26,325 - \u001b[1;33mWARNING\u001b[1;0m - Request 660 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6f3abe70b8edb2f734298c5c51031e5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:44:32,589 - \u001b[1;32mINFO\u001b[1;0m - Starting request #733\n",
      "2023-07-20 14:44:56,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #783\n",
      "2023-07-20 14:45:21,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #833\n",
      "2023-07-20 14:45:43,446 - \u001b[1;33mWARNING\u001b[1;0m - Request 816 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 54047de3f0cb5029f2d89dc96de7509b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:45:45,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #882\n",
      "2023-07-20 14:45:53,416 - \u001b[1;33mWARNING\u001b[1;0m - Request 837 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 191e1d89a4d36edeb251de4be1d43c2a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:46:03,163 - \u001b[1;33mWARNING\u001b[1;0m - Request 857 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b175685168cf4d2870443f975126d7bf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:46:04,141 - \u001b[1;33mWARNING\u001b[1;0m - Request 859 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7cd26642b4851e86e64b95db3248d079 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:46:09,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #929\n",
      "2023-07-20 14:46:34,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #979\n",
      "2023-07-20 14:46:58,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1029\n",
      "2023-07-20 14:47:08,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 988 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7bb758bcfdf9bfd89412b9140f934f92 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:47:22,020 - \u001b[1;33mWARNING\u001b[1;0m - Request 1015 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e827c23e439f641bf5a2f68f0d07e580 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:47:22,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1015\n",
      "2023-07-20 14:47:32,715 - \u001b[1;33mWARNING\u001b[1;0m - Request 1037 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f1585417bb5762ddc8092354b440e39d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:47:47,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1126\n",
      "2023-07-20 14:48:05,351 - \u001b[1;33mWARNING\u001b[1;0m - Request 1101 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2db72409926dbf4bedf24fd5b3b7ab1f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:48:11,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1175\n",
      "2023-07-20 14:48:36,028 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1225\n",
      "2023-07-20 14:48:51,165 - \u001b[1;33mWARNING\u001b[1;0m - Request 1194 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ed5d5a153cb6be5e5c17728e6bdc5599 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:49:00,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1274\n",
      "2023-07-20 14:49:24,742 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1324\n",
      "2023-07-20 14:49:33,517 - \u001b[1;33mWARNING\u001b[1;0m - Request 1280 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 411e5ff126e2fd027fa0a2fdbda3a9d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 14:49:49,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1373\n",
      "2023-07-20 14:50:13,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1423\n",
      "2023-07-20 14:50:13,513 - \u001b[1;33mWARNING\u001b[1;0m - Request 1361 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e547d0a6bc21ca440e5d79729b73a845 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:50:37,850 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1472\n",
      "2023-07-20 14:51:02,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1522\n",
      "2023-07-20 14:51:13,418 - \u001b[1;33mWARNING\u001b[1;0m - Request 1483 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ec155bd6af8fcb74f19f04e65683ea5d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:51:26,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1571\n",
      "2023-07-20 14:51:50,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1621\n",
      "2023-07-20 14:51:54,642 - \u001b[1;33mWARNING\u001b[1;0m - Request 1566 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dad50cb37269981e626d60dc9be75b39 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:51:55,849 - \u001b[1;33mWARNING\u001b[1;0m - Request 1569 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d9f9e65ad0bae0e54d0894718326688e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:52:12,389 - \u001b[1;33mWARNING\u001b[1;0m - Request 1603 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1bccd60dc73bd2a32a1b3a2687ae2aac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:52:15,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1668\n",
      "2023-07-20 14:52:39,223 - \u001b[1;33mWARNING\u001b[1;0m - Request 1656 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf2a871e14c3a3cb4018da281f84f994 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:52:39,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1656\n",
      "2023-07-20 14:52:42,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 1663 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f2e558981fce190388c1aea0fc88b46a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:52:44,102 - \u001b[1;33mWARNING\u001b[1;0m - Request 1665 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8681c163e0b94d12168547fcfcb4b85 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:52:57,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 1692 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 655d99db2163d1264dec8b4ba89ff88f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:53:03,032 - \u001b[1;33mWARNING\u001b[1;0m - Request 1648 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f71cf97a2fd1fe17ebb0697822068b8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:53:04,106 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1763\n",
      "2023-07-20 14:53:06,052 - \u001b[1;33mWARNING\u001b[1;0m - Request 1710 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69ad15f56e07871aa376fe76cb61a2bb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:53:28,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1812\n",
      "2023-07-20 14:53:52,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1862\n",
      "2023-07-20 14:54:17,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1912\n",
      "2023-07-20 14:54:24,082 - \u001b[1;33mWARNING\u001b[1;0m - Request 1864 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3be7c289ae6653ac43cae7818c7fa23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:54:26,495 - \u001b[1;33mWARNING\u001b[1;0m - Request 1869 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b50a8dcff7f68ba40cfeaba0611dd4e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:54:41,632 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1960\n",
      "2023-07-20 14:54:43,206 - \u001b[1;33mWARNING\u001b[1;0m - Request 1902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7c6803ffa104cbd6057e448229c0131a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:54:48,430 - \u001b[1;33mWARNING\u001b[1;0m - Request 1914 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b05ff468503bb212effe445434f68b0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:55:06,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2008\n",
      "2023-07-20 14:55:30,411 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2058\n",
      "2023-07-20 14:55:54,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2108\n",
      "2023-07-20 14:56:08,031 - \u001b[1;33mWARNING\u001b[1;0m - Request 2073 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 46c65291684adbb183a3dcca2b775fe1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:56:19,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2157\n",
      "2023-07-20 14:56:43,571 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2207\n",
      "2023-07-20 14:56:56,239 - \u001b[1;33mWARNING\u001b[1;0m - Request 2171 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 313487d3624660ed5a31aaad5e61e675 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:57:07,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2256\n",
      "2023-07-20 14:57:32,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2306\n",
      "2023-07-20 14:57:56,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2356\n",
      "2023-07-20 14:58:21,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 14:58:45,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2456\n",
      "2023-07-20 14:59:00,672 - \u001b[1;33mWARNING\u001b[1;0m - Request 2425 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b85edf97df024ee7c96eb21d1046e84 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 14:59:09,980 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2505\n",
      "2023-07-20 14:59:34,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2555\n",
      "2023-07-20 14:59:58,783 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2605\n",
      "2023-07-20 15:00:23,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2655\n",
      "2023-07-20 15:00:24,629 - \u001b[1;33mWARNING\u001b[1;0m - Request 2596 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e0fb36c62242012f57abba2015a6ce5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:00:46,683 - \u001b[1;33mWARNING\u001b[1;0m - Request 2641 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5dc5c5d312b7ff7edcbd26b40d08735f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:00:47,589 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2641\n",
      "2023-07-20 15:00:54,399 - \u001b[1;33mWARNING\u001b[1;0m - Request 2657 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dad276f0ca1d675d9f6e51d5606a4b13 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:01:01,693 - \u001b[1;33mWARNING\u001b[1;0m - Request 2671 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c902fc947318dbb527095d758aa92bbc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:01:03,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 2535 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f23a55798ae01e1f6a76bfe4d6617398 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:01:11,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2750\n",
      "2023-07-20 15:01:34,385 - \u001b[1;33mWARNING\u001b[1;0m - Request 2735 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 944109fd2f64358e2e33389435de3e0b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:01:36,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2799\n",
      "2023-07-20 15:01:42,682 - \u001b[1;33mWARNING\u001b[1;0m - Request 2751 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID df90b0a6c1c2fdcaecdc5a2bb01b196f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:02:00,832 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2848\n",
      "2023-07-20 15:02:09,547 - \u001b[1;33mWARNING\u001b[1;0m - Request 2805 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ec6927de517187414a80113ccf019ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:02:23,236 - \u001b[1;33mWARNING\u001b[1;0m - Request 2832 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6a425106c44146f0550c9d9cbb28a7d8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:02:25,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2896\n",
      "2023-07-20 15:02:25,663 - \u001b[1;33mWARNING\u001b[1;0m - Request 2837 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6dd48812dc0a19f06959960b9db9b7d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:02:34,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 2854 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b85413878862d520eb4bb68379b854e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:02:49,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2944\n",
      "2023-07-20 15:03:14,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2994\n",
      "2023-07-20 15:03:22,307 - \u001b[1;33mWARNING\u001b[1;0m - Request 2949 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d301c89e11324a5e1ab4a7bae6dc6c29 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:03:38,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3043\n",
      "2023-07-20 15:04:02,919 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3093\n",
      "2023-07-20 15:04:27,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3143\n",
      "2023-07-20 15:04:45,842 - \u001b[1;33mWARNING\u001b[1;0m - Request 3119 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dcad82bd6bcb8f7fde3fcb848982f6ed in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:04:51,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3192\n",
      "2023-07-20 15:04:53,171 - \u001b[1;33mWARNING\u001b[1;0m - Request 3134 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 847e76475d9c83e0629fca74c14e24f9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:05:06,327 - \u001b[1;33mWARNING\u001b[1;0m - Request 3161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e74735740ec3b53fb8af5e40935517dc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:05:13,670 - \u001b[1;33mWARNING\u001b[1;0m - Request 3176 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42438880e6a9c2914b8beaf48fa4d917 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:05:16,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3239\n",
      "2023-07-20 15:05:29,300 - \u001b[1;33mWARNING\u001b[1;0m - Request 3206 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b3f056aa655c2e7ac92d048bb8ae661 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:05:40,601 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3288\n",
      "2023-07-20 15:06:05,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3338\n",
      "2023-07-20 15:06:05,643 - \u001b[1;33mWARNING\u001b[1;0m - Request 3277 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8956dfbef9ff0d98e515adc70f829297 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:06:29,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3387\n",
      "2023-07-20 15:06:41,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 3350 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69a23dd455546ba2671e6f69252dc948 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:06:50,098 - \u001b[1;33mWARNING\u001b[1;0m - Request 3367 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c1bc699a31cfcf1ef3fd69c3a4ef27c7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:06:53,884 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3435\n",
      "2023-07-20 15:07:18,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3485\n",
      "2023-07-20 15:07:36,711 - \u001b[1;33mWARNING\u001b[1;0m - Request 3356 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 04624c22008392b6264c901c31ea56ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:07:42,747 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3534\n",
      "2023-07-20 15:07:55,713 - \u001b[1;33mWARNING\u001b[1;0m - Request 3467 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 21b205cb4e8a10a22dc3bebf0b7ead31 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:08:00,862 - \u001b[1;33mWARNING\u001b[1;0m - Request 3510 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c4615ce0b1c10d460c0646b41b44917 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:08:07,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3582\n",
      "2023-07-20 15:08:31,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3632\n",
      "2023-07-20 15:08:36,398 - \u001b[1;33mWARNING\u001b[1;0m - Request 3280 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e88cf387d0be420a174304c8c8791dd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:08:56,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3681\n",
      "2023-07-20 15:09:20,497 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3731\n",
      "2023-07-20 15:09:44,920 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3781\n",
      "2023-07-20 15:10:07,109 - \u001b[1;33mWARNING\u001b[1;0m - Request 3764 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c07923b4278ec9b1fb992e7895907354 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:10:09,362 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3830\n",
      "2023-07-20 15:10:10,727 - \u001b[1;33mWARNING\u001b[1;0m - Request 3772 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0c6c5ed3ca751acfc36226394c83bb98 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:10:13,177 - \u001b[1;33mWARNING\u001b[1;0m - Request 3777 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eb1c1bdd7c464938351460db21960a80 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:10:33,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3878\n",
      "2023-07-20 15:10:58,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3928\n",
      "2023-07-20 15:11:18,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 3907 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 470dc97ea1fcc9c87f56346ac554c414 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:11:22,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3977\n",
      "2023-07-20 15:11:32,388 - \u001b[1;33mWARNING\u001b[1;0m - Request 3936 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b54eba69f0dd1010a1efbec92658cec0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:11:33,378 - \u001b[1;33mWARNING\u001b[1;0m - Request 3938 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4452194408059cc0a6d501083656ad02 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:11:47,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4025\n",
      "2023-07-20 15:11:59,009 - \u001b[1;33mWARNING\u001b[1;0m - Request 3912 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 046c59d37b6afe1b4766c9a03fb64369 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:12:11,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 4012 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c68b17a56c02d02ce1b40c22d45a22cd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:12:11,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4012\n",
      "2023-07-20 15:12:31,606 - \u001b[1;33mWARNING\u001b[1;0m - Request 4053 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bb07a88958f43564aed590a72f41d62b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:12:36,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4122\n",
      "2023-07-20 15:12:51,114 - \u001b[1;33mWARNING\u001b[1;0m - Request 4092 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f59324db7ba96afbbf6f328141ca8f1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:12:55,979 - \u001b[1;33mWARNING\u001b[1;0m - Request 4102 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a9e6ec098a230e4ac0b8db66c5735f1f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:13:00,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4170\n",
      "2023-07-20 15:13:13,108 - \u001b[1;33mWARNING\u001b[1;0m - Request 4136 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 076d726b981b762f4be9891a807a13e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:13:24,936 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4219\n",
      "2023-07-20 15:13:34,366 - \u001b[1;33mWARNING\u001b[1;0m - Request 4110 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e1c4d8a1da773297079191562221140f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:13:49,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4268\n",
      "2023-07-20 15:14:04,931 - \u001b[1;33mWARNING\u001b[1;0m - Request 4239 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a746efc022ec18e3db50e11a92185c70 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:14:13,826 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4317\n",
      "2023-07-20 15:14:38,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4367\n",
      "2023-07-20 15:14:49,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 4329 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3d767c03993d2a9a4935b0246aa057e2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:15:02,726 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4416\n",
      "2023-07-20 15:15:27,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4466\n",
      "2023-07-20 15:15:51,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4516\n",
      "2023-07-20 15:15:58,393 - \u001b[1;33mWARNING\u001b[1;0m - Request 4468 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a157fa48892daf86acceeca7ae9a208e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:16:16,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4565\n",
      "2023-07-20 15:16:32,597 - \u001b[1;33mWARNING\u001b[1;0m - Request 4537 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4878e509c5d337484f3a8a52b1248c34 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:16:40,531 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4614\n",
      "2023-07-20 15:16:47,765 - \u001b[1;33mWARNING\u001b[1;0m - Request 4568 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b1a2238ca984242be4d2ff0d859f840 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:17:02,913 - \u001b[1;33mWARNING\u001b[1;0m - Request 4599 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b63390c041b318a7b3b34e59ee1ed58f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:17:05,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4662\n",
      "2023-07-20 15:17:29,466 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4712\n",
      "2023-07-20 15:17:53,920 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4762\n",
      "2023-07-20 15:17:55,341 - \u001b[1;33mWARNING\u001b[1;0m - Request 4703 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 849f8d53bf9df2b12763bcb2ef7d2e3b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:18:12,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 4739 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c55695c505dad69f9124812f2f8eb6a3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:18:18,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4810\n",
      "2023-07-20 15:18:29,347 - \u001b[1;33mWARNING\u001b[1;0m - Request 4771 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 84a75c6b518d0616634fd694c039a61f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:18:42,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4859\n",
      "2023-07-20 15:19:07,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4909\n",
      "2023-07-20 15:19:31,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4959\n",
      "2023-07-20 15:19:32,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 4898 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c980d855ce893fb7b2a63f99c6a5adb5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:19:56,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5008\n",
      "2023-07-20 15:20:03,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 4962 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db2af34f53f87f12cee9b4bdbe830d39 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:20:14,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 4983 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a21b02671bca54be42c48fa8d9dbacc9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:20:14,697 - \u001b[1;33mWARNING\u001b[1;0m - Request 4984 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 685345c783ae081c95909d5c857985de in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:20:20,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5055\n",
      "2023-07-20 15:20:25,034 - \u001b[1;33mWARNING\u001b[1;0m - Request 5005 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2c781ff89e4e57adbbe05d7de34fac24 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:20:34,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 5024 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 327e460efba0ebf453194e68c5a0da61 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:20:36,251 - \u001b[1;33mWARNING\u001b[1;0m - Request 5027 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bc4e7ffd16f2c4ea715fb290fcb0d66c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:20:45,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5102\n",
      "2023-07-20 15:20:53,864 - \u001b[1;33mWARNING\u001b[1;0m - Request 5061 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a97b771e55a2f64598e42ba804edc5cf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:21:01,710 - \u001b[1;33mWARNING\u001b[1;0m - Request 5076 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 20277683577eab1bab2d8e2ff7890066 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:21:04,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 5082 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99c6687c0166f3db08b5a2b8a1020c0f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:21:09,639 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5149\n",
      "2023-07-20 15:21:34,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5199\n",
      "2023-07-20 15:21:50,136 - \u001b[1;33mWARNING\u001b[1;0m - Request 5170 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ee84ce3438b7e09af1f2cd7234780cab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:21:58,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5248\n",
      "2023-07-20 15:22:18,606 - \u001b[1;33mWARNING\u001b[1;0m - Request 5228 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4ef29e94ca6c1a0b2d33aadd73388ef8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:22:23,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5297\n",
      "2023-07-20 15:22:47,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5347\n",
      "2023-07-20 15:22:56,728 - \u001b[1;33mWARNING\u001b[1;0m - Request 5304 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 952b50f09fbc53d3053c47645d66e9b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:23:12,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5396\n",
      "2023-07-20 15:23:16,799 - \u001b[1;33mWARNING\u001b[1;0m - Request 5345 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1d6848d2399675704cb4eab734fe3b95 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:23:18,820 - \u001b[1;33mWARNING\u001b[1;0m - Request 5349 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e0db146747b410ae3cfd85dbe4d569f8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:23:36,512 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5444\n",
      "2023-07-20 15:23:49,603 - \u001b[1;33mWARNING\u001b[1;0m - Request 5349 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c132aa5ac74a437829bb94784a49c0e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:24:01,012 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5493\n",
      "2023-07-20 15:24:25,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5543\n",
      "2023-07-20 15:24:26,837 - \u001b[1;33mWARNING\u001b[1;0m - Request 5484 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c3e56509fc80f9271271e5e271b9819f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:24:37,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 5506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 00881aac4372d88e7bfb08d6dedf3f0a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:24:49,997 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5591\n",
      "2023-07-20 15:24:52,789 - \u001b[1;33mWARNING\u001b[1;0m - Request 5537 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b168296c8322949b415893e49eafd218 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:25:14,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5640\n",
      "2023-07-20 15:25:38,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5690\n",
      "2023-07-20 15:26:03,447 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5740\n",
      "2023-07-20 15:26:13,565 - \u001b[1;33mWARNING\u001b[1;0m - Request 5699 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e713cd182c0e5c761b52831a3f52199b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:26:22,933 - \u001b[1;33mWARNING\u001b[1;0m - Request 5716 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0e16c2540271b7c5646d37c841ec0588 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:26:27,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5788\n",
      "2023-07-20 15:26:52,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5838\n",
      "2023-07-20 15:27:16,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5888\n",
      "2023-07-20 15:27:37,132 - \u001b[1;33mWARNING\u001b[1;0m - Request 5867 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 71429ebd69dc676fae003aa765d0a0ad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:27:41,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5937\n",
      "2023-07-20 15:28:05,886 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5987\n",
      "2023-07-20 15:28:30,397 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6037\n",
      "2023-07-20 15:28:54,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6087\n",
      "2023-07-20 15:29:03,054 - \u001b[1;33mWARNING\u001b[1;0m - Request 6042 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1cad2f15d133beba3b2555e5f3d1c67f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:29:19,417 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6136\n",
      "2023-07-20 15:29:43,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6186\n",
      "2023-07-20 15:29:54,036 - \u001b[1;33mWARNING\u001b[1;0m - Request 6145 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 475cd32ddf62ad5a47c4281991873b16 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:29:55,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 6148 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97ecd996db39097af25af410ad69be6f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:30:08,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6234\n",
      "2023-07-20 15:30:17,601 - \u001b[1;33mWARNING\u001b[1;0m - Request 6193 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1d8b6ee46520a08c8e0319527d96390c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:30:21,947 - \u001b[1;33mWARNING\u001b[1;0m - Request 6202 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b22cd5eb42edd9a654302ff1cef9b9dd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:30:23,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 6206 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56833239319e7cd1729579bdc27af3c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:30:24,409 - \u001b[1;33mWARNING\u001b[1;0m - Request 6207 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 885a802b671e3a0f791d42c5478b55dd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:30:32,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6280\n",
      "2023-07-20 15:30:57,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6330\n",
      "2023-07-20 15:31:21,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6380\n",
      "2023-07-20 15:31:35,960 - \u001b[1;33mWARNING\u001b[1;0m - Request 6347 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d46999e4541ca89adfa3c1d38d518e89 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:31:46,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6429\n",
      "2023-07-20 15:31:58,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 6393 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID da140741c4acce00e7a88cd0b3da0f89 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:32:10,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6478\n",
      "2023-07-20 15:32:35,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6528\n",
      "2023-07-20 15:32:45,062 - \u001b[1;33mWARNING\u001b[1;0m - Request 6486 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42801f0c5ff8ef9c04c2a3d72c25eacb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:32:59,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6577\n",
      "2023-07-20 15:33:14,020 - \u001b[1;33mWARNING\u001b[1;0m - Request 6545 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6ee6a03b976daba541e28bbb32b5945 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:33:24,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6626\n",
      "2023-07-20 15:33:29,718 - \u001b[1;33mWARNING\u001b[1;0m - Request 6576 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c928ad3b253f7557fe76cc29262ea47 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:33:49,010 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6675\n",
      "2023-07-20 15:34:04,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 6644 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 490001a8244c211aeef9cdab0f3dbe6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:34:13,530 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6724\n",
      "2023-07-20 15:34:21,655 - \u001b[1;33mWARNING\u001b[1;0m - Request 6680 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 31fce7ddda383961a95abf0ff95484f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:34:38,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6773\n",
      "2023-07-20 15:34:44,214 - \u001b[1;33mWARNING\u001b[1;0m - Request 6725 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e03e3c4b69e0c5754b395a2b14a332a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:34:54,414 - \u001b[1;33mWARNING\u001b[1;0m - Request 6735 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f115b1046480c650fa6380ac4fce4b1c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:35:01,881 - \u001b[1;33mWARNING\u001b[1;0m - Request 6760 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8e47384afd94b889122e2ee98d5332c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:35:02,578 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6760\n",
      "2023-07-20 15:35:27,104 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6870\n",
      "2023-07-20 15:35:51,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6920\n",
      "2023-07-20 15:35:55,351 - \u001b[1;33mWARNING\u001b[1;0m - Request 6866 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8795731ab113927b2e936f04fdb0cb30 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:35:59,753 - \u001b[1;33mWARNING\u001b[1;0m - Request 6875 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c631fa21206c64642e437b10cc1d7f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:36:10,055 - \u001b[1;33mWARNING\u001b[1;0m - Request 6896 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 71f0a880e3f7515011e7bffd0dddecf3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:36:16,138 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:36:40,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7017\n",
      "2023-07-20 15:37:05,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7067\n",
      "2023-07-20 15:37:06,959 - \u001b[1;33mWARNING\u001b[1;0m - Request 7009 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b4e65b463317ec3c83b180cf1ad0eae in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:37:27,136 - \u001b[1;33mWARNING\u001b[1;0m - Request 7050 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2103689f808679fccb812e417d83529b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:37:29,698 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7115\n",
      "2023-07-20 15:37:54,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7165\n",
      "2023-07-20 15:38:11,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 7139 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2b23a282b05119b460b8adc946c718b5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:38:16,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 7149 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0f8157dfb4894bdb090481f392a84f80 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:38:18,751 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7213\n",
      "2023-07-20 15:38:36,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 7190 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b9c13cb0110a176d79d38dbb221ef38 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:38:43,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7262\n",
      "2023-07-20 15:39:07,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7312\n",
      "2023-07-20 15:39:32,345 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7362\n",
      "2023-07-20 15:39:56,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7412\n",
      "2023-07-20 15:40:08,941 - \u001b[1;33mWARNING\u001b[1;0m - Request 7375 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ca4f69adab3efa4857ed9dae36890ba2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:40:21,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7461\n",
      "2023-07-20 15:40:37,428 - \u001b[1;33mWARNING\u001b[1;0m - Request 7433 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c083fd4d942500e9d40fafe06748d3b9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:40:45,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7510\n",
      "2023-07-20 15:40:55,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 7417 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dd8e8b056f46fd02d47dc0434f1ce4f9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:41:10,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7559\n",
      "2023-07-20 15:41:24,530 - \u001b[1;33mWARNING\u001b[1;0m - Request 7527 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6fc09474586e3838011a99f541af0b9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:41:35,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7608\n",
      "2023-07-20 15:41:42,679 - \u001b[1;33mWARNING\u001b[1;0m - Request 7563 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d5fda78675eac7926ac44994bb72cdec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:41:50,153 - \u001b[1;33mWARNING\u001b[1;0m - Request 7578 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 468f9e6d597a15bd4937f3ff9aff0a12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:41:59,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7656\n",
      "2023-07-20 15:42:24,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7706\n",
      "2023-07-20 15:42:27,087 - \u001b[1;33mWARNING\u001b[1;0m - Request 7650 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c99a2a2f1ccd618a014e9b23861920ec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:42:30,314 - \u001b[1;33mWARNING\u001b[1;0m - Request 7657 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ce92acb4d1e35b3af3dd43fcab5c10b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:42:48,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7754\n",
      "2023-07-20 15:43:13,291 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7804\n",
      "2023-07-20 15:43:37,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7854\n",
      "2023-07-20 15:43:56,296 - \u001b[1;33mWARNING\u001b[1;0m - Request 7830 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f84b1b443793fdc84348fdb8df4f7aa6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:44:02,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7903\n",
      "2023-07-20 15:44:12,492 - \u001b[1;33mWARNING\u001b[1;0m - Request 7863 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97dd41c712562303fc9b1281add32034 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:44:24,577 - \u001b[1;33mWARNING\u001b[1;0m - Request 7846 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a907a742a85f6b55255fa7b07e47ca65 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:44:25,729 - \u001b[1;33mWARNING\u001b[1;0m - Request 7890 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d2281816bc0809711a48551fac204952 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:44:26,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7950\n",
      "2023-07-20 15:44:41,454 - \u001b[1;33mWARNING\u001b[1;0m - Request 7921 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8ce715f9ee3aa5eb9b0c4ba379775633 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:44:51,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7999\n",
      "2023-07-20 15:45:15,838 - \u001b[1;33mWARNING\u001b[1;0m - Request 7987 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d33906cbf35ec5f82f24d6fd5482d999 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:45:16,089 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8049\n",
      "2023-07-20 15:45:40,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8098\n",
      "2023-07-20 15:45:45,029 - \u001b[1;33mWARNING\u001b[1;0m - Request 8046 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ea2031528c6f6a21fe45c2c10d478d10 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:45:45,809 - \u001b[1;33mWARNING\u001b[1;0m - Request 8048 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4cc2f4ad74e19a96774c44249d7281b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:46:05,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8146\n",
      "2023-07-20 15:46:29,788 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8196\n",
      "2023-07-20 15:46:53,612 - \u001b[1;33mWARNING\u001b[1;0m - Request 8183 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b2f86173fcb33f697a875d588fff214d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:46:54,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8183\n",
      "2023-07-20 15:47:06,377 - \u001b[1;33mWARNING\u001b[1;0m - Request 8209 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bd3b4286ebfa0226bb90e9ecdeb72d25 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:47:18,922 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8294\n",
      "2023-07-20 15:47:43,233 - \u001b[1;33mWARNING\u001b[1;0m - Request 8282 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID baf7d3066dc2441b8de84f8b28b93d25 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:47:43,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8344\n",
      "2023-07-20 15:48:08,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8393\n",
      "2023-07-20 15:48:09,017 - \u001b[1;33mWARNING\u001b[1;0m - Request 8334 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 871026ac42aca697350146b6c24947ce in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:48:32,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8442\n",
      "2023-07-20 15:48:57,274 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8492\n",
      "2023-07-20 15:49:13,930 - \u001b[1;33mWARNING\u001b[1;0m - Request 8464 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8fb3fc932e9aea96f1adec013f434070 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:49:16,168 - \u001b[1;33mWARNING\u001b[1;0m - Request 8469 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c1a8041646b71be165188507c786213 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:49:21,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8540\n",
      "2023-07-20 15:49:46,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8590\n",
      "2023-07-20 15:50:07,321 - \u001b[1;33mWARNING\u001b[1;0m - Request 8571 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 89fd1f2f04b9ce0fc702a30853942c23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:50:11,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8639\n",
      "2023-07-20 15:50:13,258 - \u001b[1;33mWARNING\u001b[1;0m - Request 8583 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bcf0e9af198de65b0906a49e56c193cf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:50:30,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 8617 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d31996cfc868d58286508fc938cd92f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:50:35,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8687\n",
      "2023-07-20 15:51:00,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8737\n",
      "2023-07-20 15:51:01,924 - \u001b[1;33mWARNING\u001b[1;0m - Request 8617 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fcf7b40be72ee535fde29578a7f4d8b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:51:17,178 - \u001b[1;33mWARNING\u001b[1;0m - Request 8710 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b444e841b83d50d0b6cef65838072d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:51:18,650 - \u001b[1;33mWARNING\u001b[1;0m - Request 8713 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 197fd5fce8a6ebcf04c14dacd850c1f7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:51:21,093 - \u001b[1;33mWARNING\u001b[1;0m - Request 8718 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8b3ed0f50d3000c545a1387cb9e5baf2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:51:24,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8783\n",
      "2023-07-20 15:51:49,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8833\n",
      "2023-07-20 15:52:08,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 8811 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7910159f43e7c39fc91ea768515dd421 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:52:14,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8882\n",
      "2023-07-20 15:52:36,228 - \u001b[1;33mWARNING\u001b[1;0m - Request 8859 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 66ccf98cc80f8bfe41538d97440e7b49 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:52:38,637 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8931\n",
      "2023-07-20 15:52:44,751 - \u001b[1;33mWARNING\u001b[1;0m - Request 8883 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7375d682eea087723c99dc216617d705 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:53:03,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8980\n",
      "2023-07-20 15:53:08,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 8930 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 35525a6a58c833912cbd01ef17e26296 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:53:14,800 - \u001b[1;33mWARNING\u001b[1;0m - Request 8943 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1bcaf287b46590391b2fa17be5b844a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:53:27,866 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9028\n",
      "2023-07-20 15:53:52,487 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9078\n",
      "2023-07-20 15:54:17,107 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9128\n",
      "2023-07-20 15:54:41,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9178\n",
      "2023-07-20 15:55:02,238 - \u001b[1;33mWARNING\u001b[1;0m - Request 9053 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f53bfd91cd37b2a6ba5797164406025 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:55:06,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9227\n",
      "2023-07-20 15:55:22,819 - \u001b[1;33mWARNING\u001b[1;0m - Request 9200 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 65dfbbed63171ed5e4099492c2cba4ae in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:55:31,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9276\n",
      "2023-07-20 15:55:55,706 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9326\n",
      "2023-07-20 15:56:06,694 - \u001b[1;33mWARNING\u001b[1;0m - Request 9287 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3e0abcfd87837840fb187a52f6a21b67 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:56:20,365 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9375\n",
      "2023-07-20 15:56:31,836 - \u001b[1;33mWARNING\u001b[1;0m - Request 9338 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09aba1f65d113ccdf873a34d16ead604 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:56:45,036 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9424\n",
      "2023-07-20 15:57:09,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9474\n",
      "2023-07-20 15:57:34,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9524\n",
      "2023-07-20 15:57:42,378 - \u001b[1;33mWARNING\u001b[1;0m - Request 9479 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9582141e60230b62b7882ebdb8e72aed in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:57:59,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9573\n",
      "2023-07-20 15:58:23,000 - \u001b[1;33mWARNING\u001b[1;0m - Request 9559 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4792899febe6d2e6d3809f96e79c32ff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:58:23,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9559\n",
      "2023-07-20 15:58:27,785 - \u001b[1;33mWARNING\u001b[1;0m - Request 9570 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b9c830a5ab23574cb147dcbbae8b55a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:58:48,450 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9671\n",
      "2023-07-20 15:59:13,171 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9721\n",
      "2023-07-20 15:59:23,117 - \u001b[1;33mWARNING\u001b[1;0m - Request 9680 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 65dd71d82020641ccc0dc9bd6a134250 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 15:59:37,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9770\n",
      "2023-07-20 16:00:02,615 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9820\n",
      "2023-07-20 16:00:09,583 - \u001b[1;33mWARNING\u001b[1;0m - Request 9773 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8e996cca54f9c93db0d3f9aa1091407a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 16:00:27,367 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9869\n",
      "2023-07-20 16:00:42,721 - \u001b[1;33mWARNING\u001b[1;0m - Request 9839 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ec3cb03f34df9390bef4bdd7e13c4057 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 16:00:52,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9918\n",
      "2023-07-20 16:01:17,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9968\n",
      "2023-07-20 16:01:38,265 - \u001b[1;33mWARNING\u001b[1;0m - Request 9950 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2e210302e0ed7389b278bc3251ea5589 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 16:01:44,834 - \u001b[1;33mWARNING\u001b[1;0m - Request 9963 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fcadca96f03420f3c2282a53a5fa0dfd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 16:02:08,502 - \u001b[1;33mWARNING\u001b[1;0m - Request 9950 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 32f6af9006fda480b5b8648843b1c36a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-07-20 16:05:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9819 failed with Exception \n",
      "2023-07-20 16:05:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9930 failed with Exception \n",
      "2023-07-20 16:06:07,762 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_143927.jsonl\n",
      "2023-07-20 16:06:07,765 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230720_143927.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 16:06:08,532 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...14. Deficit in\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 134, \"completion_tokens\": 76, \"total_tokens\": 210}}, {\"query\": \"loss of the\"}] for query \"loss of the\": Could not parse output: 1. Absence of\n",
      "2. Lack of\n",
      "3. Deficiency in\n",
      "4. Reduction in\n",
      "5. Diminished\n",
      "6. Decreased\n",
      "7. Missing\n",
      "8. Insufficient\n",
      "9. Decrease in\n",
      "10. Absent\n",
      "11. Inadequate\n",
      "12. Scarcity of\n",
      "13. Shortage of\n",
      "14. Deficit in\n",
      "2023-07-20 16:06:08,532 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...umber of small\"}, \"finish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 134, \"completion_tokens\": 85, \"total_tokens\": 219}}, {\"query\": \"a few small\"}] for query \"a few small\": Could not parse output: 1. Multiple tiny\n",
      "2. Some minor\n",
      "3. A couple of little\n",
      "4. Several petite\n",
      "5. Few insignificant\n",
      "6. Handful of diminutive\n",
      "7. Limited small\n",
      "8. Fewer minuscule\n",
      "9. A handful of tiny\n",
      "10. Several small-sized\n",
      "11. Few diminutive\n",
      "12. A few petite\n",
      "13. Some small-scale\n",
      "14. Limited number of small\n",
      "2023-07-20 16:06:08,655 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...ish_reason\": \"stop\"}], \"usage\": {\"prompt_tokens\": 137, \"completion_tokens\": 6, \"total_tokens\": 143}}, {\"query\": \"most recent radiograph obtained on\"}] for query \"most recent radiograph obtained on\": Could not parse output: most recent X-ray obtained on\n",
      "2023-07-20 16:06:08,895 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a fact extracted from a Chest X-ray report, output a JSON array of ...}], \"usage\": {\"prompt_tokens\": 141, \"completion_tokens\": 2, \"total_tokens\": 143}}, {\"query\": \"consolidation that developed between and has not been\"}] for query \"consolidation that developed between and has not been\": Could not parse output: resolved.\n",
      "2023-07-20 16:06:09,043 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 9986 of 9990 API responses.\n",
      "                    4 of 9990 API responses could not be processed.\n",
      "                    Saving processed texts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/paraphrase_observations_with_openai.py \\\n",
    "--integrated_fact_metadata_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_fact_metadata(578733,58628071).jsonl\" \\\n",
    "--preprocessed_sentences_to_skip_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "--precomputed_sentence_embeddings_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/cxr_bert_sentence_embeddings(1605733,71051120).pkl\" \\\n",
    "--precomputed_clusters_filepath \\\n",
    "\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/clusters(100,100297669,1315702).pkl\" \\\n",
    "--num_sentences_per_cluster 500 \\\n",
    "--min_num_words_per_sentence 2 \\\n",
    "--offset 0 \\\n",
    "--num_sentences 100000 \\\n",
    "--process_kth_of_every_n_sentences 3 5 \\\n",
    "--max_requests_per_minute 3000 \\\n",
    "--max_tokens_per_minute 80000 \\\n",
    "--max_tokens_per_request 512 \\\n",
    "--temperature 0.5 \\\n",
    "--logging_level \"INFO\" \\\n",
    "--api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "--openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "--alias \"__two-or-more-words_cluster-balanced_4of5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90076bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5df823e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14da5913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9996"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc5d8b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'query': 'pleural effusion more apparent'},\n",
       " 'parsed_response': ['The presence of pleural effusion is more evident',\n",
       "  'The pleural effusion is more noticeable',\n",
       "  'There is an increased visibility of pleural effusion',\n",
       "  'Pleural effusion is more clearly seen',\n",
       "  'The extent of pleural effusion is more pronounced',\n",
       "  'The appearance of pleural effusion is heightened',\n",
       "  'The presence of pleural effusion is more conspicuous',\n",
       "  'Pleural effusion is more evident on the X-ray',\n",
       "  'The visibility of pleural effusion is enhanced',\n",
       "  'Pleural effusion is more prominent',\n",
       "  'The degree of pleural effusion is more noticeable',\n",
       "  'The presence of pleural effusion is more discernible',\n",
       "  'Pleural effusion is more visible',\n",
       "  'The extent of pleural effusion is more apparent']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-8002]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
