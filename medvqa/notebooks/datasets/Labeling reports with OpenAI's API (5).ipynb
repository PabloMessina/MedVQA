{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525b6006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:47:35,607 - \u001b[1;32mINFO\u001b[1;0m - Loaded 100 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n",
      "2023-06-27 17:47:35,607 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 17:47:42,306 - \u001b[1;32mINFO\u001b[1;0m - Loaded 849523 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 17:47:43,474 - \u001b[1;32mINFO\u001b[1;0m - Found 414580 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 17:47:43,507 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 414580/414580 [00:51<00:00, 8072.79it/s]\n",
      "2023-06-27 17:48:34,883 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 414580/414580 [00:00<00:00, 429104.24it/s]\n",
      "2023-06-27 17:48:36,916 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-06-27 17:48:36,916 - \u001b[1;32mINFO\u001b[1;0m - First fact: Mediastinal bulgary bulgarian mediastinal bulgarian mediastinal bulgarian hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-27 17:48:36,916 - \u001b[1;32mINFO\u001b[1;0m - Last fact: Right\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 1. Left-sided pigtail-type chest tube\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 1667. Previously seen consolidation\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 3333. Re-expanding lung\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 5000. Right lung axillary abnormality\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 6666. Followup stomach NG tube\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 8332. Tube passing into stomach\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 9999. Recurrent stimulator\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 11665. Slightly leftward trachea deviation\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 13331. Optimal placement of ports within stomach\n",
      "2023-06-27 17:48:37,078 - \u001b[1;32mINFO\u001b[1;0m - 14998. Left greater density\n",
      "2023-06-27 17:48:37,150 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230627_174837.jsonl\n",
      "2023-06-27 17:48:37,151 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_174837.jsonl\n",
      "2023-06-27 17:48:37,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-27 17:48:37,888 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-06-27 17:48:37,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-06-27 17:48:38,007 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-06-27 17:48:38,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-06-27 17:48:38,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-06-27 17:48:42,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-06-27 17:48:53,039 - \u001b[1;32mINFO\u001b[1;0m - Starting request #140\n",
      "2023-06-27 17:49:03,712 - \u001b[1;32mINFO\u001b[1;0m - Starting request #160\n",
      "2023-06-27 17:49:08,343 - \u001b[1;33mWARNING\u001b[1;0m - Request 57 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ee1b65512d3938de999427d618c5251 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:49:08,473 - \u001b[1;33mWARNING\u001b[1;0m - Request 52 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8843587f152428ac4c420cdd39f64195 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:49:08,511 - \u001b[1;33mWARNING\u001b[1;0m - Request 54 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0c78a80eb1612e5a4518462c496327cc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:49:14,379 - \u001b[1;32mINFO\u001b[1;0m - Starting request #177\n",
      "2023-06-27 17:49:25,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #197\n",
      "2023-06-27 17:49:35,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #217\n",
      "2023-06-27 17:49:46,376 - \u001b[1;32mINFO\u001b[1;0m - Starting request #237\n",
      "2023-06-27 17:49:56,411 - \u001b[1;33mWARNING\u001b[1;0m - Request 199 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f781984d669575d8a888462bcfad37ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:49:57,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #199\n",
      "2023-06-27 17:50:07,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #276\n",
      "2023-06-27 17:50:18,371 - \u001b[1;32mINFO\u001b[1;0m - Starting request #296\n",
      "2023-06-27 17:50:29,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #316\n",
      "2023-06-27 17:50:39,684 - \u001b[1;32mINFO\u001b[1;0m - Starting request #336\n",
      "2023-06-27 17:50:41,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 281 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c08f89f452e97b3a5cbcb7dfdf2a346 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:50:50,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #355\n",
      "2023-06-27 17:51:01,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #375\n",
      "2023-06-27 17:51:11,673 - \u001b[1;32mINFO\u001b[1;0m - Starting request #395\n",
      "2023-06-27 17:51:22,334 - \u001b[1;32mINFO\u001b[1;0m - Starting request #415\n",
      "2023-06-27 17:51:32,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #435\n",
      "2023-06-27 17:51:38,767 - \u001b[1;33mWARNING\u001b[1;0m - Request 385 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b0abe2f51e3d9ad8801594d18969000 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:41,050 - \u001b[1;33mWARNING\u001b[1;0m - Request 393 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 646257253bddf0f8455deecc877499e1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:41,451 - \u001b[1;33mWARNING\u001b[1;0m - Request 394 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9cfd76dce8634a8897a4ff74584bb8d1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:51:43,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #452\n",
      "2023-06-27 17:51:54,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #472\n",
      "2023-06-27 17:51:58,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 425 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 521f5b754094486edccfc34ad71adb93 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:03,319 - \u001b[1;33mWARNING\u001b[1;0m - Request 435 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 58b25451b19f84b8e08403ce868aec14 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:04,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:52:07,589 - \u001b[1;33mWARNING\u001b[1;0m - Request 443 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 74b17466cc4ff21bad14ffc796a2b471 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:11,289 - \u001b[1;33mWARNING\u001b[1;0m - Request 449 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9bd36998e82042adaa605a954f7ea507 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:15,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #508\n",
      "2023-06-27 17:52:26,331 - \u001b[1;32mINFO\u001b[1;0m - Starting request #528\n",
      "2023-06-27 17:52:36,999 - \u001b[1;32mINFO\u001b[1;0m - Starting request #548\n",
      "2023-06-27 17:52:47,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #568\n",
      "2023-06-27 17:52:51,308 - \u001b[1;33mWARNING\u001b[1;0m - Request 518 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4f4a2ad14349cae336c8d9771cd29c73 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:52:58,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #587\n",
      "2023-06-27 17:53:08,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #607\n",
      "2023-06-27 17:53:11,046 - \u001b[1;33mWARNING\u001b[1;0m - Request 555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 24456e18d70736ac76ca8ff333b0bf0f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:53:15,803 - \u001b[1;33mWARNING\u001b[1;0m - Request 564 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2646e8cd678203b66a48383ceb0727ab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:53:19,660 - \u001b[1;32mINFO\u001b[1;0m - Starting request #625\n",
      "2023-06-27 17:53:30,319 - \u001b[1;32mINFO\u001b[1;0m - Starting request #645\n",
      "2023-06-27 17:53:31,299 - \u001b[1;33mWARNING\u001b[1;0m - Request 592 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 441c41cfa93cee1e0fe00461536f412f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:53:40,990 - \u001b[1;32mINFO\u001b[1;0m - Starting request #664\n",
      "2023-06-27 17:53:51,651 - \u001b[1;32mINFO\u001b[1;0m - Starting request #684\n",
      "2023-06-27 17:54:02,321 - \u001b[1;32mINFO\u001b[1;0m - Starting request #704\n",
      "2023-06-27 17:54:09,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 661 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5c17d792354cbee410eb412c7b3b0c1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:54:12,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #723\n",
      "2023-06-27 17:54:23,645 - \u001b[1;32mINFO\u001b[1;0m - Starting request #743\n",
      "2023-06-27 17:54:34,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #763\n",
      "2023-06-27 17:54:44,960 - \u001b[1;32mINFO\u001b[1;0m - Starting request #783\n",
      "2023-06-27 17:54:50,744 - \u001b[1;33mWARNING\u001b[1;0m - Request 737 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 68e836ff9c6a21ed84130fa776660b08 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:54:55,558 - \u001b[1;33mWARNING\u001b[1;0m - Request 746 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 79ceb69954cbf9ff96ab849f36ffa1e4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:54:55,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #802\n",
      "2023-06-27 17:55:04,125 - \u001b[1;33mWARNING\u001b[1;0m - Request 762 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7fabb24b9f54978c83d6fde91970b36 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:06,276 - \u001b[1;32mINFO\u001b[1;0m - Starting request #820\n",
      "2023-06-27 17:55:12,582 - \u001b[1;33mWARNING\u001b[1;0m - Request 778 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7fc6793b24d335466ca2fd57cd477eb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:16,943 - \u001b[1;32mINFO\u001b[1;0m - Starting request #839\n",
      "2023-06-27 17:55:27,604 - \u001b[1;32mINFO\u001b[1;0m - Starting request #859\n",
      "2023-06-27 17:55:31,796 - \u001b[1;33mWARNING\u001b[1;0m - Request 812 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c1fcb9d82c10d470b28de14145e6bd92 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:35,503 - \u001b[1;33mWARNING\u001b[1;0m - Request 818 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25662f4baf77b72aee650552827b90e3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:38,170 - \u001b[1;33mWARNING\u001b[1;0m - Request 823 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d2b6bac137b20c44fb3cb0cfb8248585 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:38,271 - \u001b[1;32mINFO\u001b[1;0m - Starting request #877\n",
      "2023-06-27 17:55:41,377 - \u001b[1;33mWARNING\u001b[1;0m - Request 829 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03f7eb8fa19e698e96078476dc5c47f2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:42,983 - \u001b[1;33mWARNING\u001b[1;0m - Request 832 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 544f32f71fcc2ae1930f6f5e970a4ee6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:55:48,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #894\n",
      "2023-06-27 17:55:59,600 - \u001b[1;32mINFO\u001b[1;0m - Starting request #914\n",
      "2023-06-27 17:56:09,136 - \u001b[1;33mWARNING\u001b[1;0m - Request 823 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f364eb2eed48060e90d5c71e2d1ddb6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:10,256 - \u001b[1;32mINFO\u001b[1;0m - Starting request #933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:56:11,229 - \u001b[1;33mWARNING\u001b[1;0m - Request 881 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cefbd39e41eace7bcd38c237cf70ba3e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:20,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #952\n",
      "2023-06-27 17:56:25,187 - \u001b[1;33mWARNING\u001b[1;0m - Request 905 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b13cbcfd2864599176c885c878374b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:27,776 - \u001b[1;33mWARNING\u001b[1;0m - Request 910 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2e6cbf81d6bf26fb91e06c93ad52b5d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:31,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #970\n",
      "2023-06-27 17:56:35,222 - \u001b[1;33mWARNING\u001b[1;0m - Request 924 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 00618038cc025ecf07460f0992632b17 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:38,437 - \u001b[1;33mWARNING\u001b[1;0m - Request 930 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b740a54dd85d7fe3e5cef0580e8cd1a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:56:42,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #988\n",
      "2023-06-27 17:56:52,913 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1008\n",
      "2023-06-27 17:57:03,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1028\n",
      "2023-06-27 17:57:09,341 - \u001b[1;33mWARNING\u001b[1;0m - Request 930 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 626d6880903449f790d2cb12efaad611 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:11,735 - \u001b[1;33mWARNING\u001b[1;0m - Request 986 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 949624fccfad17a92d7c663cdb069eb7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:13,612 - \u001b[1;33mWARNING\u001b[1;0m - Request 990 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f8ef370cdc386a19cfcc1f58d36e7cd5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:14,240 - \u001b[1;32mINFO\u001b[1;0m - Starting request #990\n",
      "2023-06-27 17:57:14,666 - \u001b[1;33mWARNING\u001b[1;0m - Request 992 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e5dae7a467bbf411b393521664b11264 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:24,900 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1064\n",
      "2023-06-27 17:57:28,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 532 failed with Exception \n",
      "2023-06-27 17:57:35,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1083\n",
      "2023-06-27 17:57:41,016 - \u001b[1;33mWARNING\u001b[1;0m - Request 1038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 89c9decf8438dc6d2714b48038499e28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:45,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 563 failed with Exception \n",
      "2023-06-27 17:57:46,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #563\n",
      "2023-06-27 17:57:54,652 - \u001b[1;33mWARNING\u001b[1;0m - Request 1063 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9809941a0c99339195606a02a2ff8baa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:55,557 - \u001b[1;33mWARNING\u001b[1;0m - Request 1062 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c0582974981d7205b90ae2904e6a16a9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:56,788 - \u001b[1;33mWARNING\u001b[1;0m - Request 1067 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af5dfa38a9982d499891b8845deb894d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:56,895 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1119\n",
      "2023-06-27 17:57:58,392 - \u001b[1;33mWARNING\u001b[1;0m - Request 1070 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 27bdb6be678ed33fb0d848e54e894190 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:57:59,986 - \u001b[1;33mWARNING\u001b[1;0m - Request 1072 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 52ddf271c52ccd0e61063aff78b35d4c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:01,601 - \u001b[1;33mWARNING\u001b[1;0m - Request 1075 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d65213ee686c873350a87326102a96f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:04,848 - \u001b[1;33mWARNING\u001b[1;0m - Request 1081 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0c7ef5777ed21664658f7bef098570f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:07,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1134\n",
      "2023-06-27 17:58:17,583 - \u001b[1;33mWARNING\u001b[1;0m - Request 1103 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 62133938cf97753aa75c7a35f808d2d7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:18,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1103\n",
      "2023-06-27 17:58:19,721 - \u001b[1;33mWARNING\u001b[1;0m - Request 1107 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 584cc0389f18ea42db279227d053fa5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 17:58:21,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 1111 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 872e175ba887c46422bb06d460660e59 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:58:28,899 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1171\n",
      "2023-06-27 17:58:39,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1191\n",
      "2023-06-27 17:58:50,227 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1211\n",
      "2023-06-27 17:58:58,683 - \u001b[1;33mWARNING\u001b[1;0m - Request 1170 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b334ee4d6356429b70981dde873369d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:00,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1230\n",
      "2023-06-27 17:59:06,135 - \u001b[1;33mWARNING\u001b[1;0m - Request 1184 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bcf218d47e3ed88b687f6ef3f68cfd04 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:07,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 1186 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f6c6ccfa83dfefa1da711641295b02e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:10,401 - \u001b[1;33mWARNING\u001b[1;0m - Request 1192 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 03cc7bd6a9f3df08fda30ef0909ca776 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:11,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1247\n",
      "2023-06-27 17:59:16,794 - \u001b[1;33mWARNING\u001b[1;0m - Request 1204 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e2b038ef75095fe5d45431664753f239 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:22,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1266\n",
      "2023-06-27 17:59:32,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1286\n",
      "2023-06-27 17:59:33,102 - \u001b[1;33mWARNING\u001b[1;0m - Request 1232 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a647b58c72fadee7fdbf9eb75aed288 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 17:59:43,493 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1305\n",
      "2023-06-27 17:59:54,182 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1325\n",
      "2023-06-27 18:00:04,852 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1345\n",
      "2023-06-27 18:00:06,079 - \u001b[1;33mWARNING\u001b[1;0m - Request 1290 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bf614fb56fb6bb759e409cc9e5cc17d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:09,398 - \u001b[1;33mWARNING\u001b[1;0m - Request 1296 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d9b6a8e9d95777d07238c2e9848a2e44 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:15,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1363\n",
      "2023-06-27 18:00:22,929 - \u001b[1;33mWARNING\u001b[1;0m - Request 1322 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eb2535077006cab6eb7ba8cfdedabb7a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:26,162 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1382\n",
      "2023-06-27 18:00:36,817 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1402\n",
      "2023-06-27 18:00:46,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 1365 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f7eb883b795f833995111e0bc291c17 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:00:47,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1365\n",
      "2023-06-27 18:00:54,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 903 failed with Exception \n",
      "2023-06-27 18:00:58,131 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1440\n",
      "2023-06-27 18:01:02,360 - \u001b[1;33mWARNING\u001b[1;0m - Request 1393 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fa129754daad1065df8afc6aab8e002a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:08,782 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1459\n",
      "2023-06-27 18:01:11,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 1411 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 888646afd9d0506e657de032e5ffebc9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:13,581 - \u001b[1;33mWARNING\u001b[1;0m - Request 1414 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6a748ffb5a301df35b4587047d389d90 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:16,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 942 failed with Exception \n",
      "2023-06-27 18:01:19,445 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1476\n",
      "2023-06-27 18:01:30,124 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1496\n",
      "2023-06-27 18:01:33,912 - \u001b[1;33mWARNING\u001b[1;0m - Request 1449 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 90a539e0a50e69736d56dcb2bb62119a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:40,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1515\n",
      "2023-06-27 18:01:43,881 - \u001b[1;33mWARNING\u001b[1;0m - Request 1467 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6ba1348f739a42b61fb75dae74651da8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:01:51,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1534\n",
      "2023-06-27 18:01:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1016 failed with Exception \n",
      "2023-06-27 18:02:02,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1553\n",
      "2023-06-27 18:02:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1028 failed with Exception \n",
      "2023-06-27 18:02:09,860 - \u001b[1;33mWARNING\u001b[1;0m - Request 1419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d23de54153172ca060dbbac43f873d12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:02:12,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 1458 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ea4622514daa5134745dc624aa0b6bb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:02:12,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1571\n",
      "2023-06-27 18:02:23,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1590\n",
      "2023-06-27 18:02:34,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1610\n",
      "2023-06-27 18:02:44,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1630\n",
      "2023-06-27 18:02:53,224 - \u001b[1;33mWARNING\u001b[1;0m - Request 1589 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a3ede77ac615a2defd24d64f350f15a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:02:55,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1649\n",
      "2023-06-27 18:02:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1120 failed with Exception \n",
      "2023-06-27 18:03:00,141 - \u001b[1;33mWARNING\u001b[1;0m - Request 1602 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c828c6c1145b1e98d164ee33a3c3dc79 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:06,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1667\n",
      "2023-06-27 18:03:10,281 - \u001b[1;33mWARNING\u001b[1;0m - Request 1621 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6a607eca7905d0f5e0f5ce8491eec778 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:16,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1686\n",
      "2023-06-27 18:03:27,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1706\n",
      "2023-06-27 18:03:28,426 - \u001b[1;33mWARNING\u001b[1;0m - Request 1654 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a054b7d0038cc717908d2e5d577ffe11 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:29,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1172 failed with Exception \n",
      "2023-06-27 18:03:34,305 - \u001b[1;33mWARNING\u001b[1;0m - Request 1663 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b457834e9237fa3dd7b83f9af7e75d03 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:38,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1723\n",
      "2023-06-27 18:03:40,752 - \u001b[1;33mWARNING\u001b[1;0m - Request 1675 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af26317633fadb06dddc010e23eeac4e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:03:48,760 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1742\n",
      "2023-06-27 18:03:59,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1762\n",
      "2023-06-27 18:04:07,857 - \u001b[1;33mWARNING\u001b[1;0m - Request 1722 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8704f941fe3f92bdbd1cacee0d6eda72 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:10,081 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1781\n",
      "2023-06-27 18:04:20,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1801\n",
      "2023-06-27 18:04:22,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1265 failed with Exception \n",
      "2023-06-27 18:04:31,418 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1820\n",
      "2023-06-27 18:04:33,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1287 failed with Exception \n",
      "2023-06-27 18:04:39,308 - \u001b[1;33mWARNING\u001b[1;0m - Request 1779 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6829b89e356ee3ba5288727c4c08e0c8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:42,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1838\n",
      "2023-06-27 18:04:45,199 - \u001b[1;33mWARNING\u001b[1;0m - Request 1790 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 417868533615b961ac6d73b9ce505dd7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:46,253 - \u001b[1;33mWARNING\u001b[1;0m - Request 1792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae551ed7ac37581e1d444cf4cd5123b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:52,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1856\n",
      "2023-06-27 18:04:56,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 1811 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 043c7d5ef69a2238ada9d38cb9dc99d8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:04:59,589 - \u001b[1;33mWARNING\u001b[1;0m - Request 1816 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 875317914c2f900fe8dccc00c857c5c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:01,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 1819 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d72347e3d68e7d6a1baccf1d3f601689 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1340 failed with Exception \n",
      "2023-06-27 18:05:03,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1340\n",
      "2023-06-27 18:05:10,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 1835 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 38137bd7c1691d423955e338a243c0be in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:11,908 - \u001b[1;33mWARNING\u001b[1;0m - Request 1837 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d2631e1817cccd62bd96030b849858a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:14,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1890\n",
      "2023-06-27 18:05:24,711 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1910\n",
      "2023-06-27 18:05:33,190 - \u001b[1;33mWARNING\u001b[1;0m - Request 1872 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 26a8bf9735a80cd151574e16421917b6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:05:35,368 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1929\n",
      "2023-06-27 18:05:46,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1949\n",
      "2023-06-27 18:05:46,481 - \u001b[1;33mWARNING\u001b[1;0m - Request 1894 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0346e4602d89603fa9d2db041f44068c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:50,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 1902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e424d33b7362319516d294645220ff0a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:05:56,687 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1967\n",
      "2023-06-27 18:06:07,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1987\n",
      "2023-06-27 18:06:13,211 - \u001b[1;33mWARNING\u001b[1;0m - Request 1943 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a328ab73919c707e52a80a41985262ec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:14,194 - \u001b[1;33mWARNING\u001b[1;0m - Request 1945 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8189b2f3cee60925c8b2910b3dd01aa0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:15,788 - \u001b[1;33mWARNING\u001b[1;0m - Request 1948 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 030e7386a385bfddde1e1a464a46e6ab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:18,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2004\n",
      "2023-06-27 18:06:28,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2024\n",
      "2023-06-27 18:06:36,050 - \u001b[1;33mWARNING\u001b[1;0m - Request 1984 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9a8a2d30c584b70a36c6ba030d8363c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:39,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2043\n",
      "2023-06-27 18:06:40,848 - \u001b[1;33mWARNING\u001b[1;0m - Request 1993 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a37a32bc91ca50febab988cfb1751c2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:49,912 - \u001b[1;33mWARNING\u001b[1;0m - Request 2007 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 15a91defeef4408d614dbe1558574568 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:06:49,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2062\n",
      "2023-06-27 18:07:00,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2081\n",
      "2023-06-27 18:07:11,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2101\n",
      "2023-06-27 18:07:11,743 - \u001b[1;33mWARNING\u001b[1;0m - Request 1993 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 78fa5c5389d8aaba51b31e0cf6d71d95 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:21,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2120\n",
      "2023-06-27 18:07:28,803 - \u001b[1;33mWARNING\u001b[1;0m - Request 2077 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7fbfb1cb427f78e03b08f4ed8cd2c55e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:32,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2139\n",
      "2023-06-27 18:07:39,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1619 failed with Exception \n",
      "2023-06-27 18:07:43,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2158\n",
      "2023-06-27 18:07:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1629 failed with Exception \n",
      "2023-06-27 18:07:46,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1633 failed with Exception \n",
      "2023-06-27 18:07:49,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1638 failed with Exception \n",
      "2023-06-27 18:07:50,677 - \u001b[1;33mWARNING\u001b[1;0m - Request 2117 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3d08ec77b543c0e49f4d41d72908aca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:07:53,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2174\n",
      "2023-06-27 18:07:58,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 2132 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 44aa081a2917f0e03da69d19bcc1e577 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:04,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2193\n",
      "2023-06-27 18:08:06,271 - \u001b[1;33mWARNING\u001b[1;0m - Request 2145 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID afda0b0f7c6f9ccca49aed35c25cbd5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:15,300 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2212\n",
      "2023-06-27 18:08:25,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2232\n",
      "2023-06-27 18:08:28,031 - \u001b[1;33mWARNING\u001b[1;0m - Request 2181 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6fefca6ad05012084deedbad6d1c25d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:08:33,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1715 failed with Exception \n",
      "2023-06-27 18:08:36,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2250\n",
      "2023-06-27 18:08:47,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2270\n",
      "2023-06-27 18:08:57,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2290\n",
      "2023-06-27 18:09:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1777 failed with Exception \n",
      "2023-06-27 18:09:08,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2309\n",
      "2023-06-27 18:09:19,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2329\n",
      "2023-06-27 18:09:29,954 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2349\n",
      "2023-06-27 18:09:33,110 - \u001b[1;33mWARNING\u001b[1;0m - Request 2299 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 27e9b786d1bbb486a0b8545b95ca71a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:09:40,617 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2368\n",
      "2023-06-27 18:09:51,279 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2388\n",
      "2023-06-27 18:10:01,940 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:10:06,137 - \u001b[1;33mWARNING\u001b[1;0m - Request 2359 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c38f58e968ca88488bcccbaed0310279 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:09,424 - \u001b[1;33mWARNING\u001b[1;0m - Request 2365 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 640cda00abc9a77d8cabaadbd58ba894 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:09,942 - \u001b[1;33mWARNING\u001b[1;0m - Request 2366 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cac363b561f6b423c0fb580f1ee1c3ad in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:12,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2425\n",
      "2023-06-27 18:10:23,270 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2445\n",
      "2023-06-27 18:10:23,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 2392 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 12b19f88546382f3d9be46c47aeb7d68 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:31,192 - \u001b[1;33mWARNING\u001b[1;0m - Request 2406 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f7557a27240a2023a11339b044c0770c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:33,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2463\n",
      "2023-06-27 18:10:34,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1927 failed with Exception \n",
      "2023-06-27 18:10:41,325 - \u001b[1;33mWARNING\u001b[1;0m - Request 2366 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 518fea9f2f83dd8e6b6e2a22a19f0e87 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:10:44,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2481\n",
      "2023-06-27 18:10:55,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2501\n",
      "2023-06-27 18:11:02,782 - \u001b[1;33mWARNING\u001b[1;0m - Request 2460 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7cb1b60d14abbf268483e4ef01967a3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1981 failed with Exception \n",
      "2023-06-27 18:11:05,904 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2519\n",
      "2023-06-27 18:11:06,511 - \u001b[1;33mWARNING\u001b[1;0m - Request 2466 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b80b9a2dec63b7688c6a1a2c734b390 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:11,197 - \u001b[1;33mWARNING\u001b[1;0m - Request 2475 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 04b81f63110429acabfa10e4157a0155 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:16,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2537\n",
      "2023-06-27 18:11:23,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2014 failed with Exception \n",
      "2023-06-27 18:11:27,225 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2556\n",
      "2023-06-27 18:11:29,277 - \u001b[1;33mWARNING\u001b[1;0m - Request 2508 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8e36fd689821ce3bf6153628bbcfaa05 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:29,805 - \u001b[1;33mWARNING\u001b[1;0m - Request 2509 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 29c5fb0223e5cd1744892f8ec6414340 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:37,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2574\n",
      "2023-06-27 18:11:38,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 2523 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d594ec3b420d12568574d30ebf7a3904 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:48,554 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2593\n",
      "2023-06-27 18:11:55,987 - \u001b[1;33mWARNING\u001b[1;0m - Request 2553 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f3ba4f6993cca5989418c0ea0e90d32 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:11:59,219 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2612\n",
      "2023-06-27 18:12:00,733 - \u001b[1;33mWARNING\u001b[1;0m - Request 2509 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2776509853bd83c3ae42246b49a5fc3e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2084 failed with Exception \n",
      "2023-06-27 18:12:09,882 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2630\n",
      "2023-06-27 18:12:20,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2650\n",
      "2023-06-27 18:12:22,067 - \u001b[1;33mWARNING\u001b[1;0m - Request 2599 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 87c4b7ffe943785eaf4904ccdcd960af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:31,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2669\n",
      "2023-06-27 18:12:41,878 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2689\n",
      "2023-06-27 18:12:48,745 - \u001b[1;33mWARNING\u001b[1;0m - Request 2646 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f2d35bbf0aa2bdfc6cda354485c34885 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:12:52,538 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2708\n",
      "2023-06-27 18:12:54,673 - \u001b[1;33mWARNING\u001b[1;0m - Request 2656 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5fd3ed9dbc9354c75b2d3b215b279b60 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:02,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 2670 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0d51aac4c7cdc44009fb2d82587fc2e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:13:03,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2726\n",
      "2023-06-27 18:13:04,787 - \u001b[1;33mWARNING\u001b[1;0m - Request 2675 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cc79ac3584c3cd8c5dcf1860e1ca6e06 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:13,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2745\n",
      "2023-06-27 18:13:15,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2212 failed with Exception \n",
      "2023-06-27 18:13:23,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2227 failed with Exception \n",
      "2023-06-27 18:13:24,515 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2227\n",
      "2023-06-27 18:13:35,177 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2783\n",
      "2023-06-27 18:13:37,235 - \u001b[1;33mWARNING\u001b[1;0m - Request 2732 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5c3baac48f49e335778b47bb9401911c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:13:45,840 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2802\n",
      "2023-06-27 18:13:56,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2822\n",
      "2023-06-27 18:14:02,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2298 failed with Exception \n",
      "2023-06-27 18:14:07,145 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2841\n",
      "2023-06-27 18:14:17,813 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2861\n",
      "2023-06-27 18:14:25,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2339 failed with Exception \n",
      "2023-06-27 18:14:28,456 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2880\n",
      "2023-06-27 18:14:31,718 - \u001b[1;33mWARNING\u001b[1;0m - Request 2831 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4f25182ea79c3946aea91e93e5376066 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:14:39,111 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2899\n",
      "2023-06-27 18:14:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2372 failed with Exception \n",
      "2023-06-27 18:14:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2381 failed with Exception \n",
      "2023-06-27 18:14:49,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2917\n",
      "2023-06-27 18:15:00,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2937\n",
      "2023-06-27 18:15:03,151 - \u001b[1;33mWARNING\u001b[1;0m - Request 2831 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0674b04f2047e050fa07c57791f08974 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:15:11,091 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2956\n",
      "2023-06-27 18:15:12,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 2904 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 22a69526cd26adf442e26a0c1363c4e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:15:21,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2975\n",
      "2023-06-27 18:15:26,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2449 failed with Exception \n",
      "2023-06-27 18:15:32,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2994\n",
      "2023-06-27 18:15:43,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3014\n",
      "2023-06-27 18:15:47,794 - \u001b[1;33mWARNING\u001b[1;0m - Request 2967 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 601d1dcc9dadd9a4464f7e44e1adc954 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:15:53,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3033\n",
      "2023-06-27 18:15:55,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 2981 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6991916e3640401aec9d515d96de353e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:15:55,871 - \u001b[1;33mWARNING\u001b[1;0m - Request 2982 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7fae361aeab2349c9e5baf4678978a2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:16:04,436 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3051\n",
      "2023-06-27 18:16:04,863 - \u001b[1;33mWARNING\u001b[1;0m - Request 2998 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4cd9e00fb005e420dadd666bbff50d1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:16:15,101 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3070\n",
      "2023-06-27 18:16:25,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3090\n",
      "2023-06-27 18:16:36,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3110\n",
      "2023-06-27 18:16:47,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3130\n",
      "2023-06-27 18:16:57,725 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3150\n",
      "2023-06-27 18:17:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2625 failed with Exception \n",
      "2023-06-27 18:17:08,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2625\n",
      "2023-06-27 18:17:19,056 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3189\n",
      "2023-06-27 18:17:29,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3209\n",
      "2023-06-27 18:17:32,291 - \u001b[1;33mWARNING\u001b[1;0m - Request 3158 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5cfc4f6590c82b86785745c281496df5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:40,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3228\n",
      "2023-06-27 18:17:44,013 - \u001b[1;33mWARNING\u001b[1;0m - Request 3179 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6078bc34c01dc7ad09e05e2b32345957 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:48,591 - \u001b[1;33mWARNING\u001b[1;0m - Request 3161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f7c5704358a98b34596bfab7df9acd7e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:50,779 - \u001b[1;33mWARNING\u001b[1;0m - Request 3124 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d57a286fc49c79dbecb10cf2b7f49af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:17:51,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3246\n",
      "2023-06-27 18:17:54,194 - \u001b[1;33mWARNING\u001b[1;0m - Request 3198 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c406712035123b8c6fa7339b9c46b4ed in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:01,710 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:18:07,358 - \u001b[1;33mWARNING\u001b[1;0m - Request 3220 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 814aae4494fa08fa14754cc7ab551cb9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:12,364 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3283\n",
      "2023-06-27 18:18:17,079 - \u001b[1;33mWARNING\u001b[1;0m - Request 3239 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e62aff99b66baa43851c8adb21d78588 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:23,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3302\n",
      "2023-06-27 18:18:32,543 - \u001b[1;33mWARNING\u001b[1;0m - Request 3265 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a09f374546bb103e86d035ea720b2596 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:18:33,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3321\n",
      "2023-06-27 18:18:44,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3341\n",
      "2023-06-27 18:18:55,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3361\n",
      "2023-06-27 18:19:01,989 - \u001b[1;33mWARNING\u001b[1;0m - Request 3318 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 394d4edfc3ea02567229ca2c4e1b5964 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:03,456 - \u001b[1;33mWARNING\u001b[1;0m - Request 3265 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 36e74d3d93adf04d1132581ffb34d1d7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:05,663 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3379\n",
      "2023-06-27 18:19:15,303 - \u001b[1;33mWARNING\u001b[1;0m - Request 3342 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c14cefb9012963027fe30ef00c1574ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:16,313 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3342\n",
      "2023-06-27 18:19:19,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 3350 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dac245c338367a1b17bbb4e44c41b3c4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:26,979 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3417\n",
      "2023-06-27 18:19:37,657 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3437\n",
      "2023-06-27 18:19:38,090 - \u001b[1;33mWARNING\u001b[1;0m - Request 3383 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f3f9835de8f1ea140a597274f3e9deda in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:39,674 - \u001b[1;33mWARNING\u001b[1;0m - Request 3386 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a394edf933766ca1a1b7385475df5cd7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:45,055 - \u001b[1;33mWARNING\u001b[1;0m - Request 3396 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a28ab2b03c464985e2648db2dfe14eb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:48,330 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3454\n",
      "2023-06-27 18:19:58,381 - \u001b[1;33mWARNING\u001b[1;0m - Request 3419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9f615b2039c53145674ce81ec52b69ee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:19:59,029 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3419\n",
      "2023-06-27 18:20:09,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3493\n",
      "2023-06-27 18:20:15,450 - \u001b[1;33mWARNING\u001b[1;0m - Request 3449 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e8dffeee5885c44e74c71102f36e1683 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:20,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3512\n",
      "2023-06-27 18:20:27,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 3471 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4df208faba031b03afb8cd51605a8653 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:31,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3531\n",
      "2023-06-27 18:20:35,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 3485 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f537a9b0563a4d161965883edbe8ff1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:41,688 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3550\n",
      "2023-06-27 18:20:47,476 - \u001b[1;33mWARNING\u001b[1;0m - Request 3506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b81197c864b7837aa4f79d9fa1f43954 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:20:52,351 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3569\n",
      "2023-06-27 18:20:52,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3029 failed with Exception \n",
      "2023-06-27 18:21:03,010 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3588\n",
      "2023-06-27 18:21:04,596 - \u001b[1;33mWARNING\u001b[1;0m - Request 3537 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3ad9c33f9868c81cfcc78ee57c1138af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:08,790 - \u001b[1;33mWARNING\u001b[1;0m - Request 3544 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2fb21d667ff9d9df35050735d63b2ace in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:13,051 - \u001b[1;33mWARNING\u001b[1;0m - Request 3552 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 17a4fac442aa808f4482dc6f869ca6fb in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:21:13,586 - \u001b[1;33mWARNING\u001b[1;0m - Request 3553 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f37c2e7e0a5773e55b56e4e99da0a456 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:13,676 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3552\n",
      "2023-06-27 18:21:17,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 3561 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75e039c4b8fcd08365a32d1aaba127fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:18,412 - \u001b[1;33mWARNING\u001b[1;0m - Request 3506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3294c1d3271190219087f31ea8dd2ec7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:24,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3622\n",
      "2023-06-27 18:21:26,408 - \u001b[1;33mWARNING\u001b[1;0m - Request 3575 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f025bd960e8ba5073b81fed84ecc6e2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:21:35,005 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3641\n",
      "2023-06-27 18:21:45,665 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3661\n",
      "2023-06-27 18:21:56,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3681\n",
      "2023-06-27 18:21:57,331 - \u001b[1;33mWARNING\u001b[1;0m - Request 3575 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 163e5f5d04d1954da9564c56cf1fdf12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:06,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3700\n",
      "2023-06-27 18:22:08,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 3647 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5401c58f0b884becd3f0701c4ef5fc67 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:17,649 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3719\n",
      "2023-06-27 18:22:28,243 - \u001b[1;33mWARNING\u001b[1;0m - Request 3575 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9e5550b5feabde09ae9d9ae247ad5ed in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:28,309 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3739\n",
      "2023-06-27 18:22:33,547 - \u001b[1;33mWARNING\u001b[1;0m - Request 3693 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f80ab5f5ea95276c8d1d8b6fcac67a3e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:38,984 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3757\n",
      "2023-06-27 18:22:48,485 - \u001b[1;33mWARNING\u001b[1;0m - Request 3720 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97a484d74dc9db5f6cdf164bdef961af in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:22:49,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3776\n",
      "2023-06-27 18:22:53,858 - \u001b[1;33mWARNING\u001b[1;0m - Request 3730 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 27db9c9373bc25a4036a306d687ad07c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:00,318 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3795\n",
      "2023-06-27 18:23:09,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3277 failed with Exception \n",
      "2023-06-27 18:23:10,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3814\n",
      "2023-06-27 18:23:21,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3834\n",
      "2023-06-27 18:23:29,726 - \u001b[1;33mWARNING\u001b[1;0m - Request 3793 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5ece6054f402d0122b622911485bb6be in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:31,277 - \u001b[1;33mWARNING\u001b[1;0m - Request 3796 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c07d6124b822a16b33850874181a3648 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:32,265 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3796\n",
      "2023-06-27 18:23:33,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3320 failed with Exception \n",
      "2023-06-27 18:23:33,818 - \u001b[1;33mWARNING\u001b[1;0m - Request 3801 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16827d2bb630088198e9b9c05b2c7389 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:42,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3870\n",
      "2023-06-27 18:23:49,312 - \u001b[1;33mWARNING\u001b[1;0m - Request 3829 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9b07bb5ae62eee2879b14852eda25f0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:23:53,598 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3889\n",
      "2023-06-27 18:24:04,257 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3909\n",
      "2023-06-27 18:24:14,914 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3929\n",
      "2023-06-27 18:24:25,573 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3949\n",
      "2023-06-27 18:24:36,151 - \u001b[1;33mWARNING\u001b[1;0m - Request 3912 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f4a02b1e74501b6177d29f5dcfbaf224 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:36,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3969\n",
      "2023-06-27 18:24:46,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3988\n",
      "2023-06-27 18:24:48,414 - \u001b[1;33mWARNING\u001b[1;0m - Request 3935 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3ab4255bf4daf5e8611c12bc8d4f427f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:24:57,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4007\n",
      "2023-06-27 18:25:00,130 - \u001b[1;33mWARNING\u001b[1;0m - Request 3957 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a47fc1885542ed7ef9e15a83052ddb58 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:25:08,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4026\n",
      "2023-06-27 18:25:09,732 - \u001b[1;33mWARNING\u001b[1;0m - Request 3974 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a592f2953301e0a68186faa3575c905a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:15,599 - \u001b[1;33mWARNING\u001b[1;0m - Request 3985 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 270a0816f52d80bed4672f4570d5e504 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:17,747 - \u001b[1;33mWARNING\u001b[1;0m - Request 3989 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6d65170a30ce71294874a0082a1afacf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:18,888 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4043\n",
      "2023-06-27 18:25:20,985 - \u001b[1;33mWARNING\u001b[1;0m - Request 3994 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 607766e5bb2cb8804055ef187c3086ba in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:24,660 - \u001b[1;33mWARNING\u001b[1;0m - Request 4001 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d52a960b463807244449f7e891a69e32 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:26,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3522 failed with Exception \n",
      "2023-06-27 18:25:29,562 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4060\n",
      "2023-06-27 18:25:31,116 - \u001b[1;33mWARNING\u001b[1;0m - Request 4011 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c60bdf370943f2d8debfe88cb11035b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:36,944 - \u001b[1;33mWARNING\u001b[1;0m - Request 4023 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3fc886f245fa9d8ca75ae51cf3da78fe in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:25:40,220 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4078\n",
      "2023-06-27 18:25:46,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3558 failed with Exception \n",
      "2023-06-27 18:25:50,880 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4097\n",
      "2023-06-27 18:26:01,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4117\n",
      "2023-06-27 18:26:12,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4137\n",
      "2023-06-27 18:26:12,878 - \u001b[1;33mWARNING\u001b[1;0m - Request 4082 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3e1ddd0ff8997cdcfc1896351cb41b4d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:22,900 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4156\n",
      "2023-06-27 18:26:33,553 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4176\n",
      "2023-06-27 18:26:44,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4196\n",
      "2023-06-27 18:26:47,853 - \u001b[1;33mWARNING\u001b[1;0m - Request 4146 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 59febace7ea4c7917d0bb861b656f8d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:54,883 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4215\n",
      "2023-06-27 18:26:55,856 - \u001b[1;33mWARNING\u001b[1;0m - Request 4161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a94311c1bf0a7a714d624b873c01d6bc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:26:59,060 - \u001b[1;33mWARNING\u001b[1;0m - Request 4167 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 447cafdb8244d963d10f10fc1a38fb09 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:05,555 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4233\n",
      "2023-06-27 18:27:16,218 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4253\n",
      "2023-06-27 18:27:26,886 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4273\n",
      "2023-06-27 18:27:37,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4293\n",
      "2023-06-27 18:27:45,970 - \u001b[1;33mWARNING\u001b[1;0m - Request 4252 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 83f3cfa4f6c93b5213bed0a02b5492d6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:48,235 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4312\n",
      "2023-06-27 18:27:57,705 - \u001b[1;33mWARNING\u001b[1;0m - Request 4274 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b4c6343389ce1202baf50897867c37b3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:58,246 - \u001b[1;33mWARNING\u001b[1;0m - Request 4275 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6edfef01ce11ecfbd4d4ccb83d18e180 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:27:58,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4275\n",
      "2023-06-27 18:28:05,750 - \u001b[1;33mWARNING\u001b[1;0m - Request 4289 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b61cb39ec3ead1c9316f34f1f8192e78 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:09,589 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4349\n",
      "2023-06-27 18:28:15,759 - \u001b[1;33mWARNING\u001b[1;0m - Request 4301 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 16ba1c080f2f0f339a3bfbb6cc03c2fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:20,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4368\n",
      "2023-06-27 18:28:27,487 - \u001b[1;33mWARNING\u001b[1;0m - Request 4324 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID be1cf9f62e91b0566b94ed43ab247699 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:30,923 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:28:36,692 - \u001b[1;33mWARNING\u001b[1;0m - Request 4289 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7adda9257afa3562b235ccfcc885454 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:41,588 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4406\n",
      "2023-06-27 18:28:44,792 - \u001b[1;33mWARNING\u001b[1;0m - Request 4357 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9d165dc3ebc443754dbd94129e36c76 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:28:52,248 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4425\n",
      "2023-06-27 18:29:00,175 - \u001b[1;33mWARNING\u001b[1;0m - Request 4385 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 35a662ff14bf870f63c3532434b5b51d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:02,926 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4444\n",
      "2023-06-27 18:29:10,817 - \u001b[1;33mWARNING\u001b[1;0m - Request 4404 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 72d1c15b37ffeddc7a785742f9700ccd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:13,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4463\n",
      "2023-06-27 18:29:16,670 - \u001b[1;33mWARNING\u001b[1;0m - Request 4414 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4899e04b3371b466f89658417cefa80 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:19,349 - \u001b[1;33mWARNING\u001b[1;0m - Request 4419 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c28cecc4781f6013af22b312f50a31e9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:29:24,277 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4481\n",
      "2023-06-27 18:29:34,930 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4501\n",
      "2023-06-27 18:29:45,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4521\n",
      "2023-06-27 18:29:50,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3992 failed with Exception \n",
      "2023-06-27 18:29:56,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4540\n",
      "2023-06-27 18:30:06,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4560\n",
      "2023-06-27 18:30:11,125 - \u001b[1;33mWARNING\u001b[1;0m - Request 4512 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c88fcae3768f6be6617acf6f156a4b1e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:17,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4579\n",
      "2023-06-27 18:30:28,230 - \u001b[1;33mWARNING\u001b[1;0m - Request 4543 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f58c7d1b398cdf8348a7f7f32104f8c7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:28,306 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4599\n",
      "2023-06-27 18:30:33,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4553 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 68e93d120d445ede4a7934e4df47a3e0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:38,986 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4617\n",
      "2023-06-27 18:30:43,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4083 failed with Exception \n",
      "2023-06-27 18:30:46,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 4577 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ac85c25fc4f1528337cb8f147429bdab in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:30:49,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4635\n",
      "2023-06-27 18:31:00,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4655\n",
      "2023-06-27 18:31:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4117 failed with Exception \n",
      "2023-06-27 18:31:09,814 - \u001b[1;33mWARNING\u001b[1;0m - Request 4618 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 10224ea99b0e3596dba2d4dbb22fbcb3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:10,905 - \u001b[1;33mWARNING\u001b[1;0m - Request 4620 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aa41538e5b1cf1ccffd87059b57a740b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:10,983 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4673\n",
      "2023-06-27 18:31:14,637 - \u001b[1;33mWARNING\u001b[1;0m - Request 4083 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 67873fdcbfa862d881b17b1c5f7eaf41 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:21,659 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4691\n",
      "2023-06-27 18:31:32,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4711\n",
      "2023-06-27 18:31:33,301 - \u001b[1;33mWARNING\u001b[1;0m - Request 4660 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c797620148a6d03626fdf1eb8f72a08 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:43,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4730\n",
      "2023-06-27 18:31:46,081 - \u001b[1;33mWARNING\u001b[1;0m - Request 4680 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bb2ea255ae45c338b8e0069c974b9343 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:31:53,663 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4749\n",
      "2023-06-27 18:31:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4214 failed with Exception \n",
      "2023-06-27 18:32:02,627 - \u001b[1;33mWARNING\u001b[1;0m - Request 4711 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7449af1ec2e5ab9ee197909b49f6bc85 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:03,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 4713 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf22ffc0e9e9493fa5f6de8bd83a9da7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:32:04,314 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4767\n",
      "2023-06-27 18:32:09,590 - \u001b[1;33mWARNING\u001b[1;0m - Request 4722 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b14ee79363bcf7ec00b6e0c37ffd08b1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:32:14,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4785\n",
      "2023-06-27 18:32:25,641 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4805\n",
      "2023-06-27 18:32:36,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4825\n",
      "2023-06-27 18:32:46,951 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4845\n",
      "2023-06-27 18:32:57,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4865\n",
      "2023-06-27 18:32:58,066 - \u001b[1;33mWARNING\u001b[1;0m - Request 4809 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c05367d1c80bf66e046b1b53aa6f4b8f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:00,731 - \u001b[1;33mWARNING\u001b[1;0m - Request 4814 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b293236815c9466dd8a9408ef2d24ae1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:08,253 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4883\n",
      "2023-06-27 18:33:18,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4903\n",
      "2023-06-27 18:33:29,584 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4923\n",
      "2023-06-27 18:33:35,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4394 failed with Exception \n",
      "2023-06-27 18:33:40,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4942\n",
      "2023-06-27 18:33:43,872 - \u001b[1;33mWARNING\u001b[1;0m - Request 4893 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 464541dbeee98c4283de1e16877fbac4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:46,577 - \u001b[1;33mWARNING\u001b[1;0m - Request 4898 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05474a4b0cdea686c558f3b9c9b8b30d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:33:47,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4416 failed with Exception \n",
      "2023-06-27 18:33:50,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4959\n",
      "2023-06-27 18:33:51,907 - \u001b[1;33mWARNING\u001b[1;0m - Request 4908 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 254d8e07cfcaef666742f95366ccf266 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:00,407 - \u001b[1;33mWARNING\u001b[1;0m - Request 4924 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ef432e9ac8c74973fb7738a51f238f39 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:01,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4977\n",
      "2023-06-27 18:34:12,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4997\n",
      "2023-06-27 18:34:22,930 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5017\n",
      "2023-06-27 18:34:33,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5037\n",
      "2023-06-27 18:34:42,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 4996 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 072b63474717a3edc3f247a051b2d8c9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:44,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 5000 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f2ab4f4b5dec43a93ada392e37dd03b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:34:44,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5056\n",
      "2023-06-27 18:34:54,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5075\n",
      "2023-06-27 18:34:58,566 - \u001b[1;33mWARNING\u001b[1;0m - Request 5027 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0fa4451ab47a0bb1feba32a996e36032 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:05,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5094\n",
      "2023-06-27 18:35:16,264 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5114\n",
      "2023-06-27 18:35:26,943 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5134\n",
      "2023-06-27 18:35:36,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4612 failed with Exception \n",
      "2023-06-27 18:35:37,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5153\n",
      "2023-06-27 18:35:43,323 - \u001b[1;33mWARNING\u001b[1;0m - Request 4851 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 18:35:48,255 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5172\n",
      "2023-06-27 18:35:51,353 - \u001b[1;33mWARNING\u001b[1;0m - Request 5123 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75e13e6fe34b0ccb499fa3e00c92b914 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:51,907 - \u001b[1;33mWARNING\u001b[1;0m - Request 5124 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID faaf628744d8d3b6908bad8ad3934d31 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:35:58,916 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5190\n",
      "2023-06-27 18:36:04,166 - \u001b[1;33mWARNING\u001b[1;0m - Request 5147 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4e8461dad000333d0c0391e069e5afb0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4667 failed with Exception \n",
      "2023-06-27 18:36:09,500 - \u001b[1;33mWARNING\u001b[1;0m - Request 5156 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 79731d5942bea34616302f7b57dcfd5b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:09,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5208\n",
      "2023-06-27 18:36:16,424 - \u001b[1;33mWARNING\u001b[1;0m - Request 5168 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e9a0817a333b5f93e08eea7a05422882 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:19,614 - \u001b[1;33mWARNING\u001b[1;0m - Request 5174 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b5cb6742219053d1578bbdbcd7bcf412 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:36:20,163 - \u001b[1;33mWARNING\u001b[1;0m - Request 5175 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d926d97fb050dae1ffe00599c17f10d0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:20,227 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5174\n",
      "2023-06-27 18:36:22,284 - \u001b[1;33mWARNING\u001b[1;0m - Request 5123 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 568641fa7e82a72e3f38112cace2cc29 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:30,859 - \u001b[1;33mWARNING\u001b[1;0m - Request 5193 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4fe4ca28cda5b51f363701d5fe589830 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:30,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5243\n",
      "2023-06-27 18:36:41,534 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5262\n",
      "2023-06-27 18:36:48,595 - \u001b[1;33mWARNING\u001b[1;0m - Request 5222 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d58cd4ec19324344e9d65aae927d5cdc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:51,575 - \u001b[1;33mWARNING\u001b[1;0m - Request 5226 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a788a2ca162fc8c1e3c8e0c9e532a79 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:36:52,194 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5226\n",
      "2023-06-27 18:36:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4750 failed with Exception \n",
      "2023-06-27 18:37:02,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5299\n",
      "2023-06-27 18:37:13,515 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5319\n",
      "2023-06-27 18:37:24,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5339\n",
      "2023-06-27 18:37:34,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5359\n",
      "2023-06-27 18:37:37,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4826 failed with Exception \n",
      "2023-06-27 18:37:45,481 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5378\n",
      "2023-06-27 18:37:56,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5398\n",
      "2023-06-27 18:38:00,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4869 failed with Exception \n",
      "2023-06-27 18:38:03,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4873 failed with Exception \n",
      "2023-06-27 18:38:06,804 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5416\n",
      "2023-06-27 18:38:16,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4897 failed with Exception \n",
      "2023-06-27 18:38:17,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4897\n",
      "2023-06-27 18:38:28,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5455\n",
      "2023-06-27 18:38:28,606 - \u001b[1;33mWARNING\u001b[1;0m - Request 5402 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e803a47d151529e48899cb5f24318650 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:38:38,779 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5474\n",
      "2023-06-27 18:38:49,460 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5494\n",
      "2023-06-27 18:39:00,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5514\n",
      "2023-06-27 18:39:10,798 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5534\n",
      "2023-06-27 18:39:21,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5554\n",
      "2023-06-27 18:39:26,172 - \u001b[1;33mWARNING\u001b[1;0m - Request 5506 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a52e3b368cd6fbb4f5b9f4fa64b7999 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:32,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5573\n",
      "2023-06-27 18:39:40,093 - \u001b[1;33mWARNING\u001b[1;0m - Request 5532 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4dcc137a6b5c2af41985e7df5ae29c92 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:42,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5592\n",
      "2023-06-27 18:39:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5055 failed with Exception \n",
      "2023-06-27 18:39:44,844 - \u001b[1;33mWARNING\u001b[1;0m - Request 5541 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f224bff2449d629acc47a8a733ef3b3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:45,434 - \u001b[1;33mWARNING\u001b[1;0m - Request 5542 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b7ed0900c05b753715f4071d8e540a4c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:39:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5063 failed with Exception \n",
      "2023-06-27 18:39:53,459 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5608\n",
      "2023-06-27 18:39:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5082 failed with Exception \n",
      "2023-06-27 18:40:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5087 failed with Exception \n",
      "2023-06-27 18:40:04,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5626\n",
      "2023-06-27 18:40:14,790 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5646\n",
      "2023-06-27 18:40:23,771 - \u001b[1;33mWARNING\u001b[1;0m - Request 5608 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 680a4c83ab368d9b9ec705ac0537f38d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:40:25,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5665\n",
      "2023-06-27 18:40:36,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5685\n",
      "2023-06-27 18:40:46,814 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5705\n",
      "2023-06-27 18:40:55,774 - \u001b[1;33mWARNING\u001b[1;0m - Request 5665 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aeeb48b449d1fb8499b014868e710b00 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:40:57,476 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5724\n",
      "2023-06-27 18:41:01,117 - \u001b[1;33mWARNING\u001b[1;0m - Request 5675 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 41041e3c01449a3725a7ec8c3f059872 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:41:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5195 failed with Exception \n",
      "2023-06-27 18:41:02,684 - \u001b[1;33mWARNING\u001b[1;0m - Request 5678 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c7db216e0e075de7da098cf3150b0c7c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:41:08,143 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5741\n",
      "2023-06-27 18:41:18,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5761\n",
      "2023-06-27 18:41:29,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5781\n",
      "2023-06-27 18:41:40,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5801\n",
      "2023-06-27 18:41:44,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5267 failed with Exception \n",
      "2023-06-27 18:41:47,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5272 failed with Exception \n",
      "2023-06-27 18:41:50,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5819\n",
      "2023-06-27 18:41:51,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 5765 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 337b3332ccc978889e187b5a96113a09 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:01,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5838\n",
      "2023-06-27 18:42:03,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 5787 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8cf519b9818f71f1b235820d7e372fcf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:12,136 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5857\n",
      "2023-06-27 18:42:14,170 - \u001b[1;33mWARNING\u001b[1;0m - Request 5808 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ce3cbb4197bd2b181fc95908a06cfe0b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:22,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5876\n",
      "2023-06-27 18:42:33,468 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5896\n",
      "2023-06-27 18:42:39,249 - \u001b[1;33mWARNING\u001b[1;0m - Request 5851 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 860cd37cc39370005af73f005c2ca5e1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:42:44,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5915\n",
      "2023-06-27 18:42:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5375 failed with Exception \n",
      "2023-06-27 18:42:54,805 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5934\n",
      "2023-06-27 18:43:05,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5954\n",
      "2023-06-27 18:43:06,985 - \u001b[1;33mWARNING\u001b[1;0m - Request 5902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 77d7073a6268b6feb7b18bb943061523 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:14,436 - \u001b[1;33mWARNING\u001b[1;0m - Request 5915 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 14cbfe0645eaf4b76f258db0b02dca80 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:16,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5972\n",
      "2023-06-27 18:43:22,421 - \u001b[1;33mWARNING\u001b[1;0m - Request 5929 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 815166e69f6fc33f74bd1ee6296c5c65 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:26,790 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5991\n",
      "2023-06-27 18:43:37,473 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6011\n",
      "2023-06-27 18:43:46,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5487 failed with Exception \n",
      "2023-06-27 18:43:48,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6030\n",
      "2023-06-27 18:43:56,548 - \u001b[1;33mWARNING\u001b[1;0m - Request 5990 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ff055116ad58508bf23513324f02fb5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:43:58,794 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6049\n",
      "2023-06-27 18:43:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5512 failed with Exception \n",
      "2023-06-27 18:44:08,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5529 failed with Exception \n",
      "2023-06-27 18:44:09,457 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5529\n",
      "2023-06-27 18:44:20,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6087\n",
      "2023-06-27 18:44:24,608 - \u001b[1;33mWARNING\u001b[1;0m - Request 6040 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4812f3460246ffc724685c298776e248 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:30,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6106\n",
      "2023-06-27 18:44:41,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6126\n",
      "2023-06-27 18:44:42,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5591 failed with Exception \n",
      "2023-06-27 18:44:43,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5593 failed with Exception \n",
      "2023-06-27 18:44:52,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6144\n",
      "2023-06-27 18:44:56,823 - \u001b[1;33mWARNING\u001b[1;0m - Request 6098 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2926db08f36cead00c180e98f7b90d94 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:44:58,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 6102 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e59518d8fa7b31945521f06df5d21d1d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:45:02,767 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6162\n",
      "2023-06-27 18:45:13,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6182\n",
      "2023-06-27 18:45:17,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5651 failed with Exception \n",
      "2023-06-27 18:45:24,109 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6201\n",
      "2023-06-27 18:45:34,772 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6221\n",
      "2023-06-27 18:45:44,257 - \u001b[1;33mWARNING\u001b[1;0m - Request 6183 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b66084d50ecb99379460146c1649fe24 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:45:45,453 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6240\n",
      "2023-06-27 18:45:56,094 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6260\n",
      "2023-06-27 18:45:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5723 failed with Exception \n",
      "2023-06-27 18:46:06,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6279\n",
      "2023-06-27 18:46:11,468 - \u001b[1;33mWARNING\u001b[1;0m - Request 6233 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b44af310f79c3e3323cc968bc9bd0d1c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:15,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5753 failed with Exception \n",
      "2023-06-27 18:46:17,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6297\n",
      "2023-06-27 18:46:27,469 - \u001b[1;33mWARNING\u001b[1;0m - Request 6262 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af2e94af6606dd8382c530c9fb913f64 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:46:28,091 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6262\n",
      "2023-06-27 18:46:34,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5790 failed with Exception \n",
      "2023-06-27 18:46:38,754 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6335\n",
      "2023-06-27 18:46:47,375 - \u001b[1;33mWARNING\u001b[1;0m - Request 6296 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fc14a10171a5c9ffacc57df40f1ce4da in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:46:47,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5813 failed with Exception \n",
      "2023-06-27 18:46:49,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6353\n",
      "2023-06-27 18:46:53,608 - \u001b[1;33mWARNING\u001b[1;0m - Request 6308 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1283de31686af437961dcf4212d01eb1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:00,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6372\n",
      "2023-06-27 18:47:06,917 - \u001b[1;33mWARNING\u001b[1;0m - Request 6331 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0fcecb68de5e03ea98c56430b0351808 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:10,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6391\n",
      "2023-06-27 18:47:21,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6411\n",
      "2023-06-27 18:47:29,847 - \u001b[1;33mWARNING\u001b[1;0m - Request 6371 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47a858b44c1ac2c666eb73d65236d159 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:32,080 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6430\n",
      "2023-06-27 18:47:38,909 - \u001b[1;33mWARNING\u001b[1;0m - Request 6387 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5857deca1b6dcad8fe1f4f69011d0b7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:47:42,728 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6449\n",
      "2023-06-27 18:47:53,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6469\n",
      "2023-06-27 18:48:02,377 - \u001b[1;33mWARNING\u001b[1;0m - Request 6430 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47c1feec1661660eaf676370fc009a83 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:04,061 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6488\n",
      "2023-06-27 18:48:14,239 - \u001b[1;33mWARNING\u001b[1;0m - Request 6451 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7d286a17369aceda10010cdeeebf24c4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:14,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6508\n",
      "2023-06-27 18:48:23,701 - \u001b[1;33mWARNING\u001b[1;0m - Request 6469 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9aeb88b64b5e5049eba9ad60b2329dc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:25,289 - \u001b[1;33mWARNING\u001b[1;0m - Request 6472 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d0403d9f1950890f163dde4f86191e6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:25,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6526\n",
      "2023-06-27 18:48:36,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6545\n",
      "2023-06-27 18:48:46,699 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6565\n",
      "2023-06-27 18:48:52,567 - \u001b[1;33mWARNING\u001b[1;0m - Request 6521 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID df83561bce4e5031f27a150327778b94 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:48:57,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6584\n",
      "2023-06-27 18:49:00,456 - \u001b[1;33mWARNING\u001b[1;0m - Request 6534 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 55ef4e92c4d9aa99239e6c458fbd40a5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:00,988 - \u001b[1;33mWARNING\u001b[1;0m - Request 6535 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e73def5f5d742408489d1d6a157b7fb9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:04,212 - \u001b[1;33mWARNING\u001b[1;0m - Request 6541 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e13d98e297d5c995f7e3c15dffe0ef23 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:04,712 - \u001b[1;33mWARNING\u001b[1;0m - Request 6542 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 879c1c1656f7f63c82e2f819490b0138 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:49:08,009 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6600\n",
      "2023-06-27 18:49:18,673 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6620\n",
      "2023-06-27 18:49:29,327 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6640\n",
      "2023-06-27 18:49:39,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6660\n",
      "2023-06-27 18:49:50,656 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6680\n",
      "2023-06-27 18:50:01,317 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6700\n",
      "2023-06-27 18:50:03,356 - \u001b[1;33mWARNING\u001b[1;0m - Request 6647 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 17d2826c267b7e7cdc2fad4a7d688c2c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:06,547 - \u001b[1;33mWARNING\u001b[1;0m - Request 6653 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0ea096beeb6b69e2b4720ca62de837d4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:11,970 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6718\n",
      "2023-06-27 18:50:22,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6738\n",
      "2023-06-27 18:50:23,624 - \u001b[1;33mWARNING\u001b[1;0m - Request 6685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 276db0f504c3afc97b2c22ab087523c5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:50:28,949 - \u001b[1;33mWARNING\u001b[1;0m - Request 6695 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 618b0c23328695bf0222f935c43b94c4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:31,755 - \u001b[1;33mWARNING\u001b[1;0m - Request 6700 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1db4e51c946b281890d90233180704b7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:33,289 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6755\n",
      "2023-06-27 18:50:43,952 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6775\n",
      "2023-06-27 18:50:54,597 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6795\n",
      "2023-06-27 18:50:54,623 - \u001b[1;33mWARNING\u001b[1;0m - Request 6685 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6e4b86eeb4ff5235e1df97ca40e28001 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:50:57,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6261 failed with Exception \n",
      "2023-06-27 18:51:05,247 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6813\n",
      "2023-06-27 18:51:06,781 - \u001b[1;33mWARNING\u001b[1;0m - Request 6761 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5cb1de15f771b100cd038e8436f2e9c5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:11,574 - \u001b[1;33mWARNING\u001b[1;0m - Request 6770 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a84e2943196f3a0a0a1e6fafb89ba03 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:15,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6831\n",
      "2023-06-27 18:51:18,505 - \u001b[1;33mWARNING\u001b[1;0m - Request 6783 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dcb497466205c4374ab296c27edb7b96 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:23,301 - \u001b[1;33mWARNING\u001b[1;0m - Request 6792 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c6303cd981cbcfd3cd9604616d2daf9a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:25,147 - \u001b[1;33mWARNING\u001b[1;0m - Request 6795 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9bb05b1e3cbe4ebd1253ea82dfeb40b6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:26,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6848\n",
      "2023-06-27 18:51:37,219 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6868\n",
      "2023-06-27 18:51:44,842 - \u001b[1;33mWARNING\u001b[1;0m - Request 6828 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID caed750a8a3f76a44e4b7367d8a2aa91 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:47,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6887\n",
      "2023-06-27 18:51:50,919 - \u001b[1;33mWARNING\u001b[1;0m - Request 6835 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5ee71ff40f9ea62b07c28a9bb0ff63a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:51:58,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6906\n",
      "2023-06-27 18:52:09,207 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6926\n",
      "2023-06-27 18:52:19,885 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6946\n",
      "2023-06-27 18:52:25,122 - \u001b[1;33mWARNING\u001b[1;0m - Request 6899 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e0423e30367366120736068bee158232 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:25,962 - \u001b[1;33mWARNING\u001b[1;0m - Request 6900 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 86824716242114e1e9a2e74f7ebfc903 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:26,758 - \u001b[1;33mWARNING\u001b[1;0m - Request 6902 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b0144033d69ec9134614f2e23541630 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:30,555 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6963\n",
      "2023-06-27 18:52:41,213 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6983\n",
      "2023-06-27 18:52:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6460 failed with Exception \n",
      "2023-06-27 18:52:51,786 - \u001b[1;33mWARNING\u001b[1;0m - Request 6949 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cc4ad7bad2bb13674a80a8380f98c9ee in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:51,876 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7002\n",
      "2023-06-27 18:52:56,039 - \u001b[1;33mWARNING\u001b[1;0m - Request 6899 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5d5fb9704592728ee1f8bbebab6ca014 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:52:56,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6474 failed with Exception \n",
      "2023-06-27 18:53:02,537 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7019\n",
      "2023-06-27 18:53:07,251 - \u001b[1;33mWARNING\u001b[1;0m - Request 6975 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 539aeb243d1d0fa02be041b3ac73da8d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:13,210 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7038\n",
      "2023-06-27 18:53:23,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7058\n",
      "2023-06-27 18:53:29,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 7012 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0bf8c79a3963796ce945877077b44fd6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:32,831 - \u001b[1;33mWARNING\u001b[1;0m - Request 7019 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 989315fc0761d7517a137cc82f6f834c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:53:34,544 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7076\n",
      "2023-06-27 18:53:45,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7096\n",
      "2023-06-27 18:53:45,268 - \u001b[1;33mWARNING\u001b[1;0m - Request 7041 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID be084580b841b347dddcd3ac565309a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:48,833 - \u001b[1;33mWARNING\u001b[1;0m - Request 7048 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1cbb3ec3b123ed07407694f4c75f0c06 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:50,488 - \u001b[1;33mWARNING\u001b[1;0m - Request 7051 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ac6f4e05977523474ca2ca5433c31f0f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:53:55,873 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7113\n",
      "2023-06-27 18:54:06,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7133\n",
      "2023-06-27 18:54:17,193 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7153\n",
      "2023-06-27 18:54:21,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 7105 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 35a2a2bdd2834cd60b255ec907ee0df2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:54:27,856 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7172\n",
      "2023-06-27 18:54:38,508 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7192\n",
      "2023-06-27 18:54:49,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7212\n",
      "2023-06-27 18:54:56,031 - \u001b[1;33mWARNING\u001b[1;0m - Request 7168 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d87e1a065d51061320c08565fa28aec3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:54:59,827 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7231\n",
      "2023-06-27 18:55:09,869 - \u001b[1;33mWARNING\u001b[1;0m - Request 7194 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a76bc21e738ccd2aadffa43d18d324ec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:10,491 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7194\n",
      "2023-06-27 18:55:21,141 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7270\n",
      "2023-06-27 18:55:31,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7290\n",
      "2023-06-27 18:55:34,427 - \u001b[1;33mWARNING\u001b[1;0m - Request 7239 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 20a085b5121e889201491392886c7516 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:42,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7309\n",
      "2023-06-27 18:55:43,552 - \u001b[1;33mWARNING\u001b[1;0m - Request 7253 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d4b9eaadcce55559c6448299ec02c7f6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:46,159 - \u001b[1;33mWARNING\u001b[1;0m - Request 7260 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97cf0d9dbebcafb89483ab491d52cb97 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:55:53,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7327\n",
      "2023-06-27 18:55:54,129 - \u001b[1;33mWARNING\u001b[1;0m - Request 7275 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d94576dcbb26823c261c786436fa110 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:01,042 - \u001b[1;33mWARNING\u001b[1;0m - Request 7288 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID abb8f33dbf6e36a93014ed7c564adb9a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:03,768 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7345\n",
      "2023-06-27 18:56:07,955 - \u001b[1;33mWARNING\u001b[1;0m - Request 7300 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6aeaba1e962a18135706e5520c424c14 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:14,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7364\n",
      "2023-06-27 18:56:18,624 - \u001b[1;33mWARNING\u001b[1;0m - Request 7318 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6e68ffc0b5ae331b8b9bb3320f299583 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:25,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7383\n",
      "2023-06-27 18:56:34,080 - \u001b[1;33mWARNING\u001b[1;0m - Request 7345 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c4ad6279a4eacf799bc836867660d23a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:35,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7402\n",
      "2023-06-27 18:56:46,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7422\n",
      "2023-06-27 18:56:51,654 - \u001b[1;33mWARNING\u001b[1;0m - Request 7376 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2a7dbf7ac5bfbc3c4fcccf24fc608ddf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:57,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7441\n",
      "2023-06-27 18:56:57,675 - \u001b[1;33mWARNING\u001b[1;0m - Request 7383 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c5d01f1b3c00b2fca155131d2222030 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:56:58,041 - \u001b[1;33mWARNING\u001b[1;0m - Request 7388 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9fedc3806f7df0a6e5cb8906b1d91f8e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:03,950 - \u001b[1;33mWARNING\u001b[1;0m - Request 7399 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05593c80c482cd90865df8e0f569cc2c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:57:07,718 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7458\n",
      "2023-06-27 18:57:14,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6935 failed with Exception \n",
      "2023-06-27 18:57:18,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7477\n",
      "2023-06-27 18:57:22,004 - \u001b[1;33mWARNING\u001b[1;0m - Request 7432 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0a32e694e5d0c6222c0b56fcc3d10dc5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:29,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7496\n",
      "2023-06-27 18:57:39,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7516\n",
      "2023-06-27 18:57:41,330 - \u001b[1;33mWARNING\u001b[1;0m - Request 7464 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 813222e5b41711ed5c9092f54115ae7d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:57:50,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7535\n",
      "2023-06-27 18:58:01,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7555\n",
      "2023-06-27 18:58:11,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7575\n",
      "2023-06-27 18:58:22,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7595\n",
      "2023-06-27 18:58:33,010 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7615\n",
      "2023-06-27 18:58:43,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7635\n",
      "2023-06-27 18:58:54,357 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7655\n",
      "2023-06-27 18:59:03,281 - \u001b[1;33mWARNING\u001b[1;0m - Request 7614 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 38115a2fa842c0f3b392118beb6f5afc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:05,005 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7674\n",
      "2023-06-27 18:59:13,466 - \u001b[1;33mWARNING\u001b[1;0m - Request 7634 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d366580d9a6fba3dcb344d57616c9b2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:15,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7693\n",
      "2023-06-27 18:59:23,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7105 failed with Exception \n",
      "2023-06-27 18:59:24,645 - \u001b[1;33mWARNING\u001b[1;0m - Request 7655 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7da19af18991330be96ff60027bd3696 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:26,334 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7711\n",
      "2023-06-27 18:59:37,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7731\n",
      "2023-06-27 18:59:41,696 - \u001b[1;33mWARNING\u001b[1;0m - Request 7686 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a48d08e9c16f67992eb3a3cd2b1477c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 18:59:47,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7750\n",
      "2023-06-27 18:59:58,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7770\n",
      "2023-06-27 19:00:00,914 - \u001b[1;33mWARNING\u001b[1;0m - Request 7719 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f3790f322c6ff7282629073fad3d6e5b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:08,891 - \u001b[1;33mWARNING\u001b[1;0m - Request 7734 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a97a160f0cce847389c2e72edf88ba87 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:09,008 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7789\n",
      "2023-06-27 19:00:15,825 - \u001b[1;33mWARNING\u001b[1;0m - Request 7746 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f53a185926713e26fa41f1e894ac959e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:19,682 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7807\n",
      "2023-06-27 19:00:30,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7827\n",
      "2023-06-27 19:00:36,113 - \u001b[1;33mWARNING\u001b[1;0m - Request 7783 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7a5092edb10002409e1a1f0607af0afc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:40,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7305 failed with Exception \n",
      "2023-06-27 19:00:41,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7846\n",
      "2023-06-27 19:00:48,995 - \u001b[1;33mWARNING\u001b[1;0m - Request 7805 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 454608c876091b261e95ecb295c44083 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:00:51,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7864\n",
      "2023-06-27 19:00:55,835 - \u001b[1;33mWARNING\u001b[1;0m - Request 7818 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3c8b7af045bb39e062dc66fac1f7155 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:02,332 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7883\n",
      "2023-06-27 19:01:10,900 - \u001b[1;33mWARNING\u001b[1;0m - Request 7845 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3b333ce65a062f53ad9d3af47ef66c0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:12,985 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7902\n",
      "2023-06-27 19:01:23,647 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7922\n",
      "2023-06-27 19:01:31,055 - \u001b[1;33mWARNING\u001b[1;0m - Request 7880 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e41381ea68e26ee78afb3e60bfc0c205 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:34,305 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7941\n",
      "2023-06-27 19:01:44,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7961\n",
      "2023-06-27 19:01:53,396 - \u001b[1;33mWARNING\u001b[1;0m - Request 7921 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c70d2da059ae0c7094fa83566c8c9069 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:01:55,625 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7980\n",
      "2023-06-27 19:01:57,181 - \u001b[1;33mWARNING\u001b[1;0m - Request 7928 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dd30f848f6b0b1c5b861d508ce4bfa8e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:02:06,291 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7999\n",
      "2023-06-27 19:02:07,256 - \u001b[1;33mWARNING\u001b[1;0m - Request 7946 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7e1f44aff62569341ef68c5fca56a27 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:09,431 - \u001b[1;33mWARNING\u001b[1;0m - Request 7950 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9c579e9e4ccdec13fe4a6e5e6d572a5e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:16,944 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8017\n",
      "2023-06-27 19:02:25,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7489 failed with Exception \n",
      "2023-06-27 19:02:27,050 - \u001b[1;33mWARNING\u001b[1;0m - Request 7776 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 19:02:27,600 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7776\n",
      "2023-06-27 19:02:38,271 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8055\n",
      "2023-06-27 19:02:41,423 - \u001b[1;33mWARNING\u001b[1;0m - Request 8006 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 67b0557d62764042eb7725d1570b2cbc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7521 failed with Exception \n",
      "2023-06-27 19:02:44,035 - \u001b[1;33mWARNING\u001b[1;0m - Request 8011 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d4bdd1ee3e394e30d96c53c04668c5d3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:48,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8072\n",
      "2023-06-27 19:02:59,497 - \u001b[1;33mWARNING\u001b[1;0m - Request 8038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3f929b90813bd2bc4ba8993ad556a54 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:02:59,596 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8092\n",
      "2023-06-27 19:03:00,024 - \u001b[1;33mWARNING\u001b[1;0m - Request 8039 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3907aae21a3ae6c7494f4e2f74740f28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:09,623 - \u001b[1;33mWARNING\u001b[1;0m - Request 8057 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b4f0b2281cf09d4c7ff90fb85ace9df in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:10,275 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8057\n",
      "2023-06-27 19:03:20,935 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8129\n",
      "2023-06-27 19:03:24,140 - \u001b[1;33mWARNING\u001b[1;0m - Request 8081 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 099b2880520476a64ddbf38593ba3c3e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:03:31,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8148\n",
      "2023-06-27 19:03:42,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8168\n",
      "2023-06-27 19:03:52,915 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8188\n",
      "2023-06-27 19:03:56,570 - \u001b[1;33mWARNING\u001b[1;0m - Request 8138 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6114504782b1292781fbc257f9488cc3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:04:03,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8207\n",
      "2023-06-27 19:04:14,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8227\n",
      "2023-06-27 19:04:24,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8247\n",
      "2023-06-27 19:04:32,275 - \u001b[1;33mWARNING\u001b[1;0m - Request 8204 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1ecb8d58f2baf806f6d77a2c0f72850f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:04:35,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8266\n",
      "2023-06-27 19:04:41,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 8221 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 743301f76c52cd5c0b76d5cf8f749792 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:04:46,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8285\n",
      "2023-06-27 19:04:56,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8305\n",
      "2023-06-27 19:05:00,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 8257 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56fdb75023c0f959672ea821822e46d4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:03,186 - \u001b[1;33mWARNING\u001b[1;0m - Request 8204 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 44f1a75b1f19ac327b905c4e9b068eb5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:07,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8323\n",
      "2023-06-27 19:05:18,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8343\n",
      "2023-06-27 19:05:20,618 - \u001b[1;33mWARNING\u001b[1;0m - Request 8229 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 19:05:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7809 failed with Exception \n",
      "2023-06-27 19:05:22,923 - \u001b[1;33mWARNING\u001b[1;0m - Request 8297 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ae318553bf54c1152e3e53c9d178dd4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:27,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7821 failed with Exception \n",
      "2023-06-27 19:05:28,907 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8359\n",
      "2023-06-27 19:05:33,044 - \u001b[1;33mWARNING\u001b[1;0m - Request 8315 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bb00de8ece24fa73e6cf2035bfda9dde in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:33,572 - \u001b[1;33mWARNING\u001b[1;0m - Request 8316 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff92c73c9fc2fd8c6fec6ce17c962849 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:05:36,802 - \u001b[1;33mWARNING\u001b[1;0m - Request 8321 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b9920053ff4d394dfaf0501cc254ecf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:38,386 - \u001b[1;33mWARNING\u001b[1;0m - Request 8324 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8c4478eb58ffa3db95e3c42a2b372e35 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:05:39,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8375\n",
      "2023-06-27 19:05:50,228 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8395\n",
      "2023-06-27 19:05:51,191 - \u001b[1;33mWARNING\u001b[1;0m - Request 8348 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 634f20fdba714ad538cb8626b2fc6a28 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:00,903 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8414\n",
      "2023-06-27 19:06:05,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7888 failed with Exception \n",
      "2023-06-27 19:06:11,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8433\n",
      "2023-06-27 19:06:17,340 - \u001b[1;33mWARNING\u001b[1;0m - Request 8389 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 61b9ec79413a6d33ceb2de218a7dab30 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:22,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8452\n",
      "2023-06-27 19:06:25,323 - \u001b[1;33mWARNING\u001b[1;0m - Request 8403 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 66deb79d455a5f8f04f11601f50c1250 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:06:26,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7927 failed with Exception \n",
      "2023-06-27 19:06:32,902 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8470\n",
      "2023-06-27 19:06:43,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8490\n",
      "2023-06-27 19:06:54,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8510\n",
      "2023-06-27 19:06:54,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7921 failed with Exception \n",
      "2023-06-27 19:07:04,892 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8529\n",
      "2023-06-27 19:07:08,558 - \u001b[1;33mWARNING\u001b[1;0m - Request 8480 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 67156f971eafdeebbf560c97cd87efa9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:13,335 - \u001b[1;33mWARNING\u001b[1;0m - Request 8489 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 15afb600c371339875ff40b2713896e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:15,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8547\n",
      "2023-06-27 19:07:26,190 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8567\n",
      "2023-06-27 19:07:31,994 - \u001b[1;33mWARNING\u001b[1;0m - Request 8523 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dd88e815ad46c839b19bb229c312b2a0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:36,838 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8586\n",
      "2023-06-27 19:07:47,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8606\n",
      "2023-06-27 19:07:50,156 - \u001b[1;33mWARNING\u001b[1;0m - Request 8555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 81630be0eeb23fe6ffd5cf8be0a72fc9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:52,783 - \u001b[1;33mWARNING\u001b[1;0m - Request 8560 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e6712b7da104b1b35c9748adbd79e9ec in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:53,337 - \u001b[1;33mWARNING\u001b[1;0m - Request 8561 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5aa3b03b2eec5e6c57c141700f150226 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:07:58,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8623\n",
      "2023-06-27 19:08:03,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 8580 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 72d9dab95ff64f3085c05563c5cf7185 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:08,834 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8642\n",
      "2023-06-27 19:08:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8113 failed with Exception \n",
      "2023-06-27 19:08:15,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8118 failed with Exception \n",
      "2023-06-27 19:08:19,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8660\n",
      "2023-06-27 19:08:20,997 - \u001b[1;33mWARNING\u001b[1;0m - Request 8555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c1c87187bd3830264f6cb41caebb2305 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:30,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8679\n",
      "2023-06-27 19:08:33,254 - \u001b[1;33mWARNING\u001b[1;0m - Request 8632 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b0f4c8e9b72b25d78ebe0743c1a21d9b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:37,399 - \u001b[1;33mWARNING\u001b[1;0m - Request 8635 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4a9efb71034e4c1c2ff2fee4edd8d306 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:38,610 - \u001b[1;33mWARNING\u001b[1;0m - Request 8641 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db60da2c239956b4c4770a5ad5f078d9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:08:40,791 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8696\n",
      "2023-06-27 19:08:51,451 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8716\n",
      "2023-06-27 19:09:02,150 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8736\n",
      "2023-06-27 19:09:12,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8756\n",
      "2023-06-27 19:09:23,474 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:09:34,123 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8796\n",
      "2023-06-27 19:09:44,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8816\n",
      "2023-06-27 19:09:46,836 - \u001b[1;33mWARNING\u001b[1;0m - Request 8763 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b34da0d7eb2b0bc72a3323c36293fb64 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:09:48,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8288 failed with Exception \n",
      "2023-06-27 19:09:55,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8834\n",
      "2023-06-27 19:10:06,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8854\n",
      "2023-06-27 19:10:09,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8326 failed with Exception \n",
      "2023-06-27 19:10:13,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8334 failed with Exception \n",
      "2023-06-27 19:10:16,744 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8872\n",
      "2023-06-27 19:10:27,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8892\n",
      "2023-06-27 19:10:28,026 - \u001b[1;33mWARNING\u001b[1;0m - Request 8838 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd76054a80a3305a52708c9a41f1e469 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:10:38,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8911\n",
      "2023-06-27 19:10:42,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8380 failed with Exception \n",
      "2023-06-27 19:10:48,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8930\n",
      "2023-06-27 19:10:57,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8407 failed with Exception \n",
      "2023-06-27 19:10:58,769 - \u001b[1;33mWARNING\u001b[1;0m - Request 8894 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 144ed50050fa683d1185cf1a2d10458a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:10:59,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8894\n",
      "2023-06-27 19:11:09,979 - \u001b[1;33mWARNING\u001b[1;0m - Request 8914 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 43118961bef5220cb0f8f5a4bc50eded in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:10,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8968\n",
      "2023-06-27 19:11:11,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8431 failed with Exception \n",
      "2023-06-27 19:11:18,002 - \u001b[1;33mWARNING\u001b[1;0m - Request 8928 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d2614dc3d8a901b85c07dcfe0ad1f1cf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:20,719 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8985\n",
      "2023-06-27 19:11:31,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9005\n",
      "2023-06-27 19:11:42,058 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9025\n",
      "2023-06-27 19:11:42,528 - \u001b[1;33mWARNING\u001b[1;0m - Request 8431 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7d4c187b69ed60daa5d57f587bacf31a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:11:52,740 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9044\n",
      "2023-06-27 19:12:03,404 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9064\n",
      "2023-06-27 19:12:11,846 - \u001b[1;33mWARNING\u001b[1;0m - Request 9024 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 230ddfff32286a0a02e57befb7e22519 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:14,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9083\n",
      "2023-06-27 19:12:19,830 - \u001b[1;33mWARNING\u001b[1;0m - Request 9038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7b44e657dfc67ecfa5d2b471a5f1bb10 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:24,740 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9102\n",
      "2023-06-27 19:12:35,400 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9122\n",
      "2023-06-27 19:12:46,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9142\n",
      "2023-06-27 19:12:50,801 - \u001b[1;33mWARNING\u001b[1;0m - Request 9038 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 680e2bc6c8de096a09ba3bcae1e4429b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:12:56,704 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9161\n",
      "2023-06-27 19:13:07,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9181\n",
      "2023-06-27 19:13:12,671 - \u001b[1;33mWARNING\u001b[1;0m - Request 9135 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0cb134f3bbf050d1960c461242f426e2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:18,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9200\n",
      "2023-06-27 19:13:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8663 failed with Exception \n",
      "2023-06-27 19:13:26,990 - \u001b[1;33mWARNING\u001b[1;0m - Request 9161 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 51b3aca368ac995cc5c3169667d9bef2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:28,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9218\n",
      "2023-06-27 19:13:39,381 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9238\n",
      "2023-06-27 19:13:39,811 - \u001b[1;33mWARNING\u001b[1;0m - Request 9185 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f10e7e5eefe90839a00e7cdd0e35cb1e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:13:50,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9257\n",
      "2023-06-27 19:13:58,477 - \u001b[1;33mWARNING\u001b[1;0m - Request 9217 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff820439e6f6e03cec5d627e2e9fc378 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:14:00,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9276\n",
      "2023-06-27 19:14:00,820 - \u001b[1;33mWARNING\u001b[1;0m - Request 9221 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ed93597dee5cee360b38bb8d36d66f85 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:14:11,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9295\n",
      "2023-06-27 19:14:22,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9315\n",
      "2023-06-27 19:14:32,708 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9335\n",
      "2023-06-27 19:14:43,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9355\n",
      "2023-06-27 19:14:54,047 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:15:04,328 - \u001b[1;33mWARNING\u001b[1;0m - Request 9288 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 34f6da44aec470ec8bb9c51890c6be08 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:04,534 - \u001b[1;33mWARNING\u001b[1;0m - Request 9293 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff1ef0ed77fed46ebe1f36fc2061f5f1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:04,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9395\n",
      "2023-06-27 19:15:06,254 - \u001b[1;33mWARNING\u001b[1;0m - Request 9341 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 643f3297934bb2e0bd8689112cf42604 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:10,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 9349 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7d76701bb704bc0f7716aee93adfccf in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:13,149 - \u001b[1;33mWARNING\u001b[1;0m - Request 9354 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d0454e9cebca7da408fa964b5c1260c6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:15,356 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9410\n",
      "2023-06-27 19:15:26,014 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9430\n",
      "2023-06-27 19:15:36,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9450\n",
      "2023-06-27 19:15:38,716 - \u001b[1;33mWARNING\u001b[1;0m - Request 9399 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2206756494626681cf052cd43fe1bbb5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:45,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 9409 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8a843dcdb4583aed77dd02aeb9d3284c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:47,349 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9468\n",
      "2023-06-27 19:15:49,934 - \u001b[1;33mWARNING\u001b[1;0m - Request 9418 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 28840fd3f26c16f9ee2ef4217ba9b50d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:15:58,014 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9487\n",
      "2023-06-27 19:15:58,964 - \u001b[1;33mWARNING\u001b[1;0m - Request 9435 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b0b6533a32e0c490d70add96b2507418 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:08,679 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9506\n",
      "2023-06-27 19:16:11,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 9455 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fcd861f6fcac852ef517ede8a1baaf6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:19,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9525\n",
      "2023-06-27 19:16:24,587 - \u001b[1;33mWARNING\u001b[1;0m - Request 9480 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7c6c6e3fa8a0fc4c44267d386dade809 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:30,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9544\n",
      "2023-06-27 19:16:34,182 - \u001b[1;33mWARNING\u001b[1;0m - Request 9497 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 52e0299f3ca0618bb1f8681d92a95297 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:16:40,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9563\n",
      "2023-06-27 19:16:51,325 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9583\n",
      "2023-06-27 19:17:01,973 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9603\n",
      "2023-06-27 19:17:02,045 - \u001b[1;33mWARNING\u001b[1;0m - Request 9547 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 79ce2d5fb3cf8950f8b375dcacb63b93 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:12,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9622\n",
      "2023-06-27 19:17:23,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9642\n",
      "2023-06-27 19:17:33,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9662\n",
      "2023-06-27 19:17:44,622 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9682\n",
      "2023-06-27 19:17:55,185 - \u001b[1;33mWARNING\u001b[1;0m - Request 9645 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 90750ccd474c8959b0e25c1fe5238ff8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:55,285 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9702\n",
      "2023-06-27 19:17:57,321 - \u001b[1;33mWARNING\u001b[1;0m - Request 9649 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 37e3044a3722a93616b67be69e99e212 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:17:58,388 - \u001b[1;33mWARNING\u001b[1;0m - Request 9651 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 60a5e4b28b1b473a1079f7248ff89603 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:05,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9719\n",
      "2023-06-27 19:18:10,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 9673 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 715e1d0c032e9c799c6154c0f2fd9db6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:16,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9738\n",
      "2023-06-27 19:18:18,115 - \u001b[1;33mWARNING\u001b[1;0m - Request 9688 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 239b521ac1701cb12e154bf6c9b4463b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:18:22,380 - \u001b[1;33mWARNING\u001b[1;0m - Request 9696 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e5330460febf356b10fecb028bfb65a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:27,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9756\n",
      "2023-06-27 19:18:28,264 - \u001b[1;33mWARNING\u001b[1;0m - Request 9649 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 082fd227e7820a6da5fc6da9127f862b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:28,795 - \u001b[1;33mWARNING\u001b[1;0m - Request 9706 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 837b9ce0e166f2c6e1d74abc2f0b4ad3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:30,917 - \u001b[1;33mWARNING\u001b[1;0m - Request 9709 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 59f3becb7500c4b30cf4818aa21d4e74 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:18:37,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9773\n",
      "2023-06-27 19:18:48,612 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9793\n",
      "2023-06-27 19:18:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9268 failed with Exception \n",
      "2023-06-27 19:18:59,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9812\n",
      "2023-06-27 19:19:04,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9281 failed with Exception \n",
      "2023-06-27 19:19:09,945 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9831\n",
      "2023-06-27 19:19:20,623 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9851\n",
      "2023-06-27 19:19:31,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9871\n",
      "2023-06-27 19:19:41,953 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9891\n",
      "2023-06-27 19:19:51,630 - \u001b[1;33mWARNING\u001b[1;0m - Request 9852 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6df7d4079155234a9083b4f90585e983 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:19:52,613 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9852\n",
      "2023-06-27 19:20:03,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9930\n",
      "2023-06-27 19:20:12,267 - \u001b[1;33mWARNING\u001b[1;0m - Request 9891 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ac85fc3439fef9378c54b5b693aa193c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:13,940 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9949\n",
      "2023-06-27 19:20:19,232 - \u001b[1;33mWARNING\u001b[1;0m - Request 9904 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c6b8d9f7d0900682d4aeb95e9c164bd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9422 failed with Exception \n",
      "2023-06-27 19:20:24,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9967\n",
      "2023-06-27 19:20:27,690 - \u001b[1;33mWARNING\u001b[1;0m - Request 9919 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4719b546db3aad5755289618dd833188 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:20:35,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9986\n",
      "2023-06-27 19:20:45,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10006\n",
      "2023-06-27 19:20:56,594 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10026\n",
      "2023-06-27 19:21:03,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9496 failed with Exception \n",
      "2023-06-27 19:21:05,016 - \u001b[1;33mWARNING\u001b[1;0m - Request 9985 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8251101125e55eb6ce100daa7f16169 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:05,626 - \u001b[1;33mWARNING\u001b[1;0m - Request 9986 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1049ee2cb7dac74f7974023a62a4f9f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:07,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10043\n",
      "2023-06-27 19:21:10,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9509 failed with Exception \n",
      "2023-06-27 19:21:17,918 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10062\n",
      "2023-06-27 19:21:20,485 - \u001b[1;33mWARNING\u001b[1;0m - Request 10014 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8eb8f0bdd491ad690dec7f3e98944866 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:23,126 - \u001b[1;33mWARNING\u001b[1;0m - Request 10017 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID edd961717102066a7e39d46eb0ad196a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:28,581 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10080\n",
      "2023-06-27 19:21:39,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10100\n",
      "2023-06-27 19:21:42,354 - \u001b[1;33mWARNING\u001b[1;0m - Request 10051 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 44ec46132e389e14e40434ca3d1fb684 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:21:49,927 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10119\n",
      "2023-06-27 19:21:51,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9583 failed with Exception \n",
      "2023-06-27 19:22:00,586 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10138\n",
      "2023-06-27 19:22:02,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9603 failed with Exception \n",
      "2023-06-27 19:22:09,010 - \u001b[1;33mWARNING\u001b[1;0m - Request 10099 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 296bfce3647c581d5b0b29a064b16f6c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:11,250 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10156\n",
      "2023-06-27 19:22:21,081 - \u001b[1;33mWARNING\u001b[1;0m - Request 10120 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ce1fa9a233a744f1b747ab0fe7512551 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:21,912 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10120\n",
      "2023-06-27 19:22:24,534 - \u001b[1;33mWARNING\u001b[1;0m - Request 10126 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ca63037275465d9a8fe83a551aee28f5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:22:32,569 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10194\n",
      "2023-06-27 19:22:37,899 - \u001b[1;33mWARNING\u001b[1;0m - Request 10150 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1dfdab0e6d6abdeaffac5ef83438c51d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:22:43,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10213\n",
      "2023-06-27 19:22:53,892 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10233\n",
      "2023-06-27 19:22:56,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10182 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f5f0aef00039e7c1f96c0b783135029 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:00,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 10189 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dc2ebde90b3cb0f8e1a8fdbeb4a80a95 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:01,830 - \u001b[1;33mWARNING\u001b[1;0m - Request 10192 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a1457beef25ae13bd66dfdbf22a3be10 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:04,546 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10250\n",
      "2023-06-27 19:23:06,073 - \u001b[1;33mWARNING\u001b[1;0m - Request 10200 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff2d615304d4a293e935f35f2c3f1815 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:15,208 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10269\n",
      "2023-06-27 19:23:25,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10289\n",
      "2023-06-27 19:23:34,839 - \u001b[1;33mWARNING\u001b[1;0m - Request 10250 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 673bfeec721c6aa102bd24fd537a2f83 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:36,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9770 failed with Exception \n",
      "2023-06-27 19:23:36,531 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10308\n",
      "2023-06-27 19:23:39,103 - \u001b[1;33mWARNING\u001b[1;0m - Request 10257 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a9a264468c3454fa257bdbf543c8142c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:47,200 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10326\n",
      "2023-06-27 19:23:52,452 - \u001b[1;33mWARNING\u001b[1;0m - Request 10282 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 424ad123ff3cfff7cd0da228edc6b6fd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:23:57,877 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10345\n",
      "2023-06-27 19:24:08,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10365\n",
      "2023-06-27 19:24:19,202 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10385\n",
      "2023-06-27 19:24:25,384 - \u001b[1;33mWARNING\u001b[1;0m - Request 10282 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 883a21e8546d5ef309730f3108ba65ea in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:27,811 - \u001b[1;33mWARNING\u001b[1;0m - Request 10344 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e79a3c77d173538acf1556381f0d3518 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:29,866 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10403\n",
      "2023-06-27 19:24:33,499 - \u001b[1;33mWARNING\u001b[1;0m - Request 10355 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 81c0012d1abcbacc195d475f88ebbc09 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:24:40,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10422\n",
      "2023-06-27 19:24:51,189 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10442\n",
      "2023-06-27 19:25:01,851 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10462\n",
      "2023-06-27 19:25:02,283 - \u001b[1;33mWARNING\u001b[1;0m - Request 10407 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4977d1d713d77e7efea1208c042479a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:12,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10481\n",
      "2023-06-27 19:25:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9958 failed with Exception \n",
      "2023-06-27 19:25:22,616 - \u001b[1;33mWARNING\u001b[1;0m - Request 10444 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 117baaaa5147fa91af68c9ad765d9c53 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:23,186 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10444\n",
      "2023-06-27 19:25:33,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10519\n",
      "2023-06-27 19:25:39,622 - \u001b[1;33mWARNING\u001b[1;0m - Request 10475 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 732075a0d3a0bd172af43b37c14dc39c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:44,529 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10538\n",
      "2023-06-27 19:25:44,960 - \u001b[1;33mWARNING\u001b[1;0m - Request 10485 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4c77461358cf0dbc9fd0ec416717662f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:46,545 - \u001b[1;33mWARNING\u001b[1;0m - Request 10488 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2067ef862e810f7b06b35273c224262c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:25:47,621 - \u001b[1;33mWARNING\u001b[1;0m - Request 10490 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e0459352b189eefeebca85747c89690f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:25:55,191 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10555\n",
      "2023-06-27 19:25:58,275 - \u001b[1;33mWARNING\u001b[1;0m - Request 10508 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a2e68494f2c3c0ba2167f4bb12c728e1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:05,836 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10574\n",
      "2023-06-27 19:26:12,331 - \u001b[1;33mWARNING\u001b[1;0m - Request 10533 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0fa06582ed94e82a55eb51cff3b963e3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:16,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10593\n",
      "2023-06-27 19:26:23,545 - \u001b[1;33mWARNING\u001b[1;0m - Request 10551 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd179292a19b43d3a3a8e00762e5033d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:25,478 - \u001b[1;33mWARNING\u001b[1;0m - Request 10555 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b64b4663fea63f10cca467871131619 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:27,170 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10611\n",
      "2023-06-27 19:26:37,831 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10631\n",
      "2023-06-27 19:26:44,667 - \u001b[1;33mWARNING\u001b[1;0m - Request 10589 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f3f660869c9b2c40d667b90ee783fd12 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:48,490 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10650\n",
      "2023-06-27 19:26:49,518 - \u001b[1;33mWARNING\u001b[1;0m - Request 10598 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e69a6a3831cc1f18e2b097d2f373728c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:58,200 - \u001b[1;33mWARNING\u001b[1;0m - Request 10610 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1d30ae019291ad58d2c70cb428834cb0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:26:59,152 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10610\n",
      "2023-06-27 19:27:09,811 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10688\n",
      "2023-06-27 19:27:20,476 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10708\n",
      "2023-06-27 19:27:29,971 - \u001b[1;33mWARNING\u001b[1;0m - Request 10669 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d8501f1745344fcd6ff0b4a901b4da7f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:27:31,135 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10727\n",
      "2023-06-27 19:27:41,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10747\n",
      "2023-06-27 19:27:52,467 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10767\n",
      "2023-06-27 19:28:03,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10787\n",
      "2023-06-27 19:28:05,910 - \u001b[1;33mWARNING\u001b[1;0m - Request 10735 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7df2bc9767d27abca77e6eedc866e21e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:06,762 - \u001b[1;33mWARNING\u001b[1;0m - Request 10737 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f6bdc17de9e6aea2a770d68fe23f289c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:13,797 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10805\n",
      "2023-06-27 19:28:15,332 - \u001b[1;33mWARNING\u001b[1;0m - Request 10753 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1873f0ee68fb098164c2b3ed1360906f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:19,039 - \u001b[1;33mWARNING\u001b[1;0m - Request 10760 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2ba4458dddc656e47bb1403c695af9ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:24,455 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10823\n",
      "2023-06-27 19:28:28,609 - \u001b[1;33mWARNING\u001b[1;0m - Request 10778 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b83881fa6ce29e8b1182d3703e655c47 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:35,115 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10842\n",
      "2023-06-27 19:28:40,988 - \u001b[1;33mWARNING\u001b[1;0m - Request 10799 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 670dc19f3d27b72024d6520c725500f0 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:28:45,776 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10861\n",
      "2023-06-27 19:28:56,452 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10881\n",
      "2023-06-27 19:29:02,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 10836 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 70b0ce4c5650bfd76a3e80abb39b7cbc in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:07,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10900\n",
      "2023-06-27 19:29:15,533 - \u001b[1;33mWARNING\u001b[1;0m - Request 10860 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 257bafd7f7f3f05db51ea766982b3a56 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:17,789 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10919\n",
      "2023-06-27 19:29:28,464 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10939\n",
      "2023-06-27 19:29:37,945 - \u001b[1;33mWARNING\u001b[1;0m - Request 10901 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eef0dd4e46a4a7ad5b2378c5e0b7a9cd in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:39,124 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:29:40,607 - \u001b[1;33mWARNING\u001b[1;0m - Request 10906 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76d41f97210be0853a178d37b06db02f in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:29:49,804 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10977\n",
      "2023-06-27 19:30:00,459 - \u001b[1;32mINFO\u001b[1;0m - Starting request #10997\n",
      "2023-06-27 19:30:11,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11017\n",
      "2023-06-27 19:30:21,786 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11037\n",
      "2023-06-27 19:30:32,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11057\n",
      "2023-06-27 19:30:43,121 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11077\n",
      "2023-06-27 19:30:48,409 - \u001b[1;33mWARNING\u001b[1;0m - Request 11030 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ae5f6c2eac44ab59b06dcdc296cfcae3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:30:53,775 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11096\n",
      "2023-06-27 19:31:04,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11116\n",
      "2023-06-27 19:31:15,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11136\n",
      "2023-06-27 19:31:20,352 - \u001b[1;33mWARNING\u001b[1;0m - Request 11089 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c4e7f7ec762c9c9252648489b64310b4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:31:25,769 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11155\n",
      "2023-06-27 19:31:31,107 - \u001b[1;33mWARNING\u001b[1;0m - Request 11109 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 22bced50334bb3118b4963dbbcd8312d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:31:31,538 - \u001b[1;33mWARNING\u001b[1;0m - Request 11110 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7085654976a41420f4bfa8c04344f448 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:31:32,703 - \u001b[1;33mWARNING\u001b[1;0m - Request 11112 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 71e173aef1726e99010c9a54648e4a08 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:31:36,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11172\n",
      "2023-06-27 19:31:47,098 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11192\n",
      "2023-06-27 19:31:48,544 - \u001b[1;33mWARNING\u001b[1;0m - Request 11140 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3ccaced99f04e2cbd69ab162cae7965 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:31:57,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11211\n",
      "2023-06-27 19:31:58,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10667 failed with Exception \n",
      "2023-06-27 19:32:08,431 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11230\n",
      "2023-06-27 19:32:18,996 - \u001b[1;33mWARNING\u001b[1;0m - Request 11195 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 40c8fcd971dbcc478a7df58268a32fc5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:19,104 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11250\n",
      "2023-06-27 19:32:29,761 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11269\n",
      "2023-06-27 19:32:30,231 - \u001b[1;33mWARNING\u001b[1;0m - Request 11214 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e5dfdca08424c836feef4bf139bd00a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:40,419 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11288\n",
      "2023-06-27 19:32:46,205 - \u001b[1;33mWARNING\u001b[1;0m - Request 11244 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 263398bb1ad665e6786b1f5f1994acff in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:32:51,100 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11307\n",
      "2023-06-27 19:32:59,547 - \u001b[1;33mWARNING\u001b[1;0m - Request 11268 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 305d5db6d7f914149041e4f5ab9530a4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:01,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11326\n",
      "2023-06-27 19:33:03,776 - \u001b[1;33mWARNING\u001b[1;0m - Request 11275 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5dafa6cc776ec5f56b1326a626137e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:07,658 - \u001b[1;33mWARNING\u001b[1;0m - Request 11282 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0c4a5a927d72260d6ad7adc811acc043 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:12,416 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11344\n",
      "2023-06-27 19:33:23,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11364\n",
      "2023-06-27 19:33:33,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11384\n",
      "2023-06-27 19:33:37,918 - \u001b[1;33mWARNING\u001b[1;0m - Request 11336 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d34bd1ddca998400b5c814e94c4a3b1d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:44,414 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11403\n",
      "2023-06-27 19:33:55,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11423\n",
      "2023-06-27 19:33:58,173 - \u001b[1;33mWARNING\u001b[1;0m - Request 11373 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 39acb54efd3c8585c4b9f9b55a7148a6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:33:58,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10883 failed with Exception \n",
      "2023-06-27 19:34:05,730 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11441\n",
      "2023-06-27 19:34:11,508 - \u001b[1;33mWARNING\u001b[1;0m - Request 11397 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8e6895ad1136aeb2e44997013725cfc4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:34:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 10909 failed with Exception \n",
      "2023-06-27 19:34:16,398 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11459\n",
      "2023-06-27 19:34:27,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11479\n",
      "2023-06-27 19:34:37,753 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11499\n",
      "2023-06-27 19:34:48,428 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11519\n",
      "2023-06-27 19:34:57,902 - \u001b[1;33mWARNING\u001b[1;0m - Request 11480 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e455ff69560d2afa1ffd5faefdf6600b in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:34:59,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11538\n",
      "2023-06-27 19:35:01,222 - \u001b[1;33mWARNING\u001b[1;0m - Request 11486 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f9dfcb39d9187a67a6df1f18458fbe61 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:35:09,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11557\n",
      "2023-06-27 19:35:18,285 - \u001b[1;33mWARNING\u001b[1;0m - Request 11518 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c346be9d8b574a7c46bfc8648a9e16e8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:35:20,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11576\n",
      "2023-06-27 19:35:23,520 - \u001b[1;33mWARNING\u001b[1;0m - Request 11528 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0096c1fb126109f17cbe6b715a3c90c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:35:31,066 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11595\n",
      "2023-06-27 19:35:41,746 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11615\n",
      "2023-06-27 19:35:43,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11076 failed with Exception \n",
      "2023-06-27 19:35:52,410 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11634\n",
      "2023-06-27 19:35:58,188 - \u001b[1;33mWARNING\u001b[1;0m - Request 11589 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 192db8c72671208700e91b5be94fea4a in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:03,084 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11653\n",
      "2023-06-27 19:36:13,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11673\n",
      "2023-06-27 19:36:18,438 - \u001b[1;33mWARNING\u001b[1;0m - Request 11626 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76201c493e08eebda7ae8e8f51b08d7e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:24,392 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11692\n",
      "2023-06-27 19:36:35,070 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11712\n",
      "2023-06-27 19:36:45,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11732\n",
      "2023-06-27 19:36:53,718 - \u001b[1;33mWARNING\u001b[1;0m - Request 11690 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af1e3f64db9f921881a57f1e5edbbc6d in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:36:56,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11751\n",
      "2023-06-27 19:37:03,815 - \u001b[1;33mWARNING\u001b[1;0m - Request 11709 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 80b41ac02ca08ead00463b0d0e88e363 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:04,835 - \u001b[1;33mWARNING\u001b[1;0m - Request 11711 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4bb19fd5d27cf50c5d84a3be26e4e15e in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:07,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11769\n",
      "2023-06-27 19:37:07,507 - \u001b[1;33mWARNING\u001b[1;0m - Request 11716 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b818e08331571ba93fa3bdba3ed71db in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:11,755 - \u001b[1;33mWARNING\u001b[1;0m - Request 11724 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 70134340c52a3acd952f2ba975c4c9d4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:17,737 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11787\n",
      "2023-06-27 19:37:27,234 - \u001b[1;33mWARNING\u001b[1;0m - Request 11752 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 43448d0ad71838e7759dedce92c12328 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:28,390 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11806\n",
      "2023-06-27 19:37:29,894 - \u001b[1;33mWARNING\u001b[1;0m - Request 11757 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 42e9cd3c0872b5a40f71e9327ce3f81c in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:39,048 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11825\n",
      "2023-06-27 19:37:41,661 - \u001b[1;33mWARNING\u001b[1;0m - Request 11776 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 068c886dcca1baf158e7dcf956303d68 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:49,174 - \u001b[1;33mWARNING\u001b[1;0m - Request 11789 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b15e97e12adcd8b02afbdd025e63f075 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:37:49,698 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11844\n",
      "2023-06-27 19:37:52,832 - \u001b[1;33mWARNING\u001b[1;0m - Request 11796 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 391c2fd34ee48a39b8c6a454389e6627 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:00,361 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11862\n",
      "2023-06-27 19:38:11,020 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11882\n",
      "2023-06-27 19:38:21,677 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11902\n",
      "2023-06-27 19:38:32,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:38:43,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11942\n",
      "2023-06-27 19:38:46,110 - \u001b[1;33mWARNING\u001b[1;0m - Request 11891 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7eebad6299c2188c280536cda2eda58 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:38:47,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11408 failed with Exception \n",
      "2023-06-27 19:38:53,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11960\n",
      "2023-06-27 19:39:04,334 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11980\n",
      "2023-06-27 19:39:12,245 - \u001b[1;33mWARNING\u001b[1;0m - Request 11940 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25cfb6c006d263f46415337e5f4907ac in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 19:39:15,015 - \u001b[1;32mINFO\u001b[1;0m - Starting request #11999\n",
      "2023-06-27 19:39:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 11467 failed with Exception \n",
      "2023-06-27 19:39:25,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12018\n",
      "2023-06-27 19:39:36,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12038\n",
      "2023-06-27 19:39:47,009 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12058\n",
      "2023-06-27 19:39:57,675 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12078\n",
      "2023-06-27 19:40:08,344 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12098\n",
      "2023-06-27 19:40:19,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12118\n",
      "2023-06-27 19:40:29,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12138\n",
      "2023-06-27 19:40:40,355 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12158\n",
      "2023-06-27 19:40:51,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12178\n",
      "2023-06-27 19:41:01,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12198\n",
      "2023-06-27 19:41:12,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12218\n",
      "2023-06-27 19:41:23,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12238\n",
      "2023-06-27 19:41:33,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12258\n",
      "2023-06-27 19:41:35,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 11712 failed with Exception \n",
      "2023-06-27 19:41:44,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12277\n",
      "2023-06-27 19:41:49,757 - \u001b[1;33mWARNING\u001b[1;0m - Request 11711 failed with error {'code': None, 'message': 'Invalid URL (POST /v1/chat/completions)', 'param': None, 'type': 'invalid_request_error'}\n",
      "2023-06-27 19:41:55,032 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12296\n",
      "2023-06-27 19:42:05,694 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12316\n",
      "2023-06-27 19:42:16,360 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12336\n",
      "2023-06-27 19:42:27,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12356\n",
      "2023-06-27 19:42:37,678 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12376\n",
      "2023-06-27 19:42:48,350 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12396\n",
      "2023-06-27 19:42:59,013 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12416\n",
      "2023-06-27 19:43:09,666 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12436\n",
      "2023-06-27 19:43:20,326 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12456\n",
      "2023-06-27 19:43:30,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12476\n",
      "2023-06-27 19:43:41,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12496\n",
      "2023-06-27 19:43:52,328 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12516\n",
      "2023-06-27 19:44:02,990 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12536\n",
      "2023-06-27 19:44:13,670 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12556\n",
      "2023-06-27 19:44:24,339 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12576\n",
      "2023-06-27 19:44:34,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12596\n",
      "2023-06-27 19:44:45,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12616\n",
      "2023-06-27 19:44:56,332 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12636\n",
      "2023-06-27 19:45:06,978 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12656\n",
      "2023-06-27 19:45:17,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12676\n",
      "2023-06-27 19:45:28,310 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12696\n",
      "2023-06-27 19:45:38,976 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12716\n",
      "2023-06-27 19:45:49,651 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12736\n",
      "2023-06-27 19:46:00,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12756\n",
      "2023-06-27 19:46:10,987 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12776\n",
      "2023-06-27 19:46:21,649 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12796\n",
      "2023-06-27 19:46:32,296 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12816\n",
      "2023-06-27 19:46:42,965 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12836\n",
      "2023-06-27 19:46:53,627 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12856\n",
      "2023-06-27 19:47:04,295 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12876\n",
      "2023-06-27 19:47:14,961 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12896\n",
      "2023-06-27 19:47:25,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12916\n",
      "2023-06-27 19:47:36,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12936\n",
      "2023-06-27 19:47:46,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12956\n",
      "2023-06-27 19:47:57,576 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12976\n",
      "2023-06-27 19:48:08,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #12996\n",
      "2023-06-27 19:48:18,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13016\n",
      "2023-06-27 19:48:29,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13036\n",
      "2023-06-27 19:48:40,226 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13056\n",
      "2023-06-27 19:48:50,891 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13076\n",
      "2023-06-27 19:49:01,549 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13096\n",
      "2023-06-27 19:49:12,197 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13116\n",
      "2023-06-27 19:49:22,854 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13136\n",
      "2023-06-27 19:49:33,514 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13156\n",
      "2023-06-27 19:49:44,189 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13176\n",
      "2023-06-27 19:49:54,860 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13196\n",
      "2023-06-27 19:50:05,518 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13216\n",
      "2023-06-27 19:50:16,179 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13236\n",
      "2023-06-27 19:50:26,837 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13256\n",
      "2023-06-27 19:50:37,498 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13276\n",
      "2023-06-27 19:50:48,156 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13296\n",
      "2023-06-27 19:50:58,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13316\n",
      "2023-06-27 19:51:09,466 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13336\n",
      "2023-06-27 19:51:20,125 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13356\n",
      "2023-06-27 19:51:30,777 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13376\n",
      "2023-06-27 19:51:41,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13396\n",
      "2023-06-27 19:51:52,130 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13416\n",
      "2023-06-27 19:52:02,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13436\n",
      "2023-06-27 19:52:13,434 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13456\n",
      "2023-06-27 19:52:24,099 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13476\n",
      "2023-06-27 19:52:34,773 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13496\n",
      "2023-06-27 19:52:45,433 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13516\n",
      "2023-06-27 19:52:56,083 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13536\n",
      "2023-06-27 19:53:06,738 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13556\n",
      "2023-06-27 19:53:17,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13576\n",
      "2023-06-27 19:53:28,052 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13596\n",
      "2023-06-27 19:53:38,722 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13616\n",
      "2023-06-27 19:53:49,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13636\n",
      "2023-06-27 19:54:00,045 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13656\n",
      "2023-06-27 19:54:10,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13676\n",
      "2023-06-27 19:54:21,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13696\n",
      "2023-06-27 19:54:32,049 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13716\n",
      "2023-06-27 19:54:42,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13736\n",
      "2023-06-27 19:54:53,405 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13756\n",
      "2023-06-27 19:55:04,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13776\n",
      "2023-06-27 19:55:14,730 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13796\n",
      "2023-06-27 19:55:25,402 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13816\n",
      "2023-06-27 19:55:36,077 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13836\n",
      "2023-06-27 19:55:46,740 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13856\n",
      "2023-06-27 19:55:57,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13876\n",
      "2023-06-27 19:56:08,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13896\n",
      "2023-06-27 19:56:18,740 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 19:56:29,415 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13936\n",
      "2023-06-27 19:56:40,075 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13956\n",
      "2023-06-27 19:56:50,727 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13976\n",
      "2023-06-27 19:57:01,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #13996\n",
      "2023-06-27 19:57:12,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14016\n",
      "2023-06-27 19:57:22,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14036\n",
      "2023-06-27 19:57:33,377 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14056\n",
      "2023-06-27 19:57:44,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14076\n",
      "2023-06-27 19:57:54,710 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14096\n",
      "2023-06-27 19:58:05,363 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14116\n",
      "2023-06-27 19:58:16,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14136\n",
      "2023-06-27 19:58:26,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14156\n",
      "2023-06-27 19:58:37,389 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14176\n",
      "2023-06-27 19:58:48,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14196\n",
      "2023-06-27 19:58:58,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14216\n",
      "2023-06-27 19:59:09,404 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14236\n",
      "2023-06-27 19:59:20,065 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14256\n",
      "2023-06-27 19:59:30,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14276\n",
      "2023-06-27 19:59:41,399 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14296\n",
      "2023-06-27 19:59:52,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14316\n",
      "2023-06-27 20:00:02,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14336\n",
      "2023-06-27 20:00:13,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14356\n",
      "2023-06-27 20:00:24,053 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14376\n",
      "2023-06-27 20:00:34,710 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14396\n",
      "2023-06-27 20:00:45,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14416\n",
      "2023-06-27 20:00:56,034 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14436\n",
      "2023-06-27 20:01:06,695 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14456\n",
      "2023-06-27 20:01:17,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14476\n",
      "2023-06-27 20:01:28,004 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14496\n",
      "2023-06-27 20:01:38,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14516\n",
      "2023-06-27 20:01:49,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14536\n",
      "2023-06-27 20:02:00,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14556\n",
      "2023-06-27 20:02:10,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14576\n",
      "2023-06-27 20:02:21,372 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14596\n",
      "2023-06-27 20:02:32,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14616\n",
      "2023-06-27 20:02:42,713 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14636\n",
      "2023-06-27 20:02:53,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14656\n",
      "2023-06-27 20:03:04,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14676\n",
      "2023-06-27 20:03:14,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14696\n",
      "2023-06-27 20:03:25,336 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14716\n",
      "2023-06-27 20:03:36,016 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14736\n",
      "2023-06-27 20:03:46,684 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14756\n",
      "2023-06-27 20:03:57,342 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14776\n",
      "2023-06-27 20:04:08,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14796\n",
      "2023-06-27 20:04:18,650 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14816\n",
      "2023-06-27 20:04:29,316 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14836\n",
      "2023-06-27 20:04:39,975 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14856\n",
      "2023-06-27 20:04:50,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14876\n",
      "2023-06-27 20:05:01,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14896\n",
      "2023-06-27 20:05:11,993 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14916\n",
      "2023-06-27 20:05:22,658 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14936\n",
      "2023-06-27 20:05:33,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14956\n",
      "2023-06-27 20:05:43,971 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14976\n",
      "2023-06-27 20:05:54,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #14996\n",
      "2023-06-27 20:05:55,964 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_174837.jsonl\n",
      "2023-06-27 20:05:55,967 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_174837.jsonl\n",
      "2023-06-27 20:05:56,434 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the inconsistency. Could you please provide me with a medical fact so that I can generate the JSON object for you?, returning default object\n",
      "2023-06-27 20:05:56,434 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Could you please provide the medical fact or observation that you would like me to process?, returning default object\n",
      "2023-06-27 20:05:56,437 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I didn't understand your request. Could you please provide more information or clarify your question?, returning default object\n",
      "2023-06-27 20:05:56,440 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I am not able to assess the response. Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,443 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\..., \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"Additional considerations\"}] for fact \"Additional considerations\": Could not parse output: When generating the JSON object, it is important to handle different variations and formats of the medical fact. Here are some additional considerations:\n",
      "\n",
      "1. Case sensitivity: The medical fact may be provided in uppercase, lowercase, or a combination of both. It is recommended to convert the input to a consistent format (e.g., lowercase) before processing.\n",
      "\n",
      "2. Abbreviations and acronyms: The medical fact may contain abbreviations or acronyms. It is important to handle these appropriately and expand them if necessary. For example, \"LUL\" could be expanded to \"left upper lobe\".\n",
      "\n",
      "3. Synonyms and variations: The medical fact may have different ways of expressing the same observation. For example, \"opacity\" and \"density\" could be used interchangeably. It is important to handle these variations and map them to a consistent terminology.\n",
      "\n",
      "4. Multiple observations: The medical fact may contain multiple observations. In such cases, it is important to extract and handle each observation separately. For\n",
      "2023-06-27 20:05:56,444 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize, but I am unable to provide the requested information without a specific medical fact. Could you please provide a medical fact for me to work with?, returning default object\n",
      "2023-06-27 20:05:56,448 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"developing variant\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,457 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Changed finding\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,463 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for any confusion. Could you please provide more information or clarify your request? I'll be happy to assist you further., returning default object\n",
      "2023-06-27 20:05:56,464 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm unable to assist with your request., returning default object\n",
      "2023-06-27 20:05:56,469 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Suggestions of extension\"}] for fact \"Suggestions of extension\": Could not parse output: Here are some suggestions for extending the functionality of the program:\n",
      "\n",
      "1. Handle multiple observations: Modify the program to handle cases where there are multiple observations in the input. For example, \"Linear opacity at left base and pleural effusion\" should output two separate JSON objects for each observation.\n",
      "\n",
      "2. Handle modifiers: Some medical facts may include modifiers that provide additional information about the observation. For example, \"Large mass involving left fourth rib\" or \"Small pleural effusion\". Modify the program to include a \"modifier\" field in the JSON object to capture these modifiers.\n",
      "\n",
      "3. Handle uncertainty: In some cases, the medical fact may include uncertainty or ambiguity. For example, \"Possible linear opacity at left base\" or \"Probable pleural effusion\". Modify the program to include an \"uncertainty\" field in the JSON object to capture these uncertainties.\n",
      "\n",
      "4. Handle laterality: In cases where the observation is specific to one side of the body, such as \"Opacity in the right\n",
      "2023-06-27 20:05:56,470 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"change in clinical context\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,476 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to generate JSON objects for surgical projects. My capabilities are limited to providing information and answering questions related to medical facts. If you have any medical questions or need assistance with a medical topic, feel free to ask!, returning default object\n",
      "2023-06-27 20:05:56,479 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I can't generate that JSON object for you., returning default object\n",
      "2023-06-27 20:05:56,479 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...ity\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"A little improvement\"}] for fact \"A little improvement\": Could not parse output: Sure! Here's an updated version of the prompt with some improvements:\n",
      "\n",
      "Given a medical fact, output a JSON object with 3 fields: \"location\", \"specific\", and \"general\".\n",
      "\n",
      "The \"location\" field should contain the anatomical location of the observation if provided, otherwise it should be empty.\n",
      "\n",
      "The \"specific\" field should contain the specific observation, including any additional attributes if provided. If no specific observation is provided, it should be empty.\n",
      "\n",
      "The \"general\" field should contain a general description of the observation. If a specific observation is provided, it should be a more general term that encompasses the specific observation. If no specific observation is provided, it should be empty.\n",
      "\n",
      "If only an anatomical location is provided but the observation is missing, both the \"specific\" and \"general\" fields should be empty.\n",
      "\n",
      "Examples with all the fields:\n",
      "\n",
      "Linear opacity at left base\n",
      "{\n",
      "  \"location\": \"left base\",\n",
      "  \"specific\": \"linear opacity\",\n",
      "  \"general\": \"opacity\n",
      "2023-06-27 20:05:56,497 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"new visualization\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,500 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...\\n\\n\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Confirmed follow-up\"}] for fact \"Confirmed follow-up\": Could not parse output: I apologize for the confusion. Here is the corrected response:\n",
      "\n",
      "Given a medical fact, the output should be a JSON object with the following fields: \"location\", \"specific\", and \"general\".\n",
      "\n",
      "If the medical fact provides an anatomical location and an observation, the JSON object should have the anatomical location in the \"location\" field, the observation in the \"specific\" field, and a more general term for the observation in the \"general\" field.\n",
      "\n",
      "If the medical fact only provides an anatomical location without an observation, the JSON object should have the anatomical location in the \"location\" field, and the \"specific\" and \"general\" fields should be empty.\n",
      "\n",
      "If the medical fact only provides an observation without an anatomical location, the JSON object should have the observation in the \"specific\" and \"general\" fields, and the \"location\" field should be empty.\n",
      "\n",
      "If the medical fact does not provide an anatomical location or an observation, all three fields should be empty.\n",
      "\n",
      "\n",
      "2023-06-27 20:05:56,501 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not able to assist with that request., returning default object\n",
      "2023-06-27 20:05:56,503 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"process localization\". Could you please provide more information or clarify your request?, returning default object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 20:05:56,517 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Earlier today\". Could you please provide more context or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,527 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Advanced from below\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,532 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the confusion. Could you please provide me with the medical fact or observation that you would like me to process?, returning default object\n",
      "2023-06-27 20:05:56,535 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"Follow\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,544 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I apologize for the incomplete response. Could you please provide the medical fact or observation that you would like me to process?, returning default object\n",
      "2023-06-27 20:05:56,555 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"slightly improved improvement\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,559 - \u001b[1;33mWARNING\u001b[1;0m - GPT is protesting: I'm sorry, but I'm not sure what you mean by \"slightly improved findings\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 20:05:56,568 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-06-27 20:05:56,578 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 14994 of 14998 API responses.\n",
      "                    4 of 14998 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_fine_grained_details_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\" \\\n",
    "    --offset 15000 \\\n",
    "    --num_facts 15000 \\\n",
    "    --sample_facts_uniformly \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "917ddb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:29:04,852 - \u001b[1;32mINFO\u001b[1;0m - Loaded 15094 already parsed facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n",
      "2023-06-27 21:29:04,852 - \u001b[1;32mINFO\u001b[1;0m - Loading facts from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 21:29:11,359 - \u001b[1;32mINFO\u001b[1;0m - Loaded 849523 rows from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 21:29:12,517 - \u001b[1;32mINFO\u001b[1;0m - Found 414580 unique facts in /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\n",
      "2023-06-27 21:29:12,550 - \u001b[1;32mINFO\u001b[1;0m - Sorting facts by difficulty...\n",
      "100%|█████████████████████████████████| 414580/414580 [00:51<00:00, 8094.92it/s]\n",
      "2023-06-27 21:30:03,767 - \u001b[1;32mINFO\u001b[1;0m - Counting word frequencies...\n",
      "100%|███████████████████████████████| 414580/414580 [00:00<00:00, 427499.24it/s]\n",
      "2023-06-27 21:30:05,784 - \u001b[1;32mINFO\u001b[1;0m - Done sorting facts.\n",
      "2023-06-27 21:30:05,784 - \u001b[1;32mINFO\u001b[1;0m - First fact: Mediastinal bulgary bulgarian mediastinal bulgarian mediastinal bulgarian hilar (left > right bulgarian mediastinal bulg\n",
      "2023-06-27 21:30:05,784 - \u001b[1;32mINFO\u001b[1;0m - Last fact: Right\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - Total number of facts to parse: 9650\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - Example facts to parse:\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 1. Catheter in lower right atrium\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 1073. Volume loss in this region\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 2145. Unchanged opacity over multiple prior exams\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 3217. 3 right-sided chest tubes\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 4289. Diffuse bilateral pulmonary granulomas\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 5361. Large right paratracheal mass\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 6433. Thin pleural apical thickenings\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 7505. Cardiomediastinal silhouette obscured by effusion\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 8577. Severe left upper lobe consolidation\n",
      "2023-06-27 21:30:05,940 - \u001b[1;32mINFO\u001b[1;0m - 9650. Appropriately positioned ventricular leads\n",
      "2023-06-27 21:30:06,000 - \u001b[1;32mINFO\u001b[1;0m - Saving API requests to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_requests_20230627_213006.jsonl\n",
      "2023-06-27 21:30:06,000 - \u001b[1;32mINFO\u001b[1;0m - Saving API responses to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_213006.jsonl\n",
      "2023-06-27 21:30:06,567 - \u001b[1;32mINFO\u001b[1;0m - Starting request #0\n",
      "2023-06-27 21:30:06,645 - \u001b[1;32mINFO\u001b[1;0m - Starting request #20\n",
      "2023-06-27 21:30:06,702 - \u001b[1;32mINFO\u001b[1;0m - Starting request #40\n",
      "2023-06-27 21:30:06,782 - \u001b[1;32mINFO\u001b[1;0m - Starting request #60\n",
      "2023-06-27 21:30:06,833 - \u001b[1;32mINFO\u001b[1;0m - Starting request #80\n",
      "2023-06-27 21:30:06,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #100\n",
      "2023-06-27 21:30:11,091 - \u001b[1;32mINFO\u001b[1;0m - Starting request #120\n",
      "2023-06-27 21:30:21,752 - \u001b[1;32mINFO\u001b[1;0m - Starting request #140\n",
      "2023-06-27 21:30:32,425 - \u001b[1;32mINFO\u001b[1;0m - Starting request #160\n",
      "2023-06-27 21:30:43,087 - \u001b[1;32mINFO\u001b[1;0m - Starting request #180\n",
      "2023-06-27 21:30:53,758 - \u001b[1;32mINFO\u001b[1;0m - Starting request #200\n",
      "2023-06-27 21:31:04,438 - \u001b[1;32mINFO\u001b[1;0m - Starting request #220\n",
      "2023-06-27 21:31:15,116 - \u001b[1;32mINFO\u001b[1;0m - Starting request #240\n",
      "2023-06-27 21:31:25,780 - \u001b[1;32mINFO\u001b[1;0m - Starting request #260\n",
      "2023-06-27 21:31:36,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #280\n",
      "2023-06-27 21:31:47,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #300\n",
      "2023-06-27 21:31:57,722 - \u001b[1;32mINFO\u001b[1;0m - Starting request #320\n",
      "2023-06-27 21:32:08,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #340\n",
      "2023-06-27 21:32:19,074 - \u001b[1;32mINFO\u001b[1;0m - Starting request #360\n",
      "2023-06-27 21:32:29,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #380\n",
      "2023-06-27 21:32:40,408 - \u001b[1;32mINFO\u001b[1;0m - Starting request #400\n",
      "2023-06-27 21:32:51,067 - \u001b[1;32mINFO\u001b[1;0m - Starting request #420\n",
      "2023-06-27 21:33:01,724 - \u001b[1;32mINFO\u001b[1;0m - Starting request #440\n",
      "2023-06-27 21:33:12,385 - \u001b[1;32mINFO\u001b[1;0m - Starting request #460\n",
      "2023-06-27 21:33:23,055 - \u001b[1;32mINFO\u001b[1;0m - Starting request #480\n",
      "2023-06-27 21:33:33,732 - \u001b[1;32mINFO\u001b[1;0m - Starting request #500\n",
      "2023-06-27 21:33:44,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #520\n",
      "2023-06-27 21:33:55,059 - \u001b[1;32mINFO\u001b[1;0m - Starting request #540\n",
      "2023-06-27 21:34:05,723 - \u001b[1;32mINFO\u001b[1;0m - Starting request #560\n",
      "2023-06-27 21:34:16,386 - \u001b[1;32mINFO\u001b[1;0m - Starting request #580\n",
      "2023-06-27 21:34:27,051 - \u001b[1;32mINFO\u001b[1;0m - Starting request #600\n",
      "2023-06-27 21:34:37,717 - \u001b[1;32mINFO\u001b[1;0m - Starting request #620\n",
      "2023-06-27 21:34:48,388 - \u001b[1;32mINFO\u001b[1;0m - Starting request #640\n",
      "2023-06-27 21:34:59,056 - \u001b[1;32mINFO\u001b[1;0m - Starting request #660\n",
      "2023-06-27 21:35:09,714 - \u001b[1;32mINFO\u001b[1;0m - Starting request #680\n",
      "2023-06-27 21:35:20,382 - \u001b[1;32mINFO\u001b[1;0m - Starting request #700\n",
      "2023-06-27 21:35:31,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #720\n",
      "2023-06-27 21:35:41,719 - \u001b[1;32mINFO\u001b[1;0m - Starting request #740\n",
      "2023-06-27 21:35:52,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #760\n",
      "2023-06-27 21:36:03,041 - \u001b[1;32mINFO\u001b[1;0m - Starting request #780\n",
      "2023-06-27 21:36:13,705 - \u001b[1;32mINFO\u001b[1;0m - Starting request #800\n",
      "2023-06-27 21:36:24,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #820\n",
      "2023-06-27 21:36:35,026 - \u001b[1;32mINFO\u001b[1;0m - Starting request #840\n",
      "2023-06-27 21:36:45,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #860\n",
      "2023-06-27 21:36:56,359 - \u001b[1;32mINFO\u001b[1;0m - Starting request #880\n",
      "2023-06-27 21:37:07,025 - \u001b[1;32mINFO\u001b[1;0m - Starting request #900\n",
      "2023-06-27 21:37:07,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 338 failed with Exception \n",
      "2023-06-27 21:37:17,678 - \u001b[1;32mINFO\u001b[1;0m - Starting request #919\n",
      "2023-06-27 21:37:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 365 failed with Exception \n",
      "2023-06-27 21:37:28,338 - \u001b[1;32mINFO\u001b[1;0m - Starting request #938\n",
      "2023-06-27 21:37:38,999 - \u001b[1;32mINFO\u001b[1;0m - Starting request #958\n",
      "2023-06-27 21:37:49,683 - \u001b[1;32mINFO\u001b[1;0m - Starting request #978\n",
      "2023-06-27 21:38:00,362 - \u001b[1;32mINFO\u001b[1;0m - Starting request #998\n",
      "2023-06-27 21:38:11,035 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1018\n",
      "2023-06-27 21:38:21,701 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1038\n",
      "2023-06-27 21:38:32,369 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1058\n",
      "2023-06-27 21:38:43,022 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1078\n",
      "2023-06-27 21:38:53,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1098\n",
      "2023-06-27 21:39:04,333 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1118\n",
      "2023-06-27 21:39:15,000 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1138\n",
      "2023-06-27 21:39:25,669 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1158\n",
      "2023-06-27 21:39:36,320 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1178\n",
      "2023-06-27 21:39:46,988 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1198\n",
      "2023-06-27 21:39:57,646 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1218\n",
      "2023-06-27 21:40:08,301 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1238\n",
      "2023-06-27 21:40:18,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1258\n",
      "2023-06-27 21:40:29,610 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1278\n",
      "2023-06-27 21:40:40,278 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1298\n",
      "2023-06-27 21:40:50,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1318\n",
      "2023-06-27 21:41:01,620 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1338\n",
      "2023-06-27 21:41:12,273 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1358\n",
      "2023-06-27 21:41:22,929 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1378\n",
      "2023-06-27 21:41:33,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1398\n",
      "2023-06-27 21:41:44,267 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1418\n",
      "2023-06-27 21:41:53,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 874 failed with Exception \n",
      "2023-06-27 21:41:54,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1437\n",
      "2023-06-27 21:42:05,584 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1457\n",
      "2023-06-27 21:42:09,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 902 failed with Exception \n",
      "2023-06-27 21:42:16,259 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1476\n",
      "2023-06-27 21:42:26,934 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1496\n",
      "2023-06-27 21:42:37,614 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:42:48,293 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1536\n",
      "2023-06-27 21:42:58,949 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1556\n",
      "2023-06-27 21:43:09,611 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1576\n",
      "2023-06-27 21:43:20,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1596\n",
      "2023-06-27 21:43:30,938 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1616\n",
      "2023-06-27 21:43:41,595 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1636\n",
      "2023-06-27 21:43:52,266 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1656\n",
      "2023-06-27 21:44:02,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1676\n",
      "2023-06-27 21:44:13,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1696\n",
      "2023-06-27 21:44:24,261 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1716\n",
      "2023-06-27 21:44:34,925 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1736\n",
      "2023-06-27 21:44:45,598 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1756\n",
      "2023-06-27 21:44:56,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1776\n",
      "2023-06-27 21:45:00,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1222 failed with Exception \n",
      "2023-06-27 21:45:06,947 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1795\n",
      "2023-06-27 21:45:17,606 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1815\n",
      "2023-06-27 21:45:18,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1256 failed with Exception \n",
      "2023-06-27 21:45:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1258 failed with Exception \n",
      "2023-06-27 21:45:28,260 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1833\n",
      "2023-06-27 21:45:38,917 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1853\n",
      "2023-06-27 21:45:49,579 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1873\n",
      "2023-06-27 21:45:59,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1333 failed with Exception \n",
      "2023-06-27 21:46:00,233 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1333\n",
      "2023-06-27 21:46:10,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 1354 failed with Exception \n",
      "2023-06-27 21:46:10,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1912\n",
      "2023-06-27 21:46:21,572 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1931\n",
      "2023-06-27 21:46:32,237 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1951\n",
      "2023-06-27 21:46:42,911 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1971\n",
      "2023-06-27 21:46:53,566 - \u001b[1;32mINFO\u001b[1;0m - Starting request #1991\n",
      "2023-06-27 21:47:04,232 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2011\n",
      "2023-06-27 21:47:14,897 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2031\n",
      "2023-06-27 21:47:25,561 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2051\n",
      "2023-06-27 21:47:36,217 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2071\n",
      "2023-06-27 21:47:43,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 1527 failed with Exception \n",
      "2023-06-27 21:47:46,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2090\n",
      "2023-06-27 21:47:57,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2110\n",
      "2023-06-27 21:48:08,212 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2130\n",
      "2023-06-27 21:48:18,895 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2150\n",
      "2023-06-27 21:48:29,560 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2170\n",
      "2023-06-27 21:48:40,211 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2190\n",
      "2023-06-27 21:48:50,869 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2210\n",
      "2023-06-27 21:49:01,551 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2230\n",
      "2023-06-27 21:49:12,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2250\n",
      "2023-06-27 21:49:22,870 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2270\n",
      "2023-06-27 21:49:33,539 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2290\n",
      "2023-06-27 21:49:44,199 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2310\n",
      "2023-06-27 21:49:54,858 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2330\n",
      "2023-06-27 21:50:05,533 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2350\n",
      "2023-06-27 21:50:16,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2370\n",
      "2023-06-27 21:50:26,869 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2390\n",
      "2023-06-27 21:50:37,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2410\n",
      "2023-06-27 21:50:48,203 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2430\n",
      "2023-06-27 21:50:58,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2450\n",
      "2023-06-27 21:51:09,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2470\n",
      "2023-06-27 21:51:20,188 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2490\n",
      "2023-06-27 21:51:30,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2510\n",
      "2023-06-27 21:51:41,511 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2530\n",
      "2023-06-27 21:51:52,165 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2550\n",
      "2023-06-27 21:52:02,824 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2570\n",
      "2023-06-27 21:52:13,492 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2590\n",
      "2023-06-27 21:52:24,156 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2610\n",
      "2023-06-27 21:52:34,795 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2630\n",
      "2023-06-27 21:52:37,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2072 failed with Exception \n",
      "2023-06-27 21:52:45,466 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2649\n",
      "2023-06-27 21:52:56,139 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2669\n",
      "2023-06-27 21:53:06,808 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2689\n",
      "2023-06-27 21:53:17,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2709\n",
      "2023-06-27 21:53:28,127 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2729\n",
      "2023-06-27 21:53:38,807 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2749\n",
      "2023-06-27 21:53:49,488 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2769\n",
      "2023-06-27 21:54:00,173 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2789\n",
      "2023-06-27 21:54:10,838 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2809\n",
      "2023-06-27 21:54:21,520 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2829\n",
      "2023-06-27 21:54:32,180 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2849\n",
      "2023-06-27 21:54:42,849 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2869\n",
      "2023-06-27 21:54:53,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2889\n",
      "2023-06-27 21:55:04,184 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2909\n",
      "2023-06-27 21:55:14,839 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2929\n",
      "2023-06-27 21:55:25,495 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2949\n",
      "2023-06-27 21:55:36,153 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2969\n",
      "2023-06-27 21:55:46,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2989\n",
      "2023-06-27 21:55:57,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3009\n",
      "2023-06-27 21:56:08,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3029\n",
      "2023-06-27 21:56:18,765 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3049\n",
      "2023-06-27 21:56:29,432 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3069\n",
      "2023-06-27 21:56:39,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2526 failed with Exception \n",
      "2023-06-27 21:56:40,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2526\n",
      "2023-06-27 21:56:50,781 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3108\n",
      "2023-06-27 21:57:01,437 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3128\n",
      "2023-06-27 21:57:12,113 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3148\n",
      "2023-06-27 21:57:18,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2599 failed with Exception \n",
      "2023-06-27 21:57:22,785 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3167\n",
      "2023-06-27 21:57:27,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2615 failed with Exception \n",
      "2023-06-27 21:57:33,469 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3186\n",
      "2023-06-27 21:57:44,151 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3206\n",
      "2023-06-27 21:57:54,809 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3226\n",
      "2023-06-27 21:58:00,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2677 failed with Exception \n",
      "2023-06-27 21:58:05,471 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3245\n",
      "2023-06-27 21:58:16,140 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3265\n",
      "2023-06-27 21:58:26,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3285\n",
      "2023-06-27 21:58:36,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2744 failed with Exception \n",
      "2023-06-27 21:58:37,479 - \u001b[1;32mINFO\u001b[1;0m - Starting request #2744\n",
      "2023-06-27 21:58:48,133 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3324\n",
      "2023-06-27 21:58:58,795 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3344\n",
      "2023-06-27 21:59:09,458 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3364\n",
      "2023-06-27 21:59:11,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 2810 failed with Exception \n",
      "2023-06-27 21:59:20,120 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3383\n",
      "2023-06-27 21:59:30,793 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3403\n",
      "2023-06-27 21:59:33,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 2850 failed with Exception \n",
      "2023-06-27 21:59:41,454 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3422\n",
      "2023-06-27 21:59:52,128 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3442\n",
      "2023-06-27 22:00:02,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3462\n",
      "2023-06-27 22:00:13,449 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3482\n",
      "2023-06-27 22:00:24,105 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3502\n",
      "2023-06-27 22:00:34,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3522\n",
      "2023-06-27 22:00:45,427 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:00:56,095 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3562\n",
      "2023-06-27 22:01:06,764 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3582\n",
      "2023-06-27 22:01:17,443 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3602\n",
      "2023-06-27 22:01:28,114 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3622\n",
      "2023-06-27 22:01:38,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3642\n",
      "2023-06-27 22:01:49,426 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3662\n",
      "2023-06-27 22:01:56,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3118 failed with Exception \n",
      "2023-06-27 22:02:00,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3681\n",
      "2023-06-27 22:02:10,749 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3701\n",
      "2023-06-27 22:02:21,421 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3721\n",
      "2023-06-27 22:02:32,071 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3741\n",
      "2023-06-27 22:02:35,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3189 failed with Exception \n",
      "2023-06-27 22:02:42,742 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3760\n",
      "2023-06-27 22:02:53,395 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3780\n",
      "2023-06-27 22:03:04,061 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3800\n",
      "2023-06-27 22:03:14,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3820\n",
      "2023-06-27 22:03:25,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3840\n",
      "2023-06-27 22:03:30,262 - \u001b[1;33mWARNING\u001b[1;0m - Request 3657 failed with Exception 0, message='Attempt to decode JSON with unexpected mimetype: text/html', url=URL('https://api.openai.com/v1/chat/completions')\n",
      "2023-06-27 22:03:36,021 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3859\n",
      "2023-06-27 22:03:46,685 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3879\n",
      "2023-06-27 22:03:57,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3899\n",
      "2023-06-27 22:04:08,020 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3919\n",
      "2023-06-27 22:04:18,707 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3939\n",
      "2023-06-27 22:04:29,373 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3959\n",
      "2023-06-27 22:04:40,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3979\n",
      "2023-06-27 22:04:50,703 - \u001b[1;32mINFO\u001b[1;0m - Starting request #3999\n",
      "2023-06-27 22:04:52,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3441 failed with Exception \n",
      "2023-06-27 22:04:58,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3453 failed with Exception \n",
      "2023-06-27 22:05:01,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4017\n",
      "2023-06-27 22:05:12,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4037\n",
      "2023-06-27 22:05:15,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3485 failed with Exception \n",
      "2023-06-27 22:05:22,693 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4056\n",
      "2023-06-27 22:05:33,340 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4076\n",
      "2023-06-27 22:05:43,994 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4096\n",
      "2023-06-27 22:05:44,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 3539 failed with Exception \n",
      "2023-06-27 22:05:54,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4115\n",
      "2023-06-27 22:06:05,341 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4135\n",
      "2023-06-27 22:06:16,004 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4155\n",
      "2023-06-27 22:06:26,671 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4175\n",
      "2023-06-27 22:06:37,348 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4195\n",
      "2023-06-27 22:06:48,002 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4215\n",
      "2023-06-27 22:06:58,680 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4235\n",
      "2023-06-27 22:07:09,330 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4255\n",
      "2023-06-27 22:07:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3716 failed with Exception \n",
      "2023-06-27 22:07:20,001 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4275\n",
      "2023-06-27 22:07:29,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3735 failed with Exception \n",
      "2023-06-27 22:07:30,667 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4293\n",
      "2023-06-27 22:07:41,324 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4313\n",
      "2023-06-27 22:07:52,004 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4333\n",
      "2023-06-27 22:08:02,674 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4353\n",
      "2023-06-27 22:08:06,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3803 failed with Exception \n",
      "2023-06-27 22:08:13,334 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4372\n",
      "2023-06-27 22:08:23,986 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4392\n",
      "2023-06-27 22:08:34,651 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4412\n",
      "2023-06-27 22:08:45,307 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4432\n",
      "2023-06-27 22:08:55,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4452\n",
      "2023-06-27 22:09:06,642 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4472\n",
      "2023-06-27 22:09:17,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4492\n",
      "2023-06-27 22:09:18,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3937 failed with Exception \n",
      "2023-06-27 22:09:19,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 3939 failed with Exception \n",
      "2023-06-27 22:09:27,943 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4510\n",
      "2023-06-27 22:09:38,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4530\n",
      "2023-06-27 22:09:49,252 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4550\n",
      "2023-06-27 22:09:59,924 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4570\n",
      "2023-06-27 22:10:10,577 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4590\n",
      "2023-06-27 22:10:21,249 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4610\n",
      "2023-06-27 22:10:31,915 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4630\n",
      "2023-06-27 22:10:42,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4650\n",
      "2023-06-27 22:10:53,241 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4670\n",
      "2023-06-27 22:11:03,893 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4690\n",
      "2023-06-27 22:11:14,555 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4710\n",
      "2023-06-27 22:11:25,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4730\n",
      "2023-06-27 22:11:35,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4190 failed with Exception \n",
      "2023-06-27 22:11:35,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4750\n",
      "2023-06-27 22:11:42,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4204 failed with Exception \n",
      "2023-06-27 22:11:46,571 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4768\n",
      "2023-06-27 22:11:57,227 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4788\n",
      "2023-06-27 22:12:07,901 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4808\n",
      "2023-06-27 22:12:18,565 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4828\n",
      "2023-06-27 22:12:29,224 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4848\n",
      "2023-06-27 22:12:39,879 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4868\n",
      "2023-06-27 22:12:50,556 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4888\n",
      "2023-06-27 22:13:01,221 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4908\n",
      "2023-06-27 22:13:11,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4928\n",
      "2023-06-27 22:13:22,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4948\n",
      "2023-06-27 22:13:33,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4968\n",
      "2023-06-27 22:13:35,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 4413 failed with Exception \n",
      "2023-06-27 22:13:43,896 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4987\n",
      "2023-06-27 22:13:54,563 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5007\n",
      "2023-06-27 22:14:05,222 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5027\n",
      "2023-06-27 22:14:15,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5047\n",
      "2023-06-27 22:14:26,558 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5067\n",
      "2023-06-27 22:14:30,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4513 failed with Exception \n",
      "2023-06-27 22:14:37,220 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5086\n",
      "2023-06-27 22:14:47,881 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5106\n",
      "2023-06-27 22:14:58,557 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5126\n",
      "2023-06-27 22:15:09,220 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5146\n",
      "2023-06-27 22:15:19,889 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5166\n",
      "2023-06-27 22:15:23,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4614 failed with Exception \n",
      "2023-06-27 22:15:30,540 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5185\n",
      "2023-06-27 22:15:41,200 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5205\n",
      "2023-06-27 22:15:51,859 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5225\n",
      "2023-06-27 22:16:02,519 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5245\n",
      "2023-06-27 22:16:13,180 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5265\n",
      "2023-06-27 22:16:23,850 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5285\n",
      "2023-06-27 22:16:34,516 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5305\n",
      "2023-06-27 22:16:45,181 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5325\n",
      "2023-06-27 22:16:55,850 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5345\n",
      "2023-06-27 22:17:06,519 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5365\n",
      "2023-06-27 22:17:17,185 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5385\n",
      "2023-06-27 22:17:27,863 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5405\n",
      "2023-06-27 22:17:38,524 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5425\n",
      "2023-06-27 22:17:49,191 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:17:59,840 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5465\n",
      "2023-06-27 22:18:10,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5485\n",
      "2023-06-27 22:18:20,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4943 failed with Exception \n",
      "2023-06-27 22:18:21,164 - \u001b[1;32mINFO\u001b[1;0m - Starting request #4943\n",
      "2023-06-27 22:18:31,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5524\n",
      "2023-06-27 22:18:42,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 4983 failed with Exception \n",
      "2023-06-27 22:18:42,501 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5544\n",
      "2023-06-27 22:18:53,183 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5563\n",
      "2023-06-27 22:19:03,865 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5583\n",
      "2023-06-27 22:19:14,543 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5603\n",
      "2023-06-27 22:19:25,204 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5623\n",
      "2023-06-27 22:19:35,866 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5643\n",
      "2023-06-27 22:19:46,516 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5663\n",
      "2023-06-27 22:19:57,175 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5683\n",
      "2023-06-27 22:20:07,847 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5703\n",
      "2023-06-27 22:20:18,527 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5723\n",
      "2023-06-27 22:20:29,187 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5743\n",
      "2023-06-27 22:20:39,844 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5763\n",
      "2023-06-27 22:20:50,510 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5783\n",
      "2023-06-27 22:21:01,172 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5803\n",
      "2023-06-27 22:21:11,838 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5823\n",
      "2023-06-27 22:21:22,506 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5843\n",
      "2023-06-27 22:21:33,160 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5863\n",
      "2023-06-27 22:21:43,820 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5883\n",
      "2023-06-27 22:21:54,507 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5903\n",
      "2023-06-27 22:22:02,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 5357 failed with Exception \n",
      "2023-06-27 22:22:05,174 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5922\n",
      "2023-06-27 22:22:15,829 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5942\n",
      "2023-06-27 22:22:26,494 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5962\n",
      "2023-06-27 22:22:37,157 - \u001b[1;32mINFO\u001b[1;0m - Starting request #5982\n",
      "2023-06-27 22:22:47,803 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6002\n",
      "2023-06-27 22:22:58,463 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6022\n",
      "2023-06-27 22:23:09,129 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6042\n",
      "2023-06-27 22:23:19,784 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6062\n",
      "2023-06-27 22:23:30,440 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6082\n",
      "2023-06-27 22:23:41,096 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6102\n",
      "2023-06-27 22:23:47,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 5551 failed with Exception \n",
      "2023-06-27 22:23:51,760 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6121\n",
      "2023-06-27 22:24:02,429 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6141\n",
      "2023-06-27 22:24:13,079 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6161\n",
      "2023-06-27 22:24:23,734 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6181\n",
      "2023-06-27 22:24:34,403 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6201\n",
      "2023-06-27 22:24:45,059 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6221\n",
      "2023-06-27 22:24:55,740 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6241\n",
      "2023-06-27 22:25:06,394 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6261\n",
      "2023-06-27 22:25:17,068 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6281\n",
      "2023-06-27 22:25:27,735 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6301\n",
      "2023-06-27 22:25:38,396 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6321\n",
      "2023-06-27 22:25:49,063 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6341\n",
      "2023-06-27 22:25:59,739 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6361\n",
      "2023-06-27 22:26:10,423 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6381\n",
      "2023-06-27 22:26:21,090 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6401\n",
      "2023-06-27 22:26:31,742 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6421\n",
      "2023-06-27 22:26:42,406 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6441\n",
      "2023-06-27 22:26:53,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6461\n",
      "2023-06-27 22:27:03,721 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6481\n",
      "2023-06-27 22:27:14,388 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6501\n",
      "2023-06-27 22:27:25,048 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6521\n",
      "2023-06-27 22:27:35,716 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6541\n",
      "2023-06-27 22:27:46,374 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6561\n",
      "2023-06-27 22:27:57,069 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6581\n",
      "2023-06-27 22:28:07,725 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6601\n",
      "2023-06-27 22:28:18,384 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6621\n",
      "2023-06-27 22:28:29,033 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6641\n",
      "2023-06-27 22:28:39,686 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6661\n",
      "2023-06-27 22:28:50,343 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6681\n",
      "2023-06-27 22:29:01,003 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6701\n",
      "2023-06-27 22:29:11,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6721\n",
      "2023-06-27 22:29:22,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6741\n",
      "2023-06-27 22:29:32,982 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6761\n",
      "2023-06-27 22:29:43,653 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6781\n",
      "2023-06-27 22:29:54,312 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6801\n",
      "2023-06-27 22:30:04,989 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6821\n",
      "2023-06-27 22:30:15,643 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6841\n",
      "2023-06-27 22:30:26,308 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6861\n",
      "2023-06-27 22:30:36,969 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6881\n",
      "2023-06-27 22:30:47,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6901\n",
      "2023-06-27 22:30:58,289 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6921\n",
      "2023-06-27 22:31:08,958 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6941\n",
      "2023-06-27 22:31:19,620 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6961\n",
      "2023-06-27 22:31:30,298 - \u001b[1;32mINFO\u001b[1;0m - Starting request #6981\n",
      "2023-06-27 22:31:40,964 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7001\n",
      "2023-06-27 22:31:51,635 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7021\n",
      "2023-06-27 22:31:53,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6461 failed with Exception \n",
      "2023-06-27 22:32:02,286 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7040\n",
      "2023-06-27 22:32:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6497 failed with Exception \n",
      "2023-06-27 22:32:12,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7060\n",
      "2023-06-27 22:32:23,619 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7079\n",
      "2023-06-27 22:32:34,280 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7099\n",
      "2023-06-27 22:32:44,940 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7119\n",
      "2023-06-27 22:32:55,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 6577 failed with Exception \n",
      "2023-06-27 22:32:55,592 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7139\n",
      "2023-06-27 22:33:00,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6586 failed with Exception \n",
      "2023-06-27 22:33:06,263 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7157\n",
      "2023-06-27 22:33:16,928 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7177\n",
      "2023-06-27 22:33:27,593 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7197\n",
      "2023-06-27 22:33:38,269 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7217\n",
      "2023-06-27 22:33:48,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7237\n",
      "2023-06-27 22:33:59,585 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7257\n",
      "2023-06-27 22:34:10,247 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7277\n",
      "2023-06-27 22:34:20,905 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7297\n",
      "2023-06-27 22:34:31,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7317\n",
      "2023-06-27 22:34:42,236 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7337\n",
      "2023-06-27 22:34:52,898 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7357\n",
      "2023-06-27 22:35:03,564 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7377\n",
      "2023-06-27 22:35:12,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 6835 failed with Exception \n",
      "2023-06-27 22:35:14,229 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7396\n",
      "2023-06-27 22:35:24,867 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7416\n",
      "2023-06-27 22:35:35,542 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7436\n",
      "2023-06-27 22:35:46,198 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7456\n",
      "2023-06-27 22:35:56,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7476\n",
      "2023-06-27 22:36:07,525 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7496\n",
      "2023-06-27 22:36:18,201 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7516\n",
      "2023-06-27 22:36:28,875 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7536\n",
      "2023-06-27 22:36:39,536 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7556\n",
      "2023-06-27 22:36:50,206 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7576\n",
      "2023-06-27 22:37:00,872 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:37:01,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7038 failed with Exception \n",
      "2023-06-27 22:37:11,535 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7615\n",
      "2023-06-27 22:37:22,195 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7635\n",
      "2023-06-27 22:37:32,864 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7655\n",
      "2023-06-27 22:37:43,528 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7675\n",
      "2023-06-27 22:37:54,196 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7695\n",
      "2023-06-27 22:38:04,848 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7715\n",
      "2023-06-27 22:38:15,505 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7735\n",
      "2023-06-27 22:38:26,169 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7755\n",
      "2023-06-27 22:38:36,814 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7775\n",
      "2023-06-27 22:38:47,478 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7795\n",
      "2023-06-27 22:38:58,134 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7815\n",
      "2023-06-27 22:39:08,800 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7835\n",
      "2023-06-27 22:39:19,446 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7855\n",
      "2023-06-27 22:39:30,126 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7875\n",
      "2023-06-27 22:39:40,787 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7895\n",
      "2023-06-27 22:39:51,462 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7915\n",
      "2023-06-27 22:40:02,110 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7935\n",
      "2023-06-27 22:40:12,763 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7955\n",
      "2023-06-27 22:40:23,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7975\n",
      "2023-06-27 22:40:34,082 - \u001b[1;32mINFO\u001b[1;0m - Starting request #7995\n",
      "2023-06-27 22:40:44,760 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8015\n",
      "2023-06-27 22:40:55,430 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8035\n",
      "2023-06-27 22:41:06,085 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8055\n",
      "2023-06-27 22:41:16,747 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8075\n",
      "2023-06-27 22:41:27,413 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8095\n",
      "2023-06-27 22:41:28,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7535 failed with Exception \n",
      "2023-06-27 22:41:38,078 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8114\n",
      "2023-06-27 22:41:48,750 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8134\n",
      "2023-06-27 22:41:59,409 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8154\n",
      "2023-06-27 22:42:10,076 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8174\n",
      "2023-06-27 22:42:20,743 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8194\n",
      "2023-06-27 22:42:31,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8214\n",
      "2023-06-27 22:42:42,050 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8234\n",
      "2023-06-27 22:42:52,719 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8254\n",
      "2023-06-27 22:43:03,387 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8274\n",
      "2023-06-27 22:43:12,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7728 failed with Exception \n",
      "2023-06-27 22:43:14,057 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8293\n",
      "2023-06-27 22:43:24,709 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8313\n",
      "2023-06-27 22:43:35,378 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8333\n",
      "2023-06-27 22:43:46,046 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8353\n",
      "2023-06-27 22:43:56,720 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8373\n",
      "2023-06-27 22:44:07,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8393\n",
      "2023-06-27 22:44:18,038 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8413\n",
      "2023-06-27 22:44:28,711 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8433\n",
      "2023-06-27 22:44:39,391 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8453\n",
      "2023-06-27 22:44:50,056 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8473\n",
      "2023-06-27 22:44:53,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7918 failed with Exception \n",
      "2023-06-27 22:44:57,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 7925 failed with Exception \n",
      "2023-06-27 22:45:00,697 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8491\n",
      "2023-06-27 22:45:11,366 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8511\n",
      "2023-06-27 22:45:22,023 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8531\n",
      "2023-06-27 22:45:26,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 7979 failed with Exception \n",
      "2023-06-27 22:45:32,692 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8550\n",
      "2023-06-27 22:45:43,358 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8570\n",
      "2023-06-27 22:45:54,028 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8590\n",
      "2023-06-27 22:45:57,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8037 failed with Exception \n",
      "2023-06-27 22:46:04,690 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8609\n",
      "2023-06-27 22:46:15,370 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8629\n",
      "2023-06-27 22:46:26,042 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8649\n",
      "2023-06-27 22:46:36,712 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8669\n",
      "2023-06-27 22:46:47,380 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8689\n",
      "2023-06-27 22:46:58,040 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8709\n",
      "2023-06-27 22:47:08,702 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8729\n",
      "2023-06-27 22:47:11,479 - \u001b[1;33mWARNING\u001b[1;0m - Request 8677 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4d0423eb0d2e6fd9dfc9b0accef6af5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 22:47:19,368 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8748\n",
      "2023-06-27 22:47:30,030 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8768\n",
      "2023-06-27 22:47:30,091 - \u001b[1;33mWARNING\u001b[1;0m - Request 8712 failed with error {'message': 'That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 482a3790e102dc0d9e65b20248fd00c7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}\n",
      "2023-06-27 22:47:40,679 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8787\n",
      "2023-06-27 22:47:51,343 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8807\n",
      "2023-06-27 22:48:02,024 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8827\n",
      "2023-06-27 22:48:12,691 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8847\n",
      "2023-06-27 22:48:21,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8306 failed with Exception \n",
      "2023-06-27 22:48:23,346 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8866\n",
      "2023-06-27 22:48:33,991 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8886\n",
      "2023-06-27 22:48:44,652 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8906\n",
      "2023-06-27 22:48:55,315 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8926\n",
      "2023-06-27 22:49:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8388 failed with Exception \n",
      "2023-06-27 22:49:05,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8946\n",
      "2023-06-27 22:49:16,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8965\n",
      "2023-06-27 22:49:27,280 - \u001b[1;32mINFO\u001b[1;0m - Starting request #8985\n",
      "2023-06-27 22:49:37,941 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9005\n",
      "2023-06-27 22:49:48,599 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9025\n",
      "2023-06-27 22:49:59,281 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9045\n",
      "2023-06-27 22:50:09,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9065\n",
      "2023-06-27 22:50:20,628 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9085\n",
      "2023-06-27 22:50:31,292 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9105\n",
      "2023-06-27 22:50:38,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8560 failed with Exception \n",
      "2023-06-27 22:50:41,962 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9124\n",
      "2023-06-27 22:50:49,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8581 failed with Exception \n",
      "2023-06-27 22:50:52,636 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9143\n",
      "2023-06-27 22:51:03,302 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9163\n",
      "2023-06-27 22:51:13,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9183\n",
      "2023-06-27 22:51:24,630 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9203\n",
      "2023-06-27 22:51:35,299 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9223\n",
      "2023-06-27 22:51:45,967 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9243\n",
      "2023-06-27 22:51:56,626 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9263\n",
      "2023-06-27 22:52:07,289 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9283\n",
      "2023-06-27 22:52:17,957 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9303\n",
      "2023-06-27 22:52:22,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 8753 failed with Exception \n",
      "2023-06-27 22:52:28,634 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9322\n",
      "2023-06-27 22:52:39,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9342\n",
      "2023-06-27 22:52:45,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 8796 failed with Exception \n",
      "2023-06-27 22:52:49,948 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9361\n",
      "2023-06-27 22:53:00,624 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9381\n",
      "2023-06-27 22:53:11,287 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9401\n",
      "2023-06-27 22:53:21,956 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:53:32,633 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9441\n",
      "2023-06-27 22:53:43,290 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9461\n",
      "2023-06-27 22:53:53,950 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9481\n",
      "2023-06-27 22:54:04,603 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9501\n",
      "2023-06-27 22:54:15,275 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9521\n",
      "2023-06-27 22:54:25,939 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9541\n",
      "2023-06-27 22:54:36,591 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9561\n",
      "2023-06-27 22:54:47,254 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9581\n",
      "2023-06-27 22:54:57,921 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9601\n",
      "2023-06-27 22:55:08,583 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9621\n",
      "2023-06-27 22:55:19,238 - \u001b[1;32mINFO\u001b[1;0m - Starting request #9641\n",
      "2023-06-27 22:57:05,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9278 failed with Exception \n",
      "2023-06-27 22:57:09,494 - \u001b[1;33mWARNING\u001b[1;0m - Request 9287 failed with Exception \n",
      "2023-06-27 22:57:25,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9316 failed with Exception \n",
      "2023-06-27 22:58:45,493 - \u001b[1;33mWARNING\u001b[1;0m - Request 9465 failed with Exception \n",
      "2023-06-27 22:58:47,266 - \u001b[1;32mINFO\u001b[1;0m - Parallel processing complete. Results saved to /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_213006.jsonl\n",
      "2023-06-27 22:58:47,268 - \u001b[1;32mINFO\u001b[1;0m - Loading API responses from /home/pamessina/medvqa-workspace/tmp/mimiccxr/openai/api_responses_20230627_213006.jsonl\n",
      "2023-06-27 22:58:48,260 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I need more information in order to provide a complete assessment. Please provide the medical fact or observation that you would like me to process., returning default object\n",
      "2023-06-27 22:58:48,271 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"Changed configuration\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 22:58:48,277 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...nd\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Appropriate locations\"}] for fact \"Appropriate locations\": Could not parse output: The appropriate locations for medical observations can vary depending on the specific context and condition being described. However, some common anatomical locations that may be relevant in medical observations include:\n",
      "\n",
      "- Chest: This can refer to the general area of the thoracic cavity, which includes the lungs, heart, and other structures.\n",
      "- Lungs: Specific locations within the lungs may be mentioned, such as the upper, middle, or lower lobes, as well as specific segments or regions within each lobe.\n",
      "- Heart: Observations may mention specific areas of the heart, such as the left or right ventricle, atria, or valves.\n",
      "- Abdomen: This can refer to the general area of the abdominal cavity, which includes organs such as the liver, stomach, intestines, and kidneys.\n",
      "- Bones: Observations may mention specific bones or regions of the skeletal system, such as the spine, ribs, or long bones.\n",
      "\n",
      "These are just a few examples, and the appropriate location will depend\n",
      "2023-06-27 22:58:48,289 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"two projects\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 22:58:48,300 - \u001b[1;33mWARNING\u001b[1;0m - GPT is acting weird: I'm sorry, but I'm not sure what you mean by \"All other lines\". Could you please provide more information or clarify your request?, returning default object\n",
      "2023-06-27 22:58:48,307 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 550, \"completion_tokens\": 200, \"total_tokens\": 750}}, {\"fact\": \"Possible further advancement\"}] for fact \"Possible further advancement\": Could not parse output: To further advance the solution, we can consider the following improvements:\n",
      "\n",
      "1. Handle variations in the input: The current solution assumes a specific format for the medical fact. However, in real-world scenarios, there can be variations in the format and wording of the medical facts. We can use natural language processing techniques to handle these variations and extract the relevant information accurately.\n",
      "\n",
      "2. Expand the list of anatomical locations: The current solution assumes a limited set of anatomical locations. To make the solution more comprehensive, we can expand the list of anatomical locations and use a more sophisticated approach to identify and extract the location from the medical fact.\n",
      "\n",
      "3. Handle multiple observations: In some cases, a medical fact may contain multiple observations. For example, \"Linear opacity at left base and pleural effusion in the right lung.\" In such cases, we can modify the solution to handle multiple observations and generate separate JSON objects for each observation.\n",
      "\n",
      "4. Include additional attributes: The current solution only considers the anatomical\n",
      "2023-06-27 22:58:48,316 - \u001b[1;31mERROR\u001b[1;0m - Error parsing response [{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"system\", \"content\": \"Given a medical fact, output a JSON object with 3 fields: \\\"location\\\", \\...bscess\"}, \"finish_reason\": \"length\"}], \"usage\": {\"prompt_tokens\": 549, \"completion_tokens\": 200, \"total_tokens\": 749}}, {\"fact\": \"Standard approach\"}] for fact \"Standard approach\": Could not parse output: To solve this problem, we can use regular expressions to extract the relevant information from the medical fact. We can define patterns for the anatomical location, specific observation, and general observation. Then, we can use these patterns to match and extract the information from the input.\n",
      "\n",
      "Here's an example implementation in Python:\n",
      "\n",
      "```python\n",
      "import re\n",
      "import json\n",
      "\n",
      "def extract_medical_info(medical_fact):\n",
      "    # Define patterns for location, specific, and general observations\n",
      "    location_pattern = r\"(?i)\\b(?:at|in|of|to|adjacent to|retrocardiac position|retrosternal|retrocardiac|retroperitoneal|retroperitoneum|retroperitoneal space|retroperitoneal region|retroperitoneal area|retroperitoneal mass|retroperitoneal tumor|retroperitoneal lesion|retroperitoneal cyst|retroperitoneal abscess\n",
      "2023-06-27 22:58:48,334 - \u001b[1;32mINFO\u001b[1;0m - Deleting API requests and responses\n",
      "2023-06-27 22:58:48,341 - \u001b[1;32mINFO\u001b[1;0m - Succesfully processed 9647 of 9650 API responses.\n",
      "                    3 of 9650 API responses could not be processed.\n",
      "                    Saving parsed facts to /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl\n"
     ]
    }
   ],
   "source": [
    "!python ../../scripts/mimiccxr/extract_fine_grained_details_from_facts_with_openai.py \\\n",
    "    --extracted_facts_jsonl_filepath \"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_sentence_facts(68493868,63886474).jsonl\" \\\n",
    "    --offset 30000 \\\n",
    "    --num_facts 10000 \\\n",
    "    --sample_facts_uniformly \\\n",
    "    --max_requests_per_minute 3500 \\\n",
    "    --max_tokens_per_minute 85000 \\\n",
    "    --max_tokens_per_request 200 \\\n",
    "    --logging_level \"INFO\" \\\n",
    "    --api_key_name \"OPENAI_API_KEY_2\" \\\n",
    "    --openai_model_name \"gpt-3.5-turbo-0613\" \\\n",
    "    --alias \"__uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f633648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdadc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_jsonl('/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_facts__uniform.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5702acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24741"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cb25014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'fact': 'Appropriately positioned ventricular leads'},\n",
       "  'parsed_response': {'location': '',\n",
       "   'specific': 'appropriately positioned ventricular leads',\n",
       "   'general': 'ventricular leads'}},\n",
       " {'metadata': {'fact': 'Small amount of alveolar edema'},\n",
       "  'parsed_response': {'location': '',\n",
       "   'specific': 'small amount of alveolar edema',\n",
       "   'general': 'alveolar edema'}},\n",
       " {'metadata': {'fact': 'Left shoulder repair'},\n",
       "  'parsed_response': {'location': 'left shoulder',\n",
       "   'specific': 'repair',\n",
       "   'general': 'repair'}},\n",
       " {'metadata': {'fact': 'Two nodular opacities'},\n",
       "  'parsed_response': {'location': '',\n",
       "   'specific': 'two nodular opacities',\n",
       "   'general': 'nodular opacities'}},\n",
       " {'metadata': {'fact': 'Pigtail tube in right lower lateral chest wall'},\n",
       "  'parsed_response': {'location': 'right lower lateral chest wall',\n",
       "   'specific': 'pigtail tube',\n",
       "   'general': 'tube'}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
