{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,4e-5,33,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 75\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [256, 256]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "source_image_size_mode: small_256x256\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,4e-5,33,1e-6\n",
      "1e-06 7 4e-05 33 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "227835it [00:00, 391614.57it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_40_chestimgbbmf1=0.9120.pt', 'checkpoint_50_chestimgbbmf1=0.9053.pt', 'checkpoint_20_chestimgbbmf1=0.9116.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/checkpoint_40_chestimgbbmf1=0.9120.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02407, chestimgbbmf1 0.92096, chestimgbb_loss 0.01137, chestimgbbiou 0.93649, chestimgbbmae 0.02126, 204.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91384, chestimgbbiou 0.93471, chestimgbbmae 0.02197, 15.82 secs\n",
      "Adjusting learning rate of group 0 to 1.6938e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00427, chestimgbbmf1 0.92121, chestimgbb_loss 0.01192, chestimgbbiou 0.93662, chestimgbbmae 0.02122, 205.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91306, chestimgbbiou 0.93462, chestimgbbmae 0.02202, 15.98 secs\n",
      "Adjusting learning rate of group 0 to 2.8690e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00996, chestimgbbmf1 0.92128, chestimgbb_loss 0.01216, chestimgbbiou 0.93655, chestimgbbmae 0.02124, 206.79 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91393, chestimgbbiou 0.93461, chestimgbbmae 0.02201, 16.04 secs\n",
      "Adjusting learning rate of group 0 to 4.8596e-06.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00475, chestimgbbmf1 0.92197, chestimgbb_loss 0.01099, chestimgbbiou 0.93669, chestimgbbmae 0.02117, 208.10 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91295, chestimgbbiou 0.93434, chestimgbbmae 0.02212, 16.32 secs\n",
      "Adjusting learning rate of group 0 to 8.2312e-06.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01294, chestimgbbmf1 0.92047, chestimgbb_loss 0.01190, chestimgbbiou 0.93611, chestimgbbmae 0.02137, 207.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91231, chestimgbbiou 0.93395, chestimgbbmae 0.02224, 16.39 secs\n",
      "Adjusting learning rate of group 0 to 1.3942e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.00541, chestimgbbmf1 0.91787, chestimgbb_loss 0.01230, chestimgbbiou 0.93507, chestimgbbmae 0.02174, 208.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90843, chestimgbbiou 0.93236, chestimgbbmae 0.02279, 16.38 secs\n",
      "Adjusting learning rate of group 0 to 2.3615e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.00723, chestimgbbmf1 0.91492, chestimgbb_loss 0.01230, chestimgbbiou 0.93386, chestimgbbmae 0.02213, 208.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90571, chestimgbbiou 0.93177, chestimgbbmae 0.02293, 16.39 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.02705, chestimgbbmf1 0.90943, chestimgbb_loss 0.01328, chestimgbbiou 0.93155, chestimgbbmae 0.02291, 207.91 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89050, chestimgbbiou 0.92620, chestimgbbmae 0.02497, 16.02 secs\n",
      "Adjusting learning rate of group 0 to 3.5769e-05.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 0.00883, chestimgbbmf1 0.90875, chestimgbb_loss 0.01374, chestimgbbiou 0.93154, chestimgbbmae 0.02293, 207.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90051, chestimgbbiou 0.92902, chestimgbbmae 0.02401, 16.02 secs\n",
      "Adjusting learning rate of group 0 to 3.1986e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.01127, chestimgbbmf1 0.91137, chestimgbb_loss 0.01296, chestimgbbiou 0.93229, chestimgbbmae 0.02270, 207.84 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90312, chestimgbbiou 0.93043, chestimgbbmae 0.02340, 16.44 secs\n",
      "Adjusting learning rate of group 0 to 2.8603e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 0.01165, chestimgbbmf1 0.91306, chestimgbb_loss 0.01279, chestimgbbiou 0.93313, chestimgbbmae 0.02239, 208.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90337, chestimgbbiou 0.93083, chestimgbbmae 0.02325, 16.31 secs\n",
      "Adjusting learning rate of group 0 to 2.5578e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.00422, chestimgbbmf1 0.91608, chestimgbb_loss 0.01245, chestimgbbiou 0.93428, chestimgbbmae 0.02197, 208.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90697, chestimgbbiou 0.93205, chestimgbbmae 0.02285, 16.38 secs\n",
      "Adjusting learning rate of group 0 to 2.2873e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.01352, chestimgbbmf1 0.91468, chestimgbb_loss 0.01282, chestimgbbiou 0.93398, chestimgbbmae 0.02211, 207.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90593, chestimgbbiou 0.93220, chestimgbbmae 0.02276, 16.23 secs\n",
      "Adjusting learning rate of group 0 to 2.0454e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.00645, chestimgbbmf1 0.91613, chestimgbb_loss 0.01282, chestimgbbiou 0.93442, chestimgbbmae 0.02196, 207.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90683, chestimgbbiou 0.93224, chestimgbbmae 0.02280, 16.32 secs\n",
      "Adjusting learning rate of group 0 to 1.8291e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.00708, chestimgbbmf1 0.91665, chestimgbb_loss 0.01235, chestimgbbiou 0.93469, chestimgbbmae 0.02185, 204.53 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90898, chestimgbbiou 0.93313, chestimgbbmae 0.02245, 15.04 secs\n",
      "Adjusting learning rate of group 0 to 1.6356e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01739, chestimgbbmf1 0.91794, chestimgbb_loss 0.01239, chestimgbbiou 0.93513, chestimgbbmae 0.02171, 188.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91003, chestimgbbiou 0.93367, chestimgbbmae 0.02228, 14.78 secs\n",
      "Adjusting learning rate of group 0 to 1.4626e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.01696, chestimgbbmf1 0.91757, chestimgbb_loss 0.01220, chestimgbbiou 0.93509, chestimgbbmae 0.02173, 188.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91028, chestimgbbiou 0.93349, chestimgbbmae 0.02232, 14.94 secs\n",
      "Adjusting learning rate of group 0 to 1.3079e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.01348, chestimgbbmf1 0.91996, chestimgbb_loss 0.01220, chestimgbbiou 0.93568, chestimgbbmae 0.02154, 192.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91218, chestimgbbiou 0.93404, chestimgbbmae 0.02217, 14.85 secs\n",
      "Adjusting learning rate of group 0 to 1.1696e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00911, chestimgbbmf1 0.91997, chestimgbb_loss 0.01167, chestimgbbiou 0.93602, chestimgbbmae 0.02141, 188.67 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91225, chestimgbbiou 0.93407, chestimgbbmae 0.02214, 14.83 secs\n",
      "Adjusting learning rate of group 0 to 1.0459e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.01659, chestimgbbmf1 0.92051, chestimgbb_loss 0.01167, chestimgbbiou 0.93619, chestimgbbmae 0.02134, 192.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91419, chestimgbbiou 0.93486, chestimgbbmae 0.02186, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 9.3529e-06.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.00581, chestimgbbmf1 0.92111, chestimgbb_loss 0.01213, chestimgbbiou 0.93640, chestimgbbmae 0.02128, 193.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91307, chestimgbbiou 0.93470, chestimgbbmae 0.02195, 14.93 secs\n",
      "Adjusting learning rate of group 0 to 8.3637e-06.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.00927, chestimgbbmf1 0.92193, chestimgbb_loss 0.01153, chestimgbbiou 0.93661, chestimgbbmae 0.02121, 192.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91146, chestimgbbiou 0.93429, chestimgbbmae 0.02212, 14.84 secs\n",
      "Adjusting learning rate of group 0 to 7.4791e-06.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.00914, chestimgbbmf1 0.92299, chestimgbb_loss 0.01144, chestimgbbiou 0.93714, chestimgbbmae 0.02102, 192.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91419, chestimgbbiou 0.93507, chestimgbbmae 0.02181, 14.79 secs\n",
      "Adjusting learning rate of group 0 to 6.6881e-06.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.00671, chestimgbbmf1 0.92413, chestimgbb_loss 0.01053, chestimgbbiou 0.93763, chestimgbbmae 0.02083, 190.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91400, chestimgbbiou 0.93512, chestimgbbmae 0.02180, 14.62 secs\n",
      "Adjusting learning rate of group 0 to 5.9808e-06.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.00701, chestimgbbmf1 0.92280, chestimgbb_loss 0.01105, chestimgbbiou 0.93719, chestimgbbmae 0.02099, 190.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91356, chestimgbbiou 0.93477, chestimgbbmae 0.02191, 14.68 secs\n",
      "Adjusting learning rate of group 0 to 5.3482e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.03906, chestimgbbmf1 0.92204, chestimgbb_loss 0.01159, chestimgbbiou 0.93706, chestimgbbmae 0.02105, 192.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91329, chestimgbbiou 0.93447, chestimgbbmae 0.02209, 14.89 secs\n",
      "Adjusting learning rate of group 0 to 4.7826e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00574, chestimgbbmf1 0.92185, chestimgbb_loss 0.01169, chestimgbbiou 0.93684, chestimgbbmae 0.02115, 191.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91534, chestimgbbiou 0.93570, chestimgbbmae 0.02158, 14.83 secs\n",
      "Adjusting learning rate of group 0 to 4.2768e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01140, chestimgbbmf1 0.92261, chestimgbb_loss 0.01135, chestimgbbiou 0.93722, chestimgbbmae 0.02100, 192.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91471, chestimgbbiou 0.93561, chestimgbbmae 0.02161, 14.85 secs\n",
      "Adjusting learning rate of group 0 to 3.8244e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01337, chestimgbbmf1 0.92352, chestimgbb_loss 0.01094, chestimgbbiou 0.93745, chestimgbbmae 0.02092, 192.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91495, chestimgbbiou 0.93557, chestimgbbmae 0.02162, 14.79 secs\n",
      "Adjusting learning rate of group 0 to 3.4200e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00765, chestimgbbmf1 0.92330, chestimgbb_loss 0.01089, chestimgbbiou 0.93753, chestimgbbmae 0.02088, 192.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91498, chestimgbbiou 0.93556, chestimgbbmae 0.02165, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 3.0582e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02278, chestimgbbmf1 0.92337, chestimgbb_loss 0.01116, chestimgbbiou 0.93741, chestimgbbmae 0.02095, 191.90 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91486, chestimgbbiou 0.93530, chestimgbbmae 0.02176, 14.85 secs\n",
      "Adjusting learning rate of group 0 to 2.7348e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00942, chestimgbbmf1 0.92379, chestimgbb_loss 0.01123, chestimgbbiou 0.93757, chestimgbbmae 0.02089, 193.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91544, chestimgbbiou 0.93573, chestimgbbmae 0.02157, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 2.4456e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00731, chestimgbbmf1 0.92378, chestimgbb_loss 0.01059, chestimgbbiou 0.93773, chestimgbbmae 0.02083, 192.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91528, chestimgbbiou 0.93557, chestimgbbmae 0.02163, 14.82 secs\n",
      "Adjusting learning rate of group 0 to 2.1869e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00778, chestimgbbmf1 0.92425, chestimgbb_loss 0.01065, chestimgbbiou 0.93789, chestimgbbmae 0.02075, 192.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91518, chestimgbbiou 0.93574, chestimgbbmae 0.02158, 14.93 secs\n",
      "Adjusting learning rate of group 0 to 1.9556e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01098, chestimgbbmf1 0.92447, chestimgbb_loss 0.01115, chestimgbbiou 0.93784, chestimgbbmae 0.02078, 192.53 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91563, chestimgbbiou 0.93594, chestimgbbmae 0.02150, 14.86 secs\n",
      "Adjusting learning rate of group 0 to 1.7488e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01170, chestimgbbmf1 0.92408, chestimgbb_loss 0.01152, chestimgbbiou 0.93780, chestimgbbmae 0.02078, 192.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91504, chestimgbbiou 0.93570, chestimgbbmae 0.02159, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 1.5638e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01835, chestimgbbmf1 0.92377, chestimgbb_loss 0.01118, chestimgbbiou 0.93772, chestimgbbmae 0.02084, 192.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91572, chestimgbbiou 0.93586, chestimgbbmae 0.02153, 14.76 secs\n",
      "Adjusting learning rate of group 0 to 1.3984e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.00866, chestimgbbmf1 0.92441, chestimgbb_loss 0.01091, chestimgbbiou 0.93805, chestimgbbmae 0.02069, 192.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91556, chestimgbbiou 0.93575, chestimgbbmae 0.02160, 14.77 secs\n",
      "Adjusting learning rate of group 0 to 1.2505e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01012, chestimgbbmf1 0.92525, chestimgbb_loss 0.01036, chestimgbbiou 0.93823, chestimgbbmae 0.02063, 192.60 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91593, chestimgbbiou 0.93595, chestimgbbmae 0.02150, 14.78 secs\n",
      "Adjusting learning rate of group 0 to 1.1183e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.00783, chestimgbbmf1 0.92447, chestimgbb_loss 0.01098, chestimgbbiou 0.93790, chestimgbbmae 0.02077, 192.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91578, chestimgbbiou 0.93594, chestimgbbmae 0.02151, 14.82 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 75 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,4e-5,33,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --use-chest-imagenome-decent-images-only \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
