{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,4e-5,33,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 75\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [256, 256]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "source_image_size_mode: small_256x256\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,4e-5,33,1e-6\n",
      "1e-06 7 4e-05 33 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "227835it [00:00, 391614.57it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_40_chestimgbbmf1=0.9120.pt', 'checkpoint_50_chestimgbbmf1=0.9053.pt', 'checkpoint_20_chestimgbbmf1=0.9116.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121/checkpoint_40_chestimgbbmf1=0.9120.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02407, chestimgbbmf1 0.92096, chestimgbb_loss 0.01137, chestimgbbiou 0.93649, chestimgbbmae 0.02126, 204.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91384, chestimgbbiou 0.93471, chestimgbbmae 0.02197, 15.82 secs\n",
      "Adjusting learning rate of group 0 to 1.6938e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00427, chestimgbbmf1 0.92121, chestimgbb_loss 0.01192, chestimgbbiou 0.93662, chestimgbbmae 0.02122, 205.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91306, chestimgbbiou 0.93462, chestimgbbmae 0.02202, 15.98 secs\n",
      "Adjusting learning rate of group 0 to 2.8690e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00996, chestimgbbmf1 0.92128, chestimgbb_loss 0.01216, chestimgbbiou 0.93655, chestimgbbmae 0.02124, 206.79 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91393, chestimgbbiou 0.93461, chestimgbbmae 0.02201, 16.04 secs\n",
      "Adjusting learning rate of group 0 to 4.8596e-06.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00475, chestimgbbmf1 0.92197, chestimgbb_loss 0.01099, chestimgbbiou 0.93669, chestimgbbmae 0.02117, 208.10 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91295, chestimgbbiou 0.93434, chestimgbbmae 0.02212, 16.32 secs\n",
      "Adjusting learning rate of group 0 to 8.2312e-06.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01294, chestimgbbmf1 0.92047, chestimgbb_loss 0.01190, chestimgbbiou 0.93611, chestimgbbmae 0.02137, 207.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91231, chestimgbbiou 0.93395, chestimgbbmae 0.02224, 16.39 secs\n",
      "Adjusting learning rate of group 0 to 1.3942e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.00541, chestimgbbmf1 0.91787, chestimgbb_loss 0.01230, chestimgbbiou 0.93507, chestimgbbmae 0.02174, 208.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90843, chestimgbbiou 0.93236, chestimgbbmae 0.02279, 16.38 secs\n",
      "Adjusting learning rate of group 0 to 2.3615e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 0.00723, chestimgbbmf1 0.91492, chestimgbb_loss 0.01230, chestimgbbiou 0.93386, chestimgbbmae 0.02213, 208.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90571, chestimgbbiou 0.93177, chestimgbbmae 0.02293, 16.39 secs\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.02705, chestimgbbmf1 0.90943, chestimgbb_loss 0.01328, chestimgbbiou 0.93155, chestimgbbmae 0.02291, 207.91 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.89050, chestimgbbiou 0.92620, chestimgbbmae 0.02497, 16.02 secs\n",
      "Adjusting learning rate of group 0 to 3.5769e-05.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000036) ...\n",
      "loss 0.00883, chestimgbbmf1 0.90875, chestimgbb_loss 0.01374, chestimgbbiou 0.93154, chestimgbbmae 0.02293, 207.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90051, chestimgbbiou 0.92902, chestimgbbmae 0.02401, 16.02 secs\n",
      "Adjusting learning rate of group 0 to 3.1986e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.01127, chestimgbbmf1 0.91137, chestimgbb_loss 0.01296, chestimgbbiou 0.93229, chestimgbbmae 0.02270, 207.84 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90312, chestimgbbiou 0.93043, chestimgbbmae 0.02340, 16.44 secs\n",
      "Adjusting learning rate of group 0 to 2.8603e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 0.01165, chestimgbbmf1 0.91306, chestimgbb_loss 0.01279, chestimgbbiou 0.93313, chestimgbbmae 0.02239, 208.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90337, chestimgbbiou 0.93083, chestimgbbmae 0.02325, 16.31 secs\n",
      "Adjusting learning rate of group 0 to 2.5578e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.00422, chestimgbbmf1 0.91608, chestimgbb_loss 0.01245, chestimgbbiou 0.93428, chestimgbbmae 0.02197, 208.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90697, chestimgbbiou 0.93205, chestimgbbmae 0.02285, 16.38 secs\n",
      "Adjusting learning rate of group 0 to 2.2873e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.01352, chestimgbbmf1 0.91468, chestimgbb_loss 0.01282, chestimgbbiou 0.93398, chestimgbbmae 0.02211, 207.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90593, chestimgbbiou 0.93220, chestimgbbmae 0.02276, 16.23 secs\n",
      "Adjusting learning rate of group 0 to 2.0454e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 0.00645, chestimgbbmf1 0.91613, chestimgbb_loss 0.01282, chestimgbbiou 0.93442, chestimgbbmae 0.02196, 207.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90683, chestimgbbiou 0.93224, chestimgbbmae 0.02280, 16.32 secs\n",
      "Adjusting learning rate of group 0 to 1.8291e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.00708, chestimgbbmf1 0.91665, chestimgbb_loss 0.01235, chestimgbbiou 0.93469, chestimgbbmae 0.02185, 204.53 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.90898, chestimgbbiou 0.93313, chestimgbbmae 0.02245, 15.04 secs\n",
      "Adjusting learning rate of group 0 to 1.6356e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01739, chestimgbbmf1 0.91794, chestimgbb_loss 0.01239, chestimgbbiou 0.93513, chestimgbbmae 0.02171, 188.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91003, chestimgbbiou 0.93367, chestimgbbmae 0.02228, 14.78 secs\n",
      "Adjusting learning rate of group 0 to 1.4626e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.01696, chestimgbbmf1 0.91757, chestimgbb_loss 0.01220, chestimgbbiou 0.93509, chestimgbbmae 0.02173, 188.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91028, chestimgbbiou 0.93349, chestimgbbmae 0.02232, 14.94 secs\n",
      "Adjusting learning rate of group 0 to 1.3079e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.01348, chestimgbbmf1 0.91996, chestimgbb_loss 0.01220, chestimgbbiou 0.93568, chestimgbbmae 0.02154, 192.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91218, chestimgbbiou 0.93404, chestimgbbmae 0.02217, 14.85 secs\n",
      "Adjusting learning rate of group 0 to 1.1696e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00911, chestimgbbmf1 0.91997, chestimgbb_loss 0.01167, chestimgbbiou 0.93602, chestimgbbmae 0.02141, 188.67 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91225, chestimgbbiou 0.93407, chestimgbbmae 0.02214, 14.83 secs\n",
      "Adjusting learning rate of group 0 to 1.0459e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.01659, chestimgbbmf1 0.92051, chestimgbb_loss 0.01167, chestimgbbiou 0.93619, chestimgbbmae 0.02134, 192.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91419, chestimgbbiou 0.93486, chestimgbbmae 0.02186, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 9.3529e-06.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.00581, chestimgbbmf1 0.92111, chestimgbb_loss 0.01213, chestimgbbiou 0.93640, chestimgbbmae 0.02128, 193.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91307, chestimgbbiou 0.93470, chestimgbbmae 0.02195, 14.93 secs\n",
      "Adjusting learning rate of group 0 to 8.3637e-06.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.00927, chestimgbbmf1 0.92193, chestimgbb_loss 0.01153, chestimgbbiou 0.93661, chestimgbbmae 0.02121, 192.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91146, chestimgbbiou 0.93429, chestimgbbmae 0.02212, 14.84 secs\n",
      "Adjusting learning rate of group 0 to 7.4791e-06.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.00914, chestimgbbmf1 0.92299, chestimgbb_loss 0.01144, chestimgbbiou 0.93714, chestimgbbmae 0.02102, 192.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91419, chestimgbbiou 0.93507, chestimgbbmae 0.02181, 14.79 secs\n",
      "Adjusting learning rate of group 0 to 6.6881e-06.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.00671, chestimgbbmf1 0.92413, chestimgbb_loss 0.01053, chestimgbbiou 0.93763, chestimgbbmae 0.02083, 190.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91400, chestimgbbiou 0.93512, chestimgbbmae 0.02180, 14.62 secs\n",
      "Adjusting learning rate of group 0 to 5.9808e-06.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.00701, chestimgbbmf1 0.92280, chestimgbb_loss 0.01105, chestimgbbiou 0.93719, chestimgbbmae 0.02099, 190.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91356, chestimgbbiou 0.93477, chestimgbbmae 0.02191, 14.68 secs\n",
      "Adjusting learning rate of group 0 to 5.3482e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.03906, chestimgbbmf1 0.92204, chestimgbb_loss 0.01159, chestimgbbiou 0.93706, chestimgbbmae 0.02105, 192.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91329, chestimgbbiou 0.93447, chestimgbbmae 0.02209, 14.89 secs\n",
      "Adjusting learning rate of group 0 to 4.7826e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00574, chestimgbbmf1 0.92185, chestimgbb_loss 0.01169, chestimgbbiou 0.93684, chestimgbbmae 0.02115, 191.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91534, chestimgbbiou 0.93570, chestimgbbmae 0.02158, 14.83 secs\n",
      "Adjusting learning rate of group 0 to 4.2768e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01140, chestimgbbmf1 0.92261, chestimgbb_loss 0.01135, chestimgbbiou 0.93722, chestimgbbmae 0.02100, 192.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91471, chestimgbbiou 0.93561, chestimgbbmae 0.02161, 14.85 secs\n",
      "Adjusting learning rate of group 0 to 3.8244e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01337, chestimgbbmf1 0.92352, chestimgbb_loss 0.01094, chestimgbbiou 0.93745, chestimgbbmae 0.02092, 192.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91495, chestimgbbiou 0.93557, chestimgbbmae 0.02162, 14.79 secs\n",
      "Adjusting learning rate of group 0 to 3.4200e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00765, chestimgbbmf1 0.92330, chestimgbb_loss 0.01089, chestimgbbiou 0.93753, chestimgbbmae 0.02088, 192.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91498, chestimgbbiou 0.93556, chestimgbbmae 0.02165, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 3.0582e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02278, chestimgbbmf1 0.92337, chestimgbb_loss 0.01116, chestimgbbiou 0.93741, chestimgbbmae 0.02095, 191.90 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91486, chestimgbbiou 0.93530, chestimgbbmae 0.02176, 14.85 secs\n",
      "Adjusting learning rate of group 0 to 2.7348e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00942, chestimgbbmf1 0.92379, chestimgbb_loss 0.01123, chestimgbbiou 0.93757, chestimgbbmae 0.02089, 193.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91544, chestimgbbiou 0.93573, chestimgbbmae 0.02157, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 2.4456e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00731, chestimgbbmf1 0.92378, chestimgbb_loss 0.01059, chestimgbbiou 0.93773, chestimgbbmae 0.02083, 192.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91528, chestimgbbiou 0.93557, chestimgbbmae 0.02163, 14.82 secs\n",
      "Adjusting learning rate of group 0 to 2.1869e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00778, chestimgbbmf1 0.92425, chestimgbb_loss 0.01065, chestimgbbiou 0.93789, chestimgbbmae 0.02075, 192.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91518, chestimgbbiou 0.93574, chestimgbbmae 0.02158, 14.93 secs\n",
      "Adjusting learning rate of group 0 to 1.9556e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01098, chestimgbbmf1 0.92447, chestimgbb_loss 0.01115, chestimgbbiou 0.93784, chestimgbbmae 0.02078, 192.53 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91563, chestimgbbiou 0.93594, chestimgbbmae 0.02150, 14.86 secs\n",
      "Adjusting learning rate of group 0 to 1.7488e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01170, chestimgbbmf1 0.92408, chestimgbb_loss 0.01152, chestimgbbiou 0.93780, chestimgbbmae 0.02078, 192.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91504, chestimgbbiou 0.93570, chestimgbbmae 0.02159, 14.80 secs\n",
      "Adjusting learning rate of group 0 to 1.5638e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01835, chestimgbbmf1 0.92377, chestimgbb_loss 0.01118, chestimgbbiou 0.93772, chestimgbbmae 0.02084, 192.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91572, chestimgbbiou 0.93586, chestimgbbmae 0.02153, 14.76 secs\n",
      "Adjusting learning rate of group 0 to 1.3984e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.00866, chestimgbbmf1 0.92441, chestimgbb_loss 0.01091, chestimgbbiou 0.93805, chestimgbbmae 0.02069, 192.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91556, chestimgbbiou 0.93575, chestimgbbmae 0.02160, 14.77 secs\n",
      "Adjusting learning rate of group 0 to 1.2505e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01012, chestimgbbmf1 0.92525, chestimgbb_loss 0.01036, chestimgbbiou 0.93823, chestimgbbmae 0.02063, 192.60 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91593, chestimgbbiou 0.93595, chestimgbbmae 0.02150, 14.78 secs\n",
      "Adjusting learning rate of group 0 to 1.1183e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.00783, chestimgbbmf1 0.92447, chestimgbb_loss 0.01098, chestimgbbiou 0.93790, chestimgbbmae 0.02077, 192.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.91578, chestimgbbiou 0.93594, chestimgbbmae 0.02151, 14.82 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230221_174959_mim_dn121\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 75 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,7,4e-5,33,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --use-chest-imagenome-decent-images-only \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 50\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,2e-4,42,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 75\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [256, 256]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "source_image_size_mode: small_256x256\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,2e-4,42,1e-6\n",
      "1e-06 8 0.0002 42 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "227835it [00:00, 346546.50it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.74379, chestimgbbmf1 0.00544, chestimgbb_loss 0.63000, chestimgbbiou 0.62312, chestimgbbmae 0.15924, 233.06 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.00680, chestimgbbiou 0.64072, chestimgbbmae 0.14906, 19.01 secs\n",
      "Adjusting learning rate of group 0 to 1.9392e-06.\n",
      "\u001b[1m---- Epoch 2/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.52761, chestimgbbmf1 0.00833, chestimgbb_loss 0.38782, chestimgbbiou 0.65766, chestimgbbmae 0.13902, 244.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.00841, chestimgbbiou 0.66610, chestimgbbmae 0.13430, 19.51 secs\n",
      "Adjusting learning rate of group 0 to 3.7606e-06.\n",
      "\u001b[1m---- Epoch 3/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.27413, chestimgbbmf1 0.01176, chestimgbb_loss 0.17432, chestimgbbiou 0.68559, chestimgbbmae 0.12416, 242.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.01350, chestimgbbiou 0.69823, chestimgbbmae 0.11794, 20.38 secs\n",
      "Adjusting learning rate of group 0 to 7.2927e-06.\n",
      "\u001b[1m---- Epoch 4/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.11206, chestimgbbmf1 0.02103, chestimgbb_loss 0.07974, chestimgbbiou 0.72376, chestimgbbmae 0.10569, 250.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.02569, chestimgbbiou 0.73775, chestimgbbmae 0.09921, 20.79 secs\n",
      "Adjusting learning rate of group 0 to 1.4142e-05.\n",
      "\u001b[1m---- Epoch 5/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.05262, chestimgbbmf1 0.04119, chestimgbb_loss 0.05087, chestimgbbiou 0.76242, chestimgbbmae 0.08821, 252.61 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.05302, chestimgbbiou 0.77687, chestimgbbmae 0.08201, 19.10 secs\n",
      "Adjusting learning rate of group 0 to 2.7425e-05.\n",
      "\u001b[1m---- Epoch 6/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.04709, chestimgbbmf1 0.08518, chestimgbb_loss 0.04001, chestimgbbiou 0.80038, chestimgbbmae 0.07202, 246.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.11266, chestimgbbiou 0.81453, chestimgbbmae 0.06634, 21.84 secs\n",
      "Adjusting learning rate of group 0 to 5.3183e-05.\n",
      "\u001b[1m---- Epoch 7/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 0.03779, chestimgbbmf1 0.16882, chestimgbb_loss 0.03631, chestimgbbiou 0.83380, chestimgbbmae 0.05854, 251.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21173, chestimgbbiou 0.84449, chestimgbbmae 0.05437, 21.31 secs\n",
      "Adjusting learning rate of group 0 to 1.0313e-04.\n",
      "\u001b[1m---- Epoch 8/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000103) ...\n",
      "loss 0.02242, chestimgbbmf1 0.24779, chestimgbb_loss 0.03127, chestimgbbiou 0.85315, chestimgbbmae 0.05101, 253.84 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.27436, chestimgbbiou 0.85640, chestimgbbmae 0.04972, 20.17 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 9/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 0.02509, chestimgbbmf1 0.24298, chestimgbb_loss 0.03051, chestimgbbiou 0.84619, chestimgbbmae 0.05404, 256.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.31682, chestimgbbiou 0.86563, chestimgbbmae 0.04645, 21.74 secs\n",
      "Adjusting learning rate of group 0 to 1.7630e-04.\n",
      "\u001b[1m---- Epoch 10/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000176) ...\n",
      "loss 0.01287, chestimgbbmf1 0.40702, chestimgbb_loss 0.02700, chestimgbbiou 0.87708, chestimgbbmae 0.04202, 269.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.41213, chestimgbbiou 0.87540, chestimgbbmae 0.04293, 30.65 secs\n",
      "Adjusting learning rate of group 0 to 1.5540e-04.\n",
      "\u001b[1m---- Epoch 11/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 0.02597, chestimgbbmf1 0.46700, chestimgbb_loss 0.02639, chestimgbbiou 0.88438, chestimgbbmae 0.03938, 357.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.47221, chestimgbbiou 0.88392, chestimgbbmae 0.03983, 33.84 secs\n",
      "Adjusting learning rate of group 0 to 1.3698e-04.\n",
      "\u001b[1m---- Epoch 12/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000137) ...\n",
      "loss 0.00686, chestimgbbmf1 0.51348, chestimgbb_loss 0.02366, chestimgbbiou 0.88981, chestimgbbmae 0.03740, 412.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.48650, chestimgbbiou 0.88547, chestimgbbmae 0.03911, 24.33 secs\n",
      "Adjusting learning rate of group 0 to 1.2075e-04.\n",
      "\u001b[1m---- Epoch 13/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000121) ...\n",
      "loss 0.03353, chestimgbbmf1 0.53593, chestimgbb_loss 0.02452, chestimgbbiou 0.89189, chestimgbbmae 0.03665, 302.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.53289, chestimgbbiou 0.88848, chestimgbbmae 0.03821, 25.32 secs\n",
      "Adjusting learning rate of group 0 to 1.0644e-04.\n",
      "\u001b[1m---- Epoch 14/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 0.05817, chestimgbbmf1 0.55255, chestimgbb_loss 0.02399, chestimgbbiou 0.89388, chestimgbbmae 0.03595, 327.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.52483, chestimgbbiou 0.88870, chestimgbbmae 0.03810, 29.17 secs\n",
      "Adjusting learning rate of group 0 to 9.3823e-05.\n",
      "\u001b[1m---- Epoch 15/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 0.01373, chestimgbbmf1 0.58343, chestimgbb_loss 0.02189, chestimgbbiou 0.89703, chestimgbbmae 0.03484, 311.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.55517, chestimgbbiou 0.89307, chestimgbbmae 0.03635, 29.71 secs\n",
      "Adjusting learning rate of group 0 to 8.2704e-05.\n",
      "\u001b[1m---- Epoch 16/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000083) ...\n",
      "loss 0.04619, chestimgbbmf1 0.60878, chestimgbb_loss 0.02387, chestimgbbiou 0.89992, chestimgbbmae 0.03380, 290.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.61604, chestimgbbiou 0.89967, chestimgbbmae 0.03408, 27.89 secs\n",
      "Adjusting learning rate of group 0 to 7.2902e-05.\n",
      "\u001b[1m---- Epoch 17/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000073) ...\n",
      "loss 0.01316, chestimgbbmf1 0.62685, chestimgbb_loss 0.02076, chestimgbbiou 0.90208, chestimgbbmae 0.03302, 294.97 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.61045, chestimgbbiou 0.89911, chestimgbbmae 0.03422, 35.39 secs\n",
      "Adjusting learning rate of group 0 to 6.4262e-05.\n",
      "\u001b[1m---- Epoch 18/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000064) ...\n",
      "loss 0.01182, chestimgbbmf1 0.64083, chestimgbb_loss 0.02161, chestimgbbiou 0.90334, chestimgbbmae 0.03260, 298.86 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.62261, chestimgbbiou 0.90041, chestimgbbmae 0.03385, 29.32 secs\n",
      "Adjusting learning rate of group 0 to 5.6646e-05.\n",
      "\u001b[1m---- Epoch 19/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000057) ...\n",
      "loss 0.01780, chestimgbbmf1 0.65018, chestimgbb_loss 0.02065, chestimgbbiou 0.90429, chestimgbbmae 0.03226, 314.02 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.64734, chestimgbbiou 0.90355, chestimgbbmae 0.03267, 25.32 secs\n",
      "Adjusting learning rate of group 0 to 4.9932e-05.\n",
      "\u001b[1m---- Epoch 20/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000050) ...\n",
      "loss 0.01469, chestimgbbmf1 0.66182, chestimgbb_loss 0.02091, chestimgbbiou 0.90576, chestimgbbmae 0.03176, 303.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.65012, chestimgbbiou 0.90343, chestimgbbmae 0.03275, 21.74 secs\n",
      "Adjusting learning rate of group 0 to 4.4014e-05.\n",
      "\u001b[1m---- Epoch 21/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 0.01419, chestimgbbmf1 0.67434, chestimgbb_loss 0.01935, chestimgbbiou 0.90725, chestimgbbmae 0.03120, 305.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66243, chestimgbbiou 0.90387, chestimgbbmae 0.03272, 23.81 secs\n",
      "Adjusting learning rate of group 0 to 3.8798e-05.\n",
      "\u001b[1m---- Epoch 22/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 0.01813, chestimgbbmf1 0.68258, chestimgbb_loss 0.01895, chestimgbbiou 0.90816, chestimgbbmae 0.03088, 311.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.65768, chestimgbbiou 0.90394, chestimgbbmae 0.03261, 27.16 secs\n",
      "Adjusting learning rate of group 0 to 3.4200e-05.\n",
      "\u001b[1m---- Epoch 23/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 0.02904, chestimgbbmf1 0.68536, chestimgbb_loss 0.01907, chestimgbbiou 0.90855, chestimgbbmae 0.03074, 321.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66392, chestimgbbiou 0.90508, chestimgbbmae 0.03213, 25.81 secs\n",
      "Adjusting learning rate of group 0 to 3.0146e-05.\n",
      "\u001b[1m---- Epoch 24/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.03257, chestimgbbmf1 0.68995, chestimgbb_loss 0.01859, chestimgbbiou 0.90908, chestimgbbmae 0.03057, 344.37 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66484, chestimgbbiou 0.90541, chestimgbbmae 0.03203, 33.46 secs\n",
      "Adjusting learning rate of group 0 to 2.6573e-05.\n",
      "\u001b[1m---- Epoch 25/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.00403, chestimgbbmf1 0.69408, chestimgbb_loss 0.01847, chestimgbbiou 0.90962, chestimgbbmae 0.03037, 335.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66164, chestimgbbiou 0.90471, chestimgbbmae 0.03230, 28.04 secs\n",
      "Adjusting learning rate of group 0 to 2.3424e-05.\n",
      "\u001b[1m---- Epoch 26/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.00750, chestimgbbmf1 0.69767, chestimgbb_loss 0.01983, chestimgbbiou 0.90965, chestimgbbmae 0.03041, 331.56 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68099, chestimgbbiou 0.90708, chestimgbbmae 0.03144, 21.86 secs\n",
      "Adjusting learning rate of group 0 to 2.0648e-05.\n",
      "\u001b[1m---- Epoch 27/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 0.01095, chestimgbbmf1 0.70377, chestimgbb_loss 0.01911, chestimgbbiou 0.91062, chestimgbbmae 0.03003, 309.88 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68091, chestimgbbiou 0.90766, chestimgbbmae 0.03118, 23.52 secs\n",
      "Adjusting learning rate of group 0 to 1.8201e-05.\n",
      "\u001b[1m---- Epoch 28/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.01636, chestimgbbmf1 0.70753, chestimgbb_loss 0.01827, chestimgbbiou 0.91110, chestimgbbmae 0.02985, 305.32 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68727, chestimgbbiou 0.90777, chestimgbbmae 0.03124, 24.75 secs\n",
      "Adjusting learning rate of group 0 to 1.6044e-05.\n",
      "\u001b[1m---- Epoch 29/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01171, chestimgbbmf1 0.71030, chestimgbb_loss 0.01799, chestimgbbiou 0.91151, chestimgbbmae 0.02971, 320.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.69319, chestimgbbiou 0.90852, chestimgbbmae 0.03098, 27.36 secs\n",
      "Adjusting learning rate of group 0 to 1.4142e-05.\n",
      "\u001b[1m---- Epoch 30/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.00426, chestimgbbmf1 0.71223, chestimgbb_loss 0.01885, chestimgbbiou 0.91169, chestimgbbmae 0.02966, 343.10 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.69207, chestimgbbiou 0.90859, chestimgbbmae 0.03093, 31.68 secs\n",
      "Adjusting learning rate of group 0 to 1.2466e-05.\n",
      "\u001b[1m---- Epoch 31/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.01403, chestimgbbmf1 0.71645, chestimgbb_loss 0.01880, chestimgbbiou 0.91204, chestimgbbmae 0.02956, 324.37 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68841, chestimgbbiou 0.90814, chestimgbbmae 0.03107, 28.27 secs\n",
      "Adjusting learning rate of group 0 to 1.0989e-05.\n",
      "\u001b[1m---- Epoch 32/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.01483, chestimgbbmf1 0.71348, chestimgbb_loss 0.01865, chestimgbbiou 0.91159, chestimgbbmae 0.02972, 316.42 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.69035, chestimgbbiou 0.90818, chestimgbbmae 0.03107, 22.68 secs\n",
      "Adjusting learning rate of group 0 to 9.6863e-06.\n",
      "\u001b[1m---- Epoch 33/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.01886, chestimgbbmf1 0.71816, chestimgbb_loss 0.01773, chestimgbbiou 0.91233, chestimgbbmae 0.02945, 344.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70116, chestimgbbiou 0.90937, chestimgbbmae 0.03066, 28.35 secs\n",
      "Adjusting learning rate of group 0 to 8.5383e-06.\n",
      "\u001b[1m---- Epoch 34/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.02903, chestimgbbmf1 0.72378, chestimgbb_loss 0.01675, chestimgbbiou 0.91319, chestimgbbmae 0.02914, 397.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.69870, chestimgbbiou 0.90906, chestimgbbmae 0.03083, 26.37 secs\n",
      "Adjusting learning rate of group 0 to 7.5263e-06.\n",
      "\u001b[1m---- Epoch 35/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01129, chestimgbbmf1 0.72278, chestimgbb_loss 0.01730, chestimgbbiou 0.91294, chestimgbbmae 0.02923, 340.13 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70057, chestimgbbiou 0.90959, chestimgbbmae 0.03058, 25.10 secs\n",
      "Adjusting learning rate of group 0 to 6.6343e-06.\n",
      "\u001b[1m---- Epoch 36/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.00856, chestimgbbmf1 0.72057, chestimgbb_loss 0.01670, chestimgbbiou 0.91269, chestimgbbmae 0.02931, 342.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70460, chestimgbbiou 0.91026, chestimgbbmae 0.03033, 30.59 secs\n",
      "Adjusting learning rate of group 0 to 5.8480e-06.\n",
      "\u001b[1m---- Epoch 37/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.01869, chestimgbbmf1 0.72710, chestimgbb_loss 0.01829, chestimgbbiou 0.91357, chestimgbbmae 0.02901, 350.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70161, chestimgbbiou 0.90946, chestimgbbmae 0.03066, 22.49 secs\n",
      "Adjusting learning rate of group 0 to 5.1549e-06.\n",
      "\u001b[1m---- Epoch 38/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.02018, chestimgbbmf1 0.72433, chestimgbb_loss 0.01847, chestimgbbiou 0.91321, chestimgbbmae 0.02913, 332.99 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70279, chestimgbbiou 0.90970, chestimgbbmae 0.03055, 26.24 secs\n",
      "Adjusting learning rate of group 0 to 4.5440e-06.\n",
      "\u001b[1m---- Epoch 39/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00875, chestimgbbmf1 0.72766, chestimgbb_loss 0.01698, chestimgbbiou 0.91369, chestimgbbmae 0.02896, 355.12 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70907, chestimgbbiou 0.91069, chestimgbbmae 0.03021, 23.87 secs\n",
      "Adjusting learning rate of group 0 to 4.0054e-06.\n",
      "\u001b[1m---- Epoch 40/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01472, chestimgbbmf1 0.72795, chestimgbb_loss 0.01696, chestimgbbiou 0.91351, chestimgbbmae 0.02903, 326.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70805, chestimgbbiou 0.91045, chestimgbbmae 0.03032, 27.67 secs\n",
      "Adjusting learning rate of group 0 to 3.5307e-06.\n",
      "\u001b[1m---- Epoch 41/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01114, chestimgbbmf1 0.73142, chestimgbb_loss 0.01686, chestimgbbiou 0.91392, chestimgbbmae 0.02890, 320.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71101, chestimgbbiou 0.91107, chestimgbbmae 0.03007, 32.19 secs\n",
      "Adjusting learning rate of group 0 to 3.1123e-06.\n",
      "\u001b[1m---- Epoch 42/50\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00430, chestimgbbmf1 0.73375, chestimgbb_loss 0.01722, chestimgbbiou 0.91440, chestimgbbmae 0.02872, 304.52 secs\n",
      "(2) Validation stage ...\n",
      "Current run is terminating due to exception: Caught AttributeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/mimiccxr/mimiccxr_vision_dataset_management.py\", line 156, in __getitem__\n",
      "    image = self.image_transform(image_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 437, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/image_processing.py\", line 184, in <lambda>\n",
      "    print('    augmentation_mode =', augmentation_mode)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2820, in open\n",
      "    See: :ref:`concept-modes`.\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 342, in preinit\n",
      "    \"\"\"Explicitly load standard file format drivers.\"\"\"\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/JpegImagePlugin.py\", line 44, in <module>\n",
      "    from . import Image, ImageFile, TiffImagePlugin\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 418, in <module>\n",
      "    class ImageFileDirectory_v2(MutableMapping):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 695, in ImageFileDirectory_v2\n",
      "    (TiffTags.IFD, \"L\", \"long\"),\n",
      "AttributeError: module 'PIL.TiffTags' has no attribute 'IFD'\n",
      "\n",
      "Engine run is terminating due to exception: Caught AttributeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/mimiccxr/mimiccxr_vision_dataset_management.py\", line 156, in __getitem__\n",
      "    image = self.image_transform(image_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 437, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/image_processing.py\", line 184, in <lambda>\n",
      "    print('    augmentation_mode =', augmentation_mode)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2820, in open\n",
      "    See: :ref:`concept-modes`.\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 342, in preinit\n",
      "    \"\"\"Explicitly load standard file format drivers.\"\"\"\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/JpegImagePlugin.py\", line 44, in <module>\n",
      "    from . import Image, ImageFile, TiffImagePlugin\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 418, in <module>\n",
      "    class ImageFileDirectory_v2(MutableMapping):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 695, in ImageFileDirectory_v2\n",
      "    (TiffTags.IFD, \"L\", \"long\"),\n",
      "AttributeError: module 'PIL.TiffTags' has no attribute 'IFD'\n",
      "\n",
      "Engine run is terminating due to exception: Caught AttributeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/mimiccxr/mimiccxr_vision_dataset_management.py\", line 156, in __getitem__\n",
      "    image = self.image_transform(image_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 437, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/image_processing.py\", line 184, in <lambda>\n",
      "    print('    augmentation_mode =', augmentation_mode)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2820, in open\n",
      "    See: :ref:`concept-modes`.\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 342, in preinit\n",
      "    \"\"\"Explicitly load standard file format drivers.\"\"\"\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/JpegImagePlugin.py\", line 44, in <module>\n",
      "    from . import Image, ImageFile, TiffImagePlugin\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 418, in <module>\n",
      "    class ImageFileDirectory_v2(MutableMapping):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 695, in ImageFileDirectory_v2\n",
      "    (TiffTags.IFD, \"L\", \"long\"),\n",
      "AttributeError: module 'PIL.TiffTags' has no attribute 'IFD'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_visual_module.py\", line 1316, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_visual_module.py\", line 1216, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_visual_module.py\", line 805, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 751, in _internal_run\n",
      "    self._fire_event(Events.EPOCH_COMPLETED)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"../train_visual_module.py\", line 792, in <lambda>\n",
      "    max_epochs=1, epoch_length=val_dataloader_size))\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 801, in _run_once_on_dataset\n",
      "    self.state.batch = next(self._dataloader_iter)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/dataloading_utils.py\", line 176, in multi_cyclic_dataloaders_generator\n",
      "    for batch in dataloader:\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "AttributeError: Caught AttributeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/mimiccxr/mimiccxr_vision_dataset_management.py\", line 156, in __getitem__\n",
      "    image = self.image_transform(image_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 437, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/pamessina/medvqa/medvqa/datasets/image_processing.py\", line 184, in <lambda>\n",
      "    print('    augmentation_mode =', augmentation_mode)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 2820, in open\n",
      "    See: :ref:`concept-modes`.\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/Image.py\", line 342, in preinit\n",
      "    \"\"\"Explicitly load standard file format drivers.\"\"\"\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/JpegImagePlugin.py\", line 44, in <module>\n",
      "    from . import Image, ImageFile, TiffImagePlugin\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 418, in <module>\n",
      "    class ImageFileDirectory_v2(MutableMapping):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 695, in ImageFileDirectory_v2\n",
      "    (TiffTags.IFD, \"L\", \"long\"),\n",
      "AttributeError: module 'PIL.TiffTags' has no attribute 'IFD'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --epochs 50 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 75 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,2e-4,42,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --use-chest-imagenome-decent-images-only \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 10\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: models/visual_module/20230227_130158_mim_dn121\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   num_regions: None\n",
      "   optimizer_name: adam\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 75\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: False\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,2e-4,42,1e-6\n",
      "1e-06 8 0.0002 42 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "227835it [00:00, 308351.27it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_41_chestimgbbmf1=0.7131.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/checkpoint_41_chestimgbbmf1=0.7131.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 42/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01560, chestimgbbmf1 0.73039, chestimgbb_loss 0.01733, chestimgbbiou 0.91396, chestimgbbmae 0.02887, 268.29 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71048, chestimgbbiou 0.91079, chestimgbbmae 0.03017, 20.93 secs\n",
      "Adjusting learning rate of group 0 to 2.7434e-06.\n",
      "\u001b[1m---- Epoch 43/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00900, chestimgbbmf1 0.73097, chestimgbb_loss 0.01651, chestimgbbiou 0.91401, chestimgbbmae 0.02885, 294.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70768, chestimgbbiou 0.91040, chestimgbbmae 0.03032, 22.98 secs\n",
      "Adjusting learning rate of group 0 to 2.4183e-06.\n",
      "\u001b[1m---- Epoch 44/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00488, chestimgbbmf1 0.73311, chestimgbb_loss 0.01687, chestimgbbiou 0.91425, chestimgbbmae 0.02878, 287.60 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70738, chestimgbbiou 0.91011, chestimgbbmae 0.03046, 23.30 secs\n",
      "Adjusting learning rate of group 0 to 2.1317e-06.\n",
      "\u001b[1m---- Epoch 45/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01908, chestimgbbmf1 0.72921, chestimgbb_loss 0.01677, chestimgbbiou 0.91389, chestimgbbmae 0.02888, 287.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70648, chestimgbbiou 0.91003, chestimgbbmae 0.03048, 21.09 secs\n",
      "Adjusting learning rate of group 0 to 1.8790e-06.\n",
      "\u001b[1m---- Epoch 46/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02252, chestimgbbmf1 0.73189, chestimgbb_loss 0.01714, chestimgbbiou 0.91413, chestimgbbmae 0.02882, 295.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70895, chestimgbbiou 0.91047, chestimgbbmae 0.03031, 24.34 secs\n",
      "Adjusting learning rate of group 0 to 1.6563e-06.\n",
      "\u001b[1m---- Epoch 47/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01621, chestimgbbmf1 0.73368, chestimgbb_loss 0.01626, chestimgbbiou 0.91442, chestimgbbmae 0.02871, 295.50 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.70800, chestimgbbiou 0.91069, chestimgbbmae 0.03020, 23.36 secs\n",
      "Adjusting learning rate of group 0 to 1.4600e-06.\n",
      "\u001b[1m---- Epoch 48/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02019, chestimgbbmf1 0.73006, chestimgbb_loss 0.01711, chestimgbbiou 0.91387, chestimgbbmae 0.02892, 297.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70952, chestimgbbiou 0.91077, chestimgbbmae 0.03019, 23.16 secs\n",
      "Adjusting learning rate of group 0 to 1.2870e-06.\n",
      "\u001b[1m---- Epoch 49/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01778, chestimgbbmf1 0.73093, chestimgbb_loss 0.01707, chestimgbbiou 0.91401, chestimgbbmae 0.02885, 299.67 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70975, chestimgbbiou 0.91058, chestimgbbmae 0.03028, 24.96 secs\n",
      "Adjusting learning rate of group 0 to 1.1345e-06.\n",
      "\u001b[1m---- Epoch 50/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.02384, chestimgbbmf1 0.73555, chestimgbb_loss 0.01600, chestimgbbiou 0.91461, chestimgbbmae 0.02865, 298.69 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71231, chestimgbbiou 0.91109, chestimgbbmae 0.03007, 24.79 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[1m---- Epoch 51/51\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01212, chestimgbbmf1 0.73432, chestimgbb_loss 0.01655, chestimgbbiou 0.91451, chestimgbbmae 0.02867, 307.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71196, chestimgbbiou 0.91096, chestimgbbmae 0.03011, 21.62 secs\n",
      "Adjusting learning rate of group 0 to 8.8148e-07.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --checkpoint-folder \"models/visual_module/20230227_130158_mim_dn121\" \\\n",
    "        --epochs 10 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 75 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 66\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: models/visual_module/20230227_130158_mim_dn121\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: None\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,6,6e-5,10,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 75\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: False\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: True\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+cyclicdecay scheduler: 1e-6,6,6e-5,10,1e-6\n",
      "1e-06 6 6e-05 10 1e-06\n",
      "self.steps_to_restart = 10\n",
      "self.steps = -1\n",
      "self.initial_lr = 6e-05\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "get_image_transform()\n",
      "Using standard transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "227835it [00:00, 420802.88it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_41_chestimgbbmf1=0.7131.pt', 'checkpoint_50_chestimgbbmf1=0.7146.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/checkpoint_50_chestimgbbmf1=0.7146.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 51/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.00491, chestimgbbmf1 0.73120, chestimgbb_loss 0.01734, chestimgbbiou 0.91421, chestimgbbmae 0.02878, 191.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70872, chestimgbbiou 0.91074, chestimgbbmae 0.03019, 14.83 secs\n",
      "\u001b[1m---- Epoch 52/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01513, chestimgbbmf1 0.73074, chestimgbb_loss 0.01632, chestimgbbiou 0.91400, chestimgbbmae 0.02885, 203.13 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71214, chestimgbbiou 0.91110, chestimgbbmae 0.03005, 16.08 secs\n",
      "\u001b[1m---- Epoch 53/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00614, chestimgbbmf1 0.73062, chestimgbb_loss 0.01674, chestimgbbiou 0.91400, chestimgbbmae 0.02884, 215.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70940, chestimgbbiou 0.91063, chestimgbbmae 0.03022, 17.58 secs\n",
      "\u001b[1m---- Epoch 54/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01221, chestimgbbmf1 0.72521, chestimgbb_loss 0.01648, chestimgbbiou 0.91328, chestimgbbmae 0.02910, 230.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70702, chestimgbbiou 0.91032, chestimgbbmae 0.03030, 17.56 secs\n",
      "\u001b[1m---- Epoch 55/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.00567, chestimgbbmf1 0.71389, chestimgbb_loss 0.01712, chestimgbbiou 0.91174, chestimgbbmae 0.02964, 233.50 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70196, chestimgbbiou 0.90946, chestimgbbmae 0.03062, 18.00 secs\n",
      "\u001b[1m---- Epoch 56/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.01800, chestimgbbmf1 0.69112, chestimgbb_loss 0.01763, chestimgbbiou 0.90897, chestimgbbmae 0.03061, 242.65 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68186, chestimgbbiou 0.90759, chestimgbbmae 0.03121, 18.65 secs\n",
      "\u001b[1m---- Epoch 57/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.00637, chestimgbbmf1 0.61497, chestimgbb_loss 0.01849, chestimgbbiou 0.90079, chestimgbbmae 0.03350, 253.27 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.64121, chestimgbbiou 0.90251, chestimgbbmae 0.03305, 19.39 secs\n",
      "\u001b[1m---- Epoch 58/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.02485, chestimgbbmf1 0.66412, chestimgbb_loss 0.01973, chestimgbbiou 0.90582, chestimgbbmae 0.03172, 257.86 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.64930, chestimgbbiou 0.90294, chestimgbbmae 0.03301, 19.94 secs\n",
      "\u001b[1m---- Epoch 59/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01109, chestimgbbmf1 0.72064, chestimgbb_loss 0.01690, chestimgbbiou 0.91279, chestimgbbmae 0.02925, 258.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.69597, chestimgbbiou 0.90856, chestimgbbmae 0.03091, 21.32 secs\n",
      "\u001b[1m---- Epoch 60/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01170, chestimgbbmf1 0.73970, chestimgbb_loss 0.01719, chestimgbbiou 0.91505, chestimgbbmae 0.02849, 260.84 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71652, chestimgbbiou 0.91170, chestimgbbmae 0.02983, 18.55 secs\n",
      "\u001b[1m---- Epoch 61/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.00644, chestimgbbmf1 0.75378, chestimgbb_loss 0.01601, chestimgbbiou 0.91703, chestimgbbmae 0.02780, 261.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72812, chestimgbbiou 0.91318, chestimgbbmae 0.02937, 19.23 secs\n",
      "\u001b[1m---- Epoch 62/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.02261, chestimgbbmf1 0.75995, chestimgbb_loss 0.01569, chestimgbbiou 0.91804, chestimgbbmae 0.02743, 269.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73506, chestimgbbiou 0.91437, chestimgbbmae 0.02889, 24.14 secs\n",
      "\u001b[1m---- Epoch 63/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01872, chestimgbbmf1 0.76420, chestimgbb_loss 0.01608, chestimgbbiou 0.91859, chestimgbbmae 0.02724, 269.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73980, chestimgbbiou 0.91510, chestimgbbmae 0.02865, 24.18 secs\n",
      "\u001b[1m---- Epoch 64/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.02782, chestimgbbmf1 0.76559, chestimgbb_loss 0.01553, chestimgbbiou 0.91890, chestimgbbmae 0.02713, 261.84 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73733, chestimgbbiou 0.91487, chestimgbbmae 0.02874, 19.94 secs\n",
      "\u001b[1m---- Epoch 65/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01240, chestimgbbmf1 0.76547, chestimgbb_loss 0.01580, chestimgbbiou 0.91883, chestimgbbmae 0.02717, 260.37 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74150, chestimgbbiou 0.91533, chestimgbbmae 0.02859, 22.06 secs\n",
      "\u001b[1m---- Epoch 66/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00979, chestimgbbmf1 0.76633, chestimgbb_loss 0.01527, chestimgbbiou 0.91906, chestimgbbmae 0.02708, 267.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74391, chestimgbbiou 0.91558, chestimgbbmae 0.02850, 21.86 secs\n",
      "\u001b[1m---- Epoch 67/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02309, chestimgbbmf1 0.76953, chestimgbb_loss 0.01560, chestimgbbiou 0.91943, chestimgbbmae 0.02695, 266.35 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74311, chestimgbbiou 0.91546, chestimgbbmae 0.02855, 20.67 secs\n",
      "\u001b[1m---- Epoch 68/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.02690, chestimgbbmf1 0.64382, chestimgbb_loss 0.01747, chestimgbbiou 0.90401, chestimgbbmae 0.03234, 255.01 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.64631, chestimgbbiou 0.90251, chestimgbbmae 0.03313, 19.48 secs\n",
      "\u001b[1m---- Epoch 69/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.00862, chestimgbbmf1 0.72479, chestimgbb_loss 0.01749, chestimgbbiou 0.91301, chestimgbbmae 0.02920, 267.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.70669, chestimgbbiou 0.91066, chestimgbbmae 0.03012, 20.19 secs\n",
      "\u001b[1m---- Epoch 70/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.00948, chestimgbbmf1 0.74990, chestimgbb_loss 0.01682, chestimgbbiou 0.91641, chestimgbbmae 0.02802, 264.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73018, chestimgbbiou 0.91363, chestimgbbmae 0.02915, 18.20 secs\n",
      "\u001b[1m---- Epoch 71/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.02644, chestimgbbmf1 0.75971, chestimgbb_loss 0.01732, chestimgbbiou 0.91778, chestimgbbmae 0.02755, 264.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74768, chestimgbbiou 0.91575, chestimgbbmae 0.02847, 19.28 secs\n",
      "\u001b[1m---- Epoch 72/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.01138, chestimgbbmf1 0.77272, chestimgbb_loss 0.01627, chestimgbbiou 0.91994, chestimgbbmae 0.02678, 262.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74661, chestimgbbiou 0.91619, chestimgbbmae 0.02827, 19.29 secs\n",
      "\u001b[1m---- Epoch 73/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.00570, chestimgbbmf1 0.77454, chestimgbb_loss 0.01516, chestimgbbiou 0.92011, chestimgbbmae 0.02672, 262.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75393, chestimgbbiou 0.91736, chestimgbbmae 0.02784, 19.67 secs\n",
      "\u001b[1m---- Epoch 74/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00784, chestimgbbmf1 0.77949, chestimgbb_loss 0.01511, chestimgbbiou 0.92076, chestimgbbmae 0.02650, 263.05 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75646, chestimgbbiou 0.91722, chestimgbbmae 0.02793, 18.53 secs\n",
      "\u001b[1m---- Epoch 75/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.03447, chestimgbbmf1 0.78059, chestimgbb_loss 0.01448, chestimgbbiou 0.92119, chestimgbbmae 0.02632, 257.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75436, chestimgbbiou 0.91710, chestimgbbmae 0.02798, 19.99 secs\n",
      "\u001b[1m---- Epoch 76/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01097, chestimgbbmf1 0.78149, chestimgbb_loss 0.01472, chestimgbbiou 0.92119, chestimgbbmae 0.02635, 254.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75554, chestimgbbiou 0.91721, chestimgbbmae 0.02795, 18.49 secs\n",
      "\u001b[1m---- Epoch 77/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01338, chestimgbbmf1 0.77856, chestimgbb_loss 0.01573, chestimgbbiou 0.92056, chestimgbbmae 0.02660, 259.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75532, chestimgbbiou 0.91736, chestimgbbmae 0.02788, 22.61 secs\n",
      "\u001b[1m---- Epoch 78/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.01955, chestimgbbmf1 0.64875, chestimgbb_loss 0.01675, chestimgbbiou 0.90465, chestimgbbmae 0.03209, 267.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.67746, chestimgbbiou 0.90690, chestimgbbmae 0.03139, 23.08 secs\n",
      "\u001b[1m---- Epoch 79/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01004, chestimgbbmf1 0.73811, chestimgbb_loss 0.01611, chestimgbbiou 0.91486, chestimgbbmae 0.02853, 256.65 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72035, chestimgbbiou 0.91247, chestimgbbmae 0.02951, 19.42 secs\n",
      "\u001b[1m---- Epoch 80/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.00330, chestimgbbmf1 0.75750, chestimgbb_loss 0.01675, chestimgbbiou 0.91777, chestimgbbmae 0.02753, 254.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72539, chestimgbbiou 0.91267, chestimgbbmae 0.02954, 20.77 secs\n",
      "\u001b[1m---- Epoch 81/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.01461, chestimgbbmf1 0.76949, chestimgbb_loss 0.01610, chestimgbbiou 0.91944, chestimgbbmae 0.02696, 257.24 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75291, chestimgbbiou 0.91681, chestimgbbmae 0.02809, 21.51 secs\n",
      "\u001b[1m---- Epoch 82/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00898, chestimgbbmf1 0.77798, chestimgbb_loss 0.01508, chestimgbbiou 0.92076, chestimgbbmae 0.02650, 250.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75426, chestimgbbiou 0.91706, chestimgbbmae 0.02802, 22.53 secs\n",
      "\u001b[1m---- Epoch 83/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01956, chestimgbbmf1 0.77936, chestimgbb_loss 0.01452, chestimgbbiou 0.92096, chestimgbbmae 0.02642, 254.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75169, chestimgbbiou 0.91629, chestimgbbmae 0.02834, 20.97 secs\n",
      "\u001b[1m---- Epoch 84/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01919, chestimgbbmf1 0.78548, chestimgbb_loss 0.01417, chestimgbbiou 0.92178, chestimgbbmae 0.02614, 255.06 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76326, chestimgbbiou 0.91849, chestimgbbmae 0.02748, 19.32 secs\n",
      "\u001b[1m---- Epoch 85/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01602, chestimgbbmf1 0.78788, chestimgbb_loss 0.01401, chestimgbbiou 0.92215, chestimgbbmae 0.02602, 254.25 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.76289, chestimgbbiou 0.91810, chestimgbbmae 0.02766, 20.12 secs\n",
      "\u001b[1m---- Epoch 86/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01333, chestimgbbmf1 0.78639, chestimgbb_loss 0.01450, chestimgbbiou 0.92212, chestimgbbmae 0.02601, 247.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76200, chestimgbbiou 0.91790, chestimgbbmae 0.02776, 20.65 secs\n",
      "\u001b[1m---- Epoch 87/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00932, chestimgbbmf1 0.78855, chestimgbb_loss 0.01450, chestimgbbiou 0.92224, chestimgbbmae 0.02599, 253.01 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76222, chestimgbbiou 0.91824, chestimgbbmae 0.02761, 19.09 secs\n",
      "\u001b[1m---- Epoch 88/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.00748, chestimgbbmf1 0.66791, chestimgbb_loss 0.01757, chestimgbbiou 0.90637, chestimgbbmae 0.03153, 250.32 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66478, chestimgbbiou 0.90532, chestimgbbmae 0.03207, 19.39 secs\n",
      "\u001b[1m---- Epoch 89/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01500, chestimgbbmf1 0.74084, chestimgbb_loss 0.01587, chestimgbbiou 0.91541, chestimgbbmae 0.02832, 249.97 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72785, chestimgbbiou 0.91390, chestimgbbmae 0.02896, 19.72 secs\n",
      "\u001b[1m---- Epoch 90/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01398, chestimgbbmf1 0.76262, chestimgbb_loss 0.01614, chestimgbbiou 0.91830, chestimgbbmae 0.02737, 247.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74549, chestimgbbiou 0.91599, chestimgbbmae 0.02832, 18.08 secs\n",
      "\u001b[1m---- Epoch 91/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.02181, chestimgbbmf1 0.77635, chestimgbb_loss 0.01588, chestimgbbiou 0.92023, chestimgbbmae 0.02669, 252.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75415, chestimgbbiou 0.91691, chestimgbbmae 0.02804, 22.66 secs\n",
      "\u001b[1m---- Epoch 92/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00891, chestimgbbmf1 0.78165, chestimgbb_loss 0.01480, chestimgbbiou 0.92120, chestimgbbmae 0.02635, 261.02 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76010, chestimgbbiou 0.91780, chestimgbbmae 0.02776, 19.55 secs\n",
      "\u001b[1m---- Epoch 93/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.00718, chestimgbbmf1 0.79038, chestimgbb_loss 0.01332, chestimgbbiou 0.92243, chestimgbbmae 0.02592, 252.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76706, chestimgbbiou 0.91874, chestimgbbmae 0.02742, 18.97 secs\n",
      "\u001b[1m---- Epoch 94/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.02291, chestimgbbmf1 0.79039, chestimgbb_loss 0.01428, chestimgbbiou 0.92257, chestimgbbmae 0.02587, 250.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76507, chestimgbbiou 0.91848, chestimgbbmae 0.02751, 20.21 secs\n",
      "\u001b[1m---- Epoch 95/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.03003, chestimgbbmf1 0.78793, chestimgbb_loss 0.01545, chestimgbbiou 0.92198, chestimgbbmae 0.02612, 252.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76542, chestimgbbiou 0.91838, chestimgbbmae 0.02758, 19.90 secs\n",
      "\u001b[1m---- Epoch 96/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01933, chestimgbbmf1 0.79223, chestimgbb_loss 0.01395, chestimgbbiou 0.92293, chestimgbbmae 0.02575, 248.33 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76676, chestimgbbiou 0.91879, chestimgbbmae 0.02744, 19.71 secs\n",
      "\u001b[1m---- Epoch 97/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00495, chestimgbbmf1 0.79454, chestimgbb_loss 0.01325, chestimgbbiou 0.92337, chestimgbbmae 0.02559, 250.50 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77076, chestimgbbiou 0.91935, chestimgbbmae 0.02722, 18.30 secs\n",
      "\u001b[1m---- Epoch 98/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.00780, chestimgbbmf1 0.67342, chestimgbb_loss 0.01608, chestimgbbiou 0.90728, chestimgbbmae 0.03119, 250.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.67072, chestimgbbiou 0.90550, chestimgbbmae 0.03215, 18.10 secs\n",
      "\u001b[1m---- Epoch 99/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.04132, chestimgbbmf1 0.74484, chestimgbb_loss 0.01539, chestimgbbiou 0.91591, chestimgbbmae 0.02817, 250.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73531, chestimgbbiou 0.91396, chestimgbbmae 0.02906, 19.59 secs\n",
      "\u001b[1m---- Epoch 100/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01954, chestimgbbmf1 0.77015, chestimgbb_loss 0.01564, chestimgbbiou 0.91941, chestimgbbmae 0.02696, 250.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75579, chestimgbbiou 0.91720, chestimgbbmae 0.02792, 18.56 secs\n",
      "\u001b[1m---- Epoch 101/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.00505, chestimgbbmf1 0.78467, chestimgbb_loss 0.01456, chestimgbbiou 0.92165, chestimgbbmae 0.02618, 255.05 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76400, chestimgbbiou 0.91832, chestimgbbmae 0.02757, 19.33 secs\n",
      "\u001b[1m---- Epoch 102/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00620, chestimgbbmf1 0.78752, chestimgbb_loss 0.01434, chestimgbbiou 0.92233, chestimgbbmae 0.02592, 261.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76295, chestimgbbiou 0.91827, chestimgbbmae 0.02759, 20.25 secs\n",
      "\u001b[1m---- Epoch 103/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01634, chestimgbbmf1 0.79172, chestimgbb_loss 0.01384, chestimgbbiou 0.92272, chestimgbbmae 0.02584, 259.51 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76762, chestimgbbiou 0.91890, chestimgbbmae 0.02736, 21.13 secs\n",
      "\u001b[1m---- Epoch 104/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.03900, chestimgbbmf1 0.79329, chestimgbb_loss 0.01328, chestimgbbiou 0.92321, chestimgbbmae 0.02563, 259.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77191, chestimgbbiou 0.91976, chestimgbbmae 0.02705, 25.17 secs\n",
      "\u001b[1m---- Epoch 105/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.03480, chestimgbbmf1 0.79579, chestimgbb_loss 0.01281, chestimgbbiou 0.92363, chestimgbbmae 0.02549, 250.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77348, chestimgbbiou 0.91948, chestimgbbmae 0.02719, 23.96 secs\n",
      "\u001b[1m---- Epoch 106/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01262, chestimgbbmf1 0.79512, chestimgbb_loss 0.01334, chestimgbbiou 0.92329, chestimgbbmae 0.02564, 253.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77001, chestimgbbiou 0.91904, chestimgbbmae 0.02737, 18.83 secs\n",
      "\u001b[1m---- Epoch 107/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00358, chestimgbbmf1 0.79659, chestimgbb_loss 0.01295, chestimgbbiou 0.92362, chestimgbbmae 0.02549, 245.00 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77009, chestimgbbiou 0.91902, chestimgbbmae 0.02739, 18.90 secs\n",
      "\u001b[1m---- Epoch 108/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.03540, chestimgbbmf1 0.68470, chestimgbb_loss 0.01631, chestimgbbiou 0.90818, chestimgbbmae 0.03087, 245.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.69845, chestimgbbiou 0.90857, chestimgbbmae 0.03088, 18.26 secs\n",
      "\u001b[1m---- Epoch 109/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.02234, chestimgbbmf1 0.75921, chestimgbb_loss 0.01559, chestimgbbiou 0.91764, chestimgbbmae 0.02758, 260.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73727, chestimgbbiou 0.91341, chestimgbbmae 0.02935, 20.72 secs\n",
      "\u001b[1m---- Epoch 110/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.00814, chestimgbbmf1 0.77744, chestimgbb_loss 0.01439, chestimgbbiou 0.92060, chestimgbbmae 0.02654, 263.89 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74914, chestimgbbiou 0.91552, chestimgbbmae 0.02865, 19.81 secs\n",
      "\u001b[1m---- Epoch 111/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.01057, chestimgbbmf1 0.78758, chestimgbb_loss 0.01439, chestimgbbiou 0.92230, chestimgbbmae 0.02594, 257.54 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76506, chestimgbbiou 0.91815, chestimgbbmae 0.02760, 18.75 secs\n",
      "\u001b[1m---- Epoch 112/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00469, chestimgbbmf1 0.79436, chestimgbb_loss 0.01416, chestimgbbiou 0.92332, chestimgbbmae 0.02560, 255.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77533, chestimgbbiou 0.92022, chestimgbbmae 0.02690, 19.55 secs\n",
      "\u001b[1m---- Epoch 113/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.02870, chestimgbbmf1 0.79730, chestimgbb_loss 0.01375, chestimgbbiou 0.92358, chestimgbbmae 0.02554, 245.79 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77272, chestimgbbiou 0.91954, chestimgbbmae 0.02719, 17.21 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 114/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01136, chestimgbbmf1 0.79736, chestimgbb_loss 0.01276, chestimgbbiou 0.92379, chestimgbbmae 0.02545, 212.45 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77318, chestimgbbiou 0.91945, chestimgbbmae 0.02722, 16.45 secs\n",
      "\u001b[1m---- Epoch 115/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00251, chestimgbbmf1 0.79855, chestimgbb_loss 0.01293, chestimgbbiou 0.92406, chestimgbbmae 0.02534, 205.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77497, chestimgbbiou 0.91967, chestimgbbmae 0.02719, 15.68 secs\n",
      "\u001b[1m---- Epoch 116/116\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00575, chestimgbbmf1 0.80020, chestimgbb_loss 0.01335, chestimgbbiou 0.92417, chestimgbbmae 0.02533, 197.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77780, chestimgbbiou 0.92043, chestimgbbmae 0.02687, 15.86 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --checkpoint-folder \"models/visual_module/20230227_130158_mim_dn121\" \\\n",
    "        --epochs 66 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 75 \\\n",
    "        --num-workers 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,6,6e-5,10,1e-6\" \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --override-lr \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 66\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 64\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,6,6e-5,10,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 75\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [256, 256]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "source_image_size_mode: small_256x256\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+cyclicdecay scheduler: 1e-6,6,6e-5,10,1e-6\n",
      "1e-06 6 6e-05 10 1e-06\n",
      "self.steps_to_restart = 10\n",
      "self.steps = -1\n",
      "self.initial_lr = 6e-05\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "227835it [00:00, 414191.45it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230302_080016_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230302_080016_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_41_chestimgbbmf1=0.7131.pt', 'checkpoint_50_chestimgbbmf1=0.7146.pt', 'checkpoint_116_chestimgbbmf1=0.7800.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/checkpoint_116_chestimgbbmf1=0.7800.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230302_080016_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.03037, chestimgbbmf1 0.74318, chestimgbb_loss 0.02785, chestimgbbiou 0.91605, chestimgbbmae 0.02844, 195.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76858, chestimgbbiou 0.91924, chestimgbbmae 0.02726, 15.20 secs\n",
      "\u001b[1m---- Epoch 2/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01174, chestimgbbmf1 0.74464, chestimgbb_loss 0.02523, chestimgbbiou 0.91623, chestimgbbmae 0.02831, 196.79 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76393, chestimgbbiou 0.91879, chestimgbbmae 0.02740, 15.30 secs\n",
      "\u001b[1m---- Epoch 3/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.03878, chestimgbbmf1 0.74845, chestimgbb_loss 0.02273, chestimgbbiou 0.91662, chestimgbbmae 0.02814, 197.40 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76452, chestimgbbiou 0.91894, chestimgbbmae 0.02729, 15.91 secs\n",
      "\u001b[1m---- Epoch 4/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.03122, chestimgbbmf1 0.74659, chestimgbb_loss 0.02339, chestimgbbiou 0.91635, chestimgbbmae 0.02821, 198.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76032, chestimgbbiou 0.91805, chestimgbbmae 0.02761, 15.79 secs\n",
      "\u001b[1m---- Epoch 5/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.02235, chestimgbbmf1 0.74158, chestimgbb_loss 0.02266, chestimgbbiou 0.91538, chestimgbbmae 0.02854, 197.12 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74809, chestimgbbiou 0.91599, chestimgbbmae 0.02837, 15.87 secs\n",
      "\u001b[1m---- Epoch 6/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.01756, chestimgbbmf1 0.71897, chestimgbb_loss 0.02284, chestimgbbiou 0.91215, chestimgbbmae 0.02969, 200.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72770, chestimgbbiou 0.91283, chestimgbbmae 0.02944, 15.88 secs\n",
      "\u001b[1m---- Epoch 7/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.01201, chestimgbbmf1 0.66154, chestimgbb_loss 0.02448, chestimgbbiou 0.90526, chestimgbbmae 0.03207, 200.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68731, chestimgbbiou 0.90794, chestimgbbmae 0.03117, 16.00 secs\n",
      "\u001b[1m---- Epoch 8/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.02976, chestimgbbmf1 0.69891, chestimgbb_loss 0.02312, chestimgbbiou 0.90974, chestimgbbmae 0.03047, 199.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68678, chestimgbbiou 0.90873, chestimgbbmae 0.03081, 15.90 secs\n",
      "\u001b[1m---- Epoch 9/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01904, chestimgbbmf1 0.73151, chestimgbb_loss 0.02317, chestimgbbiou 0.91367, chestimgbbmae 0.02915, 200.50 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.73777, chestimgbbiou 0.91392, chestimgbbmae 0.02909, 15.93 secs\n",
      "\u001b[1m---- Epoch 10/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01895, chestimgbbmf1 0.74991, chestimgbb_loss 0.02318, chestimgbbiou 0.91635, chestimgbbmae 0.02821, 199.75 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74237, chestimgbbiou 0.91548, chestimgbbmae 0.02854, 16.06 secs\n",
      "\u001b[1m---- Epoch 11/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.01970, chestimgbbmf1 0.75895, chestimgbb_loss 0.02146, chestimgbbiou 0.91777, chestimgbbmae 0.02769, 201.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76292, chestimgbbiou 0.91843, chestimgbbmae 0.02747, 16.11 secs\n",
      "\u001b[1m---- Epoch 12/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.01556, chestimgbbmf1 0.76213, chestimgbb_loss 0.02115, chestimgbbiou 0.91808, chestimgbbmae 0.02763, 199.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77088, chestimgbbiou 0.91932, chestimgbbmae 0.02721, 16.03 secs\n",
      "\u001b[1m---- Epoch 13/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01472, chestimgbbmf1 0.77139, chestimgbb_loss 0.02072, chestimgbbiou 0.91940, chestimgbbmae 0.02715, 198.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77330, chestimgbbiou 0.92010, chestimgbbmae 0.02690, 15.46 secs\n",
      "\u001b[1m---- Epoch 14/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01471, chestimgbbmf1 0.77250, chestimgbb_loss 0.02024, chestimgbbiou 0.91963, chestimgbbmae 0.02707, 197.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77104, chestimgbbiou 0.91976, chestimgbbmae 0.02706, 15.99 secs\n",
      "\u001b[1m---- Epoch 15/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01002, chestimgbbmf1 0.77281, chestimgbb_loss 0.02072, chestimgbbiou 0.91981, chestimgbbmae 0.02700, 200.19 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77325, chestimgbbiou 0.92005, chestimgbbmae 0.02696, 16.00 secs\n",
      "\u001b[1m---- Epoch 16/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02094, chestimgbbmf1 0.77664, chestimgbb_loss 0.02038, chestimgbbiou 0.92039, chestimgbbmae 0.02681, 200.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77462, chestimgbbiou 0.92046, chestimgbbmae 0.02680, 16.03 secs\n",
      "\u001b[1m---- Epoch 17/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.04020, chestimgbbmf1 0.77330, chestimgbb_loss 0.02121, chestimgbbiou 0.91977, chestimgbbmae 0.02704, 197.44 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77386, chestimgbbiou 0.92007, chestimgbbmae 0.02696, 15.60 secs\n",
      "\u001b[1m---- Epoch 18/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.02141, chestimgbbmf1 0.67538, chestimgbb_loss 0.02244, chestimgbbiou 0.90674, chestimgbbmae 0.03154, 198.39 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.68524, chestimgbbiou 0.90779, chestimgbbmae 0.03107, 15.69 secs\n",
      "\u001b[1m---- Epoch 19/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01801, chestimgbbmf1 0.72435, chestimgbb_loss 0.02273, chestimgbbiou 0.91261, chestimgbbmae 0.02954, 198.12 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72929, chestimgbbiou 0.91346, chestimgbbmae 0.02922, 15.47 secs\n",
      "\u001b[1m---- Epoch 20/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01813, chestimgbbmf1 0.75526, chestimgbb_loss 0.02180, chestimgbbiou 0.91704, chestimgbbmae 0.02797, 206.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76229, chestimgbbiou 0.91852, chestimgbbmae 0.02743, 22.17 secs\n",
      "\u001b[1m---- Epoch 21/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.02538, chestimgbbmf1 0.76389, chestimgbb_loss 0.02138, chestimgbbiou 0.91855, chestimgbbmae 0.02743, 325.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75720, chestimgbbiou 0.91727, chestimgbbmae 0.02792, 30.82 secs\n",
      "\u001b[1m---- Epoch 22/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.04330, chestimgbbmf1 0.77016, chestimgbb_loss 0.02114, chestimgbbiou 0.91942, chestimgbbmae 0.02714, 641.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76557, chestimgbbiou 0.91893, chestimgbbmae 0.02727, 51.96 secs\n",
      "\u001b[1m---- Epoch 23/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.03170, chestimgbbmf1 0.76952, chestimgbb_loss 0.02110, chestimgbbiou 0.91916, chestimgbbmae 0.02725, 672.47 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77090, chestimgbbiou 0.91952, chestimgbbmae 0.02714, 53.44 secs\n",
      "\u001b[1m---- Epoch 24/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01504, chestimgbbmf1 0.77626, chestimgbb_loss 0.01918, chestimgbbiou 0.92042, chestimgbbmae 0.02676, 692.61 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77349, chestimgbbiou 0.91977, chestimgbbmae 0.02707, 57.53 secs\n",
      "\u001b[1m---- Epoch 25/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02231, chestimgbbmf1 0.77675, chestimgbb_loss 0.02000, chestimgbbiou 0.92038, chestimgbbmae 0.02681, 699.68 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77475, chestimgbbiou 0.91993, chestimgbbmae 0.02702, 53.02 secs\n",
      "\u001b[1m---- Epoch 26/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01195, chestimgbbmf1 0.77908, chestimgbb_loss 0.02113, chestimgbbiou 0.92055, chestimgbbmae 0.02676, 674.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77715, chestimgbbiou 0.92049, chestimgbbmae 0.02679, 55.67 secs\n",
      "\u001b[1m---- Epoch 27/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.02250, chestimgbbmf1 0.77925, chestimgbb_loss 0.01955, chestimgbbiou 0.92081, chestimgbbmae 0.02665, 697.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77762, chestimgbbiou 0.92049, chestimgbbmae 0.02682, 49.88 secs\n",
      "\u001b[1m---- Epoch 28/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.02252, chestimgbbmf1 0.67075, chestimgbb_loss 0.02287, chestimgbbiou 0.90631, chestimgbbmae 0.03168, 665.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66178, chestimgbbiou 0.90575, chestimgbbmae 0.03170, 53.70 secs\n",
      "\u001b[1m---- Epoch 29/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.03172, chestimgbbmf1 0.73039, chestimgbb_loss 0.02123, chestimgbbiou 0.91362, chestimgbbmae 0.02914, 695.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74630, chestimgbbiou 0.91609, chestimgbbmae 0.02821, 54.50 secs\n",
      "\u001b[1m---- Epoch 30/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.02081, chestimgbbmf1 0.75658, chestimgbb_loss 0.02109, chestimgbbiou 0.91743, chestimgbbmae 0.02781, 678.96 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76201, chestimgbbiou 0.91784, chestimgbbmae 0.02765, 56.09 secs\n",
      "\u001b[1m---- Epoch 31/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.01238, chestimgbbmf1 0.77030, chestimgbb_loss 0.02014, chestimgbbiou 0.91933, chestimgbbmae 0.02715, 714.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77011, chestimgbbiou 0.91933, chestimgbbmae 0.02720, 59.98 secs\n",
      "\u001b[1m---- Epoch 32/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.01199, chestimgbbmf1 0.77442, chestimgbb_loss 0.02102, chestimgbbiou 0.91985, chestimgbbmae 0.02701, 732.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77253, chestimgbbiou 0.91963, chestimgbbmae 0.02709, 58.54 secs\n",
      "\u001b[1m---- Epoch 33/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.02354, chestimgbbmf1 0.77679, chestimgbb_loss 0.02019, chestimgbbiou 0.92040, chestimgbbmae 0.02682, 729.04 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77773, chestimgbbiou 0.92085, chestimgbbmae 0.02664, 61.92 secs\n",
      "\u001b[1m---- Epoch 34/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01093, chestimgbbmf1 0.78092, chestimgbb_loss 0.01980, chestimgbbiou 0.92104, chestimgbbmae 0.02656, 620.89 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77824, chestimgbbiou 0.92085, chestimgbbmae 0.02666, 52.83 secs\n",
      "\u001b[1m---- Epoch 35/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01913, chestimgbbmf1 0.78215, chestimgbb_loss 0.02005, chestimgbbiou 0.92112, chestimgbbmae 0.02655, 613.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77884, chestimgbbiou 0.92075, chestimgbbmae 0.02673, 55.16 secs\n",
      "\u001b[1m---- Epoch 36/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01153, chestimgbbmf1 0.78284, chestimgbb_loss 0.01865, chestimgbbiou 0.92151, chestimgbbmae 0.02640, 625.33 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77885, chestimgbbiou 0.92081, chestimgbbmae 0.02670, 51.54 secs\n",
      "\u001b[1m---- Epoch 37/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.06267, chestimgbbmf1 0.78587, chestimgbb_loss 0.01952, chestimgbbiou 0.92166, chestimgbbmae 0.02637, 648.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.78148, chestimgbbiou 0.92129, chestimgbbmae 0.02652, 47.77 secs\n",
      "\u001b[1m---- Epoch 38/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.02691, chestimgbbmf1 0.68811, chestimgbb_loss 0.02272, chestimgbbiou 0.90817, chestimgbbmae 0.03105, 654.36 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.66917, chestimgbbiou 0.90564, chestimgbbmae 0.03199, 27.21 secs\n",
      "\u001b[1m---- Epoch 39/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.02786, chestimgbbmf1 0.73697, chestimgbb_loss 0.02172, chestimgbbiou 0.91449, chestimgbbmae 0.02884, 246.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75186, chestimgbbiou 0.91650, chestimgbbmae 0.02809, 17.22 secs\n",
      "\u001b[1m---- Epoch 40/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 0.01631, chestimgbbmf1 0.76067, chestimgbb_loss 0.02080, chestimgbbiou 0.91770, chestimgbbmae 0.02776, 206.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.76608, chestimgbbiou 0.91877, chestimgbbmae 0.02732, 16.12 secs\n",
      "\u001b[1m---- Epoch 41/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 0.02879, chestimgbbmf1 0.77195, chestimgbb_loss 0.02055, chestimgbbiou 0.91960, chestimgbbmae 0.02707, 201.81 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77475, chestimgbbiou 0.92052, chestimgbbmae 0.02673, 16.46 secs\n",
      "\u001b[1m---- Epoch 42/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00641, chestimgbbmf1 0.77709, chestimgbb_loss 0.01949, chestimgbbiou 0.92044, chestimgbbmae 0.02677, 271.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77206, chestimgbbiou 0.91915, chestimgbbmae 0.02731, 23.77 secs\n",
      "\u001b[1m---- Epoch 43/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.01197, chestimgbbmf1 0.78159, chestimgbb_loss 0.02005, chestimgbbiou 0.92098, chestimgbbmae 0.02661, 356.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.78160, chestimgbbiou 0.92126, chestimgbbmae 0.02650, 34.82 secs\n",
      "\u001b[1m---- Epoch 44/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.01078, chestimgbbmf1 0.78329, chestimgbb_loss 0.01966, chestimgbbiou 0.92134, chestimgbbmae 0.02649, 314.37 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77672, chestimgbbiou 0.92003, chestimgbbmae 0.02702, 22.91 secs\n",
      "\u001b[1m---- Epoch 45/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02942, chestimgbbmf1 0.78594, chestimgbb_loss 0.01946, chestimgbbiou 0.92181, chestimgbbmae 0.02631, 344.89 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.78118, chestimgbbiou 0.92091, chestimgbbmae 0.02668, 29.91 secs\n",
      "\u001b[1m---- Epoch 46/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.01577, chestimgbbmf1 0.78760, chestimgbb_loss 0.01901, chestimgbbiou 0.92198, chestimgbbmae 0.02625, 265.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.78306, chestimgbbiou 0.92151, chestimgbbmae 0.02646, 21.50 secs\n",
      "\u001b[1m---- Epoch 47/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.00923, chestimgbbmf1 0.78736, chestimgbb_loss 0.01903, chestimgbbiou 0.92205, chestimgbbmae 0.02621, 312.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.78390, chestimgbbiou 0.92162, chestimgbbmae 0.02642, 35.92 secs\n",
      "\u001b[1m---- Epoch 48/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.01825, chestimgbbmf1 0.69160, chestimgbb_loss 0.02136, chestimgbbiou 0.90889, chestimgbbmae 0.03076, 414.38 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.71048, chestimgbbiou 0.91102, chestimgbbmae 0.03006, 31.52 secs\n",
      "\u001b[1m---- Epoch 49/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.04505, chestimgbbmf1 0.74189, chestimgbb_loss 0.02114, chestimgbbiou 0.91506, chestimgbbmae 0.02865, 388.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.74881, chestimgbbiou 0.91600, chestimgbbmae 0.02831, 32.07 secs\n",
      "\u001b[1m---- Epoch 50/66\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "^C iteration 15000\n",
      "Process ForkPoolWorker-655:\n",
      "Process ForkPoolWorker-654:\n",
      "Process ForkPoolWorker-657:\n",
      "Process ForkPoolWorker-656:\n",
      "Process ForkPoolWorker-653:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230227_130158_mim_dn121/\" \\\n",
    "        --epochs 66 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 75 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,6,6e-5,10,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --use-chest-imagenome-decent-images-only \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 55\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 64\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,5,4e-5,10,2e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 70\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: random-spatial\n",
      "   image_size: [256, 256]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   use_anaxnet_bbox_subset: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "avg_coords.shape= (72,)\n",
      "source_image_size_mode: small_256x256\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "  self.local_feat_size = 1024\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 18\n",
      "  num_regions: 64\n",
      "MultiPurposeVisualModule: self.name=dn121\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+cyclicdecay scheduler: 1e-6,5,4e-5,10,2e-6\n",
      "1e-06 5 4e-05 10 2e-06\n",
      "self.steps_to_restart = 10\n",
      "self.steps = -1\n",
      "self.initial_lr = 4e-05\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    len(_augmented_bbox_transforms) = 5\n",
      "    augmentation_mode = random-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: small_256x256\n",
      "Loaded 242280 decent image IDs\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "227835it [00:00, 308011.76it/s]\n",
      "Skipped 1017 non-decent images\n",
      "len(self.train_indices) = 234217\n",
      "len(self.val_indices) = 1934\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "  Using 18 of 36 bboxes (from AnaXNET paper)\n",
      "Loading Chest Imagenome bounding boxes (flipped)...\n",
      "  Using 18 of 36 bboxes (from AnaXNET paper)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230302_142857_mim_dn121\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230302_142857_mim_dn121/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_39_chestimgbbmf1=0.9169.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/checkpoint_39_chestimgbbmf1=0.9169.pt\n",
      "Skip loading parameter: bbox_regressor_chst_imgn.train_average_bbox_coords, required shape: torch.Size([72]), loaded shape: torch.Size([144])\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230302_142857_mim_dn121/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.03447, chestimgbbmf1 0.60527, chestimgbb_loss 0.06237, chestimgbbiou 0.89923, chestimgbbmae 0.03612, 158.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.65287, chestimgbbiou 0.90782, chestimgbbmae 0.03241, 13.45 secs\n",
      "\u001b[1m---- Epoch 2/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11847, chestimgbbmf1 0.67949, chestimgbb_loss 0.05374, chestimgbbiou 0.91054, chestimgbbmae 0.03159, 159.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.72868, chestimgbbiou 0.91760, chestimgbbmae 0.02863, 13.69 secs\n",
      "\u001b[1m---- Epoch 3/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00922, chestimgbbmf1 0.74088, chestimgbb_loss 0.03914, chestimgbbiou 0.91828, chestimgbbmae 0.02853, 165.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.75934, chestimgbbiou 0.92090, chestimgbbmae 0.02737, 16.70 secs\n",
      "\u001b[1m---- Epoch 4/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.05141, chestimgbbmf1 0.76321, chestimgbb_loss 0.02747, chestimgbbiou 0.92054, chestimgbbmae 0.02760, 176.24 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.77261, chestimgbbiou 0.92182, chestimgbbmae 0.02704, 14.69 secs\n",
      "\u001b[1m---- Epoch 5/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.03740, chestimgbbmf1 0.78575, chestimgbb_loss 0.02375, chestimgbbiou 0.92313, chestimgbbmae 0.02660, 181.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.77945, chestimgbbiou 0.92261, chestimgbbmae 0.02679, 15.11 secs\n",
      "\u001b[1m---- Epoch 6/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.04113, chestimgbbmf1 0.79194, chestimgbb_loss 0.02165, chestimgbbiou 0.92327, chestimgbbmae 0.02648, 177.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.79045, chestimgbbiou 0.92368, chestimgbbmae 0.02624, 15.13 secs\n",
      "\u001b[1m---- Epoch 7/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01095, chestimgbbmf1 0.80324, chestimgbb_loss 0.02234, chestimgbbiou 0.92496, chestimgbbmae 0.02592, 175.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.80213, chestimgbbiou 0.92560, chestimgbbmae 0.02566, 16.20 secs\n",
      "\u001b[1m---- Epoch 8/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.00927, chestimgbbmf1 0.81678, chestimgbb_loss 0.02136, chestimgbbiou 0.92755, chestimgbbmae 0.02495, 179.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.80957, chestimgbbiou 0.92620, chestimgbbmae 0.02561, 17.18 secs\n",
      "\u001b[1m---- Epoch 9/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.01185, chestimgbbmf1 0.82623, chestimgbb_loss 0.01939, chestimgbbiou 0.92961, chestimgbbmae 0.02425, 182.91 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81869, chestimgbbiou 0.92843, chestimgbbmae 0.02476, 15.75 secs\n",
      "\u001b[1m---- Epoch 10/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.02263, chestimgbbmf1 0.83455, chestimgbb_loss 0.01859, chestimgbbiou 0.93108, chestimgbbmae 0.02371, 178.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81628, chestimgbbiou 0.92849, chestimgbbmae 0.02474, 16.21 secs\n",
      "\u001b[1m---- Epoch 11/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.02610, chestimgbbmf1 0.83413, chestimgbb_loss 0.01825, chestimgbbiou 0.93121, chestimgbbmae 0.02367, 179.69 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82467, chestimgbbiou 0.93018, chestimgbbmae 0.02410, 15.19 secs\n",
      "\u001b[1m---- Epoch 12/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.00959, chestimgbbmf1 0.83869, chestimgbb_loss 0.01730, chestimgbbiou 0.93230, chestimgbbmae 0.02328, 181.71 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83094, chestimgbbiou 0.93168, chestimgbbmae 0.02355, 16.48 secs\n",
      "\u001b[1m---- Epoch 13/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.01702, chestimgbbmf1 0.84250, chestimgbb_loss 0.01793, chestimgbbiou 0.93312, chestimgbbmae 0.02300, 182.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82827, chestimgbbiou 0.93084, chestimgbbmae 0.02396, 14.49 secs\n",
      "\u001b[1m---- Epoch 14/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.02528, chestimgbbmf1 0.84396, chestimgbb_loss 0.01730, chestimgbbiou 0.93326, chestimgbbmae 0.02294, 183.53 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83126, chestimgbbiou 0.93194, chestimgbbmae 0.02347, 16.30 secs\n",
      "\u001b[1m---- Epoch 15/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00355, chestimgbbmf1 0.84535, chestimgbb_loss 0.01841, chestimgbbiou 0.93372, chestimgbbmae 0.02279, 185.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83119, chestimgbbiou 0.93161, chestimgbbmae 0.02364, 16.14 secs\n",
      "\u001b[1m---- Epoch 16/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.02567, chestimgbbmf1 0.84643, chestimgbb_loss 0.01763, chestimgbbiou 0.93379, chestimgbbmae 0.02275, 185.55 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83387, chestimgbbiou 0.93220, chestimgbbmae 0.02338, 17.14 secs\n",
      "\u001b[1m---- Epoch 17/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01652, chestimgbbmf1 0.82640, chestimgbb_loss 0.01871, chestimgbbiou 0.92896, chestimgbbmae 0.02441, 182.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81381, chestimgbbiou 0.92624, chestimgbbmae 0.02559, 16.65 secs\n",
      "\u001b[1m---- Epoch 18/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.01906, chestimgbbmf1 0.82826, chestimgbb_loss 0.02010, chestimgbbiou 0.92948, chestimgbbmae 0.02429, 183.38 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82354, chestimgbbiou 0.92924, chestimgbbmae 0.02433, 14.44 secs\n",
      "\u001b[1m---- Epoch 19/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.02239, chestimgbbmf1 0.83874, chestimgbb_loss 0.01860, chestimgbbiou 0.93186, chestimgbbmae 0.02343, 181.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82631, chestimgbbiou 0.93006, chestimgbbmae 0.02414, 17.39 secs\n",
      "\u001b[1m---- Epoch 20/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01040, chestimgbbmf1 0.84047, chestimgbb_loss 0.01835, chestimgbbiou 0.93270, chestimgbbmae 0.02311, 180.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82375, chestimgbbiou 0.93022, chestimgbbmae 0.02412, 17.24 secs\n",
      "\u001b[1m---- Epoch 21/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.02903, chestimgbbmf1 0.84368, chestimgbb_loss 0.01794, chestimgbbiou 0.93321, chestimgbbmae 0.02295, 186.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83368, chestimgbbiou 0.93242, chestimgbbmae 0.02332, 15.08 secs\n",
      "\u001b[1m---- Epoch 22/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.00914, chestimgbbmf1 0.84670, chestimgbb_loss 0.01689, chestimgbbiou 0.93401, chestimgbbmae 0.02265, 186.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83308, chestimgbbiou 0.93259, chestimgbbmae 0.02325, 17.66 secs\n",
      "\u001b[1m---- Epoch 23/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.01947, chestimgbbmf1 0.85047, chestimgbb_loss 0.01661, chestimgbbiou 0.93477, chestimgbbmae 0.02239, 193.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83766, chestimgbbiou 0.93310, chestimgbbmae 0.02309, 15.29 secs\n",
      "\u001b[1m---- Epoch 24/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00868, chestimgbbmf1 0.85150, chestimgbb_loss 0.01745, chestimgbbiou 0.93517, chestimgbbmae 0.02226, 189.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83519, chestimgbbiou 0.93291, chestimgbbmae 0.02319, 14.41 secs\n",
      "\u001b[1m---- Epoch 25/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.01713, chestimgbbmf1 0.84956, chestimgbb_loss 0.01744, chestimgbbiou 0.93488, chestimgbbmae 0.02237, 187.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83613, chestimgbbiou 0.93301, chestimgbbmae 0.02318, 15.35 secs\n",
      "\u001b[1m---- Epoch 26/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00385, chestimgbbmf1 0.85362, chestimgbb_loss 0.01715, chestimgbbiou 0.93544, chestimgbbmae 0.02217, 185.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84075, chestimgbbiou 0.93400, chestimgbbmae 0.02275, 16.39 secs\n",
      "\u001b[1m---- Epoch 27/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.00374, chestimgbbmf1 0.83144, chestimgbb_loss 0.01755, chestimgbbiou 0.92977, chestimgbbmae 0.02412, 191.27 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81106, chestimgbbiou 0.92618, chestimgbbmae 0.02559, 14.64 secs\n",
      "\u001b[1m---- Epoch 28/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.02403, chestimgbbmf1 0.83498, chestimgbb_loss 0.01856, chestimgbbiou 0.93101, chestimgbbmae 0.02372, 187.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82624, chestimgbbiou 0.92984, chestimgbbmae 0.02417, 14.37 secs\n",
      "\u001b[1m---- Epoch 29/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.01653, chestimgbbmf1 0.84022, chestimgbb_loss 0.01810, chestimgbbiou 0.93224, chestimgbbmae 0.02329, 186.83 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82590, chestimgbbiou 0.93039, chestimgbbmae 0.02387, 17.13 secs\n",
      "\u001b[1m---- Epoch 30/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01910, chestimgbbmf1 0.84330, chestimgbb_loss 0.01776, chestimgbbiou 0.93302, chestimgbbmae 0.02304, 191.24 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83535, chestimgbbiou 0.93256, chestimgbbmae 0.02320, 15.10 secs\n",
      "\u001b[1m---- Epoch 31/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.02907, chestimgbbmf1 0.84884, chestimgbb_loss 0.01639, chestimgbbiou 0.93436, chestimgbbmae 0.02253, 188.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83594, chestimgbbiou 0.93295, chestimgbbmae 0.02306, 15.22 secs\n",
      "\u001b[1m---- Epoch 32/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.01993, chestimgbbmf1 0.84920, chestimgbb_loss 0.01754, chestimgbbiou 0.93449, chestimgbbmae 0.02252, 184.72 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83621, chestimgbbiou 0.93344, chestimgbbmae 0.02292, 14.97 secs\n",
      "\u001b[1m---- Epoch 33/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.01870, chestimgbbmf1 0.85042, chestimgbb_loss 0.01757, chestimgbbiou 0.93488, chestimgbbmae 0.02238, 188.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83690, chestimgbbiou 0.93307, chestimgbbmae 0.02310, 16.46 secs\n",
      "\u001b[1m---- Epoch 34/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00838, chestimgbbmf1 0.85333, chestimgbb_loss 0.01622, chestimgbbiou 0.93555, chestimgbbmae 0.02212, 191.42 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83819, chestimgbbiou 0.93352, chestimgbbmae 0.02294, 17.05 secs\n",
      "\u001b[1m---- Epoch 35/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.02106, chestimgbbmf1 0.85705, chestimgbb_loss 0.01565, chestimgbbiou 0.93612, chestimgbbmae 0.02194, 189.41 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84061, chestimgbbiou 0.93406, chestimgbbmae 0.02274, 16.63 secs\n",
      "\u001b[1m---- Epoch 36/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01249, chestimgbbmf1 0.85795, chestimgbb_loss 0.01662, chestimgbbiou 0.93662, chestimgbbmae 0.02173, 181.40 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84014, chestimgbbiou 0.93394, chestimgbbmae 0.02280, 17.11 secs\n",
      "\u001b[1m---- Epoch 37/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.03276, chestimgbbmf1 0.83512, chestimgbb_loss 0.01827, chestimgbbiou 0.93098, chestimgbbmae 0.02369, 187.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.80934, chestimgbbiou 0.92575, chestimgbbmae 0.02577, 17.71 secs\n",
      "\u001b[1m---- Epoch 38/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.01201, chestimgbbmf1 0.83511, chestimgbb_loss 0.01826, chestimgbbiou 0.93094, chestimgbbmae 0.02373, 189.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82357, chestimgbbiou 0.93001, chestimgbbmae 0.02404, 15.75 secs\n",
      "\u001b[1m---- Epoch 39/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.04452, chestimgbbmf1 0.84270, chestimgbb_loss 0.01858, chestimgbbiou 0.93300, chestimgbbmae 0.02302, 195.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82889, chestimgbbiou 0.93061, chestimgbbmae 0.02395, 14.79 secs\n",
      "\u001b[1m---- Epoch 40/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01200, chestimgbbmf1 0.84651, chestimgbb_loss 0.01844, chestimgbbiou 0.93354, chestimgbbmae 0.02282, 197.87 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83789, chestimgbbiou 0.93267, chestimgbbmae 0.02320, 17.10 secs\n",
      "\u001b[1m---- Epoch 41/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00824, chestimgbbmf1 0.84887, chestimgbb_loss 0.01844, chestimgbbiou 0.93430, chestimgbbmae 0.02259, 191.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84048, chestimgbbiou 0.93334, chestimgbbmae 0.02298, 18.12 secs\n",
      "\u001b[1m---- Epoch 42/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.02096, chestimgbbmf1 0.85122, chestimgbb_loss 0.01719, chestimgbbiou 0.93508, chestimgbbmae 0.02230, 193.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84142, chestimgbbiou 0.93400, chestimgbbmae 0.02276, 16.84 secs\n",
      "\u001b[1m---- Epoch 43/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.01030, chestimgbbmf1 0.85355, chestimgbb_loss 0.01821, chestimgbbiou 0.93553, chestimgbbmae 0.02215, 191.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84142, chestimgbbiou 0.93445, chestimgbbmae 0.02256, 16.85 secs\n",
      "\u001b[1m---- Epoch 44/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.03175, chestimgbbmf1 0.85521, chestimgbb_loss 0.01587, chestimgbbiou 0.93608, chestimgbbmae 0.02193, 186.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84237, chestimgbbiou 0.93434, chestimgbbmae 0.02264, 17.28 secs\n",
      "\u001b[1m---- Epoch 45/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00480, chestimgbbmf1 0.85564, chestimgbb_loss 0.01660, chestimgbbiou 0.93631, chestimgbbmae 0.02186, 193.05 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84319, chestimgbbiou 0.93454, chestimgbbmae 0.02257, 14.93 secs\n",
      "\u001b[1m---- Epoch 46/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.00797, chestimgbbmf1 0.85855, chestimgbb_loss 0.01631, chestimgbbiou 0.93684, chestimgbbmae 0.02166, 190.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84409, chestimgbbiou 0.93503, chestimgbbmae 0.02236, 16.49 secs\n",
      "\u001b[1m---- Epoch 47/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.01752, chestimgbbmf1 0.84022, chestimgbb_loss 0.01772, chestimgbbiou 0.93174, chestimgbbmae 0.02344, 190.56 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.81445, chestimgbbiou 0.92810, chestimgbbmae 0.02484, 16.84 secs\n",
      "\u001b[1m---- Epoch 48/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.04834, chestimgbbmf1 0.84403, chestimgbb_loss 0.01650, chestimgbbiou 0.93276, chestimgbbmae 0.02305, 192.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83160, chestimgbbiou 0.93118, chestimgbbmae 0.02368, 15.05 secs\n",
      "\u001b[1m---- Epoch 49/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.02109, chestimgbbmf1 0.84535, chestimgbb_loss 0.01788, chestimgbbiou 0.93364, chestimgbbmae 0.02276, 194.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.82497, chestimgbbiou 0.92987, chestimgbbmae 0.02431, 14.78 secs\n",
      "\u001b[1m---- Epoch 50/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 0.01409, chestimgbbmf1 0.84816, chestimgbb_loss 0.01726, chestimgbbiou 0.93427, chestimgbbmae 0.02257, 193.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83815, chestimgbbiou 0.93335, chestimgbbmae 0.02290, 17.72 secs\n",
      "\u001b[1m---- Epoch 51/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.00861, chestimgbbmf1 0.85696, chestimgbb_loss 0.01628, chestimgbbiou 0.93596, chestimgbbmae 0.02195, 194.34 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83792, chestimgbbiou 0.93361, chestimgbbmae 0.02291, 16.55 secs\n",
      "\u001b[1m---- Epoch 52/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.01276, chestimgbbmf1 0.85510, chestimgbb_loss 0.01803, chestimgbbiou 0.93573, chestimgbbmae 0.02207, 191.98 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83993, chestimgbbiou 0.93374, chestimgbbmae 0.02292, 14.40 secs\n",
      "\u001b[1m---- Epoch 53/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.01236, chestimgbbmf1 0.85658, chestimgbb_loss 0.01676, chestimgbbiou 0.93634, chestimgbbmae 0.02183, 193.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.83792, chestimgbbiou 0.93350, chestimgbbmae 0.02301, 16.21 secs\n",
      "\u001b[1m---- Epoch 54/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.00846, chestimgbbmf1 0.85520, chestimgbb_loss 0.01630, chestimgbbiou 0.93626, chestimgbbmae 0.02186, 190.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84316, chestimgbbiou 0.93497, chestimgbbmae 0.02241, 16.61 secs\n",
      "\u001b[1m---- Epoch 55/55\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.00823, chestimgbbmf1 0.85713, chestimgbb_loss 0.01688, chestimgbbiou 0.93639, chestimgbbmae 0.02186, 189.85 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.84451, chestimgbbiou 0.93557, chestimgbbmae 0.02214, 17.16 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230224_065346_mim_dn121/\" \\\n",
    "        --epochs 55 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 70 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 3 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,5,4e-5,10,2e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --use-chest-imagenome-decent-images-only \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --img-aug-mode \"random-spatial\" \\\n",
    "        --use-anaxnet-bbox-subset \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
