{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_64_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5922.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/checkpoint_64_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5922.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99605, chxlmicf1 0.58233, chxlmacf1 0.48010, chxlacc 0.74483, chxlrocaucmic 0.82521, chxlrocaucmac 0.76051, qlmacf1 0.21576, qlmicf1 0.39086, 282.50 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 pamessina pamessina 3.7M Sep 15 18:23 '/home/pamessina/medvqa-workspace/results/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"/home/pamessina/medvqa-workspace/results/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_85_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.6035.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/checkpoint_85_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.6035.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99704, chxlmicf1 0.57969, chxlmacf1 0.46995, chxlacc 0.74573, chxlrocaucmic 0.82200, chxlrocaucmac 0.75137, qlmacf1 0.21689, qlmicf1 0.38728, 144.13 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 pamessina pamessina 3.7M Sep 15 19:05 '/home/pamessina/medvqa-workspace/results/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"/home/pamessina/medvqa-workspace/results/vqa/20220816_224509_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_98_chxlmacf1+chxlmicf1+cD+ema+gacc+oracc+qlmacf1+qlmicf1+wmdcmp=0.6059.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp/checkpoint_98_chxlmacf1+chxlmicf1+cD+ema+gacc+oracc+qlmacf1+qlmicf1+wmdcmp=0.6059.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99605, chxlmicf1 0.57686, chxlmacf1 0.47543, chxlacc 0.73212, chxlrocaucmic 0.82189, chxlrocaucmac 0.76415, qlmacf1 0.20822, qlmicf1 0.36613, 267.52 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 pamessina pamessina 3.4M Aug 26 07:29 '/home/pamessina/medvqa-workspace/results/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"/home/pamessina/medvqa-workspace/results/vqa/20220817_045815_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220817_135112_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220817_135112_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_100_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+wmdcmp=0.6339.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220817_135112_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4_orien_chx_ql_amp/checkpoint_100_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+wmdcmp=0.6339.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 126\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57933, chxlmacf1 0.48020, chxlacc 0.73247, chxlrocaucmic 0.82207, chxlrocaucmac 0.76476, qlmacf1 0.21198, qlmicf1 0.37237, 284.07 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220817_135112_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220817_135112_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220818_184727_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220818_184727_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_95_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6357.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220818_184727_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/checkpoint_95_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6357.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99704, chxlmicf1 0.58534, chxlmacf1 0.48249, chxlacc 0.73277, chxlrocaucmic 0.82823, chxlrocaucmac 0.76267, qlmacf1 0.21195, qlmicf1 0.38184, 279.61 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220818_184727_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220818_184727_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220818_184140_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220818_184140_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_100_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6402.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220818_184140_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/checkpoint_100_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6402.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99737, chxlmicf1 0.58409, chxlmacf1 0.48354, chxlacc 0.73939, chxlrocaucmic 0.82453, chxlrocaucmac 0.76173, qlmacf1 0.21348, qlmicf1 0.37677, 282.28 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220818_184140_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220818_184140_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220822_095024_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220822_095024_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_82_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6399.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220822_095024_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/checkpoint_82_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6399.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 133\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99737, chxlmicf1 0.56712, chxlmacf1 0.47120, chxlacc 0.72825, chxlrocaucmic 0.80927, chxlrocaucmac 0.76019, qlmacf1 0.20608, qlmicf1 0.35414, 148.37 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220822_095024_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220822_095024_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220822_104439_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220822_104439_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_83_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6415.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220822_104439_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/checkpoint_83_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6415.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 133\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57442, chxlmacf1 0.47597, chxlacc 0.72023, chxlrocaucmic 0.81934, chxlrocaucmac 0.76226, qlmacf1 0.21008, qlmicf1 0.37452, 142.23 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220822_104439_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220822_104439_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220823_135418_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220823_135418_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 10\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_96_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6256.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220823_135418_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_96_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6256.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 133\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "_get_output_transform(): valid_class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57151, chxlmacf1 0.47540, chxlacc 0.72156, chxlrocaucmic 0.81827, chxlrocaucmac 0.76449, qlmacf1 0.21312, qlmicf1 0.37737, 141.80 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220823_135418_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220823_135418_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220823_150528_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220823_150528_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 10\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_91_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6216.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220823_150528_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_91_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6216.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99573, chxlmicf1 0.58877, chxlmacf1 0.48531, chxlacc 0.74562, chxlrocaucmic 0.82828, chxlrocaucmac 0.76493, qlmacf1 0.21890, qlmicf1 0.39853, 254.02 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220823_150528_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220823_150528_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220824_080354_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220824_080354_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 10\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_190_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6286.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220824_080354_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_190_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6286.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99638, chxlmicf1 0.58551, chxlmacf1 0.48045, chxlacc 0.74317, chxlrocaucmic 0.82824, chxlrocaucmac 0.75639, qlmacf1 0.21103, qlmicf1 0.35400, 141.02 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220824_080354_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220824_080354_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220824_112420_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220824_112420_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 10\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_93_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6246.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220824_112420_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_93_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6246.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.59353, chxlmacf1 0.48330, chxlacc 0.75049, chxlrocaucmic 0.83142, chxlrocaucmac 0.75339, qlmacf1 0.21680, qlmicf1 0.38154, 139.56 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220824_112420_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220824_112420_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_73_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.6275.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/checkpoint_73_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.6275.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57224, chxlmacf1 0.43714, chxlacc 0.77215, chxlrocaucmic 0.81699, chxlrocaucmac 0.71535, qlmacf1 0.21055, qlmicf1 0.41484, 141.99 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 13\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_73_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.6275.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/checkpoint_73_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.6275.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57224, chxlmacf1 0.43714, chxlacc 0.77215, chxlrocaucmic 0.81699, chxlrocaucmac 0.71535, qlmacf1 0.21055, qlmicf1 0.41484, 141.99 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220825_154513_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=report__from(qa_adapted_reports__20220629_042239.json;qa_adapted_reports__20220629_050643.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 10\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.48145466, 0.4578275, 0.40821073), std = (0.26862954, 0.26130258, 0.27577711)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_76_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5945.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220629_050643.json;tokenizer=5329,43243,4002259961944187905;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vit-bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.57128, chxlmacf1 0.45484, chxlacc 0.74623, chxlrocaucmic 0.81297, chxlrocaucmac 0.72960, qlmacf1 0.20228, qlmicf1 0.36707, 110.27 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220828_160224_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vit-bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   use_amp: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 10\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_75_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5985.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/checkpoint_75_chxlmacf1+chxlmicf1+cD+ema+oracc+qlmacf1+qlmicf1+wmdcmp=0.5985.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4838,39196,466463750150781738;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99671, chxlmicf1 0.59034, chxlmacf1 0.47127, chxlacc 0.75475, chxlrocaucmic 0.82335, chxlrocaucmac 0.74281, qlmacf1 0.21872, qlmicf1 0.39605, 651.26 secs\n",
      "Chexpert-based output saved to /home/pamessina/medvqa-workspace/results/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_rg_chexpert_based.py \\\n",
    "        --checkpoint-folder \"models/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 pamessina pamessina 3.4M Aug 26 06:39 '/home/pamessina/medvqa-workspace/results/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh \"/home/pamessina/medvqa-workspace/results/vqa/20220816_210819_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1,0.2_orien_chx_ql_amp/mimiccxr_chexpert_based_output.pkl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
