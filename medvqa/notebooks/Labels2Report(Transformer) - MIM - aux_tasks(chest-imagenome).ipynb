{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 77\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   labels_hidden_dim: 256\n",
      "   embedding_dim: 256\n",
      "   transf_dec_hidden_dim: 256\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   dropout_prob: 0\n",
      "   vocab_min_freq: 10\n",
      "   use_medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,4,4e-4,8,5e-6,4e-4,8,5e-6\n",
      "   iters_to_accumulate: 2\n",
      "   override_lr: False\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   batch_size: 150\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   train_mimiccxr: True\n",
      "   mimiccxr_weight: 1.0\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   mimiccxr_balanced_sampling_mode: balanced_chest_imagenome_global_labels_batchwise\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   chest_imagenome_labels_filename: imageId2labels(min_freq=1000).pkl\n",
      "   chest_imagenome_label_names_filename: labels(min_freq=1000).pkl\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   save: True\n",
      "   use_gender: False\n",
      "   use_chexpert: False\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   use_chest_imagenome: True\n",
      "   debug: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "chest_imagenome_range: (0, 379)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mCreating instance of Labels2ReportModel ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,4,4e-4,8,5e-6,4e-4,8,5e-6\n",
      "1e-06 4 0.0004 8 5e-06 0.0004 8 5e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0004\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "227835it [00:18, 12295.40it/s]\n",
      "max_idx_count = 377110\n",
      "actual_idx_count = 240530\n",
      "** NOTE: 136580 images were skipped because they were not in the allowed DICOM IDs\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome labels...\n",
      "Balanced sampling mode: balanced_chest_imagenome_global_labels_batchwise\n",
      "Regrouping indices by Chest Imagenome labels for balanced sampling...\n",
      "100%|██████████████████████████████████| 235209/235209 [04:12<00:00, 933.08it/s]\n",
      "Global: vascular calcification                  , # images: 10203 (other: 225006)\n",
      "Global: abnormal                                , # images: 185310 (other: 49899)\n",
      "Global: atelectasis                             , # images: 79475 (other: 155734)\n",
      "Global: lung opacity                            , # images: 155627 (other: 79582)\n",
      "Global: pleural/parenchymal scarring            , # images: 14244 (other: 220965)\n",
      "Global: pneumonia                               , # images: 34361 (other: 200848)\n",
      "Global: enlarged cardiac silhouette             , # images: 57873 (other: 177336)\n",
      "Global: low lung volumes                        , # images: 28321 (other: 206888)\n",
      "Global: spinal degenerative changes             , # images: 6838 (other: 228371)\n",
      "Global: hyperaeration                           , # images: 10344 (other: 224865)\n",
      "Global: spinal fracture                         , # images: 3111 (other: 232098)\n",
      "Global: copd/emphysema                          , # images: 6573 (other: 228636)\n",
      "Global: tortuous aorta                          , # images: 13501 (other: 221708)\n",
      "Global: pleural effusion                        , # images: 72443 (other: 162766)\n",
      "Global: consolidation                           , # images: 17863 (other: 217346)\n",
      "Global: linear/patchy atelectasis               , # images: 12848 (other: 222361)\n",
      "Global: interstitial lung disease               , # images: 1948 (other: 233261)\n",
      "Global: pulmonary edema/hazy opacity            , # images: 35453 (other: 199756)\n",
      "Global: shoulder osteoarthritis                 , # images: 2188 (other: 233021)\n",
      "Global: mediastinal widening                    , # images: 5090 (other: 230119)\n",
      "Global: superior mediastinal mass/enlargement   , # images: 3305 (other: 231904)\n",
      "Global: vascular congestion                     , # images: 24731 (other: 210478)\n",
      "Global: aspiration                              , # images: 8959 (other: 226250)\n",
      "Global: enlarged hilum                          , # images: 9012 (other: 226197)\n",
      "Global: bone lesion                             , # images: 1491 (other: 233718)\n",
      "Global: lung lesion                             , # images: 13527 (other: 221682)\n",
      "Global: mass/nodule (not otherwise specified)   , # images: 7830 (other: 227379)\n",
      "Global: costophrenic angle blunting             , # images: 5740 (other: 229469)\n",
      "Global: subclavian line                         , # images: 3902 (other: 231307)\n",
      "Global: infiltration                            , # images: 2987 (other: 232222)\n",
      "Global: picc                                    , # images: 14360 (other: 220849)\n",
      "Global: prosthetic valve                        , # images: 2903 (other: 232306)\n",
      "Global: rib fracture                            , # images: 7107 (other: 228102)\n",
      "Global: endotracheal tube                       , # images: 22685 (other: 212524)\n",
      "Global: airspace opacity                        , # images: 8638 (other: 226571)\n",
      "Global: enteric tube                            , # images: 28140 (other: 207069)\n",
      "Global: ij line                                 , # images: 12182 (other: 223027)\n",
      "Global: mediastinal displacement                , # images: 3515 (other: 231694)\n",
      "Global: vascular redistribution                 , # images: 3209 (other: 232000)\n",
      "Global: fluid overload/heart failure            , # images: 6477 (other: 228732)\n",
      "Global: scoliosis                               , # images: 3215 (other: 231994)\n",
      "Global: pneumothorax                            , # images: 10677 (other: 224532)\n",
      "Global: alveolar hemorrhage                     , # images: 1780 (other: 233429)\n",
      "Global: cabg grafts                             , # images: 3856 (other: 231353)\n",
      "Global: subcutaneous air                        , # images: 3384 (other: 231825)\n",
      "Global: chest tube                              , # images: 10336 (other: 224873)\n",
      "Global: elevated hemidiaphragm                  , # images: 6439 (other: 228770)\n",
      "Global: lobar/segmental collapse                , # images: 9634 (other: 225575)\n",
      "Global: pigtail catheter                        , # images: 3559 (other: 231650)\n",
      "Global: cardiac pacer and wires                 , # images: 12504 (other: 222705)\n",
      "Global: rotated                                 , # images: 2054 (other: 233155)\n",
      "Global: hernia                                  , # images: 3042 (other: 232167)\n",
      "Global: chest port                              , # images: 7282 (other: 227927)\n",
      "Global: multiple masses/nodules                 , # images: 3750 (other: 231459)\n",
      "Global: calcified nodule                        , # images: 2719 (other: 232490)\n",
      "Global: granulomatous disease                   , # images: 2435 (other: 232774)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global: lung cancer                             , # images: 1761 (other: 233448)\n",
      "Global: pericardial effusion                    , # images: 1404 (other: 233805)\n",
      "Global: breast/nipple shadows                   , # images: 1020 (other: 234189)\n",
      "Global: increased reticular markings/ild pattern, # images: 1377 (other: 233832)\n",
      "Global: tracheostomy tube                       , # images: 4781 (other: 230428)\n",
      "Global: swan-ganz catheter                      , # images: 2212 (other: 232997)\n",
      "Global: pneumomediastinum                       , # images: 865 (other: 234344)\n",
      "Global: sub-diaphragmatic air                   , # images: 1238 (other: 233971)\n",
      "Global: bronchiectasis                          , # images: 798 (other: 234411)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_235116_mim_Labels2ReportModel(transf,379->379)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_235116_mim_Labels2ReportModel(transf,379->379)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230418_235116_mim_Labels2ReportModel(transf,379->379)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 10.66517, cD 0.00011, wmdcmp 0.00663, report_loss 8.54369, chestimglaucmic 0.52592, chestimglaucmac 0.50022, chestimglprcaucmic 0.07917, chestimglprcaucmac 0.08636, chestimgl_loss 2.00987, 475.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00015, wmdcmp 0.00660, chestimglaucmic 0.52965, chestimglaucmac 0.50067, chestimglprcaucmic 0.06479, chestimglprcaucmac 0.07896, 28.65 secs\n",
      "\u001b[1m---- Epoch 2/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 10.42140, cD 0.00083, wmdcmp 0.00793, report_loss 7.98493, chestimglaucmic 0.54178, chestimglaucmac 0.50200, chestimglprcaucmic 0.08448, chestimglprcaucmac 0.08697, chestimgl_loss 2.00487, 442.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00042, wmdcmp 0.00051, chestimglaucmic 0.55427, chestimglaucmac 0.49601, chestimglprcaucmic 0.07492, chestimglprcaucmac 0.08071, 27.96 secs\n",
      "\u001b[1m---- Epoch 3/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000020) ...\n",
      "loss 9.45056, cD 0.00004, wmdcmp 0.00034, report_loss 6.46416, chestimglaucmic 0.59039, chestimglaucmac 0.48714, chestimglprcaucmic 0.16222, chestimglprcaucmac 0.08549, chestimgl_loss 1.97078, 366.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00042, wmdcmp 0.00051, chestimglaucmic 0.57366, chestimglaucmac 0.40672, chestimglprcaucmic 0.24219, chestimglprcaucmac 0.07042, 23.31 secs\n",
      "\u001b[1m---- Epoch 4/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000089) ...\n",
      "loss 7.69858, cD 0.01526, wmdcmp 0.02696, report_loss 4.84828, chestimglaucmic 0.65549, chestimglaucmac 0.42938, chestimglprcaucmic 0.27556, chestimglprcaucmac 0.06898, chestimgl_loss 1.94648, 406.32 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00017, wmdcmp 0.01655, chestimglaucmic 0.73131, chestimglaucmac 0.43324, chestimglprcaucmic 0.35800, chestimglprcaucmac 0.07762, 28.28 secs\n",
      "\u001b[1m---- Epoch 5/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 6.14182, cD 0.44620, wmdcmp 0.10782, report_loss 3.60540, chestimglaucmic 0.92243, chestimglaucmac 0.81743, chestimglprcaucmic 0.72643, chestimglprcaucmac 0.31513, chestimgl_loss 1.42076, 352.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.20053, wmdcmp 0.09867, chestimglaucmic 0.98325, chestimglaucmac 0.93019, chestimglprcaucmic 0.92242, chestimglprcaucmac 0.65099, 22.89 secs\n",
      "\u001b[1m---- Epoch 6/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000231) ...\n",
      "loss 4.19128, cD 0.74918, wmdcmp 0.15029, report_loss 3.03640, chestimglaucmic 0.99019, chestimglaucmac 0.97035, chestimglprcaucmic 0.94571, chestimglprcaucmac 0.74104, chestimgl_loss 0.88981, 382.77 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.29406, wmdcmp 0.11052, chestimglaucmic 0.99492, chestimglaucmac 0.97258, chestimglprcaucmic 0.96984, chestimglprcaucmac 0.78795, 27.04 secs\n",
      "\u001b[1m---- Epoch 7/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 3.89192, cD 0.85168, wmdcmp 0.16889, report_loss 2.85746, chestimglaucmic 0.99575, chestimglaucmac 0.98569, chestimglprcaucmic 0.97255, chestimglprcaucmac 0.83287, chestimgl_loss 0.72280, 444.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35808, wmdcmp 0.11913, chestimglaucmic 0.99755, chestimglaucmac 0.98522, chestimglprcaucmic 0.98279, chestimglprcaucmac 0.84075, 34.60 secs\n",
      "\u001b[1m---- Epoch 8/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000077) ...\n",
      "loss 3.75867, cD 0.88960, wmdcmp 0.17438, report_loss 2.79454, chestimglaucmic 0.99731, chestimglaucmac 0.99048, chestimglprcaucmic 0.98089, chestimglprcaucmac 0.86811, chestimgl_loss 0.64931, 355.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.34447, wmdcmp 0.11955, chestimglaucmic 0.99827, chestimglaucmac 0.98930, chestimglprcaucmic 0.98692, chestimglprcaucmac 0.86586, 24.43 secs\n",
      "\u001b[1m---- Epoch 9/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 3.40362, cD 0.91554, wmdcmp 0.17922, report_loss 2.74987, chestimglaucmic 0.99795, chestimglaucmac 0.99249, chestimglprcaucmic 0.98453, chestimglprcaucmac 0.88416, chestimgl_loss 0.60863, 356.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.36661, wmdcmp 0.12477, chestimglaucmic 0.99856, chestimglaucmac 0.99145, chestimglprcaucmic 0.98872, chestimglprcaucmac 0.88136, 30.42 secs\n",
      "\u001b[1m---- Epoch 10/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000026) ...\n",
      "loss 3.33841, cD 0.92316, wmdcmp 0.17979, report_loss 2.73312, chestimglaucmic 0.99814, chestimglaucmac 0.99329, chestimglprcaucmic 0.98576, chestimglprcaucmac 0.89250, chestimgl_loss 0.59153, 366.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.36436, wmdcmp 0.12450, chestimglaucmic 0.99872, chestimglaucmac 0.99246, chestimglprcaucmic 0.98968, chestimglprcaucmac 0.88804, 26.62 secs\n",
      "\u001b[1m---- Epoch 11/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 3.16623, cD 0.93039, wmdcmp 0.18016, report_loss 2.72677, chestimglaucmic 0.99831, chestimglaucmac 0.99369, chestimglprcaucmic 0.98697, chestimglprcaucmac 0.89711, chestimgl_loss 0.58070, 364.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37060, wmdcmp 0.12596, chestimglaucmic 0.99879, chestimglaucmac 0.99280, chestimglprcaucmic 0.99014, chestimglprcaucmac 0.89149, 25.87 secs\n",
      "\u001b[1m---- Epoch 12/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 3.39599, cD 0.94024, wmdcmp 0.18265, report_loss 2.70637, chestimglaucmic 0.99839, chestimglaucmac 0.99410, chestimglprcaucmic 0.98731, chestimglprcaucmac 0.89919, chestimgl_loss 0.56950, 339.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.36950, wmdcmp 0.12630, chestimglaucmic 0.99883, chestimglaucmac 0.99304, chestimglprcaucmic 0.99040, chestimglprcaucmac 0.89326, 27.25 secs\n",
      "\u001b[1m---- Epoch 13/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.55478, cD 0.94014, wmdcmp 0.18201, report_loss 2.71257, chestimglaucmic 0.99842, chestimglaucmac 0.99419, chestimglprcaucmic 0.98750, chestimglprcaucmac 0.90079, chestimgl_loss 0.56652, 248.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37659, wmdcmp 0.12662, chestimglaucmic 0.99885, chestimglaucmac 0.99316, chestimglprcaucmic 0.99055, chestimglprcaucmac 0.89453, 17.91 secs\n",
      "\u001b[1m---- Epoch 14/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.99833, cD 0.98370, wmdcmp 0.18965, report_loss 2.62660, chestimglaucmic 0.99910, chestimglaucmac 0.99638, chestimglprcaucmic 0.99224, chestimglprcaucmac 0.92592, chestimgl_loss 0.47974, 233.99 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.35022, wmdcmp 0.12620, chestimglaucmic 0.99971, chestimglaucmac 0.99849, chestimglprcaucmic 0.99683, chestimglprcaucmac 0.95424, 17.91 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 15/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.84982, cD 1.05960, wmdcmp 0.20301, report_loss 2.51098, chestimglaucmic 0.99965, chestimglaucmac 0.99861, chestimglprcaucmic 0.99646, chestimglprcaucmac 0.95957, chestimgl_loss 0.37212, 203.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.33364, wmdcmp 0.12285, chestimglaucmic 0.99985, chestimglaucmac 0.99926, chestimglprcaucmic 0.99817, chestimglprcaucmac 0.97067, 15.91 secs\n",
      "\u001b[1m---- Epoch 16/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 2.49420, cD 1.09609, wmdcmp 0.20749, report_loss 2.46711, chestimglaucmic 0.99978, chestimglaucmac 0.99913, chestimglprcaucmic 0.99768, chestimglprcaucmac 0.97142, chestimgl_loss 0.32681, 190.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.48167, wmdcmp 0.14012, chestimglaucmic 0.99989, chestimglaucmac 0.99943, chestimglprcaucmic 0.99861, chestimglprcaucmac 0.97680, 16.56 secs\n",
      "\u001b[1m---- Epoch 17/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.60241, cD 1.11804, wmdcmp 0.21128, report_loss 2.43555, chestimglaucmic 0.99983, chestimglaucmac 0.99933, chestimglprcaucmic 0.99813, chestimglprcaucmac 0.97544, chestimgl_loss 0.30529, 190.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.40613, wmdcmp 0.14134, chestimglaucmic 0.99991, chestimglaucmac 0.99960, chestimglprcaucmic 0.99880, chestimglprcaucmac 0.97933, 16.07 secs\n",
      "\u001b[1m---- Epoch 18/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 2.61186, cD 1.12569, wmdcmp 0.21317, report_loss 2.42441, chestimglaucmic 0.99984, chestimglaucmac 0.99935, chestimglprcaucmic 0.99828, chestimglprcaucmac 0.97765, chestimgl_loss 0.29424, 206.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37814, wmdcmp 0.13138, chestimglaucmic 0.99992, chestimglaucmac 0.99963, chestimglprcaucmic 0.99889, chestimglprcaucmac 0.98030, 14.61 secs\n",
      "\u001b[1m---- Epoch 19/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.59847, cD 1.12908, wmdcmp 0.21398, report_loss 2.41594, chestimglaucmic 0.99986, chestimglaucmac 0.99946, chestimglprcaucmic 0.99848, chestimglprcaucmac 0.97898, chestimgl_loss 0.28972, 185.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.45772, wmdcmp 0.14202, chestimglaucmic 0.99992, chestimglaucmac 0.99964, chestimglprcaucmic 0.99893, chestimglprcaucmac 0.98105, 16.17 secs\n",
      "\u001b[1m---- Epoch 20/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.90009, cD 1.13609, wmdcmp 0.21467, report_loss 2.41100, chestimglaucmic 0.99986, chestimglaucmac 0.99945, chestimglprcaucmic 0.99843, chestimglprcaucmac 0.97998, chestimgl_loss 0.28709, 185.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37327, wmdcmp 0.12966, chestimglaucmic 0.99992, chestimglaucmac 0.99965, chestimglprcaucmic 0.99895, chestimglprcaucmac 0.98132, 15.39 secs\n",
      "\u001b[1m---- Epoch 21/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.88805, cD 1.13044, wmdcmp 0.21310, report_loss 2.41886, chestimglaucmic 0.99987, chestimglaucmac 0.99949, chestimglprcaucmic 0.99850, chestimglprcaucmac 0.98012, chestimgl_loss 0.28328, 175.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.37685, wmdcmp 0.13174, chestimglaucmic 0.99992, chestimglaucmac 0.99966, chestimglprcaucmic 0.99896, chestimglprcaucmac 0.98142, 14.55 secs\n",
      "\u001b[1m---- Epoch 22/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.61546, cD 1.14301, wmdcmp 0.21670, report_loss 2.38741, chestimglaucmic 0.99990, chestimglaucmac 0.99959, chestimglprcaucmic 0.99889, chestimglprcaucmac 0.98399, chestimgl_loss 0.25219, 187.16 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.44697, wmdcmp 0.14788, chestimglaucmic 0.99997, chestimglaucmac 0.99988, chestimglprcaucmic 0.99949, chestimglprcaucmac 0.98950, 13.40 secs\n",
      "\u001b[1m---- Epoch 23/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.37682, cD 1.19779, wmdcmp 0.22479, report_loss 2.32432, chestimglaucmic 0.99995, chestimglaucmac 0.99982, chestimglprcaucmic 0.99943, chestimglprcaucmac 0.99152, chestimgl_loss 0.20279, 183.52 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.49296, wmdcmp 0.15344, chestimglaucmic 0.99998, chestimglaucmac 0.99993, chestimglprcaucmic 0.99967, chestimglprcaucmac 0.99317, 13.27 secs\n",
      "\u001b[1m---- Epoch 24/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 2.36234, cD 1.22611, wmdcmp 0.22808, report_loss 2.29606, chestimglaucmic 0.99997, chestimglaucmac 0.99988, chestimglprcaucmic 0.99961, chestimglprcaucmac 0.99368, chestimgl_loss 0.18359, 192.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.44743, wmdcmp 0.14490, chestimglaucmic 0.99998, chestimglaucmac 0.99994, chestimglprcaucmic 0.99974, chestimglprcaucmac 0.99437, 18.13 secs\n",
      "\u001b[1m---- Epoch 25/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.59619, cD 1.23216, wmdcmp 0.23011, report_loss 2.27422, chestimglaucmic 0.99997, chestimglaucmac 0.99991, chestimglprcaucmic 0.99968, chestimglprcaucmac 0.99507, chestimgl_loss 0.17279, 187.28 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.48701, wmdcmp 0.14876, chestimglaucmic 0.99999, chestimglaucmac 0.99995, chestimglprcaucmic 0.99976, chestimglprcaucmac 0.99489, 15.40 secs\n",
      "\u001b[1m---- Epoch 26/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 2.64278, cD 1.24277, wmdcmp 0.23099, report_loss 2.27318, chestimglaucmic 0.99998, chestimglaucmac 0.99991, chestimglprcaucmic 0.99970, chestimglprcaucmac 0.99536, chestimgl_loss 0.16875, 184.74 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.45314, wmdcmp 0.14387, chestimglaucmic 0.99999, chestimglaucmac 0.99995, chestimglprcaucmic 0.99978, chestimglprcaucmac 0.99533, 15.49 secs\n",
      "\u001b[1m---- Epoch 27/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.20118, cD 1.25545, wmdcmp 0.23371, report_loss 2.25236, chestimglaucmic 0.99998, chestimglaucmac 0.99992, chestimglprcaucmic 0.99973, chestimglprcaucmac 0.99578, chestimgl_loss 0.16338, 192.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.49059, wmdcmp 0.15435, chestimglaucmic 0.99999, chestimglaucmac 0.99995, chestimglprcaucmic 0.99978, chestimglprcaucmac 0.99546, 16.23 secs\n",
      "\u001b[1m---- Epoch 28/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.17407, cD 1.25804, wmdcmp 0.23384, report_loss 2.25768, chestimglaucmic 0.99998, chestimglaucmac 0.99992, chestimglprcaucmic 0.99972, chestimglprcaucmac 0.99583, chestimgl_loss 0.16331, 202.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.44951, wmdcmp 0.14536, chestimglaucmic 0.99999, chestimglaucmac 0.99995, chestimglprcaucmic 0.99978, chestimglprcaucmac 0.99551, 15.83 secs\n",
      "\u001b[1m---- Epoch 29/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.27225, cD 1.25038, wmdcmp 0.23235, report_loss 2.26374, chestimglaucmic 0.99998, chestimglaucmac 0.99993, chestimglprcaucmic 0.99975, chestimglprcaucmac 0.99593, chestimgl_loss 0.16283, 187.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.49764, wmdcmp 0.15597, chestimglaucmic 0.99999, chestimglaucmac 0.99995, chestimglprcaucmic 0.99979, chestimglprcaucmac 0.99552, 14.16 secs\n",
      "\u001b[1m---- Epoch 30/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.23448, cD 1.25121, wmdcmp 0.23335, report_loss 2.25660, chestimglaucmic 0.99998, chestimglaucmac 0.99994, chestimglprcaucmic 0.99978, chestimglprcaucmac 0.99657, chestimgl_loss 0.14793, 177.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.50541, wmdcmp 0.16029, chestimglaucmic 0.99999, chestimglaucmac 0.99998, chestimglprcaucmic 0.99987, chestimglprcaucmac 0.99788, 15.85 secs\n",
      "\u001b[1m---- Epoch 31/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.22156, cD 1.28562, wmdcmp 0.23883, report_loss 2.21447, chestimglaucmic 0.99999, chestimglaucmac 0.99996, chestimglprcaucmic 0.99988, chestimglprcaucmac 0.99792, chestimgl_loss 0.12424, 180.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.52703, wmdcmp 0.16106, chestimglaucmic 0.99999, chestimglaucmac 0.99998, chestimglprcaucmic 0.99990, chestimglprcaucmac 0.99831, 16.57 secs\n",
      "\u001b[1m---- Epoch 32/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 2.39445, cD 1.31426, wmdcmp 0.24266, report_loss 2.19574, chestimglaucmic 0.99999, chestimglaucmac 0.99998, chestimglprcaucmic 0.99991, chestimglprcaucmac 0.99850, chestimgl_loss 0.11356, 203.08 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57793, wmdcmp 0.16741, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99992, chestimglprcaucmac 0.99846, 14.35 secs\n",
      "\u001b[1m---- Epoch 33/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.44537, cD 1.33026, wmdcmp 0.24560, report_loss 2.17424, chestimglaucmic 0.99999, chestimglaucmac 0.99998, chestimglprcaucmic 0.99992, chestimglprcaucmac 0.99883, chestimgl_loss 0.10717, 206.09 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 0.50678, wmdcmp 0.15312, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99992, chestimglprcaucmac 0.99850, 16.35 secs\n",
      "\u001b[1m---- Epoch 34/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 2.45676, cD 1.32769, wmdcmp 0.24482, report_loss 2.17440, chestimglaucmic 0.99999, chestimglaucmac 0.99998, chestimglprcaucmic 0.99992, chestimglprcaucmac 0.99886, chestimgl_loss 0.10564, 206.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.51681, wmdcmp 0.15343, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99993, chestimglprcaucmac 0.99853, 15.51 secs\n",
      "\u001b[1m---- Epoch 35/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.26439, cD 1.33948, wmdcmp 0.24684, report_loss 2.16157, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99994, chestimglprcaucmac 0.99905, chestimgl_loss 0.10328, 196.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57920, wmdcmp 0.15872, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99993, chestimglprcaucmac 0.99855, 14.94 secs\n",
      "\u001b[1m---- Epoch 36/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.24868, cD 1.32453, wmdcmp 0.24525, report_loss 2.16972, chestimglaucmic 0.99999, chestimglaucmac 0.99998, chestimglprcaucmic 0.99993, chestimglprcaucmac 0.99902, chestimgl_loss 0.10258, 200.85 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.52539, wmdcmp 0.15643, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99993, chestimglprcaucmac 0.99857, 15.44 secs\n",
      "\u001b[1m---- Epoch 37/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.10089, cD 1.33560, wmdcmp 0.24677, report_loss 2.15898, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99994, chestimglprcaucmac 0.99908, chestimgl_loss 0.10243, 238.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.52538, wmdcmp 0.15484, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99993, chestimglprcaucmac 0.99857, 17.67 secs\n",
      "\u001b[1m---- Epoch 38/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.33270, cD 1.32745, wmdcmp 0.24574, report_loss 2.16843, chestimglaucmic 1.00000, chestimglaucmac 0.99998, chestimglprcaucmic 0.99994, chestimglprcaucmac 0.99912, chestimgl_loss 0.09470, 198.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.50408, wmdcmp 0.15259, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99995, chestimglprcaucmac 0.99884, 15.94 secs\n",
      "\u001b[1m---- Epoch 39/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.33219, cD 1.35520, wmdcmp 0.24859, report_loss 2.14359, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99996, chestimglprcaucmac 0.99953, chestimgl_loss 0.08070, 223.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.55535, wmdcmp 0.15926, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99996, chestimglprcaucmac 0.99907, 17.21 secs\n",
      "\u001b[1m---- Epoch 40/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 1.89703, cD 1.38350, wmdcmp 0.25408, report_loss 2.11433, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99962, chestimgl_loss 0.07479, 212.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57514, wmdcmp 0.17094, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99918, 15.94 secs\n",
      "\u001b[1m---- Epoch 41/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.17893, cD 1.39010, wmdcmp 0.25424, report_loss 2.11366, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99973, chestimgl_loss 0.07114, 198.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.58956, wmdcmp 0.16396, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99927, 16.56 secs\n",
      "\u001b[1m---- Epoch 42/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.99362, cD 1.38944, wmdcmp 0.25436, report_loss 2.10649, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99973, chestimgl_loss 0.06991, 205.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.61211, wmdcmp 0.16703, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99928, 14.02 secs\n",
      "\u001b[1m---- Epoch 43/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.05461, cD 1.39335, wmdcmp 0.25569, report_loss 2.09911, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99975, chestimgl_loss 0.06902, 222.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59683, wmdcmp 0.16391, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99928, 15.22 secs\n",
      "\u001b[1m---- Epoch 44/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.12040, cD 1.39882, wmdcmp 0.25503, report_loss 2.10696, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99977, chestimgl_loss 0.06850, 200.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60028, wmdcmp 0.16509, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99928, 14.58 secs\n",
      "\u001b[1m---- Epoch 45/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.13264, cD 1.40334, wmdcmp 0.25625, report_loss 2.09901, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99978, chestimgl_loss 0.06799, 185.13 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.60729, wmdcmp 0.16417, chestimglaucmic 1.00000, chestimglaucmac 0.99999, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99928, 16.88 secs\n",
      "\u001b[1m---- Epoch 46/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.42334, cD 1.38736, wmdcmp 0.25386, report_loss 2.11094, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99975, chestimgl_loss 0.06403, 197.17 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.61225, wmdcmp 0.16510, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99997, chestimglprcaucmac 0.99963, 15.92 secs\n",
      "\u001b[1m---- Epoch 47/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.30384, cD 1.41065, wmdcmp 0.25747, report_loss 2.09132, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99986, chestimgl_loss 0.05604, 186.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59927, wmdcmp 0.16556, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99966, 16.21 secs\n",
      "\u001b[1m---- Epoch 48/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 2.00070, cD 1.42944, wmdcmp 0.26032, report_loss 2.07322, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99990, chestimgl_loss 0.05172, 218.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.62098, wmdcmp 0.16886, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99967, 15.43 secs\n",
      "\u001b[1m---- Epoch 49/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.07828, cD 1.44801, wmdcmp 0.26237, report_loss 2.05993, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99993, chestimgl_loss 0.04955, 201.23 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59982, wmdcmp 0.16707, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99970, 16.38 secs\n",
      "\u001b[1m---- Epoch 50/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.92543, cD 1.44294, wmdcmp 0.26185, report_loss 2.06597, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99993, chestimgl_loss 0.04902, 172.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.62212, wmdcmp 0.16958, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99972, 13.40 secs\n",
      "\u001b[1m---- Epoch 51/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.32720, cD 1.44894, wmdcmp 0.26287, report_loss 2.05405, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99994, chestimgl_loss 0.04819, 140.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.61650, wmdcmp 0.16781, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99970, 11.51 secs\n",
      "\u001b[1m---- Epoch 52/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.20537, cD 1.44933, wmdcmp 0.26315, report_loss 2.05506, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99994, chestimgl_loss 0.04748, 142.58 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 0.61243, wmdcmp 0.16875, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99970, 11.69 secs\n",
      "\u001b[1m---- Epoch 53/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.84175, cD 1.45632, wmdcmp 0.26421, report_loss 2.04889, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99994, chestimgl_loss 0.04771, 143.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.61738, wmdcmp 0.16796, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99998, chestimglprcaucmac 0.99970, 11.29 secs\n",
      "\u001b[1m---- Epoch 54/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.00778, cD 1.43310, wmdcmp 0.26104, report_loss 2.06453, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99992, chestimgl_loss 0.04564, 137.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57134, wmdcmp 0.16723, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99974, 12.74 secs\n",
      "\u001b[1m---- Epoch 55/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 1.95900, cD 1.44949, wmdcmp 0.26331, report_loss 2.05212, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99995, chestimgl_loss 0.04023, 136.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.66398, wmdcmp 0.17866, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99986, 11.30 secs\n",
      "\u001b[1m---- Epoch 56/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 1.90806, cD 1.46942, wmdcmp 0.26639, report_loss 2.03022, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99997, chestimgl_loss 0.03710, 138.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.61983, wmdcmp 0.17931, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99989, 11.31 secs\n",
      "\u001b[1m---- Epoch 57/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.04557, cD 1.47828, wmdcmp 0.26802, report_loss 2.02354, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99997, chestimgl_loss 0.03592, 137.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.64924, wmdcmp 0.17171, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99989, 11.46 secs\n",
      "\u001b[1m---- Epoch 58/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 2.20889, cD 1.48430, wmdcmp 0.26811, report_loss 2.02395, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99997, chestimgl_loss 0.03529, 138.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.64688, wmdcmp 0.17468, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99989, 12.87 secs\n",
      "\u001b[1m---- Epoch 59/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.31634, cD 1.48183, wmdcmp 0.26833, report_loss 2.01811, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99998, chestimgl_loss 0.03477, 138.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.65195, wmdcmp 0.17257, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99989, 11.42 secs\n",
      "\u001b[1m---- Epoch 60/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.15457, cD 1.48704, wmdcmp 0.26892, report_loss 2.02023, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99997, chestimgl_loss 0.03485, 142.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.67126, wmdcmp 0.17507, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99989, 11.46 secs\n",
      "\u001b[1m---- Epoch 61/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.01095, cD 1.49224, wmdcmp 0.27067, report_loss 2.01136, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99998, chestimgl_loss 0.03431, 138.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.67000, wmdcmp 0.17431, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99989, 11.35 secs\n",
      "\u001b[1m---- Epoch 62/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 2.11294, cD 1.46828, wmdcmp 0.26604, report_loss 2.02806, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99997, chestimgl_loss 0.03339, 138.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.57120, wmdcmp 0.15887, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99993, 13.15 secs\n",
      "\u001b[1m---- Epoch 63/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.01577, cD 1.48178, wmdcmp 0.26758, report_loss 2.02262, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99998, chestimgl_loss 0.02964, 141.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.65469, wmdcmp 0.17591, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99991, 11.61 secs\n",
      "\u001b[1m---- Epoch 64/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 2.10191, cD 1.50573, wmdcmp 0.27184, report_loss 1.99891, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02773, 143.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.66514, wmdcmp 0.17645, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99991, 11.64 secs\n",
      "\u001b[1m---- Epoch 65/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.06489, cD 1.50263, wmdcmp 0.27159, report_loss 2.00250, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02685, 145.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.67574, wmdcmp 0.17681, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99991, 11.75 secs\n",
      "\u001b[1m---- Epoch 66/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.74073, cD 1.51617, wmdcmp 0.27311, report_loss 1.99163, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02646, 144.63 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.69081, wmdcmp 0.17926, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 0.99999, chestimglprcaucmac 0.99993, 13.66 secs\n",
      "\u001b[1m---- Epoch 67/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.94116, cD 1.52232, wmdcmp 0.27373, report_loss 1.98945, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99998, chestimgl_loss 0.02575, 146.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.67581, wmdcmp 0.17757, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99992, 12.29 secs\n",
      "\u001b[1m---- Epoch 68/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.82740, cD 1.52391, wmdcmp 0.27373, report_loss 1.98432, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02587, 152.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.68618, wmdcmp 0.17892, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99991, 12.30 secs\n",
      "\u001b[1m---- Epoch 69/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.84167, cD 1.52759, wmdcmp 0.27535, report_loss 1.97954, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02558, 152.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.67242, wmdcmp 0.17871, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99991, 12.19 secs\n",
      "\u001b[1m---- Epoch 70/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000400) ...\n",
      "loss 1.98134, cD 1.48758, wmdcmp 0.26873, report_loss 2.01023, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99998, chestimgl_loss 0.02518, 160.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.59471, wmdcmp 0.17099, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99987, 15.34 secs\n",
      "\u001b[1m---- Epoch 71/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000214) ...\n",
      "loss 2.03739, cD 1.51579, wmdcmp 0.27274, report_loss 1.98757, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02234, 147.61 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 0.65437, wmdcmp 0.17613, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99993, 12.07 secs\n",
      "\u001b[1m---- Epoch 72/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000114) ...\n",
      "loss 2.16403, cD 1.52930, wmdcmp 0.27534, report_loss 1.97797, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02105, 154.59 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.65815, wmdcmp 0.17908, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99996, 12.31 secs\n",
      "\u001b[1m---- Epoch 73/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000061) ...\n",
      "loss 2.14058, cD 1.53903, wmdcmp 0.27664, report_loss 1.97275, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02027, 150.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.69509, wmdcmp 0.17990, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99996, 11.76 secs\n",
      "\u001b[1m---- Epoch 74/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.99347, cD 1.54938, wmdcmp 0.27859, report_loss 1.96372, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.02004, 144.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.70550, wmdcmp 0.18171, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99996, 13.17 secs\n",
      "\u001b[1m---- Epoch 75/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.98219, cD 1.54396, wmdcmp 0.27721, report_loss 1.96606, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 1.00000, chestimgl_loss 0.01976, 146.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.71260, wmdcmp 0.18122, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99996, 11.60 secs\n",
      "\u001b[1m---- Epoch 76/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.79427, cD 1.54037, wmdcmp 0.27711, report_loss 1.96169, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99999, chestimgl_loss 0.01984, 152.58 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.70504, wmdcmp 0.18150, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99996, 12.38 secs\n",
      "\u001b[1m---- Epoch 77/77\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.19400, cD 1.54885, wmdcmp 0.27844, report_loss 1.96108, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 1.00000, chestimgl_loss 0.01955, 147.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.72053, wmdcmp 0.18279, chestimglaucmic 1.00000, chestimglaucmac 1.00000, chestimglprcaucmic 1.00000, chestimglprcaucmac 0.99996, 12.49 secs\n"
     ]
    }
   ],
   "source": [
    "!/home/pamessina/venv2/bin/python ../train_labels2report.py \\\n",
    "    --epochs 77 \\\n",
    "    --batches-per-epoch 300 \\\n",
    "    --batch-size 150 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 2 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-decay-and-cyclic-decay-args \"1e-6,4,4e-4,8,5e-6,4e-4,8,5e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "    --mimiccxr-balanced-sampling-mode \"balanced_chest_imagenome_global_labels_batchwise\" \\\n",
    "    --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "    --use-chest-imagenome \\\n",
    "    --chest-imagenome-label-names-filename \"labels(min_freq=1000).pkl\" \\\n",
    "    --chest-imagenome-labels-filename \"imageId2labels(min_freq=1000).pkl\" \\\n",
    "    --use-medical-tokenization \\\n",
    "    --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "    --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 159\n",
      "   batches_per_epoch: 300\n",
      "   batch_size: 200\n",
      "   checkpoint_folder: None\n",
      "   generation_mode: gt2report\n",
      "   ensemble_model_checkpoint_folder_paths: None\n",
      "   ensemble_batch_size: None\n",
      "   ensemble_num_workers: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   labels_hidden_dim: 1024\n",
      "   embedding_dim: 512\n",
      "   transf_dec_num_memory_vecs: 10\n",
      "   transf_dec_hidden_dim: 512\n",
      "   transf_dec_nhead: 4\n",
      "   transf_dec_dim_forward: 512\n",
      "   transf_dec_num_layers: 3\n",
      "   dropout_prob: 0\n",
      "   vocab_min_freq: 10\n",
      "   use_medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,6,3e-4,8,3e-6,3e-4,8,3e-6\n",
      "   iters_to_accumulate: 2\n",
      "   override_lr: False\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   train_mimiccxr: True\n",
      "   mimiccxr_weight: 1.0\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   mimiccxr_balanced_sampling_mode: balanced_chest_imagenome_global_labels_batchwise\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   chest_imagenome_labels_filename: imageId2labels(min_freq=100).pkl\n",
      "   chest_imagenome_label_names_filename: labels(min_freq=100).pkl\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   save: False\n",
      "   use_gender: False\n",
      "   use_chexpert: False\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   use_chest_imagenome: True\n",
      "   debug: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "chest_imagenome_range: (0, 627)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mCreating instance of Labels2ReportModel ...\u001b[0m\n",
      "Labels2ReportModel\n",
      "  vocab_size: 4833\n",
      "  embedding_dim: 512\n",
      "  num_input_labels: 627\n",
      "  labels_hidden_dim: 1024\n",
      "  num_output_labels: 627\n",
      "  transf_dec_num_memory_vecs: 10\n",
      "  transf_dec_hidden_dim: 512\n",
      "  transf_dec_nhead: 4\n",
      "  transf_dec_dim_forward: 512\n",
      "  transf_dec_num_layers: 3\n",
      "  start_idx: 1\n",
      "  dropout_prob: 0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,6,3e-4,8,3e-6,3e-4,8,3e-6\n",
      "1e-06 6 0.0003 8 3e-06 0.0003 8 3e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0003\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR_Labels2ReportTrainer ...\u001b[0m\n",
      "227835it [00:16, 13617.79it/s]\n",
      "max_idx_count = 377110\n",
      "actual_idx_count = 240530\n",
      "** NOTE: 136580 images were skipped because they were not in the allowed DICOM IDs\n",
      "\u001b[1mRandom report:\u001b[0m\n",
      "\u001b[1m\u001b[35m<s> place dobbhoff tube . peripheral left hemithorax . place dobbhoff tube terminates distal stomach . asymmetric pattern airspace consolidation left lung greater right , asymmetric pulmonary edema . right pleural effusion , left effusion cannot . feeding tube terminates distal stomach </s>\u001b[0m\n",
      "len(self.train_indices) = 235209\n",
      "len(self.val_indices) = 1945\n",
      "Loading Chest Imagenome labels...\n",
      "Balanced sampling mode: balanced_chest_imagenome_global_labels_batchwise\n",
      "Regrouping indices by Chest Imagenome labels for balanced sampling...\n",
      "627it [01:03,  9.83it/s] \n",
      "Global: airspace opacity                        , # images: 8638 (other: 226571)\n",
      "Global: atelectasis                             , # images: 79475 (other: 155734)\n",
      "Global: bone lesion                             , # images: 1700 (other: 233509)\n",
      "Global: bronchiectasis                          , # images: 907 (other: 234302)\n",
      "Global: calcified nodule                        , # images: 2719 (other: 232490)\n",
      "Global: clavicle fracture                       , # images: 865 (other: 234344)\n",
      "Global: consolidation                           , # images: 17863 (other: 217346)\n",
      "Global: costophrenic angle blunting             , # images: 5740 (other: 229469)\n",
      "Global: cyst/bullae                             , # images: 880 (other: 234329)\n",
      "Global: elevated hemidiaphragm                  , # images: 6439 (other: 228770)\n",
      "Global: enlarged cardiac silhouette             , # images: 57873 (other: 177336)\n",
      "Global: enlarged hilum                          , # images: 9012 (other: 226197)\n",
      "Global: hernia                                  , # images: 3042 (other: 232167)\n",
      "Global: hydropneumothorax                       , # images: 955 (other: 234254)\n",
      "Global: hyperaeration                           , # images: 10344 (other: 224865)\n",
      "Global: increased reticular markings/ild pattern, # images: 1377 (other: 233832)\n",
      "Global: infiltration                            , # images: 2987 (other: 232222)\n",
      "Global: linear/patchy atelectasis               , # images: 12848 (other: 222361)\n",
      "Global: lobar/segmental collapse                , # images: 9634 (other: 225575)\n",
      "Global: lung lesion                             , # images: 13527 (other: 221682)\n",
      "Global: lung opacity                            , # images: 155627 (other: 79582)\n",
      "Global: mass/nodule (not otherwise specified)   , # images: 7830 (other: 227379)\n",
      "Global: mediastinal displacement                , # images: 3515 (other: 231694)\n",
      "Global: mediastinal widening                    , # images: 5090 (other: 230119)\n",
      "Global: multiple masses/nodules                 , # images: 3750 (other: 231459)\n",
      "Global: pleural effusion                        , # images: 72443 (other: 162766)\n",
      "Global: pleural/parenchymal scarring            , # images: 14244 (other: 220965)\n",
      "Global: pneumomediastinum                       , # images: 865 (other: 234344)\n",
      "Global: pneumothorax                            , # images: 10677 (other: 224532)\n",
      "Global: pulmonary edema/hazy opacity            , # images: 35453 (other: 199756)\n",
      "Global: rib fracture                            , # images: 7107 (other: 228102)\n",
      "Global: scoliosis                               , # images: 3215 (other: 231994)\n",
      "Global: shoulder osteoarthritis                 , # images: 2188 (other: 233021)\n",
      "Global: spinal degenerative changes             , # images: 6838 (other: 228371)\n",
      "Global: spinal fracture                         , # images: 3111 (other: 232098)\n",
      "Global: sub-diaphragmatic air                   , # images: 1238 (other: 233971)\n",
      "Global: subcutaneous air                        , # images: 3384 (other: 231825)\n",
      "Global: superior mediastinal mass/enlargement   , # images: 3305 (other: 231904)\n",
      "Global: tortuous aorta                          , # images: 13501 (other: 221708)\n",
      "Global: vascular calcification                  , # images: 10203 (other: 225006)\n",
      "Global: vascular congestion                     , # images: 24731 (other: 210478)\n",
      "Global: vascular redistribution                 , # images: 3209 (other: 232000)\n",
      "Global: aortic graft/repair                     , # images: 118 (other: 235091)\n",
      "Global: cabg grafts                             , # images: 3856 (other: 231353)\n",
      "Global: cardiac pacer and wires                 , # images: 12504 (other: 222705)\n",
      "Global: prosthetic valve                        , # images: 2903 (other: 232306)\n",
      "Global: alveolar hemorrhage                     , # images: 1780 (other: 233429)\n",
      "Global: aspiration                              , # images: 8959 (other: 226250)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global: copd/emphysema                          , # images: 6573 (other: 228636)\n",
      "Global: fluid overload/heart failure            , # images: 6477 (other: 228732)\n",
      "Global: goiter                                  , # images: 617 (other: 234592)\n",
      "Global: granulomatous disease                   , # images: 2435 (other: 232774)\n",
      "Global: interstitial lung disease               , # images: 1948 (other: 233261)\n",
      "Global: lung cancer                             , # images: 1761 (other: 233448)\n",
      "Global: pericardial effusion                    , # images: 1404 (other: 233805)\n",
      "Global: pneumonia                               , # images: 34361 (other: 200848)\n",
      "Global: abnormal                                , # images: 185340 (other: 49869)\n",
      "Global: artifact                                , # images: 300 (other: 234909)\n",
      "Global: breast/nipple shadows                   , # images: 1020 (other: 234189)\n",
      "Global: low lung volumes                        , # images: 28321 (other: 206888)\n",
      "Global: rotated                                 , # images: 2054 (other: 233155)\n",
      "Global: skin fold                               , # images: 216 (other: 234993)\n",
      "Global: chest port                              , # images: 7282 (other: 227927)\n",
      "Global: chest tube                              , # images: 10336 (other: 224873)\n",
      "Global: endotracheal tube                       , # images: 22685 (other: 212524)\n",
      "Global: enteric tube                            , # images: 28140 (other: 207069)\n",
      "Global: ij line                                 , # images: 12182 (other: 223027)\n",
      "Global: intra-aortic balloon pump               , # images: 563 (other: 234646)\n",
      "Global: mediastinal drain                       , # images: 439 (other: 234770)\n",
      "Global: picc                                    , # images: 14360 (other: 220849)\n",
      "Global: pigtail catheter                        , # images: 3559 (other: 231650)\n",
      "Global: subclavian line                         , # images: 3902 (other: 231307)\n",
      "Global: swan-ganz catheter                      , # images: 2212 (other: 232997)\n",
      "Global: tracheostomy tube                       , # images: 4781 (other: 230428)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 8.72033, wmdcmp 0.00333, report_loss 8.50837, 175.38 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.00443, cD 0.00008, 18.40 secs\n",
      "\u001b[1m---- Epoch 2/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 8.28788, wmdcmp 0.00090, report_loss 7.70478, 160.57 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.00051, cD 0.00042, 13.65 secs\n",
      "\u001b[1m---- Epoch 3/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 7.21266, wmdcmp 0.00204, report_loss 6.44701, 155.63 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.01025, cD 0.00017, 14.85 secs\n",
      "\u001b[1m---- Epoch 4/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 5.90358, wmdcmp 0.02327, report_loss 5.26410, 160.17 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.01233, cD 0.00030, 14.36 secs\n",
      "\u001b[1m---- Epoch 5/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.95587, wmdcmp 0.07472, report_loss 4.23797, 157.80 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.03090, cD 0.00261, 14.00 secs\n",
      "\u001b[1m---- Epoch 6/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000116) ...\n",
      "loss 3.60817, wmdcmp 0.13768, report_loss 3.33872, 137.47 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.12584, cD 0.36846, 13.91 secs\n",
      "\u001b[1m---- Epoch 7/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 3.12294, wmdcmp 0.18946, report_loss 2.71160, 128.49 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.14830, cD 0.46964, 13.87 secs\n",
      "\u001b[1m---- Epoch 8/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000169) ...\n",
      "loss 2.64013, wmdcmp 0.22098, report_loss 2.40733, 124.91 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.14751, cD 0.47958, 14.52 secs\n",
      "\u001b[1m---- Epoch 9/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000095) ...\n",
      "loss 2.24507, wmdcmp 0.23511, report_loss 2.29907, 123.85 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.16253, cD 0.53912, 12.96 secs\n",
      "\u001b[1m---- Epoch 10/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000053) ...\n",
      "loss 2.54281, wmdcmp 0.24113, report_loss 2.25815, 119.62 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.15794, cD 0.55099, 14.12 secs\n",
      "\u001b[1m---- Epoch 11/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 2.12357, wmdcmp 0.24318, report_loss 2.23426, 122.94 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.15760, cD 0.56446, 14.05 secs\n",
      "\u001b[1m---- Epoch 12/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.09142, wmdcmp 0.24568, report_loss 2.22296, 123.71 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.16159, cD 0.57232, 14.97 secs\n",
      "\u001b[1m---- Epoch 13/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 2.24583, wmdcmp 0.24779, report_loss 2.20856, 130.54 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.16156, cD 0.57216, 15.07 secs\n",
      "\u001b[1m---- Epoch 14/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 2.18218, wmdcmp 0.24766, report_loss 2.20740, 135.94 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.16280, cD 0.58267, 18.81 secs\n",
      "\u001b[1m---- Epoch 15/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.88935, wmdcmp 0.24807, report_loss 2.20532, 144.15 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.16219, cD 0.57664, 16.81 secs\n",
      "\u001b[1m---- Epoch 16/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 2.22681, wmdcmp 0.25047, report_loss 2.18264, 153.51 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.15243, cD 0.56393, 19.04 secs\n",
      "\u001b[1m---- Epoch 17/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 2.13276, wmdcmp 0.26479, report_loss 2.08609, 170.61 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18044, cD 0.68409, 20.27 secs\n",
      "\u001b[1m---- Epoch 18/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.12307, wmdcmp 0.27215, report_loss 2.03745, 188.91 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18118, cD 0.64869, 22.71 secs\n",
      "\u001b[1m---- Epoch 19/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 2.02715, wmdcmp 0.27605, report_loss 2.01619, 190.28 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.17684, cD 0.64271, 20.96 secs\n",
      "\u001b[1m---- Epoch 20/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 2.15967, wmdcmp 0.27696, report_loss 2.00524, 189.38 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.17785, cD 0.64346, 20.66 secs\n",
      "\u001b[1m---- Epoch 21/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 2.14249, wmdcmp 0.27809, report_loss 1.99942, 183.50 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18180, cD 0.68601, 19.78 secs\n",
      "\u001b[1m---- Epoch 22/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.91662, wmdcmp 0.27895, report_loss 1.99383, 197.32 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.17935, cD 0.67695, 19.16 secs\n",
      "\u001b[1m---- Epoch 23/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.86857, wmdcmp 0.27858, report_loss 1.98815, 196.23 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.17960, cD 0.67871, 21.14 secs\n",
      "\u001b[1m---- Epoch 24/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 2.12715, wmdcmp 0.27540, report_loss 2.00766, 198.73 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.17157, cD 0.63918, 21.08 secs\n",
      "\u001b[1m---- Epoch 25/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 2.19861, wmdcmp 0.28574, report_loss 1.94350, 200.31 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.17425, cD 0.66286, 21.24 secs\n",
      "\u001b[1m---- Epoch 26/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.95066, wmdcmp 0.29282, report_loss 1.90726, 202.01 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18093, cD 0.70444, 24.06 secs\n",
      "\u001b[1m---- Epoch 27/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.94198, wmdcmp 0.29540, report_loss 1.89038, 205.84 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18949, cD 0.73072, 20.38 secs\n",
      "\u001b[1m---- Epoch 28/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.80885, wmdcmp 0.29660, report_loss 1.87996, 201.23 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmdcmp 0.18490, cD 0.72172, 20.31 secs\n",
      "\u001b[1m---- Epoch 29/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.57525, wmdcmp 0.29823, report_loss 1.87199, 179.29 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18352, cD 0.71862, 17.38 secs\n",
      "\u001b[1m---- Epoch 30/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.51897, wmdcmp 0.29895, report_loss 1.86571, 130.92 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18426, cD 0.71404, 15.44 secs\n",
      "\u001b[1m---- Epoch 31/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 2.06841, wmdcmp 0.29956, report_loss 1.86611, 127.26 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18406, cD 0.71062, 20.06 secs\n",
      "\u001b[1m---- Epoch 32/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.81469, wmdcmp 0.29074, report_loss 1.89971, 130.69 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18634, cD 0.72974, 15.15 secs\n",
      "\u001b[1m---- Epoch 33/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 1.93358, wmdcmp 0.30201, report_loss 1.84767, 128.33 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18464, cD 0.73348, 15.21 secs\n",
      "\u001b[1m---- Epoch 34/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.67483, wmdcmp 0.30771, report_loss 1.81382, 127.60 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18694, cD 0.76302, 14.65 secs\n",
      "\u001b[1m---- Epoch 35/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.64586, wmdcmp 0.30990, report_loss 1.79653, 130.06 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19554, cD 0.80460, 14.82 secs\n",
      "\u001b[1m---- Epoch 36/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.82438, wmdcmp 0.31147, report_loss 1.78583, 127.91 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19039, cD 0.78109, 16.49 secs\n",
      "\u001b[1m---- Epoch 37/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.99170, wmdcmp 0.31130, report_loss 1.78708, 129.69 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19154, cD 0.79790, 15.35 secs\n",
      "\u001b[1m---- Epoch 38/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.85027, wmdcmp 0.31252, report_loss 1.78603, 128.97 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19064, cD 0.78429, 15.59 secs\n",
      "\u001b[1m---- Epoch 39/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.55200, wmdcmp 0.31307, report_loss 1.77657, 127.83 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19265, cD 0.78805, 15.51 secs\n",
      "\u001b[1m---- Epoch 40/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.99380, wmdcmp 0.30463, report_loss 1.81685, 130.22 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19162, cD 0.73798, 16.69 secs\n",
      "\u001b[1m---- Epoch 41/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 1.83226, wmdcmp 0.31254, report_loss 1.77478, 127.87 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19411, cD 0.81437, 15.28 secs\n",
      "\u001b[1m---- Epoch 42/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 2.00107, wmdcmp 0.31880, report_loss 1.74379, 129.47 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19440, cD 0.81410, 15.49 secs\n",
      "\u001b[1m---- Epoch 43/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.71054, wmdcmp 0.32103, report_loss 1.73535, 130.86 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19161, cD 0.78300, 16.53 secs\n",
      "\u001b[1m---- Epoch 44/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.85582, wmdcmp 0.32246, report_loss 1.72277, 128.59 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19879, cD 0.81085, 15.18 secs\n",
      "\u001b[1m---- Epoch 45/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.89806, wmdcmp 0.32342, report_loss 1.71849, 129.72 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20301, cD 0.83777, 15.87 secs\n",
      "\u001b[1m---- Epoch 46/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.60422, wmdcmp 0.32477, report_loss 1.71059, 130.87 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19405, cD 0.79717, 15.41 secs\n",
      "\u001b[1m---- Epoch 47/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.90145, wmdcmp 0.32505, report_loss 1.70969, 129.14 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19435, cD 0.79335, 15.70 secs\n",
      "\u001b[1m---- Epoch 48/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.60250, wmdcmp 0.31567, report_loss 1.74632, 130.12 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18602, cD 0.74612, 17.31 secs\n",
      "\u001b[1m---- Epoch 49/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 1.68490, wmdcmp 0.32197, report_loss 1.71966, 129.45 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19613, cD 0.81890, 15.61 secs\n",
      "\u001b[1m---- Epoch 50/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.76687, wmdcmp 0.32982, report_loss 1.68190, 130.30 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20176, cD 0.83623, 15.88 secs\n",
      "\u001b[1m---- Epoch 51/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.73795, wmdcmp 0.33341, report_loss 1.66740, 128.68 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19925, cD 0.82692, 15.30 secs\n",
      "\u001b[1m---- Epoch 52/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.49413, wmdcmp 0.33388, report_loss 1.66094, 129.89 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20094, cD 0.85013, 15.16 secs\n",
      "\u001b[1m---- Epoch 53/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.76510, wmdcmp 0.33373, report_loss 1.65916, 130.91 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19566, cD 0.81743, 17.22 secs\n",
      "\u001b[1m---- Epoch 54/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.62471, wmdcmp 0.33519, report_loss 1.65599, 132.06 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19701, cD 0.82468, 15.75 secs\n",
      "\u001b[1m---- Epoch 55/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.51744, wmdcmp 0.33462, report_loss 1.65440, 130.94 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20186, cD 0.84083, 16.04 secs\n",
      "\u001b[1m---- Epoch 56/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.60555, wmdcmp 0.32516, report_loss 1.69637, 128.65 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19208, cD 0.79102, 14.92 secs\n",
      "\u001b[1m---- Epoch 57/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 1.88400, wmdcmp 0.33158, report_loss 1.66590, 129.41 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19691, cD 0.80186, 15.58 secs\n",
      "\u001b[1m---- Epoch 58/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.75837, wmdcmp 0.33881, report_loss 1.63460, 129.08 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19544, cD 0.81391, 15.60 secs\n",
      "\u001b[1m---- Epoch 59/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.66561, wmdcmp 0.34081, report_loss 1.62529, 130.94 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20181, cD 0.83803, 16.18 secs\n",
      "\u001b[1m---- Epoch 60/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.50189, wmdcmp 0.34174, report_loss 1.61741, 130.19 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19961, cD 0.86809, 17.71 secs\n",
      "\u001b[1m---- Epoch 61/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.72801, wmdcmp 0.34391, report_loss 1.60697, 129.14 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19819, cD 0.85930, 15.20 secs\n",
      "\u001b[1m---- Epoch 62/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.70808, wmdcmp 0.34512, report_loss 1.60532, 130.99 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19828, cD 0.84775, 17.09 secs\n",
      "\u001b[1m---- Epoch 63/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.62734, wmdcmp 0.34432, report_loss 1.60613, 129.05 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19844, cD 0.84881, 15.39 secs\n",
      "\u001b[1m---- Epoch 64/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.59434, wmdcmp 0.33350, report_loss 1.65009, 129.86 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19217, cD 0.76947, 15.11 secs\n",
      "\u001b[1m---- Epoch 65/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 1.61779, wmdcmp 0.33965, report_loss 1.62328, 128.67 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20990, cD 0.93324, 17.35 secs\n",
      "\u001b[1m---- Epoch 66/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.41890, wmdcmp 0.34510, report_loss 1.59557, 130.51 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20338, cD 0.84070, 14.90 secs\n",
      "\u001b[1m---- Epoch 67/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 0.85560, wmdcmp 0.35059, report_loss 1.57473, 130.25 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20390, cD 0.84391, 15.61 secs\n",
      "\u001b[1m---- Epoch 68/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.71715, wmdcmp 0.35036, report_loss 1.57350, 127.09 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19988, cD 0.82226, 15.20 secs\n",
      "\u001b[1m---- Epoch 69/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.28045, wmdcmp 0.35236, report_loss 1.56370, 126.70 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20482, cD 0.84763, 15.22 secs\n",
      "\u001b[1m---- Epoch 70/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.67227, wmdcmp 0.35284, report_loss 1.55974, 125.23 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20497, cD 0.84478, 15.19 secs\n",
      "\u001b[1m---- Epoch 71/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.47168, wmdcmp 0.35348, report_loss 1.55761, 125.54 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmdcmp 0.20023, cD 0.82788, 15.04 secs\n",
      "\u001b[1m---- Epoch 72/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.51665, wmdcmp 0.33991, report_loss 1.61227, 128.11 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.18836, cD 0.76942, 17.61 secs\n",
      "\u001b[1m---- Epoch 73/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 1.57316, wmdcmp 0.34751, report_loss 1.58036, 127.82 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19437, cD 0.80351, 15.58 secs\n",
      "\u001b[1m---- Epoch 74/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.68565, wmdcmp 0.35323, report_loss 1.56072, 129.01 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20254, cD 0.83067, 15.79 secs\n",
      "\u001b[1m---- Epoch 75/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 1.57669, wmdcmp 0.35720, report_loss 1.53834, 129.74 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20150, cD 0.85234, 17.08 secs\n",
      "\u001b[1m---- Epoch 76/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.44953, wmdcmp 0.35886, report_loss 1.53087, 129.70 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20461, cD 0.87043, 15.30 secs\n",
      "\u001b[1m---- Epoch 77/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 1.51166, wmdcmp 0.35976, report_loss 1.52473, 129.34 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20244, cD 0.84875, 15.44 secs\n",
      "\u001b[1m---- Epoch 78/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.52331, wmdcmp 0.36068, report_loss 1.52708, 129.14 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20508, cD 0.86782, 15.30 secs\n",
      "\u001b[1m---- Epoch 79/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.68770, wmdcmp 0.36103, report_loss 1.52699, 129.92 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.20280, cD 0.86769, 17.78 secs\n",
      "\u001b[1m---- Epoch 80/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 1.46864, wmdcmp 0.34589, report_loss 1.58083, 131.94 secs\n",
      "(2) Validation stage ...\n",
      "wmdcmp 0.19524, cD 0.77469, 15.55 secs\n",
      "\u001b[1m---- Epoch 81/159\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "^C iteration 24200\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_labels2report.py\", line 1019, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_labels2report.py\", line 911, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_labels2report.py\", line 663, in train_model\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1069, in _run_once_on_dataset_as_gen\n",
      "    self._fire_event(Events.ITERATION_COMPLETED)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 425, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/dataset_aware_metric.py\", line 30, in iteration_completed_handler\n",
      "    self.update(self.output_transform(output))\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/medical/med_completeness/__init__.py\", line 281, in update\n",
      "    score = self.score(gt_s, pred_s)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/medical/med_completeness/__init__.py\", line 191, in score\n",
      "    gt_tot_weights[k] += self.ids2weight[k].get(key, 0)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!/home/pamessina/venv2/bin/python ../train_labels2report.py \\\n",
    "    --epochs 159 \\\n",
    "    --batches-per-epoch 300 \\\n",
    "    --batch-size 200 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 2 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-decay-and-cyclic-decay-args \"1e-6,6,3e-4,8,3e-6,3e-4,8,3e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "    --mimiccxr-balanced-sampling-mode \"balanced_chest_imagenome_global_labels_batchwise\" \\\n",
    "    --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "    --use-chest-imagenome \\\n",
    "    --chest-imagenome-label-names-filename \"labels(min_freq=100).pkl\" \\\n",
    "    --chest-imagenome-labels-filename \"imageId2labels(min_freq=100).pkl\" \\\n",
    "    --use-medical-tokenization \\\n",
    "    --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "    --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "    --labels-hidden-dim 1024 \\\n",
    "    --embedding-dim 512 \\\n",
    "    --transf-dec-num-memory-vecs 10 \\\n",
    "    --transf-dec-hidden-dim 512 \\\n",
    "    --transf-dec-nhead 4 \\\n",
    "    --transf-dec-dim-forward 512 \\\n",
    "    --transf-dec-num-layers 3 \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
