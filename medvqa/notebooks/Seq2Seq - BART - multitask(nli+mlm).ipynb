{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 600\n",
      "   batch_size: 10\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: facebook/bart-base\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_175612_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: multitask\n",
      "   experiment_name: nli+mlm\n",
      "   multitask_name_list: ['nli', 'mlm', 'sentence2facts']\n",
      "   task2weight: {'nli': 2.0, 'mlm': 1.0, 'sentence2facts': 0.0}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl']\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl']\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl']\n",
      "   integrated_nli_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\n",
      "   integrated_report_facts_metadata_jsonl_filepath: None\n",
      "   use_sentence2facts_for_nli: True\n",
      "   use_anli: True\n",
      "   use_multinli: True\n",
      "   use_snli: True\n",
      "   use_report_nli: True\n",
      "   use_fact_based_reports_in_mlm: False\n",
      "   only_validate_nli: True\n",
      "   nli1_only_on_train: True\n",
      "   nli1_only_on_val: True\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9891 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mB\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mbilateral\u001b[0m\n",
      "\u001b[1m\u001b[35mboth sides\u001b[0m\n",
      "\u001b[1m\u001b[35mboth\u001b[0m\n",
      "\u001b[1m\u001b[35mon both sides\u001b[0m\n",
      "\u001b[1m\u001b[35msymmetrical\u001b[0m\n",
      "\u001b[1m\u001b[35mequally on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mpresent on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mseen on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35moccurring on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mappearing on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mfound on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mseen bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mobserved bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mdetected bilaterally\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9890 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilus\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the hilum on the left side\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 8511 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary vasculature\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral lung vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary blood vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mlung periphery vasculature\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature of the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels in the outer regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular network in the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary circulation\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels supplying the outer areas of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature in the peripheral regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular system in the outer regions of the lung\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "\u001b[1mLoaded 1864 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35ma\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mone\u001b[0m\n",
      "\u001b[1m\u001b[35msingle\u001b[0m\n",
      "\u001b[1m\u001b[35msole\u001b[0m\n",
      "\u001b[1m\u001b[35monly\u001b[0m\n",
      "\u001b[1m\u001b[35mindividual\u001b[0m\n",
      "\u001b[1m\u001b[35mlone\u001b[0m\n",
      "\u001b[1m\u001b[35msolitary\u001b[0m\n",
      "\u001b[1m\u001b[35munique\u001b[0m\n",
      "\u001b[1m\u001b[35mdistinct\u001b[0m\n",
      "\u001b[1m\u001b[35msingular\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14993 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14971 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14972 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14965 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 10000 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9999 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9997 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9994 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9996 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome not detected\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome is not observed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant constriction\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of notable narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of substantial narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mlack of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of notable constriction\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19943 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of wheezing\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing detected\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing observed\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing present\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing found\u001b[0m\n",
      "--------\n",
      "\u001b[1mNumber of unique inputs: 190085\u001b[0m\n",
      "\u001b[1mNumber of total paraphrases: 2093173\u001b[0m\n",
      "Number of medical sentences from paraphrases: 2039914\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing sentence2facts dataset\u001b[0m\n",
      "Loaded 9999 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19971 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\n",
      "Loaded 19984 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\n",
      "Loaded 5000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\n",
      "Loaded 14990 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\n",
      "Loaded 14991 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\n",
      "\u001b[1mInput/output example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mS2F: Background right middle and lower lobe airspace opacification with an associated effusion unchanged.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m[\"background right middle lobe airspace opacification\", \"background right lower lobe airspace opacification\", \"associated effusion unchanged\"]\u001b[0m\n",
      "Number of train examples: 84935\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing nli dataset\u001b[0m\n",
      "----\n",
      "Loading integrated NLI from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl...\n",
      "Number of samples: 169025\n",
      "Number of sources: 7\n",
      "----\n",
      "\u001b[1mLoading sentence2facts input/output pairs for NLI...\u001b[0m\n",
      "Number of entailment samples added: 184483\n",
      "----\n",
      "\u001b[1mLoading general domain datasets...\u001b[0m\n",
      "Loading ANLI...\n",
      "Number of ANLI R1 samples: 18946\n",
      "Number of ANLI R2 samples: 47460\n",
      "Number of ANLI R3 samples: 102859\n",
      "Loading MultiNLI...\n",
      "Number of MultiNLI train samples: 392702\n",
      "Number of MultiNLI dev_matched samples: 10000\n",
      "Number of MultiNLI dev_mismatched samples: 10000\n",
      "Loading SNLI...\n",
      "Number of SNLI train samples: 550152\n",
      "Number of SNLI dev samples: 10000\n",
      "Number of SNLI test samples: 10000\n",
      "----\n",
      "\u001b[1mLoading report NLI datasets...\u001b[0m\n",
      "Loaded 54076 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\n",
      "Loaded 40000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\n",
      "----\n",
      "\u001b[1mBuilding train NLI dataset...\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: contradiction -> 79430 (4312.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A curvilinear opacity paralleling the lower edge of the 2nd rib corresponds to a skinfold. #H: The curvilinear opacity is not associated with the lower edge of the 2nd rib.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: contradiction -> 10732 (2400.52)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Left lower lobe atelectasis has increased. #H: The left lung appears relatively clear.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: contradiction -> 4170 (1739.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Lung volumes are low, worsened since . #H: In comparison with the study of , there are mildly improved lung volumes.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: contradiction -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She saw her PCP and was started on mucinex and robitussin. #H:  Patient has no complaints\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: contradiction -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Covered broadly with Vanco 1gm and Levofloxacin 750mg. #H:  Antibiotic therapy is not indicated\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: contradiction -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: He had no EKG changes and first set of enzymes were negative. #H:  the patient denies chest pain\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: contradiction -> 106 (304.54)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are probable bilateral pleural effusions, right greater left along with right-sided atelectasis. #H: No pleural abnormality is seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: anli | Label: contradiction -> 44089 (3672.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A Daughter of the Wolf is a 1919 American silent drama film directed by Irvin Willat and written by Marion Fairfax and Hugh Pendexter. The film stars Lila Lee, Elliott Dexter, Clarence Geldart, Raymond Hatton, Richard Wayne, and Minnie Devereaux. The film was released on June 22, 1919, by Paramount Pictures. #H: The film was directed by Fairfax and Pendexter.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: contradiction -> 137356 (4971.81)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Can't say as how I'd like to find out the truth. #H: I can say that I'd like to stay in the dark about this.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: snli | Label: contradiction -> 189702 (5390.10)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Man working behind a hotdog stand. #H: The man is surfing.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: contradiction -> 17038 (2777.34)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: single frontal view of the chest. pneumomediastinum remains evident. pneumomediastinum slightly smaller than on the prior exam. stable heart size. stable mediastinal contours. adjacent bibasilar opacities. persistent left lower lobe collapse. no pneumothorax. stable tracheostomy. stable PEG tube. small amount of pneumomediastinum. slightly improved pneumomediastinum. improved small bilateral pleural effusions #H: slightly larger pneumomediastinum today\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: entailment -> 13185 (2563.82)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Right lower lung atelectasis/scarring is seen. #H: There is evidence of damage in the right lower lung.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: entailment -> 5445 (1911.57)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are again seen diffuse opacities bilaterally. #H: There are a extensive bilateral diffuse opacities.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: entailment -> 1770 (1256.05)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiomediastinal and hilar contours within normal limits. #H: Cardiac mediastinal and hilar contours are within normal limits.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: entailment -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The amniotic fluid was clear. #H:  the amiotic fluid was clear\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: entailment -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She notes some swelling throughout but denies joint swelling or redness. #H:  Denies joint effusion\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: entailment -> 473 (701.58)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Vitals on floor prior to transfer to MICU were as follows:  BP 130/70   HR 90 at rest in bed (120s-160s when standing). . #H:  Vital signs were taken before transfer to the ICU\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: entailment -> 93 (279.62)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The mediastinal and hilar contours are unremarkable. #H: Mediastinal silhouette and hilar contours are normal.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: s2f | Label: entailment -> 184483 (5353.06)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Heart size is normal/slightly enlarged. #H: slightly enlarged heart\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: anli | Label: entailment -> 54251 (3890.16)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: All genetically modified food, including soya or maize oil produced from GM soya and maize, and food ingredients, must be labelled. #H: Genetically modified food made from GM soya must be labelled\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSource: multinli | Label: entailment -> 137841 (4976.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Even now our miners work for only five years and are paid the rest of their lives for it. #H: Our miners only work for give years.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: snli | Label: entailment -> 190113 (5392.98)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A group of young ballerinas are in a dance studio. #H: A group is in a dance studio.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: entailment -> 57161 (3946.37)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: comparison with chest radiographs at 12:02. substantially more distended mediastinal veins. increased central venous pressure. increased central venous volume. moderate cardiomegaly. moderate left pleural effusion. enlarged left pleural effusion. right basal atelectasis relatively mild. clear right lung. no pneumothorax. no pulmonary edema #H: minor right basilar linear atelectasis\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: neutral -> 19123 (2877.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Right infusion port terminates at the upper SVC. #H: The left lung appears clear.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: neutral -> 16675 (2758.96)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Lungs are essentially clear . #H: The lungs are essentially clear without focal consolidation.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: neutral -> 3968 (1708.29)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Median sternotomy wires are intact and unchanged compared to the most recent post operative film. #H: The mediastinal and hilar contours are within normal limits and unchanged allowing for positional differences from the prior study of .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: neutral -> 3743 (1672.44)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She is s/p 2 L NS with vitals remaining stable. #H:  the patient was hypotensive\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: neutral -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She also notes that her LE may be slightly swollen as compared to baseline; she does not believe she has had significant weight gain. #H:  She has a history of blood clots in the leg\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: neutral -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: PAST MEDICAL HISTORY:  Patient has a past medical history of papillary thyroid cancer, status post thyroidectomy, increased cholesterol, hypertension, former tobacco user, type 2 diabetes and sarcoid. #H:  The patient has coronary artery disease.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: neutral -> 281 (538.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Left pleural pigtail catheter has been removed. #H: The bilateral pleural effusions have decreased in size.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: anli | Label: neutral -> 70925 (4184.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The 2010 Duke Blue Devils football team represented Duke University in the 2010 NCAA Division I FBS football season. The Blue Devils were led by 3rd year head coach David Cutcliffe and played their home games at Wallace Wade Stadium. They are members of the Atlantic Coast Conference in the Coastal Division. They finished the season 3–9, 1–7 in ACC play. #H: The 2010 Duke Blue Devils were very impressive\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: neutral -> 137152 (4969.93)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Other new requirements address redistricting, cases involving eviction from public housing of individuals charged with or convicted of drug violations and participation in government rulemaking and solicitation. #H: They wanted to reduce the number of drug related charges.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: snli | Label: neutral -> 189218 (5386.70)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A young female african american child sitting on a swing with both arms holding the chains on the swing. #H: A young child is sitting on a swinging waiting for someone to push her.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli | Label: neutral -> 19877 (2911.23)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: frontal view of the chest obtained. lateral view of the chest obtained. no focal consolidation. no pleural effusion. no evidence of pneumothorax. stable cardiac silhouette. stable mediastinal silhouette. stable hilar contours. minimal left apical pleural thickening is stable. no acute cardiopulmonary process #H: pleuroparenchymal scarring in right lung\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "----\n",
      "Number of RadNLI test samples: 480\n",
      "Number of MS_CXR_T samples: 361\n",
      "Number of report NLI samples added to val: 300\n",
      "Number of val NLI samples: 1141\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The mediastinal silhouette, hilar contours, and pleural surfaces are normal. #H: The hilar and mediastinal silhouettes are unremarkable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: PM endotracheal tube terminates at the carinal. PM endotracheal tube possibly terminates at the proximal right mainstem bronchus. PM endotracheal tube must be pulled back. no significant interval change in the atelectatic right lung. small bilateral pleural effusions. no pneumothorax. rotated positioning. ET tube present. ET tube tip lies approximately 4.4 mm above the carina. retraction should be considered. NG tube present. NG tube tip extending beneath diaphragm off film. right-sided PIC line overlies the proximal most SVC. moderate-sized right effusion. partial opacification of the lower half of the right hemithorax. moderate-sized effusion in the lower half of the right hemithorax. underlying collapse in the lower half of the right hemithorax. underlying consolidation in the lower half of the right hemithorax. faint opacity at the left base. layering effusion at the left base. upper zone redistribution. diffuse vascular plethora. scattered vascular calcifications. improved degree of opacification at the right base #H: change in tube position\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: the right basal consolidation is unchanged. #H: the right basal consolidation is improved.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are small bilateral pleural effusions. #H: No pleural effusion or pneumothorax is seen.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The lungs are clear without pulmonary edema, consolidation, or pneumothorax. #H: No focal consolidation, pleural effusion or pneumothorax is present.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "----\n",
      "\u001b[1mBuilding val NLI dataset...\u001b[0m\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing mlm dataset\u001b[0m\n",
      "Number of general sentences: 1377099\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 1377099\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 1377099/1377099 [00:11<00:00, 124358.42it/s]\n",
      "\tlen(valid_tokens): 21522\n",
      "100%|██████████████████████████████| 1377099/1377099 [00:23<00:00, 57904.67it/s]\n",
      "Number of sentences: 1348333\n",
      "Number of bins: 7\n",
      "Bin size: 958219, weight: 7845.006940358202\n",
      "Bin size: 219530, weight: 5586.745498624757\n",
      "Bin size: 110971, weight: 4707.694773844805\n",
      "Bin size: 46036, weight: 3717.013976819967\n",
      "Bin size: 8332, weight: 2209.4180153128023\n",
      "Bin size: 4974, weight: 1851.8906668241702\n",
      "Bin size: 271, weight: 527.9351334797618\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The food is [tok1] , but the it is [tok2] in the Argentinian style and the staff is entertaining .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] mediocre [tok2] cooked\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: A young [tok1] starves .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] man\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Dick Brownell is the librarian for the [tok1] library and has been for several years now .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] public\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: A man and his [tok1] wife dance at their wedding\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] new\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of medical sentences: 2433379\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 2433379\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 2433379/2433379 [00:16<00:00, 144639.61it/s]\n",
      "\tlen(valid_tokens): 8229\n",
      "100%|██████████████████████████████| 2433379/2433379 [00:34<00:00, 70836.49it/s]\n",
      "Number of sentences: 2407333\n",
      "Number of bins: 10\n",
      "Bin size: 1149797, weight: 8160.600145146373\n",
      "Bin size: 457446, weight: 6648.110068031499\n",
      "Bin size: 448026, weight: 6616.320159634762\n",
      "Bin size: 254262, weight: 5789.294227373633\n",
      "Bin size: 79396, weight: 4312.264358335991\n",
      "Bin size: 14735, weight: 2654.9922656465883\n",
      "Bin size: 3106, weight: 1561.2359694151141\n",
      "Bin size: 276, weight: 533.1206352397179\n",
      "Bin size: 162, weight: 395.4226609416602\n",
      "Bin size: 127, weight: 341.33933626931963\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: There is no [tok1] of the right lung .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] consolidation\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: A new [tok1] fracture is observed in the upper lumbar vertebrae when compared to the previous [tok2] X-ray\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] compression [tok2] chest\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: right anteromedial [tok1]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] quadrant\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The lung [tok1] has not been fully rectified\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] collapse\u001b[0m\n",
      "----------------------------------------\n",
      "Number of train datasets: 3\n",
      "Number of val datasets: 1\n",
      "\u001b[93m\u001b[1mWARNING: CompositeInfiniteDataset(): Removed 1 datasets with zero weight\u001b[0m\n",
      "----------------------------------------\n",
      "Examples of val datasets:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The lungs are clear without pulmonary edema, consolidation, or pneumothorax. #H: No focal consolidation, pleural effusion or pneumothorax is present.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is a large right-sided pneumothorax which has developed since the previous study. #H: As compared to the previous radiograph, the patient has developed a large right-sided pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Cardiomediastinal silhouette and hilar contours are normal. #H: The cardiac and mediastinal silhouettes are unremarkable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are low lung volumes and some tortuosity of the aorta. #H: There is volume loss of the left upper lung.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "seq2seq_trainer.name =  multitask(nli+mlm)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_182751_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_182751_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_7_exact_match+s2s_loss=0.6386.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_175612_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/checkpoint_7_exact_match+s2s_loss=0.6386.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_182751_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70862, s2s_loss 0.55196, 58.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24644, exact_match 0.45662, 3.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_exact_match+s2s_loss=0.6309.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.75209, s2s_loss 0.55768, 55.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24434, exact_match 0.47152, 4.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_exact_match+s2s_loss=0.6380.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.45383, s2s_loss 0.54035, 57.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.24040, exact_match 0.47677, 3.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_exact_match+s2s_loss=0.6423.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.84287, s2s_loss 0.52393, 55.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.23195, exact_match 0.47677, 4.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_exact_match+s2s_loss=0.6454.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 0.28418, s2s_loss 0.48948, 57.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.22455, exact_match 0.54777, 3.51 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_exact_match+s2s_loss=0.6811.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.42596, s2s_loss 0.46894, 56.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21580, exact_match 0.56442, 3.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_exact_match+s2s_loss=0.6922.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.86576, s2s_loss 0.45553, 55.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21016, exact_match 0.57493, 3.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_exact_match+s2s_loss=0.6993.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.16572, s2s_loss 0.45809, 55.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21266, exact_match 0.55565, 3.72 secs\n",
      "\u001b[1m---- Epoch 9/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.40278, s2s_loss 0.44984, 56.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.21181, exact_match 0.56354, 3.97 secs\n",
      "\u001b[1m---- Epoch 10/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.43248, s2s_loss 0.44436, 57.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20903, exact_match 0.57581, 4.04 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_10_exact_match+s2s_loss=0.7005.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 11/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.38465, s2s_loss 0.43988, 58.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20855, exact_match 0.57493, 3.58 secs\n",
      "\u001b[1m---- Epoch 12/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.18972, s2s_loss 0.44177, 57.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20885, exact_match 0.56354, 3.84 secs\n",
      "\u001b[1m---- Epoch 13/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.51542, s2s_loss 0.45180, 56.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.22571, exact_match 0.56091, 3.82 secs\n",
      "\u001b[1m---- Epoch 14/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.47008, s2s_loss 0.43918, 55.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19814, exact_match 0.62226, 3.77 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_exact_match+s2s_loss=0.7251.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.36399, s2s_loss 0.42517, 58.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19527, exact_match 0.61437, 3.84 secs\n",
      "\u001b[1m---- Epoch 16/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.58611, s2s_loss 0.42032, 58.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18900, exact_match 0.63891, 3.88 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_16_exact_match+s2s_loss=0.7364.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 17/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.49574, s2s_loss 0.40738, 58.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18498, exact_match 0.64330, 3.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_exact_match+s2s_loss=0.7403.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.32305, s2s_loss 0.41642, 56.70 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.18684, exact_match 0.65557, 3.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_exact_match+s2s_loss=0.7448.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.27197, s2s_loss 0.41615, 57.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18680, exact_match 0.65469, 3.69 secs\n",
      "\u001b[1m---- Epoch 20/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.43161, s2s_loss 0.41253, 57.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18433, exact_match 0.65644, 3.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_exact_match+s2s_loss=0.7462.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.61808, s2s_loss 0.42224, 56.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.20046, exact_match 0.67222, 4.23 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_exact_match+s2s_loss=0.7477.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.36036, s2s_loss 0.41588, 57.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17551, exact_match 0.70903, 3.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_exact_match+s2s_loss=0.7725.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.35397, s2s_loss 0.38235, 56.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.18228, exact_match 0.70727, 3.77 secs\n",
      "\u001b[1m---- Epoch 24/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.44938, s2s_loss 0.39011, 58.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16961, exact_match 0.72918, 3.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_exact_match+s2s_loss=0.7848.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.48771, s2s_loss 0.39620, 57.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16744, exact_match 0.72480, 3.87 secs\n",
      "\u001b[1m---- Epoch 26/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.29989, s2s_loss 0.38321, 58.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17171, exact_match 0.72656, 3.60 secs\n",
      "\u001b[1m---- Epoch 27/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21846, s2s_loss 0.38410, 57.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17240, exact_match 0.73006, 3.66 secs\n",
      "\u001b[1m---- Epoch 28/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28201, s2s_loss 0.38068, 54.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17215, exact_match 0.73094, 3.50 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_exact_match+s2s_loss=0.7853.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.22118, s2s_loss 0.39294, 56.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17684, exact_match 0.71078, 3.84 secs\n",
      "\u001b[1m---- Epoch 30/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.23813, s2s_loss 0.38528, 59.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17341, exact_match 0.74584, 3.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_30_exact_match+s2s_loss=0.7913.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 31/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.28533, s2s_loss 0.38119, 56.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17194, exact_match 0.75022, 4.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_31_exact_match+s2s_loss=0.7940.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 32/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.57773, s2s_loss 0.38200, 58.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16198, exact_match 0.76424, 3.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_exact_match+s2s_loss=0.8035.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.52201, s2s_loss 0.37354, 58.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16781, exact_match 0.75372, 3.98 secs\n",
      "\u001b[1m---- Epoch 34/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.46402, s2s_loss 0.36985, 56.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16875, exact_match 0.75197, 3.46 secs\n",
      "\u001b[1m---- Epoch 35/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20427, s2s_loss 0.36715, 56.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16384, exact_match 0.76074, 3.50 secs\n",
      "\u001b[1m---- Epoch 36/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.57130, s2s_loss 0.35985, 59.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16493, exact_match 0.75898, 3.66 secs\n",
      "\u001b[1m---- Epoch 37/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.28261, s2s_loss 0.38647, 55.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.19284, exact_match 0.68712, 3.82 secs\n",
      "\u001b[1m---- Epoch 38/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.45708, s2s_loss 0.38670, 56.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.16660, exact_match 0.73707, 3.85 secs\n",
      "\u001b[1m---- Epoch 39/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.33035, s2s_loss 0.35854, 55.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14978, exact_match 0.76512, 3.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_exact_match+s2s_loss=0.8093.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.30955, s2s_loss 0.36699, 55.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15822, exact_match 0.75723, 3.96 secs\n",
      "\u001b[1m---- Epoch 41/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.30572, s2s_loss 0.36215, 57.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15147, exact_match 0.76424, 3.85 secs\n",
      "\u001b[1m---- Epoch 42/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.29238, s2s_loss 0.36024, 55.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15146, exact_match 0.75811, 4.09 secs\n",
      "\u001b[1m---- Epoch 43/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.76525, s2s_loss 0.35730, 58.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15230, exact_match 0.75898, 3.95 secs\n",
      "\u001b[1m---- Epoch 44/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.37920, s2s_loss 0.36172, 56.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15128, exact_match 0.76337, 3.50 secs\n",
      "\u001b[1m---- Epoch 45/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.20352, s2s_loss 0.35853, 56.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17304, exact_match 0.74321, 3.65 secs\n",
      "\u001b[1m---- Epoch 46/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.46415, s2s_loss 0.36179, 57.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13683, exact_match 0.78089, 3.93 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_46_exact_match+s2s_loss=0.8207.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 47/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.30287, s2s_loss 0.35666, 57.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15184, exact_match 0.77213, 3.96 secs\n",
      "\u001b[1m---- Epoch 48/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.57958, s2s_loss 0.35699, 59.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13814, exact_match 0.79053, 3.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_48_exact_match+s2s_loss=0.8248.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 49/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.31964, s2s_loss 0.34779, 60.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14477, exact_match 0.77739, 3.79 secs\n",
      "\u001b[1m---- Epoch 50/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.24146, s2s_loss 0.35219, 57.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14713, exact_match 0.77826, 3.96 secs\n",
      "\u001b[1m---- Epoch 51/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39923, s2s_loss 0.34814, 56.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14373, exact_match 0.78089, 3.71 secs\n",
      "\u001b[1m---- Epoch 52/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24419, s2s_loss 0.34315, 57.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14497, exact_match 0.78177, 3.59 secs\n",
      "\u001b[1m---- Epoch 53/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.18502, s2s_loss 0.35534, 55.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.17182, exact_match 0.74496, 3.61 secs\n",
      "\u001b[1m---- Epoch 54/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.30120, s2s_loss 0.36501, 57.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14799, exact_match 0.77301, 3.80 secs\n",
      "\u001b[1m---- Epoch 55/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18973, s2s_loss 0.34128, 56.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14197, exact_match 0.78791, 3.91 secs\n",
      "\u001b[1m---- Epoch 56/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.28892, s2s_loss 0.34368, 57.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14378, exact_match 0.78528, 3.58 secs\n",
      "\u001b[1m---- Epoch 57/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.30697, s2s_loss 0.33911, 58.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13904, exact_match 0.78878, 3.77 secs\n",
      "\u001b[1m---- Epoch 58/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.39413, s2s_loss 0.34624, 56.87 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.14151, exact_match 0.78177, 3.71 secs\n",
      "\u001b[1m---- Epoch 59/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.06724, s2s_loss 0.33918, 56.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13781, exact_match 0.79404, 3.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_59_exact_match+s2s_loss=0.8275.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 60/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.42391, s2s_loss 0.34636, 59.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13825, exact_match 0.78878, 3.83 secs\n",
      "\u001b[1m---- Epoch 61/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.27619, s2s_loss 0.35398, 56.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13994, exact_match 0.78440, 3.63 secs\n",
      "\u001b[1m---- Epoch 62/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.30685, s2s_loss 0.35467, 57.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.15223, exact_match 0.77826, 3.84 secs\n",
      "\u001b[1m---- Epoch 63/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.24292, s2s_loss 0.34648, 56.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13261, exact_match 0.78966, 3.72 secs\n",
      "\u001b[1m---- Epoch 64/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.23550, s2s_loss 0.33003, 57.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13147, exact_match 0.78703, 3.82 secs\n",
      "\u001b[1m---- Epoch 65/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.45653, s2s_loss 0.33402, 57.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13443, exact_match 0.79492, 3.59 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_65_exact_match+s2s_loss=0.8294.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 66/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.36471, s2s_loss 0.33410, 56.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13410, exact_match 0.79141, 3.54 secs\n",
      "\u001b[1m---- Epoch 67/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.40312, s2s_loss 0.33289, 58.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13594, exact_match 0.78878, 3.65 secs\n",
      "\u001b[1m---- Epoch 68/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.09173, s2s_loss 0.33289, 56.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13581, exact_match 0.79053, 3.45 secs\n",
      "\u001b[1m---- Epoch 69/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.31962, s2s_loss 0.34584, 56.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13858, exact_match 0.78966, 3.86 secs\n",
      "\u001b[1m---- Epoch 70/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.47326, s2s_loss 0.35357, 57.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.14980, exact_match 0.77301, 3.81 secs\n",
      "\u001b[1m---- Epoch 71/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.39094, s2s_loss 0.34376, 57.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12368, exact_match 0.80018, 3.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_71_exact_match+s2s_loss=0.8350.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 72/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.32304, s2s_loss 0.32670, 56.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12737, exact_match 0.79579, 3.92 secs\n",
      "\u001b[1m---- Epoch 73/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.18359, s2s_loss 0.33008, 57.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12273, exact_match 0.79930, 3.79 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_73_exact_match+s2s_loss=0.8357.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 74/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.48221, s2s_loss 0.32762, 58.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12669, exact_match 0.79229, 3.62 secs\n",
      "\u001b[1m---- Epoch 75/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44221, s2s_loss 0.32817, 57.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12575, exact_match 0.79492, 3.82 secs\n",
      "\u001b[1m---- Epoch 76/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.80245, s2s_loss 0.32265, 57.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12794, exact_match 0.79141, 3.59 secs\n",
      "\u001b[1m---- Epoch 77/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.33723, s2s_loss 0.33957, 56.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11430, exact_match 0.81946, 3.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_77_exact_match+s2s_loss=0.8472.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 78/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.29980, s2s_loss 0.34737, 55.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13615, exact_match 0.80719, 3.78 secs\n",
      "\u001b[1m---- Epoch 79/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.30748, s2s_loss 0.32839, 57.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13622, exact_match 0.79930, 3.90 secs\n",
      "\u001b[1m---- Epoch 80/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.39357, s2s_loss 0.32789, 59.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13051, exact_match 0.80105, 3.76 secs\n",
      "\u001b[1m---- Epoch 81/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.59006, s2s_loss 0.33393, 57.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12905, exact_match 0.80280, 4.04 secs\n",
      "\u001b[1m---- Epoch 82/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.37269, s2s_loss 0.32939, 58.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12435, exact_match 0.80894, 3.93 secs\n",
      "\u001b[1m---- Epoch 83/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11388, s2s_loss 0.31791, 57.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12413, exact_match 0.80806, 3.58 secs\n",
      "\u001b[1m---- Epoch 84/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.53580, s2s_loss 0.32815, 57.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12379, exact_match 0.80806, 3.67 secs\n",
      "\u001b[1m---- Epoch 85/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.21750, s2s_loss 0.33164, 55.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.13774, exact_match 0.80368, 3.77 secs\n",
      "\u001b[1m---- Epoch 86/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.44370, s2s_loss 0.34190, 56.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11879, exact_match 0.80894, 3.83 secs\n",
      "\u001b[1m---- Epoch 87/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.33749, s2s_loss 0.32926, 58.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.12182, exact_match 0.80631, 3.61 secs\n",
      "\u001b[1m---- Epoch 88/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.27995, s2s_loss 0.32054, 56.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11863, exact_match 0.81069, 3.71 secs\n",
      "\u001b[1m---- Epoch 89/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.27662, s2s_loss 0.31862, 55.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11431, exact_match 0.81507, 3.90 secs\n",
      "\u001b[1m---- Epoch 90/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.33029, s2s_loss 0.32949, 56.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11205, exact_match 0.81946, 3.79 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_90_exact_match+s2s_loss=0.8486.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 91/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.38116, s2s_loss 0.31828, 56.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11273, exact_match 0.81770, 3.69 secs\n",
      "\u001b[1m---- Epoch 92/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28424, s2s_loss 0.31793, 56.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11229, exact_match 0.81595, 3.79 secs\n",
      "\u001b[1m---- Epoch 93/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.22403, s2s_loss 0.32974, 56.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10471, exact_match 0.83085, 3.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_93_exact_match+s2s_loss=0.8564.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 94/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.39747, s2s_loss 0.32928, 56.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10529, exact_match 0.82822, 3.48 secs\n",
      "\u001b[1m---- Epoch 95/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.33247, s2s_loss 0.32353, 56.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10513, exact_match 0.82559, 3.96 secs\n",
      "\u001b[1m---- Epoch 96/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.36990, s2s_loss 0.32106, 55.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09739, exact_match 0.84224, 3.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_96_exact_match+s2s_loss=0.8648.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 97/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.42113, s2s_loss 0.31628, 55.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10013, exact_match 0.84049, 3.83 secs\n",
      "\u001b[1m---- Epoch 98/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.12228, s2s_loss 0.32404, 57.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10160, exact_match 0.83348, 3.58 secs\n",
      "\u001b[1m---- Epoch 99/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.42765, s2s_loss 0.31939, 56.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10118, exact_match 0.83699, 4.01 secs\n",
      "\u001b[1m---- Epoch 100/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.38447, s2s_loss 0.31879, 56.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10171, exact_match 0.83348, 3.40 secs\n",
      "\u001b[1m---- Epoch 101/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.40394, s2s_loss 0.31728, 57.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10217, exact_match 0.83961, 3.91 secs\n",
      "\u001b[1m---- Epoch 102/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.26531, s2s_loss 0.33084, 55.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09980, exact_match 0.85714, 3.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_102_exact_match+s2s_loss=0.8700.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 103/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.38238, s2s_loss 0.32941, 56.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09333, exact_match 0.85802, 3.83 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_103_exact_match+s2s_loss=0.8729.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 104/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.48712, s2s_loss 0.32210, 56.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10103, exact_match 0.83523, 3.84 secs\n",
      "\u001b[1m---- Epoch 105/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.17075, s2s_loss 0.31462, 56.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10072, exact_match 0.84049, 4.03 secs\n",
      "\u001b[1m---- Epoch 106/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.32558, s2s_loss 0.31155, 57.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10048, exact_match 0.84224, 3.61 secs\n",
      "\u001b[1m---- Epoch 107/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.22308, s2s_loss 0.31158, 55.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10209, exact_match 0.83436, 3.86 secs\n",
      "\u001b[1m---- Epoch 108/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.27601, s2s_loss 0.32002, 55.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09894, exact_match 0.84750, 3.77 secs\n",
      "\u001b[1m---- Epoch 109/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.34608, s2s_loss 0.32841, 56.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11574, exact_match 0.80368, 3.88 secs\n",
      "\u001b[1m---- Epoch 110/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.25907, s2s_loss 0.33027, 58.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10145, exact_match 0.83523, 3.83 secs\n",
      "\u001b[1m---- Epoch 111/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18753, s2s_loss 0.31987, 58.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10653, exact_match 0.83436, 3.84 secs\n",
      "\u001b[1m---- Epoch 112/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.48459, s2s_loss 0.31898, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10253, exact_match 0.83173, 3.89 secs\n",
      "\u001b[1m---- Epoch 113/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22629, s2s_loss 0.30896, 55.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10246, exact_match 0.83436, 3.73 secs\n",
      "\u001b[1m---- Epoch 114/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.37214, s2s_loss 0.30939, 55.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10091, exact_match 0.83348, 3.91 secs\n",
      "\u001b[1m---- Epoch 115/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26888, s2s_loss 0.30796, 56.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10201, exact_match 0.83523, 3.90 secs\n",
      "\u001b[1m---- Epoch 116/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30569, s2s_loss 0.31418, 58.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09985, exact_match 0.83436, 3.63 secs\n",
      "\u001b[1m---- Epoch 117/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.45177, s2s_loss 0.32451, 57.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11020, exact_match 0.82822, 3.67 secs\n",
      "\u001b[1m---- Epoch 118/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.25940, s2s_loss 0.32930, 57.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09512, exact_match 0.85977, 3.42 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_118_exact_match+s2s_loss=0.8730.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 119/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.32556, s2s_loss 0.31453, 54.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09662, exact_match 0.84575, 3.50 secs\n",
      "\u001b[1m---- Epoch 120/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.10957, s2s_loss 0.31518, 57.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09840, exact_match 0.83611, 3.94 secs\n",
      "\u001b[1m---- Epoch 121/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.19041, s2s_loss 0.30862, 56.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09725, exact_match 0.84049, 3.66 secs\n",
      "\u001b[1m---- Epoch 122/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.26397, s2s_loss 0.30689, 56.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09939, exact_match 0.83786, 3.98 secs\n",
      "\u001b[1m---- Epoch 123/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11814, s2s_loss 0.30959, 55.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10070, exact_match 0.83348, 3.64 secs\n",
      "\u001b[1m---- Epoch 124/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.35700, s2s_loss 0.31156, 54.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09868, exact_match 0.83611, 3.66 secs\n",
      "\u001b[1m---- Epoch 125/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.37283, s2s_loss 0.32750, 57.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10454, exact_match 0.83786, 3.73 secs\n",
      "\u001b[1m---- Epoch 126/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.23418, s2s_loss 0.31474, 57.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11490, exact_match 0.83173, 3.57 secs\n",
      "\u001b[1m---- Epoch 127/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.28394, s2s_loss 0.31752, 57.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10269, exact_match 0.83260, 3.45 secs\n",
      "\u001b[1m---- Epoch 128/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.40506, s2s_loss 0.31265, 57.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10124, exact_match 0.83699, 3.90 secs\n",
      "\u001b[1m---- Epoch 129/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.14965, s2s_loss 0.31485, 57.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10130, exact_match 0.83611, 3.65 secs\n",
      "\u001b[1m---- Epoch 130/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.12049, s2s_loss 0.30876, 58.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09725, exact_match 0.84224, 3.88 secs\n",
      "\u001b[1m---- Epoch 131/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.22435, s2s_loss 0.30623, 56.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09837, exact_match 0.83961, 3.78 secs\n",
      "\u001b[1m---- Epoch 132/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.54567, s2s_loss 0.31340, 55.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09676, exact_match 0.84224, 3.95 secs\n",
      "\u001b[1m---- Epoch 133/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.17512, s2s_loss 0.30819, 55.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09647, exact_match 0.85013, 3.88 secs\n",
      "\u001b[1m---- Epoch 134/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.28406, s2s_loss 0.31228, 56.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09551, exact_match 0.84400, 3.74 secs\n",
      "\u001b[1m---- Epoch 135/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.69683, s2s_loss 0.30809, 56.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09781, exact_match 0.84400, 3.72 secs\n",
      "\u001b[1m---- Epoch 136/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.24385, s2s_loss 0.30733, 56.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10229, exact_match 0.83523, 3.76 secs\n",
      "\u001b[1m---- Epoch 137/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.53506, s2s_loss 0.30293, 55.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10002, exact_match 0.83611, 4.01 secs\n",
      "\u001b[1m---- Epoch 138/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.35835, s2s_loss 0.30359, 55.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09815, exact_match 0.84312, 3.76 secs\n",
      "\u001b[1m---- Epoch 139/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21166, s2s_loss 0.30084, 55.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09832, exact_match 0.84137, 3.91 secs\n",
      "\u001b[1m---- Epoch 140/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.22621, s2s_loss 0.30465, 56.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09798, exact_match 0.84049, 3.75 secs\n",
      "\u001b[1m---- Epoch 141/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.29073, s2s_loss 0.30382, 57.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10305, exact_match 0.84926, 3.77 secs\n",
      "\u001b[1m---- Epoch 142/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.29140, s2s_loss 0.31312, 56.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09429, exact_match 0.84838, 3.84 secs\n",
      "\u001b[1m---- Epoch 143/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.48423, s2s_loss 0.31521, 57.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09018, exact_match 0.85188, 3.78 secs\n",
      "\u001b[1m---- Epoch 144/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.14493, s2s_loss 0.30365, 57.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09747, exact_match 0.85013, 3.45 secs\n",
      "\u001b[1m---- Epoch 145/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32867, s2s_loss 0.30361, 54.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09553, exact_match 0.85101, 3.66 secs\n",
      "\u001b[1m---- Epoch 146/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.19538, s2s_loss 0.29937, 55.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09206, exact_match 0.85451, 3.57 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_146_exact_match+s2s_loss=0.8736.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 147/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.19630, s2s_loss 0.29760, 56.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09177, exact_match 0.85627, 3.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_147_exact_match+s2s_loss=0.8746.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 148/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17409, s2s_loss 0.29410, 57.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09136, exact_match 0.85802, 3.45 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_148_exact_match+s2s_loss=0.8757.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 149/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.28519, s2s_loss 0.30832, 53.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09723, exact_match 0.84400, 3.58 secs\n",
      "\u001b[1m---- Epoch 150/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.25635, s2s_loss 0.30114, 55.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09552, exact_match 0.84487, 3.66 secs\n",
      "\u001b[1m---- Epoch 151/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.32489, s2s_loss 0.30763, 56.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09395, exact_match 0.84575, 3.44 secs\n",
      "\u001b[1m---- Epoch 152/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.21518, s2s_loss 0.30572, 55.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09724, exact_match 0.84049, 3.16 secs\n",
      "\u001b[1m---- Epoch 153/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.31383, s2s_loss 0.30068, 53.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09714, exact_match 0.83786, 3.79 secs\n",
      "\u001b[1m---- Epoch 154/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.26591, s2s_loss 0.29251, 55.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09425, exact_match 0.85364, 3.67 secs\n",
      "\u001b[1m---- Epoch 155/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.12993, s2s_loss 0.30244, 54.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09466, exact_match 0.84750, 3.67 secs\n",
      "\u001b[1m---- Epoch 156/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28491, s2s_loss 0.29693, 55.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09612, exact_match 0.84575, 3.48 secs\n",
      "\u001b[1m---- Epoch 157/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.26978, s2s_loss 0.31260, 56.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11022, exact_match 0.82734, 3.48 secs\n",
      "\u001b[1m---- Epoch 158/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.22490, s2s_loss 0.31340, 56.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10363, exact_match 0.83523, 3.49 secs\n",
      "\u001b[1m---- Epoch 159/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.38201, s2s_loss 0.30603, 51.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10064, exact_match 0.84487, 3.60 secs\n",
      "\u001b[1m---- Epoch 160/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.31866, s2s_loss 0.30490, 57.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08771, exact_match 0.85714, 3.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_160_exact_match+s2s_loss=0.8761.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 161/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.24523, s2s_loss 0.29280, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09000, exact_match 0.85364, 3.69 secs\n",
      "\u001b[1m---- Epoch 162/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.60402, s2s_loss 0.30023, 53.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08951, exact_match 0.85539, 3.28 secs\n",
      "\u001b[1m---- Epoch 163/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.35029, s2s_loss 0.29721, 58.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09001, exact_match 0.85451, 3.91 secs\n",
      "\u001b[1m---- Epoch 164/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24860, s2s_loss 0.29562, 56.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09008, exact_match 0.85714, 3.66 secs\n",
      "\u001b[1m---- Epoch 165/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.42788, s2s_loss 0.29950, 53.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09406, exact_match 0.85627, 3.74 secs\n",
      "\u001b[1m---- Epoch 166/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.27833, s2s_loss 0.30378, 57.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08973, exact_match 0.85627, 3.72 secs\n",
      "\u001b[1m---- Epoch 167/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.39646, s2s_loss 0.29572, 55.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09111, exact_match 0.86854, 3.76 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_167_exact_match+s2s_loss=0.8804.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 168/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.41826, s2s_loss 0.29745, 54.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09110, exact_match 0.86152, 3.81 secs\n",
      "\u001b[1m---- Epoch 169/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.42782, s2s_loss 0.29378, 55.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08982, exact_match 0.86941, 3.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_169_exact_match+s2s_loss=0.8814.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 170/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.41684, s2s_loss 0.28598, 54.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08838, exact_match 0.87029, 4.05 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_170_exact_match+s2s_loss=0.8829.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 171/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.48644, s2s_loss 0.29363, 55.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08887, exact_match 0.86941, 3.71 secs\n",
      "\u001b[1m---- Epoch 172/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.46139, s2s_loss 0.29318, 55.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08922, exact_match 0.87117, 3.49 secs\n",
      "\u001b[1m---- Epoch 173/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.07959, s2s_loss 0.30312, 54.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08555, exact_match 0.86678, 3.51 secs\n",
      "\u001b[1m---- Epoch 174/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.24746, s2s_loss 0.29766, 55.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08866, exact_match 0.86065, 3.77 secs\n",
      "\u001b[1m---- Epoch 175/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.45041, s2s_loss 0.29773, 55.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08785, exact_match 0.85890, 3.77 secs\n",
      "\u001b[1m---- Epoch 176/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.43473, s2s_loss 0.29184, 53.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08559, exact_match 0.86240, 4.04 secs\n",
      "\u001b[1m---- Epoch 177/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.18364, s2s_loss 0.28802, 55.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08337, exact_match 0.86503, 4.05 secs\n",
      "\u001b[1m---- Epoch 178/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.33273, s2s_loss 0.29584, 54.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08479, exact_match 0.86678, 3.94 secs\n",
      "\u001b[1m---- Epoch 179/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26818, s2s_loss 0.29705, 55.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08407, exact_match 0.86503, 4.09 secs\n",
      "\u001b[1m---- Epoch 180/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.36419, s2s_loss 0.29298, 54.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08451, exact_match 0.86678, 4.08 secs\n",
      "\u001b[1m---- Epoch 181/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.41241, s2s_loss 0.30414, 55.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09546, exact_match 0.83874, 3.86 secs\n",
      "\u001b[1m---- Epoch 182/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.20573, s2s_loss 0.30468, 56.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08367, exact_match 0.87467, 3.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_182_exact_match+s2s_loss=0.8855.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 183/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20235, s2s_loss 0.29332, 55.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08559, exact_match 0.86941, 3.90 secs\n",
      "\u001b[1m---- Epoch 184/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.27457, s2s_loss 0.28815, 56.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08767, exact_match 0.86415, 3.61 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 185/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22958, s2s_loss 0.29394, 54.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08608, exact_match 0.87117, 3.53 secs\n",
      "\u001b[1m---- Epoch 186/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.17307, s2s_loss 0.29328, 55.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08636, exact_match 0.86503, 4.07 secs\n",
      "\u001b[1m---- Epoch 187/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39085, s2s_loss 0.28753, 57.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08619, exact_match 0.86591, 3.59 secs\n",
      "\u001b[1m---- Epoch 188/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17880, s2s_loss 0.29672, 57.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08600, exact_match 0.86678, 3.68 secs\n",
      "\u001b[1m---- Epoch 189/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.12835, s2s_loss 0.30512, 56.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09491, exact_match 0.85276, 3.75 secs\n",
      "\u001b[1m---- Epoch 190/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.09220, s2s_loss 0.29619, 55.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08687, exact_match 0.86240, 3.54 secs\n",
      "\u001b[1m---- Epoch 191/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.25236, s2s_loss 0.29756, 54.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09441, exact_match 0.85890, 3.55 secs\n",
      "\u001b[1m---- Epoch 192/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.15664, s2s_loss 0.30248, 51.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09148, exact_match 0.85539, 3.33 secs\n",
      "\u001b[1m---- Epoch 193/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.18666, s2s_loss 0.29863, 56.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09159, exact_match 0.85802, 3.27 secs\n",
      "\u001b[1m---- Epoch 194/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.39695, s2s_loss 0.28791, 57.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09042, exact_match 0.85890, 3.82 secs\n",
      "\u001b[1m---- Epoch 195/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.17343, s2s_loss 0.28978, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09171, exact_match 0.85802, 3.83 secs\n",
      "\u001b[1m---- Epoch 196/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21130, s2s_loss 0.28997, 55.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08973, exact_match 0.85977, 3.35 secs\n",
      "\u001b[1m---- Epoch 197/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.23140, s2s_loss 0.29509, 57.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09731, exact_match 0.84926, 3.50 secs\n",
      "\u001b[1m---- Epoch 198/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.37429, s2s_loss 0.29429, 54.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08493, exact_match 0.87467, 3.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_198_exact_match+s2s_loss=0.8856.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 199/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.37943, s2s_loss 0.29205, 57.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08109, exact_match 0.87029, 3.65 secs\n",
      "\u001b[1m---- Epoch 200/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.08477, s2s_loss 0.29090, 55.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08325, exact_match 0.87555, 3.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_200_exact_match+s2s_loss=0.8869.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 201/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.56794, s2s_loss 0.28544, 53.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08536, exact_match 0.87029, 3.83 secs\n",
      "\u001b[1m---- Epoch 202/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.54967, s2s_loss 0.29507, 54.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08143, exact_match 0.87905, 3.64 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_202_exact_match+s2s_loss=0.8889.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 203/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.14108, s2s_loss 0.28717, 55.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08151, exact_match 0.87642, 3.69 secs\n",
      "\u001b[1m---- Epoch 204/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.25726, s2s_loss 0.28246, 55.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08219, exact_match 0.87905, 3.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_204_exact_match+s2s_loss=0.8894.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 205/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.30217, s2s_loss 0.29219, 54.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09284, exact_match 0.86591, 3.66 secs\n",
      "\u001b[1m---- Epoch 206/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.15621, s2s_loss 0.29629, 54.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08390, exact_match 0.87730, 3.77 secs\n",
      "\u001b[1m---- Epoch 207/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.25549, s2s_loss 0.29568, 56.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08768, exact_match 0.86766, 3.69 secs\n",
      "\u001b[1m---- Epoch 208/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.36684, s2s_loss 0.29201, 55.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08365, exact_match 0.87818, 3.55 secs\n",
      "\u001b[1m---- Epoch 209/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.25130, s2s_loss 0.28275, 53.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08294, exact_match 0.88344, 3.10 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_209_exact_match+s2s_loss=0.8910.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 210/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.32161, s2s_loss 0.28663, 53.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08400, exact_match 0.87905, 3.04 secs\n",
      "\u001b[1m---- Epoch 211/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.44357, s2s_loss 0.29045, 52.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08323, exact_match 0.88081, 3.41 secs\n",
      "\u001b[1m---- Epoch 212/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16041, s2s_loss 0.28036, 56.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08372, exact_match 0.87642, 3.50 secs\n",
      "\u001b[1m---- Epoch 213/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.20029, s2s_loss 0.29503, 56.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08090, exact_match 0.87993, 3.70 secs\n",
      "\u001b[1m---- Epoch 214/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.33777, s2s_loss 0.29961, 55.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08619, exact_match 0.86415, 3.69 secs\n",
      "\u001b[1m---- Epoch 215/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.43226, s2s_loss 0.29168, 55.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08405, exact_match 0.87818, 3.79 secs\n",
      "\u001b[1m---- Epoch 216/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.24363, s2s_loss 0.27953, 53.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08277, exact_match 0.88081, 3.47 secs\n",
      "\u001b[1m---- Epoch 217/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.20482, s2s_loss 0.28022, 53.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07916, exact_match 0.88344, 3.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_217_exact_match+s2s_loss=0.8926.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 218/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.18734, s2s_loss 0.29085, 54.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07917, exact_match 0.88256, 3.72 secs\n",
      "\u001b[1m---- Epoch 219/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.27678, s2s_loss 0.28621, 56.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07839, exact_match 0.88694, 3.89 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_219_exact_match+s2s_loss=0.8942.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 220/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38087, s2s_loss 0.28977, 54.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07810, exact_match 0.88694, 3.67 secs\n",
      "\u001b[1m---- Epoch 221/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.38045, s2s_loss 0.28753, 55.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08427, exact_match 0.86854, 3.34 secs\n",
      "\u001b[1m---- Epoch 222/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.46624, s2s_loss 0.28480, 56.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07950, exact_match 0.87730, 3.72 secs\n",
      "\u001b[1m---- Epoch 223/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.25517, s2s_loss 0.29405, 56.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07971, exact_match 0.87379, 3.85 secs\n",
      "\u001b[1m---- Epoch 224/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.14830, s2s_loss 0.28992, 56.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07971, exact_match 0.88081, 3.75 secs\n",
      "\u001b[1m---- Epoch 225/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.25235, s2s_loss 0.28742, 55.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07849, exact_match 0.87818, 3.65 secs\n",
      "\u001b[1m---- Epoch 226/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.10885, s2s_loss 0.27460, 55.40 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.07820, exact_match 0.87905, 3.80 secs\n",
      "\u001b[1m---- Epoch 227/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.18161, s2s_loss 0.28858, 56.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07679, exact_match 0.88256, 3.13 secs\n",
      "\u001b[1m---- Epoch 228/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21666, s2s_loss 0.28751, 55.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07722, exact_match 0.88168, 3.68 secs\n",
      "\u001b[1m---- Epoch 229/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.28041, s2s_loss 0.29012, 55.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07646, exact_match 0.86854, 3.76 secs\n",
      "\u001b[1m---- Epoch 230/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.30410, s2s_loss 0.29492, 56.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07427, exact_match 0.88519, 3.48 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_230_exact_match+s2s_loss=0.8945.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 231/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.06357, s2s_loss 0.28694, 54.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07564, exact_match 0.88431, 3.66 secs\n",
      "\u001b[1m---- Epoch 232/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.21503, s2s_loss 0.28430, 56.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07836, exact_match 0.88519, 3.71 secs\n",
      "\u001b[1m---- Epoch 233/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22514, s2s_loss 0.29514, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07598, exact_match 0.88519, 3.64 secs\n",
      "\u001b[1m---- Epoch 234/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.28529, s2s_loss 0.28309, 56.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07768, exact_match 0.88256, 4.13 secs\n",
      "\u001b[1m---- Epoch 235/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.28931, s2s_loss 0.27767, 56.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07590, exact_match 0.88694, 3.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_235_exact_match+s2s_loss=0.8956.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 236/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16862, s2s_loss 0.27493, 54.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07616, exact_match 0.88519, 3.81 secs\n",
      "\u001b[1m---- Epoch 237/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.14497, s2s_loss 0.29755, 54.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08739, exact_match 0.86415, 3.54 secs\n",
      "\u001b[1m---- Epoch 238/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.30039, s2s_loss 0.29432, 53.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09133, exact_match 0.86854, 3.63 secs\n",
      "\u001b[1m---- Epoch 239/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.22547, s2s_loss 0.28563, 57.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08173, exact_match 0.87467, 3.68 secs\n",
      "\u001b[1m---- Epoch 240/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.51397, s2s_loss 0.28860, 56.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07533, exact_match 0.88606, 3.37 secs\n",
      "\u001b[1m---- Epoch 241/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.41810, s2s_loss 0.28475, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07704, exact_match 0.88168, 3.58 secs\n",
      "\u001b[1m---- Epoch 242/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.11552, s2s_loss 0.28559, 57.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07636, exact_match 0.88344, 3.58 secs\n",
      "\u001b[1m---- Epoch 243/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.32557, s2s_loss 0.28169, 56.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07788, exact_match 0.87818, 3.91 secs\n",
      "\u001b[1m---- Epoch 244/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38809, s2s_loss 0.27431, 57.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07649, exact_match 0.88168, 3.30 secs\n",
      "\u001b[1m---- Epoch 245/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.22964, s2s_loss 0.29463, 53.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07152, exact_match 0.88782, 3.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_245_exact_match+s2s_loss=0.8967.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 246/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.43003, s2s_loss 0.29120, 54.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07706, exact_match 0.88431, 3.74 secs\n",
      "\u001b[1m---- Epoch 247/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.36687, s2s_loss 0.28645, 54.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07903, exact_match 0.87730, 3.60 secs\n",
      "\u001b[1m---- Epoch 248/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.31086, s2s_loss 0.27678, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08112, exact_match 0.87642, 3.92 secs\n",
      "\u001b[1m---- Epoch 249/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.21317, s2s_loss 0.28540, 53.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07981, exact_match 0.87730, 3.72 secs\n",
      "\u001b[1m---- Epoch 250/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.22524, s2s_loss 0.27643, 52.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07913, exact_match 0.87642, 3.59 secs\n",
      "\u001b[1m---- Epoch 251/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.31020, s2s_loss 0.27671, 54.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07877, exact_match 0.87555, 3.44 secs\n",
      "\u001b[1m---- Epoch 252/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21928, s2s_loss 0.27570, 54.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07993, exact_match 0.87467, 3.60 secs\n",
      "\u001b[1m---- Epoch 253/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.19217, s2s_loss 0.28499, 54.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08972, exact_match 0.87467, 3.41 secs\n",
      "\u001b[1m---- Epoch 254/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.16297, s2s_loss 0.28558, 54.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08144, exact_match 0.88081, 3.80 secs\n",
      "\u001b[1m---- Epoch 255/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.35945, s2s_loss 0.28578, 55.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07824, exact_match 0.88168, 3.52 secs\n",
      "\u001b[1m---- Epoch 256/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.27843, s2s_loss 0.28325, 56.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08026, exact_match 0.88694, 3.68 secs\n",
      "\u001b[1m---- Epoch 257/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.13986, s2s_loss 0.27305, 55.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07850, exact_match 0.89132, 3.46 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_257_exact_match+s2s_loss=0.8969.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 258/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.37023, s2s_loss 0.27866, 54.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07689, exact_match 0.89308, 3.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_258_exact_match+s2s_loss=0.8980.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 259/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.45328, s2s_loss 0.27508, 55.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07721, exact_match 0.89045, 3.61 secs\n",
      "\u001b[1m---- Epoch 260/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.19059, s2s_loss 0.28296, 53.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07638, exact_match 0.88957, 3.29 secs\n",
      "\u001b[1m---- Epoch 261/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.25446, s2s_loss 0.28518, 54.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08825, exact_match 0.87467, 3.03 secs\n",
      "\u001b[1m---- Epoch 262/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.50009, s2s_loss 0.28864, 54.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07946, exact_match 0.88168, 3.72 secs\n",
      "\u001b[1m---- Epoch 263/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.27858, s2s_loss 0.28279, 55.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07762, exact_match 0.88782, 3.32 secs\n",
      "\u001b[1m---- Epoch 264/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.19235, s2s_loss 0.28117, 56.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07899, exact_match 0.88694, 3.64 secs\n",
      "\u001b[1m---- Epoch 265/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.27804, s2s_loss 0.27323, 55.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07777, exact_match 0.88519, 3.16 secs\n",
      "\u001b[1m---- Epoch 266/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.41269, s2s_loss 0.27527, 52.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07710, exact_match 0.88694, 3.73 secs\n",
      "\u001b[1m---- Epoch 267/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.31417, s2s_loss 0.27723, 56.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07665, exact_match 0.88782, 3.57 secs\n",
      "\u001b[1m---- Epoch 268/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15654, s2s_loss 0.27170, 52.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07565, exact_match 0.88694, 3.58 secs\n",
      "\u001b[1m---- Epoch 269/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.22115, s2s_loss 0.28620, 53.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07905, exact_match 0.87292, 3.38 secs\n",
      "\u001b[1m---- Epoch 270/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31117, s2s_loss 0.28853, 53.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08137, exact_match 0.87204, 3.38 secs\n",
      "\u001b[1m---- Epoch 271/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.34245, s2s_loss 0.28387, 54.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07792, exact_match 0.87993, 3.42 secs\n",
      "\u001b[1m---- Epoch 272/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.22824, s2s_loss 0.27545, 55.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07947, exact_match 0.87905, 3.60 secs\n",
      "\u001b[1m---- Epoch 273/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39087, s2s_loss 0.27413, 53.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07726, exact_match 0.87818, 3.89 secs\n",
      "\u001b[1m---- Epoch 274/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.22728, s2s_loss 0.28096, 52.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07898, exact_match 0.88081, 3.82 secs\n",
      "\u001b[1m---- Epoch 275/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.17323, s2s_loss 0.27375, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07877, exact_match 0.88168, 3.63 secs\n",
      "\u001b[1m---- Epoch 276/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38227, s2s_loss 0.27746, 56.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07910, exact_match 0.87993, 3.75 secs\n",
      "\u001b[1m---- Epoch 277/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.06356, s2s_loss 0.28226, 57.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07444, exact_match 0.88081, 3.30 secs\n",
      "\u001b[1m---- Epoch 278/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.37134, s2s_loss 0.28431, 54.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07193, exact_match 0.88431, 2.97 secs\n",
      "\u001b[1m---- Epoch 279/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.28432, s2s_loss 0.27946, 54.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07548, exact_match 0.88431, 2.97 secs\n",
      "\u001b[1m---- Epoch 280/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.39953, s2s_loss 0.27577, 54.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07359, exact_match 0.88606, 2.99 secs\n",
      "\u001b[1m---- Epoch 281/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.41795, s2s_loss 0.27964, 53.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07280, exact_match 0.88606, 2.96 secs\n",
      "\u001b[1m---- Epoch 282/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.35195, s2s_loss 0.28122, 53.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07302, exact_match 0.88782, 2.94 secs\n",
      "\u001b[1m---- Epoch 283/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20537, s2s_loss 0.27336, 54.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07232, exact_match 0.88957, 3.00 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_283_exact_match+s2s_loss=0.8985.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 284/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21903, s2s_loss 0.27957, 54.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07315, exact_match 0.88782, 2.99 secs\n",
      "\u001b[1m---- Epoch 285/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.42458, s2s_loss 0.27485, 54.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07170, exact_match 0.88606, 2.97 secs\n",
      "\u001b[1m---- Epoch 286/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.28470, s2s_loss 0.28601, 53.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07198, exact_match 0.88344, 2.97 secs\n",
      "\u001b[1m---- Epoch 287/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.13817, s2s_loss 0.27816, 54.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07184, exact_match 0.88606, 2.96 secs\n",
      "\u001b[1m---- Epoch 288/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.20609, s2s_loss 0.27563, 54.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07347, exact_match 0.88694, 2.99 secs\n",
      "\u001b[1m---- Epoch 289/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22996, s2s_loss 0.27578, 54.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07159, exact_match 0.88957, 2.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_289_exact_match+s2s_loss=0.8986.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 290/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.22464, s2s_loss 0.27559, 54.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07194, exact_match 0.88869, 2.95 secs\n",
      "\u001b[1m---- Epoch 291/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.07980, s2s_loss 0.27906, 54.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07149, exact_match 0.89045, 2.96 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_291_exact_match+s2s_loss=0.8989.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 292/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28235, s2s_loss 0.27138, 54.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07124, exact_match 0.89132, 2.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_292_exact_match+s2s_loss=0.8998.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 293/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.35441, s2s_loss 0.28778, 48.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07204, exact_match 0.87467, 2.97 secs\n",
      "\u001b[1m---- Epoch 294/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.33547, s2s_loss 0.28209, 53.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07552, exact_match 0.88344, 2.99 secs\n",
      "\u001b[1m---- Epoch 295/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.41144, s2s_loss 0.27739, 53.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07272, exact_match 0.88606, 2.96 secs\n",
      "\u001b[1m---- Epoch 296/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.25497, s2s_loss 0.28278, 54.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07498, exact_match 0.88344, 2.96 secs\n",
      "\u001b[1m---- Epoch 297/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.24341, s2s_loss 0.26865, 54.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07436, exact_match 0.88606, 2.95 secs\n",
      "\u001b[1m---- Epoch 298/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.34039, s2s_loss 0.27955, 54.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07315, exact_match 0.89132, 2.95 secs\n",
      "\u001b[1m---- Epoch 299/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.47507, s2s_loss 0.26506, 55.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07356, exact_match 0.88431, 2.95 secs\n",
      "\u001b[1m---- Epoch 300/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.18553, s2s_loss 0.27277, 55.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07332, exact_match 0.88431, 2.96 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_175612_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--batch_size 10 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"multitask\" \\\n",
    "--experiment_name \"nli+mlm\" \\\n",
    "--multitask_name_list \\\n",
    "\"nli\" \\\n",
    "\"mlm\" \\\n",
    "\"sentence2facts\" \\\n",
    "--task2weight '{\"nli\": 2.0, \"mlm\": 1.0, \"sentence2facts\": 0.0}' \\\n",
    "--sentence_to_facts_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\"\\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\" \\\n",
    "--integrated_nli_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\" \\\n",
    "--use_sentence2facts_for_nli \\\n",
    "--use_anli \\\n",
    "--use_multinli \\\n",
    "--use_snli \\\n",
    "--use_report_nli \\\n",
    "--report_nli_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\" \\\n",
    "--paraphrased_inputs_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\" \\\n",
    "--only_validate_nli \\\n",
    "--nli1_only_on_train \\\n",
    "--nli1_only_on_val \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--t5_model_name \"facebook/bart-base\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 600\n",
      "   batch_size: 10\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: facebook/bart-base\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_182751_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: multitask\n",
      "   experiment_name: nli+mlm\n",
      "   multitask_name_list: ['nli', 'mlm', 'sentence2facts']\n",
      "   task2weight: {'nli': 2.0, 'mlm': 1.0, 'sentence2facts': 0.0}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl']\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl']\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl']\n",
      "   integrated_nli_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\n",
      "   integrated_report_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "   use_sentence2facts_for_nli: True\n",
      "   use_anli: True\n",
      "   use_multinli: True\n",
      "   use_snli: True\n",
      "   use_report_nli: True\n",
      "   use_fact_based_reports_in_mlm: True\n",
      "   use_report_nli_entailment_dataset: True\n",
      "   only_validate_nli: True\n",
      "   nli1_only_on_train: True\n",
      "   nli1_only_on_val: True\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9891 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mB\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mbilateral\u001b[0m\n",
      "\u001b[1m\u001b[35mboth sides\u001b[0m\n",
      "\u001b[1m\u001b[35mboth\u001b[0m\n",
      "\u001b[1m\u001b[35mon both sides\u001b[0m\n",
      "\u001b[1m\u001b[35msymmetrical\u001b[0m\n",
      "\u001b[1m\u001b[35mequally on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mpresent on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mseen on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35moccurring on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mappearing on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mfound on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mseen bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mobserved bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mdetected bilaterally\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9890 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilus\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the hilum on the left side\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 8511 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary vasculature\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral lung vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary blood vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mlung periphery vasculature\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature of the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels in the outer regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular network in the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary circulation\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels supplying the outer areas of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature in the peripheral regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular system in the outer regions of the lung\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "\u001b[1mLoaded 1864 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35ma\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mone\u001b[0m\n",
      "\u001b[1m\u001b[35msingle\u001b[0m\n",
      "\u001b[1m\u001b[35msole\u001b[0m\n",
      "\u001b[1m\u001b[35monly\u001b[0m\n",
      "\u001b[1m\u001b[35mindividual\u001b[0m\n",
      "\u001b[1m\u001b[35mlone\u001b[0m\n",
      "\u001b[1m\u001b[35msolitary\u001b[0m\n",
      "\u001b[1m\u001b[35munique\u001b[0m\n",
      "\u001b[1m\u001b[35mdistinct\u001b[0m\n",
      "\u001b[1m\u001b[35msingular\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14993 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14971 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14972 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14965 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 10000 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9999 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9997 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9994 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9996 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome not detected\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome is not observed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant constriction\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of notable narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of substantial narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mlack of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of notable constriction\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19943 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of wheezing\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing detected\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing observed\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing present\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing found\u001b[0m\n",
      "--------\n",
      "\u001b[1mNumber of unique inputs: 190085\u001b[0m\n",
      "\u001b[1mNumber of total paraphrases: 2093173\u001b[0m\n",
      "Number of medical sentences from paraphrases: 2039914\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing sentence2facts dataset\u001b[0m\n",
      "Loaded 9999 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19971 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\n",
      "Loaded 19984 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\n",
      "Loaded 5000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\n",
      "Loaded 14990 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\n",
      "Loaded 14991 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\n",
      "\u001b[1mInput/output example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mS2F: Left hilum is enlarged and was found to have FDG avid lymph node on PET CT on .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m[\"enlarged left hilum\", \"FDG avid lymph node in the left hilum\"]\u001b[0m\n",
      "Number of train examples: 84935\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing nli dataset\u001b[0m\n",
      "----\n",
      "Loading integrated NLI from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl...\n",
      "Number of samples: 169025\n",
      "Number of sources: 7\n",
      "----\n",
      "\u001b[1mLoading sentence2facts input/output pairs for NLI...\u001b[0m\n",
      "Number of entailment samples added: 184483\n",
      "----\n",
      "\u001b[1mLoading general domain datasets...\u001b[0m\n",
      "Loading ANLI...\n",
      "Number of ANLI R1 samples: 18946\n",
      "Number of ANLI R2 samples: 47460\n",
      "Number of ANLI R3 samples: 102859\n",
      "Loading MultiNLI...\n",
      "Number of MultiNLI train samples: 392702\n",
      "Number of MultiNLI dev_matched samples: 10000\n",
      "Number of MultiNLI dev_mismatched samples: 10000\n",
      "Loading SNLI...\n",
      "Number of SNLI train samples: 550152\n",
      "Number of SNLI dev samples: 10000\n",
      "Number of SNLI test samples: 10000\n",
      "----\n",
      "\u001b[1mLoading report NLI datasets...\u001b[0m\n",
      "Loaded 70000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\n",
      "Loaded 54076 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\n",
      "----\n",
      "\u001b[1mBuilding train NLI dataset...\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: contradiction -> 79430 (4312.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: 9:40 AM. #H: 9:43 AM.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: contradiction -> 10732 (2400.52)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Potential small-to-moderate right pleural effusion. #H: Small-to-moderate residual right pleural effusion.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: contradiction -> 4170 (1739.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Mediastinal and hilar contours are otherwise unchanged. #H: There is no cardiomediastinal silhouette and hilar contours are unremarkable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: contradiction -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She started taking ibuprofen for it at [**First Name8 (NamePattern2) **] [**Last Name (un) 5416**] dose. #H:  The patient is not in pain. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: contradiction -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Anxiety 12. h/o Anemia - hemolytic anemia after Keflex 13. #H:  No history of anemia\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: contradiction -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She was evaluated by neurosurgery, deemed to be intact neurologically. #H:  She had neurological deficits \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: contradiction -> 106 (304.54)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Large left pleural effusion persists. #H: No pleural effusion, focal consolidation or pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: anli | Label: contradiction -> 44089 (3672.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: ALBUQUERQUE, N.M. (AP) — Alaska Airlines is pulling two non-stop flights for Albuquerque International Sunport while adding two non-stop flights to El Paso. The airline announced last week it was ending its non-stop services from Albuquerque to San Francisco and Orange County because of a lack of demand. The Sunport says flights on the airline to Portland, Seattle and San Diego will remain. Meanwhile, Alaska Airlines says it will add direct daily flights from El Paso to Seattle-Tacoma International Airport and San Diego International Airport. #H: Alaska Airlines is extending its non-stop services from Albuquerque to San Francisco and Orange County because of a lack of demand.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: contradiction -> 137356 (4971.81)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Jon bowed. #H: Jon bowed, tripped over his feet and fell over.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: snli | Label: contradiction -> 189702 (5390.10)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: People shop in an outside market. #H: The people are indoors at the movies.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_facts | Label: contradiction -> 12296 (2507.64)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: frontal view of the chest. lateral view of the chest. postoperative changes of left lower lobectomy. left pleural effusion. fluid tracking just lateral to the posterior mediastinum. similar to CT scan. clear lungs. lungs without consolidation. lungs without pulmonary vascular congestion. stable cardiomediastinal silhouette. stable osseous structures. no acute cardiopulmonary process #H: lingular linear atelectasis\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_labels | Label: contradiction -> 10209 (2361.96)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: new left-sided central venous access line. course of the line is unremarkable. tip of the line projects over the mid SVC. no evidence of complications. no pneumothorax. other monitoring devices in constant position. support devices in constant position. unchanged position of the left pleural pigtail catheter #H: swan-ganz catheter seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: entailment -> 13185 (2563.82)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Previous pulmonary edema has largely cleared, persisting only in the lung bases, and left upper lobe atelectasis has resolved. #H: The patient's pulmonary edema has improved significantly, with only some remaining in the lung bases.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: entailment -> 5445 (1911.57)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is interval placement of a left PICC line with tip terminating in the cavoatrial junction. #H: Again seen is a left-sided PICC line with tip at cavoatrial junction.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: entailment -> 1770 (1256.05)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: This was most likely resolving pulmonary edema. #H: Mild pulmonary edema has continue to improve.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: entailment -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: After breaking her suspected seizure, she returned closer to her usual baseline mental status which involves responding to verbal and tactile stimuli. #H:  the patient had a suspected seizure\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: entailment -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She was extubated on [**3319-9-3**] at 5 P.M., tolerated well and was transferred to the floor on [**9-2**]. #H:  She was functioning well after tube was removed\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: entailment -> 473 (701.58)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She was not experiencing hematemasis. #H:  She was not vomiting blood\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: entailment -> 93 (279.62)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiac silhouette is top normal. #H: The heart size is normal.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSource: s2f | Label: entailment -> 184483 (5353.06)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Current AP radiograph of the chest demonstrates right perihilar opacity, most likely representing known cancer potentially after radiation treatment. #H: right perihilar opacity\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: anli | Label: entailment -> 54251 (3890.16)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: When we look at unemployment, the minister is boasting of fantastic surpluses in the unemployment insurance fund, which he is putting toward reduction of the deficit, when we look at the restrictions which have helped accumulate the unemployment insurance fund surplus, the restrictions to the new employment insurance program, we see that this is no joke. #H: The minister has produced a good surplus.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: entailment -> 137841 (4976.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: In any case, offering an assessment of an encyclopedia without having read it is like assessing an issue of Slate that hasn't been posted. #H: Encyclopedias are worthy of diligent assessment as to their worth.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: snli | Label: entailment -> 190113 (5392.98)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A man sitting on a stool playing the banjo. #H: There is a man playing a banjo.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_facts | Label: entailment -> 38483 (3533.99)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: location of the tip of small catheter. tip of small catheter in the distal SVC. best seen on the lateral view. confirmed on the frontal view. frontal view of the chest. lateral view of the chest. dense consolidation at the left lung base. obscuring hemidiaphragm at the left lung base. combination of consolidation. combination of atelectasis. combination of effusion. hiatal hernia suspected. clear right lung. separate right subclavian lines identified. larger catheter with tip terminating in the right atrium. smaller catheter tip not clearly delineated. degenerative changes in the spine. spine without acute abnormality. dense left basilar opacity. opacity similar to previous exam. opacity due to effusion. opacity due to atelectasis. opacity due to consolidation #H: lateral radiograph of the chest provided\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_labels | Label: entailment -> 33440 (3394.81)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: low lung volumes. small bilateral pleural effusions. atelectasis at the lung bases. no pneumonia. no pulmonary edema. Port-A-Cath in the left pectoral region #H: low lung volumes seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "FactBasedReportEntailmentDataset\n",
      "Loaded 227835 reports from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "\u001b[1mSource: gpt-4-0613 | Label: neutral -> 19123 (2877.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is a nodular opacity on the frontal view projecting over the anterior right third and fourth ribs. #H: VP shunt is projecting over the right hemothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: neutral -> 16675 (2758.96)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Small bilateral pleural effusions with mild adjacent compressive atelectasis is unchanged. #H: Large hiatal hernia with adjacent compressive atelectasis.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: neutral -> 3968 (1708.29)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Aortic calcification appears unchanged. #H: Atherosclerotic calcification is seen within the aortic arch.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: neutral -> 3743 (1672.44)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: After being discharged [**10-21**] for MSSA sepsis thought to be [**3-6**] HD line infection pt was sent to rehab. #H:  Patient has septic shock\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: neutral -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: GI bleeding, she did not start the heparin gtt. #H:  She has a peptic ulcer\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: neutral -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The PDA and posterolateral vessels had 90% ostial lesions. #H:  Patient may required CABG\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: neutral -> 281 (538.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The bilateral pleural effusions have decreased in size. #H: Left pleural pigtail catheter has been removed.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: anli | Label: neutral -> 70925 (4184.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Jean Charles Emmanuel Nodier (April 29, 1780 – January 27, 1844) was an influential French author and librarian who introduced a younger generation of Romanticists to the \"conte fantastique\", gothic literature, and vampire tales. His dream related writings influenced the later works of Gérard de Nerval. #H: Jean Charles Emmanuel Nodler was writing vampire novels in 1802\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: neutral -> 137152 (4969.93)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Boudhanath, 6 km (4 miles) northeast of the city center, is the valley's second important stupa and is similar in many ways to Swayambhunath. #H: Boudhanath, 6 km (4 miles) northeast of the city center, is the valley's second important stupa and is similar in many ways to Swayambhunath in that they are both underrated. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: snli | Label: neutral -> 189218 (5386.70)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A woman rides her bike with her white helmet and her biking shorts and top. #H: The woman is teaching a class on proper bike safety to her students.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_facts | Label: neutral -> 19221 (2881.71)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: AP view of the chest compared to previous exam. lateral view of the chest compared to previous exam. clear lungs. lungs without consolidation. lungs without effusion. stable cardiomediastinal silhouette. suggestion of possible left lateral rib fractures. significant overlying soft tissues. AP technique. uncertain acuity of rib fractures. dedicated rib series could be performed. no pneumothorax. osseous structures are unremarkable. findings suggestive of left rib fractures. limited evaluation secondary to technique. limited evaluation secondary to patient body habitus. dedicated left rib series is suggested #H: examination centered on the left third anterior rib\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_labels | Label: neutral -> 10427 (2378.22)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: little change compared to previous study. no evidence of acute cardiopulmonary disease. no pneumonia. no vascular congestion. no pleural effusion #H: pneumoperitoneum seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "----\n",
      "Number of RadNLI test samples: 480\n",
      "Number of MS_CXR_T samples: 361\n",
      "Number of report NLI samples added to val: 300\n",
      "Number of report NLI samples added to val: 300\n",
      "Number of val NLI samples: 1441\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: right internal jugular line in place. gradual increase in the right mediastinum. distention between the lateral border of the right mediastinum and carina at the level of the azygos vein 4.5 cm. potential extravasation and hematoma due to the presence of the subclavian line. distention due to increased volume overload. interstitial pulmonary edema. moderate left pleural effusion. unchanged appearance of the monitoring devices. ET tube tip approximately 4 cm above the carina #H: subclavian line seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: monitoring devices unchanged. support devices unchanged. no pleural lines in the right upper zone. no pleural lines in the right mid zone. no pleural lines representing skin folds. opacification in the right apical region. dense calcifications in the right apical region. sequela of previous tuberculous disease. no evidence of acute pneumonia #H: skin fold seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Normal lung volumes. #H: Heart size is normal.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: no evidence of left pneumothorax. previous line reflected a skin fold. little overall change in the appearance of the heart. little overall change in the appearance of the lungs. increased atelectatic changes at the left base #H: linear structures that correspond to skin folds\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: subtle bilateral peribronchial opacities. new opacities since the CXR. linear opacity projecting over the heart. suggesting a middle lobe process. clear lung bases on CT abdomen. no pleural effusions. no pneumothorax. cardiomediastinal silhouette within normal limits. no acute osseous abnormalities. right port unchanged in position. right port terminates at the cavoatrial junction. new bilateral peribronchial opacities. opacities concerning for infectious process. opacities in an immunocompromised patient. concern for pulmonary embolism. obtain CTA Chest #H: clinical assessment for possible pulmonic stenosis\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "----\n",
      "\u001b[1mBuilding val NLI dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing mlm dataset\u001b[0m\n",
      "Number of general sentences: 1377099\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 1377099\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 1377099/1377099 [00:10<00:00, 133457.53it/s]\n",
      "\tlen(valid_tokens): 21522\n",
      "100%|██████████████████████████████| 1377099/1377099 [00:18<00:00, 73606.34it/s]\n",
      "Number of sentences: 1348333\n",
      "Number of bins: 7\n",
      "Bin size: 958219, weight: 7845.006940358202\n",
      "Bin size: 219530, weight: 5586.745498624757\n",
      "Bin size: 110971, weight: 4707.694773844805\n",
      "Bin size: 46036, weight: 3717.013976819967\n",
      "Bin size: 8332, weight: 2209.4180153128023\n",
      "Bin size: 4974, weight: 1851.8906668241702\n",
      "Bin size: 271, weight: 527.9351334797618\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: By identifying control and [tok1] groups , we can rule out other explanations and settle on [tok2] attribution .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] comparison [tok2] firm\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: A [tok1] and two children at the beach .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] man\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The crowd of [tok1] is being monitored .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] people\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: People are painting at an art [tok1]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] studio\u001b[0m\n",
      "Loaded 227835 reports from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "Number of medical sentences: 2932778\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 2932778\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 2932778/2932778 [00:21<00:00, 138153.78it/s]\n",
      "\tlen(valid_tokens): 8359\n",
      "100%|██████████████████████████████| 2932778/2932778 [00:42<00:00, 69560.52it/s]\n",
      "Number of sentences: 2906418\n",
      "Number of bins: 10\n",
      "Bin size: 1207182, weight: 8246.340215553266\n",
      "Bin size: 689250, weight: 7295.365215618737\n",
      "Bin size: 564608, weight: 6975.4143925643\n",
      "Bin size: 322873, weight: 6129.097132424093\n",
      "Bin size: 100852, weight: 4592.407749770934\n",
      "Bin size: 17524, weight: 2801.4586201952056\n",
      "Bin size: 3528, weight: 1636.6220215729345\n",
      "Bin size: 296, weight: 553.2771321660764\n",
      "Bin size: 165, weight: 399.7165542494086\n",
      "Bin size: 140, weight: 362.3577604078641\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: [tok1] frontal view of the [tok2] . relatively low lung volumes . no definite focal consolidation . no pleural effusion . no pneumothorax . stable cardiac silhouette . [tok3] mediastinal silhouette . no [tok4] cardiopulmonary process\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] single [tok2] chest [tok3] stable [tok4] acute\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Mild [tok1] at the right base\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] presence\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Partial [tok1] of opacities in the [tok2] regions of both upper lobes\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] improvement [tok2] subpleural\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Cardiac [tok1] is stable as are the osseous and [tok2] tissue structures .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] silhouette [tok2] soft\u001b[0m\n",
      "----------------------------------------\n",
      "Number of train datasets: 3\n",
      "Number of val datasets: 1\n",
      "\u001b[93m\u001b[1mWARNING: CompositeInfiniteDataset(): Removed 1 datasets with zero weight\u001b[0m\n",
      "----------------------------------------\n",
      "Examples of val datasets:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: the left pleural effusion may have slightly decreased in size. #H: the left pleural effusion may have slightly increased in size.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Cardiomediastinal silhouette and hilar contours are normal. #H: Cardiomediastinal silhouette is normal size.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Interval improved right basilar atelectasis. #H: Interval worsening of right basilar atelectasis.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: endotracheal tube terminates approximately 6.1 cm above the carina. endotracheal tube could be advanced 2 cm for more optimal positioning. single frontal view of the chest. enteric tube terminates in left upper quadrant. enteric tube terminates in the expected location of the stomach. low lung volumes. no focal consolidation. no large pleural effusion. trace left pleural effusion. no evidence of pneumothorax. unremarkable cardiac silhouette. unremarkable mediastinal silhouette #H: tortuous aorta seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "seq2seq_trainer.name =  multitask(nli+mlm)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240308_133455_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240308_133455_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_292_exact_match+s2s_loss=0.8998.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_182751_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/checkpoint_292_exact_match+s2s_loss=0.8998.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240308_133455_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20113, s2s_loss 0.26470, 56.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09416, exact_match 0.85774, 4.40 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_exact_match+s2s_loss=0.8763.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.27285, s2s_loss 0.27619, 53.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09588, exact_match 0.85774, 4.23 secs\n",
      "\u001b[1m---- Epoch 3/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.34787, s2s_loss 0.27040, 52.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09745, exact_match 0.85566, 4.42 secs\n",
      "\u001b[1m---- Epoch 4/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.17385, s2s_loss 0.27518, 51.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.11531, exact_match 0.81263, 4.32 secs\n",
      "\u001b[1m---- Epoch 5/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 0.35583, s2s_loss 0.28173, 52.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09898, exact_match 0.84802, 4.59 secs\n",
      "\u001b[1m---- Epoch 6/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.13936, s2s_loss 0.28016, 54.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09242, exact_match 0.84386, 4.54 secs\n",
      "\u001b[1m---- Epoch 7/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.30727, s2s_loss 0.27608, 52.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09601, exact_match 0.84039, 4.55 secs\n",
      "\u001b[1m---- Epoch 8/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.35639, s2s_loss 0.27337, 53.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09526, exact_match 0.84525, 4.10 secs\n",
      "\u001b[1m---- Epoch 9/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.09486, s2s_loss 0.26293, 55.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09572, exact_match 0.84525, 4.32 secs\n",
      "\u001b[1m---- Epoch 10/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.26481, s2s_loss 0.26843, 53.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09623, exact_match 0.84316, 4.67 secs\n",
      "\u001b[1m---- Epoch 11/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.43813, s2s_loss 0.26928, 56.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09687, exact_match 0.84108, 3.94 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 12/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.25159, s2s_loss 0.26944, 54.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09586, exact_match 0.84316, 4.67 secs\n",
      "\u001b[1m---- Epoch 13/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.38684, s2s_loss 0.27957, 56.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10765, exact_match 0.82582, 4.34 secs\n",
      "\u001b[1m---- Epoch 14/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.24766, s2s_loss 0.27988, 52.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09273, exact_match 0.84178, 4.27 secs\n",
      "\u001b[1m---- Epoch 15/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.39207, s2s_loss 0.27177, 55.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09448, exact_match 0.85982, 4.52 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_15_exact_match+s2s_loss=0.8767.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 16/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.18320, s2s_loss 0.27162, 54.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09275, exact_match 0.85704, 4.42 secs\n",
      "\u001b[1m---- Epoch 17/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22671, s2s_loss 0.28105, 55.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09070, exact_match 0.86260, 4.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_exact_match+s2s_loss=0.8788.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.39248, s2s_loss 0.27084, 55.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09148, exact_match 0.86190, 4.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_exact_match+s2s_loss=0.8788.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.22941, s2s_loss 0.26943, 57.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09194, exact_match 0.86190, 4.66 secs\n",
      "\u001b[1m---- Epoch 20/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.67440, s2s_loss 0.26863, 57.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09135, exact_match 0.86398, 4.71 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_20_exact_match+s2s_loss=0.8800.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 21/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.37153, s2s_loss 0.27296, 54.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10158, exact_match 0.83831, 4.51 secs\n",
      "\u001b[1m---- Epoch 22/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.12293, s2s_loss 0.28740, 53.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09286, exact_match 0.84941, 4.54 secs\n",
      "\u001b[1m---- Epoch 23/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.24050, s2s_loss 0.28330, 55.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09459, exact_match 0.83831, 4.54 secs\n",
      "\u001b[1m---- Epoch 24/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.48673, s2s_loss 0.26904, 55.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09153, exact_match 0.84802, 4.52 secs\n",
      "\u001b[1m---- Epoch 25/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.17212, s2s_loss 0.27286, 54.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09196, exact_match 0.84525, 4.75 secs\n",
      "\u001b[1m---- Epoch 26/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.39609, s2s_loss 0.27528, 55.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09425, exact_match 0.84455, 4.47 secs\n",
      "\u001b[1m---- Epoch 27/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21842, s2s_loss 0.26872, 55.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09255, exact_match 0.84594, 4.54 secs\n",
      "\u001b[1m---- Epoch 28/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16376, s2s_loss 0.26726, 56.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09243, exact_match 0.84386, 4.48 secs\n",
      "\u001b[1m---- Epoch 29/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.10261, s2s_loss 0.27742, 56.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10403, exact_match 0.84455, 4.00 secs\n",
      "\u001b[1m---- Epoch 30/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.35219, s2s_loss 0.27956, 56.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09876, exact_match 0.84108, 4.35 secs\n",
      "\u001b[1m---- Epoch 31/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.13031, s2s_loss 0.27614, 56.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09467, exact_match 0.85704, 4.54 secs\n",
      "\u001b[1m---- Epoch 32/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.28329, s2s_loss 0.27028, 55.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09383, exact_match 0.85080, 4.68 secs\n",
      "\u001b[1m---- Epoch 33/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.39988, s2s_loss 0.26806, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09387, exact_match 0.85566, 4.00 secs\n",
      "\u001b[1m---- Epoch 34/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.41730, s2s_loss 0.26819, 55.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09506, exact_match 0.85357, 4.56 secs\n",
      "\u001b[1m---- Epoch 35/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.13034, s2s_loss 0.25999, 56.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09261, exact_match 0.85288, 4.60 secs\n",
      "\u001b[1m---- Epoch 36/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.27126, s2s_loss 0.26799, 55.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09284, exact_match 0.85704, 4.41 secs\n",
      "\u001b[1m---- Epoch 37/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.27618, s2s_loss 0.27695, 56.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09725, exact_match 0.84525, 4.21 secs\n",
      "\u001b[1m---- Epoch 38/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.25568, s2s_loss 0.28077, 55.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09175, exact_match 0.85496, 4.29 secs\n",
      "\u001b[1m---- Epoch 39/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.17909, s2s_loss 0.27145, 57.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09209, exact_match 0.85357, 4.66 secs\n",
      "\u001b[1m---- Epoch 40/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.23784, s2s_loss 0.27324, 55.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09321, exact_match 0.84941, 4.63 secs\n",
      "\u001b[1m---- Epoch 41/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.25021, s2s_loss 0.26939, 56.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09536, exact_match 0.84039, 4.69 secs\n",
      "\u001b[1m---- Epoch 42/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.26736, s2s_loss 0.26067, 57.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09260, exact_match 0.84594, 4.71 secs\n",
      "\u001b[1m---- Epoch 43/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.45191, s2s_loss 0.26922, 56.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09274, exact_match 0.84594, 4.23 secs\n",
      "\u001b[1m---- Epoch 44/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24865, s2s_loss 0.26703, 56.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09291, exact_match 0.85149, 4.64 secs\n",
      "\u001b[1m---- Epoch 45/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.12717, s2s_loss 0.27214, 56.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09449, exact_match 0.84941, 4.65 secs\n",
      "\u001b[1m---- Epoch 46/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.25498, s2s_loss 0.27842, 56.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08906, exact_match 0.85427, 4.66 secs\n",
      "\u001b[1m---- Epoch 47/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.38427, s2s_loss 0.27631, 58.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09110, exact_match 0.84872, 4.57 secs\n",
      "\u001b[1m---- Epoch 48/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33901, s2s_loss 0.26431, 54.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09318, exact_match 0.85427, 4.76 secs\n",
      "\u001b[1m---- Epoch 49/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.18454, s2s_loss 0.27372, 56.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09025, exact_match 0.85635, 4.50 secs\n",
      "\u001b[1m---- Epoch 50/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.30160, s2s_loss 0.26559, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08931, exact_match 0.85913, 4.53 secs\n",
      "\u001b[1m---- Epoch 51/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.47194, s2s_loss 0.26189, 53.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08968, exact_match 0.85843, 4.53 secs\n",
      "\u001b[1m---- Epoch 52/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.33265, s2s_loss 0.27302, 53.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08893, exact_match 0.86051, 4.69 secs\n",
      "\u001b[1m---- Epoch 53/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.17358, s2s_loss 0.27141, 57.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09931, exact_match 0.84663, 4.69 secs\n",
      "\u001b[1m---- Epoch 54/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.29375, s2s_loss 0.27338, 56.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09398, exact_match 0.85635, 4.51 secs\n",
      "\u001b[1m---- Epoch 55/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.19221, s2s_loss 0.27797, 56.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09184, exact_match 0.84455, 4.64 secs\n",
      "\u001b[1m---- Epoch 56/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.29295, s2s_loss 0.27560, 56.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09152, exact_match 0.85427, 4.75 secs\n",
      "\u001b[1m---- Epoch 57/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.16258, s2s_loss 0.26100, 55.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09016, exact_match 0.85288, 4.70 secs\n",
      "\u001b[1m---- Epoch 58/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.27939, s2s_loss 0.27023, 56.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08909, exact_match 0.85427, 4.58 secs\n",
      "\u001b[1m---- Epoch 59/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.10340, s2s_loss 0.27028, 57.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08924, exact_match 0.85427, 4.63 secs\n",
      "\u001b[1m---- Epoch 60/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.66975, s2s_loss 0.27159, 54.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09102, exact_match 0.85635, 5.01 secs\n",
      "\u001b[1m---- Epoch 61/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.35084, s2s_loss 0.27574, 55.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09479, exact_match 0.86398, 4.76 secs\n",
      "\u001b[1m---- Epoch 62/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.37829, s2s_loss 0.26984, 55.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09015, exact_match 0.85080, 4.71 secs\n",
      "\u001b[1m---- Epoch 63/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.27231, s2s_loss 0.27159, 54.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09102, exact_match 0.86398, 4.42 secs\n",
      "\u001b[1m---- Epoch 64/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.18416, s2s_loss 0.26868, 57.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08866, exact_match 0.85774, 4.38 secs\n",
      "\u001b[1m---- Epoch 65/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38682, s2s_loss 0.26920, 54.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08926, exact_match 0.85982, 4.30 secs\n",
      "\u001b[1m---- Epoch 66/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.17425, s2s_loss 0.26401, 56.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09012, exact_match 0.85913, 4.41 secs\n",
      "\u001b[1m---- Epoch 67/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11016, s2s_loss 0.26569, 55.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09013, exact_match 0.85774, 4.54 secs\n",
      "\u001b[1m---- Epoch 68/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.22627, s2s_loss 0.27026, 54.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08932, exact_match 0.85774, 4.54 secs\n",
      "\u001b[1m---- Epoch 69/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.41943, s2s_loss 0.27764, 55.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10110, exact_match 0.83831, 4.56 secs\n",
      "\u001b[1m---- Epoch 70/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.46606, s2s_loss 0.27518, 54.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09734, exact_match 0.85080, 4.82 secs\n",
      "\u001b[1m---- Epoch 71/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.31553, s2s_loss 0.27722, 55.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08932, exact_match 0.85913, 4.31 secs\n",
      "\u001b[1m---- Epoch 72/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.27605, s2s_loss 0.26767, 56.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10031, exact_match 0.84247, 4.24 secs\n",
      "\u001b[1m---- Epoch 73/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.08815, s2s_loss 0.26984, 54.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09196, exact_match 0.85774, 4.71 secs\n",
      "\u001b[1m---- Epoch 74/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.38005, s2s_loss 0.27013, 55.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08890, exact_match 0.86398, 4.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_74_exact_match+s2s_loss=0.8808.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 75/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.13787, s2s_loss 0.26505, 56.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09065, exact_match 0.86121, 4.66 secs\n",
      "\u001b[1m---- Epoch 76/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.31828, s2s_loss 0.26199, 55.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09022, exact_match 0.86121, 4.62 secs\n",
      "\u001b[1m---- Epoch 77/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.22844, s2s_loss 0.27424, 57.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09780, exact_match 0.85843, 4.83 secs\n",
      "\u001b[1m---- Epoch 78/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.41979, s2s_loss 0.26698, 57.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08797, exact_match 0.86537, 4.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_78_exact_match+s2s_loss=0.8820.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 79/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.35921, s2s_loss 0.27093, 57.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08659, exact_match 0.86398, 4.85 secs\n",
      "\u001b[1m---- Epoch 80/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.21272, s2s_loss 0.27322, 56.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08594, exact_match 0.86607, 4.54 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_80_exact_match+s2s_loss=0.8827.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 81/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.26481, s2s_loss 0.26679, 55.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08605, exact_match 0.86676, 4.91 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_81_exact_match+s2s_loss=0.8833.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 82/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.24578, s2s_loss 0.25793, 56.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08604, exact_match 0.86468, 4.65 secs\n",
      "\u001b[1m---- Epoch 83/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.10335, s2s_loss 0.26473, 56.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08618, exact_match 0.86676, 4.52 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_83_exact_match+s2s_loss=0.8834.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 84/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30071, s2s_loss 0.25918, 56.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08650, exact_match 0.86815, 4.58 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_84_exact_match+s2s_loss=0.8843.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 85/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.19153, s2s_loss 0.26828, 58.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09449, exact_match 0.84594, 4.64 secs\n",
      "\u001b[1m---- Epoch 86/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.18618, s2s_loss 0.27322, 56.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09086, exact_match 0.85982, 4.98 secs\n",
      "\u001b[1m---- Epoch 87/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18471, s2s_loss 0.26847, 56.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09121, exact_match 0.85635, 4.60 secs\n",
      "\u001b[1m---- Epoch 88/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.34556, s2s_loss 0.26816, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09172, exact_match 0.86121, 4.45 secs\n",
      "\u001b[1m---- Epoch 89/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.26401, s2s_loss 0.25970, 55.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08838, exact_match 0.86468, 5.13 secs\n",
      "\u001b[1m---- Epoch 90/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.32652, s2s_loss 0.25957, 58.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08762, exact_match 0.86884, 4.54 secs\n",
      "\u001b[1m---- Epoch 91/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.37835, s2s_loss 0.25937, 55.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08821, exact_match 0.86884, 4.32 secs\n",
      "\u001b[1m---- Epoch 92/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.27779, s2s_loss 0.27030, 56.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08724, exact_match 0.87162, 4.55 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_92_exact_match+s2s_loss=0.8848.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 93/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.29923, s2s_loss 0.26800, 55.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09494, exact_match 0.85149, 4.80 secs\n",
      "\u001b[1m---- Epoch 94/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.40695, s2s_loss 0.26815, 56.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09301, exact_match 0.86051, 4.61 secs\n",
      "\u001b[1m---- Epoch 95/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20777, s2s_loss 0.27029, 55.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09377, exact_match 0.86121, 4.52 secs\n",
      "\u001b[1m---- Epoch 96/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.11062, s2s_loss 0.25453, 55.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09274, exact_match 0.86468, 4.95 secs\n",
      "\u001b[1m---- Epoch 97/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.21227, s2s_loss 0.26891, 56.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08838, exact_match 0.87092, 4.57 secs\n",
      "\u001b[1m---- Epoch 98/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21513, s2s_loss 0.26920, 56.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08849, exact_match 0.86815, 4.22 secs\n",
      "\u001b[1m---- Epoch 99/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.07221, s2s_loss 0.26450, 57.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09023, exact_match 0.86954, 4.61 secs\n",
      "\u001b[1m---- Epoch 100/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.46829, s2s_loss 0.26389, 58.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08883, exact_match 0.86884, 4.44 secs\n",
      "\u001b[1m---- Epoch 101/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.21807, s2s_loss 0.26638, 55.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09174, exact_match 0.86607, 4.59 secs\n",
      "\u001b[1m---- Epoch 102/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.18191, s2s_loss 0.26773, 57.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08615, exact_match 0.85774, 4.53 secs\n",
      "\u001b[1m---- Epoch 103/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.24038, s2s_loss 0.26645, 56.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09062, exact_match 0.85427, 4.69 secs\n",
      "\u001b[1m---- Epoch 104/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.18698, s2s_loss 0.26296, 57.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09368, exact_match 0.85496, 4.12 secs\n",
      "\u001b[1m---- Epoch 105/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.14700, s2s_loss 0.26733, 57.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08773, exact_match 0.86190, 4.56 secs\n",
      "\u001b[1m---- Epoch 106/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.19689, s2s_loss 0.25210, 53.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08739, exact_match 0.86121, 4.50 secs\n",
      "\u001b[1m---- Epoch 107/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.15917, s2s_loss 0.25961, 59.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08590, exact_match 0.86468, 4.16 secs\n",
      "\u001b[1m---- Epoch 108/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28289, s2s_loss 0.25890, 54.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08640, exact_match 0.86537, 4.72 secs\n",
      "\u001b[1m---- Epoch 109/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.10677, s2s_loss 0.26473, 57.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09015, exact_match 0.85010, 4.53 secs\n",
      "\u001b[1m---- Epoch 110/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.24288, s2s_loss 0.26947, 58.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09995, exact_match 0.84802, 4.85 secs\n",
      "\u001b[1m---- Epoch 111/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.08552, s2s_loss 0.26592, 56.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09301, exact_match 0.86051, 4.60 secs\n",
      "\u001b[1m---- Epoch 112/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.20729, s2s_loss 0.26149, 56.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08573, exact_match 0.86676, 4.49 secs\n",
      "\u001b[1m---- Epoch 113/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.35323, s2s_loss 0.25406, 56.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08893, exact_match 0.85843, 4.93 secs\n",
      "\u001b[1m---- Epoch 114/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.34090, s2s_loss 0.25871, 56.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08848, exact_match 0.86051, 4.99 secs\n",
      "\u001b[1m---- Epoch 115/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.35805, s2s_loss 0.26241, 59.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08761, exact_match 0.86260, 4.55 secs\n",
      "\u001b[1m---- Epoch 116/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15179, s2s_loss 0.25504, 57.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08800, exact_match 0.85843, 4.48 secs\n",
      "\u001b[1m---- Epoch 117/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.33193, s2s_loss 0.26171, 58.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09177, exact_match 0.85219, 4.45 secs\n",
      "\u001b[1m---- Epoch 118/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.32170, s2s_loss 0.26502, 56.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08655, exact_match 0.85982, 4.80 secs\n",
      "\u001b[1m---- Epoch 119/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.15098, s2s_loss 0.26567, 57.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08109, exact_match 0.86537, 4.36 secs\n",
      "\u001b[1m---- Epoch 120/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.34204, s2s_loss 0.25592, 55.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08605, exact_match 0.86051, 4.76 secs\n",
      "\u001b[1m---- Epoch 121/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.13629, s2s_loss 0.25676, 55.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08129, exact_match 0.86468, 5.17 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_121_exact_match+s2s_loss=0.8848.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 122/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21249, s2s_loss 0.25791, 56.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08292, exact_match 0.86398, 4.86 secs\n",
      "\u001b[1m---- Epoch 123/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.15692, s2s_loss 0.25710, 58.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08228, exact_match 0.86607, 4.50 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_123_exact_match+s2s_loss=0.8851.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 124/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24549, s2s_loss 0.25639, 57.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08289, exact_match 0.86607, 4.84 secs\n",
      "\u001b[1m---- Epoch 125/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.06793, s2s_loss 0.26934, 58.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08645, exact_match 0.86468, 4.75 secs\n",
      "\u001b[1m---- Epoch 126/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.27813, s2s_loss 0.28304, 56.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08915, exact_match 0.85635, 4.44 secs\n",
      "\u001b[1m---- Epoch 127/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.17435, s2s_loss 0.26723, 57.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09157, exact_match 0.86260, 4.57 secs\n",
      "\u001b[1m---- Epoch 128/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.24203, s2s_loss 0.26222, 57.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08650, exact_match 0.86329, 4.62 secs\n",
      "\u001b[1m---- Epoch 129/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.25583, s2s_loss 0.26005, 58.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08741, exact_match 0.86329, 4.62 secs\n",
      "\u001b[1m---- Epoch 130/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.17069, s2s_loss 0.25456, 56.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08689, exact_match 0.86190, 4.55 secs\n",
      "\u001b[1m---- Epoch 131/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.42285, s2s_loss 0.26214, 56.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08749, exact_match 0.86051, 3.92 secs\n",
      "\u001b[1m---- Epoch 132/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.23361, s2s_loss 0.24429, 56.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08701, exact_match 0.86051, 4.27 secs\n",
      "\u001b[1m---- Epoch 133/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.22078, s2s_loss 0.27189, 56.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.10944, exact_match 0.82998, 4.82 secs\n",
      "\u001b[1m---- Epoch 134/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.60741, s2s_loss 0.27113, 57.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08830, exact_match 0.85982, 4.92 secs\n",
      "\u001b[1m---- Epoch 135/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.10985, s2s_loss 0.26687, 57.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08789, exact_match 0.86051, 4.85 secs\n",
      "\u001b[1m---- Epoch 136/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.18828, s2s_loss 0.25863, 55.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09094, exact_match 0.85427, 4.37 secs\n",
      "\u001b[1m---- Epoch 137/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.18142, s2s_loss 0.25515, 56.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08492, exact_match 0.86329, 4.71 secs\n",
      "\u001b[1m---- Epoch 138/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.30317, s2s_loss 0.25652, 57.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08690, exact_match 0.85913, 4.77 secs\n",
      "\u001b[1m---- Epoch 139/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20733, s2s_loss 0.25327, 57.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08562, exact_match 0.86051, 4.28 secs\n",
      "\u001b[1m---- Epoch 140/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15567, s2s_loss 0.25952, 54.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08568, exact_match 0.86121, 3.72 secs\n",
      "\u001b[1m---- Epoch 141/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.27436, s2s_loss 0.26052, 54.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09035, exact_match 0.86676, 3.67 secs\n",
      "\u001b[1m---- Epoch 142/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.39685, s2s_loss 0.26882, 54.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08938, exact_match 0.86190, 3.69 secs\n",
      "\u001b[1m---- Epoch 143/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18029, s2s_loss 0.27034, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08388, exact_match 0.86884, 3.72 secs\n",
      "\u001b[1m---- Epoch 144/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.38955, s2s_loss 0.26274, 54.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08552, exact_match 0.86676, 3.72 secs\n",
      "\u001b[1m---- Epoch 145/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.34551, s2s_loss 0.26209, 55.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08611, exact_match 0.86676, 3.60 secs\n",
      "\u001b[1m---- Epoch 146/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.27143, s2s_loss 0.25355, 54.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08536, exact_match 0.86468, 3.67 secs\n",
      "\u001b[1m---- Epoch 147/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.17243, s2s_loss 0.26047, 54.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08618, exact_match 0.86329, 3.68 secs\n",
      "\u001b[1m---- Epoch 148/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15054, s2s_loss 0.25228, 54.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08621, exact_match 0.86398, 3.70 secs\n",
      "\u001b[1m---- Epoch 149/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.06863, s2s_loss 0.26524, 55.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09076, exact_match 0.84941, 3.70 secs\n",
      "\u001b[1m---- Epoch 150/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31178, s2s_loss 0.26060, 52.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08934, exact_match 0.86468, 3.68 secs\n",
      "\u001b[1m---- Epoch 151/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.30988, s2s_loss 0.26376, 54.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09240, exact_match 0.85843, 3.68 secs\n",
      "\u001b[1m---- Epoch 152/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.19061, s2s_loss 0.25186, 54.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08306, exact_match 0.86676, 3.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_152_exact_match+s2s_loss=0.8854.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 153/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.17180, s2s_loss 0.25349, 55.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08367, exact_match 0.86954, 3.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_153_exact_match+s2s_loss=0.8863.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 154/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.31741, s2s_loss 0.25262, 55.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08285, exact_match 0.87162, 3.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_154_exact_match+s2s_loss=0.8876.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 155/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.14423, s2s_loss 0.25724, 54.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08359, exact_match 0.87162, 3.67 secs\n",
      "\u001b[1m---- Epoch 156/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.14910, s2s_loss 0.25757, 54.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08407, exact_match 0.87023, 3.68 secs\n",
      "\u001b[1m---- Epoch 157/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.25788, s2s_loss 0.26691, 54.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09108, exact_match 0.86537, 3.66 secs\n",
      "\u001b[1m---- Epoch 158/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.29744, s2s_loss 0.26644, 54.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08564, exact_match 0.86329, 3.66 secs\n",
      "\u001b[1m---- Epoch 159/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.21044, s2s_loss 0.26388, 54.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08434, exact_match 0.86815, 3.70 secs\n",
      "\u001b[1m---- Epoch 160/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.17936, s2s_loss 0.25964, 50.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08115, exact_match 0.87717, 3.60 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_160_exact_match+s2s_loss=0.8903.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 161/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.31675, s2s_loss 0.26194, 39.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08288, exact_match 0.87509, 3.71 secs\n",
      "\u001b[1m---- Epoch 162/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.54191, s2s_loss 0.25407, 43.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08069, exact_match 0.87717, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_162_exact_match+s2s_loss=0.8909.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 163/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.14331, s2s_loss 0.24983, 54.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08171, exact_match 0.87717, 3.69 secs\n",
      "\u001b[1m---- Epoch 164/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30199, s2s_loss 0.25227, 54.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08071, exact_match 0.87925, 3.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_164_exact_match+s2s_loss=0.8919.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 165/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.19455, s2s_loss 0.26400, 55.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09886, exact_match 0.85010, 3.69 secs\n",
      "\u001b[1m---- Epoch 166/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.47988, s2s_loss 0.26669, 54.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08391, exact_match 0.87509, 3.66 secs\n",
      "\u001b[1m---- Epoch 167/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18354, s2s_loss 0.26214, 54.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07961, exact_match 0.87509, 3.68 secs\n",
      "\u001b[1m---- Epoch 168/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.34294, s2s_loss 0.26445, 54.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08210, exact_match 0.87647, 3.66 secs\n",
      "\u001b[1m---- Epoch 169/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.14265, s2s_loss 0.24661, 54.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08299, exact_match 0.87370, 3.70 secs\n",
      "\u001b[1m---- Epoch 170/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.17549, s2s_loss 0.25807, 54.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08068, exact_match 0.87856, 3.67 secs\n",
      "\u001b[1m---- Epoch 171/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.28213, s2s_loss 0.25694, 54.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08012, exact_match 0.87994, 3.71 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_171_exact_match+s2s_loss=0.8922.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 172/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.11741, s2s_loss 0.24726, 54.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08043, exact_match 0.88064, 3.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_172_exact_match+s2s_loss=0.8930.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 173/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.16704, s2s_loss 0.25868, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08550, exact_match 0.86607, 3.69 secs\n",
      "\u001b[1m---- Epoch 174/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.34807, s2s_loss 0.26742, 54.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08343, exact_match 0.86815, 3.70 secs\n",
      "\u001b[1m---- Epoch 175/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.24466, s2s_loss 0.26497, 54.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08534, exact_match 0.86815, 3.68 secs\n",
      "\u001b[1m---- Epoch 176/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.11310, s2s_loss 0.25898, 54.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08477, exact_match 0.86954, 3.68 secs\n",
      "\u001b[1m---- Epoch 177/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.29509, s2s_loss 0.25251, 54.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08462, exact_match 0.86468, 3.70 secs\n",
      "\u001b[1m---- Epoch 178/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.13622, s2s_loss 0.25460, 54.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08324, exact_match 0.87162, 3.68 secs\n",
      "\u001b[1m---- Epoch 179/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.31425, s2s_loss 0.25507, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08443, exact_match 0.86607, 3.74 secs\n",
      "\u001b[1m---- Epoch 180/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.19361, s2s_loss 0.25140, 39.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08383, exact_match 0.86884, 3.69 secs\n",
      "\u001b[1m---- Epoch 181/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.25896, s2s_loss 0.25654, 40.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08257, exact_match 0.86815, 3.69 secs\n",
      "\u001b[1m---- Epoch 182/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.18321, s2s_loss 0.25692, 53.95 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.09844, exact_match 0.84386, 3.70 secs\n",
      "\u001b[1m---- Epoch 183/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.12458, s2s_loss 0.25502, 54.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08362, exact_match 0.87023, 3.70 secs\n",
      "\u001b[1m---- Epoch 184/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.11522, s2s_loss 0.25140, 54.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08465, exact_match 0.87162, 3.73 secs\n",
      "\u001b[1m---- Epoch 185/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.15843, s2s_loss 0.25524, 53.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08354, exact_match 0.87162, 3.63 secs\n",
      "\u001b[1m---- Epoch 186/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.38288, s2s_loss 0.25145, 54.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08354, exact_match 0.87231, 3.71 secs\n",
      "\u001b[1m---- Epoch 187/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.16932, s2s_loss 0.25514, 54.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08420, exact_match 0.86954, 3.69 secs\n",
      "\u001b[1m---- Epoch 188/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.18539, s2s_loss 0.25086, 54.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08294, exact_match 0.87231, 3.71 secs\n",
      "\u001b[1m---- Epoch 189/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.49187, s2s_loss 0.25983, 53.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07987, exact_match 0.88133, 3.72 secs\n",
      "\u001b[1m---- Epoch 190/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.16540, s2s_loss 0.26049, 53.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08760, exact_match 0.86607, 3.70 secs\n",
      "\u001b[1m---- Epoch 191/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.15071, s2s_loss 0.25347, 54.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07784, exact_match 0.87578, 3.71 secs\n",
      "\u001b[1m---- Epoch 192/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.27001, s2s_loss 0.26015, 54.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08183, exact_match 0.87300, 3.72 secs\n",
      "\u001b[1m---- Epoch 193/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.24225, s2s_loss 0.25496, 54.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08080, exact_match 0.87300, 3.70 secs\n",
      "\u001b[1m---- Epoch 194/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.20819, s2s_loss 0.25155, 53.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08359, exact_match 0.86815, 3.68 secs\n",
      "\u001b[1m---- Epoch 195/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.33805, s2s_loss 0.26150, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08102, exact_match 0.87162, 3.69 secs\n",
      "\u001b[1m---- Epoch 196/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24388, s2s_loss 0.25684, 54.63 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08090, exact_match 0.87300, 3.68 secs\n",
      "\u001b[1m---- Epoch 197/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.13239, s2s_loss 0.26383, 54.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09278, exact_match 0.86398, 3.70 secs\n",
      "\u001b[1m---- Epoch 198/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.28285, s2s_loss 0.25727, 55.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07960, exact_match 0.87231, 3.70 secs\n",
      "\u001b[1m---- Epoch 199/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18339, s2s_loss 0.25078, 54.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08795, exact_match 0.86468, 3.71 secs\n",
      "\u001b[1m---- Epoch 200/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.26443, s2s_loss 0.25647, 54.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08020, exact_match 0.88064, 3.68 secs\n",
      "\u001b[1m---- Epoch 201/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.13077, s2s_loss 0.25968, 54.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08025, exact_match 0.88064, 3.68 secs\n",
      "\u001b[1m---- Epoch 202/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.16220, s2s_loss 0.24963, 54.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07980, exact_match 0.87717, 3.71 secs\n",
      "\u001b[1m---- Epoch 203/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.09952, s2s_loss 0.24890, 55.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08040, exact_match 0.87925, 3.68 secs\n",
      "\u001b[1m---- Epoch 204/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10026, s2s_loss 0.25604, 54.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08052, exact_match 0.87856, 3.64 secs\n",
      "\u001b[1m---- Epoch 205/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.20904, s2s_loss 0.25633, 54.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08412, exact_match 0.87509, 3.67 secs\n",
      "\u001b[1m---- Epoch 206/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.10750, s2s_loss 0.26320, 54.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09613, exact_match 0.85427, 3.69 secs\n",
      "\u001b[1m---- Epoch 207/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.06512, s2s_loss 0.25289, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08391, exact_match 0.87231, 3.69 secs\n",
      "\u001b[1m---- Epoch 208/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.25712, s2s_loss 0.25387, 54.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08602, exact_match 0.86815, 3.68 secs\n",
      "\u001b[1m---- Epoch 209/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.23640, s2s_loss 0.25361, 54.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08406, exact_match 0.87162, 3.72 secs\n",
      "\u001b[1m---- Epoch 210/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.35769, s2s_loss 0.25138, 54.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08530, exact_match 0.86745, 3.71 secs\n",
      "\u001b[1m---- Epoch 211/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11150, s2s_loss 0.24786, 54.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08501, exact_match 0.86815, 3.74 secs\n",
      "\u001b[1m---- Epoch 212/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.04207, s2s_loss 0.25330, 54.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08474, exact_match 0.86815, 3.69 secs\n",
      "\u001b[1m---- Epoch 213/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.37620, s2s_loss 0.25853, 54.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.09341, exact_match 0.85357, 3.69 secs\n",
      "\u001b[1m---- Epoch 214/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31244, s2s_loss 0.26094, 54.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08086, exact_match 0.87856, 3.70 secs\n",
      "\u001b[1m---- Epoch 215/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.13937, s2s_loss 0.25104, 40.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08320, exact_match 0.87925, 3.67 secs\n",
      "\u001b[1m---- Epoch 216/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.11146, s2s_loss 0.25915, 53.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07935, exact_match 0.88133, 3.69 secs\n",
      "\u001b[1m---- Epoch 217/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22670, s2s_loss 0.25378, 54.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07972, exact_match 0.88480, 3.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_217_exact_match+s2s_loss=0.8947.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 218/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.19756, s2s_loss 0.24863, 49.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08145, exact_match 0.88550, 3.66 secs\n",
      "\u001b[1m---- Epoch 219/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20289, s2s_loss 0.25379, 54.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08054, exact_match 0.88758, 3.67 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_219_exact_match+s2s_loss=0.8956.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 220/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.32195, s2s_loss 0.24770, 54.86 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08036, exact_match 0.88758, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_220_exact_match+s2s_loss=0.8961.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 221/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.24316, s2s_loss 0.25406, 54.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08464, exact_match 0.86745, 3.72 secs\n",
      "\u001b[1m---- Epoch 222/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.16100, s2s_loss 0.25366, 54.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08679, exact_match 0.86190, 3.71 secs\n",
      "\u001b[1m---- Epoch 223/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.30468, s2s_loss 0.25943, 54.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08040, exact_match 0.87578, 3.70 secs\n",
      "\u001b[1m---- Epoch 224/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.16527, s2s_loss 0.24348, 54.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07949, exact_match 0.87231, 3.66 secs\n",
      "\u001b[1m---- Epoch 225/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.15510, s2s_loss 0.24897, 54.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07951, exact_match 0.87717, 3.68 secs\n",
      "\u001b[1m---- Epoch 226/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.35495, s2s_loss 0.25311, 54.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07986, exact_match 0.87509, 3.68 secs\n",
      "\u001b[1m---- Epoch 227/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.06911, s2s_loss 0.24391, 54.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08025, exact_match 0.87578, 3.73 secs\n",
      "\u001b[1m---- Epoch 228/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.47949, s2s_loss 0.24828, 54.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07955, exact_match 0.87647, 3.68 secs\n",
      "\u001b[1m---- Epoch 229/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.41936, s2s_loss 0.26483, 54.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08521, exact_match 0.86260, 3.70 secs\n",
      "\u001b[1m---- Epoch 230/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.06908, s2s_loss 0.26805, 54.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08600, exact_match 0.85774, 3.69 secs\n",
      "\u001b[1m---- Epoch 231/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20634, s2s_loss 0.26219, 54.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07969, exact_match 0.87231, 3.67 secs\n",
      "\u001b[1m---- Epoch 232/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.28635, s2s_loss 0.25809, 54.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07933, exact_match 0.87370, 3.69 secs\n",
      "\u001b[1m---- Epoch 233/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.10574, s2s_loss 0.25437, 55.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08003, exact_match 0.87717, 3.69 secs\n",
      "\u001b[1m---- Epoch 234/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.22465, s2s_loss 0.24536, 55.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07941, exact_match 0.87925, 3.69 secs\n",
      "\u001b[1m---- Epoch 235/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.31524, s2s_loss 0.25514, 54.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08029, exact_match 0.87578, 3.68 secs\n",
      "\u001b[1m---- Epoch 236/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10662, s2s_loss 0.24670, 54.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07978, exact_match 0.87925, 3.71 secs\n",
      "\u001b[1m---- Epoch 237/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.39122, s2s_loss 0.25350, 54.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08210, exact_match 0.87786, 3.68 secs\n",
      "\u001b[1m---- Epoch 238/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31722, s2s_loss 0.25672, 54.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08300, exact_match 0.87231, 3.70 secs\n",
      "\u001b[1m---- Epoch 239/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.58650, s2s_loss 0.24989, 54.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07790, exact_match 0.88688, 3.70 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_239_exact_match+s2s_loss=0.8966.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 240/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.24329, s2s_loss 0.25149, 54.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07771, exact_match 0.88272, 3.67 secs\n",
      "\u001b[1m---- Epoch 241/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.24532, s2s_loss 0.25002, 54.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07878, exact_match 0.88341, 3.67 secs\n",
      "\u001b[1m---- Epoch 242/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.38670, s2s_loss 0.25212, 54.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07854, exact_match 0.88203, 3.66 secs\n",
      "\u001b[1m---- Epoch 243/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26610, s2s_loss 0.25408, 54.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07855, exact_match 0.87786, 3.70 secs\n",
      "\u001b[1m---- Epoch 244/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16098, s2s_loss 0.25316, 54.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07877, exact_match 0.87856, 3.70 secs\n",
      "\u001b[1m---- Epoch 245/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.26798, s2s_loss 0.26001, 53.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08405, exact_match 0.87300, 3.67 secs\n",
      "\u001b[1m---- Epoch 246/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.42589, s2s_loss 0.26254, 54.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08638, exact_match 0.86607, 3.66 secs\n",
      "\u001b[1m---- Epoch 247/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.28291, s2s_loss 0.26090, 54.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07636, exact_match 0.88966, 3.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_247_exact_match+s2s_loss=0.8977.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 248/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.27102, s2s_loss 0.25113, 54.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07931, exact_match 0.88203, 3.71 secs\n",
      "\u001b[1m---- Epoch 249/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.22453, s2s_loss 0.24505, 55.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07909, exact_match 0.88064, 3.71 secs\n",
      "\u001b[1m---- Epoch 250/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21275, s2s_loss 0.24641, 55.05 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07987, exact_match 0.87786, 3.69 secs\n",
      "\u001b[1m---- Epoch 251/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.35440, s2s_loss 0.24616, 54.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07886, exact_match 0.87925, 3.72 secs\n",
      "\u001b[1m---- Epoch 252/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20232, s2s_loss 0.24171, 54.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07953, exact_match 0.87994, 3.73 secs\n",
      "\u001b[1m---- Epoch 253/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.48222, s2s_loss 0.25205, 53.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08880, exact_match 0.86121, 3.68 secs\n",
      "\u001b[1m---- Epoch 254/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.09966, s2s_loss 0.25276, 53.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08516, exact_match 0.87994, 3.69 secs\n",
      "\u001b[1m---- Epoch 255/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.41752, s2s_loss 0.24855, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08580, exact_match 0.86884, 3.67 secs\n",
      "\u001b[1m---- Epoch 256/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.29501, s2s_loss 0.25231, 54.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08188, exact_match 0.87231, 3.69 secs\n",
      "\u001b[1m---- Epoch 257/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.28829, s2s_loss 0.24443, 54.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07919, exact_match 0.87856, 3.70 secs\n",
      "\u001b[1m---- Epoch 258/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.33448, s2s_loss 0.25189, 54.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07971, exact_match 0.87786, 3.66 secs\n",
      "\u001b[1m---- Epoch 259/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21966, s2s_loss 0.25051, 55.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07921, exact_match 0.87786, 3.68 secs\n",
      "\u001b[1m---- Epoch 260/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38265, s2s_loss 0.24872, 54.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07855, exact_match 0.87925, 3.68 secs\n",
      "\u001b[1m---- Epoch 261/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.13462, s2s_loss 0.25498, 54.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08032, exact_match 0.87162, 3.68 secs\n",
      "\u001b[1m---- Epoch 262/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.35555, s2s_loss 0.25601, 54.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07324, exact_match 0.88619, 3.68 secs\n",
      "\u001b[1m---- Epoch 263/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.24344, s2s_loss 0.25726, 55.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07571, exact_match 0.88203, 3.68 secs\n",
      "\u001b[1m---- Epoch 264/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33519, s2s_loss 0.25373, 55.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07992, exact_match 0.87439, 3.70 secs\n",
      "\u001b[1m---- Epoch 265/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32762, s2s_loss 0.25237, 54.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07437, exact_match 0.89174, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_265_exact_match+s2s_loss=0.9000.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 266/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.31971, s2s_loss 0.24170, 54.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07421, exact_match 0.89174, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_266_exact_match+s2s_loss=0.9007.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 267/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.16289, s2s_loss 0.25192, 39.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07454, exact_match 0.88897, 3.72 secs\n",
      "\u001b[1m---- Epoch 268/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20724, s2s_loss 0.24598, 54.97 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07451, exact_match 0.88966, 3.71 secs\n",
      "\u001b[1m---- Epoch 269/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.33621, s2s_loss 0.25195, 54.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08079, exact_match 0.88411, 3.68 secs\n",
      "\u001b[1m---- Epoch 270/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.18194, s2s_loss 0.26098, 54.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08331, exact_match 0.87994, 3.69 secs\n",
      "\u001b[1m---- Epoch 271/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.10713, s2s_loss 0.24966, 54.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07928, exact_match 0.88619, 3.68 secs\n",
      "\u001b[1m---- Epoch 272/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.10130, s2s_loss 0.25210, 53.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08171, exact_match 0.87925, 3.71 secs\n",
      "\u001b[1m---- Epoch 273/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.24544, s2s_loss 0.25861, 53.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07850, exact_match 0.88550, 3.70 secs\n",
      "\u001b[1m---- Epoch 274/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.16617, s2s_loss 0.25133, 54.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07851, exact_match 0.88411, 3.63 secs\n",
      "\u001b[1m---- Epoch 275/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.29250, s2s_loss 0.24719, 54.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07843, exact_match 0.88758, 3.66 secs\n",
      "\u001b[1m---- Epoch 276/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.29836, s2s_loss 0.25215, 54.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07837, exact_match 0.88827, 3.68 secs\n",
      "\u001b[1m---- Epoch 277/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.11059, s2s_loss 0.25690, 54.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07880, exact_match 0.88619, 3.69 secs\n",
      "\u001b[1m---- Epoch 278/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31940, s2s_loss 0.25299, 54.00 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08294, exact_match 0.87300, 3.68 secs\n",
      "\u001b[1m---- Epoch 279/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.07660, s2s_loss 0.25085, 54.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07673, exact_match 0.89105, 3.70 secs\n",
      "\u001b[1m---- Epoch 280/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33263, s2s_loss 0.24448, 53.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07872, exact_match 0.88897, 3.72 secs\n",
      "\u001b[1m---- Epoch 281/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.28045, s2s_loss 0.25706, 54.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07857, exact_match 0.88550, 3.68 secs\n",
      "\u001b[1m---- Epoch 282/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21388, s2s_loss 0.24805, 54.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07820, exact_match 0.88758, 3.68 secs\n",
      "\u001b[1m---- Epoch 283/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.09972, s2s_loss 0.24762, 54.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07835, exact_match 0.88341, 3.69 secs\n",
      "\u001b[1m---- Epoch 284/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.32079, s2s_loss 0.24621, 54.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07841, exact_match 0.88480, 3.68 secs\n",
      "\u001b[1m---- Epoch 285/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.44727, s2s_loss 0.25663, 51.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08479, exact_match 0.86468, 3.70 secs\n",
      "\u001b[1m---- Epoch 286/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.32369, s2s_loss 0.25518, 54.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08144, exact_match 0.87162, 3.70 secs\n",
      "\u001b[1m---- Epoch 287/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20112, s2s_loss 0.25183, 54.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07875, exact_match 0.87162, 3.68 secs\n",
      "\u001b[1m---- Epoch 288/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.31366, s2s_loss 0.24477, 53.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07792, exact_match 0.88133, 3.66 secs\n",
      "\u001b[1m---- Epoch 289/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.31660, s2s_loss 0.25165, 55.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08051, exact_match 0.87231, 3.71 secs\n",
      "\u001b[1m---- Epoch 290/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.18068, s2s_loss 0.24285, 54.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07859, exact_match 0.87578, 3.69 secs\n",
      "\u001b[1m---- Epoch 291/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.22225, s2s_loss 0.24773, 54.20 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07910, exact_match 0.87647, 3.69 secs\n",
      "\u001b[1m---- Epoch 292/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.23848, s2s_loss 0.24409, 54.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07967, exact_match 0.87509, 3.69 secs\n",
      "\u001b[1m---- Epoch 293/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.35045, s2s_loss 0.25420, 54.73 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07644, exact_match 0.87647, 3.71 secs\n",
      "\u001b[1m---- Epoch 294/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.56821, s2s_loss 0.26183, 55.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08238, exact_match 0.87578, 3.70 secs\n",
      "\u001b[1m---- Epoch 295/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.28539, s2s_loss 0.25415, 55.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07789, exact_match 0.87717, 3.68 secs\n",
      "\u001b[1m---- Epoch 296/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.24105, s2s_loss 0.25384, 54.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07810, exact_match 0.87925, 3.71 secs\n",
      "\u001b[1m---- Epoch 297/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.25203, s2s_loss 0.24169, 54.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07964, exact_match 0.87578, 3.71 secs\n",
      "\u001b[1m---- Epoch 298/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.34510, s2s_loss 0.24955, 54.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07631, exact_match 0.88411, 3.70 secs\n",
      "\u001b[1m---- Epoch 299/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.33963, s2s_loss 0.24950, 54.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07672, exact_match 0.88133, 3.70 secs\n",
      "\u001b[1m---- Epoch 300/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20388, s2s_loss 0.24329, 54.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07706, exact_match 0.88203, 3.70 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240307_182751_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--batch_size 10 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"multitask\" \\\n",
    "--experiment_name \"nli+mlm\" \\\n",
    "--multitask_name_list \\\n",
    "\"nli\" \\\n",
    "\"mlm\" \\\n",
    "\"sentence2facts\" \\\n",
    "--task2weight '{\"nli\": 2.0, \"mlm\": 1.0, \"sentence2facts\": 0.0}' \\\n",
    "--sentence_to_facts_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\"\\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\" \\\n",
    "--integrated_nli_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\" \\\n",
    "--use_sentence2facts_for_nli \\\n",
    "--use_anli \\\n",
    "--use_multinli \\\n",
    "--use_snli \\\n",
    "--use_report_nli \\\n",
    "--use_report_nli_entailment_dataset \\\n",
    "--use_fact_based_reports_in_mlm \\\n",
    "--integrated_report_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\" \\\n",
    "--report_nli_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\" \\\n",
    "--paraphrased_inputs_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\" \\\n",
    "--only_validate_nli \\\n",
    "--nli1_only_on_train \\\n",
    "--nli1_only_on_val \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--t5_model_name \"facebook/bart-base\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 300\n",
      "   batches_per_epoch: 600\n",
      "   batch_size: 10\n",
      "   checkpoint_folder: None\n",
      "   seq2seq_model_name: bart\n",
      "   t5_model_name: facebook/bart-base\n",
      "   bart_model_name: facebook/bart-base\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240308_133455_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "   iters_to_accumulate: 20\n",
      "   override_lr: False\n",
      "   task_name: multitask\n",
      "   experiment_name: nli+mlm\n",
      "   multitask_name_list: ['nli', 'mlm', 'sentence2facts']\n",
      "   task2weight: {'nli': 2.0, 'mlm': 1.0, 'sentence2facts': 0.0}\n",
      "   val_size: 200\n",
      "   mlm_min_token_count: 20\n",
      "   mlm_masking_fraction: 0.15\n",
      "   integrated_facts_metadata_jsonl_filepath: None\n",
      "   paraphrased_inputs_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl']\n",
      "   chest_imagenome_phrases2labels_filepath: None\n",
      "   sentence_to_facts_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl']\n",
      "   fact_to_metadata_input_output_jsonl_filepaths: None\n",
      "   fact_to_comparison_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_obs_input_output_jsonl_filepaths: None\n",
      "   chest_imagenome_anatloc_input_output_jsonl_filepaths: None\n",
      "   report_nli_input_output_jsonl_filepaths: ['/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl', '/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl']\n",
      "   integrated_nli_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\n",
      "   integrated_report_facts_metadata_jsonl_filepath: /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "   use_sentence2facts_for_nli: True\n",
      "   use_anli: True\n",
      "   use_multinli: True\n",
      "   use_snli: True\n",
      "   use_report_nli: True\n",
      "   use_fact_based_reports_in_mlm: True\n",
      "   use_report_nli_entailment_dataset: True\n",
      "   only_validate_nli: True\n",
      "   nli1_only_on_train: True\n",
      "   nli1_only_on_val: True\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of Seq2SeqModel ...\u001b[0m\n",
      "Seq2Seq model:\n",
      "  model_name: facebook/bart-base\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\n",
      "1e-06 3 8e-05 8 1e-06 8e-05 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 20, max_grad_norm = None\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating Seq2SeqTrainer ...\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9891 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mB\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mbilateral\u001b[0m\n",
      "\u001b[1m\u001b[35mboth sides\u001b[0m\n",
      "\u001b[1m\u001b[35mboth\u001b[0m\n",
      "\u001b[1m\u001b[35mon both sides\u001b[0m\n",
      "\u001b[1m\u001b[35msymmetrical\u001b[0m\n",
      "\u001b[1m\u001b[35mequally on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mpresent on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mseen on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35moccurring on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mappearing on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mfound on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted on both sides\u001b[0m\n",
      "\u001b[1m\u001b[35mnoted bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mseen bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mobserved bilaterally\u001b[0m\n",
      "\u001b[1m\u001b[35mdetected bilaterally\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9890 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilus\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the left hilum\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleft to the hilum on the left side\u001b[0m\n",
      "\u001b[1m\u001b[35mleft side of the pulmonary hilum on the left\u001b[0m\n",
      "\u001b[1m\u001b[35mleftward to the hilum on the left side\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 8511 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary vasculature\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral lung vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary blood vessels\u001b[0m\n",
      "\u001b[1m\u001b[35mlung periphery vasculature\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature of the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels in the outer regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular network in the peripheral lung\u001b[0m\n",
      "\u001b[1m\u001b[35mperipheral pulmonary circulation\u001b[0m\n",
      "\u001b[1m\u001b[35mblood vessels supplying the outer areas of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mvasculature in the peripheral regions of the lung\u001b[0m\n",
      "\u001b[1m\u001b[35mpulmonary vessels in the lung periphery\u001b[0m\n",
      "\u001b[1m\u001b[35mvascular system in the outer regions of the lung\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "\u001b[1mLoaded 1864 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35ma\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mone\u001b[0m\n",
      "\u001b[1m\u001b[35msingle\u001b[0m\n",
      "\u001b[1m\u001b[35msole\u001b[0m\n",
      "\u001b[1m\u001b[35monly\u001b[0m\n",
      "\u001b[1m\u001b[35mindividual\u001b[0m\n",
      "\u001b[1m\u001b[35mlone\u001b[0m\n",
      "\u001b[1m\u001b[35msolitary\u001b[0m\n",
      "\u001b[1m\u001b[35munique\u001b[0m\n",
      "\u001b[1m\u001b[35mdistinct\u001b[0m\n",
      "\u001b[1m\u001b[35msingular\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14993 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimetres\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in size\u001b[0m\n",
      "\u001b[1m\u001b[35ma length of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35ma measurement of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35mmeasuring 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 centimeters in length\u001b[0m\n",
      "\u001b[1m\u001b[35ma size of 5 cm\u001b[0m\n",
      "\u001b[1m\u001b[35m5 cm in dimension\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14971 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited base\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained base\u001b[0m\n",
      "\u001b[1m\u001b[35mnarrowed base\u001b[0m\n",
      "\u001b[1m\u001b[35mlimited foundation\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted support\u001b[0m\n",
      "\u001b[1m\u001b[35mconstricted base\u001b[0m\n",
      "\u001b[1m\u001b[35mreduced base\u001b[0m\n",
      "\u001b[1m\u001b[35mdiminished base\u001b[0m\n",
      "\u001b[1m\u001b[35mrestricted bottom\u001b[0m\n",
      "\u001b[1m\u001b[35mconstrained footing\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14972 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visible\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot visualized\u001b[0m\n",
      "\u001b[1m\u001b[35mnot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot detectable\u001b[0m\n",
      "\u001b[1m\u001b[35mabsent\u001b[0m\n",
      "\u001b[1m\u001b[35mnot present\u001b[0m\n",
      "\u001b[1m\u001b[35munable to visualize\u001b[0m\n",
      "\u001b[1m\u001b[35mnot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mnot evident\u001b[0m\n",
      "\u001b[1m\u001b[35mnot identifiable\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 14965 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel loops\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal loops\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal segments\u001b[0m\n",
      "\u001b[1m\u001b[35mbowel segments\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal coils\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal twists\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal convolutions\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal turns\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal curvatures\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal windings\u001b[0m\n",
      "\u001b[1m\u001b[35mintestinal meanders\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 10000 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mRib number five\u001b[0m\n",
      "\u001b[1m\u001b[35mRib 5\u001b[0m\n",
      "\u001b[1m\u001b[35m5th rib bone\u001b[0m\n",
      "\u001b[1m\u001b[35mBone of the fifth rib\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth rib structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th rib\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costal bone\u001b[0m\n",
      "\u001b[1m\u001b[35mCostal bone number five\u001b[0m\n",
      "\u001b[1m\u001b[35m5th costae\u001b[0m\n",
      "\u001b[1m\u001b[35mCostae number five\u001b[0m\n",
      "\u001b[1m\u001b[35mFifth costae structure\u001b[0m\n",
      "\u001b[1m\u001b[35mStructure of the 5th costae\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9999 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT 2\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography exam\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan test\u001b[0m\n",
      "\u001b[1m\u001b[35mCT diagnostic imaging\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging technique\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan investigation\u001b[0m\n",
      "\u001b[1m\u001b[35mCT radiographic study\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography imaging procedure\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan evaluation\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9997 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mline location\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is located\u001b[0m\n",
      "\u001b[1m\u001b[35mThe position of the line is\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line can be seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is situated\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is found\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line appears\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is detected\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is identified\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is visible\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is present\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is observed\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is noted\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is seen\u001b[0m\n",
      "\u001b[1m\u001b[35mThe line is evident\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9994 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mnot apparent\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence of\u001b[0m\n",
      "\u001b[1m\u001b[35mNot visible\u001b[0m\n",
      "\u001b[1m\u001b[35mNot observable\u001b[0m\n",
      "\u001b[1m\u001b[35mNot detected\u001b[0m\n",
      "\u001b[1m\u001b[35mNot seen\u001b[0m\n",
      "\u001b[1m\u001b[35mNot present\u001b[0m\n",
      "\u001b[1m\u001b[35mAbsence of\u001b[0m\n",
      "\u001b[1m\u001b[35mLack of\u001b[0m\n",
      "\u001b[1m\u001b[35mNegative for\u001b[0m\n",
      "\u001b[1m\u001b[35mNo signs of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo findings of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo indications of\u001b[0m\n",
      "\u001b[1m\u001b[35mNo evidence suggesting\u001b[0m\n",
      "\u001b[1m\u001b[35mNo abnormalities detected\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 9996 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mCT on\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan done\u001b[0m\n",
      "\u001b[1m\u001b[35mImaging study using computed tomography\u001b[0m\n",
      "\u001b[1m\u001b[35mRadiological examination using CT\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan taken\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging performed\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan carried out\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging study performed\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan conducted\u001b[0m\n",
      "\u001b[1m\u001b[35mComputed tomography study done\u001b[0m\n",
      "\u001b[1m\u001b[35mCT imaging examination\u001b[0m\n",
      "\u001b[1m\u001b[35mCT scan performed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of all-trans retinoic acid syndrome\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome not detected\u001b[0m\n",
      "\u001b[1m\u001b[35mall-trans retinoic acid syndrome is not observed\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19937 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant constriction\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno indication of notable narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of substantial narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of significant narrowing\u001b[0m\n",
      "\u001b[1m\u001b[35mlack of significant constriction\u001b[0m\n",
      "\u001b[1m\u001b[35mno presence of notable constriction\u001b[0m\n",
      "--------\n",
      "\u001b[1mLoaded 19943 paraphrased inputs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mno evidence of wheezing\u001b[0m\n",
      "\u001b[1mParaphrases:\u001b[0m\n",
      "\u001b[1m\u001b[35mno signs of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mabsence of wheezing\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing detected\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing observed\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing present\u001b[0m\n",
      "\u001b[1m\u001b[35mno wheezing found\u001b[0m\n",
      "--------\n",
      "\u001b[1mNumber of unique inputs: 190085\u001b[0m\n",
      "\u001b[1mNumber of total paraphrases: 2093173\u001b[0m\n",
      "Number of medical sentences from paraphrases: 2039914\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing sentence2facts dataset\u001b[0m\n",
      "Loaded 9999 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19971 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\n",
      "Loaded 19984 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\n",
      "Loaded 5000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\n",
      "Loaded 14990 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\n",
      "Loaded 14991 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\n",
      "\u001b[1mInput/output example:\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mS2F: There is new wall right basal consolidation that might potentially represent aspiration were interval development or infectious process.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35m[\"new wall right basal consolidation\", \"potential representation of aspiration\", \"potential representation of interval development\", \"potential representation of infectious process\"]\u001b[0m\n",
      "Number of train examples: 84935\n",
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing nli dataset\u001b[0m\n",
      "----\n",
      "Loading integrated NLI from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl...\n",
      "Number of samples: 169025\n",
      "Number of sources: 7\n",
      "----\n",
      "\u001b[1mLoading sentence2facts input/output pairs for NLI...\u001b[0m\n",
      "Number of entailment samples added: 184483\n",
      "----\n",
      "\u001b[1mLoading general domain datasets...\u001b[0m\n",
      "Loading ANLI...\n",
      "Number of ANLI R1 samples: 18946\n",
      "Number of ANLI R2 samples: 47460\n",
      "Number of ANLI R3 samples: 102859\n",
      "Loading MultiNLI...\n",
      "Number of MultiNLI train samples: 392702\n",
      "Number of MultiNLI dev_matched samples: 10000\n",
      "Number of MultiNLI dev_mismatched samples: 10000\n",
      "Loading SNLI...\n",
      "Number of SNLI train samples: 550152\n",
      "Number of SNLI dev samples: 10000\n",
      "Number of SNLI test samples: 10000\n",
      "----\n",
      "\u001b[1mLoading report NLI datasets...\u001b[0m\n",
      "Loaded 80000 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\n",
      "Loaded 58072 input/output pairs from /home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\n",
      "----\n",
      "\u001b[1mBuilding train NLI dataset...\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: contradiction -> 79430 (4312.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The right lower lobe consolidation seen on radiograph has substantially worsened and most likely consistent with progression of aspiration. #H: The right lower lobe consolidation seen on radiograph has substantially improved and most likely consistent with resolution of aspiration.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: contradiction -> 10732 (2400.52)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No pleural effusion, pneumothorax, or consolidation is seen. #H: Probably small left pleural effusion.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: contradiction -> 4170 (1739.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No pleural effusion or pneumothorax is seen either. #H: Moderate to Large bilateral pleural effusions right greater than left are unchanged associated with adjacent atelectasis.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: contradiction -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Tonsilectomy L arm ORIF Recent teeth surgery #H:  The patient has no surgical history.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: contradiction -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Obstetrical history was notable for 2 [** Location **]us sections in [**3452**] at 28 weeks gestation and [**3457**] at 36 weeks gestation. #H:  She has a history of infertility\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: contradiction -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Pt received  1 L NS. #H:  the patient did not recieve fluids\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: contradiction -> 106 (304.54)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No pleural effusion or pneumothorax is seen. #H: A small left pleural effusion is also likely present.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: anli | Label: contradiction -> 44089 (3672.32)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Months ago, CEO John Stumpf praised the executive in hot water as “a standard-bearer” for the bank. Wells Fargo & Co’s WFC -0.45% “sandbagger”-in-chief is leaving the giant bank with an enormous pay day—$124.6 million. Come on U.S. Code When is enough going to be enough???? #H: John Stumpf is the CEO of Standard Chartered bank. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: contradiction -> 137356 (4971.81)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: absolutely that's what happened to us we had a boat for several years in early marriage and along came the kids and it kind of sat there #H: I've been boating the whole time, even since I had kids.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: snli | Label: contradiction -> 189702 (5390.10)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Andy Rodderick gets ready to hit a tennis ball. #H: Andy Rodderick playing basketball.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_facts | Label: contradiction -> 14141 (2620.99)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: PA chest view obtained with patient in upright position. lateral chest view obtained with patient in upright position. heart size at the upper limit of normal variation. no typical configurational abnormality. mildly widened thoracic aorta. elongated thoracic aorta. no local contour abnormalities in the thoracic aorta. no wall calcifications in the thoracic aorta. pulmonary vasculature not congested. no signs of acute parenchymal infiltrates. no signs of chronic parenchymal infiltrates. free lateral pleural sinuses. free posterior pleural sinuses. unremarkable superior portion of the apex. no evidence of masses in superior mediastinum. no evidence of masses in retrosternal position. skeletal structures grossly within normal limits. mild degree of diffuse demineralization in the vertebral bodies of the thoracic spine #H: no radiographic abnormalities\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_labels | Label: contradiction -> 11641 (2464.16)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: hyperexpanded lungs. diffuse hyperlucency. widening of the retrosternal clear space. questionable opacity in the right superior mediastinum. questionable opacity underlying the sternoclavicular junction. irregular pleural scarring at the left lung apex. normal cardiomediastinal contours. normal hilar contours. probable small hiatal hernia. no pleural effusions. no pneumothorax. COPD. questionable opacity in the right lung apex. repeat PA chest radiograph. repeat apical lordotic view #H: mediastinal widening seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[93mGeneral datasets for label contradiction: 3\u001b[0m\n",
      "\u001b[93mMedical datasets for label contradiction: 7\u001b[0m\n",
      "\u001b[93mMedical report from facts datasets for label contradiction: 1\u001b[0m\n",
      "\u001b[93mMedical report from labels datasets for label contradiction: 1\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: entailment -> 13185 (2563.82)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The mediastinum is unremarkable. #H: Mediastinum appears normal.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: entailment -> 5445 (1911.57)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are low lung volumes with crowding of the bronchovascular markings. #H: The lungs are low, with resultant crowding of the bronchovascular markings.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: entailment -> 1770 (1256.05)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Frontal and lateral chest radiographs demonstrate unremarkable cardiomediastinal and hilar silhouettes. #H: The cardiomediastinal and contours are within normal limits.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: entailment -> 3744 (1672.60)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: At [**Hospital1 294**], initial HCT there was 41 --> dropped to 26. #H:  The patient had an acute bleed. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: entailment -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: She received a total of 4 L NS in the Ed. #H:  Patient has been resuscitated\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: entailment -> 473 (701.58)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The PDA and posterolateral vessels had 90% ostial lesions. #H:  Patient has multivessel disease\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: entailment -> 93 (279.62)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: No pleural effusions. #H: There is no pleural effusions.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSource: s2f | Label: entailment -> 184483 (5353.06)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There is blunting of the costophrenic sulci consistent with small effusions and possibly pleural thickening. #H: pleural thickening\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: anli | Label: entailment -> 54251 (3890.16)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Sea Lion Park was a 16 acre amusement park started in 1895 on Coney Island by Paul Boyton. He fenced the property and charged admission, the park becoming the first enclosed and permanent amusement park in North America. Up until the establishment of this park, amusement areas around the country consisted of pay-as-you-go concessions. In 1903, Sea Lion Park was replaced by Luna Park. #H: Sea Lion Park was a 16 acre amusement park started in 1895 but was replaced by another park in a very short period of time.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: entailment -> 137841 (4976.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The Rising is commemorated in the main hall by a beautiful bronze statue of the mythic folk hero Cuchulainn. #H: The main hall has a beautiful statue in it.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: snli | Label: entailment -> 190113 (5392.98)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A group of climbers in silhouette stare towards the sun over the mountaintops. #H: A group of climbers stare towards the sun.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_facts | Label: entailment -> 43411 (3656.37)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: ET tube 3.7cm above the carina. the PICC line catheter tip in the mid-to-lower SVC. NG tube tip in expected region of stomach. Right IJ catheter sheath tip at the confluence of the right IJ and right subclavian veins. Mild cardiomegaly. silhouette slightly accentuated by low lung vol. moderate right pleural effusion. small left pleural effusion. adjacent bibasilar opacities. likely atelectasis. infectious process can't be excluded. increased pulmonary vascular engorgement. mild pulmonary edema. ET tube 3.7 cm above the carina. PICC line catheter tip in the mid axillary vein. PICC line catheter tip not seen extending beyond this point. left subclavian line tip in the SVC. increased pulmonary vascular congestion. moderate cardiomegaly. bilateral pleural effusions. right pulmonary vascular redistribution. left pulmonary vascular redistribution. alveolar edema. Increased CHF #H: tip of PICC line in mid SVC region\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_labels | Label: entailment -> 33940 (3409.34)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: severe chronic bronchiectasis. peribronchial infiltration. severely enlarged hila. consolidation in the left midlung. increase in the retention of secretions in severe bronchiectasis in the right upper lobe. scarring in the right upper lobe. minimal improvement. heart obscured by pleural parenchymal abnormalities. continuous transvenous pacemaker leads from the left axillary generator. tip of the atrial lead included on this study. unchanged position of the atrial lead. no pneumothorax. small left pleural effusion #H: bronchiectasis seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[93mGeneral datasets for label entailment: 3\u001b[0m\n",
      "\u001b[93mMedical datasets for label entailment: 8\u001b[0m\n",
      "FactBasedReportEntailmentDataset\n",
      "Loaded 227835 reports from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "\u001b[93mMedical report from facts datasets for label entailment: 2\u001b[0m\n",
      "\u001b[93mMedical report from labels datasets for label entailment: 1\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613 | Label: neutral -> 19123 (2877.24)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There has been interval placement of a left pigtail pleural catheter. #H: Dr. has been notified by telephone of this result at 4 p.m. on .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-1106-preview_reasoning-prompt | Label: neutral -> 16675 (2758.96)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiac and mediastinal silhouettes are stable appearance. #H: The cardiac silhouette does not appear enlarged.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: gpt-4-0613_reasoning-prompt | Label: neutral -> 3968 (1708.29)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Bones are normal in appearance. #H: The hilar silhouettes are normal.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_train | Label: neutral -> 3743 (1672.44)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Was stable on Lithium for several years, has also been treated with Risperdal. (but pt. has been resistant and often non-compliant to increased doses of Risperdal, goal had been 2-4mg PO BID). #H:  Pt has a history of hallucinations and delusions\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_dev | Label: neutral -> 465 (695.76)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Family reports loss of consciousness. #H:  the patient had a seizure\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: mednli_test | Label: neutral -> 474 (702.30)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Her chronic obstructive pulmonary disease was diagnosed approximately three years ago. #H:  The patient is a chronic smoker. \u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: radnli_dev | Label: neutral -> 281 (538.25)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The lungs are clear. #H: Lung volumes are low.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: anli | Label: neutral -> 70925 (4184.18)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: A New Kind of Army is a punk rock album originally released by Anti-Flag on May 25, 1999. It was reissued by A-F Records on October 19, 2004 and is also the only album to feature only Justin Sane as lead vocalist. All other albums featured at least one song sung by either Andy Flag or Chris #2. #H: The album was originally released on Epitaph Records.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: multinli | Label: neutral -> 137152 (4969.93)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: It would take the mountainous man a long time to pull it free but he never got the chance. #H: He died before he could retrieve it.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: snli | Label: neutral -> 189218 (5386.70)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Man with a yellow jacket is riding a motorbike through a street marketplace filled with people and vendors. #H: The man is talented.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_facts | Label: neutral -> 22448 (3019.89)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: improved heterogeneous opacities in the right lung. residual opacification most confluent in the right upper lobe. concerning for pneumonia. new patchy opacities at the left lung base. moderate right pleural effusion. metastatic disease in the thorax #H: left subclavian pacer in place\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mSource: report_nli_from_labels | Label: neutral -> 12491 (2520.23)\u001b[0m\n",
      "Example:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: hyperexpanded lungs. flattening of the diaphragms. suggestive of COPD. no focal consolidation within the lungs. no infectious process. normal cardiomediastinal silhouette. normal hilar contours. retrocardiac density. moderate to large hiatal hernia. no evidence of pulmonary edema. no evidence of pleural effusion. no evidence of pneumothorax #H: chest port seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[93mGeneral datasets for label neutral: 3\u001b[0m\n",
      "\u001b[93mMedical datasets for label neutral: 7\u001b[0m\n",
      "\u001b[93mMedical report from facts datasets for label neutral: 1\u001b[0m\n",
      "\u001b[93mMedical report from labels datasets for label neutral: 1\u001b[0m\n",
      "----\n",
      "Number of RadNLI test samples: 480\n",
      "Number of MS_CXR_T samples: 361\n",
      "Number of report NLI samples added to val: 300\n",
      "Number of report NLI samples added to val: 300\n",
      "Number of val NLI samples: 1441\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The cardiac and mediastinal silhouettes are stable. #H: No abnormal hilar or mediastinal contours.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: There are no pleural effusions. #H: There is no pleural effusion or pneumothorax.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: The mediastinal silhouette, hilar contours, and pleural surfaces are normal. #H: The hilar and mediastinal silhouettes are unremarkable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: frontal view. lateral view. Chest frontal chest. Chest lateral chest. small bilateral pleural effusions. blunting of the posterior costophrenic angles. no focal consolidation. no pneumothorax. moderately enlarged cardiac silhouette. unremarkable mediastinal contours. no overt pulmonary edema. moderate cardiomegaly #H: calcified texture seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: opacity projecting over the lateral right upper hemithorax. opacity may be external to the patient. no pleural effusion. no pneumothorax. unremarkable cardiac silhouette. unremarkable mediastinal silhouette. no evidence of free air beneath the diaphragms. no priors for comparison. correlation for external artifact at this location. removal of external artifact. removal of oblique views. no focal consolidation seen elsewhere #H: overlying trauma board obscures detailed evaluation\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "----\n",
      "\u001b[1mBuilding val NLI dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m----------------------------------------\u001b[0m\n",
      "\u001b[1mPreparing mlm dataset\u001b[0m\n",
      "Number of general sentences: 1377099\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 1377099\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 1377099/1377099 [00:08<00:00, 158334.76it/s]\n",
      "\tlen(valid_tokens): 21522\n",
      "100%|██████████████████████████████| 1377099/1377099 [00:22<00:00, 61997.47it/s]\n",
      "Number of sentences: 1348333\n",
      "Number of bins: 7\n",
      "Bin size: 958219, weight: 7845.006940358202\n",
      "Bin size: 219530, weight: 5586.745498624757\n",
      "Bin size: 110971, weight: 4707.694773844805\n",
      "Bin size: 46036, weight: 3717.013976819967\n",
      "Bin size: 8332, weight: 2209.4180153128023\n",
      "Bin size: 4974, weight: 1851.8906668241702\n",
      "Bin size: 271, weight: 527.9351334797618\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: A man in blue walks [tok1] a crowd of women .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] past\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: The [tok1] is pissed at someone .\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] man\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: and she 's doing it i mean it 's not [tok1] it 's like\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] like\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: A man rides on the [tok1]\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] water\u001b[0m\n",
      "Loaded 227835 reports from /home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\n",
      "Number of medical sentences: 2932778\n",
      "Preparing masked LM dataset with masking\n",
      "\tmin_token_count: 20\n",
      "\tmasking_fraction: 0.15\n",
      "\tlen(sentences): 2932778\n",
      "Tokenizing sentences...\n",
      "Lowercasing tokens...\n",
      "100%|█████████████████████████████| 2932778/2932778 [00:20<00:00, 146524.37it/s]\n",
      "\tlen(valid_tokens): 8359\n",
      "100%|██████████████████████████████| 2932778/2932778 [00:41<00:00, 71204.85it/s]\n",
      "Number of sentences: 2906418\n",
      "Number of bins: 10\n",
      "Bin size: 1207182, weight: 8246.340215553266\n",
      "Bin size: 689250, weight: 7295.365215618737\n",
      "Bin size: 564608, weight: 6975.4143925643\n",
      "Bin size: 322873, weight: 6129.097132424093\n",
      "Bin size: 100852, weight: 4592.407749770934\n",
      "Bin size: 17524, weight: 2801.4586201952056\n",
      "Bin size: 3528, weight: 1636.6220215729345\n",
      "Bin size: 296, weight: 553.2771321660764\n",
      "Bin size: 165, weight: 399.7165542494086\n",
      "Bin size: 140, weight: 362.3577604078641\n",
      "Examples:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: upper most [tok1] of the stomach\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] portion\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: Right mid [tok1] displays a linear density\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] lung\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: mild infiltrate [tok1] in the right basal area\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] seen\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[35mMLM: There is scarring of the [tok1] in the left lung\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[35m[tok1] pleura\u001b[0m\n",
      "----------------------------------------\n",
      "Number of train datasets: 3\n",
      "Number of val datasets: 1\n",
      "\u001b[93m\u001b[1mWARNING: CompositeInfiniteDataset(): Removed 1 datasets with zero weight\u001b[0m\n",
      "----------------------------------------\n",
      "Examples of val datasets:\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: intra-aortic balloon pump has been removed. Swan-Ganz catheter with distal tip near the main pulmonary artery trunk. nasogastric tube with sideport above the GE junction. nasogastric tube should be advanced several centimeters for more optimal placement. endotracheal tube 6.7 cm above the carina. normal heart size. clear lungs. no pneumothoraces #H: no abnormalities seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: endotracheal tube tip lies approximately 3.5 cm above the carina. nasogastric tube extends into the stomach. side hole of nasogastric tube probably just distal to the esophagogastric junction. diffuse bilateral pulmonary opacifications. severe pulmonary edema associated with cardiomegaly. hazy opacification at the bases. layering pleural effusions at the bases. compressive atelectasis at the bases #H: endotracheal tube seen\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mentailment\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: moderate to severe enlargement of the cardiac silhouette. prominence of the interstitial markings. no large effusion. no confluent consolidation. intact median sternotomy wires. left-sided venous catheter identified extending to the midline. tip of the catheter not clearly delineated. no acute osseous abnormalities. enlargement potentially due to cardiomegaly. enlargement potentially due to pericardial effusion. vascular congestion. no evidence of overt pulmonary edema #H: effusions obscuring the cardiac borders\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mcontradiction\u001b[0m\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\u001b[1m\u001b[35mNLI1: Lung volumes are reduced. #H: Heart size is stable.\u001b[0m\n",
      "\u001b[1mOutput:\u001b[0m\n",
      "\u001b[1m\u001b[35mneutral\u001b[0m\n",
      "seq2seq_trainer.name =  multitask(nli+mlm)\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240310_092411_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240310_092411_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_266_exact_match+s2s_loss=0.9007.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240308_133455_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/checkpoint_266_exact_match+s2s_loss=0.9007.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240310_092411_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.37122, s2s_loss 0.24777, 56.84 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06906, exact_match 0.90562, 4.68 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_exact_match+s2s_loss=0.9086.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.16025, s2s_loss 0.24383, 54.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06924, exact_match 0.90007, 4.23 secs\n",
      "\u001b[1m---- Epoch 3/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.38472, s2s_loss 0.24198, 54.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06997, exact_match 0.89591, 4.49 secs\n",
      "\u001b[1m---- Epoch 4/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.29363, s2s_loss 0.25319, 55.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07417, exact_match 0.88688, 4.41 secs\n",
      "\u001b[1m---- Epoch 5/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000046) ...\n",
      "loss 0.22846, s2s_loss 0.25723, 55.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07453, exact_match 0.89105, 4.18 secs\n",
      "\u001b[1m---- Epoch 6/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.47469, s2s_loss 0.24802, 55.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07403, exact_match 0.89105, 4.53 secs\n",
      "\u001b[1m---- Epoch 7/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.23458, s2s_loss 0.25042, 51.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07516, exact_match 0.89174, 4.44 secs\n",
      "\u001b[1m---- Epoch 8/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.09951, s2s_loss 0.24927, 55.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06956, exact_match 0.89729, 3.98 secs\n",
      "\u001b[1m---- Epoch 9/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.27802, s2s_loss 0.24495, 53.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06998, exact_match 0.89868, 4.11 secs\n",
      "\u001b[1m---- Epoch 10/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.35864, s2s_loss 0.24469, 53.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06971, exact_match 0.89729, 4.53 secs\n",
      "\u001b[1m---- Epoch 11/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.08233, s2s_loss 0.25167, 57.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06859, exact_match 0.89868, 4.19 secs\n",
      "\u001b[1m---- Epoch 12/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24881, s2s_loss 0.24929, 54.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06909, exact_match 0.89799, 4.41 secs\n",
      "\u001b[1m---- Epoch 13/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.40029, s2s_loss 0.24651, 53.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08486, exact_match 0.86676, 4.35 secs\n",
      "\u001b[1m---- Epoch 14/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.33632, s2s_loss 0.25585, 53.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07094, exact_match 0.89452, 4.49 secs\n",
      "\u001b[1m---- Epoch 15/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.14285, s2s_loss 0.25317, 54.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06682, exact_match 0.89660, 4.53 secs\n",
      "\u001b[1m---- Epoch 16/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.34151, s2s_loss 0.25496, 55.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07164, exact_match 0.88758, 4.51 secs\n",
      "\u001b[1m---- Epoch 17/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.21996, s2s_loss 0.25080, 54.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06937, exact_match 0.89382, 3.88 secs\n",
      "\u001b[1m---- Epoch 18/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.15964, s2s_loss 0.23875, 56.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07279, exact_match 0.89174, 4.35 secs\n",
      "\u001b[1m---- Epoch 19/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.06068, s2s_loss 0.24556, 56.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07053, exact_match 0.89035, 4.29 secs\n",
      "\u001b[1m---- Epoch 20/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21250, s2s_loss 0.24481, 54.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07099, exact_match 0.88897, 4.14 secs\n",
      "\u001b[1m---- Epoch 21/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.24616, s2s_loss 0.25965, 56.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07897, exact_match 0.87786, 4.44 secs\n",
      "\u001b[1m---- Epoch 22/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.32798, s2s_loss 0.25330, 56.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08556, exact_match 0.87717, 4.21 secs\n",
      "\u001b[1m---- Epoch 23/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.38673, s2s_loss 0.25722, 55.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07341, exact_match 0.89244, 4.17 secs\n",
      "\u001b[1m---- Epoch 24/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.20150, s2s_loss 0.24220, 59.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07411, exact_match 0.89105, 4.16 secs\n",
      "\u001b[1m---- Epoch 25/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.23279, s2s_loss 0.24197, 57.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07353, exact_match 0.89244, 4.37 secs\n",
      "\u001b[1m---- Epoch 26/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.19257, s2s_loss 0.24457, 53.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07351, exact_match 0.89521, 4.36 secs\n",
      "\u001b[1m---- Epoch 27/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.37120, s2s_loss 0.24903, 56.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07370, exact_match 0.89382, 4.37 secs\n",
      "\u001b[1m---- Epoch 28/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30301, s2s_loss 0.24713, 54.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07392, exact_match 0.89382, 4.32 secs\n",
      "\u001b[1m---- Epoch 29/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.17140, s2s_loss 0.24516, 55.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07619, exact_match 0.89382, 4.45 secs\n",
      "\u001b[1m---- Epoch 30/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.11109, s2s_loss 0.26136, 57.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07804, exact_match 0.89035, 4.25 secs\n",
      "\u001b[1m---- Epoch 31/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20282, s2s_loss 0.26551, 55.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07191, exact_match 0.89382, 4.32 secs\n",
      "\u001b[1m---- Epoch 32/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.08148, s2s_loss 0.25388, 56.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07126, exact_match 0.89244, 4.23 secs\n",
      "\u001b[1m---- Epoch 33/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.27094, s2s_loss 0.24583, 56.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07437, exact_match 0.88550, 4.23 secs\n",
      "\u001b[1m---- Epoch 34/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.36371, s2s_loss 0.24295, 55.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07177, exact_match 0.88966, 4.35 secs\n",
      "\u001b[1m---- Epoch 35/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.12375, s2s_loss 0.24181, 56.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07296, exact_match 0.89105, 4.61 secs\n",
      "\u001b[1m---- Epoch 36/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.11445, s2s_loss 0.24442, 56.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07315, exact_match 0.89174, 4.65 secs\n",
      "\u001b[1m---- Epoch 37/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.15503, s2s_loss 0.25331, 56.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07794, exact_match 0.88758, 4.43 secs\n",
      "\u001b[1m---- Epoch 38/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.19192, s2s_loss 0.25880, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08167, exact_match 0.87717, 4.70 secs\n",
      "\u001b[1m---- Epoch 39/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.16097, s2s_loss 0.25343, 55.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07644, exact_match 0.89035, 4.57 secs\n",
      "\u001b[1m---- Epoch 40/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.26150, s2s_loss 0.24461, 54.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08038, exact_match 0.87994, 4.38 secs\n",
      "\u001b[1m---- Epoch 41/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.30555, s2s_loss 0.24308, 54.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07664, exact_match 0.88688, 4.73 secs\n",
      "\u001b[1m---- Epoch 42/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.18992, s2s_loss 0.25359, 55.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07448, exact_match 0.89244, 4.40 secs\n",
      "\u001b[1m---- Epoch 43/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.17157, s2s_loss 0.24455, 55.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07351, exact_match 0.89452, 4.12 secs\n",
      "\u001b[1m---- Epoch 44/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.09443, s2s_loss 0.24358, 55.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07360, exact_match 0.89521, 4.46 secs\n",
      "\u001b[1m---- Epoch 45/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.37886, s2s_loss 0.25578, 58.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07391, exact_match 0.88827, 4.76 secs\n",
      "\u001b[1m---- Epoch 46/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.20409, s2s_loss 0.25468, 56.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06899, exact_match 0.89591, 4.90 secs\n",
      "\u001b[1m---- Epoch 47/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.17271, s2s_loss 0.26261, 57.36 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07343, exact_match 0.88827, 4.48 secs\n",
      "\u001b[1m---- Epoch 48/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.35161, s2s_loss 0.25097, 53.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07069, exact_match 0.89452, 4.59 secs\n",
      "\u001b[1m---- Epoch 49/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.21887, s2s_loss 0.24170, 58.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06956, exact_match 0.89799, 4.23 secs\n",
      "\u001b[1m---- Epoch 50/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.17485, s2s_loss 0.24319, 56.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06996, exact_match 0.89938, 4.43 secs\n",
      "\u001b[1m---- Epoch 51/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.43852, s2s_loss 0.24507, 55.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07091, exact_match 0.90076, 4.26 secs\n",
      "\u001b[1m---- Epoch 52/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.12004, s2s_loss 0.24316, 57.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07039, exact_match 0.90146, 4.65 secs\n",
      "\u001b[1m---- Epoch 53/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.27706, s2s_loss 0.24349, 55.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07245, exact_match 0.88688, 4.72 secs\n",
      "\u001b[1m---- Epoch 54/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.13043, s2s_loss 0.25906, 55.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07069, exact_match 0.89591, 4.56 secs\n",
      "\u001b[1m---- Epoch 55/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.23292, s2s_loss 0.24952, 58.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07648, exact_match 0.88272, 4.42 secs\n",
      "\u001b[1m---- Epoch 56/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.29940, s2s_loss 0.24013, 56.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07114, exact_match 0.88966, 4.27 secs\n",
      "\u001b[1m---- Epoch 57/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.17531, s2s_loss 0.24217, 55.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07194, exact_match 0.88758, 4.43 secs\n",
      "\u001b[1m---- Epoch 58/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.11607, s2s_loss 0.24537, 56.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07354, exact_match 0.89105, 4.45 secs\n",
      "\u001b[1m---- Epoch 59/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.10616, s2s_loss 0.24555, 55.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07221, exact_match 0.88897, 4.57 secs\n",
      "\u001b[1m---- Epoch 60/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20074, s2s_loss 0.24263, 56.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07142, exact_match 0.88827, 4.45 secs\n",
      "\u001b[1m---- Epoch 61/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.31268, s2s_loss 0.25249, 57.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07929, exact_match 0.88133, 4.75 secs\n",
      "\u001b[1m---- Epoch 62/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.23584, s2s_loss 0.24952, 55.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07458, exact_match 0.89105, 4.24 secs\n",
      "\u001b[1m---- Epoch 63/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.17991, s2s_loss 0.25032, 56.43 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06912, exact_match 0.89799, 4.47 secs\n",
      "\u001b[1m---- Epoch 64/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.09314, s2s_loss 0.24226, 55.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07041, exact_match 0.89521, 4.55 secs\n",
      "\u001b[1m---- Epoch 65/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.13534, s2s_loss 0.24532, 55.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07074, exact_match 0.89244, 4.65 secs\n",
      "\u001b[1m---- Epoch 66/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.45585, s2s_loss 0.24538, 57.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07074, exact_match 0.89591, 4.16 secs\n",
      "\u001b[1m---- Epoch 67/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.17494, s2s_loss 0.24431, 56.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06989, exact_match 0.89591, 4.20 secs\n",
      "\u001b[1m---- Epoch 68/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.14846, s2s_loss 0.24494, 56.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06952, exact_match 0.89729, 4.94 secs\n",
      "\u001b[1m---- Epoch 69/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.20244, s2s_loss 0.24382, 54.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07829, exact_match 0.88203, 4.58 secs\n",
      "\u001b[1m---- Epoch 70/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.20262, s2s_loss 0.25522, 53.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07298, exact_match 0.89382, 4.54 secs\n",
      "\u001b[1m---- Epoch 71/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.21809, s2s_loss 0.24708, 54.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07691, exact_match 0.88758, 4.56 secs\n",
      "\u001b[1m---- Epoch 72/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.06671, s2s_loss 0.24401, 56.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07371, exact_match 0.89660, 4.48 secs\n",
      "\u001b[1m---- Epoch 73/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.09024, s2s_loss 0.24852, 56.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07202, exact_match 0.89938, 4.48 secs\n",
      "\u001b[1m---- Epoch 74/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.28460, s2s_loss 0.24592, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07494, exact_match 0.88827, 4.31 secs\n",
      "\u001b[1m---- Epoch 75/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.13254, s2s_loss 0.25574, 54.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07363, exact_match 0.89591, 4.53 secs\n",
      "\u001b[1m---- Epoch 76/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.10882, s2s_loss 0.24053, 57.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07371, exact_match 0.89382, 4.29 secs\n",
      "\u001b[1m---- Epoch 77/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.04954, s2s_loss 0.24541, 55.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07443, exact_match 0.89382, 4.35 secs\n",
      "\u001b[1m---- Epoch 78/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.31335, s2s_loss 0.25497, 55.18 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07473, exact_match 0.89035, 4.52 secs\n",
      "\u001b[1m---- Epoch 79/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.33331, s2s_loss 0.24567, 56.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06986, exact_match 0.90285, 4.58 secs\n",
      "\u001b[1m---- Epoch 80/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.47308, s2s_loss 0.23862, 53.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06959, exact_match 0.90215, 4.36 secs\n",
      "\u001b[1m---- Epoch 81/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.26508, s2s_loss 0.25095, 53.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07148, exact_match 0.89521, 4.49 secs\n",
      "\u001b[1m---- Epoch 82/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21663, s2s_loss 0.24610, 56.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07034, exact_match 0.89729, 4.67 secs\n",
      "\u001b[1m---- Epoch 83/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.16131, s2s_loss 0.23443, 57.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07089, exact_match 0.89452, 4.49 secs\n",
      "\u001b[1m---- Epoch 84/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.11586, s2s_loss 0.24659, 55.82 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07059, exact_match 0.89660, 4.52 secs\n",
      "\u001b[1m---- Epoch 85/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.11178, s2s_loss 0.24576, 57.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07245, exact_match 0.89244, 4.23 secs\n",
      "\u001b[1m---- Epoch 86/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.14151, s2s_loss 0.25087, 56.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07214, exact_match 0.89591, 4.65 secs\n",
      "\u001b[1m---- Epoch 87/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.31531, s2s_loss 0.25122, 56.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07319, exact_match 0.89521, 4.58 secs\n",
      "\u001b[1m---- Epoch 88/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.37962, s2s_loss 0.24231, 54.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07219, exact_match 0.90007, 4.50 secs\n",
      "\u001b[1m---- Epoch 89/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.67818, s2s_loss 0.24216, 57.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07172, exact_match 0.89868, 4.33 secs\n",
      "\u001b[1m---- Epoch 90/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.30534, s2s_loss 0.24135, 56.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06892, exact_match 0.90354, 4.65 secs\n",
      "\u001b[1m---- Epoch 91/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20432, s2s_loss 0.24087, 56.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06962, exact_match 0.90423, 4.51 secs\n",
      "\u001b[1m---- Epoch 92/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.25400, s2s_loss 0.24613, 56.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06945, exact_match 0.90423, 4.30 secs\n",
      "\u001b[1m---- Epoch 93/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.21991, s2s_loss 0.24537, 57.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07897, exact_match 0.89382, 4.53 secs\n",
      "\u001b[1m---- Epoch 94/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.29764, s2s_loss 0.25268, 55.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06854, exact_match 0.90354, 4.44 secs\n",
      "\u001b[1m---- Epoch 95/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.32322, s2s_loss 0.25409, 57.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06644, exact_match 0.90840, 4.35 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_95_exact_match+s2s_loss=0.9105.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 96/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.22229, s2s_loss 0.24832, 57.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06684, exact_match 0.90770, 4.46 secs\n",
      "\u001b[1m---- Epoch 97/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.29202, s2s_loss 0.24715, 55.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06667, exact_match 0.90632, 4.49 secs\n",
      "\u001b[1m---- Epoch 98/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.26846, s2s_loss 0.24060, 57.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06589, exact_match 0.90632, 4.55 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_98_exact_match+s2s_loss=0.9106.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 99/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.17868, s2s_loss 0.24958, 57.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06555, exact_match 0.90493, 4.20 secs\n",
      "\u001b[1m---- Epoch 100/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30685, s2s_loss 0.23891, 55.53 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.06586, exact_match 0.90493, 4.23 secs\n",
      "\u001b[1m---- Epoch 101/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.33298, s2s_loss 0.25238, 54.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06440, exact_match 0.90840, 4.51 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_101_exact_match+s2s_loss=0.9114.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 102/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.04777, s2s_loss 0.25641, 52.46 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06446, exact_match 0.90632, 4.56 secs\n",
      "\u001b[1m---- Epoch 103/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.24074, s2s_loss 0.24612, 55.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06697, exact_match 0.90285, 4.60 secs\n",
      "\u001b[1m---- Epoch 104/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.61865, s2s_loss 0.24788, 54.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06935, exact_match 0.90076, 4.70 secs\n",
      "\u001b[1m---- Epoch 105/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.31863, s2s_loss 0.24299, 55.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06241, exact_match 0.90978, 4.56 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_105_exact_match+s2s_loss=0.9134.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 106/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.36031, s2s_loss 0.23245, 57.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06485, exact_match 0.90840, 4.62 secs\n",
      "\u001b[1m---- Epoch 107/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.30561, s2s_loss 0.23793, 54.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06485, exact_match 0.90909, 5.06 secs\n",
      "\u001b[1m---- Epoch 108/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.13664, s2s_loss 0.24351, 57.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06436, exact_match 0.90909, 4.48 secs\n",
      "\u001b[1m---- Epoch 109/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.22166, s2s_loss 0.24894, 55.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07320, exact_match 0.89105, 4.55 secs\n",
      "\u001b[1m---- Epoch 110/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.27533, s2s_loss 0.25880, 55.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07200, exact_match 0.90146, 4.24 secs\n",
      "\u001b[1m---- Epoch 111/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.44053, s2s_loss 0.24228, 55.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06649, exact_match 0.90701, 4.26 secs\n",
      "\u001b[1m---- Epoch 112/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33684, s2s_loss 0.24002, 52.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06537, exact_match 0.91464, 4.28 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_112_exact_match+s2s_loss=0.9146.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 113/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.33167, s2s_loss 0.25051, 56.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06541, exact_match 0.91325, 4.44 secs\n",
      "\u001b[1m---- Epoch 114/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.32301, s2s_loss 0.24082, 53.99 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06413, exact_match 0.91256, 4.47 secs\n",
      "\u001b[1m---- Epoch 115/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39819, s2s_loss 0.25136, 56.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06474, exact_match 0.91048, 4.44 secs\n",
      "\u001b[1m---- Epoch 116/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.27228, s2s_loss 0.23603, 54.42 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06481, exact_match 0.91117, 4.47 secs\n",
      "\u001b[1m---- Epoch 117/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.45758, s2s_loss 0.24801, 56.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07311, exact_match 0.90354, 4.18 secs\n",
      "\u001b[1m---- Epoch 118/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.18413, s2s_loss 0.25038, 54.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06864, exact_match 0.90285, 4.45 secs\n",
      "\u001b[1m---- Epoch 119/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20099, s2s_loss 0.24583, 56.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06584, exact_match 0.90909, 4.10 secs\n",
      "\u001b[1m---- Epoch 120/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.29742, s2s_loss 0.24296, 56.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06609, exact_match 0.90701, 4.52 secs\n",
      "\u001b[1m---- Epoch 121/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.15309, s2s_loss 0.24132, 54.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06432, exact_match 0.91048, 4.32 secs\n",
      "\u001b[1m---- Epoch 122/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.52505, s2s_loss 0.23814, 56.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06397, exact_match 0.90978, 4.15 secs\n",
      "\u001b[1m---- Epoch 123/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26595, s2s_loss 0.24291, 54.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06419, exact_match 0.90840, 3.71 secs\n",
      "\u001b[1m---- Epoch 124/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.14516, s2s_loss 0.24494, 54.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06498, exact_match 0.90840, 3.70 secs\n",
      "\u001b[1m---- Epoch 125/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.16504, s2s_loss 0.24888, 54.22 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06848, exact_match 0.90562, 3.70 secs\n",
      "\u001b[1m---- Epoch 126/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.43023, s2s_loss 0.24622, 54.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06932, exact_match 0.90215, 3.68 secs\n",
      "\u001b[1m---- Epoch 127/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.58873, s2s_loss 0.25356, 54.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06930, exact_match 0.90007, 3.71 secs\n",
      "\u001b[1m---- Epoch 128/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.38937, s2s_loss 0.24274, 54.83 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06966, exact_match 0.89868, 3.69 secs\n",
      "\u001b[1m---- Epoch 129/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.16759, s2s_loss 0.24316, 55.02 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06833, exact_match 0.90215, 3.72 secs\n",
      "\u001b[1m---- Epoch 130/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.09418, s2s_loss 0.24256, 54.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06745, exact_match 0.90493, 3.72 secs\n",
      "\u001b[1m---- Epoch 131/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.32226, s2s_loss 0.24057, 54.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06836, exact_match 0.90354, 3.75 secs\n",
      "\u001b[1m---- Epoch 132/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.23339, s2s_loss 0.23961, 54.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06868, exact_match 0.90285, 3.72 secs\n",
      "\u001b[1m---- Epoch 133/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.34051, s2s_loss 0.25290, 55.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.08055, exact_match 0.88411, 3.71 secs\n",
      "\u001b[1m---- Epoch 134/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.22127, s2s_loss 0.25146, 54.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06986, exact_match 0.90423, 3.68 secs\n",
      "\u001b[1m---- Epoch 135/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.29954, s2s_loss 0.24587, 55.07 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06704, exact_match 0.90493, 3.70 secs\n",
      "\u001b[1m---- Epoch 136/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.30984, s2s_loss 0.24637, 54.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06867, exact_match 0.89938, 3.66 secs\n",
      "\u001b[1m---- Epoch 137/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.38140, s2s_loss 0.23558, 54.25 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06728, exact_match 0.90562, 3.71 secs\n",
      "\u001b[1m---- Epoch 138/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.63217, s2s_loss 0.24268, 54.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06744, exact_match 0.90285, 3.75 secs\n",
      "\u001b[1m---- Epoch 139/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.11564, s2s_loss 0.23999, 54.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06794, exact_match 0.90285, 3.71 secs\n",
      "\u001b[1m---- Epoch 140/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.24141, s2s_loss 0.23893, 54.53 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06741, exact_match 0.90215, 3.69 secs\n",
      "\u001b[1m---- Epoch 141/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.57993, s2s_loss 0.25056, 54.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06709, exact_match 0.90493, 3.68 secs\n",
      "\u001b[1m---- Epoch 142/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.37807, s2s_loss 0.25008, 55.10 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06672, exact_match 0.90285, 3.70 secs\n",
      "\u001b[1m---- Epoch 143/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18254, s2s_loss 0.24975, 55.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06527, exact_match 0.90840, 3.68 secs\n",
      "\u001b[1m---- Epoch 144/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.25015, s2s_loss 0.23629, 54.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06575, exact_match 0.90909, 3.68 secs\n",
      "\u001b[1m---- Epoch 145/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.30273, s2s_loss 0.24197, 54.28 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06459, exact_match 0.91187, 3.67 secs\n",
      "\u001b[1m---- Epoch 146/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.17460, s2s_loss 0.23676, 54.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06737, exact_match 0.90354, 3.68 secs\n",
      "\u001b[1m---- Epoch 147/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.07761, s2s_loss 0.23851, 44.34 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06795, exact_match 0.90354, 3.71 secs\n",
      "\u001b[1m---- Epoch 148/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.17842, s2s_loss 0.24314, 54.21 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06633, exact_match 0.90423, 3.70 secs\n",
      "\u001b[1m---- Epoch 149/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.09631, s2s_loss 0.24776, 54.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07303, exact_match 0.89938, 3.71 secs\n",
      "\u001b[1m---- Epoch 150/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.05203, s2s_loss 0.25011, 54.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06431, exact_match 0.90770, 3.68 secs\n",
      "\u001b[1m---- Epoch 151/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.15665, s2s_loss 0.24860, 54.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06460, exact_match 0.91464, 3.69 secs\n",
      "\u001b[1m---- Epoch 152/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.28265, s2s_loss 0.23911, 54.76 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06513, exact_match 0.91117, 3.65 secs\n",
      "\u001b[1m---- Epoch 153/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.10431, s2s_loss 0.24059, 55.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06576, exact_match 0.90840, 3.72 secs\n",
      "\u001b[1m---- Epoch 154/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21420, s2s_loss 0.24448, 54.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06550, exact_match 0.91048, 3.65 secs\n",
      "\u001b[1m---- Epoch 155/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.33208, s2s_loss 0.23585, 54.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06507, exact_match 0.91117, 3.68 secs\n",
      "\u001b[1m---- Epoch 156/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.33584, s2s_loss 0.23219, 54.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06524, exact_match 0.91117, 3.69 secs\n",
      "\u001b[1m---- Epoch 157/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.10756, s2s_loss 0.24312, 54.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07759, exact_match 0.89382, 3.70 secs\n",
      "\u001b[1m---- Epoch 158/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.26304, s2s_loss 0.24935, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07571, exact_match 0.89521, 3.70 secs\n",
      "\u001b[1m---- Epoch 159/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.18344, s2s_loss 0.24454, 54.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06749, exact_match 0.90840, 3.69 secs\n",
      "\u001b[1m---- Epoch 160/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.13058, s2s_loss 0.23799, 54.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06581, exact_match 0.90770, 3.68 secs\n",
      "\u001b[1m---- Epoch 161/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.09016, s2s_loss 0.24992, 54.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06750, exact_match 0.90840, 3.71 secs\n",
      "\u001b[1m---- Epoch 162/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.35612, s2s_loss 0.24027, 54.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06698, exact_match 0.90632, 3.68 secs\n",
      "\u001b[1m---- Epoch 163/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.13525, s2s_loss 0.23421, 54.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06672, exact_match 0.90701, 3.64 secs\n",
      "\u001b[1m---- Epoch 164/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.23145, s2s_loss 0.23706, 55.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06703, exact_match 0.90701, 3.71 secs\n",
      "\u001b[1m---- Epoch 165/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.15502, s2s_loss 0.24359, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07174, exact_match 0.89244, 3.71 secs\n",
      "\u001b[1m---- Epoch 166/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.16963, s2s_loss 0.25067, 54.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07256, exact_match 0.89174, 3.72 secs\n",
      "\u001b[1m---- Epoch 167/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.21317, s2s_loss 0.24891, 54.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06390, exact_match 0.90354, 3.71 secs\n",
      "\u001b[1m---- Epoch 168/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.38449, s2s_loss 0.23500, 54.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06517, exact_match 0.90354, 3.69 secs\n",
      "\u001b[1m---- Epoch 169/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32606, s2s_loss 0.23280, 54.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06454, exact_match 0.90562, 3.72 secs\n",
      "\u001b[1m---- Epoch 170/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.37237, s2s_loss 0.24243, 54.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06642, exact_match 0.90285, 3.72 secs\n",
      "\u001b[1m---- Epoch 171/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20912, s2s_loss 0.24431, 55.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06633, exact_match 0.90146, 3.70 secs\n",
      "\u001b[1m---- Epoch 172/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.23813, s2s_loss 0.23529, 54.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06529, exact_match 0.90215, 3.74 secs\n",
      "\u001b[1m---- Epoch 173/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.40530, s2s_loss 0.24198, 54.74 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06979, exact_match 0.90215, 3.71 secs\n",
      "\u001b[1m---- Epoch 174/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.46831, s2s_loss 0.25075, 54.48 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06708, exact_match 0.90632, 3.68 secs\n",
      "\u001b[1m---- Epoch 175/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.35450, s2s_loss 0.24158, 54.30 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06507, exact_match 0.90770, 3.67 secs\n",
      "\u001b[1m---- Epoch 176/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.13337, s2s_loss 0.24619, 54.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06614, exact_match 0.90770, 3.69 secs\n",
      "\u001b[1m---- Epoch 177/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.08309, s2s_loss 0.23825, 54.59 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06365, exact_match 0.90840, 3.70 secs\n",
      "\u001b[1m---- Epoch 178/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.24964, s2s_loss 0.23654, 54.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06614, exact_match 0.90770, 3.73 secs\n",
      "\u001b[1m---- Epoch 179/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.08882, s2s_loss 0.24341, 52.03 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06514, exact_match 0.90770, 3.70 secs\n",
      "\u001b[1m---- Epoch 180/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21302, s2s_loss 0.23779, 39.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06469, exact_match 0.90770, 3.68 secs\n",
      "\u001b[1m---- Epoch 181/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.07156, s2s_loss 0.24141, 42.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06950, exact_match 0.89660, 3.66 secs\n",
      "\u001b[1m---- Epoch 182/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.25943, s2s_loss 0.25314, 54.35 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06368, exact_match 0.90840, 3.65 secs\n",
      "\u001b[1m---- Epoch 183/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.14371, s2s_loss 0.24650, 54.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06418, exact_match 0.91534, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_183_exact_match+s2s_loss=0.9150.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 184/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.23070, s2s_loss 0.23567, 54.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06476, exact_match 0.91603, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_184_exact_match+s2s_loss=0.9158.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 185/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.20789, s2s_loss 0.24290, 54.71 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06295, exact_match 0.91395, 3.69 secs\n",
      "\u001b[1m---- Epoch 186/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.46570, s2s_loss 0.24377, 54.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06305, exact_match 0.91881, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_186_exact_match+s2s_loss=0.9172.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 187/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.14722, s2s_loss 0.23312, 54.92 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.06323, exact_match 0.91534, 3.69 secs\n",
      "\u001b[1m---- Epoch 188/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.21821, s2s_loss 0.23972, 54.49 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06299, exact_match 0.91325, 3.69 secs\n",
      "\u001b[1m---- Epoch 189/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.18908, s2s_loss 0.23936, 54.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06515, exact_match 0.89799, 3.71 secs\n",
      "\u001b[1m---- Epoch 190/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.32383, s2s_loss 0.24203, 54.50 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06867, exact_match 0.89660, 3.71 secs\n",
      "\u001b[1m---- Epoch 191/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.32325, s2s_loss 0.24763, 54.80 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07043, exact_match 0.89174, 3.71 secs\n",
      "\u001b[1m---- Epoch 192/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.35112, s2s_loss 0.24337, 54.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06676, exact_match 0.90770, 3.70 secs\n",
      "\u001b[1m---- Epoch 193/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.11704, s2s_loss 0.24262, 55.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06559, exact_match 0.90840, 3.71 secs\n",
      "\u001b[1m---- Epoch 194/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.12889, s2s_loss 0.23896, 54.81 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06576, exact_match 0.90978, 3.71 secs\n",
      "\u001b[1m---- Epoch 195/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26117, s2s_loss 0.23750, 55.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06550, exact_match 0.90770, 3.73 secs\n",
      "\u001b[1m---- Epoch 196/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30477, s2s_loss 0.24507, 54.23 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06509, exact_match 0.90909, 3.73 secs\n",
      "\u001b[1m---- Epoch 197/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.08280, s2s_loss 0.24841, 53.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06456, exact_match 0.90840, 3.71 secs\n",
      "\u001b[1m---- Epoch 198/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.36800, s2s_loss 0.25435, 54.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06222, exact_match 0.91048, 3.65 secs\n",
      "\u001b[1m---- Epoch 199/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.17757, s2s_loss 0.23945, 54.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06818, exact_match 0.91048, 3.69 secs\n",
      "\u001b[1m---- Epoch 200/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.09603, s2s_loss 0.24395, 54.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06653, exact_match 0.90909, 3.67 secs\n",
      "\u001b[1m---- Epoch 201/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.40750, s2s_loss 0.24572, 54.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06903, exact_match 0.90978, 3.68 secs\n",
      "\u001b[1m---- Epoch 202/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.16758, s2s_loss 0.24192, 54.57 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06557, exact_match 0.91117, 3.69 secs\n",
      "\u001b[1m---- Epoch 203/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.29096, s2s_loss 0.23470, 54.92 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06484, exact_match 0.91256, 3.69 secs\n",
      "\u001b[1m---- Epoch 204/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.25218, s2s_loss 0.23520, 54.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06515, exact_match 0.91048, 3.68 secs\n",
      "\u001b[1m---- Epoch 205/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.30574, s2s_loss 0.24280, 54.54 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06728, exact_match 0.90423, 3.67 secs\n",
      "\u001b[1m---- Epoch 206/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.20473, s2s_loss 0.24593, 54.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06925, exact_match 0.90701, 3.68 secs\n",
      "\u001b[1m---- Epoch 207/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.25405, s2s_loss 0.24300, 54.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06840, exact_match 0.90562, 3.66 secs\n",
      "\u001b[1m---- Epoch 208/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.05046, s2s_loss 0.23131, 54.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06762, exact_match 0.90215, 3.69 secs\n",
      "\u001b[1m---- Epoch 209/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.23079, s2s_loss 0.23854, 47.33 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06667, exact_match 0.90076, 3.71 secs\n",
      "\u001b[1m---- Epoch 210/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.38454, s2s_loss 0.23434, 54.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06604, exact_match 0.90493, 3.73 secs\n",
      "\u001b[1m---- Epoch 211/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21100, s2s_loss 0.23694, 54.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06577, exact_match 0.90423, 3.71 secs\n",
      "\u001b[1m---- Epoch 212/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.14567, s2s_loss 0.24196, 54.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06535, exact_match 0.90701, 3.72 secs\n",
      "\u001b[1m---- Epoch 213/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.37278, s2s_loss 0.24295, 53.98 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06680, exact_match 0.90146, 3.70 secs\n",
      "\u001b[1m---- Epoch 214/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.08705, s2s_loss 0.25420, 54.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06734, exact_match 0.89799, 3.71 secs\n",
      "\u001b[1m---- Epoch 215/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20024, s2s_loss 0.24282, 54.89 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06431, exact_match 0.90354, 3.68 secs\n",
      "\u001b[1m---- Epoch 216/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.23993, s2s_loss 0.23813, 55.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07049, exact_match 0.90285, 3.70 secs\n",
      "\u001b[1m---- Epoch 217/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.13843, s2s_loss 0.24108, 54.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06722, exact_match 0.90632, 3.68 secs\n",
      "\u001b[1m---- Epoch 218/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.42638, s2s_loss 0.24129, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06767, exact_match 0.90770, 3.68 secs\n",
      "\u001b[1m---- Epoch 219/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.31567, s2s_loss 0.23715, 54.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06646, exact_match 0.90701, 3.70 secs\n",
      "\u001b[1m---- Epoch 220/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15589, s2s_loss 0.23695, 54.91 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06662, exact_match 0.90909, 3.68 secs\n",
      "\u001b[1m---- Epoch 221/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.21735, s2s_loss 0.24035, 53.93 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07267, exact_match 0.90076, 3.69 secs\n",
      "\u001b[1m---- Epoch 222/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.35513, s2s_loss 0.24331, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07449, exact_match 0.89660, 3.71 secs\n",
      "\u001b[1m---- Epoch 223/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.39786, s2s_loss 0.23928, 55.09 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07516, exact_match 0.89382, 3.69 secs\n",
      "\u001b[1m---- Epoch 224/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.35880, s2s_loss 0.23793, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06816, exact_match 0.90354, 3.68 secs\n",
      "\u001b[1m---- Epoch 225/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.27051, s2s_loss 0.24273, 55.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06594, exact_match 0.90909, 3.71 secs\n",
      "\u001b[1m---- Epoch 226/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.21646, s2s_loss 0.23654, 55.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06672, exact_match 0.90354, 3.70 secs\n",
      "\u001b[1m---- Epoch 227/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.18412, s2s_loss 0.22929, 54.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06641, exact_match 0.90423, 3.70 secs\n",
      "\u001b[1m---- Epoch 228/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.20067, s2s_loss 0.23761, 54.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06625, exact_match 0.90423, 3.71 secs\n",
      "\u001b[1m---- Epoch 229/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.16025, s2s_loss 0.24456, 53.88 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06674, exact_match 0.90076, 3.71 secs\n",
      "\u001b[1m---- Epoch 230/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.14915, s2s_loss 0.24669, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07146, exact_match 0.89938, 3.70 secs\n",
      "\u001b[1m---- Epoch 231/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.41696, s2s_loss 0.24158, 55.06 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06479, exact_match 0.91256, 3.70 secs\n",
      "\u001b[1m---- Epoch 232/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.21910, s2s_loss 0.23851, 54.70 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.06607, exact_match 0.90909, 3.69 secs\n",
      "\u001b[1m---- Epoch 233/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.35026, s2s_loss 0.23060, 54.77 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06743, exact_match 0.90701, 3.68 secs\n",
      "\u001b[1m---- Epoch 234/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.39597, s2s_loss 0.23313, 54.65 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06630, exact_match 0.90978, 3.69 secs\n",
      "\u001b[1m---- Epoch 235/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.37230, s2s_loss 0.23632, 54.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06574, exact_match 0.91325, 3.70 secs\n",
      "\u001b[1m---- Epoch 236/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.30564, s2s_loss 0.23971, 54.94 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06662, exact_match 0.90840, 3.68 secs\n",
      "\u001b[1m---- Epoch 237/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.53974, s2s_loss 0.24330, 54.79 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06838, exact_match 0.89868, 3.70 secs\n",
      "\u001b[1m---- Epoch 238/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.28872, s2s_loss 0.24507, 55.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06795, exact_match 0.90007, 3.69 secs\n",
      "\u001b[1m---- Epoch 239/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.13263, s2s_loss 0.23504, 54.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06827, exact_match 0.90423, 3.70 secs\n",
      "\u001b[1m---- Epoch 240/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.11797, s2s_loss 0.23810, 54.19 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06929, exact_match 0.90632, 3.69 secs\n",
      "\u001b[1m---- Epoch 241/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32849, s2s_loss 0.23539, 55.17 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06645, exact_match 0.90909, 3.68 secs\n",
      "\u001b[1m---- Epoch 242/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.41241, s2s_loss 0.23438, 54.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06726, exact_match 0.90909, 3.70 secs\n",
      "\u001b[1m---- Epoch 243/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.20805, s2s_loss 0.23627, 54.44 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06690, exact_match 0.91117, 3.70 secs\n",
      "\u001b[1m---- Epoch 244/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28270, s2s_loss 0.23710, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06668, exact_match 0.90978, 3.70 secs\n",
      "\u001b[1m---- Epoch 245/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.34912, s2s_loss 0.24191, 53.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06116, exact_match 0.90701, 3.69 secs\n",
      "\u001b[1m---- Epoch 246/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.19159, s2s_loss 0.24602, 54.51 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06558, exact_match 0.91256, 3.68 secs\n",
      "\u001b[1m---- Epoch 247/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.15876, s2s_loss 0.23974, 54.75 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06413, exact_match 0.91117, 3.68 secs\n",
      "\u001b[1m---- Epoch 248/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33231, s2s_loss 0.23938, 54.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06546, exact_match 0.90909, 3.70 secs\n",
      "\u001b[1m---- Epoch 249/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.16338, s2s_loss 0.23737, 55.14 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06255, exact_match 0.90978, 3.69 secs\n",
      "\u001b[1m---- Epoch 250/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.13367, s2s_loss 0.22866, 54.55 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06371, exact_match 0.91117, 3.69 secs\n",
      "\u001b[1m---- Epoch 251/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.27589, s2s_loss 0.22927, 55.27 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06327, exact_match 0.91048, 3.70 secs\n",
      "\u001b[1m---- Epoch 252/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.15018, s2s_loss 0.23493, 54.47 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06269, exact_match 0.91117, 3.69 secs\n",
      "\u001b[1m---- Epoch 253/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.16277, s2s_loss 0.24363, 47.11 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06389, exact_match 0.90909, 3.68 secs\n",
      "\u001b[1m---- Epoch 254/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.17344, s2s_loss 0.24740, 53.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06560, exact_match 0.90840, 3.67 secs\n",
      "\u001b[1m---- Epoch 255/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.29578, s2s_loss 0.24068, 54.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06338, exact_match 0.90562, 3.68 secs\n",
      "\u001b[1m---- Epoch 256/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.11684, s2s_loss 0.23657, 54.62 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06222, exact_match 0.91464, 3.70 secs\n",
      "\u001b[1m---- Epoch 257/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.34875, s2s_loss 0.22158, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06027, exact_match 0.91811, 3.69 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_257_exact_match+s2s_loss=0.9194.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 258/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.23928, s2s_loss 0.22881, 55.04 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06072, exact_match 0.92019, 3.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_258_exact_match+s2s_loss=0.9197.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 259/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.23100, s2s_loss 0.24067, 55.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06129, exact_match 0.91950, 3.68 secs\n",
      "\u001b[1m---- Epoch 260/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.16190, s2s_loss 0.23759, 53.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06137, exact_match 0.91811, 3.70 secs\n",
      "\u001b[1m---- Epoch 261/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.21864, s2s_loss 0.24327, 54.40 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06318, exact_match 0.90562, 3.71 secs\n",
      "\u001b[1m---- Epoch 262/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.13567, s2s_loss 0.23843, 55.39 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06578, exact_match 0.90285, 3.70 secs\n",
      "\u001b[1m---- Epoch 263/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.28061, s2s_loss 0.24329, 54.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06592, exact_match 0.90840, 3.69 secs\n",
      "\u001b[1m---- Epoch 264/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.40617, s2s_loss 0.23477, 55.12 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06857, exact_match 0.90493, 3.68 secs\n",
      "\u001b[1m---- Epoch 265/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.20088, s2s_loss 0.22327, 53.85 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06447, exact_match 0.90493, 3.70 secs\n",
      "\u001b[1m---- Epoch 266/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.19324, s2s_loss 0.23304, 54.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06432, exact_match 0.90909, 3.69 secs\n",
      "\u001b[1m---- Epoch 267/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.18324, s2s_loss 0.23092, 54.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06420, exact_match 0.90562, 3.70 secs\n",
      "\u001b[1m---- Epoch 268/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.12731, s2s_loss 0.22994, 54.61 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06347, exact_match 0.90840, 3.72 secs\n",
      "\u001b[1m---- Epoch 269/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.18761, s2s_loss 0.24014, 54.67 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07088, exact_match 0.89729, 3.67 secs\n",
      "\u001b[1m---- Epoch 270/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.55455, s2s_loss 0.24238, 54.70 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06840, exact_match 0.90701, 3.72 secs\n",
      "\u001b[1m---- Epoch 271/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.20783, s2s_loss 0.24716, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06588, exact_match 0.91117, 3.70 secs\n",
      "\u001b[1m---- Epoch 272/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.37942, s2s_loss 0.23334, 54.24 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06391, exact_match 0.91742, 3.67 secs\n",
      "\u001b[1m---- Epoch 273/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.28624, s2s_loss 0.23436, 54.68 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06178, exact_match 0.91464, 3.71 secs\n",
      "\u001b[1m---- Epoch 274/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.24878, s2s_loss 0.23672, 54.52 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06362, exact_match 0.91395, 3.70 secs\n",
      "\u001b[1m---- Epoch 275/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.28311, s2s_loss 0.22863, 54.26 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06281, exact_match 0.91395, 3.69 secs\n",
      "\u001b[1m---- Epoch 276/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.19733, s2s_loss 0.23615, 55.07 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s2s_loss 0.06229, exact_match 0.91603, 3.74 secs\n",
      "\u001b[1m---- Epoch 277/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.11497, s2s_loss 0.23754, 54.87 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06085, exact_match 0.91325, 3.71 secs\n",
      "\u001b[1m---- Epoch 278/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.14943, s2s_loss 0.23563, 55.01 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.05998, exact_match 0.91534, 3.68 secs\n",
      "\u001b[1m---- Epoch 279/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.33967, s2s_loss 0.23559, 54.66 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06768, exact_match 0.90076, 3.71 secs\n",
      "\u001b[1m---- Epoch 280/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.43485, s2s_loss 0.24461, 39.69 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06319, exact_match 0.91048, 3.71 secs\n",
      "\u001b[1m---- Epoch 281/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.42360, s2s_loss 0.23540, 54.72 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06250, exact_match 0.91117, 3.71 secs\n",
      "\u001b[1m---- Epoch 282/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.50277, s2s_loss 0.23728, 54.38 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06372, exact_match 0.90840, 3.68 secs\n",
      "\u001b[1m---- Epoch 283/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.18943, s2s_loss 0.23521, 54.29 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06220, exact_match 0.91325, 3.68 secs\n",
      "\u001b[1m---- Epoch 284/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.28460, s2s_loss 0.23537, 54.64 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06212, exact_match 0.91534, 3.69 secs\n",
      "\u001b[1m---- Epoch 285/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.15862, s2s_loss 0.24447, 54.41 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.07128, exact_match 0.89938, 3.70 secs\n",
      "\u001b[1m---- Epoch 286/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.20360, s2s_loss 0.24437, 55.13 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06424, exact_match 0.90632, 3.68 secs\n",
      "\u001b[1m---- Epoch 287/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.15178, s2s_loss 0.24401, 54.31 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06435, exact_match 0.90632, 3.68 secs\n",
      "\u001b[1m---- Epoch 288/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.12865, s2s_loss 0.23820, 54.08 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06282, exact_match 0.90701, 3.68 secs\n",
      "\u001b[1m---- Epoch 289/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.18581, s2s_loss 0.23570, 53.58 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06390, exact_match 0.90701, 3.71 secs\n",
      "\u001b[1m---- Epoch 290/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.19613, s2s_loss 0.22715, 54.32 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06387, exact_match 0.90770, 3.70 secs\n",
      "\u001b[1m---- Epoch 291/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.13686, s2s_loss 0.23707, 55.15 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06361, exact_match 0.90770, 3.69 secs\n",
      "\u001b[1m---- Epoch 292/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.23771, s2s_loss 0.23922, 54.96 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06306, exact_match 0.90978, 3.72 secs\n",
      "\u001b[1m---- Epoch 293/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.46721, s2s_loss 0.24357, 55.60 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06932, exact_match 0.89591, 3.71 secs\n",
      "\u001b[1m---- Epoch 294/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.20072, s2s_loss 0.23846, 55.37 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06441, exact_match 0.90909, 3.70 secs\n",
      "\u001b[1m---- Epoch 295/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.14878, s2s_loss 0.24808, 53.16 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06218, exact_match 0.91117, 3.73 secs\n",
      "\u001b[1m---- Epoch 296/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.15190, s2s_loss 0.23329, 54.45 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06459, exact_match 0.91187, 3.71 secs\n",
      "\u001b[1m---- Epoch 297/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.32425, s2s_loss 0.23562, 54.78 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06402, exact_match 0.91256, 3.69 secs\n",
      "\u001b[1m---- Epoch 298/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.14981, s2s_loss 0.22844, 53.90 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06269, exact_match 0.91256, 3.69 secs\n",
      "\u001b[1m---- Epoch 299/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.21674, s2s_loss 0.23330, 54.95 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06357, exact_match 0.91256, 3.68 secs\n",
      "\u001b[1m---- Epoch 300/300\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.31697, s2s_loss 0.23102, 54.56 secs\n",
      "(2) Validation stage ...\n",
      "s2s_loss 0.06330, exact_match 0.91256, 3.62 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_seq2seq.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/seq2seq/20240308_133455_multitask(nli+mlm)_Seq2Seq(facebook-bart-base)\" \\\n",
    "--epochs 300 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--batch_size 10 \\\n",
    "--num_workers 3 \\\n",
    "--iters_to_accumulate 20 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,8,1e-6,8e-5,8,1e-6\" \\\n",
    "--task_name \"multitask\" \\\n",
    "--experiment_name \"nli+mlm\" \\\n",
    "--multitask_name_list \\\n",
    "\"nli\" \\\n",
    "\"mlm\" \\\n",
    "\"sentence2facts\" \\\n",
    "--task2weight '{\"nli\": 2.0, \"mlm\": 1.0, \"sentence2facts\": 0.0}' \\\n",
    "--sentence_to_facts_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_parsed_sentences__v2(uniform).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_facts_from_sentences(cluster-balanced,hardest).jsonl\"\\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_facts_from_sentences(cluster-balanced,hardest)_part2.jsonl\" \\\n",
    "--integrated_nli_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_nli_examples(169025,21838032).jsonl\" \\\n",
    "--use_sentence2facts_for_nli \\\n",
    "--use_anli \\\n",
    "--use_multinli \\\n",
    "--use_snli \\\n",
    "--use_report_nli \\\n",
    "--use_report_nli_entailment_dataset \\\n",
    "--use_fact_based_reports_in_mlm \\\n",
    "--integrated_report_facts_metadata_jsonl_filepath \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/integrated_report_facts_metadata(227835,78646269).jsonl\" \\\n",
    "--report_nli_input_output_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_labels).jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-1106-preview_fact_based_report_nli_queries(from_facts).jsonl\" \\\n",
    "--paraphrased_inputs_jsonl_filepaths \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_anatomical_locations__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_anatomical_locations__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__single-words.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words__part3.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-16k-0613_paraphrased_observations__two-or-more-words__part4.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-4-0613_paraphrased_observations__two-or-more-words_cluster-balanced.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_1of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_2of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_3of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_paraphrased_observations__two-or-more-words_cluster-balanced_4of5.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part1.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part2.jsonl\" \\\n",
    "\"/home/pamessina/medvqa-workspace/cache/mimiccxr/openai/gpt-3.5-turbo-0613_hard_triplets_from_facts(cluster-balanced,hardest)-part3.jsonl\" \\\n",
    "--only_validate_nli \\\n",
    "--nli1_only_on_train \\\n",
    "--nli1_only_on_val \\\n",
    "--seq2seq_model_name \"bart\" \\\n",
    "--t5_model_name \"facebook/bart-base\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
