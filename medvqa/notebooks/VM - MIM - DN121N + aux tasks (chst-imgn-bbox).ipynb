{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 2\n",
      "   batches_per_epoch: 30\n",
      "   checkpoint_folder: None\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v2\n",
      "   num_regions: 64\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,4,1e-4,16,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 140\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 0\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [256, 256]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\n",
      "   save: False\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(qa_adapted_reports__20220904_095810.json,clamped.pkl...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModel ...\u001b[0m\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,4,1e-4,16,1e-6\n",
      "1e-06 4 0.0001 16 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "train_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "val_image_transform_kwargs: {'image_size': [256, 256], 'augmentation_mode': None, 'use_clip_transform': False, 'clip_version': None, 'use_huggingface_vitmodel_transform': False, 'huggingface_vitmodel_name': None}\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/qa_adapted_reports__20220904_095810.json__detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "227835it [00:00, 483799.14it/s]\n",
      "Loading Chest Imagenome bounding boxes...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_17_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.4304.pt', 'checkpoint_34_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.5019.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/checkpoint_34_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.5019.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/2\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.01516, chestimgbbmf1 0.82411, chestimgbb_loss 0.01630, chestimgbbiou 0.90871, chestimgbbmae 0.03113, 42.60 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.79689, chestimgbbiou 0.90113, chestimgbbmae 0.03449, 17.18 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 2/2\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.01699, chestimgbbmf1 0.81729, chestimgbb_loss 0.01845, chestimgbbiou 0.90699, chestimgbbmae 0.03191, 42.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.79671, chestimgbbiou 0.90132, chestimgbbmae 0.03444, 17.05 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\" \\\n",
    "        --epochs 2 \\\n",
    "        --batches-per-epoch 30 \\\n",
    "        --batch-size 140 \\\n",
    "        --num-workers 0 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,4,1e-4,16,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "        --predict-bboxes-chest-imagenome \\\n",
    "        --clamp-bboxes-chest-imagenome \\\n",
    "        --chest-imagenome-bbox-regressor-version \"v2\" \\\n",
    "        --raw-image-encoding \"densenet-121\" \\\n",
    "        --image-size 256 256 \\\n",
    "        --image-local-feat-size 1024 \\\n",
    "        --num-regions 64 \\\n",
    "        --use-amp \\\n",
    "        --no-save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
