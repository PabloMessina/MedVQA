{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import medvqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'medvqa.models.huggingface_utils' from '/home/pamessina/medvqa/medvqa/models/huggingface_utils.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(medvqa.models.huggingface_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.models.huggingface_utils import TripletRankingEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-CXR-BERT-specialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n"
     ]
    }
   ],
   "source": [
    "tre1 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=116,1396652957813721259).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 159761.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.956\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.88\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.992\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.896\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.914\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.904\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.932\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.717\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.914\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.804\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.978\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre1.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-BioViL-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=104,2678825193822464594).pkl\n",
      "len(self.cache[\"hashes\"]) = 4451804\n",
      "self.cache[\"embeddings\"].shape = (4451804, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 32416/32416 [00:04<00:00, 7928.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.968\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.91\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 1.0\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.93\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.938\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 1.0\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.944\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.765\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.948\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.851\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 1.0\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre2 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-BioViL-T\",\n",
    ")\n",
    "tre2.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,40983794350539675).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 104882.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 1024)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [01:09<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,40983794350539675).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 427127.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.763\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.71\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.705\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.762\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.633\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.619\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.694\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.508\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.72\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.697\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.757\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre3 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"michiyasunaga/BioLinkBERT-large\",\n",
    ")\n",
    "tre3.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,1253761809285128054).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 85678.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 1024)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [01:12<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,1253761809285128054).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 385769.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.796\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.753\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.786\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.819\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.756\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.644\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.774\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.52\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.771\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.725\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.798\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre4 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"michiyasunaga/BioLinkBERT-large\",\n",
    "    average_token_embeddings=True,\n",
    ")\n",
    "tre4.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=137,1948119357925567498).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 91615.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 768)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:21<00:00, 47.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=137,1948119357925567498).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 422183.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.821\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.769\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.746\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.825\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.76\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.617\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.69\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.503\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.754\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.722\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.756\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre5 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    ")\n",
    "tre5.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=162,1758876944325999998).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 78962.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 768)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:21<00:00, 46.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=162,1758876944325999998).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 466288.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.95\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.901\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.905\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.939\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.873\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.767\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.834\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.603\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.935\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.853\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.932\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre6 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
    "    average_token_embeddings=True,\n",
    ")\n",
    "tre6.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,1542209846559636901).pkl\n",
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 110041.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:23<00:00, 43.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,1542209846559636901).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 435293.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.696\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.654\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.618\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.67\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.635\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.553\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.614\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.515\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.646\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.612\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.634\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre7 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    ")\n",
    "tre7.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/32416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,412155249657523952).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 97002.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 768)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:23<00:00, 42.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,412155249657523952).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 347513.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.977\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.922\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.933\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.951\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.912\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.834\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.948\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.601\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.957\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.864\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.948\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre8 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    average_token_embeddings=True,\n",
    ")\n",
    "tre8.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 310540.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=359,388447562913600091).pkl\n",
      "len(self.cache[\"hashes\"]) = 9782\n",
      "self.cache[\"embeddings\"].shape = (9782, 128)\n",
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:44<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=359,388447562913600091).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 438901.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.994\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.968\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.925\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.979\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.964\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.798\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.952\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.946\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.967\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.955\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.88\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre9 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre9.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_47_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9451.pt']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 470685.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_47_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9451.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_234549_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_47_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9451.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:34<00:00, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=367,2428892134441720844).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 603323.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.99\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.969\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.94\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.974\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.963\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.747\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.966\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.931\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.972\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.951\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.876\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre10 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_234549_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre10.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 170263.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=366,4246634492375333681).pkl\n",
      "len(self.cache[\"hashes\"]) = 102464\n",
      "self.cache[\"embeddings\"].shape = (102464, 128)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:38<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=366,4246634492375333681).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 393478.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.99\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.963\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.942\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.974\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.969\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.797\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.964\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.942\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.981\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.952\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.888\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre10 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre10.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 495667.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 223 keys, intersection has 211 keys, union has 223 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.bias\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:31<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,2492157991032224976).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 682111.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.992\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.971\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.969\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.989\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.981\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.907\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.979\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.933\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.984\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.941\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.907\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre11 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre11.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 292378.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,1308360022390228203).pkl\n",
      "len(self.cache[\"hashes\"]) = 9782\n",
      "self.cache[\"embeddings\"].shape = (9782, 128)\n",
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 223 keys, intersection has 211 keys, union has 223 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:42<00:00, 23.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,1308360022390228203).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 372843.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.996\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.967\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.967\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.992\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.982\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.926\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.988\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.937\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.986\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.945\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.919\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre11 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre11.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+EC+NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_17_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8973.pt']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 388859.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_17_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8973.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_045139_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_17_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.8973.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 215 keys, intersection has 211 keys, union has 215 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:32<00:00, 31.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,696859487587268917).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 517260.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.989\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.943\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.931\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.955\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.941\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.782\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.943\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.914\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.96\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.944\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.871\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre12 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_045139_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre12.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 167500.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,1493189425621868816).pkl\n",
      "len(self.cache[\"hashes\"]) = 102464\n",
      "self.cache[\"embeddings\"].shape = (102464, 128)\n",
      "Computing embeddings for 32390 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 215 keys, intersection has 211 keys, union has 215 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:36<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,1493189425621868816).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32390/32390 [00:00<00:00, 415295.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.974\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.941\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.925\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.955\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.945\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.751\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.936\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.919\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.966\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.944\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.893\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre12 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre12.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 410386.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 216 keys, intersection has 211 keys, union has 216 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_size_embeddings.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:34<00:00, 29.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=368,1866338409828607810).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 586455.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.991\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.962\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.917\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.978\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.961\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.798\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.954\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.927\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.976\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.946\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.897\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre13 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre13.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C+EC+NLI+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_67_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9336.pt']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 518822.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_67_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9336.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_144824_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_67_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9336.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 232 keys, intersection has 211 keys, union has 232 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_size_embeddings.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:31<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,543192558617698066).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 665576.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.994\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.977\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.967\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.992\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.981\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.888\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.973\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.93\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.978\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.948\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.888\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre14 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_144824_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre14.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_26_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9386.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 493039.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_26_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9386.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_26_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9386.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 232 keys, intersection has 211 keys, union has 232 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:31<00:00, 31.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,141429923173682938).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 570571.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.994\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.972\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.97\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.99\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.987\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.889\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.975\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.933\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.982\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.947\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.905\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre14 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\",\n",
    ")\n",
    "tre14.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 490490.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,3677907674814022869).pkl\n",
      "len(self.cache[\"hashes\"]) = 9782\n",
      "self.cache[\"embeddings\"].shape = (9782, 128)\n",
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 232 keys, intersection has 211 keys, union has 232 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:42<00:00, 23.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,3677907674814022869).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 368871.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.994\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.976\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.969\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.99\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.98\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.905\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.979\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.929\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.988\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.948\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.895\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre14 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre14.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 482917.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n",
      "len(self.cache[\"hashes\"]) = 9782\n",
      "self.cache[\"embeddings\"].shape = (9782, 128)\n",
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 237 keys, intersection has 211 keys, union has 237 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear2.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.start_idx\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm1.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm3.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.in_proj_weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm3.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear2.weight\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:31<00:00, 32.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 652840.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.996\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.981\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.954\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.98\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.977\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.875\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.981\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.898\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.992\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.966\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.942\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C+EC+NLI+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n",
      "checkpoint_names = ['checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 500320.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=425,2776001221282427137).pkl\n",
      "len(self.cache[\"hashes\"]) = 9782\n",
      "self.cache[\"embeddings\"].shape = (9782, 128)\n",
      "Computing embeddings for 32416 new texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_names = ['checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 253 keys, intersection has 211 keys, union has 253 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.start_idx\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.in_proj_weight\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder_input_layer.bias\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:31<00:00, 32.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=425,2776001221282427137).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 32416/32416 [00:00<00:00, 627761.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.997\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.973\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.976\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.989\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.989\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.905\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.982\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.94\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.991\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.964\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.953\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tre = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "    model_checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    ")\n",
    "tre.evaluate_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triplets from /mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 32416/32416 [09:06<00:00, 59.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: observations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.938\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.855\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus, while anchor and positive share the same health status\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.908\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard health-status-vs-others triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.851\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Short observation, detailed observation, and fact must be close to each other\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.884\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Rank triplets according to Chest ImaGenome labels\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.76\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: RadGraph-based triplets\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.937\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: observations, Rule: Hard negative triplets generated by ChatGPT\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.635\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.862\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank paraphrases very highly - Hard negative\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.771\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "Category: anatomical_locations, Rule: Rank some triplets according to CXR-BERT and Leveinshtein consensus\n",
      "triplets.shape = (1000, 3)\n",
      "\u001b[1maccuracy = 0.826\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tre15 = TripletRankingEvaluator(\n",
    "    triplets_filepath=\"/mnt/workspace/pamessina/medvqa-workspace/cache/mimiccxr/triplets(4374074,318620,2395255,3002000,1000,1000,274,1091231605151220188).pkl\",\n",
    "    model_name=\"CheXbert\",\n",
    "    device='cuda',\n",
    ")\n",
    "tre15.evaluate_split('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
