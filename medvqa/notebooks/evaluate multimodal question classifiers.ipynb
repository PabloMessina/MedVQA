{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   num_workers: 0\n",
      "   device: GPU\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=background__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of ImageTextEncoder model ...\u001b[0m\n",
      "self.multimodal_global_feat_size = 3072\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating validator engine ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR multimodal trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_multimodal_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=8676,61772,79269394504155791).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "generating datasets and dataloaders ...\n",
      "num_workers = 0\n",
      "len(self.test_indices) = 3269\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_191_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6045.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/checkpoint_191_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6045.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning validator engine ...\u001b[0m\n",
      "Evaluating model ...\n",
      "b_bg 0.79155, oracc 0.99441, qlmacf1 0.23282, qlmicf1 0.44319, chxlmacf1 0.45023, chxlmicf1 0.56629, chxlacc 0.72816, chxlrocaucmic 0.80415, chxlrocaucmac 0.71492, 15.54 secs\n",
      "Question probabilities saved to /home/pamessina/medvqa-workspace/results/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/mimiccxr_question_probs.pkl\n",
      "Metrics successfully saved to /home/pamessina/medvqa-workspace/results/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/mimiccxr_multimodal_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_multimodal_question_classifier.py \\\n",
    "        --checkpoint-folder \"models/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/multimodal/20220907_084600_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   num_workers: 0\n",
      "   device: GPU\n",
      "\u001b[34m----- Evaluating model ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/multimodal/20220907_084600_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=background__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of ImageTextEncoder model ...\u001b[0m\n",
      "self.multimodal_global_feat_size = 3072\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating validator engine ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR multimodal trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_multimodal_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=8676,61772,79269394504155791).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "generating datasets and dataloaders ...\n",
      "num_workers = 0\n",
      "len(self.test_indices) = 3269\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_241_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6165.pt', 'checkpoint_303_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6217.pt', 'checkpoint_83_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.5965.pt', 'checkpoint_363_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6269.pt', 'checkpoint_568_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6365.pt', 'checkpoint_432_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6300.pt', 'checkpoint_505_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6350.pt', 'checkpoint_162_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6089.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/multimodal/20220907_084600_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/checkpoint_568_b_bg+chxlmacf1+chxlmicf1+cxr14macf1+cxr14micf1+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1=0.6365.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning validator engine ...\u001b[0m\n",
      "Evaluating model ...\n",
      "b_bg 0.84347, oracc 0.99540, qlmacf1 0.23916, qlmicf1 0.50711, chxlmacf1 0.46626, chxlmicf1 0.57922, chxlacc 0.73876, chxlrocaucmic 0.81684, chxlrocaucmac 0.74140, 16.98 secs\n",
      "Question probabilities saved to /home/pamessina/medvqa-workspace/results/multimodal/20220907_084600_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/mimiccxr_question_probs.pkl\n",
      "Metrics successfully saved to /home/pamessina/medvqa-workspace/results/multimodal/20220907_084600_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/mimiccxr_multimodal_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_multimodal_question_classifier.py \\\n",
    "        --checkpoint-folder \"models/multimodal/20220907_084600_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/multimodal/20220913_080931_mim+iu+chexp_imgtxtenc(dense121(niqc)+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   num_workers: 0\n",
      "   device: GPU\n",
      "\u001b[34m----- Evaluating model ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/multimodal/20220913_080931_mim+iu+chexp_imgtxtenc(dense121(niqc)+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=background__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of ImageTextEncoder model ...\u001b[0m\n",
      "self.multimodal_global_feat_size = 1024\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating validator engine ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR multimodal trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_multimodal_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=8676,61772,79269394504155791).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "generating datasets and dataloaders ...\n",
      "num_workers = 0\n",
      "len(self.test_indices) = 3269\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_74_b_bg+chxlmacf1+chxlmicf1+gacc+oracc+qlmacf1+qlmicf1=0.6330.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/multimodal/20220913_080931_mim+iu+chexp_imgtxtenc(dense121(niqc)+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/checkpoint_74_b_bg+chxlmacf1+chxlmicf1+gacc+oracc+qlmacf1+qlmicf1=0.6330.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning validator engine ...\u001b[0m\n",
      "Evaluating model ...\n",
      "b_bg 0.84314, oracc 0.99605, qlmacf1 0.22974, qlmicf1 0.49677, chxlmacf1 0.46307, chxlmicf1 0.56241, chxlacc 0.71252, chxlrocaucmic 0.80370, chxlrocaucmac 0.74370, 18.03 secs\n",
      "Question probabilities saved to /home/pamessina/medvqa-workspace/results/multimodal/20220913_080931_mim+iu+chexp_imgtxtenc(dense121(niqc)+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/mimiccxr_question_probs.pkl\n",
      "Metrics successfully saved to /home/pamessina/medvqa-workspace/results/multimodal/20220913_080931_mim+iu+chexp_imgtxtenc(dense121(niqc)+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/mimiccxr_multimodal_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_multimodal_question_classifier.py \\\n",
    "        --checkpoint-folder \"models/multimodal/20220913_080931_mim+iu+chexp_imgtxtenc(dense121(niqc)+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/multimodal/20220913_062801_mim+iu+chexp_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   num_workers: 0\n",
      "   device: GPU\n",
      "\u001b[34m----- Evaluating model ------\u001b[0m\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/multimodal/20220913_062801_mim+iu+chexp_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=5__mode=background__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating instance of ImageTextEncoder model ...\u001b[0m\n",
      "self.multimodal_global_feat_size = 3072\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating validator engine ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR multimodal trainer ...\u001b[0m\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_multimodal_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=8676,61772,79269394504155791).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "generating datasets and dataloaders ...\n",
      "num_workers = 0\n",
      "len(self.test_indices) = 3269\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_180_b_bg+chxlmacf1+chxlmicf1+gacc+oracc+qlmacf1+qlmicf1=0.6420.pt', 'checkpoint_84_b_bg+chxlmacf1+chxlmicf1+gacc+oracc+qlmacf1+qlmicf1=0.6393.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /home/pamessina/medvqa-workspace/models/multimodal/20220913_062801_mim+iu+chexp_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/checkpoint_180_b_bg+chxlmacf1+chxlmicf1+gacc+oracc+qlmacf1+qlmicf1=0.6420.pt\n",
      "Loading model and epoch only\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning validator engine ...\u001b[0m\n",
      "Evaluating model ...\n",
      "b_bg 0.84211, oracc 0.99605, qlmacf1 0.23408, qlmicf1 0.51629, chxlmacf1 0.46468, chxlmicf1 0.57272, chxlacc 0.72545, chxlrocaucmic 0.81259, chxlrocaucmac 0.74007, 27.23 secs\n",
      "Question probabilities saved to /home/pamessina/medvqa-workspace/results/multimodal/20220913_062801_mim+iu+chexp_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/mimiccxr_question_probs.pkl\n",
      "Metrics successfully saved to /home/pamessina/medvqa-workspace/results/multimodal/20220913_062801_mim+iu+chexp_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp/mimiccxr_multimodal_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_multimodal_question_classifier.py \\\n",
    "        --checkpoint-folder \"models/multimodal/20220913_062801_mim+iu+chexp_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3_orien_chx_ql_amp\" \\\n",
    "        --batch-size 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_pickle('/home/pamessina/medvqa-workspace/results/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/mimiccxr_question_probs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = load_pickle('/home/pamessina/medvqa-workspace/results/multimodal/20220907_043140_mim+iu+chexp+cxr14+vinbig_imgtxtenc(dense121+chx-emb+txtenc=bilstm+txtdec=lstm)_visenc-pretr=0_dws=1.0,0.2,0.3,0.25,0.25_orien_chx_ql_amp/mimiccxr_multimodal_metrics.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
