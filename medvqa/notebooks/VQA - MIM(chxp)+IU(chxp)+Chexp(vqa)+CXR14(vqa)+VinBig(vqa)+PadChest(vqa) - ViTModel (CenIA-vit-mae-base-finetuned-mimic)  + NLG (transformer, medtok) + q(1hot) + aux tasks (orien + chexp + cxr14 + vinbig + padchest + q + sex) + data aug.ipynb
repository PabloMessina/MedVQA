{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: True\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-base-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,5e-4,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 150\n",
      "   iters_to_accumulate: 1\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "Ignore freezing parameter: pooler.dense.weight\n",
      "Ignore freezing parameter: pooler.dense.bias\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-base-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,5e-4,32,1e-6\n",
      "1e-06 8 0.0005 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for CenIA/vit-mae-base-finetuned-mimic\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 150\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=287,3559006002065882738).pkl\n",
      "\tlen(question_datasets) = 92\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 150\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=283,2750089748417475840).pkl\n",
      "\tlen(question_datasets) = 42\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading CXR14 labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n",
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1442: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 133636.76it/s]\n",
      "Done. Example answer: <s> normal </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 135831.25it/s]\n",
      "Done. Example answer: <s> loc hilar , loc cardiac , loc left , loc paracardiac </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 77295.91it/s]\n",
      "Done. Example answer: <s> copd signs calcified granuloma loc hilar loc right upper lobe loc left </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc basal bilateral , loc rib , loc right , loc right upper lobe , loc bronchi </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:25,  7.44it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 12.15034, a_loss 8.55430, cD 0.00020, wmdcmp 0.00170, ema 0.00000, oracc 0.38809, orien_loss 1.15155, qlmicf1 0.09335, qlmacf1 0.08932, ql_loss 1.12909, chxlmicf1 0.35682, chxlmacf1 0.29317, chx_loss 1.10178, chxlacc 0.39000, chxlrocaucmic 0.52989, chxlrocaucmac 0.49304, gacc 0.44103, gloss 0.70510, cxr14micf1 0.14586, cxr14macf1 0.12744, cxr14_loss 1.23873, vnbgmicf1 0.08627, vnbgmacf1 0.12104, vnbg_loss 9.72483, b1 0.00161, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01510, padchxlmicf1 0.00977, padchxlzmacf1 0.02046, padchxlzmicf1 0.01470, padchxl_loss 0.95871, padchxlz_loss 1.02463, 165.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.00014, wmdcmp 0.00173, ema 0.00000, oracc 0.63744, qlmicf1 0.10782, qlmacf1 0.09881, chxlmicf1 0.37357, chxlmacf1 0.30534, chxlacc 0.39829, chxlrocaucmic 0.52901, chxlrocaucmac 0.49242, 30.37 secs\n",
      "Adjusting learning rate of group 0 to 2.1746e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 11.54923, a_loss 8.05960, cD 0.01126, wmdcmp 0.00649, ema 0.00013, oracc 0.65871, orien_loss 1.04316, qlmicf1 0.10593, qlmacf1 0.09757, ql_loss 1.12791, chxlmicf1 0.33972, chxlmacf1 0.29449, chx_loss 1.09973, chxlacc 0.40534, chxlrocaucmic 0.52420, chxlrocaucmac 0.50099, gacc 0.50224, gloss 0.69359, cxr14micf1 0.15371, cxr14macf1 0.12944, cxr14_loss 1.23817, vnbgmicf1 0.09088, vnbgmacf1 0.13163, vnbg_loss 9.06948, b1 0.00932, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01490, padchxlmicf1 0.00867, padchxlzmacf1 0.02045, padchxlzmicf1 0.01446, padchxl_loss 0.95004, padchxlz_loss 1.02216, 143.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.03908, wmdcmp 0.01200, ema 0.00000, oracc 0.63720, qlmicf1 0.13044, qlmacf1 0.10993, chxlmicf1 0.33517, chxlmacf1 0.30536, chxlacc 0.41109, chxlrocaucmic 0.51627, chxlrocaucmac 0.49209, 29.09 secs\n",
      "Adjusting learning rate of group 0 to 4.7287e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 10.21187, a_loss 6.95695, cD 0.03409, wmdcmp 0.00643, ema 0.03056, oracc 0.68060, orien_loss 0.88215, qlmicf1 0.13771, qlmacf1 0.11014, ql_loss 1.12406, chxlmicf1 0.27637, chxlmacf1 0.29493, chx_loss 1.09931, chxlacc 0.45337, chxlrocaucmic 0.52170, chxlrocaucmac 0.51375, gacc 0.56705, gloss 0.68265, cxr14micf1 0.16438, cxr14macf1 0.13089, cxr14_loss 1.23967, vnbgmicf1 0.10461, vnbgmacf1 0.14321, vnbg_loss 7.66851, b1 0.00016, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01590, padchxlmicf1 0.00977, padchxlzmacf1 0.02225, padchxlzmicf1 0.01526, padchxl_loss 0.93922, padchxlz_loss 1.00761, 140.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.01509, wmdcmp 0.00222, ema 0.03044, oracc 0.67468, qlmicf1 0.16644, qlmacf1 0.11934, chxlmicf1 0.27433, chxlmacf1 0.30239, chxlacc 0.48064, chxlrocaucmic 0.52176, chxlrocaucmac 0.51469, 30.42 secs\n",
      "Adjusting learning rate of group 0 to 1.0283e-05.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 10.16123, a_loss 5.77526, cD 0.05512, wmdcmp 0.00972, ema 0.02667, oracc 0.76390, orien_loss 0.67657, qlmicf1 0.20910, qlmacf1 0.12368, ql_loss 1.10399, chxlmicf1 0.29166, chxlmacf1 0.31514, chx_loss 1.09674, chxlacc 0.53226, chxlrocaucmic 0.57423, chxlrocaucmac 0.55923, gacc 0.55962, gloss 0.66993, cxr14micf1 0.16721, cxr14macf1 0.15234, cxr14_loss 1.23552, vnbgmicf1 0.12070, vnbgmacf1 0.15564, vnbg_loss 6.26239, b1 0.00058, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.01752, padchxlmicf1 0.01753, padchxlzmacf1 0.02667, padchxlzmicf1 0.02545, padchxl_loss 0.90824, padchxlz_loss 0.98782, 149.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.08767, wmdcmp 0.01358, ema 0.00000, oracc 0.84748, qlmicf1 0.22962, qlmacf1 0.13093, chxlmicf1 0.33788, chxlmacf1 0.33506, chxlacc 0.53166, chxlrocaucmic 0.59695, chxlrocaucmac 0.56505, 30.22 secs\n",
      "Adjusting learning rate of group 0 to 2.2361e-05.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 9.35773, a_loss 4.62581, cD 0.06140, wmdcmp 0.01297, ema 0.02252, oracc 0.84291, orien_loss 0.47947, qlmicf1 0.23758, qlmacf1 0.13402, ql_loss 1.08106, chxlmicf1 0.37601, chxlmacf1 0.35069, chx_loss 1.08849, chxlacc 0.55708, chxlrocaucmic 0.64313, chxlrocaucmac 0.60329, gacc 0.63283, gloss 0.64790, cxr14micf1 0.15646, cxr14macf1 0.19202, cxr14_loss 1.23352, vnbgmicf1 0.17315, vnbgmacf1 0.18928, vnbg_loss 5.05693, b1 0.00821, b2 0.00000, b3 0.00000, b4 0.00000, padchxlmacf1 0.02225, padchxlmicf1 0.05825, padchxlzmacf1 0.03449, padchxlzmicf1 0.05916, padchxl_loss 0.83089, padchxlz_loss 0.91426, 155.28 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 0.08765, wmdcmp 0.01358, ema 0.00000, oracc 0.90146, qlmicf1 0.23172, qlmacf1 0.13955, chxlmicf1 0.42204, chxlmacf1 0.36310, chxlacc 0.55740, chxlrocaucmic 0.65557, chxlrocaucmac 0.59104, 31.92 secs\n",
      "Adjusting learning rate of group 0 to 4.8625e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 5.44558, a_loss 3.50920, cD 0.07486, wmdcmp 0.01765, ema 0.02338, oracc 0.88808, orien_loss 0.30788, qlmicf1 0.22181, qlmacf1 0.14206, ql_loss 1.06512, chxlmicf1 0.40304, chxlmacf1 0.36150, chx_loss 1.07223, chxlacc 0.55823, chxlrocaucmic 0.65927, chxlrocaucmac 0.61905, gacc 0.72635, gloss 0.59806, cxr14micf1 0.15544, cxr14macf1 0.20312, cxr14_loss 1.21791, vnbgmicf1 0.19393, vnbgmacf1 0.20060, vnbg_loss 3.91133, b1 0.03163, b2 0.01554, b3 0.00752, b4 0.00393, padchxlmacf1 0.02552, padchxlmicf1 0.07645, padchxlzmacf1 0.04383, padchxlzmicf1 0.08714, padchxl_loss 0.73087, padchxlz_loss 0.84628, 154.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.14684, wmdcmp 0.02493, ema 0.03581, oracc 0.94625, qlmicf1 0.21696, qlmacf1 0.14930, chxlmicf1 0.42762, chxlmacf1 0.37320, chxlacc 0.55904, chxlrocaucmic 0.66451, chxlrocaucmac 0.61630, 32.52 secs\n",
      "Adjusting learning rate of group 0 to 1.0574e-04.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 3.76894, a_loss 2.70558, cD 0.14544, wmdcmp 0.03072, ema 0.06545, oracc 0.93535, orien_loss 0.18888, qlmicf1 0.21192, qlmacf1 0.14681, ql_loss 1.04993, chxlmicf1 0.40009, chxlmacf1 0.36285, chx_loss 1.06688, chxlacc 0.56408, chxlrocaucmic 0.66328, chxlrocaucmac 0.63014, gacc 0.81644, gloss 0.49377, cxr14micf1 0.16003, cxr14macf1 0.20629, cxr14_loss 1.20192, vnbgmicf1 0.22120, vnbgmacf1 0.21164, vnbg_loss 3.06835, b1 0.10596, b2 0.06822, b3 0.04782, b4 0.03499, padchxlmacf1 0.02801, padchxlmicf1 0.07451, padchxlzmacf1 0.04633, padchxlzmicf1 0.08175, padchxl_loss 0.67472, padchxlz_loss 0.80432, 157.86 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.16323, wmdcmp 0.02601, ema 0.21934, oracc 0.95898, qlmicf1 0.21881, qlmacf1 0.15357, chxlmicf1 0.43134, chxlmacf1 0.37480, chxlacc 0.58067, chxlrocaucmic 0.67428, chxlrocaucmac 0.63543, 31.61 secs\n",
      "Adjusting learning rate of group 0 to 2.2993e-04.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000230) ...\n",
      "loss 7.11451, a_loss 2.07079, cD 0.31170, wmdcmp 0.05265, ema 0.29885, oracc 0.95631, orien_loss 0.11907, qlmicf1 0.22290, qlmacf1 0.15515, ql_loss 1.04351, chxlmicf1 0.39734, chxlmacf1 0.37018, chx_loss 1.05281, chxlacc 0.58743, chxlrocaucmic 0.67486, chxlrocaucmac 0.64934, gacc 0.85340, gloss 0.37835, cxr14micf1 0.17123, cxr14macf1 0.21622, cxr14_loss 1.18618, vnbgmicf1 0.27329, vnbgmacf1 0.24477, vnbg_loss 2.22911, b1 0.23728, b2 0.16090, b3 0.11377, b4 0.08314, padchxlmacf1 0.03203, padchxlmicf1 0.07455, padchxlzmacf1 0.05158, padchxlzmicf1 0.07573, padchxl_loss 0.66563, padchxlz_loss 0.79384, 160.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.15683, wmdcmp 0.02660, ema 0.49955, oracc 0.96841, qlmicf1 0.23619, qlmacf1 0.16520, chxlmicf1 0.44334, chxlmacf1 0.39215, chxlacc 0.60723, chxlrocaucmic 0.69901, chxlrocaucmac 0.66008, 32.12 secs\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000500) ...\n",
      "loss 1.88991, a_loss 1.62909, cD 0.53435, wmdcmp 0.08051, ema 0.41104, oracc 0.96912, orien_loss 0.07838, qlmicf1 0.24046, qlmacf1 0.16416, ql_loss 1.02090, chxlmicf1 0.41306, chxlmacf1 0.38541, chx_loss 1.02758, chxlacc 0.61390, chxlrocaucmic 0.69421, chxlrocaucmac 0.67159, gacc 0.84500, gloss 0.36015, cxr14micf1 0.18119, cxr14macf1 0.22320, cxr14_loss 1.18082, vnbgmicf1 0.33084, vnbgmacf1 0.27793, vnbg_loss 1.68980, b1 0.38984, b2 0.26808, b3 0.18349, b4 0.12872, padchxlmacf1 0.03925, padchxlmicf1 0.08205, padchxlzmacf1 0.05804, padchxlzmicf1 0.08664, padchxl_loss 0.64081, padchxlz_loss 0.78127, 163.27 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.50159, wmdcmp 0.07251, ema 0.52551, oracc 0.97643, qlmicf1 0.26176, qlmacf1 0.17820, chxlmicf1 0.40625, chxlmacf1 0.38784, chxlacc 0.63176, chxlrocaucmic 0.68842, chxlrocaucmac 0.66988, 32.94 secs\n",
      "Adjusting learning rate of group 0 to 4.1174e-04.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000412) ...\n",
      "loss 2.18440, a_loss 1.38066, cD 0.79235, wmdcmp 0.11223, ema 0.48131, oracc 0.97189, orien_loss 0.06554, qlmicf1 0.24732, qlmacf1 0.16917, ql_loss 1.01213, chxlmicf1 0.42326, chxlmacf1 0.39343, chx_loss 1.01541, chxlacc 0.62203, chxlrocaucmic 0.70225, chxlrocaucmac 0.68242, gacc 0.89551, gloss 0.26956, cxr14micf1 0.21741, cxr14macf1 0.24854, cxr14_loss 1.14304, vnbgmicf1 0.38125, vnbgmacf1 0.29783, vnbg_loss 1.36079, b1 0.41895, b2 0.30412, b3 0.21851, b4 0.15750, padchxlmacf1 0.04381, padchxlmicf1 0.09119, padchxlzmacf1 0.06161, padchxlzmicf1 0.09600, padchxl_loss 0.62284, padchxlz_loss 0.76664, 160.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 0.91242, wmdcmp 0.13108, ema 0.55327, oracc 0.98067, qlmicf1 0.24844, qlmacf1 0.17942, chxlmicf1 0.45460, chxlmacf1 0.40722, chxlacc 0.61899, chxlrocaucmic 0.71645, chxlrocaucmac 0.68431, 32.64 secs\n",
      "Adjusting learning rate of group 0 to 3.3907e-04.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000339) ...\n",
      "loss 1.54373, a_loss 1.28188, cD 0.93531, wmdcmp 0.13038, ema 0.51049, oracc 0.97450, orien_loss 0.06089, qlmicf1 0.25030, qlmacf1 0.17136, ql_loss 1.00400, chxlmicf1 0.42922, chxlmacf1 0.39630, chx_loss 1.00974, chxlacc 0.62479, chxlrocaucmic 0.70642, chxlrocaucmac 0.68632, gacc 0.89467, gloss 0.26545, cxr14micf1 0.20885, cxr14macf1 0.24308, cxr14_loss 1.14691, vnbgmicf1 0.41065, vnbgmacf1 0.31297, vnbg_loss 1.25026, b1 0.44355, b2 0.33270, b3 0.24694, b4 0.18364, padchxlmacf1 0.04485, padchxlmicf1 0.09560, padchxlzmacf1 0.06410, padchxlzmicf1 0.10049, padchxl_loss 0.59963, padchxlz_loss 0.74897, 161.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.08424, wmdcmp 0.14944, ema 0.59445, oracc 0.97878, qlmicf1 0.27000, qlmacf1 0.18353, chxlmicf1 0.41829, chxlmacf1 0.39304, chxlacc 0.65304, chxlrocaucmic 0.69765, chxlrocaucmac 0.67934, 31.14 secs\n",
      "Adjusting learning rate of group 0 to 2.7922e-04.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000279) ...\n",
      "loss 5.19187, a_loss 1.24056, cD 1.01290, wmdcmp 0.14051, ema 0.54327, oracc 0.97331, orien_loss 0.05943, qlmicf1 0.25341, qlmacf1 0.17175, ql_loss 1.00278, chxlmicf1 0.43135, chxlmacf1 0.39736, chx_loss 1.00655, chxlacc 0.62782, chxlrocaucmic 0.71029, chxlrocaucmac 0.69017, gacc 0.89962, gloss 0.24804, cxr14micf1 0.22347, cxr14macf1 0.25267, cxr14_loss 1.12704, vnbgmicf1 0.41806, vnbgmacf1 0.32008, vnbg_loss 1.17471, b1 0.45358, b2 0.34115, b3 0.25398, b4 0.19016, padchxlmacf1 0.04675, padchxlmicf1 0.09821, padchxlzmacf1 0.06504, padchxlzmicf1 0.10209, padchxl_loss 0.60740, padchxlz_loss 0.74603, 159.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.11891, wmdcmp 0.16102, ema 0.62220, oracc 0.97902, qlmicf1 0.25806, qlmacf1 0.18229, chxlmicf1 0.45805, chxlmacf1 0.41275, chxlacc 0.62255, chxlrocaucmic 0.71809, chxlrocaucmac 0.68671, 32.24 secs\n",
      "Adjusting learning rate of group 0 to 2.2993e-04.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000230) ...\n",
      "loss 3.16393, a_loss 1.18805, cD 1.07346, wmdcmp 0.14853, ema 0.55439, oracc 0.97492, orien_loss 0.05422, qlmicf1 0.25937, qlmacf1 0.17413, ql_loss 0.99344, chxlmicf1 0.43609, chxlmacf1 0.40058, chx_loss 1.00295, chxlacc 0.63178, chxlrocaucmic 0.71349, chxlrocaucmac 0.69428, gacc 0.90184, gloss 0.25163, cxr14micf1 0.21644, cxr14macf1 0.25044, cxr14_loss 1.12833, vnbgmicf1 0.42435, vnbgmacf1 0.32037, vnbg_loss 1.13515, b1 0.46151, b2 0.35019, b3 0.26526, b4 0.20316, padchxlmacf1 0.04778, padchxlmicf1 0.09630, padchxlzmacf1 0.06482, padchxlzmicf1 0.10040, padchxl_loss 0.58677, padchxlz_loss 0.72500, 160.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.12839, wmdcmp 0.15614, ema 0.61235, oracc 0.97855, qlmicf1 0.27009, qlmacf1 0.18385, chxlmicf1 0.45990, chxlmacf1 0.41349, chxlacc 0.63398, chxlrocaucmic 0.71977, chxlrocaucmac 0.68865, 32.04 secs\n",
      "Adjusting learning rate of group 0 to 1.8935e-04.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000189) ...\n",
      "loss 4.61147, a_loss 1.17900, cD 1.11305, wmdcmp 0.15335, ema 0.56429, oracc 0.97454, orien_loss 0.05784, qlmicf1 0.25725, qlmacf1 0.17495, ql_loss 0.99352, chxlmicf1 0.43530, chxlmacf1 0.40007, chx_loss 1.00027, chxlacc 0.63290, chxlrocaucmic 0.71336, chxlrocaucmac 0.69631, gacc 0.90385, gloss 0.24380, cxr14micf1 0.21852, cxr14macf1 0.25021, cxr14_loss 1.13171, vnbgmicf1 0.42014, vnbgmacf1 0.31929, vnbg_loss 1.12671, b1 0.46896, b2 0.35768, b3 0.26864, b4 0.20242, padchxlmacf1 0.04751, padchxlmicf1 0.09638, padchxlzmacf1 0.06547, padchxlzmicf1 0.10329, padchxl_loss 0.58622, padchxlz_loss 0.74881, 160.81 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.17457, wmdcmp 0.16114, ema 0.59266, oracc 0.98020, qlmicf1 0.27605, qlmacf1 0.18667, chxlmicf1 0.46449, chxlmacf1 0.41379, chxlacc 0.64963, chxlrocaucmic 0.72140, chxlrocaucmac 0.69063, 31.53 secs\n",
      "Adjusting learning rate of group 0 to 1.5592e-04.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000156) ...\n",
      "loss 2.05517, a_loss 1.14624, cD 1.14741, wmdcmp 0.15732, ema 0.57244, oracc 0.97598, orien_loss 0.05494, qlmicf1 0.25831, qlmacf1 0.17528, ql_loss 0.99467, chxlmicf1 0.43904, chxlmacf1 0.40313, chx_loss 0.99818, chxlacc 0.63324, chxlrocaucmic 0.71568, chxlrocaucmac 0.69665, gacc 0.90564, gloss 0.23650, cxr14micf1 0.23280, cxr14macf1 0.25905, cxr14_loss 1.11111, vnbgmicf1 0.43254, vnbgmacf1 0.32701, vnbg_loss 1.09896, b1 0.46836, b2 0.35840, b3 0.27151, b4 0.20740, padchxlmacf1 0.04728, padchxlmicf1 0.09866, padchxlzmacf1 0.06495, padchxlzmicf1 0.10182, padchxl_loss 0.58011, padchxlz_loss 0.72701, 161.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.16682, wmdcmp 0.16239, ema 0.63384, oracc 0.98020, qlmicf1 0.26973, qlmacf1 0.18831, chxlmicf1 0.46559, chxlmacf1 0.41844, chxlacc 0.62666, chxlrocaucmic 0.72984, chxlrocaucmac 0.69224, 31.31 secs\n",
      "Adjusting learning rate of group 0 to 1.2840e-04.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000128) ...\n",
      "loss 4.94769, a_loss 1.14377, cD 1.17847, wmdcmp 0.16121, ema 0.57170, oracc 0.97625, orien_loss 0.05080, qlmicf1 0.26000, qlmacf1 0.17527, ql_loss 0.98761, chxlmicf1 0.43760, chxlmacf1 0.40253, chx_loss 0.99775, chxlacc 0.63368, chxlrocaucmic 0.71654, chxlrocaucmac 0.69767, gacc 0.91122, gloss 0.22718, cxr14micf1 0.22533, cxr14macf1 0.25567, cxr14_loss 1.11523, vnbgmicf1 0.43835, vnbgmacf1 0.33427, vnbg_loss 1.08390, b1 0.48342, b2 0.37320, b3 0.28478, b4 0.21884, padchxlmacf1 0.04980, padchxlmicf1 0.10442, padchxlzmacf1 0.06829, padchxlzmicf1 0.10810, padchxl_loss 0.57601, padchxlz_loss 0.72022, 161.24 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.23024, wmdcmp 0.17104, ema 0.62220, oracc 0.98303, qlmicf1 0.26767, qlmacf1 0.18681, chxlmicf1 0.46357, chxlmacf1 0.41537, chxlacc 0.63809, chxlrocaucmic 0.72437, chxlrocaucmac 0.69243, 31.84 secs\n",
      "Adjusting learning rate of group 0 to 1.0574e-04.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000106) ...\n",
      "loss 1.61481, a_loss 1.12217, cD 1.19012, wmdcmp 0.16188, ema 0.57270, oracc 0.97598, orien_loss 0.05231, qlmicf1 0.25996, qlmacf1 0.17624, ql_loss 0.98832, chxlmicf1 0.43794, chxlmacf1 0.40196, chx_loss 0.99895, chxlacc 0.63614, chxlrocaucmic 0.71656, chxlrocaucmac 0.69811, gacc 0.91181, gloss 0.22216, cxr14micf1 0.23270, cxr14macf1 0.25923, cxr14_loss 1.11519, vnbgmicf1 0.43893, vnbgmacf1 0.33376, vnbg_loss 1.08305, b1 0.48359, b2 0.37573, b3 0.28805, b4 0.22318, padchxlmacf1 0.04973, padchxlmicf1 0.09886, padchxlzmacf1 0.06667, padchxlzmicf1 0.10331, padchxl_loss 0.58138, padchxlz_loss 0.73798, 157.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26424, wmdcmp 0.17425, ema 0.61862, oracc 0.98020, qlmicf1 0.27421, qlmacf1 0.18808, chxlmicf1 0.46943, chxlmacf1 0.42045, chxlacc 0.62614, chxlrocaucmic 0.73331, chxlrocaucmac 0.69505, 32.29 secs\n",
      "Adjusting learning rate of group 0 to 8.7073e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000087) ...\n",
      "loss 1.38266, a_loss 1.11190, cD 1.21541, wmdcmp 0.16522, ema 0.58169, oracc 0.97824, orien_loss 0.04919, qlmicf1 0.26026, qlmacf1 0.17600, ql_loss 0.98482, chxlmicf1 0.44172, chxlmacf1 0.40584, chx_loss 0.99375, chxlacc 0.63659, chxlrocaucmic 0.71973, chxlrocaucmac 0.70032, gacc 0.91206, gloss 0.22136, cxr14micf1 0.22990, cxr14macf1 0.25795, cxr14_loss 1.11321, vnbgmicf1 0.43648, vnbgmacf1 0.33112, vnbg_loss 1.08157, b1 0.49367, b2 0.38313, b3 0.29274, b4 0.22517, padchxlmacf1 0.05140, padchxlmicf1 0.09953, padchxlzmacf1 0.06688, padchxlzmicf1 0.10264, padchxl_loss 0.57678, padchxlz_loss 0.73205, 159.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26813, wmdcmp 0.17461, ema 0.61056, oracc 0.98020, qlmicf1 0.26882, qlmacf1 0.18618, chxlmicf1 0.46740, chxlmacf1 0.41904, chxlacc 0.62996, chxlrocaucmic 0.73067, chxlrocaucmac 0.69434, 31.59 secs\n",
      "Adjusting learning rate of group 0 to 7.1704e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000072) ...\n",
      "loss 2.14093, a_loss 1.11120, cD 1.23166, wmdcmp 0.16685, ema 0.58418, oracc 0.97566, orien_loss 0.04980, qlmicf1 0.26373, qlmacf1 0.17713, ql_loss 0.98308, chxlmicf1 0.44098, chxlmacf1 0.40508, chx_loss 0.99539, chxlacc 0.63491, chxlrocaucmic 0.71841, chxlrocaucmac 0.69910, gacc 0.91365, gloss 0.22132, cxr14micf1 0.23854, cxr14macf1 0.26337, cxr14_loss 1.11116, vnbgmicf1 0.43593, vnbgmacf1 0.33076, vnbg_loss 1.07330, b1 0.50091, b2 0.38809, b3 0.29414, b4 0.22220, padchxlmacf1 0.05165, padchxlmicf1 0.10346, padchxlzmacf1 0.06696, padchxlzmicf1 0.10532, padchxl_loss 0.57444, padchxlz_loss 0.73768, 158.34 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.20985, wmdcmp 0.16689, ema 0.62936, oracc 0.98114, qlmicf1 0.26949, qlmacf1 0.18744, chxlmicf1 0.46281, chxlmacf1 0.41459, chxlacc 0.64581, chxlrocaucmic 0.72216, chxlrocaucmac 0.69530, 32.26 secs\n",
      "Adjusting learning rate of group 0 to 5.9047e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 4.91185, a_loss 1.10196, cD 1.24226, wmdcmp 0.16769, ema 0.58830, oracc 0.97543, orien_loss 0.05386, qlmicf1 0.26062, qlmacf1 0.17832, ql_loss 0.98656, chxlmicf1 0.44361, chxlmacf1 0.40757, chx_loss 0.98900, chxlacc 0.63982, chxlrocaucmic 0.72164, chxlrocaucmac 0.70422, gacc 0.91109, gloss 0.22237, cxr14micf1 0.23988, cxr14macf1 0.26297, cxr14_loss 1.10741, vnbgmicf1 0.43698, vnbgmacf1 0.33325, vnbg_loss 1.06419, b1 0.48421, b2 0.37745, b3 0.28986, b4 0.22358, padchxlmacf1 0.05104, padchxlmicf1 0.10146, padchxlzmacf1 0.06751, padchxlzmicf1 0.10463, padchxl_loss 0.57242, padchxlz_loss 0.71774, 157.60 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29179, wmdcmp 0.17422, ema 0.62757, oracc 0.98326, qlmicf1 0.26706, qlmacf1 0.18707, chxlmicf1 0.47195, chxlmacf1 0.42125, chxlacc 0.64568, chxlrocaucmic 0.73144, chxlrocaucmac 0.69723, 32.73 secs\n",
      "Adjusting learning rate of group 0 to 4.8625e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 2.69127, a_loss 1.09361, cD 1.26303, wmdcmp 0.17000, ema 0.59145, oracc 0.97647, orien_loss 0.05184, qlmicf1 0.26346, qlmacf1 0.17742, ql_loss 0.98199, chxlmicf1 0.44189, chxlmacf1 0.40614, chx_loss 0.99126, chxlacc 0.63838, chxlrocaucmic 0.72109, chxlrocaucmac 0.70384, gacc 0.91137, gloss 0.22718, cxr14micf1 0.22809, cxr14macf1 0.25577, cxr14_loss 1.10933, vnbgmicf1 0.43311, vnbgmacf1 0.33096, vnbg_loss 1.06387, b1 0.49119, b2 0.38034, b3 0.29046, b4 0.22258, padchxlmacf1 0.05211, padchxlmicf1 0.10648, padchxlzmacf1 0.07168, padchxlzmicf1 0.10621, padchxl_loss 0.55383, padchxlz_loss 0.72224, 159.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34243, wmdcmp 0.18140, ema 0.64011, oracc 0.98232, qlmicf1 0.27411, qlmacf1 0.18810, chxlmicf1 0.47633, chxlmacf1 0.42314, chxlacc 0.64616, chxlrocaucmic 0.73700, chxlrocaucmac 0.69916, 31.76 secs\n",
      "Adjusting learning rate of group 0 to 4.0042e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 1.09755, a_loss 1.09023, cD 1.26097, wmdcmp 0.17017, ema 0.59222, oracc 0.97587, orien_loss 0.05500, qlmicf1 0.26248, qlmacf1 0.17788, ql_loss 0.98371, chxlmicf1 0.44298, chxlmacf1 0.40670, chx_loss 0.99201, chxlacc 0.63731, chxlrocaucmic 0.71947, chxlrocaucmac 0.70222, gacc 0.91391, gloss 0.21917, cxr14micf1 0.24064, cxr14macf1 0.26356, cxr14_loss 1.10220, vnbgmicf1 0.43985, vnbgmacf1 0.33162, vnbg_loss 1.05884, b1 0.49882, b2 0.38799, b3 0.29728, b4 0.22804, padchxlmacf1 0.04960, padchxlmicf1 0.10094, padchxlzmacf1 0.06989, padchxlzmicf1 0.10834, padchxl_loss 0.57470, padchxlz_loss 0.74455, 161.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29656, wmdcmp 0.17685, ema 0.62489, oracc 0.98114, qlmicf1 0.27045, qlmacf1 0.18670, chxlmicf1 0.47102, chxlmacf1 0.42155, chxlacc 0.64136, chxlrocaucmic 0.73076, chxlrocaucmac 0.69751, 31.52 secs\n",
      "Adjusting learning rate of group 0 to 3.2974e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 2.18095, a_loss 1.08002, cD 1.27394, wmdcmp 0.17248, ema 0.59582, oracc 0.97702, orien_loss 0.04815, qlmicf1 0.26367, qlmacf1 0.17736, ql_loss 0.98542, chxlmicf1 0.44228, chxlmacf1 0.40575, chx_loss 0.99317, chxlacc 0.63845, chxlrocaucmic 0.72151, chxlrocaucmac 0.70204, gacc 0.91147, gloss 0.22518, cxr14micf1 0.23391, cxr14macf1 0.25894, cxr14_loss 1.10924, vnbgmicf1 0.43632, vnbgmacf1 0.32892, vnbg_loss 1.07348, b1 0.48978, b2 0.38490, b3 0.29881, b4 0.23131, padchxlmacf1 0.05001, padchxlmicf1 0.10652, padchxlzmacf1 0.07076, padchxlzmicf1 0.10839, padchxl_loss 0.55647, padchxlz_loss 0.71788, 163.21 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.29782, wmdcmp 0.17754, ema 0.63205, oracc 0.98256, qlmicf1 0.27195, qlmacf1 0.18763, chxlmicf1 0.46861, chxlmacf1 0.42141, chxlacc 0.64465, chxlrocaucmic 0.72582, chxlrocaucmac 0.70017, 32.54 secs\n",
      "Adjusting learning rate of group 0 to 2.7154e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.82621, a_loss 1.09224, cD 1.26520, wmdcmp 0.17052, ema 0.59538, oracc 0.97785, orien_loss 0.05008, qlmicf1 0.26471, qlmacf1 0.17849, ql_loss 0.98102, chxlmicf1 0.44235, chxlmacf1 0.40584, chx_loss 0.99200, chxlacc 0.63819, chxlrocaucmic 0.72052, chxlrocaucmac 0.70225, gacc 0.91160, gloss 0.22147, cxr14micf1 0.23892, cxr14macf1 0.26322, cxr14_loss 1.10576, vnbgmicf1 0.44287, vnbgmacf1 0.33306, vnbg_loss 1.04859, b1 0.49689, b2 0.38832, b3 0.29916, b4 0.23121, padchxlmacf1 0.05118, padchxlmicf1 0.10087, padchxlzmacf1 0.07004, padchxlzmicf1 0.10561, padchxl_loss 0.56145, padchxlz_loss 0.72915, 163.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33054, wmdcmp 0.18066, ema 0.63205, oracc 0.98138, qlmicf1 0.27235, qlmacf1 0.18817, chxlmicf1 0.46790, chxlmacf1 0.41976, chxlacc 0.63829, chxlrocaucmic 0.72998, chxlrocaucmac 0.69941, 31.98 secs\n",
      "Adjusting learning rate of group 0 to 2.2361e-05.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 2.07929, a_loss 1.08171, cD 1.26362, wmdcmp 0.17056, ema 0.59525, oracc 0.97695, orien_loss 0.04775, qlmicf1 0.26220, qlmacf1 0.17707, ql_loss 0.98407, chxlmicf1 0.44327, chxlmacf1 0.40705, chx_loss 0.98968, chxlacc 0.63927, chxlrocaucmic 0.72047, chxlrocaucmac 0.70393, gacc 0.91295, gloss 0.21842, cxr14micf1 0.24025, cxr14macf1 0.26505, cxr14_loss 1.10269, vnbgmicf1 0.43571, vnbgmacf1 0.33028, vnbg_loss 1.04904, b1 0.50048, b2 0.39285, b3 0.30336, b4 0.23327, padchxlmacf1 0.05174, padchxlmicf1 0.10474, padchxlzmacf1 0.06982, padchxlzmicf1 0.11049, padchxl_loss 0.56130, padchxlz_loss 0.72366, 163.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33309, wmdcmp 0.18183, ema 0.62847, oracc 0.98138, qlmicf1 0.27558, qlmacf1 0.18826, chxlmicf1 0.47167, chxlmacf1 0.42227, chxlacc 0.64134, chxlrocaucmic 0.73220, chxlrocaucmac 0.69737, 30.41 secs\n",
      "Adjusting learning rate of group 0 to 1.8414e-05.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 1.27098, a_loss 1.07872, cD 1.27699, wmdcmp 0.17207, ema 0.59085, oracc 0.97695, orien_loss 0.04954, qlmicf1 0.26349, qlmacf1 0.17781, ql_loss 0.98271, chxlmicf1 0.44592, chxlmacf1 0.41015, chx_loss 0.98788, chxlacc 0.63935, chxlrocaucmic 0.72468, chxlrocaucmac 0.70565, gacc 0.91784, gloss 0.21483, cxr14micf1 0.23804, cxr14macf1 0.26288, cxr14_loss 1.10392, vnbgmicf1 0.44059, vnbgmacf1 0.33435, vnbg_loss 1.06281, b1 0.49791, b2 0.38928, b3 0.29958, b4 0.23141, padchxlmacf1 0.05071, padchxlmicf1 0.10400, padchxlzmacf1 0.06902, padchxlzmicf1 0.11056, padchxl_loss 0.56271, padchxlz_loss 0.72480, 139.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29062, wmdcmp 0.17734, ema 0.63295, oracc 0.98091, qlmicf1 0.27176, qlmacf1 0.18800, chxlmicf1 0.47139, chxlmacf1 0.42191, chxlacc 0.64087, chxlrocaucmic 0.73163, chxlrocaucmac 0.69710, 30.08 secs\n",
      "Adjusting learning rate of group 0 to 1.5163e-05.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 4.77282, a_loss 1.08799, cD 1.25723, wmdcmp 0.16894, ema 0.59558, oracc 0.97607, orien_loss 0.05208, qlmicf1 0.26245, qlmacf1 0.17799, ql_loss 0.97818, chxlmicf1 0.44425, chxlmacf1 0.40730, chx_loss 0.98760, chxlacc 0.64028, chxlrocaucmic 0.72349, chxlrocaucmac 0.70624, gacc 0.91013, gloss 0.22563, cxr14micf1 0.23126, cxr14macf1 0.25946, cxr14_loss 1.10971, vnbgmicf1 0.43662, vnbgmacf1 0.33500, vnbg_loss 1.05344, b1 0.50434, b2 0.39612, b3 0.30825, b4 0.24076, padchxlmacf1 0.05196, padchxlmicf1 0.10484, padchxlzmacf1 0.06982, padchxlzmicf1 0.10674, padchxl_loss 0.55701, padchxlz_loss 0.71814, 133.42 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32820, wmdcmp 0.18110, ema 0.62220, oracc 0.98091, qlmicf1 0.27522, qlmacf1 0.18768, chxlmicf1 0.47330, chxlmacf1 0.42248, chxlacc 0.64503, chxlrocaucmic 0.73282, chxlrocaucmac 0.69855, 29.57 secs\n",
      "Adjusting learning rate of group 0 to 1.2487e-05.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 3.01137, a_loss 1.07435, cD 1.27827, wmdcmp 0.17278, ema 0.59525, oracc 0.97627, orien_loss 0.05188, qlmicf1 0.26652, qlmacf1 0.17926, ql_loss 0.97855, chxlmicf1 0.44393, chxlmacf1 0.40714, chx_loss 0.98877, chxlacc 0.64032, chxlrocaucmic 0.72264, chxlrocaucmac 0.70406, gacc 0.91314, gloss 0.22809, cxr14micf1 0.22839, cxr14macf1 0.25690, cxr14_loss 1.11132, vnbgmicf1 0.44317, vnbgmacf1 0.33809, vnbg_loss 1.04541, b1 0.49948, b2 0.39112, b3 0.30390, b4 0.23843, padchxlmacf1 0.04953, padchxlmicf1 0.10261, padchxlzmacf1 0.06730, padchxlzmicf1 0.10282, padchxl_loss 0.57632, padchxlz_loss 0.72774, 133.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32391, wmdcmp 0.18048, ema 0.63921, oracc 0.98091, qlmicf1 0.27287, qlmacf1 0.18671, chxlmicf1 0.47182, chxlmacf1 0.42267, chxlacc 0.64408, chxlrocaucmic 0.73098, chxlrocaucmac 0.69834, 28.93 secs\n",
      "Adjusting learning rate of group 0 to 1.0283e-05.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.05684, a_loss 1.07456, cD 1.29112, wmdcmp 0.17370, ema 0.59860, oracc 0.97692, orien_loss 0.05026, qlmicf1 0.26542, qlmacf1 0.17811, ql_loss 0.97788, chxlmicf1 0.44164, chxlmacf1 0.40602, chx_loss 0.99081, chxlacc 0.63882, chxlrocaucmic 0.72216, chxlrocaucmac 0.70472, gacc 0.91628, gloss 0.21370, cxr14micf1 0.24962, cxr14macf1 0.26927, cxr14_loss 1.09980, vnbgmicf1 0.44447, vnbgmacf1 0.33703, vnbg_loss 1.03505, b1 0.50143, b2 0.39468, b3 0.30587, b4 0.23768, padchxlmacf1 0.05253, padchxlmicf1 0.10258, padchxlzmacf1 0.06825, padchxlzmicf1 0.10681, padchxl_loss 0.56243, padchxlz_loss 0.71320, 132.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30601, wmdcmp 0.17801, ema 0.63384, oracc 0.97949, qlmicf1 0.27378, qlmacf1 0.18763, chxlmicf1 0.47331, chxlmacf1 0.42239, chxlacc 0.64428, chxlrocaucmic 0.73322, chxlrocaucmac 0.69859, 28.86 secs\n",
      "Adjusting learning rate of group 0 to 8.4678e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 1.52588, a_loss 1.07143, cD 1.28943, wmdcmp 0.17405, ema 0.59368, oracc 0.97656, orien_loss 0.05196, qlmicf1 0.26246, qlmacf1 0.17763, ql_loss 0.97964, chxlmicf1 0.44290, chxlmacf1 0.40677, chx_loss 0.99070, chxlacc 0.63886, chxlrocaucmic 0.72228, chxlrocaucmac 0.70374, gacc 0.91175, gloss 0.22383, cxr14micf1 0.23747, cxr14macf1 0.26285, cxr14_loss 1.09888, vnbgmicf1 0.44325, vnbgmacf1 0.33525, vnbg_loss 1.04183, b1 0.50310, b2 0.39493, b3 0.30532, b4 0.23520, padchxlmacf1 0.05184, padchxlmicf1 0.10690, padchxlzmacf1 0.07056, padchxlzmicf1 0.11009, padchxl_loss 0.56326, padchxlz_loss 0.71800, 130.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33315, wmdcmp 0.18056, ema 0.63474, oracc 0.98043, qlmicf1 0.27012, qlmacf1 0.18729, chxlmicf1 0.47139, chxlmacf1 0.42177, chxlacc 0.63925, chxlrocaucmic 0.73387, chxlrocaucmac 0.69870, 28.97 secs\n",
      "Adjusting learning rate of group 0 to 6.9731e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.74533, a_loss 1.08056, cD 1.27647, wmdcmp 0.17110, ema 0.59346, oracc 0.97778, orien_loss 0.04965, qlmicf1 0.26550, qlmacf1 0.17832, ql_loss 0.98116, chxlmicf1 0.44444, chxlmacf1 0.40802, chx_loss 0.98714, chxlacc 0.63994, chxlrocaucmic 0.72266, chxlrocaucmac 0.70516, gacc 0.91205, gloss 0.21731, cxr14micf1 0.23543, cxr14macf1 0.26085, cxr14_loss 1.11327, vnbgmicf1 0.43458, vnbgmacf1 0.32718, vnbg_loss 1.06975, b1 0.49659, b2 0.39003, b3 0.30388, b4 0.23714, padchxlmacf1 0.05232, padchxlmicf1 0.10370, padchxlzmacf1 0.06799, padchxlzmicf1 0.10632, padchxl_loss 0.55829, padchxlz_loss 0.71631, 131.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32070, wmdcmp 0.17965, ema 0.64100, oracc 0.98185, qlmicf1 0.27174, qlmacf1 0.18732, chxlmicf1 0.47125, chxlmacf1 0.42139, chxlacc 0.63894, chxlrocaucmic 0.73332, chxlrocaucmac 0.69639, 28.94 secs\n",
      "Adjusting learning rate of group 0 to 5.7423e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.11632, a_loss 1.06787, cD 1.30218, wmdcmp 0.17490, ema 0.59869, oracc 0.97658, orien_loss 0.05093, qlmicf1 0.26293, qlmacf1 0.17782, ql_loss 0.97920, chxlmicf1 0.44471, chxlmacf1 0.40863, chx_loss 0.98738, chxlacc 0.64073, chxlrocaucmic 0.72432, chxlrocaucmac 0.70675, gacc 0.91641, gloss 0.21341, cxr14micf1 0.23122, cxr14macf1 0.26019, cxr14_loss 1.10531, vnbgmicf1 0.44602, vnbgmacf1 0.33784, vnbg_loss 1.03603, b1 0.50475, b2 0.39890, b3 0.31168, b4 0.24454, padchxlmacf1 0.05202, padchxlmicf1 0.10485, padchxlzmacf1 0.07039, padchxlzmicf1 0.10866, padchxl_loss 0.56706, padchxlz_loss 0.72369, 130.84 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.29282, wmdcmp 0.17663, ema 0.62936, oracc 0.98138, qlmicf1 0.27337, qlmacf1 0.18786, chxlmicf1 0.47260, chxlmacf1 0.42313, chxlacc 0.64118, chxlrocaucmic 0.73226, chxlrocaucmac 0.69876, 29.12 secs\n",
      "Adjusting learning rate of group 0 to 4.7287e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.99058, a_loss 1.07119, cD 1.27365, wmdcmp 0.17121, ema 0.59805, oracc 0.97766, orien_loss 0.04948, qlmicf1 0.26411, qlmacf1 0.17840, ql_loss 0.97638, chxlmicf1 0.44489, chxlmacf1 0.40829, chx_loss 0.98873, chxlacc 0.64203, chxlrocaucmic 0.72367, chxlrocaucmac 0.70543, gacc 0.91468, gloss 0.22214, cxr14micf1 0.23687, cxr14macf1 0.26176, cxr14_loss 1.09967, vnbgmicf1 0.44277, vnbgmacf1 0.33628, vnbg_loss 1.04760, b1 0.50770, b2 0.40058, b3 0.31274, b4 0.24426, padchxlmacf1 0.05309, padchxlmicf1 0.10673, padchxlzmacf1 0.06806, padchxlzmicf1 0.10581, padchxl_loss 0.56715, padchxlz_loss 0.72063, 131.19 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28672, wmdcmp 0.17693, ema 0.64279, oracc 0.98161, qlmicf1 0.27344, qlmacf1 0.18748, chxlmicf1 0.47355, chxlmacf1 0.42335, chxlacc 0.64088, chxlrocaucmic 0.73605, chxlrocaucmac 0.69882, 28.82 secs\n",
      "Adjusting learning rate of group 0 to 3.8940e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.37409, a_loss 1.06739, cD 1.28081, wmdcmp 0.17225, ema 0.59920, oracc 0.97854, orien_loss 0.04791, qlmicf1 0.26303, qlmacf1 0.17800, ql_loss 0.97490, chxlmicf1 0.44675, chxlmacf1 0.41060, chx_loss 0.98554, chxlacc 0.64144, chxlrocaucmic 0.72581, chxlrocaucmac 0.70884, gacc 0.91422, gloss 0.21891, cxr14micf1 0.23605, cxr14macf1 0.26088, cxr14_loss 1.10251, vnbgmicf1 0.44425, vnbgmacf1 0.33922, vnbg_loss 1.03618, b1 0.50906, b2 0.40206, b3 0.31346, b4 0.24584, padchxlmacf1 0.05038, padchxlmicf1 0.10676, padchxlzmacf1 0.07061, padchxlzmicf1 0.11216, padchxl_loss 0.55200, padchxlz_loss 0.72448, 131.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31514, wmdcmp 0.17871, ema 0.63742, oracc 0.98326, qlmicf1 0.27441, qlmacf1 0.18849, chxlmicf1 0.47369, chxlmacf1 0.42245, chxlacc 0.64496, chxlrocaucmic 0.73424, chxlrocaucmac 0.69907, 29.06 secs\n",
      "Adjusting learning rate of group 0 to 3.2067e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.58414, a_loss 1.07857, cD 1.28792, wmdcmp 0.17339, ema 0.60029, oracc 0.97726, orien_loss 0.04882, qlmicf1 0.26307, qlmacf1 0.17767, ql_loss 0.98210, chxlmicf1 0.44389, chxlmacf1 0.40648, chx_loss 0.99098, chxlacc 0.64049, chxlrocaucmic 0.72215, chxlrocaucmac 0.70367, gacc 0.91122, gloss 0.22513, cxr14micf1 0.25287, cxr14macf1 0.26960, cxr14_loss 1.10010, vnbgmicf1 0.44967, vnbgmacf1 0.34375, vnbg_loss 1.02843, b1 0.50541, b2 0.39882, b3 0.30885, b4 0.23931, padchxlmacf1 0.05014, padchxlmicf1 0.10529, padchxlzmacf1 0.06734, padchxlzmicf1 0.10689, padchxl_loss 0.56477, padchxlz_loss 0.72223, 130.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31709, wmdcmp 0.17947, ema 0.63832, oracc 0.98185, qlmicf1 0.27734, qlmacf1 0.18919, chxlmicf1 0.47254, chxlmacf1 0.42182, chxlacc 0.64233, chxlrocaucmic 0.73412, chxlrocaucmac 0.69939, 28.90 secs\n",
      "Adjusting learning rate of group 0 to 2.6407e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 3.15084, a_loss 1.07458, cD 1.29526, wmdcmp 0.17437, ema 0.59394, oracc 0.97717, orien_loss 0.04673, qlmicf1 0.26118, qlmacf1 0.17751, ql_loss 0.98406, chxlmicf1 0.44685, chxlmacf1 0.41020, chx_loss 0.98636, chxlacc 0.64027, chxlrocaucmic 0.72439, chxlrocaucmac 0.70550, gacc 0.91829, gloss 0.21329, cxr14micf1 0.24534, cxr14macf1 0.26800, cxr14_loss 1.09690, vnbgmicf1 0.44368, vnbgmacf1 0.33888, vnbg_loss 1.04978, b1 0.50130, b2 0.39365, b3 0.30405, b4 0.23506, padchxlmacf1 0.05314, padchxlmicf1 0.10923, padchxlzmacf1 0.06916, padchxlzmicf1 0.11023, padchxl_loss 0.56490, padchxlz_loss 0.73164, 131.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31212, wmdcmp 0.17880, ema 0.64279, oracc 0.98208, qlmicf1 0.27406, qlmacf1 0.18794, chxlmicf1 0.47095, chxlmacf1 0.42163, chxlacc 0.64155, chxlrocaucmic 0.73410, chxlrocaucmac 0.70106, 28.85 secs\n",
      "Adjusting learning rate of group 0 to 2.1746e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.24361, a_loss 1.07709, cD 1.28326, wmdcmp 0.17379, ema 0.59567, oracc 0.97737, orien_loss 0.04849, qlmicf1 0.26513, qlmacf1 0.17897, ql_loss 0.97554, chxlmicf1 0.44475, chxlmacf1 0.40825, chx_loss 0.98965, chxlacc 0.64157, chxlrocaucmic 0.72399, chxlrocaucmac 0.70574, gacc 0.91891, gloss 0.21306, cxr14micf1 0.24396, cxr14macf1 0.26650, cxr14_loss 1.10446, vnbgmicf1 0.44448, vnbgmacf1 0.33829, vnbg_loss 1.02695, b1 0.51702, b2 0.40836, b3 0.31767, b4 0.24729, padchxlmacf1 0.05280, padchxlmicf1 0.10403, padchxlzmacf1 0.06797, padchxlzmicf1 0.10629, padchxl_loss 0.57268, padchxlz_loss 0.71752, 132.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30682, wmdcmp 0.17833, ema 0.63921, oracc 0.98303, qlmicf1 0.27581, qlmacf1 0.18841, chxlmicf1 0.47467, chxlmacf1 0.42396, chxlacc 0.64483, chxlrocaucmic 0.73304, chxlrocaucmac 0.69877, 28.85 secs\n",
      "Adjusting learning rate of group 0 to 1.7907e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.98820, a_loss 1.06917, cD 1.27649, wmdcmp 0.17231, ema 0.59885, oracc 0.97738, orien_loss 0.04900, qlmicf1 0.26327, qlmacf1 0.17760, ql_loss 0.97761, chxlmicf1 0.44585, chxlmacf1 0.40959, chx_loss 0.98745, chxlacc 0.64018, chxlrocaucmic 0.72312, chxlrocaucmac 0.70514, gacc 0.91718, gloss 0.21734, cxr14micf1 0.23789, cxr14macf1 0.26334, cxr14_loss 1.10456, vnbgmicf1 0.43228, vnbgmacf1 0.32398, vnbg_loss 1.06447, b1 0.50086, b2 0.39382, b3 0.30644, b4 0.23921, padchxlmacf1 0.05263, padchxlmicf1 0.10374, padchxlzmacf1 0.06989, padchxlzmicf1 0.10551, padchxl_loss 0.56678, padchxlz_loss 0.71820, 130.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31515, wmdcmp 0.17918, ema 0.61504, oracc 0.98043, qlmicf1 0.27449, qlmacf1 0.18815, chxlmicf1 0.47379, chxlmacf1 0.42406, chxlacc 0.64235, chxlrocaucmic 0.73329, chxlrocaucmac 0.69957, 28.65 secs\n",
      "Adjusting learning rate of group 0 to 1.4746e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.89309, a_loss 1.07547, cD 1.29030, wmdcmp 0.17304, ema 0.59337, oracc 0.97770, orien_loss 0.04879, qlmicf1 0.26380, qlmacf1 0.17814, ql_loss 0.98130, chxlmicf1 0.44324, chxlmacf1 0.40727, chx_loss 0.98868, chxlacc 0.64006, chxlrocaucmic 0.72304, chxlrocaucmac 0.70586, gacc 0.91141, gloss 0.22629, cxr14micf1 0.23747, cxr14macf1 0.26147, cxr14_loss 1.10914, vnbgmicf1 0.43857, vnbgmacf1 0.33291, vnbg_loss 1.05837, b1 0.50555, b2 0.39787, b3 0.30910, b4 0.24151, padchxlmacf1 0.05444, padchxlmicf1 0.10663, padchxlzmacf1 0.06991, padchxlzmicf1 0.11039, padchxl_loss 0.56872, padchxlz_loss 0.72614, 130.72 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32958, wmdcmp 0.18014, ema 0.63115, oracc 0.98138, qlmicf1 0.27461, qlmacf1 0.18802, chxlmicf1 0.47220, chxlmacf1 0.42173, chxlacc 0.63992, chxlrocaucmic 0.73438, chxlrocaucmac 0.69900, 28.95 secs\n",
      "Adjusting learning rate of group 0 to 1.2143e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.53480, a_loss 1.07179, cD 1.27354, wmdcmp 0.17195, ema 0.59774, oracc 0.97760, orien_loss 0.04905, qlmicf1 0.26176, qlmacf1 0.17695, ql_loss 0.98202, chxlmicf1 0.44156, chxlmacf1 0.40564, chx_loss 0.99071, chxlacc 0.63887, chxlrocaucmic 0.72055, chxlrocaucmac 0.70283, gacc 0.91352, gloss 0.21914, cxr14micf1 0.23741, cxr14macf1 0.26180, cxr14_loss 1.10670, vnbgmicf1 0.44813, vnbgmacf1 0.33993, vnbg_loss 1.02761, b1 0.50320, b2 0.39322, b3 0.30164, b4 0.23257, padchxlmacf1 0.05096, padchxlmicf1 0.10306, padchxlzmacf1 0.06679, padchxlzmicf1 0.10567, padchxl_loss 0.56565, padchxlz_loss 0.72232, 131.27 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31276, wmdcmp 0.17937, ema 0.63563, oracc 0.98185, qlmicf1 0.27505, qlmacf1 0.18827, chxlmicf1 0.47100, chxlmacf1 0.42108, chxlacc 0.64297, chxlrocaucmic 0.73351, chxlrocaucmac 0.69971, 28.89 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 150 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 1 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,5e-4,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-base-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --freeze-image-encoder \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-base-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,9e-5,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 50\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.4\n",
      "   vinbig_weight: 0.4\n",
      "   iuxray_weight: 0.2\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.16\n",
      "   padchest_weight: 0.5\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-base-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,9e-5,32,1e-6\n",
      "1e-06 8 9e-05 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for CenIA/vit-mae-base-finetuned-mimic\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "get_vqa_collate_batch_fn(): dataset_id=6, one_hot_question_offset=111\n",
      "get_vqa_collate_batch_fn(): dataset_id=5, one_hot_question_offset=126\n",
      "get_vqa_collate_batch_fn(): dataset_id=7, one_hot_question_offset=154\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 50\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,3547888293769522994).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 50\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,1637362445184610094).pkl\n",
      "\tlen(question_datasets) = 55\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating CXR14 vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/data/chest-x-ray-8/metadata/Data_Entry_2017_v2020.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading CXR14 labels\n",
      "label = 0, onehot=0, len(pos_indices)=60361, len(neg_indices)=51759\n",
      "label = 1, onehot=1, len(pos_indices)=11559, len(neg_indices)=100561\n",
      "label = 2, onehot=2, len(pos_indices)=2776, len(neg_indices)=109344\n",
      "label = 3, onehot=3, len(pos_indices)=4667, len(neg_indices)=107453\n",
      "label = 4, onehot=4, len(pos_indices)=2303, len(neg_indices)=109817\n",
      "label = 5, onehot=5, len(pos_indices)=13317, len(neg_indices)=98803\n",
      "label = 6, onehot=6, len(pos_indices)=2516, len(neg_indices)=109604\n",
      "label = 7, onehot=7, len(pos_indices)=1686, len(neg_indices)=110434\n",
      "label = 8, onehot=8, len(pos_indices)=227, len(neg_indices)=111893\n",
      "label = 9, onehot=9, len(pos_indices)=19894, len(neg_indices)=92226\n",
      "label = 10, onehot=10, len(pos_indices)=5782, len(neg_indices)=106338\n",
      "label = 11, onehot=11, len(pos_indices)=6331, len(neg_indices)=105789\n",
      "label = 12, onehot=12, len(pos_indices)=3385, len(neg_indices)=108735\n",
      "label = 13, onehot=13, len(pos_indices)=1431, len(neg_indices)=110689\n",
      "label = 14, onehot=14, len(pos_indices)=5302, len(neg_indices)=106818\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mCreating VinBig vqa trainer ...\u001b[0m\n",
      "Loading dataframe from:\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_train.csv\n",
      "  /mnt/workspace/vinbig-cxr/dataset-png/annotations/image_labels_test.csv\n",
      "Sanity checking train labels ...\n",
      "Done!\n",
      "Generating train dataset and dataloader\n",
      "label = 0, onehot=0, len(pos_indices)=3287, len(neg_indices)=14713\n",
      "label = 1, onehot=1, len(pos_indices)=272, len(neg_indices)=17728\n",
      "label = 2, onehot=2, len(pos_indices)=646, len(neg_indices)=17354\n",
      "label = 3, onehot=3, len(pos_indices)=2609, len(neg_indices)=15391\n",
      "label = 4, onehot=4, len(pos_indices)=29, len(neg_indices)=17971\n",
      "label = 5, onehot=5, len(pos_indices)=449, len(neg_indices)=17551\n",
      "label = 6, onehot=6, len(pos_indices)=13, len(neg_indices)=17987\n",
      "label = 7, onehot=7, len(pos_indices)=81, len(neg_indices)=17919\n",
      "label = 8, onehot=8, len(pos_indices)=139, len(neg_indices)=17861\n",
      "label = 9, onehot=9, len(pos_indices)=607, len(neg_indices)=17393\n",
      "label = 10, onehot=10, len(pos_indices)=671, len(neg_indices)=17329\n",
      "label = 11, onehot=11, len(pos_indices)=1406, len(neg_indices)=16594\n",
      "label = 12, onehot=12, len(pos_indices)=59, len(neg_indices)=17941\n",
      "label = 13, onehot=13, len(pos_indices)=34, len(neg_indices)=17966\n",
      "label = 14, onehot=14, len(pos_indices)=170, len(neg_indices)=17830\n",
      "label = 15, onehot=15, len(pos_indices)=1006, len(neg_indices)=16994\n",
      "label = 16, onehot=16, len(pos_indices)=1143, len(neg_indices)=16857\n",
      "label = 17, onehot=17, len(pos_indices)=2150, len(neg_indices)=15850\n",
      "label = 18, onehot=18, len(pos_indices)=114, len(neg_indices)=17886\n",
      "label = 19, onehot=19, len(pos_indices)=1834, len(neg_indices)=16166\n",
      "label = 20, onehot=20, len(pos_indices)=101, len(neg_indices)=17899\n",
      "label = 21, onehot=21, len(pos_indices)=1228, len(neg_indices)=16772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 22, onehot=22, len(pos_indices)=37, len(neg_indices)=17963\n",
      "label = 23, onehot=23, len(pos_indices)=371, len(neg_indices)=17629\n",
      "label = 24, onehot=24, len(pos_indices)=1163, len(neg_indices)=16837\n",
      "label = 25, onehot=25, len(pos_indices)=914, len(neg_indices)=17086\n",
      "label = 26, onehot=26, len(pos_indices)=4945, len(neg_indices)=13055\n",
      "label = 27, onehot=27, len(pos_indices)=12652, len(neg_indices)=5348\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mCreating PadChest vqa trainer ...\u001b[0m\n",
      "../train_vqa.py:1442: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  debug=debug)\n",
      "Number of rows before filtering: 160861\n",
      "Number of rows after filtering: 160754 (dropped nan rows)\n",
      "Number of rows after filtering: 160741 (dropped study ids not in all_study_ids_set)\n",
      "Number of rows after filtering: 160723 (dropped rows with unexpected PatientSex_DICOM)\n",
      "Number of rows after filtering: 160704 (dropped rows with unexpected Projection)\n",
      "Number of rows after filtering: 160692 (dropped rows with broken images)\n",
      "Number of rows after filtering: 109821 (dropped rows with duplicate StudyID)\n",
      "Number of labels: 193\n",
      "Number of localizations: 104\n",
      "Generating answers based on labels...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 126496.59it/s]\n",
      "Done. Example answer: <s> azygos lobe </s>\n",
      "Generating answers based on localizations...\n",
      "100%|███████████████████████████████| 109821/109821 [00:00<00:00, 129927.18it/s]\n",
      "Done. Example answer: <s> loc right , loc basal </s>\n",
      "Number of non-empty answers: 63528\n",
      "Generating answers based on labels localizations by sentence...\n",
      "100%|████████████████████████████████| 109821/109821 [00:01<00:00, 72306.13it/s]\n",
      "Done. Example answer: <s> infiltrates pleural effusion loc hemithorax loc bilateral loc left loc pleural </s>\n",
      "Creating dataset and dataloader...\n",
      "Example of positive localization answer: <s> loc left </s>\n",
      "Example of negative localization answer: <s> </s>\n",
      "193it [00:30,  6.35it/s]\n",
      "Done!\n",
      "len(self.train_dataset) = 1000000000000000000\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 8\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8, 0.2, 0.16, 0.5, 0.4, 0.4, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223745_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223745_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m21) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_21_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5127.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_21_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5127.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m22) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223745_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m23) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.74461, a_loss 1.01873, cD 1.42409, wmdcmp 0.18388, ema 0.59442, oracc 0.97777, orien_loss 0.04685, qlmicf1 0.27223, qlmacf1 0.17804, ql_loss 0.84701, chxlmicf1 0.45245, chxlmacf1 0.40664, chx_loss 0.98495, chxlacc 0.66401, chxlrocaucmic 0.72970, chxlrocaucmac 0.70516, gacc 0.91346, gloss 0.22516, cxr14micf1 0.24108, cxr14macf1 0.26712, cxr14_loss 1.09476, vnbgmicf1 0.44814, vnbgmacf1 0.33617, vnbg_loss 0.99617, b1 0.48132, b2 0.37941, b3 0.29777, b4 0.23400, padchxlmacf1 0.05627, padchxlmicf1 0.11363, padchxlzmacf1 0.07450, padchxlzmicf1 0.11262, padchxl_loss 0.40353, padchxlz_loss 0.54124, 107.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32330, wmdcmp 0.17791, ema 0.66428, oracc 0.98137, qlmicf1 0.28712, qlmacf1 0.18972, chxlmicf1 0.48370, chxlmacf1 0.42319, chxlacc 0.66369, chxlrocaucmic 0.74204, chxlrocaucmac 0.69995, 30.56 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.80948, a_loss 1.08590, cD 1.30334, wmdcmp 0.17180, ema 0.59120, oracc 0.97684, orien_loss 0.04718, qlmicf1 0.27859, qlmacf1 0.17912, ql_loss 0.85089, chxlmicf1 0.45507, chxlmacf1 0.40784, chx_loss 0.98016, chxlacc 0.66525, chxlrocaucmic 0.73141, chxlrocaucmac 0.70502, gacc 0.91481, gloss 0.21358, cxr14micf1 0.25230, cxr14macf1 0.27348, cxr14_loss 1.09426, vnbgmicf1 0.45087, vnbgmacf1 0.33270, vnbg_loss 1.00247, b1 0.51427, b2 0.40055, b3 0.30863, b4 0.23897, padchxlmacf1 0.05426, padchxlmicf1 0.11195, padchxlzmacf1 0.07198, padchxlzmicf1 0.10686, padchxl_loss 0.39456, padchxlz_loss 0.54014, 99.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.30206, wmdcmp 0.17479, ema 0.66070, oracc 0.97948, qlmicf1 0.29959, qlmacf1 0.19114, chxlmicf1 0.48233, chxlmacf1 0.41943, chxlacc 0.67709, chxlrocaucmic 0.73803, chxlrocaucmac 0.70042, 29.87 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.43761, a_loss 1.09153, cD 1.25011, wmdcmp 0.16735, ema 0.59742, oracc 0.97832, orien_loss 0.04591, qlmicf1 0.29490, qlmacf1 0.18348, ql_loss 0.84782, chxlmicf1 0.45902, chxlmacf1 0.41219, chx_loss 0.98143, chxlacc 0.66463, chxlrocaucmic 0.73527, chxlrocaucmac 0.70731, gacc 0.91200, gloss 0.22189, cxr14micf1 0.23909, cxr14macf1 0.26806, cxr14_loss 1.10757, vnbgmicf1 0.47360, vnbgmacf1 0.34624, vnbg_loss 0.96055, b1 0.52911, b2 0.41877, b3 0.33063, b4 0.26252, padchxlmacf1 0.05493, padchxlmicf1 0.11956, padchxlzmacf1 0.07219, padchxlzmicf1 0.12841, padchxl_loss 0.38319, padchxlz_loss 0.53247, 103.06 secs\n",
      "(2) Validation stage ...\n",
      "loss 4.62764, a_loss 1.11361, cD 1.23347, wmdcmp 0.16529, ema 0.60115, oracc 0.97962, orien_loss 0.03936, qlmicf1 0.29733, qlmacf1 0.18431, ql_loss 0.84927, chxlmicf1 0.45248, chxlmacf1 0.41030, chx_loss 0.98037, chxlacc 0.65787, chxlrocaucmic 0.73208, chxlrocaucmac 0.70709, gacc 0.92692, gloss 0.19270, cxr14micf1 0.24714, cxr14macf1 0.26971, cxr14_loss 1.11167, vnbgmicf1 0.46978, vnbgmacf1 0.34825, vnbg_loss 0.95597, b1 0.50507, b2 0.39029, b3 0.29696, b4 0.22603, padchxlmacf1 0.05185, padchxlmicf1 0.11763, padchxlzmacf1 0.06900, padchxlzmicf1 0.11743, padchxl_loss 0.39522, padchxlz_loss 0.51858, 105.89 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29912, wmdcmp 0.17430, ema 0.65891, oracc 0.98278, qlmicf1 0.31119, qlmacf1 0.19153, chxlmicf1 0.48132, chxlmacf1 0.42396, chxlacc 0.66413, chxlrocaucmic 0.74036, chxlrocaucmac 0.70436, 31.30 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.19467, a_loss 1.09935, cD 1.24264, wmdcmp 0.16613, ema 0.58517, oracc 0.97930, orien_loss 0.04777, qlmicf1 0.30668, qlmacf1 0.18278, ql_loss 0.84172, chxlmicf1 0.45197, chxlmacf1 0.41060, chx_loss 0.98446, chxlacc 0.65505, chxlrocaucmic 0.73008, chxlrocaucmac 0.70691, gacc 0.91600, gloss 0.22180, cxr14micf1 0.24537, cxr14macf1 0.26501, cxr14_loss 1.09714, vnbgmicf1 0.47347, vnbgmacf1 0.35575, vnbg_loss 0.96482, b1 0.50313, b2 0.39568, b3 0.30752, b4 0.23959, padchxlmacf1 0.05340, padchxlmicf1 0.11751, padchxlzmacf1 0.07155, padchxlzmicf1 0.12287, padchxl_loss 0.38631, padchxlz_loss 0.51756, 106.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29816, wmdcmp 0.17461, ema 0.65980, oracc 0.97995, qlmicf1 0.31173, qlmacf1 0.19109, chxlmicf1 0.48409, chxlmacf1 0.42029, chxlacc 0.68691, chxlrocaucmic 0.74065, chxlrocaucmac 0.70736, 31.07 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.86599, a_loss 1.09853, cD 1.25573, wmdcmp 0.16669, ema 0.59866, oracc 0.97841, orien_loss 0.03789, qlmicf1 0.30980, qlmacf1 0.18364, ql_loss 0.84081, chxlmicf1 0.45475, chxlmacf1 0.41384, chx_loss 0.97527, chxlacc 0.65367, chxlrocaucmic 0.73206, chxlrocaucmac 0.70972, gacc 0.91712, gloss 0.20053, cxr14micf1 0.25680, cxr14macf1 0.27554, cxr14_loss 1.09370, vnbgmicf1 0.47127, vnbgmacf1 0.34413, vnbg_loss 0.95435, b1 0.48490, b2 0.38155, b3 0.29641, b4 0.22970, padchxlmacf1 0.05498, padchxlmicf1 0.12925, padchxlzmacf1 0.06860, padchxlzmicf1 0.13089, padchxl_loss 0.37272, padchxlz_loss 0.49499, 104.83 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28569, wmdcmp 0.17322, ema 0.66697, oracc 0.98113, qlmicf1 0.35110, qlmacf1 0.19401, chxlmicf1 0.46936, chxlmacf1 0.42058, chxlacc 0.67422, chxlrocaucmic 0.72559, chxlrocaucmac 0.70928, 30.84 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.49437, a_loss 1.09513, cD 1.26051, wmdcmp 0.16610, ema 0.59589, oracc 0.97614, orien_loss 0.05192, qlmicf1 0.32121, qlmacf1 0.18581, ql_loss 0.83935, chxlmicf1 0.45261, chxlmacf1 0.41313, chx_loss 0.97785, chxlacc 0.65100, chxlrocaucmic 0.73220, chxlrocaucmac 0.71118, gacc 0.90400, gloss 0.25306, cxr14micf1 0.23885, cxr14macf1 0.26315, cxr14_loss 1.10912, vnbgmicf1 0.48243, vnbgmacf1 0.35046, vnbg_loss 0.94742, b1 0.50761, b2 0.39711, b3 0.30483, b4 0.23399, padchxlmacf1 0.06025, padchxlmicf1 0.13197, padchxlzmacf1 0.07126, padchxlzmicf1 0.13727, padchxl_loss 0.37259, padchxlz_loss 0.51141, 107.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28477, wmdcmp 0.17392, ema 0.67234, oracc 0.98302, qlmicf1 0.34764, qlmacf1 0.19306, chxlmicf1 0.47685, chxlmacf1 0.42805, chxlacc 0.67407, chxlrocaucmic 0.73378, chxlrocaucmac 0.71558, 31.62 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 4.75706, a_loss 1.09719, cD 1.22884, wmdcmp 0.16291, ema 0.59423, oracc 0.97503, orien_loss 0.05525, qlmicf1 0.32403, qlmacf1 0.18731, ql_loss 0.83417, chxlmicf1 0.45256, chxlmacf1 0.41417, chx_loss 0.97546, chxlacc 0.65252, chxlrocaucmic 0.73080, chxlrocaucmac 0.71165, gacc 0.89077, gloss 0.32385, cxr14micf1 0.24308, cxr14macf1 0.26877, cxr14_loss 1.09176, vnbgmicf1 0.47118, vnbgmacf1 0.34420, vnbg_loss 0.96143, b1 0.48486, b2 0.37879, b3 0.29173, b4 0.22617, padchxlmacf1 0.05430, padchxlmicf1 0.12118, padchxlzmacf1 0.07259, padchxlzmicf1 0.13220, padchxl_loss 0.37277, padchxlz_loss 0.52234, 107.67 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.28436, wmdcmp 0.17334, ema 0.66070, oracc 0.98160, qlmicf1 0.35256, qlmacf1 0.19348, chxlmicf1 0.48776, chxlmacf1 0.42738, chxlacc 0.69123, chxlrocaucmic 0.74406, chxlrocaucmac 0.71784, 31.10 secs\n",
      "Adjusting learning rate of group 0 to 9.0000e-05.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.93304, a_loss 1.10042, cD 1.24991, wmdcmp 0.16623, ema 0.59282, oracc 0.96075, orien_loss 0.11048, qlmicf1 0.31394, qlmacf1 0.18271, ql_loss 0.84098, chxlmicf1 0.43999, chxlmacf1 0.40114, chx_loss 0.99726, chxlacc 0.64172, chxlrocaucmic 0.71756, chxlrocaucmac 0.69991, gacc 0.90596, gloss 0.25198, cxr14micf1 0.22475, cxr14macf1 0.25613, cxr14_loss 1.12780, vnbgmicf1 0.44176, vnbgmacf1 0.32718, vnbg_loss 1.02038, b1 0.49109, b2 0.38323, b3 0.29611, b4 0.23041, padchxlmacf1 0.05265, padchxlmicf1 0.11520, padchxlzmacf1 0.06377, padchxlzmicf1 0.12506, padchxl_loss 0.38708, padchxlz_loss 0.50684, 106.10 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.26966, wmdcmp 0.17263, ema 0.64637, oracc 0.97712, qlmicf1 0.36638, qlmacf1 0.19499, chxlmicf1 0.50853, chxlmacf1 0.43388, chxlacc 0.65892, chxlrocaucmic 0.77887, chxlrocaucmac 0.71471, 31.35 secs\n",
      "Adjusting learning rate of group 0 to 7.8194e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000078) ...\n",
      "loss 1.87423, a_loss 1.09595, cD 1.28437, wmdcmp 0.17067, ema 0.59885, oracc 0.97692, orien_loss 0.04406, qlmicf1 0.32719, qlmacf1 0.18451, ql_loss 0.82955, chxlmicf1 0.46035, chxlmacf1 0.42080, chx_loss 0.96301, chxlacc 0.65719, chxlrocaucmic 0.74159, chxlrocaucmac 0.72274, gacc 0.93346, gloss 0.17526, cxr14micf1 0.26354, cxr14macf1 0.27735, cxr14_loss 1.06946, vnbgmicf1 0.49706, vnbgmacf1 0.36724, vnbg_loss 0.92101, b1 0.47853, b2 0.37460, b3 0.29118, b4 0.22520, padchxlmacf1 0.05213, padchxlmicf1 0.13397, padchxlzmacf1 0.07232, padchxlzmicf1 0.13961, padchxl_loss 0.35996, padchxlz_loss 0.51000, 104.96 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32815, wmdcmp 0.17912, ema 0.66338, oracc 0.98278, qlmicf1 0.34199, qlmacf1 0.19354, chxlmicf1 0.49572, chxlmacf1 0.44124, chxlacc 0.63920, chxlrocaucmic 0.76897, chxlrocaucmac 0.72043, 31.03 secs\n",
      "Adjusting learning rate of group 0 to 6.7936e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 1.26204, a_loss 1.09280, cD 1.24913, wmdcmp 0.16476, ema 0.59847, oracc 0.97843, orien_loss 0.04789, qlmicf1 0.33499, qlmacf1 0.18985, ql_loss 0.82881, chxlmicf1 0.47017, chxlmacf1 0.42861, chx_loss 0.95031, chxlacc 0.66950, chxlrocaucmic 0.75059, chxlrocaucmac 0.73145, gacc 0.94286, gloss 0.14848, cxr14micf1 0.26864, cxr14macf1 0.28171, cxr14_loss 1.06993, vnbgmicf1 0.50956, vnbgmacf1 0.37606, vnbg_loss 0.89430, b1 0.49526, b2 0.38409, b3 0.29283, b4 0.22374, padchxlmacf1 0.05169, padchxlmicf1 0.13615, padchxlzmacf1 0.06723, padchxlzmicf1 0.13453, padchxl_loss 0.35232, padchxlz_loss 0.49159, 107.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32510, wmdcmp 0.17943, ema 0.64996, oracc 0.98278, qlmicf1 0.33509, qlmacf1 0.19445, chxlmicf1 0.49636, chxlmacf1 0.44340, chxlacc 0.63654, chxlrocaucmic 0.76769, chxlrocaucmac 0.72177, 31.87 secs\n",
      "Adjusting learning rate of group 0 to 5.9024e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 4.27893, a_loss 1.09409, cD 1.23584, wmdcmp 0.16491, ema 0.60356, oracc 0.98275, orien_loss 0.03354, qlmicf1 0.33602, qlmacf1 0.19127, ql_loss 0.81826, chxlmicf1 0.47152, chxlmacf1 0.43159, chx_loss 0.94258, chxlacc 0.67006, chxlrocaucmic 0.75516, chxlrocaucmac 0.73677, gacc 0.94365, gloss 0.13577, cxr14micf1 0.26369, cxr14macf1 0.27639, cxr14_loss 1.06258, vnbgmicf1 0.51094, vnbgmacf1 0.38220, vnbg_loss 0.88401, b1 0.50887, b2 0.40198, b3 0.31465, b4 0.24490, padchxlmacf1 0.05570, padchxlmicf1 0.14343, padchxlzmacf1 0.07527, padchxlzmicf1 0.15618, padchxl_loss 0.36202, padchxlz_loss 0.48624, 108.80 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29685, wmdcmp 0.17496, ema 0.67055, oracc 0.98373, qlmicf1 0.35880, qlmacf1 0.19875, chxlmicf1 0.50346, chxlmacf1 0.43725, chxlacc 0.69455, chxlrocaucmic 0.76335, chxlrocaucmac 0.72467, 31.59 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 2.43368, a_loss 1.09782, cD 1.27868, wmdcmp 0.16913, ema 0.60144, oracc 0.98163, orien_loss 0.03283, qlmicf1 0.33785, qlmacf1 0.19102, ql_loss 0.81605, chxlmicf1 0.47807, chxlmacf1 0.43499, chx_loss 0.94268, chxlacc 0.67554, chxlrocaucmic 0.75907, chxlrocaucmac 0.73957, gacc 0.94933, gloss 0.13702, cxr14micf1 0.28320, cxr14macf1 0.29089, cxr14_loss 1.04823, vnbgmicf1 0.52377, vnbgmacf1 0.38099, vnbg_loss 0.86454, b1 0.48398, b2 0.37925, b3 0.29118, b4 0.22427, padchxlmacf1 0.05756, padchxlmicf1 0.14642, padchxlzmacf1 0.07336, padchxlzmicf1 0.15335, padchxl_loss 0.35333, padchxlz_loss 0.50695, 105.57 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.32251, wmdcmp 0.17801, ema 0.66428, oracc 0.98349, qlmicf1 0.34151, qlmacf1 0.19739, chxlmicf1 0.50455, chxlmacf1 0.44384, chxlacc 0.67272, chxlrocaucmic 0.77070, chxlrocaucmac 0.72748, 31.14 secs\n",
      "Adjusting learning rate of group 0 to 4.4555e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.01753, a_loss 1.09481, cD 1.25861, wmdcmp 0.16618, ema 0.60548, oracc 0.98224, orien_loss 0.03137, qlmicf1 0.33701, qlmacf1 0.19276, ql_loss 0.81931, chxlmicf1 0.47602, chxlmacf1 0.43635, chx_loss 0.93654, chxlacc 0.67519, chxlrocaucmic 0.76196, chxlrocaucmac 0.74463, gacc 0.95173, gloss 0.12848, cxr14micf1 0.29468, cxr14macf1 0.29891, cxr14_loss 1.04913, vnbgmicf1 0.52698, vnbgmacf1 0.38270, vnbg_loss 0.85210, b1 0.50505, b2 0.39764, b3 0.30968, b4 0.24090, padchxlmacf1 0.06020, padchxlmicf1 0.15348, padchxlzmacf1 0.07880, padchxlzmicf1 0.16885, padchxl_loss 0.37213, padchxlz_loss 0.49961, 105.68 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33298, wmdcmp 0.17774, ema 0.67144, oracc 0.98349, qlmicf1 0.36273, qlmacf1 0.20017, chxlmicf1 0.52127, chxlmacf1 0.44896, chxlacc 0.68735, chxlrocaucmic 0.78644, chxlrocaucmac 0.73069, 31.24 secs\n",
      "Adjusting learning rate of group 0 to 3.8710e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000039) ...\n",
      "loss 1.76412, a_loss 1.08410, cD 1.27336, wmdcmp 0.16976, ema 0.60335, oracc 0.98032, orien_loss 0.03282, qlmicf1 0.33977, qlmacf1 0.19287, ql_loss 0.81824, chxlmicf1 0.47726, chxlmacf1 0.43504, chx_loss 0.93250, chxlacc 0.67587, chxlrocaucmic 0.76215, chxlrocaucmac 0.74348, gacc 0.95712, gloss 0.11127, cxr14micf1 0.28205, cxr14macf1 0.28996, cxr14_loss 1.05067, vnbgmicf1 0.52696, vnbgmacf1 0.38285, vnbg_loss 0.82976, b1 0.50596, b2 0.39744, b3 0.30737, b4 0.23994, padchxlmacf1 0.05831, padchxlmicf1 0.16214, padchxlzmacf1 0.07909, padchxlzmicf1 0.16424, padchxl_loss 0.34155, padchxlz_loss 0.48047, 110.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.33260, wmdcmp 0.17860, ema 0.67234, oracc 0.98467, qlmicf1 0.36882, qlmacf1 0.20080, chxlmicf1 0.50465, chxlmacf1 0.44207, chxlacc 0.70413, chxlrocaucmic 0.76343, chxlrocaucmac 0.73221, 31.55 secs\n",
      "Adjusting learning rate of group 0 to 3.3632e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.26703, a_loss 1.09324, cD 1.26158, wmdcmp 0.16954, ema 0.61279, oracc 0.98091, orien_loss 0.03525, qlmicf1 0.34573, qlmacf1 0.19551, ql_loss 0.81813, chxlmicf1 0.48367, chxlmacf1 0.44185, chx_loss 0.92549, chxlacc 0.68094, chxlrocaucmic 0.76459, chxlrocaucmac 0.74674, gacc 0.95519, gloss 0.11857, cxr14micf1 0.28120, cxr14macf1 0.28881, cxr14_loss 1.03621, vnbgmicf1 0.53030, vnbgmacf1 0.39375, vnbg_loss 0.83992, b1 0.50189, b2 0.39941, b3 0.31456, b4 0.24613, padchxlmacf1 0.05698, padchxlmicf1 0.13867, padchxlzmacf1 0.07086, padchxlzmicf1 0.14708, padchxl_loss 0.37112, padchxlz_loss 0.50686, 108.49 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37432, wmdcmp 0.18391, ema 0.66517, oracc 0.98514, qlmicf1 0.36719, qlmacf1 0.20159, chxlmicf1 0.50427, chxlmacf1 0.44442, chxlacc 0.69499, chxlrocaucmic 0.76526, chxlrocaucmac 0.73206, 31.57 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.26568, a_loss 1.08566, cD 1.27918, wmdcmp 0.16701, ema 0.61378, oracc 0.98219, orien_loss 0.03500, qlmicf1 0.34117, qlmacf1 0.19763, ql_loss 0.81096, chxlmicf1 0.48264, chxlmacf1 0.44145, chx_loss 0.92832, chxlacc 0.68231, chxlrocaucmic 0.76620, chxlrocaucmac 0.74918, gacc 0.95886, gloss 0.10647, cxr14micf1 0.29635, cxr14macf1 0.29857, cxr14_loss 1.02441, vnbgmicf1 0.53098, vnbgmacf1 0.39247, vnbg_loss 0.79453, b1 0.49161, b2 0.38600, b3 0.29919, b4 0.23170, padchxlmacf1 0.05678, padchxlmicf1 0.14554, padchxlzmacf1 0.07402, padchxlzmicf1 0.15395, padchxl_loss 0.35363, padchxlz_loss 0.49007, 106.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36637, wmdcmp 0.18313, ema 0.69114, oracc 0.98514, qlmicf1 0.37102, qlmacf1 0.20255, chxlmicf1 0.50746, chxlmacf1 0.45037, chxlacc 0.68991, chxlrocaucmic 0.76897, chxlrocaucmac 0.73601, 31.23 secs\n",
      "Adjusting learning rate of group 0 to 2.5387e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 1.18835, a_loss 1.08541, cD 1.26659, wmdcmp 0.16808, ema 0.60651, oracc 0.98062, orien_loss 0.03304, qlmicf1 0.34500, qlmacf1 0.19691, ql_loss 0.81183, chxlmicf1 0.48173, chxlmacf1 0.44039, chx_loss 0.92561, chxlacc 0.68024, chxlrocaucmic 0.76740, chxlrocaucmac 0.74700, gacc 0.96286, gloss 0.10203, cxr14micf1 0.30848, cxr14macf1 0.30460, cxr14_loss 1.02536, vnbgmicf1 0.53690, vnbgmacf1 0.39091, vnbg_loss 0.82424, b1 0.47428, b2 0.37041, b3 0.28366, b4 0.21505, padchxlmacf1 0.05803, padchxlmicf1 0.14726, padchxlzmacf1 0.07095, padchxlzmicf1 0.14525, padchxl_loss 0.36869, padchxlz_loss 0.49888, 105.56 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36607, wmdcmp 0.18498, ema 0.67950, oracc 0.98491, qlmicf1 0.36055, qlmacf1 0.20300, chxlmicf1 0.51659, chxlmacf1 0.45533, chxlacc 0.68405, chxlrocaucmic 0.78189, chxlrocaucmac 0.73629, 31.47 secs\n",
      "Adjusting learning rate of group 0 to 2.2057e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.81958, a_loss 1.07373, cD 1.25658, wmdcmp 0.16754, ema 0.62632, oracc 0.98107, orien_loss 0.03461, qlmicf1 0.34884, qlmacf1 0.19894, ql_loss 0.80631, chxlmicf1 0.48656, chxlmacf1 0.44422, chx_loss 0.92555, chxlacc 0.68489, chxlrocaucmic 0.77087, chxlrocaucmac 0.75188, gacc 0.96500, gloss 0.09528, cxr14micf1 0.29827, cxr14macf1 0.30068, cxr14_loss 1.02307, vnbgmicf1 0.54320, vnbgmacf1 0.39583, vnbg_loss 0.78346, b1 0.50231, b2 0.39737, b3 0.31086, b4 0.24641, padchxlmacf1 0.05734, padchxlmicf1 0.15424, padchxlzmacf1 0.07096, padchxlzmicf1 0.15350, padchxl_loss 0.34477, padchxlz_loss 0.47071, 109.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38348, wmdcmp 0.18612, ema 0.66786, oracc 0.98514, qlmicf1 0.34434, qlmacf1 0.20205, chxlmicf1 0.49759, chxlmacf1 0.45069, chxlacc 0.66011, chxlrocaucmic 0.76589, chxlrocaucmac 0.73726, 31.81 secs\n",
      "Adjusting learning rate of group 0 to 1.9163e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 4.43243, a_loss 1.08726, cD 1.29332, wmdcmp 0.17202, ema 0.61000, oracc 0.98285, orien_loss 0.03227, qlmicf1 0.34857, qlmacf1 0.20106, ql_loss 0.81252, chxlmicf1 0.48716, chxlmacf1 0.44679, chx_loss 0.92269, chxlacc 0.68484, chxlrocaucmic 0.77002, chxlrocaucmac 0.75352, gacc 0.96000, gloss 0.10774, cxr14micf1 0.29371, cxr14macf1 0.29905, cxr14_loss 1.02705, vnbgmicf1 0.54605, vnbgmacf1 0.40906, vnbg_loss 0.81628, b1 0.49168, b2 0.39004, b3 0.30644, b4 0.23905, padchxlmacf1 0.06170, padchxlmicf1 0.16323, padchxlzmacf1 0.07932, padchxlzmicf1 0.16646, padchxl_loss 0.34274, padchxlz_loss 0.47807, 109.11 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36560, wmdcmp 0.18393, ema 0.67323, oracc 0.98443, qlmicf1 0.34478, qlmacf1 0.20177, chxlmicf1 0.50848, chxlmacf1 0.45208, chxlacc 0.67303, chxlrocaucmic 0.77743, chxlrocaucmac 0.73743, 31.60 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 2.28135, a_loss 1.07970, cD 1.28156, wmdcmp 0.16863, ema 0.61330, oracc 0.98291, orien_loss 0.02965, qlmicf1 0.34835, qlmacf1 0.19886, ql_loss 0.81046, chxlmicf1 0.48803, chxlmacf1 0.44567, chx_loss 0.92175, chxlacc 0.68394, chxlrocaucmic 0.77150, chxlrocaucmac 0.75351, gacc 0.96514, gloss 0.09154, cxr14micf1 0.31902, cxr14macf1 0.31281, cxr14_loss 1.00858, vnbgmicf1 0.55238, vnbgmacf1 0.41207, vnbg_loss 0.77121, b1 0.52932, b2 0.42070, b3 0.32950, b4 0.25762, padchxlmacf1 0.06231, padchxlmicf1 0.16417, padchxlzmacf1 0.07919, padchxlzmicf1 0.17177, padchxl_loss 0.33543, padchxlz_loss 0.47464, 106.73 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34273, wmdcmp 0.17920, ema 0.67860, oracc 0.98420, qlmicf1 0.37132, qlmacf1 0.20478, chxlmicf1 0.52190, chxlmacf1 0.45231, chxlacc 0.70315, chxlrocaucmic 0.78509, chxlrocaucmac 0.74091, 30.77 secs\n",
      "Adjusting learning rate of group 0 to 1.4465e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.87046, a_loss 1.07877, cD 1.25906, wmdcmp 0.16592, ema 0.60699, oracc 0.98117, orien_loss 0.02874, qlmicf1 0.34742, qlmacf1 0.19790, ql_loss 0.80329, chxlmicf1 0.48603, chxlmacf1 0.44476, chx_loss 0.92022, chxlacc 0.68348, chxlrocaucmic 0.77082, chxlrocaucmac 0.75198, gacc 0.96615, gloss 0.08452, cxr14micf1 0.29856, cxr14macf1 0.30046, cxr14_loss 1.00707, vnbgmicf1 0.54651, vnbgmacf1 0.40509, vnbg_loss 0.80110, b1 0.52648, b2 0.42085, b3 0.32994, b4 0.25729, padchxlmacf1 0.06159, padchxlmicf1 0.15942, padchxlzmacf1 0.07967, padchxlzmicf1 0.17030, padchxl_loss 0.36161, padchxlz_loss 0.49900, 106.36 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.34931, wmdcmp 0.18062, ema 0.66965, oracc 0.98491, qlmicf1 0.36711, qlmacf1 0.20608, chxlmicf1 0.51520, chxlmacf1 0.45302, chxlacc 0.69074, chxlrocaucmic 0.78039, chxlrocaucmac 0.74038, 31.44 secs\n",
      "Adjusting learning rate of group 0 to 1.2568e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.86344, a_loss 1.07552, cD 1.30664, wmdcmp 0.17335, ema 0.62402, oracc 0.98162, orien_loss 0.02997, qlmicf1 0.35065, qlmacf1 0.19990, ql_loss 0.80390, chxlmicf1 0.48457, chxlmacf1 0.44395, chx_loss 0.91563, chxlacc 0.68683, chxlrocaucmic 0.77327, chxlrocaucmac 0.75753, gacc 0.96904, gloss 0.08773, cxr14micf1 0.29067, cxr14macf1 0.29833, cxr14_loss 1.02129, vnbgmicf1 0.53428, vnbgmacf1 0.39515, vnbg_loss 0.77495, b1 0.52123, b2 0.41532, b3 0.32589, b4 0.25613, padchxlmacf1 0.06559, padchxlmicf1 0.17021, padchxlzmacf1 0.08083, padchxlzmicf1 0.17455, padchxl_loss 0.33914, padchxlz_loss 0.48253, 108.71 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35449, wmdcmp 0.18131, ema 0.67681, oracc 0.98443, qlmicf1 0.36528, qlmacf1 0.20456, chxlmicf1 0.51912, chxlmacf1 0.45540, chxlacc 0.68918, chxlrocaucmic 0.78575, chxlrocaucmac 0.73984, 32.16 secs\n",
      "Adjusting learning rate of group 0 to 1.0919e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 4.61901, a_loss 1.08501, cD 1.26926, wmdcmp 0.16958, ema 0.61375, oracc 0.98382, orien_loss 0.02943, qlmicf1 0.35284, qlmacf1 0.20174, ql_loss 0.79931, chxlmicf1 0.49104, chxlmacf1 0.45019, chx_loss 0.91686, chxlacc 0.68783, chxlrocaucmic 0.77378, chxlrocaucmac 0.75523, gacc 0.96154, gloss 0.10041, cxr14micf1 0.29707, cxr14macf1 0.30138, cxr14_loss 1.00543, vnbgmicf1 0.54399, vnbgmacf1 0.39842, vnbg_loss 0.78484, b1 0.51806, b2 0.41571, b3 0.32927, b4 0.25983, padchxlmacf1 0.06224, padchxlmicf1 0.15956, padchxlzmacf1 0.07726, padchxlzmicf1 0.16669, padchxl_loss 0.36000, padchxlz_loss 0.49163, 108.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31845, wmdcmp 0.17742, ema 0.67234, oracc 0.98538, qlmicf1 0.36529, qlmacf1 0.20490, chxlmicf1 0.52270, chxlmacf1 0.45659, chxlacc 0.69107, chxlrocaucmic 0.78711, chxlrocaucmac 0.73988, 31.47 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.74662, a_loss 1.06240, cD 1.28410, wmdcmp 0.17087, ema 0.62431, oracc 0.98215, orien_loss 0.03351, qlmicf1 0.35619, qlmacf1 0.20269, ql_loss 0.79753, chxlmicf1 0.49418, chxlmacf1 0.45170, chx_loss 0.91169, chxlacc 0.68852, chxlrocaucmic 0.77516, chxlrocaucmac 0.75866, gacc 0.96558, gloss 0.09553, cxr14micf1 0.28664, cxr14macf1 0.29720, cxr14_loss 1.03981, vnbgmicf1 0.55583, vnbgmacf1 0.41424, vnbg_loss 0.77396, b1 0.48092, b2 0.38151, b3 0.29538, b4 0.22973, padchxlmacf1 0.06076, padchxlmicf1 0.16518, padchxlzmacf1 0.07757, padchxlzmicf1 0.16590, padchxl_loss 0.33315, padchxlz_loss 0.47283, 106.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.32853, wmdcmp 0.17905, ema 0.68218, oracc 0.98302, qlmicf1 0.35046, qlmacf1 0.20311, chxlmicf1 0.51174, chxlmacf1 0.45529, chxlacc 0.67409, chxlrocaucmic 0.77965, chxlrocaucmac 0.73840, 31.01 secs\n",
      "Adjusting learning rate of group 0 to 8.2424e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "cD 1.34259, wmdcmp 0.18016, ema 0.68397, oracc 0.98373, qlmicf1 0.37393, qlmacf1 0.20764, chxlmicf1 0.51421, chxlmacf1 0.45697, chxlacc 0.68571, chxlrocaucmic 0.77649, chxlrocaucmac 0.74141, 31.90 secs\n",
      "Adjusting learning rate of group 0 to 7.1611e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.53840, a_loss 1.07778, cD 1.26429, wmdcmp 0.16964, ema 0.62452, oracc 0.98369, orien_loss 0.03097, qlmicf1 0.36074, qlmacf1 0.20419, ql_loss 0.79747, chxlmicf1 0.49358, chxlmacf1 0.45134, chx_loss 0.90903, chxlacc 0.69063, chxlrocaucmic 0.77674, chxlrocaucmac 0.75825, gacc 0.96538, gloss 0.09124, cxr14micf1 0.31998, cxr14macf1 0.31258, cxr14_loss 0.99059, vnbgmicf1 0.55065, vnbgmacf1 0.40679, vnbg_loss 0.76483, b1 0.52243, b2 0.40954, b3 0.31153, b4 0.23752, padchxlmacf1 0.06065, padchxlmicf1 0.15975, padchxlzmacf1 0.06740, padchxlzmicf1 0.14551, padchxl_loss 0.33274, padchxlz_loss 0.46635, 107.95 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36232, wmdcmp 0.18241, ema 0.68487, oracc 0.98491, qlmicf1 0.36737, qlmacf1 0.20636, chxlmicf1 0.51159, chxlmacf1 0.45513, chxlacc 0.68418, chxlrocaucmic 0.77582, chxlrocaucmac 0.74151, 32.25 secs\n",
      "Adjusting learning rate of group 0 to 6.2217e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.92831, a_loss 1.06878, cD 1.29660, wmdcmp 0.17315, ema 0.61062, oracc 0.98267, orien_loss 0.03112, qlmicf1 0.35459, qlmacf1 0.20412, ql_loss 0.79889, chxlmicf1 0.49226, chxlmacf1 0.45073, chx_loss 0.90886, chxlacc 0.68900, chxlrocaucmic 0.77512, chxlrocaucmac 0.75862, gacc 0.96819, gloss 0.08342, cxr14micf1 0.30541, cxr14macf1 0.30671, cxr14_loss 1.00054, vnbgmicf1 0.54416, vnbgmacf1 0.40466, vnbg_loss 0.78338, b1 0.51066, b2 0.40658, b3 0.31890, b4 0.25129, padchxlmacf1 0.06469, padchxlmicf1 0.17537, padchxlzmacf1 0.08362, padchxlzmicf1 0.17779, padchxl_loss 0.35124, padchxlz_loss 0.48828, 108.61 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36221, wmdcmp 0.18202, ema 0.68039, oracc 0.98420, qlmicf1 0.35646, qlmacf1 0.20560, chxlmicf1 0.51137, chxlmacf1 0.45527, chxlacc 0.67956, chxlrocaucmic 0.77677, chxlrocaucmac 0.74209, 31.54 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.77620, a_loss 1.06938, cD 1.28116, wmdcmp 0.17143, ema 0.62517, oracc 0.98431, orien_loss 0.03179, qlmicf1 0.35377, qlmacf1 0.20321, ql_loss 0.80123, chxlmicf1 0.49306, chxlmacf1 0.45181, chx_loss 0.91044, chxlacc 0.68917, chxlrocaucmic 0.77590, chxlrocaucmac 0.75888, gacc 0.96865, gloss 0.08889, cxr14micf1 0.30389, cxr14macf1 0.30740, cxr14_loss 1.02234, vnbgmicf1 0.55360, vnbgmacf1 0.40747, vnbg_loss 0.75558, b1 0.51539, b2 0.40759, b3 0.31810, b4 0.24641, padchxlmacf1 0.06896, padchxlmicf1 0.17705, padchxlzmacf1 0.07713, padchxlzmicf1 0.16911, padchxl_loss 0.32104, padchxlz_loss 0.46366, 107.70 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35827, wmdcmp 0.18232, ema 0.67681, oracc 0.98514, qlmicf1 0.36662, qlmacf1 0.20644, chxlmicf1 0.52250, chxlmacf1 0.45911, chxlacc 0.69231, chxlrocaucmic 0.78664, chxlrocaucmac 0.74221, 30.97 secs\n",
      "Adjusting learning rate of group 0 to 4.6965e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.07646, a_loss 1.07167, cD 1.30283, wmdcmp 0.17268, ema 0.62038, oracc 0.97997, orien_loss 0.03866, qlmicf1 0.35293, qlmacf1 0.20292, ql_loss 0.80560, chxlmicf1 0.49223, chxlmacf1 0.45080, chx_loss 0.90419, chxlacc 0.68946, chxlrocaucmic 0.77682, chxlrocaucmac 0.76042, gacc 0.96914, gloss 0.07993, cxr14micf1 0.28772, cxr14macf1 0.29796, cxr14_loss 1.00994, vnbgmicf1 0.54554, vnbgmacf1 0.40545, vnbg_loss 0.77699, b1 0.48520, b2 0.38828, b3 0.30534, b4 0.24031, padchxlmacf1 0.06828, padchxlmicf1 0.16555, padchxlzmacf1 0.07920, padchxlzmicf1 0.17691, padchxl_loss 0.35771, padchxlz_loss 0.48933, 105.91 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36062, wmdcmp 0.18242, ema 0.67950, oracc 0.98538, qlmicf1 0.36934, qlmacf1 0.20813, chxlmicf1 0.51226, chxlmacf1 0.45472, chxlacc 0.69624, chxlrocaucmic 0.77264, chxlrocaucmac 0.74267, 30.77 secs\n",
      "Adjusting learning rate of group 0 to 4.0804e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.45777, a_loss 1.09054, cD 1.31141, wmdcmp 0.17248, ema 0.61760, oracc 0.98451, orien_loss 0.02779, qlmicf1 0.35571, qlmacf1 0.20474, ql_loss 0.80007, chxlmicf1 0.49032, chxlmacf1 0.44766, chx_loss 0.91060, chxlacc 0.69078, chxlrocaucmic 0.77311, chxlrocaucmac 0.75582, gacc 0.97288, gloss 0.07482, cxr14micf1 0.32342, cxr14macf1 0.31114, cxr14_loss 0.98196, vnbgmicf1 0.55410, vnbgmacf1 0.42036, vnbg_loss 0.77419, b1 0.49013, b2 0.38242, b3 0.29240, b4 0.22344, padchxlmacf1 0.06409, padchxlmicf1 0.15419, padchxlzmacf1 0.07508, padchxlzmicf1 0.15210, padchxl_loss 0.34868, padchxlz_loss 0.50119, 105.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35898, wmdcmp 0.18152, ema 0.67055, oracc 0.98514, qlmicf1 0.36570, qlmacf1 0.20638, chxlmicf1 0.51714, chxlmacf1 0.45598, chxlacc 0.68640, chxlrocaucmic 0.78276, chxlrocaucmac 0.74189, 31.54 secs\n",
      "Adjusting learning rate of group 0 to 3.5451e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.71463, a_loss 1.06950, cD 1.27238, wmdcmp 0.16932, ema 0.62555, oracc 0.98190, orien_loss 0.02706, qlmicf1 0.35407, qlmacf1 0.20279, ql_loss 0.79816, chxlmicf1 0.49484, chxlmacf1 0.45218, chx_loss 0.90279, chxlacc 0.69015, chxlrocaucmic 0.77764, chxlrocaucmac 0.75990, gacc 0.97481, gloss 0.07288, cxr14micf1 0.30490, cxr14macf1 0.30809, cxr14_loss 0.99061, vnbgmicf1 0.55419, vnbgmacf1 0.40904, vnbg_loss 0.76556, b1 0.50356, b2 0.39689, b3 0.30944, b4 0.24162, padchxlmacf1 0.06285, padchxlmicf1 0.16467, padchxlzmacf1 0.07147, padchxlzmicf1 0.15315, padchxl_loss 0.33484, padchxlz_loss 0.48516, 108.42 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34504, wmdcmp 0.18077, ema 0.66786, oracc 0.98514, qlmicf1 0.36678, qlmacf1 0.20680, chxlmicf1 0.51211, chxlmacf1 0.45646, chxlacc 0.68287, chxlrocaucmic 0.77591, chxlrocaucmac 0.74322, 31.77 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.85289, a_loss 1.07462, cD 1.28517, wmdcmp 0.17011, ema 0.61722, oracc 0.98405, orien_loss 0.02655, qlmicf1 0.35634, qlmacf1 0.20299, ql_loss 0.79344, chxlmicf1 0.49242, chxlmacf1 0.45119, chx_loss 0.91270, chxlacc 0.69260, chxlrocaucmic 0.77745, chxlrocaucmac 0.75946, gacc 0.96865, gloss 0.08237, cxr14micf1 0.29879, cxr14macf1 0.30538, cxr14_loss 1.00855, vnbgmicf1 0.55802, vnbgmacf1 0.41137, vnbg_loss 0.76006, b1 0.49142, b2 0.39100, b3 0.30582, b4 0.23850, padchxlmacf1 0.06272, padchxlmicf1 0.16608, padchxlzmacf1 0.07918, padchxlzmicf1 0.16747, padchxl_loss 0.34174, padchxlz_loss 0.48782, 108.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35896, wmdcmp 0.18177, ema 0.67413, oracc 0.98561, qlmicf1 0.36014, qlmacf1 0.20672, chxlmicf1 0.51068, chxlmacf1 0.45460, chxlacc 0.68496, chxlrocaucmic 0.77611, chxlrocaucmac 0.74363, 31.54 secs\n",
      "Adjusting learning rate of group 0 to 2.6760e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.11495, a_loss 1.07405, cD 1.29850, wmdcmp 0.17288, ema 0.62182, oracc 0.98290, orien_loss 0.02451, qlmicf1 0.35530, qlmacf1 0.20444, ql_loss 0.79571, chxlmicf1 0.49245, chxlmacf1 0.45070, chx_loss 0.90598, chxlacc 0.69353, chxlrocaucmic 0.77727, chxlrocaucmac 0.76104, gacc 0.97067, gloss 0.07580, cxr14micf1 0.30376, cxr14macf1 0.30802, cxr14_loss 1.01730, vnbgmicf1 0.55243, vnbgmacf1 0.40800, vnbg_loss 0.79492, b1 0.51533, b2 0.40932, b3 0.31865, b4 0.24782, padchxlmacf1 0.06698, padchxlmicf1 0.16039, padchxlzmacf1 0.07674, padchxlzmicf1 0.16717, padchxl_loss 0.35145, padchxlz_loss 0.48746, 105.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.35329, wmdcmp 0.18138, ema 0.67413, oracc 0.98538, qlmicf1 0.36111, qlmacf1 0.20606, chxlmicf1 0.51495, chxlmacf1 0.45772, chxlacc 0.68376, chxlrocaucmic 0.77913, chxlrocaucmac 0.74354, 31.29 secs\n",
      "Adjusting learning rate of group 0 to 2.3250e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.96083, a_loss 1.07860, cD 1.28401, wmdcmp 0.16945, ema 0.62058, oracc 0.98343, orien_loss 0.02560, qlmicf1 0.35507, qlmacf1 0.20533, ql_loss 0.79429, chxlmicf1 0.49304, chxlmacf1 0.45182, chx_loss 0.90506, chxlacc 0.69103, chxlrocaucmic 0.77653, chxlrocaucmac 0.75952, gacc 0.97019, gloss 0.08125, cxr14micf1 0.30271, cxr14macf1 0.30461, cxr14_loss 1.01835, vnbgmicf1 0.55266, vnbgmacf1 0.41196, vnbg_loss 0.76579, b1 0.52182, b2 0.41781, b3 0.33237, b4 0.26229, padchxlmacf1 0.06973, padchxlmicf1 0.15837, padchxlzmacf1 0.08260, padchxlzmicf1 0.16634, padchxl_loss 0.34684, padchxlz_loss 0.48806, 106.47 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36226, wmdcmp 0.18239, ema 0.67323, oracc 0.98443, qlmicf1 0.36789, qlmacf1 0.20712, chxlmicf1 0.51601, chxlmacf1 0.45815, chxlacc 0.68470, chxlrocaucmic 0.78086, chxlrocaucmac 0.74390, 31.55 secs\n",
      "Adjusting learning rate of group 0 to 2.0200e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.50123, a_loss 1.07659, cD 1.27646, wmdcmp 0.16868, ema 0.61962, oracc 0.98461, orien_loss 0.02770, qlmicf1 0.35746, qlmacf1 0.20472, ql_loss 0.79929, chxlmicf1 0.49348, chxlmacf1 0.45274, chx_loss 0.90830, chxlacc 0.69030, chxlrocaucmic 0.77661, chxlrocaucmac 0.75986, gacc 0.96933, gloss 0.07850, cxr14micf1 0.31352, cxr14macf1 0.31001, cxr14_loss 1.00786, vnbgmicf1 0.55170, vnbgmacf1 0.40823, vnbg_loss 0.77303, b1 0.49891, b2 0.39397, b3 0.30696, b4 0.23886, padchxlmacf1 0.06020, padchxlmicf1 0.16056, padchxlzmacf1 0.07387, padchxlzmicf1 0.15197, padchxl_loss 0.34092, padchxlz_loss 0.47959, 109.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36147, wmdcmp 0.18268, ema 0.67771, oracc 0.98561, qlmicf1 0.36319, qlmacf1 0.20706, chxlmicf1 0.51520, chxlmacf1 0.45683, chxlacc 0.68358, chxlrocaucmic 0.78079, chxlrocaucmac 0.74259, 31.64 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.39800, a_loss 1.07827, cD 1.29259, wmdcmp 0.17183, ema 0.61933, oracc 0.98238, orien_loss 0.02941, qlmicf1 0.35795, qlmacf1 0.20584, ql_loss 0.79677, chxlmicf1 0.49324, chxlmacf1 0.45177, chx_loss 0.90342, chxlacc 0.69092, chxlrocaucmic 0.77864, chxlrocaucmac 0.76129, gacc 0.97635, gloss 0.07309, cxr14micf1 0.31075, cxr14macf1 0.31001, cxr14_loss 0.99935, vnbgmicf1 0.54787, vnbgmacf1 0.40901, vnbg_loss 0.78618, b1 0.48868, b2 0.38516, b3 0.30006, b4 0.23484, padchxlmacf1 0.06150, padchxlmicf1 0.16293, padchxlzmacf1 0.08117, padchxlzmicf1 0.18112, padchxl_loss 0.34157, padchxlz_loss 0.47357, 108.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37912, wmdcmp 0.18396, ema 0.67950, oracc 0.98514, qlmicf1 0.36381, qlmacf1 0.20753, chxlmicf1 0.51552, chxlmacf1 0.45682, chxlacc 0.68454, chxlrocaucmic 0.78075, chxlrocaucmac 0.74218, 31.50 secs\n",
      "Adjusting learning rate of group 0 to 1.5248e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.86538, a_loss 1.07126, cD 1.29177, wmdcmp 0.17107, ema 0.61895, oracc 0.98397, orien_loss 0.02746, qlmicf1 0.35544, qlmacf1 0.20216, ql_loss 0.79447, chxlmicf1 0.49077, chxlmacf1 0.44896, chx_loss 0.91021, chxlacc 0.69013, chxlrocaucmic 0.77553, chxlrocaucmac 0.75813, gacc 0.97173, gloss 0.07442, cxr14micf1 0.30583, cxr14macf1 0.30747, cxr14_loss 1.00446, vnbgmicf1 0.55208, vnbgmacf1 0.40855, vnbg_loss 0.76816, b1 0.49885, b2 0.39173, b3 0.30152, b4 0.23302, padchxlmacf1 0.06564, padchxlmicf1 0.16861, padchxlzmacf1 0.07496, padchxlzmicf1 0.16133, padchxl_loss 0.33808, padchxlz_loss 0.47792, 106.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34427, wmdcmp 0.18023, ema 0.68129, oracc 0.98467, qlmicf1 0.37022, qlmacf1 0.20741, chxlmicf1 0.51742, chxlmacf1 0.45678, chxlacc 0.68875, chxlrocaucmic 0.78267, chxlrocaucmac 0.74357, 31.04 secs\n",
      "Adjusting learning rate of group 0 to 1.3248e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.25885, a_loss 1.07647, cD 1.27897, wmdcmp 0.17004, ema 0.62548, oracc 0.98349, orien_loss 0.02499, qlmicf1 0.35738, qlmacf1 0.20509, ql_loss 0.79623, chxlmicf1 0.49384, chxlmacf1 0.45193, chx_loss 0.90400, chxlacc 0.68926, chxlrocaucmic 0.77809, chxlrocaucmac 0.75971, gacc 0.96769, gloss 0.07961, cxr14micf1 0.33517, cxr14macf1 0.32371, cxr14_loss 0.98056, vnbgmicf1 0.55390, vnbgmacf1 0.41321, vnbg_loss 0.77987, b1 0.51715, b2 0.41554, b3 0.33090, b4 0.26332, padchxlmacf1 0.05959, padchxlmicf1 0.15788, padchxlzmacf1 0.08021, padchxlzmicf1 0.17012, padchxl_loss 0.35813, padchxlz_loss 0.48278, 107.09 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36122, wmdcmp 0.18207, ema 0.67592, oracc 0.98632, qlmicf1 0.37008, qlmacf1 0.20797, chxlmicf1 0.51627, chxlmacf1 0.45546, chxlacc 0.69154, chxlrocaucmic 0.78147, chxlrocaucmac 0.74288, 31.40 secs\n",
      "Adjusting learning rate of group 0 to 1.1510e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.13200, a_loss 1.07074, cD 1.28660, wmdcmp 0.17100, ema 0.61981, oracc 0.98255, orien_loss 0.03164, qlmicf1 0.35460, qlmacf1 0.20524, ql_loss 0.79760, chxlmicf1 0.49076, chxlmacf1 0.44774, chx_loss 0.91060, chxlacc 0.69078, chxlrocaucmic 0.77495, chxlrocaucmac 0.75634, gacc 0.97238, gloss 0.07291, cxr14micf1 0.32656, cxr14macf1 0.32106, cxr14_loss 0.98761, vnbgmicf1 0.54986, vnbgmacf1 0.41486, vnbg_loss 0.77221, b1 0.50006, b2 0.39531, b3 0.30667, b4 0.23707, padchxlmacf1 0.07051, padchxlmicf1 0.17393, padchxlzmacf1 0.08289, padchxlzmicf1 0.16590, padchxl_loss 0.33404, padchxlz_loss 0.47553, 109.75 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.36176, wmdcmp 0.18237, ema 0.67860, oracc 0.98491, qlmicf1 0.36988, qlmacf1 0.20743, chxlmicf1 0.51479, chxlmacf1 0.45785, chxlacc 0.68260, chxlrocaucmic 0.78092, chxlrocaucmac 0.74398, 31.51 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_184019_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 50 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,9e-5,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0.2 \\\n",
    "        --iuxray-weight-chexpert-mode 0.16 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0.4 \\\n",
    "        --vinbig-weight 0.4 \\\n",
    "        --padchest-weight 0.5 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-base-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-base-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,9e-5,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 50\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.5\n",
      "   cxr14_weight: 0.0\n",
      "   vinbig_weight: 0.0\n",
      "   iuxray_weight: 0.1\n",
      "   mimiccxr_weight_chexpert_mode: 0.5\n",
      "   iuxray_weight_chexpert_mode: 0.08\n",
      "   padchest_weight: 0.0\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223745_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-base-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,9e-5,32,1e-6\n",
      "1e-06 8 9e-05 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for CenIA/vit-mae-base-finetuned-mimic\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=0, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=3, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=2, one_hot_question_offset=97\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 50\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=286,3547888293769522994).pkl\n",
      "\tlen(question_datasets) = 95\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n",
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating IU X-Ray vqa trainer ...\u001b[0m\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/iuxray_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_091601.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "Assigning all data to training ...\n",
      "All data assigned to train: len(train_indices) = 29046, len(val_indices) = 0\n",
      "batch_size = 50\n",
      "len(self.report_ids) = 29046, len(set(self.report_ids)) = 3806\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray/balanced_train_data(hash=282,1637362445184610094).pkl\n",
      "\tlen(question_datasets) = 55\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 3\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=1414, len(neg_indices)=2392\n",
      "label = 1, onehot=98, len(pos_indices)=387, len(neg_indices)=3419\n",
      "label = 2, onehot=99, len(pos_indices)=675, len(neg_indices)=3131\n",
      "label = 3, onehot=100, len(pos_indices)=232, len(neg_indices)=3574\n",
      "label = 4, onehot=101, len(pos_indices)=708, len(neg_indices)=3098\n",
      "label = 5, onehot=102, len(pos_indices)=153, len(neg_indices)=3653\n",
      "label = 6, onehot=103, len(pos_indices)=43, len(neg_indices)=3763\n",
      "label = 7, onehot=104, len(pos_indices)=138, len(neg_indices)=3668\n",
      "label = 8, onehot=105, len(pos_indices)=368, len(neg_indices)=3438\n",
      "label = 9, onehot=106, len(pos_indices)=100, len(neg_indices)=3706\n",
      "label = 10, onehot=107, len(pos_indices)=295, len(neg_indices)=3511\n",
      "label = 11, onehot=108, len(pos_indices)=71, len(neg_indices)=3735\n",
      "label = 12, onehot=109, len(pos_indices)=119, len(neg_indices)=3687\n",
      "label = 13, onehot=110, len(pos_indices)=220, len(neg_indices)=3586\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mCreating CheXpert vqa trainer ...\u001b[0m\n",
      "Loading dataframe from /mnt/workspace/chexpert/CheXpert-v1.0-small/train-val.csv\n",
      "Loading images\n",
      "Loading orientations\n",
      "Loading genders\n",
      "Loading chexpert labels\n",
      "label = 0, onehot=0, len(pos_indices)=22414, len(neg_indices)=201216\n",
      "label = 1, onehot=1, len(pos_indices)=23309, len(neg_indices)=200321\n",
      "label = 2, onehot=2, len(pos_indices)=35151, len(neg_indices)=188479\n",
      "label = 3, onehot=3, len(pos_indices)=10675, len(neg_indices)=212955\n",
      "label = 4, onehot=4, len(pos_indices)=111301, len(neg_indices)=112329\n",
      "label = 5, onehot=5, len(pos_indices)=65274, len(neg_indices)=158356\n",
      "label = 6, onehot=6, len(pos_indices)=42556, len(neg_indices)=181074\n",
      "label = 7, onehot=7, len(pos_indices)=24815, len(neg_indices)=198815\n",
      "label = 8, onehot=8, len(pos_indices)=67191, len(neg_indices)=156439\n",
      "label = 9, onehot=9, len(pos_indices)=22601, len(neg_indices)=201029\n",
      "label = 10, onehot=10, len(pos_indices)=97875, len(neg_indices)=125755\n",
      "label = 11, onehot=11, len(pos_indices)=6174, len(neg_indices)=217456\n",
      "label = 12, onehot=12, len(pos_indices)=9680, len(neg_indices)=213950\n",
      "label = 13, onehot=13, len(pos_indices)=117184, len(neg_indices)=106446\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 5\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.5, 0.1, 0.08, 0.5]\n",
      "merged_dataset_name = mim+mim(chex)+iu+iu(chex)+chexp(vqa)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_001640_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_001640_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_27_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5444.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223745_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_27_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5444.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m19) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_001640_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m20) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.62528, a_loss 1.34052, cD 1.37228, wmdcmp 0.18070, ema 0.64430, oracc 0.98650, orien_loss 0.01719, qlmicf1 0.36002, qlmacf1 0.20657, ql_loss 0.80652, chxlmicf1 0.49190, chxlmacf1 0.44747, chx_loss 0.90949, chxlacc 0.68614, chxlrocaucmic 0.77412, chxlrocaucmac 0.75577, gacc 0.97014, gloss 0.08374, 98.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38134, wmdcmp 0.18587, ema 0.67592, oracc 0.98727, qlmicf1 0.36866, qlmacf1 0.20771, chxlmicf1 0.51129, chxlmacf1 0.45389, chxlacc 0.68240, chxlrocaucmic 0.77735, chxlrocaucmac 0.74190, 30.40 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.92435, a_loss 1.41237, cD 1.26208, wmdcmp 0.16846, ema 0.64437, oracc 0.98706, orien_loss 0.01460, qlmicf1 0.35763, qlmacf1 0.20588, ql_loss 0.81836, chxlmicf1 0.49405, chxlmacf1 0.45006, chx_loss 0.90411, chxlacc 0.68750, chxlrocaucmic 0.77285, chxlrocaucmac 0.75636, gacc 0.96638, gloss 0.08927, 101.85 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.38201, wmdcmp 0.18617, ema 0.66338, oracc 0.98633, qlmicf1 0.36922, qlmacf1 0.20926, chxlmicf1 0.51636, chxlmacf1 0.45606, chxlacc 0.68715, chxlrocaucmic 0.78196, chxlrocaucmac 0.74302, 31.36 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.12203, a_loss 1.43966, cD 1.27568, wmdcmp 0.16985, ema 0.64416, oracc 0.98659, orien_loss 0.01582, qlmicf1 0.35425, qlmacf1 0.20829, ql_loss 0.81733, chxlmicf1 0.49316, chxlmacf1 0.44935, chx_loss 0.90861, chxlacc 0.68634, chxlrocaucmic 0.77431, chxlrocaucmac 0.75608, gacc 0.96812, gloss 0.08626, 103.20 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37261, wmdcmp 0.18503, ema 0.67055, oracc 0.98774, qlmicf1 0.36407, qlmacf1 0.20867, chxlmicf1 0.51644, chxlmacf1 0.45523, chxlacc 0.69117, chxlrocaucmic 0.78163, chxlrocaucmac 0.74356, 30.80 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.10101, a_loss 1.42320, cD 1.25912, wmdcmp 0.16875, ema 0.65219, oracc 0.98763, orien_loss 0.01180, qlmicf1 0.35312, qlmacf1 0.20753, ql_loss 0.81857, chxlmicf1 0.49245, chxlmacf1 0.44809, chx_loss 0.90837, chxlacc 0.68376, chxlrocaucmic 0.77111, chxlrocaucmac 0.75410, gacc 0.96886, gloss 0.08516, 103.01 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36393, wmdcmp 0.18446, ema 0.66786, oracc 0.98633, qlmicf1 0.35889, qlmacf1 0.20898, chxlmicf1 0.50371, chxlmacf1 0.45038, chxlacc 0.67886, chxlrocaucmic 0.77028, chxlrocaucmac 0.74319, 31.40 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.73092, a_loss 1.43001, cD 1.27104, wmdcmp 0.16996, ema 0.64403, oracc 0.98760, orien_loss 0.01591, qlmicf1 0.34898, qlmacf1 0.20668, ql_loss 0.81405, chxlmicf1 0.49348, chxlmacf1 0.44998, chx_loss 0.90703, chxlacc 0.68662, chxlrocaucmic 0.77283, chxlrocaucmac 0.75552, gacc 0.96522, gloss 0.09895, 105.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37351, wmdcmp 0.18564, ema 0.69024, oracc 0.98562, qlmicf1 0.37221, qlmacf1 0.20802, chxlmicf1 0.52110, chxlmacf1 0.45483, chxlacc 0.69602, chxlrocaucmic 0.78778, chxlrocaucmac 0.74308, 31.97 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.82950, a_loss 1.41006, cD 1.26430, wmdcmp 0.17048, ema 0.64583, oracc 0.98604, orien_loss 0.02000, qlmicf1 0.35516, qlmacf1 0.20700, ql_loss 0.81462, chxlmicf1 0.49823, chxlmacf1 0.45392, chx_loss 0.89969, chxlacc 0.69021, chxlrocaucmic 0.77648, chxlrocaucmac 0.75929, gacc 0.96348, gloss 0.10358, 106.84 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39368, wmdcmp 0.18790, ema 0.67055, oracc 0.98680, qlmicf1 0.37882, qlmacf1 0.21087, chxlmicf1 0.51966, chxlmacf1 0.45778, chxlacc 0.69144, chxlrocaucmic 0.78547, chxlrocaucmac 0.74473, 31.33 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 4.71979, a_loss 1.44315, cD 1.27605, wmdcmp 0.16825, ema 0.63329, oracc 0.98693, orien_loss 0.01913, qlmicf1 0.35215, qlmacf1 0.20857, ql_loss 0.81495, chxlmicf1 0.49095, chxlmacf1 0.44745, chx_loss 0.91199, chxlacc 0.68631, chxlrocaucmic 0.76946, chxlrocaucmac 0.75281, gacc 0.95826, gloss 0.10374, 105.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.34990, wmdcmp 0.18386, ema 0.67413, oracc 0.98703, qlmicf1 0.36851, qlmacf1 0.20768, chxlmicf1 0.51054, chxlmacf1 0.45135, chxlacc 0.68805, chxlrocaucmic 0.77655, chxlrocaucmac 0.74457, 31.28 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 1.31460, a_loss 1.42578, cD 1.24486, wmdcmp 0.16683, ema 0.63947, oracc 0.98659, orien_loss 0.02177, qlmicf1 0.34244, qlmacf1 0.20437, ql_loss 0.81875, chxlmicf1 0.49116, chxlmacf1 0.44698, chx_loss 0.91663, chxlacc 0.68283, chxlrocaucmic 0.76814, chxlrocaucmac 0.75004, gacc 0.95057, gloss 0.12969, 104.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38562, wmdcmp 0.18647, ema 0.66876, oracc 0.98703, qlmicf1 0.36765, qlmacf1 0.20879, chxlmicf1 0.50977, chxlmacf1 0.45198, chxlacc 0.67512, chxlrocaucmic 0.77867, chxlrocaucmac 0.74121, 31.90 secs\n",
      "Adjusting learning rate of group 0 to 9.0000e-05.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 4.41299, a_loss 1.43873, cD 1.23206, wmdcmp 0.16557, ema 0.63275, oracc 0.98085, orien_loss 0.03711, qlmicf1 0.33302, qlmacf1 0.19796, ql_loss 0.83220, chxlmicf1 0.47924, chxlmacf1 0.43628, chx_loss 0.93637, chxlacc 0.67380, chxlrocaucmic 0.75567, chxlrocaucmac 0.73831, gacc 0.91623, gloss 0.27835, 106.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.31592, wmdcmp 0.17994, ema 0.68308, oracc 0.98468, qlmicf1 0.35092, qlmacf1 0.20426, chxlmicf1 0.49042, chxlmacf1 0.44449, chxlacc 0.63211, chxlrocaucmic 0.77142, chxlrocaucmac 0.73175, 31.97 secs\n",
      "Adjusting learning rate of group 0 to 7.8194e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000078) ...\n",
      "loss 1.74641, a_loss 1.41449, cD 1.25137, wmdcmp 0.16826, ema 0.63841, oracc 0.98590, orien_loss 0.02546, qlmicf1 0.34546, qlmacf1 0.20243, ql_loss 0.82254, chxlmicf1 0.48721, chxlmacf1 0.44246, chx_loss 0.92118, chxlacc 0.67753, chxlrocaucmic 0.76286, chxlrocaucmac 0.74397, gacc 0.93971, gloss 0.16395, 107.57 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.29941, wmdcmp 0.17769, ema 0.68577, oracc 0.98562, qlmicf1 0.35191, qlmacf1 0.20609, chxlmicf1 0.50930, chxlmacf1 0.44775, chxlacc 0.67381, chxlrocaucmic 0.78253, chxlrocaucmac 0.74164, 31.46 secs\n",
      "Adjusting learning rate of group 0 to 6.7936e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000068) ...\n",
      "loss 4.65017, a_loss 1.42692, cD 1.27449, wmdcmp 0.17103, ema 0.62765, oracc 0.98557, orien_loss 0.02525, qlmicf1 0.34789, qlmacf1 0.20463, ql_loss 0.81861, chxlmicf1 0.49201, chxlmacf1 0.44852, chx_loss 0.91199, chxlacc 0.68494, chxlrocaucmic 0.77103, chxlrocaucmac 0.75290, gacc 0.94928, gloss 0.13031, 105.81 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36288, wmdcmp 0.18505, ema 0.68218, oracc 0.98680, qlmicf1 0.34754, qlmacf1 0.20814, chxlmicf1 0.50507, chxlmacf1 0.45091, chxlacc 0.67027, chxlrocaucmic 0.77579, chxlrocaucmac 0.74349, 31.15 secs\n",
      "Adjusting learning rate of group 0 to 5.9024e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000059) ...\n",
      "loss 1.21274, a_loss 1.40954, cD 1.30083, wmdcmp 0.17321, ema 0.64874, oracc 0.98687, orien_loss 0.01967, qlmicf1 0.35640, qlmacf1 0.21008, ql_loss 0.80525, chxlmicf1 0.50007, chxlmacf1 0.45422, chx_loss 0.90266, chxlacc 0.69219, chxlrocaucmic 0.77689, chxlrocaucmac 0.75980, gacc 0.95686, gloss 0.10678, 104.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.36656, wmdcmp 0.18605, ema 0.67055, oracc 0.98656, qlmicf1 0.36773, qlmacf1 0.21018, chxlmicf1 0.52351, chxlmacf1 0.44987, chxlacc 0.71474, chxlrocaucmic 0.78701, chxlrocaucmac 0.74884, 31.59 secs\n",
      "Adjusting learning rate of group 0 to 5.1282e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000051) ...\n",
      "loss 4.05255, a_loss 1.41537, cD 1.29450, wmdcmp 0.17245, ema 0.64413, oracc 0.98548, orien_loss 0.02060, qlmicf1 0.35005, qlmacf1 0.21015, ql_loss 0.81322, chxlmicf1 0.49701, chxlmacf1 0.45242, chx_loss 0.90234, chxlacc 0.69157, chxlrocaucmic 0.77670, chxlrocaucmac 0.75945, gacc 0.96290, gloss 0.09929, 107.21 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37427, wmdcmp 0.18558, ema 0.68756, oracc 0.98727, qlmicf1 0.38860, qlmacf1 0.21368, chxlmicf1 0.52666, chxlmacf1 0.45934, chxlacc 0.71319, chxlrocaucmic 0.78693, chxlrocaucmac 0.75009, 32.11 secs\n",
      "Adjusting learning rate of group 0 to 4.4555e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 4.34976, a_loss 1.41462, cD 1.28650, wmdcmp 0.17203, ema 0.65678, oracc 0.98699, orien_loss 0.02007, qlmicf1 0.35859, qlmacf1 0.21484, ql_loss 0.80598, chxlmicf1 0.50466, chxlmacf1 0.45798, chx_loss 0.89314, chxlacc 0.69460, chxlrocaucmic 0.78215, chxlrocaucmac 0.76262, gacc 0.95797, gloss 0.10925, 107.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37408, wmdcmp 0.18602, ema 0.67681, oracc 0.98703, qlmicf1 0.36567, qlmacf1 0.21039, chxlmicf1 0.51198, chxlmacf1 0.45766, chxlacc 0.67453, chxlrocaucmic 0.78371, chxlrocaucmac 0.75090, 31.47 secs\n",
      "Adjusting learning rate of group 0 to 3.8710e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000039) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.67392, a_loss 1.40677, cD 1.26705, wmdcmp 0.16851, ema 0.64914, oracc 0.98570, orien_loss 0.02328, qlmicf1 0.36461, qlmacf1 0.21349, ql_loss 0.80136, chxlmicf1 0.50426, chxlmacf1 0.45798, chx_loss 0.89353, chxlacc 0.69404, chxlrocaucmic 0.78237, chxlrocaucmac 0.76503, gacc 0.96029, gloss 0.10222, 102.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41932, wmdcmp 0.19110, ema 0.68577, oracc 0.98680, qlmicf1 0.35680, qlmacf1 0.21103, chxlmicf1 0.51639, chxlmacf1 0.45759, chxlacc 0.68878, chxlrocaucmic 0.78570, chxlrocaucmac 0.75039, 29.12 secs\n",
      "Adjusting learning rate of group 0 to 3.3632e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000034) ...\n",
      "loss 4.51335, a_loss 1.40971, cD 1.29815, wmdcmp 0.17292, ema 0.65436, oracc 0.98655, orien_loss 0.01929, qlmicf1 0.35639, qlmacf1 0.21261, ql_loss 0.80463, chxlmicf1 0.50531, chxlmacf1 0.46004, chx_loss 0.88717, chxlacc 0.69501, chxlrocaucmic 0.78372, chxlrocaucmac 0.76674, gacc 0.96638, gloss 0.08553, 96.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42319, wmdcmp 0.19035, ema 0.68577, oracc 0.98703, qlmicf1 0.37913, qlmacf1 0.21326, chxlmicf1 0.53603, chxlmacf1 0.46093, chxlacc 0.71104, chxlrocaucmic 0.80363, chxlrocaucmac 0.75504, 28.55 secs\n",
      "Adjusting learning rate of group 0 to 2.9220e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000029) ...\n",
      "loss 1.11261, a_loss 1.40748, cD 1.28434, wmdcmp 0.17179, ema 0.65073, oracc 0.98704, orien_loss 0.01797, qlmicf1 0.35894, qlmacf1 0.21319, ql_loss 0.80686, chxlmicf1 0.50476, chxlmacf1 0.46005, chx_loss 0.89116, chxlacc 0.69628, chxlrocaucmic 0.78274, chxlrocaucmac 0.76580, gacc 0.96914, gloss 0.08376, 95.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40471, wmdcmp 0.18986, ema 0.67860, oracc 0.98774, qlmicf1 0.37120, qlmacf1 0.21464, chxlmicf1 0.52888, chxlmacf1 0.46032, chxlacc 0.69881, chxlrocaucmic 0.79873, chxlrocaucmac 0.75201, 28.63 secs\n",
      "Adjusting learning rate of group 0 to 2.5387e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 4.65305, a_loss 1.40990, cD 1.30182, wmdcmp 0.17393, ema 0.65221, oracc 0.98629, orien_loss 0.02084, qlmicf1 0.36534, qlmacf1 0.21734, ql_loss 0.79820, chxlmicf1 0.50545, chxlmacf1 0.45812, chx_loss 0.88944, chxlacc 0.69725, chxlrocaucmic 0.78476, chxlrocaucmac 0.76681, gacc 0.97304, gloss 0.07756, 94.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42128, wmdcmp 0.19077, ema 0.68756, oracc 0.98774, qlmicf1 0.36401, qlmacf1 0.21536, chxlmicf1 0.51795, chxlmacf1 0.46086, chxlacc 0.68078, chxlrocaucmic 0.79174, chxlrocaucmac 0.75595, 28.36 secs\n",
      "Adjusting learning rate of group 0 to 2.2057e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 1.68577, a_loss 1.39560, cD 1.29674, wmdcmp 0.17244, ema 0.64768, oracc 0.98588, orien_loss 0.02110, qlmicf1 0.36009, qlmacf1 0.21799, ql_loss 0.79503, chxlmicf1 0.50733, chxlmacf1 0.46165, chx_loss 0.88642, chxlacc 0.69899, chxlrocaucmic 0.78739, chxlrocaucmac 0.76985, gacc 0.96522, gloss 0.09144, 92.98 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43655, wmdcmp 0.19359, ema 0.68577, oracc 0.98821, qlmicf1 0.36733, qlmacf1 0.21679, chxlmicf1 0.52553, chxlmacf1 0.45936, chxlacc 0.71035, chxlrocaucmic 0.79190, chxlrocaucmac 0.75711, 28.30 secs\n",
      "Adjusting learning rate of group 0 to 1.9163e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 4.57778, a_loss 1.41557, cD 1.30434, wmdcmp 0.17374, ema 0.65691, oracc 0.98694, orien_loss 0.02007, qlmicf1 0.36781, qlmacf1 0.21926, ql_loss 0.78943, chxlmicf1 0.51088, chxlmacf1 0.46426, chx_loss 0.87930, chxlacc 0.70289, chxlrocaucmic 0.79060, chxlrocaucmac 0.77349, gacc 0.97130, gloss 0.07706, 92.90 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37600, wmdcmp 0.18699, ema 0.69472, oracc 0.98727, qlmicf1 0.36918, qlmacf1 0.21779, chxlmicf1 0.52090, chxlmacf1 0.46045, chxlacc 0.69784, chxlrocaucmic 0.79033, chxlrocaucmac 0.75723, 28.21 secs\n",
      "Adjusting learning rate of group 0 to 1.6650e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 1.11673, a_loss 1.38899, cD 1.29502, wmdcmp 0.17340, ema 0.66013, oracc 0.98701, orien_loss 0.01629, qlmicf1 0.36405, qlmacf1 0.21873, ql_loss 0.79377, chxlmicf1 0.51322, chxlmacf1 0.46700, chx_loss 0.87706, chxlacc 0.70284, chxlrocaucmic 0.78974, chxlrocaucmac 0.77431, gacc 0.97143, gloss 0.07428, 92.93 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42351, wmdcmp 0.19061, ema 0.67950, oracc 0.98751, qlmicf1 0.35683, qlmacf1 0.21207, chxlmicf1 0.52824, chxlmacf1 0.46124, chxlacc 0.69820, chxlrocaucmic 0.79854, chxlrocaucmac 0.75624, 29.47 secs\n",
      "Adjusting learning rate of group 0 to 1.4465e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.45007, a_loss 1.40684, cD 1.30632, wmdcmp 0.17412, ema 0.65839, oracc 0.98678, orien_loss 0.01650, qlmicf1 0.37074, qlmacf1 0.22093, ql_loss 0.79237, chxlmicf1 0.51285, chxlmacf1 0.46683, chx_loss 0.87525, chxlacc 0.70420, chxlrocaucmic 0.79192, chxlrocaucmac 0.77538, gacc 0.97101, gloss 0.07139, 93.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38719, wmdcmp 0.18809, ema 0.69024, oracc 0.98821, qlmicf1 0.37428, qlmacf1 0.21748, chxlmicf1 0.52919, chxlmacf1 0.46416, chxlacc 0.70127, chxlrocaucmic 0.79736, chxlrocaucmac 0.75803, 28.22 secs\n",
      "Adjusting learning rate of group 0 to 1.2568e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 1.66118, a_loss 1.38314, cD 1.30604, wmdcmp 0.17372, ema 0.67152, oracc 0.98638, orien_loss 0.01949, qlmicf1 0.37007, qlmacf1 0.22044, ql_loss 0.79105, chxlmicf1 0.51774, chxlmacf1 0.47024, chx_loss 0.87056, chxlacc 0.70717, chxlrocaucmic 0.79437, chxlrocaucmac 0.77665, gacc 0.97188, gloss 0.07599, 92.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43590, wmdcmp 0.19342, ema 0.68218, oracc 0.98703, qlmicf1 0.36797, qlmacf1 0.21552, chxlmicf1 0.52752, chxlmacf1 0.46582, chxlacc 0.69321, chxlrocaucmic 0.79702, chxlrocaucmac 0.76041, 28.19 secs\n",
      "Adjusting learning rate of group 0 to 1.0919e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 4.82354, a_loss 1.41559, cD 1.31579, wmdcmp 0.17412, ema 0.66456, oracc 0.98583, orien_loss 0.01665, qlmicf1 0.36328, qlmacf1 0.21967, ql_loss 0.79503, chxlmicf1 0.51125, chxlmacf1 0.46595, chx_loss 0.87472, chxlacc 0.70305, chxlrocaucmic 0.79227, chxlrocaucmac 0.77626, gacc 0.97420, gloss 0.06752, 92.12 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42289, wmdcmp 0.19051, ema 0.69114, oracc 0.98821, qlmicf1 0.36826, qlmacf1 0.21646, chxlmicf1 0.51758, chxlmacf1 0.46062, chxlacc 0.68838, chxlrocaucmic 0.78798, chxlrocaucmac 0.75861, 28.13 secs\n",
      "Adjusting learning rate of group 0 to 9.4868e-06.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 1.13715, a_loss 1.38677, cD 1.31600, wmdcmp 0.17558, ema 0.65762, oracc 0.98776, orien_loss 0.01748, qlmicf1 0.36911, qlmacf1 0.22050, ql_loss 0.78521, chxlmicf1 0.51566, chxlmacf1 0.46870, chx_loss 0.87216, chxlacc 0.70587, chxlrocaucmic 0.79364, chxlrocaucmac 0.77754, gacc 0.97600, gloss 0.06180, 91.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43634, wmdcmp 0.19227, ema 0.68845, oracc 0.98680, qlmicf1 0.36960, qlmacf1 0.21737, chxlmicf1 0.52101, chxlmacf1 0.46052, chxlacc 0.69773, chxlrocaucmic 0.78949, chxlrocaucmac 0.75858, 28.19 secs\n",
      "Adjusting learning rate of group 0 to 8.2424e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 3.77589, a_loss 1.39621, cD 1.31564, wmdcmp 0.17472, ema 0.66653, oracc 0.98794, orien_loss 0.01368, qlmicf1 0.36730, qlmacf1 0.22266, ql_loss 0.78809, chxlmicf1 0.51408, chxlmacf1 0.46792, chx_loss 0.87614, chxlacc 0.70637, chxlrocaucmic 0.79365, chxlrocaucmac 0.77600, gacc 0.97420, gloss 0.06712, 92.69 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43380, wmdcmp 0.19181, ema 0.68666, oracc 0.98727, qlmicf1 0.36645, qlmacf1 0.21682, chxlmicf1 0.52390, chxlmacf1 0.46300, chxlacc 0.69308, chxlrocaucmic 0.79618, chxlrocaucmac 0.75934, 28.32 secs\n",
      "Adjusting learning rate of group 0 to 7.1611e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.81832, a_loss 1.40751, cD 1.30365, wmdcmp 0.17376, ema 0.66604, oracc 0.98664, orien_loss 0.01798, qlmicf1 0.36733, qlmacf1 0.22099, ql_loss 0.79145, chxlmicf1 0.51650, chxlmacf1 0.47102, chx_loss 0.86887, chxlacc 0.70568, chxlrocaucmic 0.79323, chxlrocaucmac 0.77978, gacc 0.97159, gloss 0.07226, 91.92 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "cD 1.41322, wmdcmp 0.19006, ema 0.69114, oracc 0.98727, qlmicf1 0.36290, qlmacf1 0.21711, chxlmicf1 0.51794, chxlmacf1 0.46066, chxlacc 0.69420, chxlrocaucmic 0.78865, chxlrocaucmac 0.75937, 28.27 secs\n",
      "Adjusting learning rate of group 0 to 6.2217e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.78110, a_loss 1.38356, cD 1.31458, wmdcmp 0.17538, ema 0.67033, oracc 0.98752, orien_loss 0.01518, qlmicf1 0.36863, qlmacf1 0.22149, ql_loss 0.79099, chxlmicf1 0.51789, chxlmacf1 0.47148, chx_loss 0.86979, chxlacc 0.70719, chxlrocaucmic 0.79577, chxlrocaucmac 0.78055, gacc 0.97826, gloss 0.06555, 91.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43076, wmdcmp 0.19196, ema 0.69203, oracc 0.98774, qlmicf1 0.36565, qlmacf1 0.21585, chxlmicf1 0.52407, chxlmacf1 0.46498, chxlacc 0.69507, chxlrocaucmic 0.79163, chxlrocaucmac 0.75780, 28.10 secs\n",
      "Adjusting learning rate of group 0 to 5.4056e-06.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.32383, a_loss 1.39770, cD 1.32091, wmdcmp 0.17561, ema 0.66591, oracc 0.98768, orien_loss 0.01456, qlmicf1 0.37321, qlmacf1 0.22361, ql_loss 0.78366, chxlmicf1 0.51802, chxlmacf1 0.47035, chx_loss 0.87193, chxlacc 0.70784, chxlrocaucmic 0.79638, chxlrocaucmac 0.77892, gacc 0.97217, gloss 0.07665, 91.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43359, wmdcmp 0.19206, ema 0.69472, oracc 0.98727, qlmicf1 0.37374, qlmacf1 0.21937, chxlmicf1 0.52722, chxlmacf1 0.46505, chxlacc 0.70095, chxlrocaucmic 0.79506, chxlrocaucmac 0.76074, 27.99 secs\n",
      "Adjusting learning rate of group 0 to 4.6965e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 1.03825, a_loss 1.38608, cD 1.30414, wmdcmp 0.17425, ema 0.67166, oracc 0.98590, orien_loss 0.01514, qlmicf1 0.37385, qlmacf1 0.22464, ql_loss 0.78711, chxlmicf1 0.51714, chxlmacf1 0.47056, chx_loss 0.86560, chxlacc 0.70698, chxlrocaucmic 0.79497, chxlrocaucmac 0.77889, gacc 0.97629, gloss 0.06056, 91.51 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.42873, wmdcmp 0.19239, ema 0.68845, oracc 0.98774, qlmicf1 0.37272, qlmacf1 0.21844, chxlmicf1 0.52724, chxlmacf1 0.46604, chxlacc 0.69789, chxlrocaucmic 0.79672, chxlrocaucmac 0.76117, 28.18 secs\n",
      "Adjusting learning rate of group 0 to 4.0804e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.39402, a_loss 1.40369, cD 1.31158, wmdcmp 0.17451, ema 0.65866, oracc 0.98719, orien_loss 0.01750, qlmicf1 0.37096, qlmacf1 0.22364, ql_loss 0.78644, chxlmicf1 0.51884, chxlmacf1 0.47203, chx_loss 0.86942, chxlacc 0.70716, chxlrocaucmic 0.79518, chxlrocaucmac 0.78000, gacc 0.97681, gloss 0.07144, 92.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41368, wmdcmp 0.19048, ema 0.69651, oracc 0.98798, qlmicf1 0.37301, qlmacf1 0.21872, chxlmicf1 0.52346, chxlmacf1 0.46482, chxlacc 0.69739, chxlrocaucmic 0.79140, chxlrocaucmac 0.75992, 28.19 secs\n",
      "Adjusting learning rate of group 0 to 3.5451e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.76208, a_loss 1.38113, cD 1.31947, wmdcmp 0.17489, ema 0.66570, oracc 0.98632, orien_loss 0.01529, qlmicf1 0.36649, qlmacf1 0.22025, ql_loss 0.79145, chxlmicf1 0.51588, chxlmacf1 0.46897, chx_loss 0.86689, chxlacc 0.70880, chxlrocaucmic 0.79502, chxlrocaucmac 0.77844, gacc 0.97913, gloss 0.06134, 92.76 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.44257, wmdcmp 0.19319, ema 0.69651, oracc 0.98845, qlmicf1 0.37573, qlmacf1 0.22075, chxlmicf1 0.52851, chxlmacf1 0.46392, chxlacc 0.70340, chxlrocaucmic 0.79764, chxlrocaucmac 0.75902, 28.20 secs\n",
      "Adjusting learning rate of group 0 to 3.0801e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.77100, a_loss 1.39882, cD 1.32560, wmdcmp 0.17625, ema 0.65960, oracc 0.98705, orien_loss 0.01288, qlmicf1 0.37392, qlmacf1 0.22299, ql_loss 0.77866, chxlmicf1 0.51795, chxlmacf1 0.47080, chx_loss 0.86301, chxlacc 0.70909, chxlrocaucmic 0.79895, chxlrocaucmac 0.78292, gacc 0.97246, gloss 0.07474, 92.22 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43315, wmdcmp 0.19183, ema 0.69293, oracc 0.98798, qlmicf1 0.37772, qlmacf1 0.22192, chxlmicf1 0.52638, chxlmacf1 0.46588, chxlacc 0.69956, chxlrocaucmic 0.79452, chxlrocaucmac 0.75957, 28.09 secs\n",
      "Adjusting learning rate of group 0 to 2.6760e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 1.23486, a_loss 1.38219, cD 1.31165, wmdcmp 0.17463, ema 0.66848, oracc 0.98741, orien_loss 0.01679, qlmicf1 0.37545, qlmacf1 0.22434, ql_loss 0.78197, chxlmicf1 0.51474, chxlmacf1 0.46913, chx_loss 0.86697, chxlacc 0.70781, chxlrocaucmic 0.79560, chxlrocaucmac 0.77980, gacc 0.97429, gloss 0.06808, 92.38 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43144, wmdcmp 0.19157, ema 0.69740, oracc 0.98774, qlmicf1 0.37655, qlmacf1 0.22089, chxlmicf1 0.52293, chxlmacf1 0.46466, chxlacc 0.69388, chxlrocaucmic 0.79489, chxlrocaucmac 0.76174, 28.16 secs\n",
      "Adjusting learning rate of group 0 to 2.3250e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.49348, a_loss 1.41220, cD 1.28694, wmdcmp 0.17191, ema 0.66913, oracc 0.98610, orien_loss 0.01930, qlmicf1 0.37551, qlmacf1 0.22746, ql_loss 0.78794, chxlmicf1 0.51956, chxlmacf1 0.47314, chx_loss 0.86166, chxlacc 0.70950, chxlrocaucmic 0.79599, chxlrocaucmac 0.78154, gacc 0.97246, gloss 0.06802, 92.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.44624, wmdcmp 0.19411, ema 0.69919, oracc 0.98727, qlmicf1 0.37633, qlmacf1 0.22191, chxlmicf1 0.52951, chxlmacf1 0.46704, chxlacc 0.70183, chxlrocaucmic 0.79776, chxlrocaucmac 0.76162, 28.17 secs\n",
      "Adjusting learning rate of group 0 to 2.0200e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.63017, a_loss 1.37501, cD 1.29654, wmdcmp 0.17326, ema 0.66861, oracc 0.98707, orien_loss 0.01441, qlmicf1 0.37611, qlmacf1 0.22570, ql_loss 0.78066, chxlmicf1 0.52043, chxlmacf1 0.47211, chx_loss 0.86392, chxlacc 0.70949, chxlrocaucmic 0.79717, chxlrocaucmac 0.78062, gacc 0.97826, gloss 0.05735, 92.78 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43988, wmdcmp 0.19274, ema 0.69024, oracc 0.98821, qlmicf1 0.37414, qlmacf1 0.21925, chxlmicf1 0.52684, chxlmacf1 0.46503, chxlacc 0.70078, chxlrocaucmic 0.79590, chxlrocaucmac 0.76050, 28.19 secs\n",
      "Adjusting learning rate of group 0 to 1.7550e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.22847, a_loss 1.40239, cD 1.30257, wmdcmp 0.17390, ema 0.66537, oracc 0.98759, orien_loss 0.01548, qlmicf1 0.37104, qlmacf1 0.22341, ql_loss 0.78669, chxlmicf1 0.52035, chxlmacf1 0.47343, chx_loss 0.86705, chxlacc 0.70898, chxlrocaucmic 0.79726, chxlrocaucmac 0.78110, gacc 0.98348, gloss 0.05005, 92.48 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.45438, wmdcmp 0.19419, ema 0.69561, oracc 0.98774, qlmicf1 0.37132, qlmacf1 0.21901, chxlmicf1 0.52449, chxlmacf1 0.46186, chxlacc 0.69662, chxlrocaucmic 0.79662, chxlrocaucmac 0.75882, 28.08 secs\n",
      "Adjusting learning rate of group 0 to 1.5248e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.26054, a_loss 1.39413, cD 1.30062, wmdcmp 0.17313, ema 0.67563, oracc 0.98684, orien_loss 0.01664, qlmicf1 0.36811, qlmacf1 0.22228, ql_loss 0.78788, chxlmicf1 0.51859, chxlmacf1 0.47181, chx_loss 0.86520, chxlacc 0.70958, chxlrocaucmic 0.79639, chxlrocaucmac 0.78067, gacc 0.97343, gloss 0.06777, 91.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.44832, wmdcmp 0.19441, ema 0.69024, oracc 0.98821, qlmicf1 0.37489, qlmacf1 0.21885, chxlmicf1 0.52863, chxlmacf1 0.46552, chxlacc 0.69812, chxlrocaucmic 0.79922, chxlrocaucmac 0.76089, 28.09 secs\n",
      "Adjusting learning rate of group 0 to 1.3248e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.69245, a_loss 1.38769, cD 1.32733, wmdcmp 0.17667, ema 0.67093, oracc 0.98761, orien_loss 0.01686, qlmicf1 0.37196, qlmacf1 0.22476, ql_loss 0.78113, chxlmicf1 0.52077, chxlmacf1 0.47378, chx_loss 0.86258, chxlacc 0.71119, chxlrocaucmic 0.79943, chxlrocaucmac 0.78287, gacc 0.97884, gloss 0.05988, 92.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43032, wmdcmp 0.19182, ema 0.68666, oracc 0.98774, qlmicf1 0.37716, qlmacf1 0.22034, chxlmicf1 0.52634, chxlmacf1 0.46474, chxlacc 0.70072, chxlrocaucmic 0.79742, chxlrocaucmac 0.76090, 28.29 secs\n",
      "Adjusting learning rate of group 0 to 1.1510e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.12984, a_loss 1.39804, cD 1.33844, wmdcmp 0.17778, ema 0.66107, oracc 0.98746, orien_loss 0.01757, qlmicf1 0.37500, qlmacf1 0.22412, ql_loss 0.77895, chxlmicf1 0.51898, chxlmacf1 0.47119, chx_loss 0.86665, chxlacc 0.70912, chxlrocaucmic 0.79747, chxlrocaucmac 0.78077, gacc 0.97768, gloss 0.06218, 92.79 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.45159, wmdcmp 0.19478, ema 0.69293, oracc 0.98845, qlmicf1 0.37939, qlmacf1 0.21943, chxlmicf1 0.52757, chxlmacf1 0.46648, chxlacc 0.70211, chxlrocaucmic 0.79516, chxlrocaucmac 0.76250, 28.13 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230123_223745_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 50 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,9e-5,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.5 \\\n",
    "        --iuxray-weight 0.1 \\\n",
    "        --iuxray-weight-chexpert-mode 0.08 \\\n",
    "        --chexpert-weight 0.5 \\\n",
    "        --cxr14-weight 0 \\\n",
    "        --vinbig-weight 0 \\\n",
    "        --padchest-weight 0 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-base-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   iuxray_qa_adapted_reports_filename: qa_adapted_reports__20220904_091601.json\n",
      "   mimiccxr_qa_adapted_reports_filename: qa_adapted_reports__20220904_095810.json\n",
      "   vocab_min_freq: 10\n",
      "   embed_size: 256\n",
      "   question_encoding: one-hot\n",
      "   answer_decoding: transformer\n",
      "   question_hidden_size: 128\n",
      "   answer_hidden_size: 256\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: vitmodel-huggingface\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: CenIA/vit-mae-base-finetuned-mimic\n",
      "   n_lstm_layers: 1\n",
      "   transf_dec_nhead: 2\n",
      "   transf_dec_dim_forward: 256\n",
      "   transf_dec_num_layers: 2\n",
      "   question_vec_size: 128\n",
      "   dropout_prob: 0\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,8,1e-4,32,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 100\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 4\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [224, 224]\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.0\n",
      "   cxr14_weight: 0.0\n",
      "   vinbig_weight: 0.0\n",
      "   iuxray_weight: 0.0\n",
      "   mimiccxr_weight_chexpert_mode: 0.8\n",
      "   iuxray_weight_chexpert_mode: 0.0\n",
      "   padchest_weight: 0.0\n",
      "   mimiccxr_include_chexpert_mode: True\n",
      "   iuxray_include_chexpert_mode: True\n",
      "   use_chexpert_mode_only: False\n",
      "   val_answer_decoding: greedy-search\n",
      "   beam_search_k: None\n",
      "   use_amp: True\n",
      "   medical_tokenization: True\n",
      "   medical_terms_frequency_filename: medical_terms_frequency__20220918_184255.pkl\n",
      "   allowed_questions: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_001640_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp\n",
      "   balanced_dataloading: True\n",
      "   imbalance_reduction_coef: 0.5\n",
      "   iuxray_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210029.pkl\n",
      "   mimiccxr_balanced_metadata_filename: balanced_dataloading_metadata__20220918_210415.pkl\n",
      "   one_question_per_batch: False\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: True\n",
      "   train_chexpert: True\n",
      "   chexpert_mode: vqa\n",
      "   train_cxr14: True\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: True\n",
      "   padchest_training_data_mode: all\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\n",
      "   padchest_val_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\n",
      "   padchest_test_study_ids_path: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\n",
      "   binary_loss_name: wbce-c\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: True\n",
      "   classify_chexpert: True\n",
      "   iuxray_chexpert_labels_filename: chexpert_labels_per_report__20220904_113427.pkl\n",
      "   mimiccxr_chexpert_labels_filename: chexpert_labels_per_report__20220904_113605.pkl\n",
      "   classify_questions: True\n",
      "   n_questions: 97\n",
      "   iuxray_question_labels_filename: question_labels_per_report__20220904_105752.pkl\n",
      "   mimiccxr_question_labels_filename: question_labels_per_report__20220904_105753.pkl\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Debug: balanced_dataloading = True\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mLoading mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-base-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,8,1e-4,32,1e-6\n",
      "1e-06 8 0.0001 32 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=True\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for CenIA/vit-mae-base-finetuned-mimic\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "len(final_transforms) = 16\n",
      "default_prob = 0.3\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "get_vqa_collate_batch_fn(): dataset_id=4, one_hot_question_offset=0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa trainer ...\u001b[0m\n",
      "MIMICCXR_VQA_Trainer: balanced_dataloading = True\n",
      "self.balanced_dataloading = True\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053,medical_terms_frequency__20220918_184255.pkl).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 100\n",
      "len(self.report_ids) = 2034935, len(set(self.report_ids)) = 223623\n",
      "_generate_datasets_and_dataloaders()\n",
      "self.balanced_dataloading = True\n",
      "_generate_train_dataset__balanced()\n",
      "Balanced train data loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/balanced_train_data(hash=287,3668960449562639709).pkl\n",
      "\tlen(question_datasets) = 93\n",
      "len(self.val_indices) = 16416\n",
      "len(val_indices) = 3258\n",
      "generating training and validation dataloaders ...\n",
      "num_workers = 4\n",
      "Generating perfectly balanced train dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=43016, len(neg_indices)=178811\n",
      "label = 1, onehot=98, len(pos_indices)=43215, len(neg_indices)=178612\n",
      "label = 2, onehot=99, len(pos_indices)=71655, len(neg_indices)=150172\n",
      "label = 3, onehot=100, len(pos_indices)=9668, len(neg_indices)=212159\n",
      "label = 4, onehot=101, len(pos_indices)=73721, len(neg_indices)=148106\n",
      "label = 5, onehot=102, len(pos_indices)=42623, len(neg_indices)=179204\n",
      "label = 6, onehot=103, len(pos_indices)=19790, len(neg_indices)=202037\n",
      "label = 7, onehot=104, len(pos_indices)=37343, len(neg_indices)=184484\n",
      "label = 8, onehot=105, len(pos_indices)=69678, len(neg_indices)=152149\n",
      "label = 9, onehot=106, len(pos_indices)=13071, len(neg_indices)=208756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 10, onehot=107, len(pos_indices)=68496, len(neg_indices)=153331\n",
      "label = 11, onehot=108, len(pos_indices)=4944, len(neg_indices)=216883\n",
      "label = 12, onehot=109, len(pos_indices)=8414, len(neg_indices)=213413\n",
      "label = 13, onehot=110, len(pos_indices)=87913, len(neg_indices)=133914\n",
      "len(self.train_dataset__chexpert_mode) = 1000000000000000000\n",
      "Generating balanced validation dataset in chexpert mode ...\n",
      "label = 0, onehot=97, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 1, onehot=98, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 2, onehot=99, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 3, onehot=100, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 4, onehot=101, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 5, onehot=102, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 6, onehot=103, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 7, onehot=104, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 8, onehot=105, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 9, onehot=106, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 10, onehot=107, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 11, onehot=108, len(pos_indices)=40, len(neg_indices)=40\n",
      "label = 12, onehot=109, len(pos_indices)=37, len(neg_indices)=40\n",
      "label = 13, onehot=110, len(pos_indices)=40, len(neg_indices)=40\n",
      "len(self.val_dataset__chexpert_mode) = 1117\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 2\n",
      "len(_val_dataloaders) = 2\n",
      "_train_weights = [1.0, 0.8]\n",
      "merged_dataset_name = mim+mim(chex)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m15) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m16) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_35_chf1+chf1+cD+ema+gacc+orcc+qlf1+qlf1+wmmp=0.5700.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_001640_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp/checkpoint_35_chf1+chf1+cD+ema+gacc+orcc+qlf1+qlf1+wmmp=0.5700.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m17) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m18) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.69734, a_loss 1.34844, cD 1.35066, wmdcmp 0.17939, ema 0.68253, oracc 0.97825, orien_loss 0.01102, qlmicf1 0.35550, qlmacf1 0.20940, ql_loss 0.85676, chxlmicf1 0.52763, chxlmacf1 0.48102, chx_loss 0.85188, chxlacc 0.70493, chxlrocaucmic 0.80143, chxlrocaucmac 0.78601, 137.31 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41843, wmdcmp 0.19204, ema 0.69830, oracc 0.98753, qlmicf1 0.36079, qlmacf1 0.22118, chxlmicf1 0.52512, chxlmacf1 0.46797, chxlacc 0.69527, chxlrocaucmic 0.79588, chxlrocaucmac 0.76531, 17.55 secs\n",
      "Adjusting learning rate of group 0 to 1.7783e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.44899, a_loss 1.38855, cD 1.29056, wmdcmp 0.17492, ema 0.67700, oracc 0.97655, orien_loss 0.01160, qlmicf1 0.34406, qlmacf1 0.20793, ql_loss 0.86206, chxlmicf1 0.52672, chxlmacf1 0.47925, chx_loss 0.85252, chxlacc 0.70601, chxlrocaucmic 0.79994, chxlrocaucmac 0.78562, 135.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40925, wmdcmp 0.18980, ema 0.70188, oracc 0.98729, qlmicf1 0.35504, qlmacf1 0.21762, chxlmicf1 0.52972, chxlmacf1 0.46926, chxlacc 0.70162, chxlrocaucmic 0.79909, chxlrocaucmac 0.76647, 17.59 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.40539, a_loss 1.38581, cD 1.32248, wmdcmp 0.17720, ema 0.68587, oracc 0.97561, orien_loss 0.01240, qlmicf1 0.34128, qlmacf1 0.20753, ql_loss 0.86429, chxlmicf1 0.52792, chxlmacf1 0.48018, chx_loss 0.85177, chxlacc 0.70830, chxlrocaucmic 0.80145, chxlrocaucmac 0.78568, 135.62 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40395, wmdcmp 0.18953, ema 0.71173, oracc 0.98682, qlmicf1 0.35184, qlmacf1 0.21994, chxlmicf1 0.52480, chxlmacf1 0.46825, chxlacc 0.69925, chxlrocaucmic 0.79354, chxlrocaucmac 0.76650, 17.58 secs\n",
      "Adjusting learning rate of group 0 to 5.6234e-06.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.38806, a_loss 1.38722, cD 1.29123, wmdcmp 0.17460, ema 0.68460, oracc 0.97636, orien_loss 0.01036, qlmicf1 0.34003, qlmacf1 0.20865, ql_loss 0.85973, chxlmicf1 0.52979, chxlmacf1 0.48179, chx_loss 0.84687, chxlacc 0.71029, chxlrocaucmic 0.80246, chxlrocaucmac 0.78787, 135.46 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.39508, wmdcmp 0.18839, ema 0.70725, oracc 0.98729, qlmicf1 0.34574, qlmacf1 0.21944, chxlmicf1 0.52810, chxlmacf1 0.46792, chxlacc 0.70279, chxlrocaucmic 0.79688, chxlrocaucmac 0.76675, 17.77 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 4.54479, a_loss 1.38838, cD 1.30055, wmdcmp 0.17481, ema 0.68413, oracc 0.97661, orien_loss 0.01057, qlmicf1 0.33810, qlmacf1 0.20681, ql_loss 0.85952, chxlmicf1 0.52635, chxlmacf1 0.47775, chx_loss 0.85719, chxlacc 0.70841, chxlrocaucmic 0.79957, chxlrocaucmac 0.78335, 135.06 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.38795, wmdcmp 0.18811, ema 0.70278, oracc 0.98753, qlmicf1 0.35158, qlmacf1 0.22067, chxlmicf1 0.52865, chxlmacf1 0.46974, chxlacc 0.68854, chxlrocaucmic 0.80348, chxlrocaucmac 0.76459, 17.60 secs\n",
      "Adjusting learning rate of group 0 to 1.7783e-05.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 4.58545, a_loss 1.38758, cD 1.30968, wmdcmp 0.17536, ema 0.68573, oracc 0.97739, orien_loss 0.01234, qlmicf1 0.33470, qlmacf1 0.20776, ql_loss 0.85975, chxlmicf1 0.52696, chxlmacf1 0.47909, chx_loss 0.85512, chxlacc 0.70771, chxlrocaucmic 0.79973, chxlrocaucmac 0.78391, 135.26 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40705, wmdcmp 0.19006, ema 0.70457, oracc 0.98753, qlmicf1 0.34166, qlmacf1 0.21849, chxlmicf1 0.52863, chxlmacf1 0.47042, chxlacc 0.69541, chxlrocaucmic 0.79998, chxlrocaucmac 0.76665, 17.69 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-05.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 4.35721, a_loss 1.39361, cD 1.31420, wmdcmp 0.17701, ema 0.68480, oracc 0.97549, orien_loss 0.01498, qlmicf1 0.33416, qlmacf1 0.20706, ql_loss 0.85896, chxlmicf1 0.52541, chxlmacf1 0.47746, chx_loss 0.85588, chxlacc 0.70835, chxlrocaucmic 0.79899, chxlrocaucmac 0.78374, 135.53 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41139, wmdcmp 0.19062, ema 0.70815, oracc 0.98682, qlmicf1 0.35680, qlmacf1 0.22225, chxlmicf1 0.52649, chxlmacf1 0.46849, chxlacc 0.70171, chxlrocaucmic 0.79344, chxlrocaucmac 0.76701, 17.65 secs\n",
      "Adjusting learning rate of group 0 to 5.6234e-05.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 4.46191, a_loss 1.38716, cD 1.31022, wmdcmp 0.17570, ema 0.68593, oracc 0.97545, orien_loss 0.01554, qlmicf1 0.33149, qlmacf1 0.20658, ql_loss 0.86299, chxlmicf1 0.52235, chxlmacf1 0.47395, chx_loss 0.86420, chxlacc 0.70458, chxlrocaucmic 0.79440, chxlrocaucmac 0.77842, 135.04 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cD 1.40409, wmdcmp 0.18939, ema 0.71352, oracc 0.98611, qlmicf1 0.34658, qlmacf1 0.21906, chxlmicf1 0.51274, chxlmacf1 0.46116, chxlacc 0.68584, chxlrocaucmic 0.78221, chxlrocaucmac 0.76110, 17.55 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.16841, a_loss 1.39116, cD 1.29204, wmdcmp 0.17423, ema 0.66720, oracc 0.97259, orien_loss 0.02195, qlmicf1 0.32667, qlmacf1 0.20502, ql_loss 0.86637, chxlmicf1 0.51967, chxlmacf1 0.47185, chx_loss 0.87094, chxlacc 0.70182, chxlrocaucmic 0.79145, chxlrocaucmac 0.77463, 135.66 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41261, wmdcmp 0.19068, ema 0.69919, oracc 0.98353, qlmicf1 0.32193, qlmacf1 0.21183, chxlmicf1 0.51490, chxlmacf1 0.46232, chxlacc 0.66699, chxlrocaucmic 0.79135, chxlrocaucmac 0.76062, 17.60 secs\n",
      "Adjusting learning rate of group 0 to 8.6596e-05.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000087) ...\n",
      "loss 4.59552, a_loss 1.38887, cD 1.29963, wmdcmp 0.17513, ema 0.68573, oracc 0.97346, orien_loss 0.02051, qlmicf1 0.32990, qlmacf1 0.20682, ql_loss 0.86029, chxlmicf1 0.52113, chxlmacf1 0.47275, chx_loss 0.86632, chxlacc 0.70380, chxlrocaucmic 0.79506, chxlrocaucmac 0.77798, 135.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.37693, wmdcmp 0.18459, ema 0.71262, oracc 0.98659, qlmicf1 0.36510, qlmacf1 0.22236, chxlmicf1 0.52532, chxlmacf1 0.46544, chxlacc 0.68524, chxlrocaucmic 0.79899, chxlrocaucmac 0.76228, 17.66 secs\n",
      "Adjusting learning rate of group 0 to 7.4989e-05.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000075) ...\n",
      "loss 4.39291, a_loss 1.37588, cD 1.32245, wmdcmp 0.17812, ema 0.68807, oracc 0.97438, orien_loss 0.01709, qlmicf1 0.33511, qlmacf1 0.20879, ql_loss 0.85298, chxlmicf1 0.52801, chxlmacf1 0.47927, chx_loss 0.85222, chxlacc 0.70960, chxlrocaucmic 0.80105, chxlrocaucmac 0.78456, 135.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43063, wmdcmp 0.19170, ema 0.70725, oracc 0.98588, qlmicf1 0.33930, qlmacf1 0.21868, chxlmicf1 0.53297, chxlmacf1 0.47111, chxlacc 0.70495, chxlrocaucmic 0.80053, chxlrocaucmac 0.76501, 17.73 secs\n",
      "Adjusting learning rate of group 0 to 6.4938e-05.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000065) ...\n",
      "loss 4.42267, a_loss 1.37021, cD 1.33210, wmdcmp 0.17792, ema 0.69800, oracc 0.97617, orien_loss 0.01471, qlmicf1 0.33771, qlmacf1 0.21109, ql_loss 0.84405, chxlmicf1 0.53166, chxlmacf1 0.48299, chx_loss 0.84715, chxlacc 0.71548, chxlrocaucmic 0.80487, chxlrocaucmac 0.78973, 135.65 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.40973, wmdcmp 0.19005, ema 0.71173, oracc 0.98588, qlmicf1 0.34264, qlmacf1 0.22041, chxlmicf1 0.52959, chxlmacf1 0.46806, chxlacc 0.70877, chxlrocaucmic 0.79500, chxlrocaucmac 0.76660, 17.63 secs\n",
      "Adjusting learning rate of group 0 to 5.6234e-05.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 4.44894, a_loss 1.36910, cD 1.34169, wmdcmp 0.17895, ema 0.69333, oracc 0.97511, orien_loss 0.01337, qlmicf1 0.34087, qlmacf1 0.21314, ql_loss 0.84180, chxlmicf1 0.53596, chxlmacf1 0.48605, chx_loss 0.84147, chxlacc 0.71740, chxlrocaucmic 0.80686, chxlrocaucmac 0.79152, 136.92 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41044, wmdcmp 0.18910, ema 0.71262, oracc 0.98682, qlmicf1 0.35897, qlmacf1 0.22190, chxlmicf1 0.53065, chxlmacf1 0.47141, chxlacc 0.69976, chxlrocaucmic 0.79743, chxlrocaucmac 0.76560, 17.55 secs\n",
      "Adjusting learning rate of group 0 to 4.8697e-05.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 4.36939, a_loss 1.37101, cD 1.32857, wmdcmp 0.17855, ema 0.70313, oracc 0.97926, orien_loss 0.01116, qlmicf1 0.34311, qlmacf1 0.21405, ql_loss 0.83410, chxlmicf1 0.53829, chxlmacf1 0.48856, chx_loss 0.83658, chxlacc 0.72044, chxlrocaucmic 0.80926, chxlrocaucmac 0.79449, 135.55 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.43043, wmdcmp 0.19308, ema 0.71889, oracc 0.98635, qlmicf1 0.36765, qlmacf1 0.22272, chxlmicf1 0.54289, chxlmacf1 0.47755, chxlacc 0.70408, chxlrocaucmic 0.81063, chxlrocaucmac 0.76409, 17.77 secs\n",
      "Adjusting learning rate of group 0 to 4.2170e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 4.42983, a_loss 1.35754, cD 1.33141, wmdcmp 0.17890, ema 0.70233, oracc 0.97659, orien_loss 0.01248, qlmicf1 0.34728, qlmacf1 0.21549, ql_loss 0.83164, chxlmicf1 0.54051, chxlmacf1 0.48954, chx_loss 0.83540, chxlacc 0.72265, chxlrocaucmic 0.81031, chxlrocaucmac 0.79570, 136.82 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.41994, wmdcmp 0.19103, ema 0.73321, oracc 0.98706, qlmicf1 0.34279, qlmacf1 0.22205, chxlmicf1 0.52021, chxlmacf1 0.47025, chxlacc 0.70062, chxlrocaucmic 0.78535, chxlrocaucmac 0.77026, 17.76 secs\n",
      "Adjusting learning rate of group 0 to 3.6517e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 4.32464, a_loss 1.35495, cD 1.36251, wmdcmp 0.18103, ema 0.70633, oracc 0.97665, orien_loss 0.01229, qlmicf1 0.34911, qlmacf1 0.21719, ql_loss 0.82557, chxlmicf1 0.54426, chxlmacf1 0.49448, chx_loss 0.82334, chxlacc 0.72468, chxlrocaucmic 0.81397, chxlrocaucmac 0.79998, 137.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48241, wmdcmp 0.19828, ema 0.72247, oracc 0.98753, qlmicf1 0.34929, qlmacf1 0.22322, chxlmicf1 0.52440, chxlmacf1 0.47114, chxlacc 0.69788, chxlrocaucmic 0.79327, chxlrocaucmac 0.76951, 17.86 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 4.36164, a_loss 1.35601, cD 1.35729, wmdcmp 0.18166, ema 0.70613, oracc 0.97596, orien_loss 0.01298, qlmicf1 0.35209, qlmacf1 0.21878, ql_loss 0.82215, chxlmicf1 0.54896, chxlmacf1 0.49706, chx_loss 0.81972, chxlacc 0.72912, chxlrocaucmic 0.81659, chxlrocaucmac 0.80312, 136.15 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.46298, wmdcmp 0.19574, ema 0.71531, oracc 0.98776, qlmicf1 0.36136, qlmacf1 0.22902, chxlmicf1 0.53825, chxlmacf1 0.47071, chxlacc 0.72780, chxlrocaucmic 0.80243, chxlrocaucmac 0.77394, 17.58 secs\n",
      "Adjusting learning rate of group 0 to 2.7384e-05.\n",
      "\u001b[1m---- Epoch 18/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 4.08499, a_loss 1.34442, cD 1.36486, wmdcmp 0.18233, ema 0.70387, oracc 0.97710, orien_loss 0.00987, qlmicf1 0.35326, qlmacf1 0.22020, ql_loss 0.81981, chxlmicf1 0.54687, chxlmacf1 0.49652, chx_loss 0.82072, chxlacc 0.72697, chxlrocaucmic 0.81627, chxlrocaucmac 0.80278, 136.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.46062, wmdcmp 0.19431, ema 0.72695, oracc 0.98753, qlmicf1 0.35503, qlmacf1 0.22578, chxlmicf1 0.53643, chxlmacf1 0.47428, chxlacc 0.71443, chxlrocaucmic 0.80169, chxlrocaucmac 0.76823, 17.66 secs\n",
      "Adjusting learning rate of group 0 to 2.3714e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000024) ...\n",
      "loss 4.36472, a_loss 1.34537, cD 1.37557, wmdcmp 0.18287, ema 0.71333, oracc 0.97715, orien_loss 0.00884, qlmicf1 0.35441, qlmacf1 0.21915, ql_loss 0.81744, chxlmicf1 0.54949, chxlmacf1 0.49901, chx_loss 0.81250, chxlacc 0.72984, chxlrocaucmic 0.81882, chxlrocaucmac 0.80546, 136.40 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.46391, wmdcmp 0.19564, ema 0.72068, oracc 0.98776, qlmicf1 0.37762, qlmacf1 0.23037, chxlmicf1 0.54259, chxlmacf1 0.48055, chxlacc 0.71856, chxlrocaucmic 0.80770, chxlrocaucmac 0.77515, 17.75 secs\n",
      "Adjusting learning rate of group 0 to 2.0535e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 4.27284, a_loss 1.34972, cD 1.36159, wmdcmp 0.18161, ema 0.71513, oracc 0.97779, orien_loss 0.00776, qlmicf1 0.35808, qlmacf1 0.22457, ql_loss 0.81017, chxlmicf1 0.55268, chxlmacf1 0.50087, chx_loss 0.80729, chxlacc 0.73181, chxlrocaucmic 0.82166, chxlrocaucmac 0.80873, 135.88 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.45136, wmdcmp 0.19511, ema 0.72337, oracc 0.98588, qlmicf1 0.34694, qlmacf1 0.22394, chxlmicf1 0.54313, chxlmacf1 0.47894, chxlacc 0.71522, chxlrocaucmic 0.80930, chxlrocaucmac 0.77335, 17.75 secs\n",
      "Adjusting learning rate of group 0 to 1.7783e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 4.51893, a_loss 1.34485, cD 1.37215, wmdcmp 0.18335, ema 0.71793, oracc 0.97612, orien_loss 0.01057, qlmicf1 0.35626, qlmacf1 0.22418, ql_loss 0.80895, chxlmicf1 0.55354, chxlmacf1 0.50363, chx_loss 0.80510, chxlacc 0.73348, chxlrocaucmic 0.82179, chxlrocaucmac 0.80953, 135.02 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.47787, wmdcmp 0.19740, ema 0.71173, oracc 0.98706, qlmicf1 0.36421, qlmacf1 0.22766, chxlmicf1 0.53944, chxlmacf1 0.47767, chxlacc 0.71497, chxlrocaucmic 0.80419, chxlrocaucmac 0.76959, 17.60 secs\n",
      "Adjusting learning rate of group 0 to 1.5399e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 4.14617, a_loss 1.34785, cD 1.35322, wmdcmp 0.18064, ema 0.71593, oracc 0.97658, orien_loss 0.00921, qlmicf1 0.35869, qlmacf1 0.22170, ql_loss 0.80854, chxlmicf1 0.55473, chxlmacf1 0.50348, chx_loss 0.80365, chxlacc 0.73485, chxlrocaucmic 0.82329, chxlrocaucmac 0.81069, 135.37 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.44000, wmdcmp 0.19371, ema 0.73232, oracc 0.98706, qlmicf1 0.36036, qlmacf1 0.22854, chxlmicf1 0.53981, chxlmacf1 0.47668, chxlacc 0.72527, chxlrocaucmic 0.80243, chxlrocaucmac 0.77319, 17.66 secs\n",
      "Adjusting learning rate of group 0 to 1.3335e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 4.16904, a_loss 1.34309, cD 1.38078, wmdcmp 0.18450, ema 0.71927, oracc 0.97740, orien_loss 0.01062, qlmicf1 0.35950, qlmacf1 0.22274, ql_loss 0.80704, chxlmicf1 0.55555, chxlmacf1 0.50505, chx_loss 0.80236, chxlacc 0.73552, chxlrocaucmic 0.82234, chxlrocaucmac 0.81043, 134.64 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.46301, wmdcmp 0.19470, ema 0.72426, oracc 0.98753, qlmicf1 0.36244, qlmacf1 0.22864, chxlmicf1 0.54422, chxlmacf1 0.47597, chxlacc 0.72856, chxlrocaucmic 0.80819, chxlrocaucmac 0.77311, 17.56 secs\n",
      "Adjusting learning rate of group 0 to 1.1548e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 4.34310, a_loss 1.34130, cD 1.36810, wmdcmp 0.18310, ema 0.71580, oracc 0.97706, orien_loss 0.00991, qlmicf1 0.36090, qlmacf1 0.22526, ql_loss 0.80333, chxlmicf1 0.55755, chxlmacf1 0.50667, chx_loss 0.79904, chxlacc 0.73759, chxlrocaucmic 0.82571, chxlrocaucmac 0.81353, 135.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48546, wmdcmp 0.19817, ema 0.72068, oracc 0.98753, qlmicf1 0.36843, qlmacf1 0.22967, chxlmicf1 0.54977, chxlmacf1 0.48095, chxlacc 0.73007, chxlrocaucmic 0.81335, chxlrocaucmac 0.77549, 17.59 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 4.35605, a_loss 1.33955, cD 1.37237, wmdcmp 0.18295, ema 0.71967, oracc 0.97794, orien_loss 0.01075, qlmicf1 0.36284, qlmacf1 0.22642, ql_loss 0.80075, chxlmicf1 0.55595, chxlmacf1 0.50506, chx_loss 0.80072, chxlacc 0.73677, chxlrocaucmic 0.82420, chxlrocaucmac 0.81223, 135.54 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.46780, wmdcmp 0.19562, ema 0.72695, oracc 0.98729, qlmicf1 0.37676, qlmacf1 0.22985, chxlmicf1 0.54233, chxlmacf1 0.47868, chxlacc 0.71767, chxlrocaucmic 0.80571, chxlrocaucmac 0.77289, 17.75 secs\n",
      "Adjusting learning rate of group 0 to 8.6596e-06.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 4.30393, a_loss 1.33958, cD 1.36095, wmdcmp 0.18220, ema 0.72093, oracc 0.97757, orien_loss 0.00844, qlmicf1 0.36325, qlmacf1 0.22513, ql_loss 0.80173, chxlmicf1 0.56006, chxlmacf1 0.50909, chx_loss 0.79163, chxlacc 0.73890, chxlrocaucmic 0.82727, chxlrocaucmac 0.81581, 135.43 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48004, wmdcmp 0.19691, ema 0.72605, oracc 0.98753, qlmicf1 0.35822, qlmacf1 0.22642, chxlmicf1 0.54200, chxlmacf1 0.47864, chxlacc 0.72322, chxlrocaucmic 0.80518, chxlrocaucmac 0.77329, 17.51 secs\n",
      "Adjusting learning rate of group 0 to 7.4989e-06.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.19556, a_loss 1.34307, cD 1.36361, wmdcmp 0.18305, ema 0.72000, oracc 0.97631, orien_loss 0.00829, qlmicf1 0.36440, qlmacf1 0.22849, ql_loss 0.79701, chxlmicf1 0.56187, chxlmacf1 0.51204, chx_loss 0.78800, chxlacc 0.74130, chxlrocaucmic 0.82886, chxlrocaucmac 0.81752, 136.07 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.49576, wmdcmp 0.19906, ema 0.72426, oracc 0.98800, qlmicf1 0.36404, qlmacf1 0.22799, chxlmicf1 0.54716, chxlmacf1 0.48047, chxlacc 0.72230, chxlrocaucmic 0.81177, chxlrocaucmac 0.77455, 17.53 secs\n",
      "Adjusting learning rate of group 0 to 6.4938e-06.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.14823, a_loss 1.33736, cD 1.38230, wmdcmp 0.18454, ema 0.72107, oracc 0.97743, orien_loss 0.00686, qlmicf1 0.36679, qlmacf1 0.23074, ql_loss 0.79720, chxlmicf1 0.56018, chxlmacf1 0.51034, chx_loss 0.78786, chxlacc 0.73873, chxlrocaucmic 0.82829, chxlrocaucmac 0.81700, 135.35 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48308, wmdcmp 0.19859, ema 0.72247, oracc 0.98776, qlmicf1 0.36468, qlmacf1 0.22955, chxlmicf1 0.54970, chxlmacf1 0.47934, chxlacc 0.72965, chxlrocaucmic 0.81144, chxlrocaucmac 0.77097, 17.60 secs\n",
      "Adjusting learning rate of group 0 to 5.6234e-06.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 4.20647, a_loss 1.34026, cD 1.39158, wmdcmp 0.18534, ema 0.72327, oracc 0.97759, orien_loss 0.00838, qlmicf1 0.36595, qlmacf1 0.22621, ql_loss 0.79516, chxlmicf1 0.56046, chxlmacf1 0.50955, chx_loss 0.78904, chxlacc 0.73973, chxlrocaucmic 0.82854, chxlrocaucmac 0.81675, 135.87 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48183, wmdcmp 0.19800, ema 0.72158, oracc 0.98800, qlmicf1 0.36754, qlmacf1 0.22827, chxlmicf1 0.54740, chxlmacf1 0.48152, chxlacc 0.72740, chxlrocaucmic 0.80968, chxlrocaucmac 0.77217, 17.65 secs\n",
      "Adjusting learning rate of group 0 to 4.8697e-06.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 4.15343, a_loss 1.34067, cD 1.38645, wmdcmp 0.18496, ema 0.71993, oracc 0.97866, orien_loss 0.00628, qlmicf1 0.36627, qlmacf1 0.22583, ql_loss 0.79520, chxlmicf1 0.56272, chxlmacf1 0.51168, chx_loss 0.78764, chxlacc 0.74166, chxlrocaucmic 0.83010, chxlrocaucmac 0.81812, 135.14 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.47060, wmdcmp 0.19677, ema 0.73142, oracc 0.98753, qlmicf1 0.37359, qlmacf1 0.22946, chxlmicf1 0.55209, chxlmacf1 0.48127, chxlacc 0.72780, chxlrocaucmic 0.81586, chxlrocaucmac 0.77374, 17.59 secs\n",
      "Adjusting learning rate of group 0 to 4.2170e-06.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.25520, a_loss 1.33350, cD 1.37100, wmdcmp 0.18315, ema 0.72527, oracc 0.97811, orien_loss 0.00882, qlmicf1 0.36342, qlmacf1 0.22982, ql_loss 0.79594, chxlmicf1 0.56337, chxlmacf1 0.51288, chx_loss 0.78557, chxlacc 0.74096, chxlrocaucmic 0.83135, chxlrocaucmac 0.81959, 134.25 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48818, wmdcmp 0.19774, ema 0.73142, oracc 0.98800, qlmicf1 0.36510, qlmacf1 0.22916, chxlmicf1 0.54358, chxlmacf1 0.47896, chxlacc 0.72374, chxlrocaucmic 0.80865, chxlrocaucmac 0.77484, 17.75 secs\n",
      "Adjusting learning rate of group 0 to 3.6517e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 4.24231, a_loss 1.33504, cD 1.37243, wmdcmp 0.18400, ema 0.72507, oracc 0.97722, orien_loss 0.00745, qlmicf1 0.36931, qlmacf1 0.22895, ql_loss 0.79152, chxlmicf1 0.56450, chxlmacf1 0.51450, chx_loss 0.78300, chxlacc 0.74316, chxlrocaucmic 0.83197, chxlrocaucmac 0.82020, 135.29 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.47272, wmdcmp 0.19621, ema 0.72963, oracc 0.98800, qlmicf1 0.36184, qlmacf1 0.22803, chxlmicf1 0.54660, chxlmacf1 0.48313, chxlacc 0.71923, chxlrocaucmic 0.81215, chxlrocaucmac 0.77404, 17.63 secs\n",
      "Adjusting learning rate of group 0 to 3.1623e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.17034, a_loss 1.33337, cD 1.39489, wmdcmp 0.18638, ema 0.73087, oracc 0.97909, orien_loss 0.00761, qlmicf1 0.36347, qlmacf1 0.23105, ql_loss 0.79530, chxlmicf1 0.56111, chxlmacf1 0.51149, chx_loss 0.78861, chxlacc 0.74021, chxlrocaucmic 0.82929, chxlrocaucmac 0.81774, 135.00 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.45766, wmdcmp 0.19530, ema 0.73321, oracc 0.98729, qlmicf1 0.36176, qlmacf1 0.22816, chxlmicf1 0.55001, chxlmacf1 0.48411, chxlacc 0.72660, chxlrocaucmic 0.81337, chxlrocaucmac 0.77545, 17.58 secs\n",
      "Adjusting learning rate of group 0 to 2.7384e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 4.15547, a_loss 1.33669, cD 1.39503, wmdcmp 0.18670, ema 0.72147, oracc 0.97972, orien_loss 0.00517, qlmicf1 0.36682, qlmacf1 0.22668, ql_loss 0.79260, chxlmicf1 0.56312, chxlmacf1 0.51384, chx_loss 0.77961, chxlacc 0.74208, chxlrocaucmic 0.83169, chxlrocaucmac 0.82099, 135.50 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.46559, wmdcmp 0.19682, ema 0.72516, oracc 0.98706, qlmicf1 0.36478, qlmacf1 0.22813, chxlmicf1 0.54828, chxlmacf1 0.48032, chxlacc 0.72681, chxlrocaucmic 0.81203, chxlrocaucmac 0.77265, 17.62 secs\n",
      "Adjusting learning rate of group 0 to 2.3714e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.20715, a_loss 1.33121, cD 1.38866, wmdcmp 0.18519, ema 0.72120, oracc 0.97626, orien_loss 0.00601, qlmicf1 0.36924, qlmacf1 0.22660, ql_loss 0.79314, chxlmicf1 0.56632, chxlmacf1 0.51625, chx_loss 0.78094, chxlacc 0.74394, chxlrocaucmic 0.83224, chxlrocaucmac 0.82125, 136.75 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.47670, wmdcmp 0.19756, ema 0.72963, oracc 0.98729, qlmicf1 0.36455, qlmacf1 0.22889, chxlmicf1 0.54687, chxlmacf1 0.48110, chxlacc 0.72531, chxlrocaucmic 0.81089, chxlrocaucmac 0.77537, 17.58 secs\n",
      "Adjusting learning rate of group 0 to 2.0535e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.34853, a_loss 1.33374, cD 1.38595, wmdcmp 0.18532, ema 0.72420, oracc 0.97573, orien_loss 0.00577, qlmicf1 0.36749, qlmacf1 0.23162, ql_loss 0.79305, chxlmicf1 0.56303, chxlmacf1 0.51328, chx_loss 0.78099, chxlacc 0.74263, chxlrocaucmic 0.83089, chxlrocaucmac 0.82045, 136.33 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.48856, wmdcmp 0.19805, ema 0.71620, oracc 0.98800, qlmicf1 0.36243, qlmacf1 0.22835, chxlmicf1 0.55015, chxlmacf1 0.48281, chxlacc 0.72996, chxlrocaucmic 0.81218, chxlrocaucmac 0.77443, 17.56 secs\n",
      "Adjusting learning rate of group 0 to 1.7783e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.14512, a_loss 1.33667, cD 1.37848, wmdcmp 0.18404, ema 0.72773, oracc 0.97741, orien_loss 0.00686, qlmicf1 0.36971, qlmacf1 0.23148, ql_loss 0.78639, chxlmicf1 0.56565, chxlmacf1 0.51654, chx_loss 0.77738, chxlacc 0.74393, chxlrocaucmic 0.83334, chxlrocaucmac 0.82220, 136.41 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.47119, wmdcmp 0.19602, ema 0.72247, oracc 0.98800, qlmicf1 0.37128, qlmacf1 0.23031, chxlmicf1 0.54954, chxlmacf1 0.48197, chxlacc 0.72875, chxlrocaucmic 0.81356, chxlrocaucmac 0.77417, 17.69 secs\n",
      "Adjusting learning rate of group 0 to 1.5399e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.05832, a_loss 1.33973, cD 1.37445, wmdcmp 0.18311, ema 0.72133, oracc 0.97835, orien_loss 0.00731, qlmicf1 0.37195, qlmacf1 0.22952, ql_loss 0.78992, chxlmicf1 0.56625, chxlmacf1 0.51592, chx_loss 0.77706, chxlacc 0.74547, chxlrocaucmic 0.83394, chxlrocaucmac 0.82290, 136.36 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.49472, wmdcmp 0.19811, ema 0.72784, oracc 0.98823, qlmicf1 0.37142, qlmacf1 0.22970, chxlmicf1 0.54848, chxlmacf1 0.48195, chxlacc 0.72893, chxlrocaucmic 0.81106, chxlrocaucmac 0.77220, 17.66 secs\n",
      "Adjusting learning rate of group 0 to 1.3335e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.19357, a_loss 1.33075, cD 1.39753, wmdcmp 0.18594, ema 0.72247, oracc 0.97872, orien_loss 0.00707, qlmicf1 0.37003, qlmacf1 0.23240, ql_loss 0.78822, chxlmicf1 0.56648, chxlmacf1 0.51658, chx_loss 0.77658, chxlacc 0.74447, chxlrocaucmic 0.83317, chxlrocaucmac 0.82297, 135.94 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.45437, wmdcmp 0.19441, ema 0.72784, oracc 0.98753, qlmicf1 0.36908, qlmacf1 0.23006, chxlmicf1 0.55354, chxlmacf1 0.48429, chxlacc 0.73234, chxlrocaucmic 0.81436, chxlrocaucmac 0.77632, 17.68 secs\n",
      "Adjusting learning rate of group 0 to 1.1548e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.07307, a_loss 1.33589, cD 1.37859, wmdcmp 0.18442, ema 0.73373, oracc 0.97669, orien_loss 0.00699, qlmicf1 0.36868, qlmacf1 0.22898, ql_loss 0.78959, chxlmicf1 0.56683, chxlmacf1 0.51593, chx_loss 0.77681, chxlacc 0.74519, chxlrocaucmic 0.83382, chxlrocaucmac 0.82293, 136.04 secs\n",
      "(2) Validation stage ...\n",
      "cD 1.47224, wmdcmp 0.19736, ema 0.71889, oracc 0.98753, qlmicf1 0.37134, qlmacf1 0.23032, chxlmicf1 0.54834, chxlmacf1 0.48064, chxlacc 0.72870, chxlrocaucmic 0.81283, chxlrocaucmac 0.77379, 17.64 secs\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_vqa.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_001640_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.5,0.1,0.08,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --epochs 40 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 4 \\\n",
    "        --iters-to-accumulate 2 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"warmup+decay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-and-decay-args \"1e-6,8,1e-4,32,1e-6\" \\\n",
    "        --use-mimiccxr \\\n",
    "        --use-iuxray \\\n",
    "        --use-chexpert \\\n",
    "        --use-cxr14 \\\n",
    "        --use-vinbig \\\n",
    "        --use-padchest \\\n",
    "        --mimiccxr-include-chexpert-mode \\\n",
    "        --iuxray-include-chexpert-mode \\\n",
    "        --chexpert-mode \"vqa\" \\\n",
    "        --vinbig-training-data 'all' \\\n",
    "        --mimiccxr-weight 1.0 \\\n",
    "        --mimiccxr-weight-chexpert-mode 0.8 \\\n",
    "        --iuxray-weight 0 \\\n",
    "        --iuxray-weight-chexpert-mode 0 \\\n",
    "        --chexpert-weight 0 \\\n",
    "        --cxr14-weight 0 \\\n",
    "        --vinbig-weight 0 \\\n",
    "        --padchest-weight 0 \\\n",
    "        --padchest-train-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/train_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-val-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/val_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-test-study-ids-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest/test_study_ids_20221226_161248.txt\" \\\n",
    "        --padchest-training-data-mode \"all\" \\\n",
    "        --mimiccxr-qa-adapted-reports-filename \"qa_adapted_reports__20220904_095810.json\" \\\n",
    "        --iuxray-qa-adapted-reports-filename \"qa_adapted_reports__20220904_091601.json\" \\\n",
    "        --classify-orientation \\\n",
    "        --classify-chexpert \\\n",
    "        --mimiccxr-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113605.pkl\" \\\n",
    "        --iuxray-chexpert-labels-filename \"chexpert_labels_per_report__20220904_113427.pkl\" \\\n",
    "        --classify-questions \\\n",
    "        --n-questions 97 \\\n",
    "        --mimiccxr-question-labels-filename \"question_labels_per_report__20220904_105753.pkl\" \\\n",
    "        --iuxray-question-labels-filename \"question_labels_per_report__20220904_105752.pkl\" \\\n",
    "        --mimiccxr-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210415.pkl\" \\\n",
    "        --iuxray-balanced-metadata-filename \"balanced_dataloading_metadata__20220918_210029.pkl\" \\\n",
    "        --balanced-dataloading \\\n",
    "        --medical-tokenization \\\n",
    "        --medical-terms-frequency-filename \"medical_terms_frequency__20220918_184255.pkl\" \\\n",
    "        --raw-image-encoding \"vitmodel-huggingface\" \\\n",
    "        --huggingface-model-name \"CenIA/vit-mae-base-finetuned-mimic\" \\\n",
    "        --image-size 224 224 \\\n",
    "        --image-local-feat-size 768 \\\n",
    "        --question-encoding \"one-hot\" \\\n",
    "        --answer-decoding \"transformer\" \\\n",
    "        --binary-loss-name \"wbce-c\" \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
