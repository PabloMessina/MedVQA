{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iuxray reports from /mnt/workspace/iu-x-ray/dataset/reports/reports.min.json\n",
      "Number of sentences: 8617\n",
      "Shortest sentence: KUB.\n",
      "Longest sentence: The infrahilar pulmonary markings appear slightly prominent bilaterally, which XXXX represents XXXX appearance for the patient but difficult to completely exclude some reactive airway/bronchitic changes in the absence of comparison radiographs.. No airspace consolidation or lobar atelectasis.\n",
      "Loading CheXpert labeler\n",
      "Loading CheXbert labeler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8617it [00:00, 18598.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RadGraph labeler\n"
     ]
    }
   ],
   "source": [
    "from medvqa.datasets.iuxray import IUXRAY_REPORTS_MIN_JSON_PATH\n",
    "from medvqa.utils.files import (\n",
    "    get_checkpoint_folder_path,\n",
    "    get_results_folder_path,\n",
    "    load_json, load_pickle,\n",
    "    save_pickle,\n",
    ")\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "def _load_iuxray_sentences():\n",
    "    print(f'Loading iuxray reports from {IUXRAY_REPORTS_MIN_JSON_PATH}')\n",
    "    reports = load_json(IUXRAY_REPORTS_MIN_JSON_PATH)\n",
    "    sentences = set()\n",
    "    for r in reports.values():\n",
    "        findings = r['findings']\n",
    "        impression = r['impression']\n",
    "        for x in (findings, impression):\n",
    "            if x:\n",
    "                for s in sent_tokenize(x):\n",
    "                    s = ' '.join(s.split()) # Remove extra spaces\n",
    "                    sentences.add(s)\n",
    "    sentences = list(sentences)\n",
    "    sentences.sort(key=lambda x: (len(x), x)) # Sort by length and then alphabetically\n",
    "    sentences = [s for s in sentences if any(c.isalpha() for c in s)] # Remove sentences without any alphabetic character\n",
    "    print(f'Number of sentences: {len(sentences)}')\n",
    "    print(f'Shortest sentence: {sentences[0]}')\n",
    "    print(f'Longest sentence: {sentences[-1]}')\n",
    "    return sentences\n",
    "\n",
    "sentences = _load_iuxray_sentences()\n",
    "\n",
    "print('Loading CheXpert labeler')\n",
    "from medvqa.metrics.medical.chexpert import ChexpertLabeler\n",
    "chexpert_labeler = ChexpertLabeler()\n",
    "chexpert_labels = chexpert_labeler.get_labels(sentences, update_cache_on_disk=True)\n",
    "\n",
    "print('Loading CheXbert labeler')\n",
    "from medvqa.metrics.medical.chexbert import CheXbertLabeler\n",
    "chexbert_labeler = CheXbertLabeler()\n",
    "chexbert_labels = chexbert_labeler.get_labels(sentences, update_cache_on_disk=True)\n",
    "\n",
    "print('Loading RadGraph labeler')\n",
    "from medvqa.metrics.medical.radgraph import RadGraphLabeler\n",
    "radgraph_labeler = RadGraphLabeler()\n",
    "radgraph_labels = radgraph_labeler.get_labels(sentences, update_cache_on_disk=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from medvqa.utils.metrics import jaccard_between_dicts\n",
    "\n",
    "i = 3001\n",
    "\n",
    "relevant_sentences = []\n",
    "if len(radgraph_labels[i]) > 0:\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            js = jaccard_between_dicts(radgraph_labels[i], radgraph_labels[j])\n",
    "            if js >= 0.4 or ((np.all(chexpert_labels[i] == chexpert_labels[j]) or \\\n",
    "                np.all(chexbert_labels[i] == chexbert_labels[j])) and js >= 0.2):\n",
    "                relevant_sentences.append(j)\n",
    "len(relevant_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal degenerative disease thoracic spine\n",
      "\n",
      "Thoracic spine.\n",
      "Degenerative spine.\n",
      "DISH of the thoracic spine.\n",
      "Degenerative changes spine.\n",
      "Minimal thoracic spondylosis.\n",
      "Degenerative changes the spine.\n",
      "Degenerative change of the spine.\n",
      "Degenerative changes in the spine.\n",
      "Degenerative changes of the spine.\n",
      "Scattered thoracic spine spurring.\n",
      "Degenerative changes of the spine..\n",
      "Degenerative changes thoracic spine.\n",
      "Levoscoliosis of the thoracic spine.\n",
      "Degenerative changes of the the spine.\n",
      "Dextroscoliosis of the thoracic spine.\n",
      "degenerative changes within the spine.\n",
      "Degenerative changes are present spine.\n",
      "Degenerative changes of thoracic spine.\n",
      "Degenerative disease of thoracic spine.\n",
      "Mild degenerative changes in the spine.\n",
      "Mild degenerative changes of the spine.\n",
      "Mild thoracic spine degenerative change\n",
      "Degenerative changes noted in the spine.\n",
      "Degenerative spurring of thoracic spine.\n",
      "Mild degenerative change thoracic spine.\n",
      "Mild thoracic spine degenerative change.\n",
      "No XXXX fractures of the thoracic spine.\n",
      "There degenerative changes of the spine.\n",
      "Mild degenerative changes thoracic spine.\n",
      "Mild thoracic spine degenerative changes.\n",
      "Stable degenerative changes in the spine.\n",
      "Stable degenerative changes of the spine.\n",
      "Degenerative changes in the thoracic spine\n",
      "Minimal osteophytes of the thoracic spine.\n",
      "Anterior osteophytes of the thoracic spine.\n",
      "Degenerative changes are seen in the spine.\n",
      "Degenerative changes in the thoracic spine.\n",
      "Degenerative changes of the thoracic spine.\n",
      "Degenerative spurring of the thoracic spine\n",
      "Degenerative this disease within the spine.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[i])\n",
    "print()\n",
    "for j in range(min(40, len(relevant_sentences))):\n",
    "    print(sentences[relevant_sentences[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8617, 14), (8617, 14))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_labels.shape, chexbert_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(11, 652562049788717786): 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radgraph_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.eval_fact_embedding_on_ranking import _load_mimiccxr_radiologist_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = _load_mimiccxr_radiologist_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(a, b):\n",
    "    for x, y in zip(a, b):\n",
    "        if x == -2:\n",
    "            continue\n",
    "        if x != y:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recurrent right lower lobe patchy airspace opacity , suggestive of waxing and waning atelectasis .\n",
      "\n",
      "band of atelectasis crossing the left hilus has been present for several days . 0.8571428571428571 1\n",
      "lungs are clear except for minimal patchy atelectasis in the right infrahilar region . 0.8571428571428571 1\n",
      "lungs are clear except for minimal lingular atelectasis or scar . 0.8571428571428571 1\n",
      "left lung is clear except for minor linear atelectasis in the left mid and lower lung regions . 0.8571428571428571 1\n",
      "lungs are clear except for linear atelectasis at the lung bases , left greater than right . 0.8571428571428571 1\n",
      "aside from mild atelectasis at the right base , lungs are clear . 0.8571428571428571 1\n",
      "aside from atelectasis in the right base the lungs are clear . 0.8571428571428571 1\n",
      "aside from atelectasis , left lung is grossly clear . 0.8571428571428571 1\n",
      "no substantial atelectasis except for the retrocardiac lung area . 0.8571428571428571 1\n",
      "left lung is clear aside from minimal left basal atelectasis . 0.8571428571428571 1\n",
      "the mid and upper zones are grossly clear except for some right mid zone atelectasis . 0.8571428571428571 1\n",
      "there is bilateral basal atelectasis , but overall improved since the prior study . 0.8571428571428571 1\n",
      "bilateral lower lobe atelectasis has improved . 0.8571428571428571 1\n",
      "there is increasing bibasilar atelectasis . 0.8571428571428571 1\n",
      "right basal linear atelectasis . 0.8571428571428571 1\n",
      "a mild increase in atelectatic lung regions at the right lung bases might be present . 0.8571428571428571 1\n",
      "left lower lobe opacities consistent with a large area of atelectasis and small effusion are unchanged . 0.8571428571428571 1\n",
      "otherwise , there has been little change in the appearance of the chest since the recent study of a few hours earlier , except for slight worsening of atelectasis in the left retrocardiac region . 0.8571428571428571 1\n",
      "worsening left lower lobe atelectasis . 0.8571428571428571 1\n",
      "overall appearance of the chest is unchanged except for development of minimal linear bibasilar atelectasis . 0.8571428571428571 1\n",
      "interval development of focal atelectasis in the retrocardiac region . 0.8571428571428571 1\n",
      "lungs are essentially clear with bibasal atelectasis . 0.8571428571428571 1\n",
      "lungs are clear except for linear atelectasis the left base . 0.8571428571428571 1\n",
      "new large left lower lobe atelectasis . 0.8571428571428571 1\n",
      "as compared to the previous radiograph , a minimal atelectasis at the right lung bases has cleared . 0.8571428571428571 1\n",
      "residual opacification at the left base is consistent with pleural fluid , atelectatic changes , and possible mild re expansion edema . 0.7142857142857143 1\n",
      "there is increasing opacification at the left base , worrisome for atelectasis and effusion . 0.8571428571428571 1\n",
      "in comparison with the study of xxxx , there is increased opacification at both bases with poor definition of the hemidiaphragms , consistent with bilateral pleural effusions and compressive basilar atelectasis . 0.8571428571428571 1\n",
      "bibasilar opacities likely reflect mild chf . 0.8571428571428571 1\n",
      "the lungs are essentially clear except for linear atelectasis in the left mid lower lung . 0.8571428571428571 1\n",
      "right lung grossly clear except for atelectasis at right lung base . 0.8571428571428571 1\n",
      "lungs are essentially clear except for minimal atelectasis at the left lower lung , unchanged since xxxx . 0.8571428571428571 1\n",
      "a platelike atelectasis and an opacity in the right lung , paralleling the minor fissure , has almost completely resolved . 1.0 1\n",
      "lungs are grossly clear aside from mild left basal atelectasis , not unexpected . 0.8571428571428571 1\n",
      "lungs are clear except for linear bibasilar atelectasis . 0.8571428571428571 1\n",
      "lungs overall clear except for minimal left basal atelectasis . 0.8571428571428571 1\n",
      "aside from linear atelectasis at the base , right lung is clear . 0.8571428571428571 1\n",
      "mild left basal atelectasis , otherwise normal . 0.8571428571428571 1\n",
      "aside from mild bibasilar atelectasis or linear scarring lungs are clear . 0.8571428571428571 1\n",
      "left lung is essentially clear except for left basal atelectasis . 0.8571428571428571 1\n",
      "aside from minimal atelectasis in the left lower lobe and left upper lobe , the lungs are clear . 0.8571428571428571 1\n",
      "aside from mild left lower lobe atelectasis , lungs are grossly clear . 0.8571428571428571 1\n",
      "aside from linear atelectasis at the base , the left lung is clear . 0.8571428571428571 1\n",
      "the lungs are clear aside from minimal atelectasis in the left base . 0.8571428571428571 1\n",
      "the left lung is essentially clear except for minimal atelectatic changes . 0.8571428571428571 1\n",
      "lungs are overall clear except for right basal atelectasis . 0.8571428571428571 1\n",
      "residual opacification at the left base with poor definition of the hemidiaphragm is consistent with layering effusion and atelectasis . 0.8571428571428571 1\n",
      "however , atelectasis at the left lung base has developed . 0.8571428571428571 1\n",
      "a linear focus of atelectasis in the mid lung region on the left is similar to the prior study . 0.8571428571428571 1\n",
      "atelectasis at both lung bases are present . 0.8571428571428571 1\n",
      "recurrent right lower lobe patchy airspace opacity , suggestive of waxing and waning atelectasis . 1.0 1\n",
      "increase of the pre existing retrocardiac atelectasis with substantial volume loss of the left hemithorax and leftward displacement of the mediastinum . 0.8571428571428571 1\n",
      "bibasilar opacities reflecting lower lung atelectasis have minimally worsened . 1.0 1\n",
      "continued bibasilar opacification with atelectatic changes , more prominent on the left , where there is also retrocardiac opacification consistent with volume loss in the lower lobe . 0.7142857142857143 1\n",
      "retrocardiac consolidation and patchy opacity at the right base most likely represent partial lower lobe compressive atelectasis . 0.8571428571428571 1\n",
      "there are atelectasis in the right lower lobe . 0.8571428571428571 1\n",
      "right lung nodules , masslike opacity in the left hemi thorax , left lower lobe atelectasis and small left effusion were better characterized in prior ct . 0.8571428571428571 1\n",
      "persistent opacification at the lung bases is probably a combination of residual edema and concurrent lower lobe atelectasis . 0.8571428571428571 1\n",
      "basal areas of atelectasis . 0.8571428571428571 1\n",
      "left retrocardiac consolidation is noted associated with minimal of vessel effusion . 0.5 0\n",
      "there is moderate pulmonary edema which has worsened slightly . 0.5714285714285714 0\n",
      "increased patchy opacities in the lung bases may reflect progression of underlying chronic interstitial lung disease , but superimposed atelectasis or infection cannot be completely excluded . 0.8571428571428571 0\n",
      "right upper lobe new consolidation is compatible with atelectasis with possibly superimposed aspiration . 0.6428571428571429 0\n",
      "whether this is atelectasis alone or concurrent pneumonia is radiographically indeterminate . 0.7142857142857143 0\n",
      "there is interval increase in retrocardiac density , likely reflecting a combination of layering pleural fluid and underlying collapse and / or consolidation . 0.5 0\n",
      "moderate pulmonary edema appears slightly improved since the xxxx examination . 0.5714285714285714 0\n",
      "same can be said for apparent consolidation at the base of the left lung , which , alternatively , could be due to atelectasis . 0.6428571428571429 0\n",
      "diffuse opacification and volume loss of the right lung is likely due to a combination of post surgical changes , the known hilar mass , and possible worsening atelectasis . 0.7857142857142857 0\n",
      "retrocardiac consolidation , may represent atelectasis or infection in the appropriate clinical setting . 0.5714285714285714 0\n",
      "a left lower lobe opacity is better delineated on the subsequent ct of the chest as an area of probable rounded atelectasis . 0.9285714285714286 0\n",
      "ap chest compared to xxxx left heart border is consistently obscured on prior chest radiographs , probably by atelectasis in the lingula which persists . 0.6428571428571429 0\n",
      "findings indicating early congestive heart failure . 0.5714285714285714 0\n",
      "severe cardiomegaly with small bilateral pleural effusions . 0.42857142857142855 0\n",
      "the effusions are somewhat improved since the prior chest xray . 0.5714285714285714 0\n",
      "a large mass like opacity sub cm in the right hilus traversed by air bronchograms could be atelectasis , particularly if the patient has had radiation . 0.8571428571428571 0\n",
      "subtle increase in opacity over the inferior spine on the lateral view , not substantiated on the frontal view , felt to unlikely represent consolidation , possibly atelectasis vs artifact . 0.6428571428571429 0\n",
      "right sided effusion is resolved . 0.5714285714285714 0\n",
      "there is again a large right pleural effusion with compressive basilar atelectasis as well as volume loss in the left lower lobe with smaller effusion . 0.42857142857142855 0\n",
      "although this most likely represents atelectasis and effusion , the possibility of supervening pneumonia would have to be considered in the appropriate clinical setting . 0.42857142857142855 0\n",
      "unchanged appearance of substantial left sided pleural effusion . 0.5714285714285714 0\n",
      "in addition to severe bibasilar atelectasis and small to moderate pleural effusions , there is now consolidation in the right lower lung , probably pneumonia . 0.5714285714285714 0\n",
      "there is again seen cardiomegaly , bilateral pleural effusions left greater than right and left retrocardiac opacity . 0.5 0\n",
      "pa and lateral chest compared to xxxx moderate right middle and lower lobe atelectasis and moderate right pleural effusion , partially fissural , not appreciably changed since xxxx . 0.5714285714285714 0\n",
      "there is a small left pleural effusion has increased compared to prior . 0.5714285714285714 0\n",
      "there are bilateral small pleural effusions with compressive atelectasis at the bases . 0.5714285714285714 0\n",
      "there are layering bilateral effusions with associated bibasilar airspace disease , left greater the right tube which is also unchanged . 0.5714285714285714 0\n",
      "small bilateral pleural effusions have significantly improved since xxxx . 0.5714285714285714 0\n",
      "improving patchy and linear opacities at both lung bases favor atelectasis . 0.9285714285714286 0\n",
      "increase in bilateral pleural effusion now small to moderate in size with bibasilar right greater than left opacities which are likely atelectatic however infection cannot be excluded given the clinical circumstance . 0.6428571428571429 0\n",
      "bibasilar opacities consistent with collapse and / or consolidation appear similar to xxxx at NUMBER p . 0.7142857142857143 0\n",
      "there is a left retrocardiac opacity which may be due to atelectasis or developing infiltrate . 0.8571428571428571 0\n",
      "patchy bilateral consolidation could represent either subsegmental atelectasis or the developing aspiration pneumonia . 0.5714285714285714 0\n",
      "left lower lobe opacification has been persistent since xxxx , presumably atelectasis . 0.8571428571428571 0\n",
      "differential considerations include aspiration , although findings are not definitely changed , versus atelectasis or pneumonia . 0.6428571428571429 0\n",
      "perihilar opacification in both lungs could be atelectasis or pneumonia , worsened on the right and improved on the left since xxxx . 0.7857142857142857 0\n",
      "left lower lobe opacity could reflect pneumonia or atelectasis depending on the clinical setting . 0.7857142857142857 0\n",
      "there is increasing airspace opacity in both lungs which may represent worsening consolidation related to atelectasis or pneumonia , although superimposed pulmonary edema should also be considered . 0.5714285714285714 0\n",
      "this could be due to atelectasis alone , but pneumonia cannot be excluded radiographically . 0.7142857142857143 0\n",
      "hazy right basilar opacity seen only on the frontal view may reflect overlying soft tissue as there is no correlate on the lateral view , though atelectasis or infection is not completely excluded . 0.7857142857142857 0\n",
      "new bibasilar opacities in the setting of very shallow inspiration , favor atelectasis , consider pneumonitis in the appropriate clinical setting . 0.8571428571428571 0\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "print(sentences[idx])\n",
    "sorted_idxs = np.argsort([score(labels[idx], x) or score(x, labels[idx]) for x in labels])[::-1]\n",
    "print()\n",
    "for i in range(100):\n",
    "    j = sorted_idxs[i]\n",
    "    print(sentences[j],  np.mean(labels[j] == labels[idx]), score(labels[idx], labels[j]) or score(labels[j], labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import medvqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'medvqa.eval_fact_embedding_on_ranking' from '/home/pamessina/medvqa/medvqa/eval_fact_embedding_on_ranking.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(medvqa.eval_fact_embedding_on_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.eval_fact_embedding_on_ranking import SentenceRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = SentenceRanker('mimiccxr_rad_annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1165/1165 [00:00<00:00, 401905.26it/s]\n"
     ]
    }
   ],
   "source": [
    "query_idx = 11\n",
    "output = sr.rank_sentences(query_idx, model_name='microsoft/BiomedVLP-CXR-BERT-specialized',\n",
    "                           checkpoint_folder_path='/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)',\n",
    "                           top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1165/1165 [00:00<00:00, 434111.95it/s]\n"
     ]
    }
   ],
   "source": [
    "query_idx = 6\n",
    "output = sr.rank_sentences(query_idx, model_name='emilyalsentzer/Bio_ClinicalBERT', average_token_embeddings=True,\n",
    "                           top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recurrent right lower lobe patchy airspace opacity , suggestive of waxing and waning atelectasis .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['recurrent right lower lobe patchy airspace opacity , suggestive of waxing and waning atelectasis .',\n",
       "  'pneumonia or atelectasis at the right lung base .',\n",
       "  'there is patchy opacity at the right base which could reflect compressive atelectasis .',\n",
       "  'right lower lobe collapse is persistent .',\n",
       "  'consolidation continues to progress in the right lower lobe .',\n",
       "  'patchy opacity at the right base may represent partial lower lobe atelectasis , although pneumonia or aspiration cannot be entirely excluded .',\n",
       "  'subtle opacification at the right lung base , which may represent atelectasis , however an early developing pneumonia is a consideration .',\n",
       "  'subtle opacity at the base of the right lung could represent atelectasis however infection should be considered in the appropriate clinical setting .',\n",
       "  'focal opacity at the right lung base has increased , either an atelectasis or consolidation .',\n",
       "  'subtle patchy right base opacity could be due to aspiration , infection or atelectasis .',\n",
       "  'increased opacities at the right lung base may reflect atelectasis or pneumonia in the proper clinical context .',\n",
       "  'there are atelectasis in the right lower lobe .',\n",
       "  'there is persistent atelectasis or consolidation in the right lower lobe .',\n",
       "  'a mild increase in atelectatic lung regions at the right lung bases might be present .',\n",
       "  'the only focal pulmonary abnormality today consolidation at the right lung base which could be either pneumonia or atelectasis , increased since xxxx .',\n",
       "  'would be difficult to entirely exclude right basilar consolidation although there is not evidence of such on the lateral view .',\n",
       "  'slight worsening of the right lower lobe atelectasis is noted on the current radiograph that might reflect interval increase in pleural effusion or additional compression of the right lower lobe airways .',\n",
       "  'minimal right lower lobe opacity , possibly atelectasis but infection cannot be excluded .',\n",
       "  'increased patchy opacification in the right lung base could reflect worsening atelectasis however infection is not excluded in the correct clinical setting .',\n",
       "  'there are minimal opacities in the right lower lobe , could be atelectasis , but superimposed infection / aspiration cannot be excluded and attention on followup studies is recommended .',\n",
       "  'linear density in the right infrahilar region may represent atelectasis or effusion in the right major fissure .',\n",
       "  'right basal consolidations appear to be increased and might potentially reflect increasing atelectasis , but infectious process in the area cannot be excluded .',\n",
       "  'underlying right base consolidation is not excluded .',\n",
       "  'subtle patchy right lower lobe opacity may relate to atelectasis and overlying vascular structures , but overlying consolidation due to pneumonia is not excluded in the appropriate clinical setting .',\n",
       "  'increased right pleural fluid obscuring a large right lower lobe consolidation .',\n",
       "  'right basilar opacity potentially due to layering effusion with atelectasis , infection not excluded .',\n",
       "  'moderate right sided pleural effusion with increased right basilar opacity , likely atelectasis , though infection is not excluded .',\n",
       "  'there is increasing opacification of the partially collapsed right lung .',\n",
       "  'persistent right basilar atelectasis and suspected small right pleural effusion .',\n",
       "  'right basal consolidation which persisted following clearing of right lower lobe collapse after xxxx has subsequently improved , though not cleared .',\n",
       "  'right basilar opacity silhouetting the hemidiaphragm suggestive of effusion with underlying atelectasis and possible consolidation .',\n",
       "  'interval increase in right pleural effusion with complete atelectasis of the right middle and lower lobes , raising concern for bronchial obstruction .',\n",
       "  'there is a right sided pleural effusion and some right basilar consolidation .',\n",
       "  'moderate right pleural effusion and right basal consolidation are new .',\n",
       "  'worsening right pleural effusion and increasing consolidation in the right lower lung raises concern for pneumonia , aspiration versus atelectasis .',\n",
       "  'relative opacity at the medial right lung base may be due to overlapping vascular structures , although consolidation is not excluded in the appropriate clinical setting .',\n",
       "  'increasing opacification at the right base medially with silhouetting of the hemidiaphragm is worrisome for a right middle lobe consolidation .',\n",
       "  'interval development of moderate right effusion with possible loculation and adjacent atelectasis and / or consolidation .',\n",
       "  'new small right sided pleural effusion with adjacent atelectasis .',\n",
       "  'large opacity projecting over the right mid to lower hemithorax may represent combination of pleural effusion and atelectasis , underlying consolidation is not excluded .',\n",
       "  'increased interstitial markings throughout the lungs with more confluent consolidation at the right lung base .',\n",
       "  'in comparison to xxxx chest radiograph , a moderate sized right pleural effusion has slightly increased in size with associated worsening right basilar atelectasis and or consolidation .',\n",
       "  'residual focal consolidation in right lower lung is worrisome for pneumonia .',\n",
       "  'consolidation involving the right lung base may be secondary to pneumonia .',\n",
       "  'more coalescent area medially on the right could well represent a developing consolidation .',\n",
       "  'hazy right basilar opacity seen only on the frontal view may reflect overlying soft tissue as there is no correlate on the lateral view , though atelectasis or infection is not completely excluded .',\n",
       "  'right lower lobe consolidation better seen on subsequent chest ct .',\n",
       "  'right lung base is partially obscured by the pleural fluid .',\n",
       "  'increased right mid and low lung opacity could represent consolidation or effusion .',\n",
       "  'new consolidation in the right middle lobe is consistent with pneumonia .',\n",
       "  'complete opacification of the right lower lung due to a combination of effusion and consolidation .',\n",
       "  'worsened right lung opacity , likely secondary to pleural effusion more or less segmental atelectasis .',\n",
       "  'right pleural effusion and right lower lobe opacity are noted and although the effusion appears to be grossly unchanged , the extent of the right basal consolidation potentially has increased and might reflect pleural effusion .',\n",
       "  'new consolidation developing in the right lung .',\n",
       "  'increased patchy opacities in the lung bases may reflect progression of underlying chronic interstitial lung disease , but superimposed atelectasis or infection cannot be completely excluded .',\n",
       "  'right pleural effusion is redemonstrated , associated with right lower lobe consolidation that appears to be slightly increased since the prior study and might reflect interval development of right lower lobe pneumonia .',\n",
       "  'small amount of pleural effusion cannot be excluded in particular on the right although it might represent atelectasis due to elevated right hemidiaphragm .',\n",
       "  'bibasilar opacities reflecting lower lung atelectasis have minimally worsened .',\n",
       "  'posterior opacity is noted , and might represent part of the atelectasis in combination with elevated right hemidiaphragm .',\n",
       "  'consolidation or collapse of the superior segment of the right lower lobe is probably still present , explaining the definition of the lowered major fissure medially .',\n",
       "  'right base opacity is concerning for consolidation possibly due to infection , underlying neoplastic process is not excluded either .',\n",
       "  'progressive opacification in the right lower lung could be fissural pleural fluid , but raises serious concern for pneumonia in a solitary aerated right lung .',\n",
       "  'right basal linear atelectasis .',\n",
       "  'low lung volumes with atelectasis at the right lung bases .',\n",
       "  'right basilar consolidation concerning for pneumonia and / or aspiration .',\n",
       "  'probable small right pleural effusion and right basal atelectasis .',\n",
       "  'a large mass like opacity sub cm in the right hilus traversed by air bronchograms could be atelectasis , particularly if the patient has had radiation .',\n",
       "  'there is increasing bibasilar atelectasis .',\n",
       "  'this may reflect atelectasis and dependent edema , but coexisting infection should be considered in the appropriate clinical setting .',\n",
       "  'as compared to the previous radiograph , there is a substantial increase in extent of the right pleural effusion with subsequent areas of atelectasis in the right lung .',\n",
       "  'right upper lobe new consolidation is compatible with atelectasis with possibly superimposed aspiration .',\n",
       "  'worsening consolidative opacity in the right infrahilar region may potentially represent an evolving aspiration pneumonia in the appropriate clinical setting .',\n",
       "  'this opacities could be atelectasis and or pneumonia .',\n",
       "  'bibasilar opacities likely reflect areas of atelectasis , although aspiration or pneumonia should also be considered .',\n",
       "  'superimposed atelectasis or pneumonia would be difficult to exclude .',\n",
       "  'right lower opacity is unchanged , is a combination of a pneumonic consolidation .',\n",
       "  'nodular opacities at the right lung base may be due to a combination of atelectasis and overlying rib shadows , but metastasis or even pneumonia are also possible .',\n",
       "  'this likely represents atelectasis and / or pneumonia in the appropriate clinical setting .',\n",
       "  'this could merely reflect atelectasis , though in the appropriate clinical setting superimposed pneumonia could be considered .',\n",
       "  'patchy bilateral consolidation could represent either subsegmental atelectasis or the developing aspiration pneumonia .',\n",
       "  'worsening superimposed opacities at the lung bases could be due to atelectasis , aspiration or infectious consolidation .',\n",
       "  'right pleural effusion and a adjacent consolidation is not excluded .',\n",
       "  'moderate pulmonary edema has increased .',\n",
       "  'bibasilar patchy airspace opacity could reflect atelectasis but infection or aspiration are not excluded .',\n",
       "  'vague increased density in the bilateral lower lung zones may represent micro atelectasis ( secondary to low lung volumes ) or early airspace consolidation .',\n",
       "  'more dense consolidation in the right lower lungs could be confluent edema or developing pneumonia .',\n",
       "  'although possibly representing bibasilar atelectasis , coexisting pneumonia should be considered in the appropriate clinical setting .',\n",
       "  'severe consolidation , right upper lobe , longstanding .',\n",
       "  'mild interstitial edema has increased , superimposed to known mild chronic interstitial lung disease .',\n",
       "  'increased bibasilar airspace opacities may be due to the edema , but pneumonia cannot be excluded in the appropriate clinical setting .',\n",
       "  'right lower lobe collapse has improved , but the lower lobe is still severely atelectatic and / or consolidated .',\n",
       "  'right upper lobe consolidation with cavitation .',\n",
       "  'lungs are overall clear except for right basal atelectasis .',\n",
       "  'minimally increased opacity at the lung bases which likely reflects atelectasis .',\n",
       "  'lungs are clear except for minimal patchy atelectasis in the right infrahilar region .',\n",
       "  'bibasilar atelectasis versus aspiration .',\n",
       "  'bibasilar opacities , likely atelectasis but pneumonia is not excluded .',\n",
       "  'interval worsening pulmonary edema .',\n",
       "  'possible mild increased pulmonary vascular prominence and possible tiny right pleural effusion .',\n",
       "  'right upper lobe and likely right middle lobe consolidation compatible with pneumonia in the proper clinical setting .'],\n",
       " [array([ 1, -2, -2, -2,  1, -2, -2,  1, -2, -2, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -2, -2, -2, -2, -2, -1, -2, -2, -2, -2, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -2, -2, -2, -2,  1, -1, -2, -2, -2, -2, -2,  1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-1, -2, -1, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -1, -2, -2, -2, -2, -1, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-1, -2,  1, -2, -2, -2, -2, -1, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  0, -2, -2, -2, -2, -2, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2,  1, -2,  1, -2, -2, -2, -2, -1,  1], dtype=int8),\n",
       "  array([-1, -2, -2, -2,  1, -2, -1, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-1, -2, -2, -2,  1, -1, -2, -1, -2, -2, -2, -2, -1, -2], dtype=int8),\n",
       "  array([ 1, -2,  1, -2, -2, -2, -2, -1, -2,  1, -2, -2, -2, -1], dtype=int8),\n",
       "  array([-2, -2, -1, -2, -2, -2, -2, -2, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -1, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2,  1, -2, -2, -2, -1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-1, -2, -2, -2,  1, -1, -2, -1, -2, -2, -2,  1, -1, -2], dtype=int8),\n",
       "  array([ 1, -2, -1, -2, -2,  1, -2, -1, -2, -2, -2,  1,  1, -2], dtype=int8),\n",
       "  array([-2, -2, -2, -2,  1, -2,  1, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2,  1, -2,  1, -2, -2, -2, -2, -1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2,  1, -2, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -1, -2,  1,  1, -2, -1, -2, -1, -2,  1, -1, -2], dtype=int8),\n",
       "  array([ 1, -2,  1, -2, -2,  1,  1,  1, -2, -2, -2, -2,  1,  1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2,  1, -2, -2, -2,  1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2,  1, -2, -2, -2,  1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-1, -2,  1, -2, -2,  1, -2, -1, -2,  1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-2, -2, -1, -2,  1, -2, -2, -2, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2,  1, -2, -2, -2, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -1, -2, -2,  1, -2, -1, -2, -1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2,  1, -2,  1, -2, -2, -2, -2,  1, -2], dtype=int8),\n",
       "  array([ 1, -2, -1, -2,  1,  1, -2, -1, -2, -1, -2,  1, -1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2,  1, -2, -2, -2, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2,  1, -2, -2,  1, -2, -1, -2, -1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2,  1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -1, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -1, -2,  1, -2, -2, -2, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-2, -2, -1, -2,  1, -1, -2, -2, -2, -1, -2,  1, -1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2,  1, -2,  1], dtype=int8),\n",
       "  array([-2, -2,  1, -2,  1,  1, -2, -2, -2,  1, -2,  1,  1, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1,  1, -2, -1, -2, -2, -2,  1, -1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2,  1,  1, -2, -2, -2, -2, -2,  1, -1, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2,  1, -2, -2, -2,  1, -2, -2,  1,  1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -1,  1, -1, -2, -2, -2, -2, -1, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2,  1, -2, -2, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2,  1, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -1, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2,  1, -2, -2, -2, -2,  1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -1, -2, -2,  1, -2, -2, -2, -2, -2,  1, -1, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2,  1,  1, -2, -2, -2, -2, -2,  1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2,  1, -2, -1, -2, -2, -2, -2, -1, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2,  1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -1,  1, -2, -2, -2, -1, -2, -2, -1, -2, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2,  1, -2,  1, -2, -2, -2, -2,  1, -2], dtype=int8),\n",
       "  array([ 1, -2,  1, -2, -2, -2, -2,  1, -2,  1, -2, -2, -2, -1], dtype=int8),\n",
       "  array([-2, -2, -2, -2,  1, -2, -2, -2, -2,  1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -2, -2, -2, -2, -2, -1, -2, -2, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -1, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-1, -2, -1, -2, -2, -2, -2, -1, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2, -1, -2, -1, -2, -1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2, -1, -2, -1, -2, -1, -2, -2], dtype=int8),\n",
       "  array([-1, -2,  1, -2, -2, -2, -2, -1, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -1, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2,  1, -2, -2, -2,  1, -2, -2,  1, -2], dtype=int8),\n",
       "  array([-2, -2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -2, -2,  1, -2, -1], dtype=int8),\n",
       "  array([-1, -2, -1, -2,  1, -2, -2, -1, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -1, -2, -2, -1, -2, -2,  1, -1, -2, -2, -1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2, -1, -2, -1, -2, -1, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -2,  1,  1, -2, -2, -2, -2, -2,  1, -2, -2,  1], dtype=int8),\n",
       "  array([-2, -2, -1,  1,  1, -2, -2, -2, -2, -2, -1,  1, -2, -1], dtype=int8),\n",
       "  array([ 1, -2,  1, -2, -2, -2,  1, -1, -2, -1, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2,  1], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([-1, -2, -2, -2, -2, -2, -1, -1, -2, -2, -2, -2, -2, -2], dtype=int8),\n",
       "  array([ 1, -2, -2, -2,  1, -2, -2, -1, -2, -1, -2,  1, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -2,  1, -2, -2, -2, -2, -2, -2,  1, -2, -2, -2], dtype=int8),\n",
       "  array([-2, -2, -2, -2, -2,  1,  1, -2, -2, -2, -2, -2, -1, -1], dtype=int8),\n",
       "  array([-2, -2,  1, -2, -2, -2, -2, -2, -2, -1, -2, -1, -2, -2], dtype=int8)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sr.sentences[query_idx])\n",
    "print()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-CXR Radiologist Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-CXR-BERT-specialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=116,1396652957813721259).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 5315.63it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1145.26it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7021\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-BioViL-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-BioViL-T\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=104,2678825193822464594).pkl\n",
      "len(self.cache[\"hashes\"]) = 4451804\n",
      "self.cache[\"embeddings\"].shape = (4451804, 128)\n",
      "100%|██████████████████████████████████████| 1165/1165 [00:04<00:00, 236.70it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1161.96it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7097\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-BioViL-T\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: michiyasunaga/BioLinkBERT-large\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,40983794350539675).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 1024)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1517.76it/s]\n",
      "Embeddings shape: (1165, 1024)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1104.13it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.5205\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"michiyasunaga/BioLinkBERT-large\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: michiyasunaga/BioLinkBERT-large\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,1253761809285128054).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 1024)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1489.36it/s]\n",
      "Embeddings shape: (1165, 1024)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1112.89it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6087\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"michiyasunaga/BioLinkBERT-large\" \\\n",
    "--batch_size 100 \\\n",
    "--average_token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=137,1948119357925567498).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1819.72it/s]\n",
      "Embeddings shape: (1165, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1112.26it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.5853\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=162,1758876944325999998).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1819.70it/s]\n",
      "Embeddings shape: (1165, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1140.10it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6065\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\" \\\n",
    "--batch_size 100 \\\n",
    "--average_token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: emilyalsentzer/Bio_ClinicalBERT\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,1542209846559636901).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1776.79it/s]\n",
      "Embeddings shape: (1165, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1137.14it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.5197\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"emilyalsentzer/Bio_ClinicalBERT\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: emilyalsentzer/Bio_ClinicalBERT\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,412155249657523952).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 3205.03it/s]\n",
      "Embeddings shape: (1165, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1121.49it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6310\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"emilyalsentzer/Bio_ClinicalBERT\" \\\n",
    "--batch_size 100 \\\n",
    "--average_token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: CheXbert\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "100%|███████████████████████████████████████| 1165/1165 [00:13<00:00, 85.50it/s]\n",
      "Embeddings shape: (1165, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1125.10it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8698\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"CheXbert\" \\\n",
    "--device \"cuda\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=359,388447562913600091).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 4490.74it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1169.27it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7410\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=366,4246634492375333681).pkl\n",
      "len(self.cache[\"hashes\"]) = 134854\n",
      "self.cache[\"embeddings\"].shape = (134854, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 5391.96it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  5.44it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=366,4246634492375333681).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 232794.86it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1153.45it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6606\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,2492157991032224976).pkl\n",
      "len(self.cache[\"hashes\"]) = 134854\n",
      "self.cache[\"embeddings\"].shape = (134854, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 4315.76it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 223 keys, intersection has 211 keys, union has 223 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  5.36it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,2492157991032224976).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 262990.54it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1158.07it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7881\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,1308360022390228203).pkl\n",
      "len(self.cache[\"hashes\"]) = 8617\n",
      "self.cache[\"embeddings\"].shape = (8617, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 9423.09it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 223 keys, intersection has 211 keys, union has 223 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  4.92it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,1308360022390228203).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 371388.93it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1167.89it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7875\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+EC+NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,1493189425621868816).pkl\n",
      "len(self.cache[\"hashes\"]) = 134854\n",
      "self.cache[\"embeddings\"].shape = (134854, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 5449.10it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 215 keys, intersection has 211 keys, union has 215 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  5.42it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,1493189425621868816).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 222826.58it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1159.77it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6365\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=368,1866338409828607810).pkl\n",
      "len(self.cache[\"hashes\"]) = 134854\n",
      "self.cache[\"embeddings\"].shape = (134854, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 4499.87it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 216 keys, intersection has 211 keys, union has 216 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_size_embeddings.weight\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.bias\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  5.35it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=368,1866338409828607810).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 220156.08it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1163.19it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7161\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C+EC+NLI+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_26_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9386.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,141429923173682938).pkl\n",
      "len(self.cache[\"hashes\"]) = 103629\n",
      "self.cache[\"embeddings\"].shape = (103629, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 6083.98it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1114.13it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7396\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt']\n",
      "  0%|                                                  | 0/1165 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,3677907674814022869).pkl\n",
      "len(self.cache[\"hashes\"]) = 8617\n",
      "self.cache[\"embeddings\"].shape = (8617, 128)\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 9150.85it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 232 keys, intersection has 211 keys, union has 232 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  5.00it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,3677907674814022869).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 708271.37it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:00<00:00, 1167.26it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7529\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 533387.64it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 237 keys, intersection has 211 keys, union has 237 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.start_idx\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm3.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.embedding_table.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  4.98it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 781068.44it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1158.17it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6992\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C+EC+NLI+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: mimiccxr_radiologist_annotations\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading mimiccxr sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr_sentences_and_relevant.pkl\n",
      "len(sentences): 1165\n",
      "len(relevant_sentences): 1165\n",
      "checkpoint_names = ['checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt']\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 518612.20it/s]\n",
      "Computing embeddings for 1165 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 253 keys, intersection has 211 keys, union has 253 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm3.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm1.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  5.02it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=425,2776001221282427137).pkl\n",
      "100%|███████████████████████████████████| 1165/1165 [00:00<00:00, 753254.84it/s]\n",
      "Embeddings shape: (1165, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|█████████████████████████████████████| 1165/1165 [00:01<00:00, 1162.12it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7579\u001b[0m\n",
      "mean_relevant: 57.8080\n",
      "count: 1156 / 1165 (99.23%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"mimiccxr_radiologist_annotations\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IU X-ray Automatic Labelers (chexpert + chexbert + radgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-CXR-BERT-specialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray reports from /mnt/workspace/iu-x-ray/dataset/reports/reports.min.json\n",
      "Number of sentences: 8617\n",
      "Shortest sentence: KUB.\n",
      "Longest sentence: The infrahilar pulmonary markings appear slightly prominent bilaterally, which XXXX represents XXXX appearance for the patient but difficult to completely exclude some reactive airway/bronchitic changes in the absence of comparison radiographs.. No airspace consolidation or lobar atelectasis.\n",
      "Loading CheXpert labeler\n",
      "Loading CheXbert labeler\n",
      "8617it [00:00, 17841.73it/s]\n",
      "Loading RadGraph labeler\n",
      "100%|███████████████████████████████████████| 8617/8617 [03:07<00:00, 45.92it/s]\n",
      "Saving iuxray sentences and relevant sentences to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=116,1396652957813721259).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 74038.46it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:53<00:00, 162.32it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8515\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-BioViL-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-BioViL-T\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=104,2678825193822464594).pkl\n",
      "len(self.cache[\"hashes\"]) = 4451804\n",
      "self.cache[\"embeddings\"].shape = (4451804, 128)\n",
      "100%|█████████████████████████████████████| 8617/8617 [00:03<00:00, 2565.91it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:51<00:00, 168.34it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8658\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-BioViL-T\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: michiyasunaga/BioLinkBERT-large\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,40983794350539675).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 1024)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 26704.83it/s]\n",
      "Embeddings shape: (8617, 1024)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:58<00:00, 147.38it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.6601\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"michiyasunaga/BioLinkBERT-large\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: michiyasunaga/BioLinkBERT-large\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,1253761809285128054).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 1024)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 26889.74it/s]\n",
      "Embeddings shape: (8617, 1024)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:58<00:00, 147.44it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8621\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"michiyasunaga/BioLinkBERT-large\" \\\n",
    "--batch_size 100 \\\n",
    "--average_token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=137,1948119357925567498).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 32819.15it/s]\n",
      "Embeddings shape: (8617, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [01:00<00:00, 143.52it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7768\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=162,1758876944325999998).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 33578.34it/s]\n",
      "Embeddings shape: (8617, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:59<00:00, 143.83it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9076\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\" \\\n",
    "--batch_size 100 \\\n",
    "--average_token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT (cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: emilyalsentzer/Bio_ClinicalBERT\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=107,1542209846559636901).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 33897.08it/s]\n",
      "Embeddings shape: (8617, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [01:00<00:00, 143.41it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.5998\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"emilyalsentzer/Bio_ClinicalBERT\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT (tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: emilyalsentzer/Bio_ClinicalBERT\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,412155249657523952).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 768)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 32540.98it/s]\n",
      "Embeddings shape: (8617, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:54<00:00, 157.44it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9241\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"emilyalsentzer/Bio_ClinicalBERT\" \\\n",
    "--batch_size 100 \\\n",
    "--average_token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: CheXbert\n",
      "   device: cuda\n",
      "   batch_size: 32\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "100%|███████████████████████████████████████| 8617/8617 [01:34<00:00, 91.56it/s]\n",
      "Embeddings shape: (8617, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [01:00<00:00, 143.33it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9327\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"CheXbert\" \\\n",
    "--device \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=359,388447562913600091).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 72143.81it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:56<00:00, 153.57it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9149\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_1_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9444.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=366,4246634492375333681).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 70188.93it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [01:00<00:00, 142.96it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8074\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231003_001641_MIMIC-CXR(triplets+entcont)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,2492157991032224976).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 76619.62it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:56<00:00, 153.43it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9435\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_29_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9495.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,1308360022390228203).pkl\n",
      "len(self.cache[\"hashes\"]) = 42198\n",
      "self.cache[\"embeddings\"].shape = (42198, 128)\n",
      "100%|███████████████████████████████████| 8617/8617 [00:00<00:00, 189559.27it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:56<00:00, 151.31it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9435\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+EC+NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_52_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9002.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,1493189425621868816).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 75187.79it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:56<00:00, 153.14it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7581\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=368,1866338409828607810).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 73764.05it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [01:00<00:00, 141.36it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9038\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C+EC+NLI+R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_26_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9386.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,141429923173682938).pkl\n",
      "len(self.cache[\"hashes\"]) = 111895\n",
      "self.cache[\"embeddings\"].shape = (111895, 128)\n",
      "100%|████████████████████████████████████| 8617/8617 [00:00<00:00, 93461.52it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:56<00:00, 151.38it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8816\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_50_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9373.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=423,3677907674814022869).pkl\n",
      "len(self.cache[\"hashes\"]) = 42198\n",
      "self.cache[\"embeddings\"].shape = (42198, 128)\n",
      "100%|███████████████████████████████████| 8617/8617 [00:00<00:00, 197126.29it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:55<00:00, 154.70it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9005\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_174626_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+SD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n",
      "len(self.cache[\"hashes\"]) = 1165\n",
      "self.cache[\"embeddings\"].shape = (1165, 128)\n",
      "100%|███████████████████████████████████| 8617/8617 [00:00<00:00, 560937.38it/s]\n",
      "Computing embeddings for 8617 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 237 keys, intersection has 211 keys, union has 237 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.start_idx\u001b[0m\n",
      "\u001b[93m  fact_decoder_input_layer.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.pos_encoder.pe\u001b[0m\n",
      "\u001b[93m  fact_decoder.embedding_table.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.out_proj.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 87/87 [00:05<00:00, 15.38it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n",
      "100%|███████████████████████████████████| 8617/8617 [00:00<00:00, 330220.63it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:49<00:00, 173.09it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9530\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T -> T+C+EC+NLI+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: iuxray_with_automatic_labelers\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n",
      "len(sentences): 8617\n",
      "len(relevant_sentences): 8617\n",
      "checkpoint_names = ['checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt']\n",
      "  0%|                                                  | 0/8617 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=425,2776001221282427137).pkl\n",
      "len(self.cache[\"hashes\"]) = 1165\n",
      "self.cache[\"embeddings\"].shape = (1165, 128)\n",
      "100%|███████████████████████████████████| 8617/8617 [00:00<00:00, 563992.28it/s]\n",
      "Computing embeddings for 8617 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_1_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9160.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 253 keys, intersection has 211 keys, union has 253 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.pos_encoder.pe\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.in_proj_weight\u001b[0m\n",
      "\u001b[93m  fact_decoder_input_layer.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm1.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.in_proj_weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.out_proj.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 87/87 [00:05<00:00, 15.28it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=425,2776001221282427137).pkl\n",
      "100%|███████████████████████████████████| 8617/8617 [00:00<00:00, 721331.56it/s]\n",
      "Embeddings shape: (8617, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "\u001b[93m\u001b[1mEvaluating embeddings on ranking task with each sentence as query\u001b[0m\n",
      "100%|██████████████████████████████████████| 8617/8617 [00:52<00:00, 163.86it/s]\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9089\u001b[0m\n",
      "mean_relevant: 63.7905\n",
      "count: 7742 / 8617 (89.85%)\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"iuxray_with_automatic_labelers\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading iuxray sentences and relevant sentences from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/iuxray_sentences_and_relevant(thr1=0.4,thr2=0.2).pkl\n"
     ]
    }
   ],
   "source": [
    "from medvqa.eval_fact_embedding_on_ranking import SentenceRanker\n",
    "\n",
    "sr = SentenceRanker('iuxray_with_automatic_labelers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal heart size and normal mediastinal contours.\n",
      "num_relevant: 193\n",
      "\n",
      "The cardio mediastinal silhouette is of normal size and contour.\n",
      "Mediastinal silhouette is normal.\n",
      "Heart is normal in size.\n",
      "Heart and mediastinal contour normal.\n",
      "Heart size is at upper limits normal.\n",
      "Heart size is normal lungs are clear.\n",
      "The heart is normal in size and contour.\n",
      "Mediastinal silhouette and pulmonary vascularity within normal limits.\n",
      "Heart size normal and lungs are clear\n",
      "Mediastinal contour appears normal and pulmonary vascularity is within normal limits.\n",
      "Mediastinal silhouette and pulmonary vascularity are stable and within normal limits.\n",
      "Normal heart size, mediastinal and aortic contours.\n",
      "Mediastinal contours appear normal 7.\n",
      "Stable normal cardiac size and contour, normal mediastinal silhouette.\n",
      "Normal cardiac contours.\n",
      "Heart size and pulmonary XXXX appear normal.\n",
      "The cardiac mediastinal silhouettes are normal.\n",
      "Heart size and pulmonary vascularity normal.\n",
      "The cardiac and mediastinal silhouettes are normal.\n",
      "Heart size and mediastinal contour are within normal limits.\n",
      "Heart normal.\n",
      "The mediastinal silhouette is within normal limits.\n",
      "Cardiac size, mediastinal contour, and pulmonary vascularity are within normal limits.\n",
      "Normal heart.\n",
      "Normal size and mediastinal contours.\n",
      "Mediastinal silhouette and pulmonary vascularity appear within normal limits.\n",
      "Heart size, mediastinal silhouette and pulmonary vascularity are within normal limits.\n",
      "Heart size and pulmonary XXXX are normal.\n",
      "Heart size and mediastinal contour within normal limits.\n",
      "The pleural spaces are clear and mediastinal contours are normal.\n"
     ]
    }
   ],
   "source": [
    "query_idx = 4010\n",
    "print(sr.sentences[query_idx])\n",
    "print('num_relevant:', len(sr.relevant_sentences[query_idx]))\n",
    "print()\n",
    "for i, idx in enumerate(sr.relevant_sentences[query_idx]):\n",
    "    if i == 30: break\n",
    "    print(sr.sentences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8617/8617 [00:00<00:00, 511091.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal heart size and normal mediastinal contours.\n",
      "num_relevant: 193\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Normal heart size and normal mediastinal contours.\n",
      "0\n",
      "\n",
      "Normal heart size and mediastinal contours.\n",
      "1\n",
      "\n",
      "Normal heart size and mediastinal silhouette.\n",
      "1\n",
      "\n",
      "Normal heart and mediastinal contours.\n",
      "1\n",
      "\n",
      "Normal heart size and mediastinum.\n",
      "1\n",
      "\n",
      "Normal heart size and mediastinal contour.\n",
      "1\n",
      "\n",
      "Normal cardiac size and contour unremarkable mediastinal silhouette.\n",
      "0\n",
      "\n",
      "Normal heart size mediastinal contours.\n",
      "1\n",
      "\n",
      "Normal heart and mediastinum.\n",
      "0\n",
      "\n",
      "Heart and mediastinum normal.\n",
      "0\n",
      "\n",
      "Cardiac and mediastinal XXXX appear normal.\n",
      "1\n",
      "\n",
      "Normal cardiomediastinal silhouettes.\n",
      "0\n",
      "\n",
      "Normal cardiomediastinal contours.\n",
      "1\n",
      "\n",
      "Normal cardiac size and contour, unremarkable mediastinal silhouette.\n",
      "0\n",
      "\n",
      "Normal size and mediastinal contours.\n",
      "1\n",
      "\n",
      "Heart and mediastinal contours are normal.\n",
      "1\n",
      "\n",
      "Normal cardiomediastinal silhouette.\n",
      "0\n",
      "\n",
      "Heart and mediastinal contour normal.\n",
      "1\n",
      "\n",
      "Heart size and mediastinal contour normal.\n",
      "1\n",
      "\n",
      "Heart size mediastinal contours are normal in appearance.\n",
      "1\n",
      "\n",
      "Cardiac and mediastinal silhouettes are normal.\n",
      "1\n",
      "\n",
      "Heart and mediastinum are normal.\n",
      "0\n",
      "\n",
      "Heart size is normal and cardiomediastinal contours are normal.\n",
      "1\n",
      "\n",
      "Heart size and mediastinal contours are normal.\n",
      "1\n",
      "\n",
      "Heart size within normal limits and cardiomediastinal contours are normal.\n",
      "1\n",
      "\n",
      "Heart size is normal and cardiomediastinal silhouette is normal.\n",
      "1\n",
      "\n",
      "Heart size and mediastinal contour are normal.\n",
      "1\n",
      "\n",
      "Heart size and mediastinal contours are normal in appearance.\n",
      "1\n",
      "\n",
      "Heart size is normal in cardiomediastinal silhouette is normal in contour.\n",
      "1\n",
      "\n",
      "Heart size and cardiomediastinal contours are normal.\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = sr.rank_sentences(\n",
    "    query_idx,\n",
    "    model_name=\"microsoft/BiomedVLP-CXR-BERT-specialized\",\n",
    "#     checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_220207_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    "#     checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    "#     checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231002_152825_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    "#     checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231004_155915_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    "    checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231013_073812_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\",\n",
    "#     checkpoint_folder_path=\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\",\n",
    "    top_k=30,\n",
    ")\n",
    "print(sr.sentences[query_idx])\n",
    "print('num_relevant:', len(sr.relevant_sentences[query_idx]))\n",
    "print('-'*100)\n",
    "print()\n",
    "for i in range(len(output[0])):\n",
    "    print(output[0][i])\n",
    "    print(output[1][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest ImaGenome Gold Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-CXR-BERT-specialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=116,1396652957813721259).pkl\n",
      "len(self.cache[\"hashes\"]) = 146286\n",
      "self.cache[\"embeddings\"].shape = (146286, 128)\n",
      "100%|████████████████████████████████████| 2412/2412 [00:00<00:00, 13831.89it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8368\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9742\n",
      "mean_average_accuracy_at_10: 0.9669\n",
      "mean_average_accuracy_at_20: 0.9609\n",
      "mean_average_accuracy_at_50: 0.9534\n",
      "mean_average_accuracy_at_100: 0.9469\n",
      "mean_average_accuracy_at_200: 0.9399\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.1721\n",
      "mean_num_contradictions_at_10: 0.4175\n",
      "mean_num_contradictions_at_20: 0.9710\n",
      "mean_num_contradictions_at_50: 2.9051\n",
      "mean_num_contradictions_at_100: 6.2297\n",
      "mean_num_contradictions_at_200: 13.2442\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-BioViL-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-BioViL-T\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=104,2678825193822464594).pkl\n",
      "len(self.cache[\"hashes\"]) = 4452094\n",
      "self.cache[\"embeddings\"].shape = (4452094, 128)\n",
      "100%|██████████████████████████████████████| 2412/2412 [00:04<00:00, 527.87it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8447\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9771\n",
      "mean_average_accuracy_at_10: 0.9701\n",
      "mean_average_accuracy_at_20: 0.9639\n",
      "mean_average_accuracy_at_50: 0.9555\n",
      "mean_average_accuracy_at_100: 0.9486\n",
      "mean_average_accuracy_at_200: 0.9407\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.1679\n",
      "mean_num_contradictions_at_10: 0.4109\n",
      "mean_num_contradictions_at_20: 1.0211\n",
      "mean_num_contradictions_at_50: 3.1584\n",
      "mean_num_contradictions_at_100: 6.9030\n",
      "mean_num_contradictions_at_200: 14.8748\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-BioViL-T\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: michiyasunaga/BioLinkBERT-large\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,1253761809285128054).pkl\n",
      "len(self.cache[\"hashes\"]) = 146286\n",
      "self.cache[\"embeddings\"].shape = (146286, 1024)\n",
      "100%|█████████████████████████████████████| 2412/2412 [00:00<00:00, 4952.63it/s]\n",
      "Embeddings shape: (2412, 1024)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7171\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9739\n",
      "mean_average_accuracy_at_10: 0.9664\n",
      "mean_average_accuracy_at_20: 0.9599\n",
      "mean_average_accuracy_at_50: 0.9512\n",
      "mean_average_accuracy_at_100: 0.9448\n",
      "mean_average_accuracy_at_200: 0.9386\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.2790\n",
      "mean_num_contradictions_at_10: 0.7496\n",
      "mean_num_contradictions_at_20: 1.8499\n",
      "mean_num_contradictions_at_50: 5.5232\n",
      "mean_num_contradictions_at_100: 12.1584\n",
      "mean_num_contradictions_at_200: 26.2090\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"michiyasunaga/BioLinkBERT-large\" \\\n",
    "--average_token_embeddings \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=162,1758876944325999998).pkl\n",
      "len(self.cache[\"hashes\"]) = 146286\n",
      "self.cache[\"embeddings\"].shape = (146286, 768)\n",
      "100%|█████████████████████████████████████| 2412/2412 [00:00<00:00, 6153.63it/s]\n",
      "Embeddings shape: (2412, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.7749\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9761\n",
      "mean_average_accuracy_at_10: 0.9693\n",
      "mean_average_accuracy_at_20: 0.9628\n",
      "mean_average_accuracy_at_50: 0.9540\n",
      "mean_average_accuracy_at_100: 0.9472\n",
      "mean_average_accuracy_at_200: 0.9399\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.2218\n",
      "mean_num_contradictions_at_10: 0.5945\n",
      "mean_num_contradictions_at_20: 1.4776\n",
      "mean_num_contradictions_at_50: 4.5518\n",
      "mean_num_contradictions_at_100: 10.1335\n",
      "mean_num_contradictions_at_200: 22.5506\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\" \\\n",
    "--average_token_embeddings \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: emilyalsentzer/Bio_ClinicalBERT\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: True\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,412155249657523952).pkl\n",
      "len(self.cache[\"hashes\"]) = 146286\n",
      "self.cache[\"embeddings\"].shape = (146286, 768)\n",
      "100%|█████████████████████████████████████| 2412/2412 [00:00<00:00, 4808.18it/s]\n",
      "Embeddings shape: (2412, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8302\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9777\n",
      "mean_average_accuracy_at_10: 0.9711\n",
      "mean_average_accuracy_at_20: 0.9652\n",
      "mean_average_accuracy_at_50: 0.9567\n",
      "mean_average_accuracy_at_100: 0.9498\n",
      "mean_average_accuracy_at_200: 0.9425\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.2048\n",
      "mean_num_contradictions_at_10: 0.5211\n",
      "mean_num_contradictions_at_20: 1.2255\n",
      "mean_num_contradictions_at_50: 3.8230\n",
      "mean_num_contradictions_at_100: 8.6148\n",
      "mean_num_contradictions_at_200: 20.4639\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"emilyalsentzer/Bio_ClinicalBERT\" \\\n",
    "--average_token_embeddings \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: CheXbert\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "100%|███████████████████████████████████████| 2412/2412 [00:39<00:00, 60.46it/s]\n",
      "Embeddings shape: (2412, 768)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8641\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9793\n",
      "mean_average_accuracy_at_10: 0.9739\n",
      "mean_average_accuracy_at_20: 0.9692\n",
      "mean_average_accuracy_at_50: 0.9623\n",
      "mean_average_accuracy_at_100: 0.9559\n",
      "mean_average_accuracy_at_200: 0.9476\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0958\n",
      "mean_num_contradictions_at_10: 0.2405\n",
      "mean_num_contradictions_at_20: 0.6036\n",
      "mean_num_contradictions_at_50: 1.9142\n",
      "mean_num_contradictions_at_100: 4.2985\n",
      "mean_num_contradictions_at_200: 8.8636\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"CheXbert\" \\\n",
    "--device 'cuda' \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=359,388447562913600091).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|█████████████████████████████████████| 2412/2412 [00:00<00:00, 9777.05it/s]\n",
      "Computing embeddings for 2001 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 21/21 [00:03<00:00,  5.80it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=359,388447562913600091).pkl\n",
      "100%|███████████████████████████████████| 2001/2001 [00:00<00:00, 558700.73it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8956\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9813\n",
      "mean_average_accuracy_at_10: 0.9760\n",
      "mean_average_accuracy_at_20: 0.9707\n",
      "mean_average_accuracy_at_50: 0.9632\n",
      "mean_average_accuracy_at_100: 0.9566\n",
      "mean_average_accuracy_at_200: 0.9484\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0813\n",
      "mean_num_contradictions_at_10: 0.2243\n",
      "mean_num_contradictions_at_20: 0.5410\n",
      "mean_num_contradictions_at_50: 1.6675\n",
      "mean_num_contradictions_at_100: 3.9395\n",
      "mean_num_contradictions_at_200: 9.5381\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,2492157991032224976).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|█████████████████████████████████████| 2412/2412 [00:00<00:00, 8570.99it/s]\n",
      "Computing embeddings for 2001 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 223 keys, intersection has 211 keys, union has 223 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 21/21 [00:04<00:00,  5.18it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,2492157991032224976).pkl\n",
      "100%|███████████████████████████████████| 2001/2001 [00:00<00:00, 518074.22it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9188\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9896\n",
      "mean_average_accuracy_at_10: 0.9859\n",
      "mean_average_accuracy_at_20: 0.9817\n",
      "mean_average_accuracy_at_50: 0.9748\n",
      "mean_average_accuracy_at_100: 0.9667\n",
      "mean_average_accuracy_at_200: 0.9569\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.1066\n",
      "mean_num_contradictions_at_10: 0.2865\n",
      "mean_num_contradictions_at_20: 0.8064\n",
      "mean_num_contradictions_at_50: 2.9552\n",
      "mean_num_contradictions_at_100: 9.1571\n",
      "mean_num_contradictions_at_200: 24.5328\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=368,1866338409828607810).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|████████████████████████████████████| 2412/2412 [00:00<00:00, 10088.81it/s]\n",
      "Computing embeddings for 2001 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 216 keys, intersection has 211 keys, union has 216 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.weight\u001b[0m\n",
      "\u001b[93m  spert_size_embeddings.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 21/21 [00:03<00:00,  5.47it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=368,1866338409828607810).pkl\n",
      "100%|███████████████████████████████████| 2001/2001 [00:00<00:00, 219839.23it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8875\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9810\n",
      "mean_average_accuracy_at_10: 0.9757\n",
      "mean_average_accuracy_at_20: 0.9707\n",
      "mean_average_accuracy_at_50: 0.9635\n",
      "mean_average_accuracy_at_100: 0.9569\n",
      "mean_average_accuracy_at_200: 0.9483\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0871\n",
      "mean_num_contradictions_at_10: 0.2077\n",
      "mean_num_contradictions_at_20: 0.4590\n",
      "mean_num_contradictions_at_50: 1.4030\n",
      "mean_num_contradictions_at_100: 3.5427\n",
      "mean_num_contradictions_at_200: 10.1476\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n",
      "len(self.cache[\"hashes\"]) = 144285\n",
      "self.cache[\"embeddings\"].shape = (144285, 128)\n",
      "100%|█████████████████████████████████████| 2412/2412 [00:00<00:00, 8608.20it/s]\n",
      "Computing embeddings for 2001 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 237 keys, intersection has 211 keys, union has 237 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.in_proj_weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder_input_layer.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.start_idx\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm1.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 21/21 [00:03<00:00,  5.82it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=372,2533955929466572136).pkl\n",
      "100%|███████████████████████████████████| 2001/2001 [00:00<00:00, 491640.93it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8972\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9802\n",
      "mean_average_accuracy_at_10: 0.9742\n",
      "mean_average_accuracy_at_20: 0.9687\n",
      "mean_average_accuracy_at_50: 0.9612\n",
      "mean_average_accuracy_at_100: 0.9546\n",
      "mean_average_accuracy_at_200: 0.9474\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.1430\n",
      "mean_num_contradictions_at_10: 0.3532\n",
      "mean_num_contradictions_at_20: 0.8143\n",
      "mean_num_contradictions_at_50: 2.4270\n",
      "mean_num_contradictions_at_100: 5.4652\n",
      "mean_num_contradictions_at_200: 12.6061\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_125012_MIMIC-CXR(triplets+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_116_nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9199.pt']\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 515840.37it/s]\n",
      "Computing embeddings for 2412 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_116_nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9199.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_125012_MIMIC-CXR(triplets+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_116_nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9199.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 215 keys, intersection has 211 keys, union has 215 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.20it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=364,459173252947772357).pkl\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 459409.71it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8201\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9715\n",
      "mean_average_accuracy_at_10: 0.9640\n",
      "mean_average_accuracy_at_20: 0.9581\n",
      "mean_average_accuracy_at_50: 0.9509\n",
      "mean_average_accuracy_at_100: 0.9448\n",
      "mean_average_accuracy_at_200: 0.9388\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0883\n",
      "mean_num_contradictions_at_10: 0.2056\n",
      "mean_num_contradictions_at_20: 0.4391\n",
      "mean_num_contradictions_at_50: 1.3777\n",
      "mean_num_contradictions_at_100: 3.2396\n",
      "mean_num_contradictions_at_200: 7.3997\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_125012_MIMIC-CXR(triplets+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_080646_MIMIC-CXR(triplets+entcon)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_98_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9440.pt']\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 449230.07it/s]\n",
      "Computing embeddings for 2412 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_98_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9440.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_080646_MIMIC-CXR(triplets+entcon)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_98_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9440.pt\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.86it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=366,313298442480815119).pkl\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 617962.33it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8395\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9773\n",
      "mean_average_accuracy_at_10: 0.9709\n",
      "mean_average_accuracy_at_20: 0.9653\n",
      "mean_average_accuracy_at_50: 0.9572\n",
      "mean_average_accuracy_at_100: 0.9509\n",
      "mean_average_accuracy_at_200: 0.9436\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0862\n",
      "mean_num_contradictions_at_10: 0.2119\n",
      "mean_num_contradictions_at_20: 0.4515\n",
      "mean_num_contradictions_at_50: 1.2367\n",
      "mean_num_contradictions_at_100: 2.5220\n",
      "mean_num_contradictions_at_200: 5.1256\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_080646_MIMIC-CXR(triplets+entcon)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+NLI+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240128_173216_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_92_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9209.pt']\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 286282.79it/s]\n",
      "Computing embeddings for 2412 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_92_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9209.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240128_173216_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_92_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9209.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 215 keys, intersection has 211 keys, union has 215 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.89it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=375,2949907930748449873).pkl\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 647839.48it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8117\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9708\n",
      "mean_average_accuracy_at_10: 0.9635\n",
      "mean_average_accuracy_at_20: 0.9577\n",
      "mean_average_accuracy_at_50: 0.9500\n",
      "mean_average_accuracy_at_100: 0.9434\n",
      "mean_average_accuracy_at_200: 0.9366\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0659\n",
      "mean_num_contradictions_at_10: 0.1534\n",
      "mean_num_contradictions_at_20: 0.3516\n",
      "mean_num_contradictions_at_50: 0.9693\n",
      "mean_num_contradictions_at_100: 2.4784\n",
      "mean_num_contradictions_at_200: 6.1298\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240128_173216_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_213433_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_184_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9569.pt']\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 340823.41it/s]\n",
      "Computing embeddings for 2412 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_184_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9569.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_213433_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_184_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9569.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 232 keys, intersection has 211 keys, union has 232 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  spert_size_embeddings.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.bias\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.bias\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.08it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=424,3351509109300070142).pkl\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 398623.32it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9170\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9882\n",
      "mean_average_accuracy_at_10: 0.9840\n",
      "mean_average_accuracy_at_20: 0.9796\n",
      "mean_average_accuracy_at_50: 0.9720\n",
      "mean_average_accuracy_at_100: 0.9638\n",
      "mean_average_accuracy_at_200: 0.9538\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0813\n",
      "mean_num_contradictions_at_10: 0.2036\n",
      "mean_num_contradictions_at_20: 0.5439\n",
      "mean_num_contradictions_at_50: 1.7193\n",
      "mean_num_contradictions_at_100: 4.6940\n",
      "mean_num_contradictions_at_200: 10.0896\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_213433_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_151525_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_98_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9322.pt']\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 288265.03it/s]\n",
      "Computing embeddings for 2412 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_98_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9322.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_151525_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_98_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9322.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 253 keys, intersection has 211 keys, union has 253 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear2.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.W_vocab.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.norm2.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.out_proj.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  category_classifier.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.multihead_attn.in_proj_bias\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.05it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=426,3489013806009299070).pkl\n",
      "100%|███████████████████████████████████| 2412/2412 [00:00<00:00, 717341.08it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9055\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9877\n",
      "mean_average_accuracy_at_10: 0.9832\n",
      "mean_average_accuracy_at_20: 0.9785\n",
      "mean_average_accuracy_at_50: 0.9706\n",
      "mean_average_accuracy_at_100: 0.9624\n",
      "mean_average_accuracy_at_200: 0.9522\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0891\n",
      "mean_num_contradictions_at_10: 0.1998\n",
      "mean_num_contradictions_at_20: 0.4954\n",
      "mean_num_contradictions_at_50: 1.4453\n",
      "mean_num_contradictions_at_100: 3.6032\n",
      "mean_num_contradictions_at_200: 7.6331\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_151525_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_235928_MIMIC-CXR(triplets+classif+entcont+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9472.pt']\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=410,2647990738830975744).pkl\n",
      "len(self.cache[\"hashes\"]) = 32416\n",
      "self.cache[\"embeddings\"].shape = (32416, 128)\n",
      "100%|████████████████████████████████████| 2412/2412 [00:00<00:00, 55384.60it/s]\n",
      "Computing embeddings for 2410 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9472.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_235928_MIMIC-CXR(triplets+classif+entcont+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9472.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 227 keys, intersection has 211 keys, union has 227 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  nli_classifier.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_hidden_layer.bias\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  nli_classifier.bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_obs_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.weight\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.weight\u001b[0m\n",
      "\u001b[93m  aux_task_hidden_layer.bias\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.22it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=410,2647990738830975744).pkl\n",
      "100%|███████████████████████████████████| 2410/2410 [00:00<00:00, 225158.65it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.8903\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9873\n",
      "mean_average_accuracy_at_10: 0.9825\n",
      "mean_average_accuracy_at_20: 0.9774\n",
      "mean_average_accuracy_at_50: 0.9692\n",
      "mean_average_accuracy_at_100: 0.9604\n",
      "mean_average_accuracy_at_200: 0.9494\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0659\n",
      "mean_num_contradictions_at_10: 0.1725\n",
      "mean_num_contradictions_at_20: 0.4449\n",
      "mean_num_contradictions_at_50: 1.4370\n",
      "mean_num_contradictions_at_100: 3.7890\n",
      "mean_num_contradictions_at_200: 7.8263\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_235928_MIMIC-CXR(triplets+classif+entcont+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+ER+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   evaluation_mode: chest_imagenome_gold\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_184445_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Loading sentence2labels_gold from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\n",
      "Number of sentences: 2412\n",
      "label.shape: (2412, 108)\n",
      "Loaded chest_imagenome_gold_relevance matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_relevance,2412,70,2412,38).pkl\n",
      "Loaded gold_accuracy matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(gold_accuracy,2412,108).pkl\n",
      "Loaded chest_imagenome_gold_contradictions matrix from /mnt/workspace/pamessina/medvqa-workspace/cache/score_matrix(chest_imagenome_gold_contradictions,2412,70).pkl\n",
      "checkpoint_names = ['checkpoint_91_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9337.pt']\n",
      "  0%|                                                  | 0/2412 [00:00<?, ?it/s]Loading cached text embeddings from /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=440,3465006188639683439).pkl\n",
      "len(self.cache[\"hashes\"]) = 32416\n",
      "self.cache[\"embeddings\"].shape = (32416, 128)\n",
      "100%|████████████████████████████████████| 2412/2412 [00:00<00:00, 56468.13it/s]\n",
      "Computing embeddings for 2410 new texts\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "checkpoint_names = ['checkpoint_91_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9337.pt']\n",
      "Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_184445_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_91_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9337.pt\n",
      "\u001b[93mWarning: model state dict has 211 keys, loaded state dict has 258 keys, intersection has 211 keys, union has 258 keys.\u001b[0m\n",
      "\u001b[93mExamples of keys in loaded state dict but not in model:\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear2.weight\u001b[0m\n",
      "\u001b[93m  health_status_classifier.weight\u001b[0m\n",
      "\u001b[93m  category_classifier.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.in_proj_bias\u001b[0m\n",
      "\u001b[93m  chest_imagenome_anatloc_classifier.bias\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.linear1.bias\u001b[0m\n",
      "\u001b[93m  spert_entity_classifier.bias\u001b[0m\n",
      "\u001b[93m  spert_rel_classifier.weight\u001b[0m\n",
      "\u001b[93m  fact_decoder.decoder.layers.0.self_attn.out_proj.bias\u001b[0m\n",
      "\u001b[93m  comparison_status_classifier.weight\u001b[0m\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.72it/s]\n",
      "Saving updated cache to /mnt/workspace/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=440,3465006188639683439).pkl\n",
      "100%|███████████████████████████████████| 2410/2410 [00:00<00:00, 223530.50it/s]\n",
      "Embeddings shape: (2412, 128)\n",
      "Normalizing embeddings (for cosine similarity)\n",
      "Computing score matrix\n",
      "score_matrix.shape: (2412, 2412)\n",
      "\u001b[1m\u001b[35mmean_AUC: 0.9071\u001b[0m\n",
      "mean_average_accuracy_at_1: 1.0000\n",
      "mean_average_accuracy_at_5: 0.9875\n",
      "mean_average_accuracy_at_10: 0.9832\n",
      "mean_average_accuracy_at_20: 0.9784\n",
      "mean_average_accuracy_at_50: 0.9704\n",
      "mean_average_accuracy_at_100: 0.9622\n",
      "mean_average_accuracy_at_200: 0.9521\n",
      "mean_num_contradictions_at_1: 0.0000\n",
      "mean_num_contradictions_at_5: 0.0896\n",
      "mean_num_contradictions_at_10: 0.2098\n",
      "mean_num_contradictions_at_20: 0.4851\n",
      "mean_num_contradictions_at_50: 1.5017\n",
      "mean_num_contradictions_at_100: 3.8039\n",
      "mean_num_contradictions_at_200: 7.8532\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"chest_imagenome_gold\" \\\n",
    "--chest_imagenome_sentence2labels_gold_filepath \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/phrases2labels_gold(num_obs=70,num_anat=38,num_phrases=2412).pkl\" \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_184445_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PadChest-GR + MS-CXR custom ranking evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-CXR-BERT-specialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-25 09:30:31,642 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:31,644 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\n",
      "   save_worst_queries_for_inspection: True\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:31,644 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:31,657 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:31,657 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:31,657 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "  0%|                                                  | 0/3988 [00:00<?, ?it/s]\u001b[32m2025-05-25 09:30:31,885 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading cached text embeddings from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=144,90025341481394601).pkl\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,145 - INFO - medvqa.models.huggingface_utils\u001b[0m - len(self.cache[\"hashes\"]) = 681722\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,146 - INFO - medvqa.models.huggingface_utils\u001b[0m - self.cache[\"embeddings\"].shape = (681722, 128)\u001b[0m\n",
      "100%|█████████████████████████████████████| 3988/3988 [00:00<00:00, 8795.61it/s]\n",
      "\u001b[32m2025-05-25 09:30:32,340 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,340 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,340 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,341 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,342 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,342 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,343 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,344 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,344 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,345 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,346 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,346 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,347 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,347 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,347 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,357 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,358 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.9074, 0.9994]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:32,358 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,928 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,928 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.7924 ± 0.0813\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m -   Median: 0.8041\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m -   Range: [0.5101, 0.9555]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.6068 ± 0.0841\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m -   Median: 0.6098\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,929 - INFO - __main__\u001b[0m -   Range: [0.3546, 0.8158]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9801 ± 0.0063\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m -   Median: 0.9806\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m -   Range: [0.9634, 0.9932]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9494 ± 0.0490\u001b[0m, Median: 0.9618, Range: [0.6541, 0.9992]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,930 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9400 ± 0.0488\u001b[0m, Median: 0.9500, Range: [0.6676, 0.9993]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,931 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9367 ± 0.0475\u001b[0m, Median: 0.9435, Range: [0.7041, 0.9998]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,931 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.9332 ± 0.0475\u001b[0m, Median: 0.9396, Range: [0.7009, 0.9996]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,931 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.9306 ± 0.0469\u001b[0m, Median: 0.9379, Range: [0.6885, 0.9998]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,931 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.9281 ± 0.0472\u001b[0m, Median: 0.9345, Range: [0.6833, 0.9999]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,931 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.9259 ± 0.0473\u001b[0m, Median: 0.9319, Range: [0.6733, 0.9956]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,931 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.9232 ± 0.0478\u001b[0m, Median: 0.9302, Range: [0.6851, 0.9942]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,932 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.9217 ± 0.0475\u001b[0m, Median: 0.9291, Range: [0.6748, 0.9934]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,932 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.9199 ± 0.0478\u001b[0m, Median: 0.9279, Range: [0.6810, 0.9928]\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,932 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.9309\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,932 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n",
      "\u001b[32m2025-05-25 09:30:39,932 - INFO - __main__\u001b[0m - Saving worst queries for inspection to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_worst_queries_for_inspection_20250525_093039.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--batch_size 100 \\\n",
    "--save_worst_queries_for_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedVLP-BioViL-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 20:58:17,761 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:17,762 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-BioViL-T\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:17,762 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:17,776 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:17,777 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:17,777 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 622836.03it/s]\n",
      "\u001b[32m2025-05-24 20:58:18,082 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "Some weights of the model checkpoint at microsoft/BiomedVLP-BioViL-T were not used when initializing CXRBertModel: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CXRBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CXRBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 19.18it/s]\n",
      "\u001b[32m2025-05-24 20:58:22,759 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=132,203616028629610525).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 758279.36it/s]\n",
      "\u001b[32m2025-05-24 20:58:22,771 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,771 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,772 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,774 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,775 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,775 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,776 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,777 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,777 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,778 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,778 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,779 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,780 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,780 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,780 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,790 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,791 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8878, 0.9985]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:22,791 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,356 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,356 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.7319 ± 0.0933\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m -   Median: 0.7492\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m -   Range: [0.4216, 0.9154]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.5439 ± 0.0858\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m -   Median: 0.5541\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m -   Range: [0.2859, 0.7429]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,357 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9785 ± 0.0066\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m -   Median: 0.9794\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m -   Range: [0.9528, 0.9921]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9507 ± 0.0475\u001b[0m, Median: 0.9629, Range: [0.7034, 0.9990]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9417 ± 0.0476\u001b[0m, Median: 0.9528, Range: [0.6867, 0.9992]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,358 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9375 ± 0.0472\u001b[0m, Median: 0.9451, Range: [0.6849, 0.9999]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,359 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.9334 ± 0.0465\u001b[0m, Median: 0.9396, Range: [0.6998, 0.9998]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,359 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.9297 ± 0.0470\u001b[0m, Median: 0.9361, Range: [0.6923, 0.9999]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,359 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.9262 ± 0.0476\u001b[0m, Median: 0.9315, Range: [0.6881, 0.9995]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,359 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.9238 ± 0.0477\u001b[0m, Median: 0.9296, Range: [0.6824, 0.9986]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,359 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.9203 ± 0.0482\u001b[0m, Median: 0.9272, Range: [0.6937, 0.9979]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,360 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.9183 ± 0.0481\u001b[0m, Median: 0.9246, Range: [0.6813, 0.9962]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,360 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.9160 ± 0.0482\u001b[0m, Median: 0.9251, Range: [0.6879, 0.9962]\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,360 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.9298\u001b[0m\n",
      "\u001b[32m2025-05-24 20:58:30,360 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-BioViL-T\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### michiyasunaga/BioLinkBERT-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 20:59:41,120 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 20:59:41,121 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: michiyasunaga/BioLinkBERT-large\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 20:59:41,121 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 20:59:41,136 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 20:59:41,136 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 20:59:41,136 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 602466.66it/s]\n",
      "\u001b[32m2025-05-24 20:59:41,435 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "config.json: 100%|█████████████████████████████| 560/560 [00:00<00:00, 2.35MB/s]\n",
      "pytorch_model.bin: 100%|███████████████████| 1.33G/1.33G [00:29<00:00, 45.8MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████| 379/379 [00:00<00:00, 1.75MB/s]\n",
      "vocab.txt: 100%|██████████████████████████████| 225k/225k [00:00<00:00, 783kB/s]\n",
      "tokenizer.json: 100%|████████████████████████| 447k/447k [00:00<00:00, 3.01MB/s]\n",
      "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 567kB/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:04<00:00,  8.29it/s]\n",
      "\u001b[32m2025-05-24 21:00:21,052 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=135,4126654352468122202).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 745404.83it/s]\n",
      "\u001b[32m2025-05-24 21:00:21,078 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 1024)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,079 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,080 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,081 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,081 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,082 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,083 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,083 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,084 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,085 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,085 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,086 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,096 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 1024)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,097 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 1024)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,097 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,109 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,110 - INFO - __main__\u001b[0m - Embedding similarity range: [0.1036, 0.9920]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:21,110 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,724 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,724 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,724 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.1485 ± 0.1371\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   Median: 0.1501\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   Range: [-0.2078, 0.4504]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.1015 ± 0.0939\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   Median: 0.1022\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   Range: [-0.1397, 0.3124]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9405 ± 0.0213\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,725 - INFO - __main__\u001b[0m -   Median: 0.9431\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,726 - INFO - __main__\u001b[0m -   Range: [0.8844, 0.9780]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,726 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,726 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.6935 ± 0.1968\u001b[0m, Median: 0.7068, Range: [0.1552, 0.9984]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,726 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.6808 ± 0.1727\u001b[0m, Median: 0.7056, Range: [0.2014, 0.9927]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,726 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.6718 ± 0.1588\u001b[0m, Median: 0.6898, Range: [0.2310, 0.9658]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,726 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.6647 ± 0.1508\u001b[0m, Median: 0.6775, Range: [0.2398, 0.9614]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,727 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.6612 ± 0.1446\u001b[0m, Median: 0.6757, Range: [0.2540, 0.9578]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,727 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.6585 ± 0.1377\u001b[0m, Median: 0.6728, Range: [0.2786, 0.9361]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,727 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.6549 ± 0.1334\u001b[0m, Median: 0.6675, Range: [0.2964, 0.9229]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,727 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.6511 ± 0.1302\u001b[0m, Median: 0.6584, Range: [0.2930, 0.8981]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,727 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.6487 ± 0.1271\u001b[0m, Median: 0.6543, Range: [0.2930, 0.8849]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,728 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.6461 ± 0.1246\u001b[0m, Median: 0.6507, Range: [0.3062, 0.8839]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,728 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.6631\u001b[0m\n",
      "\u001b[32m2025-05-24 21:00:28,728 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"michiyasunaga/BioLinkBERT-large\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:01:29,157 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:29,159 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:29,159 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:29,173 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:29,174 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:29,174 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 624323.84it/s]\n",
      "\u001b[32m2025-05-24 21:01:29,517 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:01<00:00, 22.08it/s]\n",
      "\u001b[32m2025-05-24 21:01:35,921 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=165,4285473352768493116).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 739865.73it/s]\n",
      "\u001b[32m2025-05-24 21:01:35,947 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,947 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,947 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,950 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,951 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,952 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,953 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,953 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,954 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,955 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,955 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,955 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,962 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,962 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,962 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,970 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,971 - INFO - __main__\u001b[0m - Embedding similarity range: [0.2445, 0.9989]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:35,972 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,602 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,602 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,602 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.1331 ± 0.0816\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   Median: 0.1288\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   Range: [-0.0765, 0.3528]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.0897 ± 0.0555\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   Median: 0.0862\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   Range: [-0.0522, 0.2408]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9402 ± 0.0157\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,603 - INFO - __main__\u001b[0m -   Median: 0.9420\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,604 - INFO - __main__\u001b[0m -   Range: [0.8895, 0.9695]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,604 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,604 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.7200 ± 0.1586\u001b[0m, Median: 0.7403, Range: [0.3053, 0.9974]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,604 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.6955 ± 0.1336\u001b[0m, Median: 0.7113, Range: [0.3610, 0.9893]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,604 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.6844 ± 0.1233\u001b[0m, Median: 0.6970, Range: [0.3760, 0.9836]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,604 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.6762 ± 0.1170\u001b[0m, Median: 0.6908, Range: [0.3779, 0.9570]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,605 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.6670 ± 0.1106\u001b[0m, Median: 0.6724, Range: [0.3516, 0.9334]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,605 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.6599 ± 0.1050\u001b[0m, Median: 0.6695, Range: [0.3437, 0.9227]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,605 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.6543 ± 0.0995\u001b[0m, Median: 0.6656, Range: [0.3489, 0.9154]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,605 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.6504 ± 0.0977\u001b[0m, Median: 0.6605, Range: [0.3504, 0.9122]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,605 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.6460 ± 0.0945\u001b[0m, Median: 0.6565, Range: [0.3642, 0.8946]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,606 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.6439 ± 0.0915\u001b[0m, Median: 0.6523, Range: [0.3642, 0.8997]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,606 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.6698\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:43,606 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### emilyalsentzer/Bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:01:53,302 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:53,303 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: emilyalsentzer/Bio_ClinicalBERT\n",
      "   device: GPU\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:53,303 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:53,318 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:53,318 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:01:53,318 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 623091.24it/s]\n",
      "\u001b[32m2025-05-24 21:01:53,642 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "config.json: 100%|█████████████████████████████| 385/385 [00:00<00:00, 1.56MB/s]\n",
      "pytorch_model.bin: 100%|█████████████████████| 436M/436M [00:04<00:00, 90.1MB/s]\n",
      "vocab.txt: 100%|██████████████████████████████| 213k/213k [00:00<00:00, 765kB/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 19.42it/s]\n",
      "\u001b[32m2025-05-24 21:02:06,974 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=135,1334081344076698724).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 726245.41it/s]\n",
      "\u001b[32m2025-05-24 21:02:07,000 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,000 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,001 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,002 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,003 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,003 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,004 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,005 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,005 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,006 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,007 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,007 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,015 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,015 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,015 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,028 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,029 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.4648, 0.9997]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:07,029 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,622 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,622 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,622 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.0574 ± 0.1266\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,622 - INFO - __main__\u001b[0m -   Median: 0.0407\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,622 - INFO - __main__\u001b[0m -   Range: [-0.2812, 0.3220]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.0388 ± 0.0851\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m -   Median: 0.0276\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m -   Range: [-0.1902, 0.2154]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9306 ± 0.0181\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m -   Median: 0.9334\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m -   Range: [0.8753, 0.9652]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,623 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,624 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.5908 ± 0.1712\u001b[0m, Median: 0.5939, Range: [0.0869, 0.9574]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,624 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.5753 ± 0.1488\u001b[0m, Median: 0.5631, Range: [0.1624, 0.8966]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,624 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.5709 ± 0.1383\u001b[0m, Median: 0.5680, Range: [0.1792, 0.8742]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,624 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.5666 ± 0.1290\u001b[0m, Median: 0.5611, Range: [0.2099, 0.8597]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,624 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.5622 ± 0.1193\u001b[0m, Median: 0.5562, Range: [0.2571, 0.8568]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.5588 ± 0.1129\u001b[0m, Median: 0.5594, Range: [0.2798, 0.8634]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.5563 ± 0.1089\u001b[0m, Median: 0.5538, Range: [0.2761, 0.8431]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.5538 ± 0.1057\u001b[0m, Median: 0.5490, Range: [0.2847, 0.8265]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.5520 ± 0.1025\u001b[0m, Median: 0.5490, Range: [0.2813, 0.8293]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.5510 ± 0.1009\u001b[0m, Median: 0.5450, Range: [0.2903, 0.8138]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.5638\u001b[0m\n",
      "\u001b[32m2025-05-24 21:02:14,625 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"emilyalsentzer/Bio_ClinicalBERT\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:03:50,170 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:50,172 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: CheXbert\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: None\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:50,172 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:50,185 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:50,186 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:50,186 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,712 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,712 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,714 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,715 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,716 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,716 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,717 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,717 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,718 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,719 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,719 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,720 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,728 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,728 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 768)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,728 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,739 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,740 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.0741, 0.9991]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:03:58,740 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,304 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4432 ± 0.1230\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m -   Median: 0.4604\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m -   Range: [-0.0552, 0.6867]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3082 ± 0.0891\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m -   Median: 0.3191\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,305 - INFO - __main__\u001b[0m -   Range: [-0.0332, 0.4930]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9644 ± 0.0120\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m -   Median: 0.9667\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m -   Range: [0.9243, 0.9870]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.8930 ± 0.1292\u001b[0m, Median: 0.9400, Range: [0.1944, 0.9997]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,306 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8825 ± 0.1254\u001b[0m, Median: 0.9180, Range: [0.2321, 0.9995]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,307 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8711 ± 0.1245\u001b[0m, Median: 0.9059, Range: [0.2585, 0.9992]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,307 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8636 ± 0.1223\u001b[0m, Median: 0.8983, Range: [0.3712, 0.9988]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,307 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8580 ± 0.1212\u001b[0m, Median: 0.8874, Range: [0.3786, 0.9966]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,307 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8528 ± 0.1206\u001b[0m, Median: 0.8792, Range: [0.3985, 0.9945]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,307 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8482 ± 0.1198\u001b[0m, Median: 0.8744, Range: [0.4111, 0.9953]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,308 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8444 ± 0.1195\u001b[0m, Median: 0.8689, Range: [0.4169, 0.9956]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,308 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8403 ± 0.1178\u001b[0m, Median: 0.8665, Range: [0.4291, 0.9964]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,308 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8365 ± 0.1166\u001b[0m, Median: 0.8614, Range: [0.4267, 0.9968]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,308 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8590\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:06,308 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"CheXbert\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:04:22,045 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:22,047 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:22,047 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:22,061 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:22,061 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:22,061 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:22,072 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 614146.14it/s]\n",
      "\u001b[32m2025-05-24 21:04:22,386 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:23,895 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:23,896 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_40_ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9355.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:04:32,266 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 211 keys, intersection has 210 keys, union has 211 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  bert.embeddings.position_ids\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.14it/s]\n",
      "\u001b[32m2025-05-24 21:04:35,714 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=387,3256372920853286864).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 774500.36it/s]\n",
      "\u001b[32m2025-05-24 21:04:35,724 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,725 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,727 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,727 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,728 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,729 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,729 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,730 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,731 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,731 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,732 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,732 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,734 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,734 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,734 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,743 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,744 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.9489, 1.0000]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:35,744 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,309 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,309 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4753 ± 0.1491\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m -   Median: 0.4978\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m -   Range: [-0.1696, 0.7505]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3313 ± 0.1084\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m -   Median: 0.3469\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m -   Range: [-0.1139, 0.5472]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,310 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9638 ± 0.0123\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m -   Median: 0.9659\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m -   Range: [0.9138, 0.9869]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.8883 ± 0.1149\u001b[0m, Median: 0.9204, Range: [0.1378, 0.9993]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8716 ± 0.1092\u001b[0m, Median: 0.8947, Range: [0.1519, 0.9987]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,311 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8628 ± 0.1076\u001b[0m, Median: 0.8818, Range: [0.1236, 0.9946]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,312 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8563 ± 0.1062\u001b[0m, Median: 0.8715, Range: [0.1141, 0.9947]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,312 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8507 ± 0.1050\u001b[0m, Median: 0.8689, Range: [0.1111, 0.9960]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,312 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8464 ± 0.1046\u001b[0m, Median: 0.8646, Range: [0.1159, 0.9967]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,312 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8423 ± 0.1031\u001b[0m, Median: 0.8601, Range: [0.1473, 0.9901]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,312 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8362 ± 0.1018\u001b[0m, Median: 0.8499, Range: [0.1522, 0.9872]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,313 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8322 ± 0.1015\u001b[0m, Median: 0.8422, Range: [0.1383, 0.9861]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,313 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8287 ± 0.1002\u001b[0m, Median: 0.8404, Range: [0.1443, 0.9760]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,313 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8515\u001b[0m\n",
      "\u001b[32m2025-05-24 21:04:43,313 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230927_194923_MIMIC-CXR(triplets-only)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:05:44,415 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:44,416 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:44,417 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:44,431 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:44,431 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:44,431 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:44,439 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 575578.42it/s]\n",
      "\u001b[32m2025-05-24 21:05:44,755 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:46,156 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:46,156 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_64_cacc+chf1+chf1+cscc+hscc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9474.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:05:54,577 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 223 keys, intersection has 210 keys, union has 223 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  comparison_status_classifier.weight\n",
      "  chest_imagenome_anatloc_classifier.weight\n",
      "  aux_task_hidden_layer.weight\n",
      "  health_status_classifier.weight\n",
      "  aux_task_hidden_layer.bias\n",
      "  chest_imagenome_obs_classifier.bias\n",
      "  category_classifier.weight\n",
      "  chest_imagenome_obs_classifier.weight\n",
      "  health_status_classifier.bias\n",
      "  bert.embeddings.position_ids\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.53it/s]\n",
      "\u001b[32m2025-05-24 21:05:58,234 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=415,375492133104041857).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 636777.99it/s]\n",
      "\u001b[32m2025-05-24 21:05:58,246 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,246 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,248 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,248 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,249 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,250 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,250 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,251 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,251 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,252 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,253 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,253 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,254 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,254 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,255 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,259 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,260 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8326, 0.9998]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:05:58,260 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,115 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,116 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,116 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3997 ± 0.1353\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,116 - INFO - __main__\u001b[0m -   Median: 0.4077\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,116 - INFO - __main__\u001b[0m -   Range: [-0.0284, 0.7042]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,116 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,116 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.2745 ± 0.0966\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m -   Median: 0.2759\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m -   Range: [-0.0258, 0.5128]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9640 ± 0.0109\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m -   Median: 0.9669\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m -   Range: [0.9203, 0.9808]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,117 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9275 ± 0.0778\u001b[0m, Median: 0.9502, Range: [0.3979, 0.9992]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,118 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9075 ± 0.0797\u001b[0m, Median: 0.9262, Range: [0.4509, 0.9982]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,118 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8961 ± 0.0812\u001b[0m, Median: 0.9123, Range: [0.4590, 0.9973]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,118 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8867 ± 0.0795\u001b[0m, Median: 0.9013, Range: [0.5238, 0.9978]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,118 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8772 ± 0.0796\u001b[0m, Median: 0.8903, Range: [0.5346, 0.9982]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,118 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8703 ± 0.0789\u001b[0m, Median: 0.8839, Range: [0.5415, 0.9983]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,119 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8647 ± 0.0783\u001b[0m, Median: 0.8785, Range: [0.5514, 0.9983]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,119 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8576 ± 0.0783\u001b[0m, Median: 0.8696, Range: [0.5586, 0.9928]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,119 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8524 ± 0.0775\u001b[0m, Median: 0.8650, Range: [0.5613, 0.9937]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,119 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8479 ± 0.0767\u001b[0m, Median: 0.8627, Range: [0.5620, 0.9941]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,119 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8788\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:06,119 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_013825_MIMIC-CXR(triplets+classif)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:06:59,120 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:59,121 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:59,121 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:59,136 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:59,136 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:59,136 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:06:59,136 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 612437.18it/s]\n",
      "\u001b[32m2025-05-24 21:06:59,450 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:00,874 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:00,874 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_93_spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9415.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:07:09,432 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 216 keys, intersection has 210 keys, union has 216 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  spert_rel_classifier.bias\n",
      "  spert_entity_classifier.bias\n",
      "  bert.embeddings.position_ids\n",
      "  spert_rel_classifier.weight\n",
      "  spert_size_embeddings.weight\n",
      "  spert_entity_classifier.weight\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.14it/s]\n",
      "\u001b[32m2025-05-24 21:07:12,922 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=396,2471005870178057331).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 757249.51it/s]\n",
      "\u001b[32m2025-05-24 21:07:12,932 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,933 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,934 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,935 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,936 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,936 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,937 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,937 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,939 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,940 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,940 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,940 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,942 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,942 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,942 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,951 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,952 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.9383, 1.0000]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:12,952 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,485 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,485 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4683 ± 0.1596\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m -   Median: 0.4960\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m -   Range: [-0.2306, 0.7396]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3266 ± 0.1163\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m -   Median: 0.3440\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m -   Range: [-0.1536, 0.5385]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,486 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9648 ± 0.0109\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m -   Median: 0.9669\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m -   Range: [0.9212, 0.9850]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.8874 ± 0.1181\u001b[0m, Median: 0.9215, Range: [0.0596, 0.9995]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8704 ± 0.1121\u001b[0m, Median: 0.8940, Range: [0.0933, 0.9980]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,487 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8620 ± 0.1095\u001b[0m, Median: 0.8843, Range: [0.0695, 0.9951]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,488 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8551 ± 0.1088\u001b[0m, Median: 0.8732, Range: [0.0617, 0.9951]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,488 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8490 ± 0.1088\u001b[0m, Median: 0.8690, Range: [0.0591, 0.9945]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,488 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8440 ± 0.1086\u001b[0m, Median: 0.8665, Range: [0.0696, 0.9942]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,488 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8395 ± 0.1064\u001b[0m, Median: 0.8605, Range: [0.1126, 0.9862]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,488 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8333 ± 0.1059\u001b[0m, Median: 0.8520, Range: [0.1266, 0.9838]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,489 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8290 ± 0.1060\u001b[0m, Median: 0.8484, Range: [0.1253, 0.9821]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,489 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8256 ± 0.1049\u001b[0m, Median: 0.8447, Range: [0.1515, 0.9817]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,489 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8495\u001b[0m\n",
      "\u001b[32m2025-05-24 21:07:20,489 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20230928_110825_MIMIC-CXR(triplets+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:08:16,449 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:16,451 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:16,451 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:16,465 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:16,465 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:16,465 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:16,479 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 597559.46it/s]\n",
      "\u001b[32m2025-05-24 21:08:16,815 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:18,196 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:18,196 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_166_sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9026.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:08:31,951 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 237 keys, intersection has 210 keys, union has 237 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  fact_decoder.decoder.layers.0.norm3.bias\n",
      "  fact_decoder.decoder.layers.0.norm1.bias\n",
      "  fact_decoder.decoder.layers.0.norm2.bias\n",
      "  fact_decoder.decoder.layers.0.multihead_attn.in_proj_bias\n",
      "  fact_decoder.decoder.layers.0.norm2.weight\n",
      "  fact_decoder.decoder.layers.0.self_attn.out_proj.bias\n",
      "  fact_decoder.decoder.layers.0.linear1.weight\n",
      "  fact_decoder.decoder.layers.0.norm1.weight\n",
      "  fact_decoder.start_idx\n",
      "  bert.embeddings.position_ids\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.39it/s]\n",
      "\u001b[32m2025-05-24 21:08:35,543 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=400,3939502591827249705).pkl\u001b[0m\n",
      "100%|██████████████████████████████████| 3988/3988 [00:00<00:00, 1684988.85it/s]\n",
      "\u001b[32m2025-05-24 21:08:35,549 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,550 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,551 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,552 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,552 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,553 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,554 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,554 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,555 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,556 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,556 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,556 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,558 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,558 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,558 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,565 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,567 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8815, 0.9886]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:35,567 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,198 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,198 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,198 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4690 ± 0.1686\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,198 - INFO - __main__\u001b[0m -   Median: 0.4718\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,198 - INFO - __main__\u001b[0m -   Range: [-0.1246, 0.7845]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3273 ± 0.1243\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m -   Median: 0.3243\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m -   Range: [-0.0908, 0.5834]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9671 ± 0.0097\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m -   Median: 0.9697\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m -   Range: [0.9252, 0.9847]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,199 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9370 ± 0.0624\u001b[0m, Median: 0.9564, Range: [0.6073, 0.9990]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9205 ± 0.0668\u001b[0m, Median: 0.9369, Range: [0.4700, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9116 ± 0.0681\u001b[0m, Median: 0.9255, Range: [0.5065, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.9050 ± 0.0689\u001b[0m, Median: 0.9194, Range: [0.5277, 0.9976]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8983 ± 0.0701\u001b[0m, Median: 0.9138, Range: [0.5278, 0.9964]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8919 ± 0.0719\u001b[0m, Median: 0.9030, Range: [0.5132, 0.9967]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8872 ± 0.0729\u001b[0m, Median: 0.8989, Range: [0.5246, 0.9924]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8809 ± 0.0741\u001b[0m, Median: 0.8950, Range: [0.4971, 0.9853]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8758 ± 0.0750\u001b[0m, Median: 0.8884, Range: [0.4897, 0.9821]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8710 ± 0.0758\u001b[0m, Median: 0.8829, Range: [0.4888, 0.9798]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,201 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8979\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:43,202 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20231010_210936_MIMIC-CXR(triplets+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:08:52,859 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:52,860 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_125012_MIMIC-CXR(triplets+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:52,860 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:52,875 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:52,875 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:52,875 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:52,887 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_116_nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9199.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 608007.14it/s]\n",
      "\u001b[32m2025-05-24 21:08:53,200 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:54,591 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_116_nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9199.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:08:54,591 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_125012_MIMIC-CXR(triplets+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_116_nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9199.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:09:07,960 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 215 keys, intersection has 210 keys, union has 215 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  bert.embeddings.position_ids\n",
      "  nli_classifier.bias\n",
      "  nli_hidden_layer.bias\n",
      "  nli_hidden_layer.weight\n",
      "  nli_classifier.weight\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.00it/s]\n",
      "\u001b[32m2025-05-24 21:09:11,600 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=392,543079116167501952).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 775038.66it/s]\n",
      "\u001b[32m2025-05-24 21:09:11,612 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,612 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,614 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,615 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,615 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,616 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,616 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,617 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,618 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,618 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,619 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,619 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,621 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,621 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,621 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,630 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,631 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.9285, 0.9993]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:11,631 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,197 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,197 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,197 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4476 ± 0.1292\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m -   Median: 0.4541\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m -   Range: [-0.1459, 0.7405]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3094 ± 0.0938\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m -   Median: 0.3123\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m -   Range: [-0.0967, 0.5329]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,198 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9641 ± 0.0101\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,199 - INFO - __main__\u001b[0m -   Median: 0.9650\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,199 - INFO - __main__\u001b[0m -   Range: [0.9186, 0.9861]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,199 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,199 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9022 ± 0.0986\u001b[0m, Median: 0.9363, Range: [0.3474, 0.9994]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,199 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8912 ± 0.0924\u001b[0m, Median: 0.9242, Range: [0.4560, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,199 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8817 ± 0.0943\u001b[0m, Median: 0.9048, Range: [0.4706, 0.9971]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8756 ± 0.0922\u001b[0m, Median: 0.8973, Range: [0.4935, 0.9965]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8697 ± 0.0928\u001b[0m, Median: 0.8906, Range: [0.4994, 0.9953]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8651 ± 0.0932\u001b[0m, Median: 0.8857, Range: [0.5157, 0.9968]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8615 ± 0.0924\u001b[0m, Median: 0.8840, Range: [0.5157, 0.9949]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,200 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8568 ± 0.0926\u001b[0m, Median: 0.8780, Range: [0.5159, 0.9935]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8529 ± 0.0919\u001b[0m, Median: 0.8725, Range: [0.5033, 0.9880]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,201 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8484 ± 0.0920\u001b[0m, Median: 0.8643, Range: [0.4923, 0.9888]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,201 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8705\u001b[0m\n",
      "\u001b[32m2025-05-24 21:09:19,201 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_125012_MIMIC-CXR(triplets+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:12:28,290 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:28,291 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_080646_MIMIC-CXR(triplets+entcon)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:28,291 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:28,305 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:28,305 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:28,306 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:28,324 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_98_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9440.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 604557.05it/s]\n",
      "\u001b[32m2025-05-24 21:12:28,641 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:30,350 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_98_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9440.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:30,351 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_080646_MIMIC-CXR(triplets+entcon)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_98_encc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9440.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:12:43,351 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 211 keys, intersection has 210 keys, union has 211 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  bert.embeddings.position_ids\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.43it/s]\n",
      "\u001b[32m2025-05-24 21:12:47,119 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=394,859002337683317134).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 760278.37it/s]\n",
      "\u001b[32m2025-05-24 21:12:47,131 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,131 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,132 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,133 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,134 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,134 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,135 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,136 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,136 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,137 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,138 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,138 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,139 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,139 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,140 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,149 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,150 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.9869, 0.9998]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:47,150 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,093 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,093 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,093 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.5187 ± 0.1511\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,093 - INFO - __main__\u001b[0m -   Median: 0.5446\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,093 - INFO - __main__\u001b[0m -   Range: [-0.2162, 0.7880]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,093 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3643 ± 0.1126\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   Median: 0.3802\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   Range: [-0.1437, 0.5829]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9669 ± 0.0121\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   Median: 0.9693\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   Range: [0.8995, 0.9878]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,094 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9063 ± 0.1015\u001b[0m, Median: 0.9337, Range: [0.0840, 0.9985]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,095 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8920 ± 0.0979\u001b[0m, Median: 0.9179, Range: [0.1340, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,095 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8848 ± 0.0977\u001b[0m, Median: 0.9060, Range: [0.1480, 0.9945]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,095 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8792 ± 0.0972\u001b[0m, Median: 0.8982, Range: [0.1542, 0.9935]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,095 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8739 ± 0.0975\u001b[0m, Median: 0.8927, Range: [0.1513, 0.9926]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,095 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8695 ± 0.0981\u001b[0m, Median: 0.8900, Range: [0.1451, 0.9923]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,096 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8660 ± 0.0969\u001b[0m, Median: 0.8859, Range: [0.1464, 0.9881]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,096 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8608 ± 0.0967\u001b[0m, Median: 0.8809, Range: [0.1481, 0.9866]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,096 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8572 ± 0.0969\u001b[0m, Median: 0.8758, Range: [0.1364, 0.9850]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,096 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8543 ± 0.0956\u001b[0m, Median: 0.8719, Range: [0.1516, 0.9827]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,096 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8744\u001b[0m\n",
      "\u001b[32m2025-05-24 21:12:55,096 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_080646_MIMIC-CXR(triplets+entcon)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+NLI+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:13:10,145 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:10,147 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240128_173216_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:10,147 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:10,161 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:10,161 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:10,161 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:10,166 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_92_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9209.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 600606.26it/s]\n",
      "\u001b[32m2025-05-24 21:13:10,488 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:11,839 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_92_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9209.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:11,839 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240128_173216_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_92_encc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9209.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:13:24,896 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 215 keys, intersection has 210 keys, union has 215 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  nli_hidden_layer.bias\n",
      "  nli_classifier.bias\n",
      "  nli_classifier.weight\n",
      "  nli_hidden_layer.weight\n",
      "  bert.embeddings.position_ids\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.20it/s]\n",
      "\u001b[32m2025-05-24 21:13:28,472 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=403,2373524718818758725).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 761143.26it/s]\n",
      "\u001b[32m2025-05-24 21:13:28,483 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,483 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,485 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,485 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,486 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,487 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,487 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,488 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,489 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,490 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,490 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,490 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,492 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,492 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,492 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,500 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,502 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.9267, 0.9998]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:28,502 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4485 ± 0.1614\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m -   Median: 0.4649\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m -   Range: [-0.1781, 0.7820]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,164 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3116 ± 0.1176\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m -   Median: 0.3207\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m -   Range: [-0.1202, 0.5795]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9599 ± 0.0156\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m -   Median: 0.9632\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m -   Range: [0.8921, 0.9870]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,165 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.8856 ± 0.0999\u001b[0m, Median: 0.9109, Range: [0.2569, 0.9992]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,166 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8686 ± 0.0928\u001b[0m, Median: 0.8947, Range: [0.3786, 0.9909]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,166 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8587 ± 0.0915\u001b[0m, Median: 0.8777, Range: [0.3771, 0.9869]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,166 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8505 ± 0.0907\u001b[0m, Median: 0.8718, Range: [0.3604, 0.9845]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,166 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8436 ± 0.0905\u001b[0m, Median: 0.8633, Range: [0.3501, 0.9827]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,166 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8376 ± 0.0914\u001b[0m, Median: 0.8559, Range: [0.3437, 0.9817]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,167 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8335 ± 0.0905\u001b[0m, Median: 0.8517, Range: [0.3432, 0.9799]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,167 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8274 ± 0.0906\u001b[0m, Median: 0.8421, Range: [0.3386, 0.9705]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,167 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8227 ± 0.0915\u001b[0m, Median: 0.8391, Range: [0.3187, 0.9702]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,167 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8193 ± 0.0917\u001b[0m, Median: 0.8326, Range: [0.3222, 0.9679]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,167 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8447\u001b[0m\n",
      "\u001b[32m2025-05-24 21:13:36,167 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240128_173216_MIMIC-CXR(triplets+entcon+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:14:11,743 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:11,744 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_213433_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:11,745 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:11,759 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:11,759 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:11,759 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:11,760 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_184_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9569.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 605038.14it/s]\n",
      "\u001b[32m2025-05-24 21:14:12,090 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:13,473 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_184_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9569.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:13,473 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_213433_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_184_cacc+chf1+chf1+cscc+encc+hscc+nlcc+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9569.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:14:27,209 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 232 keys, intersection has 210 keys, union has 232 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  spert_entity_classifier.weight\n",
      "  chest_imagenome_obs_classifier.weight\n",
      "  chest_imagenome_anatloc_classifier.weight\n",
      "  spert_size_embeddings.weight\n",
      "  category_classifier.bias\n",
      "  spert_entity_classifier.bias\n",
      "  health_status_classifier.weight\n",
      "  category_classifier.weight\n",
      "  chest_imagenome_anatloc_classifier.bias\n",
      "  bert.embeddings.position_ids\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.17it/s]\n",
      "\u001b[32m2025-05-24 21:14:30,698 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=452,830637656331350842).pkl\u001b[0m\n",
      "100%|██████████████████████████████████| 3988/3988 [00:00<00:00, 1610367.22it/s]\n",
      "\u001b[32m2025-05-24 21:14:30,704 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,704 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,706 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,707 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,707 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,708 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,708 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,709 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,710 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,711 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,712 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,712 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,713 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,713 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,713 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,716 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,717 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.7782, 0.9976]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:30,717 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,289 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,289 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.4078 ± 0.1479\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   Median: 0.4262\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   Range: [-0.0683, 0.6922]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.2803 ± 0.1055\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   Median: 0.2893\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   Range: [-0.0473, 0.4997]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,290 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9647 ± 0.0103\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,291 - INFO - __main__\u001b[0m -   Median: 0.9662\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,291 - INFO - __main__\u001b[0m -   Range: [0.9144, 0.9830]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,291 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,291 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9367 ± 0.0706\u001b[0m, Median: 0.9630, Range: [0.5407, 0.9992]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,291 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9182 ± 0.0777\u001b[0m, Median: 0.9410, Range: [0.5353, 0.9980]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,291 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9073 ± 0.0814\u001b[0m, Median: 0.9290, Range: [0.4966, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,292 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8984 ± 0.0822\u001b[0m, Median: 0.9175, Range: [0.5289, 0.9970]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,292 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8897 ± 0.0824\u001b[0m, Median: 0.9097, Range: [0.4790, 0.9972]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,292 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8833 ± 0.0827\u001b[0m, Median: 0.9042, Range: [0.4656, 0.9948]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,292 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8775 ± 0.0827\u001b[0m, Median: 0.8943, Range: [0.4748, 0.9951]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,292 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8707 ± 0.0830\u001b[0m, Median: 0.8886, Range: [0.4785, 0.9909]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,292 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8652 ± 0.0833\u001b[0m, Median: 0.8833, Range: [0.4830, 0.9907]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,293 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8605 ± 0.0832\u001b[0m, Median: 0.8766, Range: [0.4891, 0.9898]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,293 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8908\u001b[0m\n",
      "\u001b[32m2025-05-24 21:14:38,293 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_213433_MIMIC-CXR(triplets+classif+entcont+nli+radgraph)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:15:39,554 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:39,556 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_151525_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:39,556 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:39,570 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:39,570 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:39,571 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:39,571 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_98_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9322.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 602683.73it/s]\n",
      "\u001b[32m2025-05-24 21:15:39,891 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:41,795 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_98_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9322.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:41,796 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_151525_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_98_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9322.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:15:56,346 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 253 keys, intersection has 210 keys, union has 253 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  nli_hidden_layer.bias\n",
      "  chest_imagenome_obs_classifier.bias\n",
      "  fact_decoder.decoder.layers.0.self_attn.out_proj.bias\n",
      "  fact_decoder.decoder.layers.0.multihead_attn.out_proj.bias\n",
      "  fact_decoder.pos_encoder.pe\n",
      "  health_status_classifier.weight\n",
      "  fact_decoder.decoder.layers.0.self_attn.in_proj_weight\n",
      "  fact_decoder.decoder.layers.0.norm3.weight\n",
      "  fact_decoder.decoder.layers.0.norm1.weight\n",
      "  fact_decoder.embedding_table.weight\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 17.84it/s]\n",
      "\u001b[32m2025-05-24 21:15:59,924 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=454,2490515629853320319).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 766655.25it/s]\n",
      "\u001b[32m2025-05-24 21:15:59,935 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,935 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,936 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,937 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,938 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,940 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,941 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,941 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,942 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,943 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,943 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,943 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,945 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,945 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,945 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,955 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,956 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8059, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:15:59,956 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,623 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,623 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,623 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3817 ± 0.1373\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,623 - INFO - __main__\u001b[0m -   Median: 0.3983\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,623 - INFO - __main__\u001b[0m -   Range: [-0.0446, 0.6735]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,623 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.2619 ± 0.0977\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m -   Median: 0.2713\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m -   Range: [-0.0309, 0.4857]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9631 ± 0.0114\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m -   Median: 0.9653\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m -   Range: [0.9079, 0.9810]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,624 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9333 ± 0.0705\u001b[0m, Median: 0.9569, Range: [0.5907, 0.9990]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9147 ± 0.0754\u001b[0m, Median: 0.9382, Range: [0.5653, 0.9982]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9011 ± 0.0797\u001b[0m, Median: 0.9216, Range: [0.5458, 0.9970]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8920 ± 0.0819\u001b[0m, Median: 0.9087, Range: [0.5508, 0.9968]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,625 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8824 ± 0.0824\u001b[0m, Median: 0.8973, Range: [0.5423, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8767 ± 0.0819\u001b[0m, Median: 0.8910, Range: [0.5403, 0.9949]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8708 ± 0.0819\u001b[0m, Median: 0.8843, Range: [0.5562, 0.9955]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8634 ± 0.0827\u001b[0m, Median: 0.8746, Range: [0.5595, 0.9936]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8577 ± 0.0834\u001b[0m, Median: 0.8711, Range: [0.5548, 0.9928]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8524 ± 0.0841\u001b[0m, Median: 0.8642, Range: [0.5456, 0.9906]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8844\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:07,626 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240129_151525_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:16:44,058 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:44,060 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_235928_MIMIC-CXR(triplets+classif+entcont+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:44,060 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:44,074 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:44,074 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:44,074 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:44,095 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9472.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 612213.03it/s]\n",
      "\u001b[32m2025-05-24 21:16:44,418 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:46,099 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9472.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:46,100 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_235928_MIMIC-CXR(triplets+classif+entcont+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9472.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:16:54,707 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 227 keys, intersection has 210 keys, union has 227 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  chest_imagenome_obs_classifier.weight\n",
      "  aux_task_hidden_layer.bias\n",
      "  comparison_status_classifier.bias\n",
      "  nli_hidden_layer.weight\n",
      "  chest_imagenome_anatloc_classifier.bias\n",
      "  chest_imagenome_obs_classifier.bias\n",
      "  comparison_status_classifier.weight\n",
      "  nli_classifier.bias\n",
      "  bert.embeddings.position_ids\n",
      "  health_status_classifier.bias\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.23it/s]\n",
      "\u001b[32m2025-05-24 21:16:58,234 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=438,1902595230268154243).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 601491.76it/s]\n",
      "\u001b[32m2025-05-24 21:16:58,247 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,247 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,248 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,249 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,250 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,250 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,251 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,252 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,252 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,253 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,254 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,254 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,255 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,255 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,255 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,262 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,263 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.7563, 0.9985]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:16:58,263 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,866 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,866 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3340 ± 0.1283\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m -   Median: 0.3320\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m -   Range: [-0.0256, 0.6453]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.2280 ± 0.0903\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m -   Median: 0.2260\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m -   Range: [-0.0198, 0.4569]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,867 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9604 ± 0.0121\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m -   Median: 0.9619\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m -   Range: [0.9126, 0.9807]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9103 ± 0.0978\u001b[0m, Median: 0.9439, Range: [0.2694, 0.9993]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.8893 ± 0.1006\u001b[0m, Median: 0.9117, Range: [0.2893, 0.9971]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,868 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8747 ± 0.1023\u001b[0m, Median: 0.8981, Range: [0.3035, 0.9966]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,869 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8650 ± 0.1007\u001b[0m, Median: 0.8924, Range: [0.3507, 0.9971]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,869 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8537 ± 0.1015\u001b[0m, Median: 0.8739, Range: [0.3514, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,869 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8470 ± 0.1014\u001b[0m, Median: 0.8692, Range: [0.3670, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,869 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8411 ± 0.1015\u001b[0m, Median: 0.8606, Range: [0.3706, 0.9981]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,869 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8339 ± 0.1015\u001b[0m, Median: 0.8479, Range: [0.3923, 0.9918]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,870 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8285 ± 0.1010\u001b[0m, Median: 0.8389, Range: [0.3921, 0.9906]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,870 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8232 ± 0.1006\u001b[0m, Median: 0.8324, Range: [0.4169, 0.9876]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,870 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8567\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:05,870 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_235928_MIMIC-CXR(triplets+classif+entcont+nli)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+ER+SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-24 21:17:20,280 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:20,281 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_184445_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:20,281 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:20,296 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:20,296 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:20,296 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:20,304 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_91_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9337.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 605454.24it/s]\n",
      "\u001b[32m2025-05-24 21:17:20,629 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:22,009 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_91_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9337.pt']\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:22,010 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_184445_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_91_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9337.pt\u001b[0m\n",
      "\u001b[33m2025-05-24 21:17:31,280 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 258 keys, intersection has 210 keys, union has 258 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  comparison_status_classifier.bias\n",
      "  nli_hidden_layer.weight\n",
      "  fact_decoder.decoder.layers.0.self_attn.out_proj.weight\n",
      "  aux_task_hidden_layer.bias\n",
      "  fact_decoder.decoder.layers.0.linear1.weight\n",
      "  spert_size_embeddings.weight\n",
      "  fact_decoder.decoder.layers.0.multihead_attn.in_proj_weight\n",
      "  chest_imagenome_obs_classifier.bias\n",
      "  chest_imagenome_anatloc_classifier.bias\n",
      "  comparison_status_classifier.weight\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 18.00it/s]\n",
      "\u001b[32m2025-05-24 21:17:34,824 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=468,3107956748600071578).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 769052.15it/s]\n",
      "\u001b[32m2025-05-24 21:17:34,835 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,835 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,837 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,838 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,838 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,839 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,840 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,840 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,841 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,842 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,842 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,842 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,844 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,844 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,844 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,853 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,854 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8146, 0.9971]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:34,854 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,375 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3738 ± 0.1379\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m -   Median: 0.3880\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m -   Range: [-0.0493, 0.6702]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.2563 ± 0.0980\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,376 - INFO - __main__\u001b[0m -   Median: 0.2634\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m -   Range: [-0.0350, 0.4818]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9626 ± 0.0116\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m -   Median: 0.9650\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m -   Range: [0.9018, 0.9809]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,377 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9300 ± 0.0738\u001b[0m, Median: 0.9572, Range: [0.5927, 0.9990]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,378 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9109 ± 0.0792\u001b[0m, Median: 0.9351, Range: [0.5705, 0.9982]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,378 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8974 ± 0.0835\u001b[0m, Median: 0.9190, Range: [0.5672, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,378 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8884 ± 0.0857\u001b[0m, Median: 0.9070, Range: [0.5317, 0.9972]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,378 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8790 ± 0.0859\u001b[0m, Median: 0.8934, Range: [0.5546, 0.9976]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,378 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8735 ± 0.0853\u001b[0m, Median: 0.8859, Range: [0.5400, 0.9958]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,379 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8679 ± 0.0846\u001b[0m, Median: 0.8824, Range: [0.5486, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,379 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8606 ± 0.0851\u001b[0m, Median: 0.8698, Range: [0.5626, 0.9937]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,379 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8551 ± 0.0858\u001b[0m, Median: 0.8654, Range: [0.5351, 0.9926]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,379 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8499 ± 0.0863\u001b[0m, Median: 0.8627, Range: [0.5331, 0.9902]\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,379 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8813\u001b[0m\n",
      "\u001b[32m2025-05-24 21:17:42,380 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240207_184445_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+ER+SD) v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-25 08:59:36,728 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:36,730 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240629_084405_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\n",
      "   save_worst_queries_for_inspection: True\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:36,730 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:36,745 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:36,745 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:36,745 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:36,745 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_196_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+spss+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)=0.9189.pt']\u001b[0m\n",
      "  0%|                                                  | 0/3988 [00:00<?, ?it/s]\u001b[32m2025-05-25 08:59:36,987 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading cached text embeddings from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=469,680486110513564934).pkl\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:37,946 - INFO - medvqa.models.huggingface_utils\u001b[0m - len(self.cache[\"hashes\"]) = 1987476\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:37,947 - INFO - medvqa.models.huggingface_utils\u001b[0m - self.cache[\"embeddings\"].shape = (1987476, 128)\u001b[0m\n",
      "100%|█████████████████████████████████████| 3988/3988 [00:01<00:00, 2471.03it/s]\n",
      "\u001b[32m2025-05-25 08:59:38,603 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,603 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,603 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,604 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,605 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,605 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,606 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,607 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,607 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,608 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,609 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,609 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,610 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,610 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,610 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,615 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,616 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.7949, 0.9982]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:38,616 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,365 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,365 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,365 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3799 ± 0.1346\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,365 - INFO - __main__\u001b[0m -   Median: 0.3947\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,365 - INFO - __main__\u001b[0m -   Range: [0.0177, 0.6883]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,365 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.2604 ± 0.0957\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m -   Median: 0.2696\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m -   Range: [0.0113, 0.4979]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9629 ± 0.0110\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m -   Median: 0.9652\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m -   Range: [0.9106, 0.9817]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,366 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,367 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9306 ± 0.0706\u001b[0m, Median: 0.9519, Range: [0.5998, 0.9991]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,367 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9114 ± 0.0750\u001b[0m, Median: 0.9338, Range: [0.6158, 0.9975]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,367 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.8977 ± 0.0796\u001b[0m, Median: 0.9171, Range: [0.6095, 0.9964]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,367 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.8885 ± 0.0818\u001b[0m, Median: 0.9073, Range: [0.5649, 0.9970]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,367 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.8784 ± 0.0826\u001b[0m, Median: 0.8948, Range: [0.5325, 0.9972]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.8725 ± 0.0827\u001b[0m, Median: 0.8860, Range: [0.5331, 0.9959]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8667 ± 0.0822\u001b[0m, Median: 0.8784, Range: [0.5742, 0.9935]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8596 ± 0.0830\u001b[0m, Median: 0.8696, Range: [0.5855, 0.9915]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8536 ± 0.0837\u001b[0m, Median: 0.8642, Range: [0.5612, 0.9906]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8483 ± 0.0841\u001b[0m, Median: 0.8628, Range: [0.5625, 0.9858]\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.8807\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,368 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n",
      "\u001b[32m2025-05-25 08:59:46,369 - INFO - __main__\u001b[0m - Saving worst queries for inspection to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_worst_queries_for_inspection_20250525_085946.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20240629_084405_MIMIC-CXR(triplets+classif+entcont+nli+radgraph+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100 \\\n",
    "--save_worst_queries_for_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+SD) v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-02 17:37:36,336 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:36,338 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250602_122454_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\n",
      "   save_worst_queries_for_inspection: True\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:36,338 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:36,352 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:36,352 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:36,352 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:36,352 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9073.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 510884.96it/s]\n",
      "\u001b[32m2025-06-02 17:37:36,620 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:38,464 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9073.pt']\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:38,464 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250602_122454_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_193_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9073.pt\u001b[0m\n",
      "\u001b[33m2025-06-02 17:37:40,131 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 252 keys, intersection has 210 keys, union has 252 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  nli_hidden_layer.bias\n",
      "  fact_decoder.W_vocab.bias\n",
      "  fact_decoder.decoder.layers.0.self_attn.in_proj_bias\n",
      "  chest_imagenome_anatloc_classifier.weight\n",
      "  fact_decoder.decoder.layers.0.multihead_attn.in_proj_bias\n",
      "  aux_task_hidden_layer.weight\n",
      "  health_status_classifier.bias\n",
      "  fact_decoder.decoder.layers.0.norm2.weight\n",
      "  fact_decoder.decoder.layers.0.norm1.weight\n",
      "  health_status_classifier.weight\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 15.39it/s]\n",
      "\u001b[32m2025-06-02 17:37:43,969 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=460,2823790497979246262).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 609913.74it/s]\n",
      "\u001b[32m2025-06-02 17:37:43,982 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,982 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,984 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,985 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,986 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,989 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,990 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,991 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,991 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,992 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,993 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,993 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,995 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,995 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:43,995 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:44,018 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:44,019 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8486, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:44,019 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.5031 ± 0.1342\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m -   Median: 0.5117\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m -   Range: [0.0877, 0.7752]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,189 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3516 ± 0.1008\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m -   Median: 0.3552\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m -   Range: [0.0582, 0.5784]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9714 ± 0.0080\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m -   Median: 0.9730\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m -   Range: [0.9319, 0.9850]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,190 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9466 ± 0.0566\u001b[0m, Median: 0.9652, Range: [0.5921, 0.9993]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,191 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9318 ± 0.0578\u001b[0m, Median: 0.9470, Range: [0.5988, 0.9981]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,191 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9223 ± 0.0601\u001b[0m, Median: 0.9327, Range: [0.5823, 0.9979]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,191 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.9153 ± 0.0601\u001b[0m, Median: 0.9252, Range: [0.6458, 0.9980]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,191 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.9078 ± 0.0613\u001b[0m, Median: 0.9158, Range: [0.6670, 0.9954]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,191 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.9024 ± 0.0613\u001b[0m, Median: 0.9139, Range: [0.6664, 0.9958]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,192 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8976 ± 0.0609\u001b[0m, Median: 0.9084, Range: [0.6451, 0.9968]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,192 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8915 ± 0.0614\u001b[0m, Median: 0.9024, Range: [0.6155, 0.9959]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,192 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8862 ± 0.0621\u001b[0m, Median: 0.8956, Range: [0.5868, 0.9953]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,192 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8818 ± 0.0626\u001b[0m, Median: 0.8878, Range: [0.5741, 0.9924]\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,192 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.9083\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,192 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n",
      "\u001b[32m2025-06-02 17:37:52,193 - INFO - __main__\u001b[0m - Saving worst queries for inspection to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_worst_queries_for_inspection_20250602_173752.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250602_122454_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100 \\\n",
    "--save_worst_queries_for_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CXR Fact Encoder (T+C+NLI+EC+SD) v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-11 01:47:40,663 - INFO - root\u001b[0m - Logging configured (Color: True).\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:40,665 - INFO - medvqa.utils.common\u001b[0m - \n",
      "script's arguments:\n",
      "   evaluation_mode: padchest_gr_mscxr_custom\n",
      "   model_name: microsoft/BiomedVLP-CXR-BERT-specialized\n",
      "   device: cuda\n",
      "   batch_size: 100\n",
      "   num_workers: 4\n",
      "   model_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250610_213953_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\n",
      "   distance_metric: cosine\n",
      "   average_token_embeddings: False\n",
      "   chest_imagenome_sentence2labels_gold_filepath: None\n",
      "   revised_groundings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\n",
      "   num_query_samples: 300\n",
      "   save_worst_queries_for_inspection: True\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:40,665 - INFO - __main__\u001b[0m - Loading evaluation data from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:40,678 - INFO - __main__\u001b[0m - len(query_phrases): 300\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:40,679 - INFO - __main__\u001b[0m - len(candidate_phrases): 3688\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:40,679 - INFO - __main__\u001b[0m - metrics.keys(): ['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1']\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:40,679 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_154_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9070.pt']\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 855901.57it/s]\n",
      "\u001b[32m2025-06-11 01:47:40,938 - INFO - medvqa.models.huggingface_utils\u001b[0m - Computing embeddings for 3988 new texts\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:43,641 - INFO - medvqa.models.checkpoint\u001b[0m - checkpoint_names = ['checkpoint_154_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9070.pt']\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:43,641 - INFO - medvqa.models.huggingface_utils\u001b[0m - Loading model weights from /mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250610_213953_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)/checkpoint_154_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9070.pt\u001b[0m\n",
      "\u001b[33m2025-06-11 01:47:44,532 - WARNING - medvqa.models.checkpoint\u001b[0m - model state dict has 210 keys, loaded state dict has 252 keys, intersection has 210 keys, union has 252 keys.\n",
      "Examples of keys in loaded state dict but not in model:\n",
      "  fact_decoder.decoder.layers.0.self_attn.out_proj.bias\n",
      "  fact_decoder.decoder.layers.0.norm2.bias\n",
      "  fact_decoder.decoder.layers.0.self_attn.in_proj_weight\n",
      "  aux_task_hidden_layer.weight\n",
      "  fact_decoder.decoder.layers.0.linear1.bias\n",
      "  fact_decoder.decoder.layers.0.multihead_attn.out_proj.weight\n",
      "  category_classifier.weight\n",
      "  chest_imagenome_anatloc_classifier.bias\n",
      "  fact_decoder.decoder.layers.0.linear1.weight\n",
      "  fact_decoder_input_layer.weight\u001b[0m\n",
      "100%|███████████████████████████████████████████| 40/40 [00:02<00:00, 13.54it/s]\n",
      "\u001b[32m2025-06-11 01:47:48,703 - INFO - medvqa.models.huggingface_utils\u001b[0m - Saving updated cache to /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/text_embeddings_cache(hash=460,3706359848383981295).pkl\u001b[0m\n",
      "100%|███████████████████████████████████| 3988/3988 [00:00<00:00, 744674.76it/s]\n",
      "\u001b[32m2025-06-11 01:47:48,714 - INFO - __main__\u001b[0m - Embeddings shape: (3988, 128)\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,715 - INFO - __main__\u001b[0m - Computing hybrid ground-truth scores by averaging all metrics...\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,716 - INFO - __main__\u001b[0m - Adding bleu1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,717 - INFO - __main__\u001b[0m - Adding rouge_l to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,718 - INFO - __main__\u001b[0m - Adding levenshtein to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,718 - INFO - __main__\u001b[0m - Adding bertscore_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,719 - INFO - __main__\u001b[0m - Adding cxr_bert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,720 - INFO - __main__\u001b[0m - Adding chexbert_cosine to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,720 - INFO - __main__\u001b[0m - Adding radgraph_f1 to hybrid score (shape: (300, 3688))\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,721 - INFO - __main__\u001b[0m - Hybrid metrics_matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,721 - INFO - __main__\u001b[0m - Hybrid score range: [-0.0640, 0.9006]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,722 - INFO - __main__\u001b[0m - Using cosine similarity: normalizing embeddings for dot product equivalence\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,723 - INFO - __main__\u001b[0m - Query embeddings shape: (300, 128)\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,723 - INFO - __main__\u001b[0m - Candidate embeddings shape: (3688, 128)\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,723 - INFO - __main__\u001b[0m - Computing embedding-based similarity scores...\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,749 - INFO - __main__\u001b[0m - Embedding similarity matrix shape: (300, 3688)\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,750 - INFO - __main__\u001b[0m - Embedding similarity range: [-0.8462, 0.9968]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:48,751 - INFO - __main__\u001b[0m - Computing ranking evaluation metrics...\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,464 - INFO - __main__\u001b[0m - === RANKING EVALUATION RESULTS ===\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,464 - INFO - __main__\u001b[0m - \u001b[1;35mSpearman Rank Correlation:\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,465 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.5143 ± 0.1366\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,465 - INFO - __main__\u001b[0m -   Median: 0.5245\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,465 - INFO - __main__\u001b[0m -   Range: [0.0746, 0.7788]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,465 - INFO - __main__\u001b[0m - \u001b[1;35mKendall Tau Correlation:\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,465 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.3603 ± 0.1029\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,465 - INFO - __main__\u001b[0m -   Median: 0.3641\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m -   Range: [0.0495, 0.5823]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m - \u001b[1;35mNDCG Score:\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m -   \u001b[1;35mMean: 0.9713 ± 0.0090\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m -   Median: 0.9730\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m -   Range: [0.9267, 0.9854]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m - \u001b[1;35mAUC@K (Area Under Curve for Top-K):\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,466 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@10: Mean: 0.9473 ± 0.0515\u001b[0m, Median: 0.9595, Range: [0.6827, 0.9989]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,467 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@20: Mean: 0.9319 ± 0.0540\u001b[0m, Median: 0.9450, Range: [0.6993, 0.9977]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,467 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@30: Mean: 0.9228 ± 0.0557\u001b[0m, Median: 0.9324, Range: [0.6937, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,467 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@40: Mean: 0.9164 ± 0.0559\u001b[0m, Median: 0.9246, Range: [0.6743, 0.9974]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,467 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@50: Mean: 0.9093 ± 0.0576\u001b[0m, Median: 0.9168, Range: [0.6344, 0.9969]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,467 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@60: Mean: 0.9041 ± 0.0577\u001b[0m, Median: 0.9122, Range: [0.6283, 0.9974]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,468 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@70: Mean: 0.8996 ± 0.0575\u001b[0m, Median: 0.9059, Range: [0.6382, 0.9973]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,468 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@80: Mean: 0.8937 ± 0.0587\u001b[0m, Median: 0.9018, Range: [0.6326, 0.9961]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,468 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@90: Mean: 0.8888 ± 0.0598\u001b[0m, Median: 0.8934, Range: [0.6017, 0.9954]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,468 - INFO - __main__\u001b[0m -   \u001b[1;35mAUC@100: Mean: 0.8846 ± 0.0607\u001b[0m, Median: 0.8907, Range: [0.5925, 0.9945]\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,468 - INFO - __main__\u001b[0m -   \u001b[1;35mOverall Mean AUC@K (averaged across K=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]): 0.9098\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,469 - INFO - __main__\u001b[0m - Ranking evaluation completed successfully.\u001b[0m\n",
      "\u001b[32m2025-06-11 01:47:56,469 - INFO - __main__\u001b[0m - Saving worst queries for inspection to /mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_worst_queries_for_inspection_20250611_014756.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../eval_fact_embedding_on_ranking.py \\\n",
    "--evaluation_mode \"padchest_gr_mscxr_custom\" \\\n",
    "--revised_groundings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/chest_imagenome/integrated_llm_revised_phrase_groundings.pkl\" \\\n",
    "--num_query_samples 300 \\\n",
    "--model_name \"microsoft/BiomedVLP-CXR-BERT-specialized\" \\\n",
    "--model_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250610_213953_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\" \\\n",
    "--batch_size 100 \\\n",
    "--save_worst_queries_for_inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'checkpoint_154_cacc+chf1+chf1+cscc+encc+hscc+nlcc+sass+ta0)+ta1)+ta2)+ta0)+ta1)+ta2)+ta3)+ta4)+ta5)+ta6)+ta7)+ta8)=0.9070.pt'\r\n",
      " metadata.json\r\n",
      " metrics_logs.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/fact_embedding/20250610_213953_MIMIC-CXR(triplets+classif+entcont+nli+autoencoder)_FactEncoder(microsoft-BiomedVLP-CXR-BERT-specialized)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from medvqa.utils.files_utils import load_pickle\n",
    "\n",
    "tmp = load_pickle('/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_custom_eval_data(num_query_samples=300).pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['metrics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_queries = load_pickle('/mnt/data/pamessina/workspaces/medvqa-workspace/cache/padchest_gr_mscxr_worst_queries_for_inspection_20250611_014756.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['queries', 'auc_scores'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_queries.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657677039222273 The aortic knob is deformed by a large mediastinal hematoma\n",
      "0.6918567540492067 Fluid within the fissures\n",
      "0.7161880824123329 No definite effusions\n",
      "0.7367287026723689 Minimal basal apical blood flow redistribution unchanged\n",
      "0.7616047851607978 Minimal residual linear opacity likely scar\n",
      "0.7616736551976169 Right-sided cardiac contour obliterated by retrocardiac neo-esophagus\n",
      "0.7665093199026197 Bullous changes in the right lung base\n",
      "0.7696063011241314 Pulmonary hyperinflation due to emphysema\n",
      "0.8062298187285715 Increased opacity projecting over the left first costochondral junction\n",
      "0.8069886761043845 Left upper lobe opacity improving\n",
      "0.8076023521820022 Multiple moderate to severe compression deformities in the mid to lower thoracic spine\n",
      "0.8188245562414469 Patchy left mid lung opacities, infection vs aspiration\n",
      "0.824721076347441 Nodule in the left mid-to-upper lung\n",
      "0.8250068615138056 Mild pleural thickening at the left lung base is noted\n",
      "0.8264953314110567 Minimal atelectasis/scarring at right lung base\n",
      "0.8269728629440708 Left-sided pleural calcifications\n",
      "0.8273011091443108 Patchy opacities at right lung base, possibly atelectasis or scarring\n",
      "0.828167846113401 Subcutaneous emphysema overlying the left supraclavicular soft tissues\n",
      "0.8285772406912507 No left-sided effusion\n",
      "0.8288313260781639 Hazy opacifications in the left and right lower lobes\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(worst_queries['auc_scores'][i], worst_queries['queries'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union, List, Dict, Any\n",
    "\n",
    "def print_top_k_sentences(\n",
    "    evaluation_data: Dict[str, Any],\n",
    "    query_index: int,\n",
    "    metric_input: Union[str, List[str]],\n",
    "    k: int = 5,\n",
    "    weights: Union[List[float], None] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Prints the specified query and its top K candidate sentences based on a single\n",
    "    metric or a weighted average of multiple metrics.\n",
    "\n",
    "    Args:\n",
    "        evaluation_data (dict): The dictionary returned by a function like\n",
    "            `compute_padchest_gr_mscxr_custom_evaluation_data`.\n",
    "            Expected keys: 'query_phrases', 'candidate_phrases', 'metrics'.\n",
    "        query_index (int): The index of the query in `evaluation_data['query_phrases']`.\n",
    "        metric_input (Union[str, List[str]]):\n",
    "            - If a string, it's the name of the single metric to use for ranking\n",
    "              (e.g., 'bleu1', 'cxr_bert_cosine').\n",
    "            - If a list of strings, these are the names of metrics to combine.\n",
    "              In this case, `weights` must also be provided.\n",
    "        k (int): The number of top candidate sentences to print. Defaults to 5.\n",
    "        weights (Union[List[float], None]):\n",
    "            - If `metric_input` is a list of metric names, this must be a list\n",
    "              of corresponding weights (floats) of the same length.\n",
    "            - Ignored if `metric_input` is a single string. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Input Validation ---\n",
    "    if not isinstance(evaluation_data, dict):\n",
    "        print(\"Error: evaluation_data must be a dictionary.\")\n",
    "        return\n",
    "    required_keys = ['query_phrases', 'candidate_phrases', 'metrics']\n",
    "    if not all(key in evaluation_data for key in required_keys):\n",
    "        print(f\"Error: evaluation_data is missing one or more required keys: {required_keys}\")\n",
    "        return\n",
    "    if not isinstance(evaluation_data['metrics'], dict):\n",
    "        print(\"Error: evaluation_data['metrics'] must be a dictionary.\")\n",
    "        return\n",
    "\n",
    "    num_queries = len(evaluation_data['query_phrases'])\n",
    "    if not 0 <= query_index < num_queries:\n",
    "        print(f\"Error: query_index {query_index} is out of bounds. Must be between 0 and {num_queries - 1}.\")\n",
    "        return\n",
    "\n",
    "    if not isinstance(k, int) or k <= 0:\n",
    "        print(f\"Error: k must be a positive integer. Got {k}.\")\n",
    "        return\n",
    "\n",
    "    # --- Determine scoring mode and validate metrics/weights ---\n",
    "    is_weighted_average = isinstance(metric_input, list)\n",
    "    display_metric_name = \"\"\n",
    "\n",
    "    if is_weighted_average:\n",
    "        metric_names_list = metric_input\n",
    "        if not isinstance(weights, list) or len(weights) != len(metric_names_list):\n",
    "            print(\"Error: If metric_input is a list, 'weights' must be a list of the same length.\")\n",
    "            return\n",
    "        if not all(isinstance(w, (int, float)) for w in weights):\n",
    "            print(\"Error: All weights must be numeric (int or float).\")\n",
    "            return\n",
    "        for m_name in metric_names_list:\n",
    "            if m_name not in evaluation_data['metrics']:\n",
    "                print(f\"Error: Metric '{m_name}' in metric_input list not found in evaluation_data['metrics'].\")\n",
    "                available_metrics = list(evaluation_data['metrics'].keys())\n",
    "                print(f\"Available metrics are: {available_metrics}\")\n",
    "                return\n",
    "        weight_strs = [f\"{w:.2f}*{m}\" for w, m in zip(weights, metric_names_list)]\n",
    "        display_metric_name = f\"Weighted Average ({', '.join(weight_strs)})\"\n",
    "    else: # Single metric mode\n",
    "        single_metric_name = metric_input\n",
    "        if not isinstance(single_metric_name, str):\n",
    "            print(\"Error: metric_input must be a string or a list of strings.\")\n",
    "            return\n",
    "        if single_metric_name not in evaluation_data['metrics']:\n",
    "            print(f\"Error: Metric '{single_metric_name}' not found in evaluation_data['metrics'].\")\n",
    "            available_metrics = list(evaluation_data['metrics'].keys())\n",
    "            print(f\"Available metrics are: {available_metrics}\")\n",
    "            return\n",
    "        display_metric_name = single_metric_name\n",
    "\n",
    "    # --- Extract Data ---\n",
    "    try:\n",
    "        query_phrase = evaluation_data['query_phrases'][query_index]\n",
    "        candidate_phrases = evaluation_data['candidate_phrases']\n",
    "        num_candidates = len(candidate_phrases)\n",
    "\n",
    "        if num_candidates == 0:\n",
    "            print(\"Warning: There are no candidate phrases to rank.\")\n",
    "            print(f\"\\nQuery (Index {query_index}): \\\"{query_phrase}\\\"\")\n",
    "            return\n",
    "\n",
    "        # Calculate scores to be used for ranking\n",
    "        if is_weighted_average:\n",
    "            scores_to_sort = np.zeros(num_candidates, dtype=np.float32)\n",
    "            for metric_name, weight in zip(metric_names_list, weights):\n",
    "                metric_scores = evaluation_data['metrics'][metric_name][query_index, :]\n",
    "                scores_to_sort += metric_scores * weight\n",
    "        else: # Single metric\n",
    "            scores_to_sort = evaluation_data['metrics'][single_metric_name][query_index, :]\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"Error: Could not access scores for query_index {query_index} and metric(s).\")\n",
    "        # Further details could be printed here if needed\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while extracting/calculating scores: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Rank and Select Top K ---\n",
    "    sorted_candidate_indices = np.argsort(scores_to_sort)[::-1]\n",
    "    actual_k = min(k, num_candidates)\n",
    "\n",
    "    # --- Print Results ---\n",
    "    print(f\"\\n--- Top {actual_k} Sentences for Query (Index {query_index}) using Metric '{display_metric_name}' ---\")\n",
    "    print(f\"Query: \\\"{query_phrase}\\\"\")\n",
    "    print(\"-\" * (len(display_metric_name) + 40)) # Adjust line width\n",
    "\n",
    "    if actual_k == 0:\n",
    "        print(\"No candidates to display (k=0 or no candidates available).\")\n",
    "        return\n",
    "\n",
    "    for i in range(actual_k):\n",
    "        candidate_idx = sorted_candidate_indices[i]\n",
    "        top_candidate_phrase = candidate_phrases[candidate_idx]\n",
    "        # The score displayed is either the single metric score or the final weighted score\n",
    "        top_score_value = scores_to_sort[candidate_idx]\n",
    "        print(f\"{i+1}. Score: {top_score_value:.4f} | Sentence: \\\"{top_candidate_phrase}\\\"\")\n",
    "\n",
    "    print(\"-\" * (len(display_metric_name) + 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stable right mid lung zone airspace opacity',\n",
       " 'Stable vague opacity in the right mid lung, likely post-surgical',\n",
       " 'Subcutaneous emphysema overlying the left supraclavicular soft tissues',\n",
       " 'Subsegmental atelectasis of the left base',\n",
       " 'Subsegmental right mid to lower lung atelectasis',\n",
       " 'Substantial right pneumothorax, unchanged',\n",
       " 'Subtle confluent opacity in the right lower lung field concerning for pneumonia',\n",
       " 'Subtle increase in right base opacity',\n",
       " 'The aorta is unfolded but unchanged',\n",
       " 'The aortic knob is deformed by a large mediastinal hematoma',\n",
       " 'The cardiac silhouette is minimally enlarged',\n",
       " 'The extent of the known hiatal hernia is unchanged',\n",
       " 'The right pleural effusion is persistent',\n",
       " 'There continues to be mild pulmonary vascular congestion',\n",
       " 'There is a healed left clavicle fracture',\n",
       " 'There is a remnant opacity at the right lung base, potentially reflecting either atelectasis or pneumonia',\n",
       " 'There is linear focus of atelectasis in the left lower lung',\n",
       " 'There is mild new vascular congestion',\n",
       " 'There is mild-to-moderate stable cardiomegaly',\n",
       " 'There is new pneumoperitoneum',\n",
       " 'Tiny left pleural effusion, stable',\n",
       " 'Unchanged moderate left pleural effusion',\n",
       " 'Upper lobe hyperlucency consistent with emphysema',\n",
       " 'Vague densities at right lung base suggestive of atelectasis or early infiltrate',\n",
       " 'Vague density projecting over the right mid lung',\n",
       " 'Vague opacification overlying the left fifth rib above the aortic arch',\n",
       " 'Worsened mild-to-moderate pulmonary edema',\n",
       " 'Worsening of left pleural effusion',\n",
       " 'Worsening of the right lower lobe opacity',\n",
       " 'Worsening opacification within the right lung base, possibly compressive atelectasis, aspiration, or infection']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['query_phrases'][-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 30 Sentences for Query (Index 214) using Metric 'Weighted Average (1.00*bleu1, 1.00*rouge_l, 1.00*levenshtein, 1.00*bertscore_f1, 1.00*cxr_bert_cosine, 1.00*chexbert_cosine, 1.00*radgraph_f1)' ---\n",
      "Query: \"Pulmonary hyperinflation due to emphysema\"\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1. Score: 4.3205 | Sentence: \"Pulmonary hyperinflation\"\n",
      "2. Score: 4.2769 | Sentence: \"Signs of pulmonary hyperinflation\"\n",
      "3. Score: 3.6026 | Sentence: \"Signs of lung hyperinflation\"\n",
      "4. Score: 3.5638 | Sentence: \"Signs of hyperinflation\"\n",
      "5. Score: 3.3879 | Sentence: \"Compensatory hyperinflation of the right hemithorax\"\n",
      "6. Score: 3.3294 | Sentence: \"Extensive signs of air trapping due to emphysema predominantly in the upper fields\"\n",
      "7. Score: 3.2568 | Sentence: \"Lung parenchyma with signs of hyperinflation\"\n",
      "8. Score: 3.0011 | Sentence: \"Right hemithorax with compensatory hyperinflation\"\n",
      "9. Score: 2.9241 | Sentence: \"Changes due to left mastectomy\"\n",
      "10. Score: 2.8596 | Sentence: \"Due to bronchiectasis\"\n",
      "11. Score: 2.8459 | Sentence: \"Calcified granulomas in the right pulmonary apex\"\n",
      "12. Score: 2.8213 | Sentence: \"Calcified granulomas in the left pulmonary apex\"\n",
      "13. Score: 2.7036 | Sentence: \"Probably due to thyroid goiter\"\n",
      "14. Score: 2.6925 | Sentence: \"Extensive signs of emphysema with bullae in the upper fields, especially on the right\"\n",
      "15. Score: 2.6748 | Sentence: \"Bilateral pulmonary nodules in relation to known metastases\"\n",
      "16. Score: 2.6458 | Sentence: \"Likely due to goiter\"\n",
      "17. Score: 2.6433 | Sentence: \"Pulmonary nodule in the right upper lobe\"\n",
      "18. Score: 2.6270 | Sentence: \"Subcutaneous emphysema\"\n",
      "19. Score: 2.5936 | Sentence: \"Probably due to intrathoracic goiter\"\n",
      "20. Score: 2.5773 | Sentence: \"Surgical technique for pulmonary bullae\"\n",
      "21. Score: 2.5622 | Sentence: \"Right subcutaneous emphysema\"\n",
      "22. Score: 2.5594 | Sentence: \"Pulmonary nodule in the middle field of the left lung\"\n",
      "23. Score: 2.5570 | Sentence: \"High-density pulmonary micronodule in the LSI related to a known calcified granuloma\"\n",
      "24. Score: 2.5530 | Sentence: \"Deformity of the right rib cage due to multiple fracture calluses\"\n",
      "25. Score: 2.5512 | Sentence: \"Small bilateral pulmonary nodules\"\n",
      "26. Score: 2.5397 | Sentence: \"Nodules related to nipples\"\n",
      "27. Score: 2.5362 | Sentence: \"Increased bibasal density likely related to gynecomastia\"\n",
      "28. Score: 2.5221 | Sentence: \"Some air trapping in relation to signs of COPD\"\n",
      "29. Score: 2.5171 | Sentence: \"Asymmetry in both hemithoraces probably secondary to dorsal scoliosis\"\n",
      "30. Score: 2.4999 | Sentence: \"Multiple bilateral calcified nodules, predominantly in the upper lung fields, already known, related to granulomas\"\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = 'Pulmonary hyperinflation due to emphysema'\n",
    "query_index = tmp['query_phrases'].index(query)\n",
    "print_top_k_sentences(evaluation_data=tmp,\n",
    "                      query_index=query_index,\n",
    "#                       metric_input=['bleu1', 'levenshtein', 'rouge_l', 'bertscore_f1'],\n",
    "#                       weights=[1, 1, 0.5, 0.5],\n",
    "#                       metric_input=['bleu1', 'radgraph_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'bertscore_f1'],\n",
    "#                       weights=[1, 1, 1, 1, 1],\n",
    "                      metric_input=['bleu1', 'rouge_l', 'levenshtein', 'bertscore_f1', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1'],\n",
    "                      weights=[1, 1, 1, 1, 1, 1, 1],\n",
    "#                       metric_input=['bleu1', 'rouge_l', 'levenshtein', 'cxr_bert_cosine', 'chexbert_cosine', 'radgraph_f1'],\n",
    "#                       weights=[1, 1, 1, 1, 1, 1, ],\n",
    "#                       metric_input=['bleu1', 'rouge_l', 'levenshtein', 'cxr_bert_cosine', 'chexbert_cosine'],\n",
    "#                       weights=[1, 1, 1, 1, 1],\n",
    "#                       metric_input=['bertscore_f1'],\n",
    "#                       weights=[1],\n",
    "#                         metric_input=['bleu1', 'rouge_l', 'cxr_bert_cosine', 'chexbert_cosine'],\n",
    "#                         weights=[1, 1, 1, 1],\n",
    "#                         metric_input=['bleu1', 'levenshtein', 'cxr_bert_cosine', 'chexbert_cosine'],\n",
    "#                         weights=[1, 1, 1, 1],\n",
    "#                       metric_input=['bleu1', 'rouge_l'],\n",
    "#                       weights=[1, 1],\n",
    "#                       metric_input=['bleu1', 'cxr_bert_cosine'],\n",
    "#                         weights=[1, 1],\n",
    "                      k=30,                      \n",
    "                     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
