{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.models.vision.visual_modules import create_detectron2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Detectron2 model\n",
      "Loading weights from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "Detectron2 model successfully built\n"
     ]
    }
   ],
   "source": [
    "model = create_detectron2_model(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import  medvqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(medvqa.datasets.image_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_train_loader, build_detection_test_loader\n",
    "\n",
    "from medvqa.datasets.chest_imagenome import CHEST_IMAGENOME_BBOX_NAMES\n",
    "from medvqa.datasets.mimiccxr.mimiccxr_vision_dataset_management import Detectron2AdaptedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.datasets.image_processing import image_size_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in ['train', 'validate']:\n",
    "    DatasetCatalog.register('chest_imagenome_' + d, lambda d=d: Detectron2AdaptedDataset(d, None))\n",
    "    MetadataCatalog.get('chest_imagenome_' + d).set(thing_classes=CHEST_IMAGENOME_BBOX_NAMES)\n",
    "cfg.DATASETS.TRAIN = ('chest_imagenome_train',)\n",
    "cfg.DATASETS.TEST = ('chest_imagenome_validate',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/227835 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227835/227835 [00:03<00:00, 65508.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 992 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_d = DatasetCatalog.get('chest_imagenome_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/227835 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 227835/227835 [00:00<00:00, 682504.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 11 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_d_val = DatasetCatalog.get('chest_imagenome_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1934"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_d_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('chest_imagenome_validate',)\n",
      "  TRAIN: ('chest_imagenome_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    CONV_DIMS: [-1]\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.02\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 16\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 270000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: None\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'MIN_SIZE_TRAIN': (640, 672, 704, 736, 768, 800), 'MIN_SIZE_TRAIN_SAMPLING': 'choice', 'MAX_SIZE_TRAIN': 1333, 'MIN_SIZE_TEST': 800, 'MAX_SIZE_TEST': 1333, 'RANDOM_FLIP': 'horizontal', 'CROP': CfgNode({'ENABLED': False, 'TYPE': 'relative_range', 'SIZE': [0.9, 0.9]}), 'FORMAT': 'BGR', 'MASK_FORMAT': 'polygon'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"SemanticSegmentor\" in cfg.MODEL.META_ARCHITECTURE:\n",
    "#             mapper = DatasetMapper(cfg, is_train=True, augmentations=build_sem_seg_train_aug(cfg))\n",
    "#         else:\n",
    "#             mapper = None\n",
    "#         return build_detection_train_loader(cfg, mapper=mapper\n",
    "\n",
    "dataloader = build_detection_train_loader(\n",
    "    dataset=DatasetCatalog.get('chest_imagenome_train'),\n",
    "    mapper=DatasetMapper(is_train=True, image_format=cfg.INPUT.FORMAT, augmentations=[]),\n",
    "    total_batch_size=cfg.SOLVER.IMS_PER_BATCH,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/227835 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 227835/227835 [00:00<00:00, 471135.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 11 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader_val = build_detection_test_loader(\n",
    "    dataset=DatasetCatalog.get('chest_imagenome_validate'),\n",
    "    mapper=DatasetMapper(is_train=False, image_format=cfg.INPUT.FORMAT, augmentations=[]),\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '/mnt/workspace/mimic-cxr-jpg/images-medium(512)/p10/p10003502/s52139270/550e6f3b-f008c1d0-8d2dee2a-649b30f4-101a98cc.jpg',\n",
       " 'image_id': '550e6f3b-f008c1d0-8d2dee2a-649b30f4-101a98cc',\n",
       " 'height': 615,\n",
       " 'width': 512,\n",
       " 'image': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 615, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.events import EventStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventStorage() as storage:\n",
    "    model.eval()\n",
    "    output = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=8, image_height=615, image_width=512, fields=[pred_boxes: Boxes(tensor([[ 59.9608,  31.3847, 450.1136, 504.6334],\n",
       "        [ 71.6471,  13.2026, 451.3328, 496.2819],\n",
       "        [131.7231,  12.1683, 348.4443, 251.0878],\n",
       "        [ 44.5138,  34.2821, 468.4243, 481.5617],\n",
       "        [150.4755,   8.9024, 348.4955, 274.0350],\n",
       "        [129.8500,  16.7071, 347.4103, 236.9656],\n",
       "        [ 48.3948,  48.5375, 468.9896, 478.5137],\n",
       "        [258.0957,   7.2502, 468.6046, 457.0898]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)), scores: tensor([0.6643, 0.5768, 0.3042, 0.2017, 0.1412, 0.0812, 0.0509, 0.0506],\n",
       "       device='cuda:0', grad_fn=<IndexBackward0>), pred_classes: tensor([15,  0, 15, 59,  0, 16, 57,  0], device='cuda:0')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 120\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: detectron2\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\n",
      "   num_regions: None\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,7,2e-4,53,1e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 50\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [512, 512]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "Building Detectron2 model\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.RETINANET.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "Loading weights from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (37, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (37,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (144, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (144,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "Detectron2 model successfully built\n",
      "MultiPurposeVisualModule: self.name=D2-CocoDet-faster-rcnn-R-50-FPN-3x\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,2e-4,53,1e-6\n",
      "1e-06 7 0.0002 53 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n",
      "  0%|                                                | 0/227835 [00:00<?, ?it/s]image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n",
      "100%|████████████████████████████████| 227835/227835 [00:03<00:00, 62183.67it/s]\n",
      "Skipped 992 images\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n",
      "100%|███████████████████████████████| 227835/227835 [00:00<00:00, 625973.08it/s]\n",
      "Skipped 11 images\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 8.20738, d2box_loss 0.85440, d2cls_loss 3.43679, d2rpncls_loss 1.52046, d2rpnloc_loss 0.39105, 128.23 secs\n",
      "(2) Validation stage ...\n",
      "WARNING: Bbox MAE defaulting to 0 since self._count is 0\n",
      "WARNING: Bbox IOU defaulting to 0 since self._count is 0\n",
      "chestimgbbmf1 0.00000, chestimgbbiou 0.00000, chestimgbbmae 0.00000, 32.67 secs\n",
      "Adjusting learning rate of group 0 to 2.1317e-06.\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.78592, d2box_loss 0.87551, d2cls_loss 2.18433, d2rpncls_loss 0.30223, d2rpnloc_loss 0.36458, 130.20 secs\n",
      "(2) Validation stage ...\n",
      "WARNING: Bbox MAE defaulting to 0 since self._count is 0\n",
      "WARNING: Bbox IOU defaulting to 0 since self._count is 0\n",
      "chestimgbbmf1 0.00000, chestimgbbiou 0.00000, chestimgbbmae 0.00000, 31.16 secs\n",
      "Adjusting learning rate of group 0 to 4.5440e-06.\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 3.02361, d2box_loss 0.86415, d2cls_loss 1.36573, d2rpncls_loss 0.20689, d2rpnloc_loss 0.33931, 130.45 secs\n",
      "(2) Validation stage ...\n",
      "WARNING: Bbox MAE defaulting to 0 since self._count is 0\n",
      "WARNING: Bbox IOU defaulting to 0 since self._count is 0\n",
      "chestimgbbmf1 0.00000, chestimgbbiou 0.00000, chestimgbbmae 0.00000, 32.06 secs\n",
      "Adjusting learning rate of group 0 to 9.6863e-06.\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.57191, d2box_loss 0.82839, d2cls_loss 0.99247, d2rpncls_loss 0.16249, d2rpnloc_loss 0.31792, 133.55 secs\n",
      "(2) Validation stage ...\n",
      "Engine run is terminating due to exception: list indices must be integers or slices, not tuple\n",
      "Engine run is terminating due to exception: list indices must be integers or slices, not tuple\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/bbox/utils.py\", line 181, in _compute_f1__detectron2\n",
      "    return _compute_score__detectron2(task, _f1_score)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/bbox/utils.py\", line 169, in _compute_score__detectron2\n",
      "    if compute_iou(_shared_pred_boxes[i], _shared_gt_coords[i,][a:b]) >= iou_thr:\n",
      "TypeError: list indices must be integers or slices, not tuple\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_visual_module.py\", line 1358, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_visual_module.py\", line 1258, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_visual_module.py\", line 833, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 751, in _internal_run\n",
      "    self._fire_event(Events.EPOCH_COMPLETED)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"../train_visual_module.py\", line 820, in <lambda>\n",
      "    max_epochs=1, epoch_length=val_dataloader_size))\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 751, in _internal_run\n",
      "    self._fire_event(Events.EPOCH_COMPLETED)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/dataset_aware_metric.py\", line 33, in epoch_completed_handler\n",
      "    engine.state.metrics[metric_alias] = self.compute()\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/bbox/bbox_mean_prf1.py\", line 74, in compute\n",
      "    num_workers=num_workers,\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/bbox/utils.py\", line 214, in compute_multiple_f1_scores__detectron2\n",
      "    pred_boxes, pred_classes, scores, gt_coords, gt_presences, iou_thresholds, num_workers, _compute_f1__detectron2)\n",
      "  File \"/home/pamessina/medvqa/medvqa/metrics/bbox/utils.py\", line 204, in _compute_multiple_scores__detectron2\n",
      "    scores = p.map(metric_fn, task_args)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 266, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "TypeError: list indices must be integers or slices, not tuple\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "    --epochs 60 \\\n",
    "    --batches-per-epoch 120 \\\n",
    "    --batch-size 50 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 2 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"warmup+decay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-and-decay-args \"1e-6,7,2e-4,53,1e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "    --predict-bboxes-chest-imagenome \\\n",
    "    --clamp-bboxes-chest-imagenome \\\n",
    "    --use-chest-imagenome-decent-images-only \\\n",
    "    --raw-image-encoding \"detectron2\" \\\n",
    "    --detectron2-model-yaml \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\" \\\n",
    "    --image-size 512 512 \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 57\n",
      "   batches_per_epoch: 120\n",
      "   checkpoint_folder: models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: densenet-121\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: None\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adam\n",
      "   lr: 0.001\n",
      "   scheduler: reduce-lr-on-plateau\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 50\n",
      "   iters_to_accumulate: 2\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: (256, 256)\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: False\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "Building Detectron2 model\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.RETINANET.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "Loading weights from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (37, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (37,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (144, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (144,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "Detectron2 model successfully built\n",
      "MultiPurposeVisualModule: self.name=D2-CocoDet-faster-rcnn-R-50-FPN-3x\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,7,2e-4,53,1e-6\n",
      "1e-06 7 0.0002 53 1e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n",
      "  0%|                                                | 0/227835 [00:00<?, ?it/s]image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n",
      "100%|████████████████████████████████| 227835/227835 [00:04<00:00, 49547.23it/s]\n",
      "Skipped 992 images\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n",
      "100%|███████████████████████████████| 227835/227835 [00:00<00:00, 661790.26it/s]\n",
      "Skipped 11 images\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_3_chestimgbbmf1=0.0000.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/checkpoint_3_chestimgbbmf1=0.0000.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 2.73425, d2box_loss 0.82557, d2cls_loss 0.98912, d2rpncls_loss 0.16140, d2rpnloc_loss 0.31805, 130.05 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.01111, chestimgbbiou 0.65831, chestimgbbmae 22.02673, 46.20 secs\n",
      "Adjusting learning rate of group 0 to 2.0648e-05.\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000021) ...\n",
      "loss 1.74694, d2box_loss 0.66081, d2cls_loss 0.53649, d2rpncls_loss 0.12732, d2rpnloc_loss 0.29629, 131.14 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.05654, chestimgbbiou 0.70886, chestimgbbmae 13.25749, 50.88 secs\n",
      "Adjusting learning rate of group 0 to 4.4014e-05.\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000044) ...\n",
      "loss 1.41344, d2box_loss 0.59881, d2cls_loss 0.52826, d2rpncls_loss 0.11207, d2rpnloc_loss 0.27557, 132.40 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.09624, chestimgbbiou 0.73046, chestimgbbmae 11.63401, 52.56 secs\n",
      "Adjusting learning rate of group 0 to 9.3823e-05.\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000094) ...\n",
      "loss 1.28725, d2box_loss 0.52570, d2cls_loss 0.41610, d2rpncls_loss 0.09158, d2rpnloc_loss 0.26064, 132.81 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.13710, chestimgbbiou 0.76737, chestimgbbmae 9.67948, 55.93 secs\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000200) ...\n",
      "loss 1.21416, d2box_loss 0.50262, d2cls_loss 0.39489, d2rpncls_loss 0.08222, d2rpnloc_loss 0.24194, 140.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.17103, chestimgbbiou 0.77159, chestimgbbmae 9.05966, 72.43 secs\n",
      "Adjusting learning rate of group 0 to 1.8097e-04.\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000181) ...\n",
      "loss 1.06130, d2box_loss 0.45278, d2cls_loss 0.36373, d2rpncls_loss 0.07667, d2rpnloc_loss 0.22799, 165.27 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20330, chestimgbbiou 0.79014, chestimgbbmae 8.49246, 85.67 secs\n",
      "Adjusting learning rate of group 0 to 1.6376e-04.\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000164) ...\n",
      "loss 1.16489, d2box_loss 0.42975, d2cls_loss 0.34827, d2rpncls_loss 0.06909, d2rpnloc_loss 0.21098, 174.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.24826, chestimgbbiou 0.79573, chestimgbbmae 8.10796, 74.64 secs\n",
      "Adjusting learning rate of group 0 to 1.4818e-04.\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000148) ...\n",
      "loss 1.10738, d2box_loss 0.42005, d2cls_loss 0.34288, d2rpncls_loss 0.06785, d2rpnloc_loss 0.20785, 166.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.24509, chestimgbbiou 0.79430, chestimgbbmae 8.09768, 77.67 secs\n",
      "Adjusting learning rate of group 0 to 1.3408e-04.\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000134) ...\n",
      "loss 0.92523, d2box_loss 0.40300, d2cls_loss 0.32743, d2rpncls_loss 0.06118, d2rpnloc_loss 0.19495, 163.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.26272, chestimgbbiou 0.79753, chestimgbbmae 7.92382, 79.62 secs\n",
      "Adjusting learning rate of group 0 to 1.2133e-04.\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000121) ...\n",
      "loss 0.91281, d2box_loss 0.39954, d2cls_loss 0.32820, d2rpncls_loss 0.06195, d2rpnloc_loss 0.19890, 166.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.27552, chestimgbbiou 0.79626, chestimgbbmae 7.85598, 84.56 secs\n",
      "Adjusting learning rate of group 0 to 1.0978e-04.\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000110) ...\n",
      "loss 0.83609, d2box_loss 0.39376, d2cls_loss 0.32413, d2rpncls_loss 0.06457, d2rpnloc_loss 0.19629, 167.40 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.28635, chestimgbbiou 0.80277, chestimgbbmae 7.69945, 81.53 secs\n",
      "Adjusting learning rate of group 0 to 9.9339e-05.\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000099) ...\n",
      "loss 0.93553, d2box_loss 0.38957, d2cls_loss 0.32235, d2rpncls_loss 0.05847, d2rpnloc_loss 0.18906, 164.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.29353, chestimgbbiou 0.80524, chestimgbbmae 7.53140, 81.82 secs\n",
      "Adjusting learning rate of group 0 to 8.9889e-05.\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000090) ...\n",
      "loss 0.93566, d2box_loss 0.38354, d2cls_loss 0.31655, d2rpncls_loss 0.06206, d2rpnloc_loss 0.19089, 164.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.30267, chestimgbbiou 0.80631, chestimgbbmae 7.37396, 85.94 secs\n",
      "Adjusting learning rate of group 0 to 8.1337e-05.\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000081) ...\n",
      "loss 0.88335, d2box_loss 0.37982, d2cls_loss 0.31672, d2rpncls_loss 0.05942, d2rpnloc_loss 0.19042, 165.08 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.30964, chestimgbbiou 0.80871, chestimgbbmae 7.30869, 80.75 secs\n",
      "Adjusting learning rate of group 0 to 7.3599e-05.\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000074) ...\n",
      "loss 1.11730, d2box_loss 0.37611, d2cls_loss 0.31326, d2rpncls_loss 0.06353, d2rpnloc_loss 0.19101, 168.60 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.31202, chestimgbbiou 0.80753, chestimgbbmae 7.31190, 87.18 secs\n",
      "Adjusting learning rate of group 0 to 6.6597e-05.\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000067) ...\n",
      "loss 1.00647, d2box_loss 0.37278, d2cls_loss 0.31144, d2rpncls_loss 0.06230, d2rpnloc_loss 0.18675, 171.11 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.30421, chestimgbbiou 0.80653, chestimgbbmae 7.43259, 86.76 secs\n",
      "Adjusting learning rate of group 0 to 6.0262e-05.\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000060) ...\n",
      "loss 0.87265, d2box_loss 0.37817, d2cls_loss 0.31317, d2rpncls_loss 0.06530, d2rpnloc_loss 0.19101, 169.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.31507, chestimgbbiou 0.81140, chestimgbbmae 7.20506, 89.72 secs\n",
      "Adjusting learning rate of group 0 to 5.4529e-05.\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000055) ...\n",
      "loss 0.80650, d2box_loss 0.36990, d2cls_loss 0.30750, d2rpncls_loss 0.05853, d2rpnloc_loss 0.18419, 171.02 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.32491, chestimgbbiou 0.80951, chestimgbbmae 7.21682, 84.22 secs\n",
      "Adjusting learning rate of group 0 to 4.9341e-05.\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000049) ...\n",
      "loss 1.03198, d2box_loss 0.36496, d2cls_loss 0.30485, d2rpncls_loss 0.05911, d2rpnloc_loss 0.18255, 165.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.32791, chestimgbbiou 0.81315, chestimgbbmae 7.20311, 78.21 secs\n",
      "Adjusting learning rate of group 0 to 4.4647e-05.\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000045) ...\n",
      "loss 1.02358, d2box_loss 0.36372, d2cls_loss 0.30630, d2rpncls_loss 0.05800, d2rpnloc_loss 0.17843, 169.12 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.33704, chestimgbbiou 0.81113, chestimgbbmae 7.25377, 87.35 secs\n",
      "Adjusting learning rate of group 0 to 4.0400e-05.\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 1.01663, d2box_loss 0.36531, d2cls_loss 0.30744, d2rpncls_loss 0.05956, d2rpnloc_loss 0.18273, 169.94 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.33487, chestimgbbiou 0.81398, chestimgbbmae 7.04235, 83.81 secs\n",
      "Adjusting learning rate of group 0 to 3.6556e-05.\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 0.84959, d2box_loss 0.36192, d2cls_loss 0.30518, d2rpncls_loss 0.05507, d2rpnloc_loss 0.17955, 168.40 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.34387, chestimgbbiou 0.81370, chestimgbbmae 7.04195, 78.97 secs\n",
      "Adjusting learning rate of group 0 to 3.3079e-05.\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "Current run is terminating due to exception: CUDA out of memory. Tried to allocate 1.34 GiB (GPU 0; 23.70 GiB total capacity; 18.38 GiB already allocated; 54.38 MiB free; 21.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Engine run is terminating due to exception: CUDA out of memory. Tried to allocate 1.34 GiB (GPU 0; 23.70 GiB total capacity; 18.38 GiB already allocated; 54.38 MiB free; 21.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_visual_module.py\", line 1354, in <module>\n",
      "    resume_training(**args)\n",
      "  File \"../train_visual_module.py\", line 1337, in resume_training\n",
      "    debug=debug)\n",
      "  File \"../train_visual_module.py\", line 833, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 770, in step_fn\n",
      "    output = step_fn__mimiccxr_chest_imagenome_detectron2(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 132, in step_fn__mimiccxr_chest_imagenome_detectron2\n",
      "    gradient_accumulator.step(batch_loss)\n",
      "  File \"/home/pamessina/medvqa/medvqa/losses/optimizers.py\", line 25, in step\n",
      "    self.scaler.scale(batch_loss).backward()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 156, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1.34 GiB (GPU 0; 23.70 GiB total capacity; 18.38 GiB already allocated; 54.38 MiB free; 21.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "    --checkpoint-folder \"models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x\" \\\n",
    "    --epochs 57 \\\n",
    "    --batches-per-epoch 120 \\\n",
    "    --batch-size 50 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 2 \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 40\n",
      "   batches_per_epoch: 120\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: detectron2\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: v1\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\n",
      "   num_regions: None\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: warmup+decay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: 1e-6,5,3e-4,35,3e-6\n",
      "   warmup_and_cosine_args: None\n",
      "   batch_size: 30\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [512, 512]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "Building Detectron2 model\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.RETINANET.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "Loading weights from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (37, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (37,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (144, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (144,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "Detectron2 model successfully built\n",
      "MultiPurposeVisualModule: self.name=D2-CocoDet-faster-rcnn-R-50-FPN-3x\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using warmup+decay scheduler: 1e-6,5,3e-4,35,3e-6\n",
      "1e-06 5 0.0003 35 3e-06\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n",
      "  0%|                                                | 0/227835 [00:00<?, ?it/s]image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n",
      "100%|████████████████████████████████| 227835/227835 [00:04<00:00, 50646.63it/s]\n",
      "Skipped 992 images\n",
      "Loading cached detailed metadata from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/detailed_metadata.pkl\n",
      "Loaded 240530 non-gold DICOM IDs from Chest Imagenome\n",
      "Using source image size mode: medium_512\n",
      "Loaded 242280 decent image IDs\n",
      "100%|███████████████████████████████| 227835/227835 [00:00<00:00, 669868.71it/s]\n",
      "Skipped 11 images\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_180949_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_180949_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_25_chestimgbbmf1=0.3439.pt', 'checkpoint_3_chestimgbbmf1=0.0000.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/checkpoint_25_chestimgbbmf1=0.3439.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_180949_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.03849, d2box_loss 0.35539, d2cls_loss 0.29932, d2rpncls_loss 0.05736, d2rpnloc_loss 0.17804, 76.87 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.35211, chestimgbbiou 0.81823, chestimgbbmae 6.89542, 44.86 secs\n",
      "Adjusting learning rate of group 0 to 3.1291e-06.\n",
      "\u001b[1m---- Epoch 2/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.82427, d2box_loss 0.35252, d2cls_loss 0.29779, d2rpncls_loss 0.05466, d2rpnloc_loss 0.17871, 76.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.35116, chestimgbbiou 0.81706, chestimgbbmae 6.94133, 46.33 secs\n",
      "Adjusting learning rate of group 0 to 9.7915e-06.\n",
      "\u001b[1m---- Epoch 3/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.84699, d2box_loss 0.35216, d2cls_loss 0.29469, d2rpncls_loss 0.05511, d2rpnloc_loss 0.17373, 77.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.34999, chestimgbbiou 0.81802, chestimgbbmae 6.94179, 47.67 secs\n",
      "Adjusting learning rate of group 0 to 3.0639e-05.\n",
      "\u001b[1m---- Epoch 4/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000031) ...\n",
      "loss 1.20327, d2box_loss 0.36368, d2cls_loss 0.30257, d2rpncls_loss 0.05720, d2rpnloc_loss 0.17912, 78.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.32439, chestimgbbiou 0.80994, chestimgbbmae 7.23449, 48.32 secs\n",
      "Adjusting learning rate of group 0 to 9.5873e-05.\n",
      "\u001b[1m---- Epoch 5/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000096) ...\n",
      "loss 0.78808, d2box_loss 0.39131, d2cls_loss 0.32015, d2rpncls_loss 0.05643, d2rpnloc_loss 0.18533, 78.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.28462, chestimgbbiou 0.80365, chestimgbbmae 7.54972, 51.97 secs\n",
      "Adjusting learning rate of group 0 to 3.0000e-04.\n",
      "\u001b[1m---- Epoch 6/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000300) ...\n",
      "loss 0.98953, d2box_loss 0.49154, d2cls_loss 0.40046, d2rpncls_loss 0.08259, d2rpnloc_loss 0.22753, 81.61 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21410, chestimgbbiou 0.78182, chestimgbbmae 8.87770, 58.68 secs\n",
      "Adjusting learning rate of group 0 to 2.6301e-04.\n",
      "\u001b[1m---- Epoch 7/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000263) ...\n",
      "loss 1.04945, d2box_loss 0.42263, d2cls_loss 0.34340, d2rpncls_loss 0.07686, d2rpnloc_loss 0.21382, 85.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.26043, chestimgbbiou 0.78925, chestimgbbmae 8.22080, 64.18 secs\n",
      "Adjusting learning rate of group 0 to 2.3059e-04.\n",
      "\u001b[1m---- Epoch 8/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000231) ...\n",
      "loss 1.03342, d2box_loss 0.40409, d2cls_loss 0.32891, d2rpncls_loss 0.06398, d2rpnloc_loss 0.19389, 88.54 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.28267, chestimgbbiou 0.80100, chestimgbbmae 7.75174, 70.82 secs\n",
      "Adjusting learning rate of group 0 to 2.0216e-04.\n",
      "\u001b[1m---- Epoch 9/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000202) ...\n",
      "loss 0.92479, d2box_loss 0.38942, d2cls_loss 0.31494, d2rpncls_loss 0.06215, d2rpnloc_loss 0.18722, 93.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.28844, chestimgbbiou 0.80440, chestimgbbmae 7.59448, 72.23 secs\n",
      "Adjusting learning rate of group 0 to 1.7724e-04.\n",
      "\u001b[1m---- Epoch 10/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000177) ...\n",
      "loss 1.17560, d2box_loss 0.37503, d2cls_loss 0.31115, d2rpncls_loss 0.06754, d2rpnloc_loss 0.19143, 93.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.30507, chestimgbbiou 0.80728, chestimgbbmae 7.34151, 72.54 secs\n",
      "Adjusting learning rate of group 0 to 1.5538e-04.\n",
      "\u001b[1m---- Epoch 11/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000155) ...\n",
      "loss 0.82429, d2box_loss 0.38212, d2cls_loss 0.31459, d2rpncls_loss 0.06023, d2rpnloc_loss 0.18479, 94.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.31565, chestimgbbiou 0.81029, chestimgbbmae 7.21757, 75.29 secs\n",
      "Adjusting learning rate of group 0 to 1.3623e-04.\n",
      "\u001b[1m---- Epoch 12/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000136) ...\n",
      "loss 0.90655, d2box_loss 0.36749, d2cls_loss 0.30167, d2rpncls_loss 0.05658, d2rpnloc_loss 0.18141, 95.40 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.32064, chestimgbbiou 0.80841, chestimgbbmae 7.34545, 73.25 secs\n",
      "Adjusting learning rate of group 0 to 1.1943e-04.\n",
      "\u001b[1m---- Epoch 13/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000119) ...\n",
      "loss 1.02163, d2box_loss 0.36809, d2cls_loss 0.30644, d2rpncls_loss 0.06280, d2rpnloc_loss 0.18279, 90.68 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.32458, chestimgbbiou 0.81335, chestimgbbmae 7.16248, 71.79 secs\n",
      "Adjusting learning rate of group 0 to 1.0471e-04.\n",
      "\u001b[1m---- Epoch 14/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000105) ...\n",
      "loss 0.88945, d2box_loss 0.36174, d2cls_loss 0.29824, d2rpncls_loss 0.05842, d2rpnloc_loss 0.17954, 92.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.33223, chestimgbbiou 0.81091, chestimgbbmae 7.19366, 71.89 secs\n",
      "Adjusting learning rate of group 0 to 9.1798e-05.\n",
      "\u001b[1m---- Epoch 15/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000092) ...\n",
      "loss 0.72868, d2box_loss 0.36268, d2cls_loss 0.30262, d2rpncls_loss 0.05482, d2rpnloc_loss 0.17918, 91.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.33425, chestimgbbiou 0.81225, chestimgbbmae 7.18867, 73.08 secs\n",
      "Adjusting learning rate of group 0 to 8.0481e-05.\n",
      "\u001b[1m---- Epoch 16/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.97302, d2box_loss 0.35744, d2cls_loss 0.30012, d2rpncls_loss 0.06068, d2rpnloc_loss 0.17879, 91.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.34151, chestimgbbiou 0.81547, chestimgbbmae 7.07947, 72.06 secs\n",
      "Adjusting learning rate of group 0 to 7.0559e-05.\n",
      "\u001b[1m---- Epoch 17/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000071) ...\n",
      "loss 0.76145, d2box_loss 0.35192, d2cls_loss 0.29334, d2rpncls_loss 0.05346, d2rpnloc_loss 0.17201, 96.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.34935, chestimgbbiou 0.81725, chestimgbbmae 6.91690, 75.48 secs\n",
      "Adjusting learning rate of group 0 to 5.4233e-05.\n",
      "\u001b[1m---- Epoch 19/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000054) ...\n",
      "loss 0.83607, d2box_loss 0.35355, d2cls_loss 0.29698, d2rpncls_loss 0.06056, d2rpnloc_loss 0.17725, 94.18 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.35012, chestimgbbiou 0.81955, chestimgbbmae 6.89962, 75.46 secs\n",
      "Adjusting learning rate of group 0 to 4.7547e-05.\n",
      "\u001b[1m---- Epoch 20/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000048) ...\n",
      "loss 0.87592, d2box_loss 0.35175, d2cls_loss 0.29400, d2rpncls_loss 0.05282, d2rpnloc_loss 0.16990, 95.44 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.35579, chestimgbbiou 0.81664, chestimgbbmae 6.94411, 72.44 secs\n",
      "Adjusting learning rate of group 0 to 4.1685e-05.\n",
      "\u001b[1m---- Epoch 21/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000042) ...\n",
      "loss 0.79457, d2box_loss 0.35201, d2cls_loss 0.29202, d2rpncls_loss 0.05207, d2rpnloc_loss 0.16754, 95.74 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.36057, chestimgbbiou 0.81642, chestimgbbmae 6.94013, 75.93 secs\n",
      "Adjusting learning rate of group 0 to 3.6546e-05.\n",
      "\u001b[1m---- Epoch 22/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000037) ...\n",
      "loss 0.96741, d2box_loss 0.34825, d2cls_loss 0.29056, d2rpncls_loss 0.05019, d2rpnloc_loss 0.16793, 93.97 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.35930, chestimgbbiou 0.81974, chestimgbbmae 6.84102, 69.98 secs\n",
      "Adjusting learning rate of group 0 to 3.2040e-05.\n",
      "\u001b[1m---- Epoch 23/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 0.72892, d2box_loss 0.34363, d2cls_loss 0.28734, d2rpncls_loss 0.05439, d2rpnloc_loss 0.17082, 95.35 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.36303, chestimgbbiou 0.81968, chestimgbbmae 6.83120, 77.71 secs\n",
      "Adjusting learning rate of group 0 to 2.8090e-05.\n",
      "\u001b[1m---- Epoch 24/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000028) ...\n",
      "loss 0.87893, d2box_loss 0.34778, d2cls_loss 0.29283, d2rpncls_loss 0.05006, d2rpnloc_loss 0.17138, 96.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.36426, chestimgbbiou 0.82185, chestimgbbmae 6.73313, 75.19 secs\n",
      "Adjusting learning rate of group 0 to 2.4627e-05.\n",
      "\u001b[1m---- Epoch 25/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000025) ...\n",
      "loss 0.77714, d2box_loss 0.34372, d2cls_loss 0.28695, d2rpncls_loss 0.05688, d2rpnloc_loss 0.16978, 96.07 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestimgbbmf1 0.36892, chestimgbbiou 0.82152, chestimgbbmae 6.73778, 72.68 secs\n",
      "Adjusting learning rate of group 0 to 2.1591e-05.\n",
      "\u001b[1m---- Epoch 26/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 0.87882, d2box_loss 0.33809, d2cls_loss 0.28368, d2rpncls_loss 0.04809, d2rpnloc_loss 0.16404, 91.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.36788, chestimgbbiou 0.82033, chestimgbbmae 6.79036, 73.32 secs\n",
      "Adjusting learning rate of group 0 to 1.8929e-05.\n",
      "\u001b[1m---- Epoch 27/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.83756, d2box_loss 0.33865, d2cls_loss 0.28290, d2rpncls_loss 0.04819, d2rpnloc_loss 0.16352, 93.02 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.36990, chestimgbbiou 0.82275, chestimgbbmae 6.68623, 71.47 secs\n",
      "Adjusting learning rate of group 0 to 1.6595e-05.\n",
      "\u001b[1m---- Epoch 28/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.85930, d2box_loss 0.33967, d2cls_loss 0.28670, d2rpncls_loss 0.05582, d2rpnloc_loss 0.16885, 94.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37111, chestimgbbiou 0.82202, chestimgbbmae 6.69948, 72.34 secs\n",
      "Adjusting learning rate of group 0 to 1.4549e-05.\n",
      "\u001b[1m---- Epoch 29/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000015) ...\n",
      "loss 0.74948, d2box_loss 0.33902, d2cls_loss 0.28634, d2rpncls_loss 0.05666, d2rpnloc_loss 0.16890, 96.62 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37082, chestimgbbiou 0.82277, chestimgbbmae 6.70549, 73.72 secs\n",
      "Adjusting learning rate of group 0 to 1.2755e-05.\n",
      "\u001b[1m---- Epoch 30/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000013) ...\n",
      "loss 0.86526, d2box_loss 0.33937, d2cls_loss 0.28770, d2rpncls_loss 0.05451, d2rpnloc_loss 0.16909, 94.95 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37283, chestimgbbiou 0.82225, chestimgbbmae 6.68650, 71.81 secs\n",
      "Adjusting learning rate of group 0 to 1.1183e-05.\n",
      "\u001b[1m---- Epoch 31/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000011) ...\n",
      "loss 0.75020, d2box_loss 0.33939, d2cls_loss 0.28629, d2rpncls_loss 0.05688, d2rpnloc_loss 0.17246, 93.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37279, chestimgbbiou 0.82267, chestimgbbmae 6.67400, 70.55 secs\n",
      "Adjusting learning rate of group 0 to 9.8041e-06.\n",
      "\u001b[1m---- Epoch 32/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.90235, d2box_loss 0.34228, d2cls_loss 0.28862, d2rpncls_loss 0.05519, d2rpnloc_loss 0.17089, 94.37 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37419, chestimgbbiou 0.82417, chestimgbbmae 6.65544, 74.38 secs\n",
      "Adjusting learning rate of group 0 to 8.5954e-06.\n",
      "\u001b[1m---- Epoch 33/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.73162, d2box_loss 0.34048, d2cls_loss 0.28736, d2rpncls_loss 0.05483, d2rpnloc_loss 0.17104, 96.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37429, chestimgbbiou 0.82197, chestimgbbmae 6.70111, 74.42 secs\n",
      "Adjusting learning rate of group 0 to 7.5357e-06.\n",
      "\u001b[1m---- Epoch 34/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000008) ...\n",
      "loss 0.93936, d2box_loss 0.33720, d2cls_loss 0.28341, d2rpncls_loss 0.05366, d2rpnloc_loss 0.16675, 95.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37261, chestimgbbiou 0.82358, chestimgbbmae 6.66599, 69.19 secs\n",
      "Adjusting learning rate of group 0 to 6.6066e-06.\n",
      "\u001b[1m---- Epoch 35/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.99329, d2box_loss 0.33632, d2cls_loss 0.28296, d2rpncls_loss 0.04925, d2rpnloc_loss 0.16347, 93.16 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37657, chestimgbbiou 0.82335, chestimgbbmae 6.65580, 70.31 secs\n",
      "Adjusting learning rate of group 0 to 5.7921e-06.\n",
      "\u001b[1m---- Epoch 36/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.78778, d2box_loss 0.33412, d2cls_loss 0.28134, d2rpncls_loss 0.05589, d2rpnloc_loss 0.16812, 90.23 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37806, chestimgbbiou 0.82426, chestimgbbmae 6.61071, 73.33 secs\n",
      "Adjusting learning rate of group 0 to 5.0780e-06.\n",
      "\u001b[1m---- Epoch 37/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.81155, d2box_loss 0.33855, d2cls_loss 0.28631, d2rpncls_loss 0.05641, d2rpnloc_loss 0.16858, 92.97 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37745, chestimgbbiou 0.82374, chestimgbbmae 6.62701, 74.26 secs\n",
      "Adjusting learning rate of group 0 to 4.4519e-06.\n",
      "\u001b[1m---- Epoch 38/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.75792, d2box_loss 0.33804, d2cls_loss 0.28642, d2rpncls_loss 0.05675, d2rpnloc_loss 0.17031, 91.20 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37744, chestimgbbiou 0.82356, chestimgbbmae 6.63278, 69.91 secs\n",
      "Adjusting learning rate of group 0 to 3.9031e-06.\n",
      "\u001b[1m---- Epoch 39/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.93908, d2box_loss 0.34110, d2cls_loss 0.29094, d2rpncls_loss 0.05341, d2rpnloc_loss 0.17113, 89.89 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37793, chestimgbbiou 0.82397, chestimgbbmae 6.62529, 71.51 secs\n",
      "Adjusting learning rate of group 0 to 3.4219e-06.\n",
      "\u001b[1m---- Epoch 40/40\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.78664, d2box_loss 0.33517, d2cls_loss 0.28471, d2rpncls_loss 0.04709, d2rpnloc_loss 0.16498, 91.86 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.37614, chestimgbbiou 0.82379, chestimgbbmae 6.64953, 71.07 secs\n",
      "Adjusting learning rate of group 0 to 3.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "    --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230301_144556_mim_D2-CocoDet-faster-rcnn-R-50-FPN-3x\" \\\n",
    "    --epochs 40 \\\n",
    "    --batches-per-epoch 120 \\\n",
    "    --batch-size 30 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 4 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"warmup+decay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-and-decay-args \"1e-6,5,3e-4,35,3e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "    --predict-bboxes-chest-imagenome \\\n",
    "    --clamp-bboxes-chest-imagenome \\\n",
    "    --use-chest-imagenome-decent-images-only \\\n",
    "    --raw-image-encoding \"detectron2\" \\\n",
    "    --detectron2-model-yaml \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\" \\\n",
    "    --image-size 512 512 \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
