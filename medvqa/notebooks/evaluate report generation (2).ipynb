{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pamessina/venv/lib/python3.6/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 8\n",
      "   save_for_error_analysis: True\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_25_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt', 'checkpoint_50_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_50_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt\n",
      "pretrained_checkpoint_path = /home/pamessina/medvqa-workspace/models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_50_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5757.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /home/pamessina/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4838,39196,466463750150781738;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 100\n",
      "len(self.report_ids) = 32697, len(set(self.report_ids)) = 3258\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 32697, len(set(self.report_ids)) = 3258\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 1024\n",
      "  n_questions = 154\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/clip-vte-vit-lp16bcbf-v3+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 32697\n",
      "len(dataloader) = 327\n",
      "Evaluating model ...\n",
      "oracc 0.99288, chxlmicf1 0.57988, chxlmacf1 0.48746, chxlacc 0.69928, chxlrocaucmic 0.80708, chxlrocaucmac 0.76497, qlmacf1 0.22349, 446.87 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3258, len(gt_reports)=3258\n",
      "Cache successfully loaded from /home/pamessina/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "Chexpert labeler: running a maximum of 8 concurrent processes over 8 chunks\n",
      "chunk: i=0, b=0, e=407, chunk_size=407\n",
      "chunk: i=1, b=407, e=814, chunk_size=407\n",
      "chunk: i=2, b=814, e=1221, chunk_size=407\n",
      "chunk: i=3, b=1221, e=1628, chunk_size=407\n",
      "chunk: i=4, b=1628, e=2035, chunk_size=407\n",
      "chunk: i=5, b=2035, e=2442, chunk_size=407\n",
      "chunk: i=6, b=2442, e=2849, chunk_size=407\n",
      "chunk: i=7, b=2849, e=3256, chunk_size=401\n",
      "\t#### process 1: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_0.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_0.csv\n",
      "\t#### process 2: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_1.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_1.csv\n",
      "\t#### process 3: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_2.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_2.csv\n",
      "\t#### process 4: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_3.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_3.csv\n",
      "\t#### process 5: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_4.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_4.csv\n",
      "\t#### process 6: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_5.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_5.csv\n",
      "\t#### process 7: running chexpert labeler over 407 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_6.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_6.csv\n",
      "\t#### process 8: running chexpert labeler over 401 texts ...\n",
      "\tCommand = docker run -v /home/pamessina/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20221109_191006_0.910211692373571_7.csv --output_path /data/labeler-output_20221109_191006_0.910211692373571_7.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 365.38137650489807\n",
      "\t**** process 2 finished, elapsed time = 365.381555557251\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 3 finished, elapsed time = 366.8703842163086\n",
      "\t**** process 4 finished, elapsed time = 366.8704934120178\n",
      "\t**** process 5 finished, elapsed time = 366.87055587768555\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 6 finished, elapsed time = 382.7937092781067\n",
      "\t**** process 7 finished, elapsed time = 382.7938132286072\n",
      "\t**** process 8 finished, elapsed time = 382.7938778400421\n",
      "Report-level metrics successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n",
      "Report-level results for error analysis successfully saved to /home/pamessina/medvqa-workspace/results/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_results_for_error_analysis(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221106_115622_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 5 \\\n",
    "        --max-processes-for-chexpert-labeler 8 \\\n",
    "        --save-for-error-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 8\n",
      "   save_for_error_analysis: True\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcpu\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_49_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6035.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_49_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.6035.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"../eval_report_generation.py\", line 634, in <module>\n",
      "    evaluate_model(**args)\n",
      "  File \"../eval_report_generation.py\", line 628, in evaluate_model\n",
      "    save_for_error_analysis = save_for_error_analysis,\n",
      "  File \"../eval_report_generation.py\", line 365, in _evaluate_model\n",
      "    checkpoint = torch.load(checkpoint_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 607, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 882, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 857, in persistent_load\n",
      "    load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 846, in load_tensor\n",
      "    loaded_storages[key] = restore_location(storage, location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 175, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 151, in _cuda_deserialize\n",
      "    device = validate_cuda_device(location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 135, in validate_cuda_device\n",
      "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221109_121920_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf-v3+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 5 \\\n",
    "        --max-processes-for-chexpert-labeler 8 \\\n",
    "        --save-for-error-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 8\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcpu\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_45_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5625.pt', 'checkpoint_28_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5595.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_45_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5625.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"../eval_report_generation.py\", line 634, in <module>\n",
      "    evaluate_model(**args)\n",
      "  File \"../eval_report_generation.py\", line 628, in evaluate_model\n",
      "    save_for_error_analysis = save_for_error_analysis,\n",
      "  File \"../eval_report_generation.py\", line 365, in _evaluate_model\n",
      "    checkpoint = torch.load(checkpoint_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 607, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 882, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 857, in persistent_load\n",
      "    load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 846, in load_tensor\n",
      "    loaded_storages[key] = restore_location(storage, location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 175, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 151, in _cuda_deserialize\n",
      "    device = validate_cuda_device(location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 135, in validate_cuda_device\n",
      "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221106_125948_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 5 \\\n",
    "        --max-processes-for-chexpert-labeler 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 100\n",
      "   device: GPU\n",
      "   num_workers: 5\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 8\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /home/pamessina/medvqa-workspace/models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcpu\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /home/pamessina/medvqa-workspace/cache/vocab__min_freq=10__mode=report__from(qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)\n",
      "Returning default transform\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_43_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5866.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /home/pamessina/medvqa-workspace/models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp/checkpoint_43_chxlmacf1+chxlmicf1+cD+cxr14macf1+cxr14micf1+ema+gacc+oracc+qlmacf1+qlmicf1+vnbgmacf1+vnbgmicf1+wmdcmp=0.5866.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"../eval_report_generation.py\", line 634, in <module>\n",
      "    evaluate_model(**args)\n",
      "  File \"../eval_report_generation.py\", line 628, in evaluate_model\n",
      "    save_for_error_analysis = save_for_error_analysis,\n",
      "  File \"../eval_report_generation.py\", line 365, in _evaluate_model\n",
      "    checkpoint = torch.load(checkpoint_path)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 607, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 882, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 857, in persistent_load\n",
      "    load_tensor(data_type, size, key, _maybe_decode_ascii(location))\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 846, in load_tensor\n",
      "    loaded_storages[key] = restore_location(storage, location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 175, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 151, in _cuda_deserialize\n",
      "    device = validate_cuda_device(location)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/serialization.py\", line 135, in validate_cuda_device\n",
      "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221109_120303_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf-v2+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.1,0.08,0.5,0.4,0.4_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 100 \\\n",
    "        --num-workers 5 \\\n",
    "        --max-processes-for-chexpert-labeler 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
