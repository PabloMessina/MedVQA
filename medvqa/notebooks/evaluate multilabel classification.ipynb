{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   eval_dataset_name: mimiccxr_test_set\n",
      "   checkpoint_folder: models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 0\n",
      "   mimiccxr_preprocessed_test_data_filename: mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4833,39148,4210956387659547011;eval_view_mode=front_single;report_eval_mode=chexpert-labels).pkl\n",
      "   mimiccxr_preprocessed_train_data_filename: mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   use_amp: False\n",
      "   calibrate_thresholds: True\n",
      "\n",
      "\u001b[34m----- Evaluating model ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "checkpoint_names = ['checkpoint_17_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.4304.pt', 'checkpoint_34_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.5019.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/checkpoint_34_chf1+chf1+chf1+chf1+chf1+cD+ema+wmmp=0.5019.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "BoundingBoxRegressor_v2:\n",
      "  local_feat_dim: 1024\n",
      "  global_feat_dim: 2048\n",
      "  hidden_dim: 128\n",
      "  num_classes: 36\n",
      "  num_regions: 64\n",
      "  n_questions = 111\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (256, 256), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module evaluator ...\u001b[0m\n",
      "Loading data from path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4833,39148,4210956387659547011;eval_view_mode=front_single;report_eval_mode=chexpert-labels).pkl ...\n",
      "data.keys() = dict_keys(['report_ids', 'images', 'questions', 'question_ids'])\n",
      "\tDone!\n",
      "batch_size = 160\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mAttaching metrics, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test set ...\u001b[0m\n",
      "len(mimiccxr_vision_evaluator.test_dataset) = 3041\n",
      "len(mimiccxr_vision_evaluator.test_dataloader) = 20\n",
      "Evaluating model ...\n",
      "chxlmacf1 0.42314, chxlmicf1 0.58005, chxlacc 0.75917, chxlrocaucmic 0.81266, chxlrocaucmac 0.70092, chestimglmacf1 0.13436, chestimglmicf1 0.36011, chestimgl_acc 0.89397, chestimglrocaucmic 0.89758, chestimglrocaucmac 0.75550, 14.19 secs\n",
      "\u001b[34mCalibrating thresholds using MIMICCXR validation dataset and CheXpert labels\u001b[0m\n",
      "Loading data from path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl ...\n",
      "data.keys() = dict_keys(['report_ids', 'images', 'questions', 'question_ids', 'answers', 'train_indices', 'val_indices', 'orientations', 'dicom_ids'])\n",
      "\tDone!\n",
      "batch_size = 160\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "Running model on MIMICCXR validation dataset ...\n",
      "chxlmacf1 0.41390, chxlmicf1 0.55439, chxlacc 0.79563, chxlrocaucmic 0.83027, chxlrocaucmac 0.73048, 3.75 secs\n",
      "pred_probs.shape: (1, 1708, 14)\n",
      "gt_labels.shape: (1708, 14)\n",
      "Searching optimal thresholds ...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 105.86it/s]\n",
      "\u001b[34mf1(macro)=0.4336319882129284, f1(micro)=0.5460263884627187, score=0.979658376675647\u001b[0m\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 102.44it/s]\n",
      "\u001b[34mf1(macro)=0.4346288735496901, f1(micro)=0.5473538674245334, score=0.9819827409742234\u001b[0m\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 101.87it/s]\n",
      "\u001b[34mf1(macro)=0.4346288735496901, f1(micro)=0.5473538674245334, score=0.9819827409742234\u001b[0m\n",
      "\u001b[34mf1(macro)=0.4346288735496901, f1(micro)=0.5473538674245334, score=0.9819827409742234\u001b[0m\n",
      "thresholds.shape: (14,)\n",
      "thresholds: [0.27547654 0.38794362 0.40463111 0.00480646 0.24411826 0.55060289\n",
      " 0.1999882  0.25301996 0.2416716  0.77711547 0.44796463 0.120309\n",
      " 0.97607451 0.57884608]\n",
      "Done!\n",
      "\u001b[34mCalibrating thresholds using MIMICCXR validation dataset and Chest-ImaGenome labels\u001b[0m\n",
      "Loading data from path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl ...\n",
      "data.keys() = dict_keys(['report_ids', 'images', 'questions', 'question_ids', 'answers', 'train_indices', 'val_indices', 'orientations', 'dicom_ids'])\n",
      "\tDone!\n",
      "batch_size = 160\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "Running model on MIMICCXR validation dataset ...\n",
      "chestimglmacf1 0.12947, chestimglmicf1 0.34952, chestimgl_acc 0.91606, chestimglrocaucmic 0.90881, chestimglrocaucmac 0.77488, 7.90 secs\n",
      "pred_probs.shape: (1, 1708, 627)\n",
      "gt_labels.shape: (1708, 627)\n",
      "Searching optimal thresholds ...\n",
      "100%|█████████████████████████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "\u001b[34mf1(macro)=0.1841992409599267, f1(micro)=0.35549901347614443, score=0.5396982544360711\u001b[0m\n",
      "100%|█████████████████████████████████████████| 100/100 [00:38<00:00,  2.57it/s]\n",
      "\u001b[34mf1(macro)=0.18879450994589697, f1(micro)=0.3674649115228438, score=0.5562594214687407\u001b[0m\n",
      "100%|█████████████████████████████████████████| 100/100 [00:39<00:00,  2.56it/s]\n",
      "\u001b[34mf1(macro)=0.18897729664586438, f1(micro)=0.36998315526417763, score=0.558960451910042\u001b[0m\n",
      "100%|█████████████████████████████████████████| 100/100 [00:39<00:00,  2.56it/s]\n",
      "\u001b[34mf1(macro)=0.1890983393868527, f1(micro)=0.37162881617214694, score=0.5607271555589997\u001b[0m\n",
      "100%|█████████████████████████████████████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "\u001b[34mf1(macro)=0.1893395410518555, f1(micro)=0.37287135188597226, score=0.5622108929378278\u001b[0m\n",
      "100%|█████████████████████████████████████████| 100/100 [00:39<00:00,  2.55it/s]\n",
      "\u001b[34mf1(macro)=0.18937787686221857, f1(micro)=0.37329308610033063, score=0.5626709629625493\u001b[0m\n",
      "\u001b[34mf1(macro)=0.18937787686221857, f1(micro)=0.37329308610033063, score=0.5626709629625493\u001b[0m\n",
      "thresholds.shape: (627,)\n",
      "Done!\n",
      "Multilabel classification metrics saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp/mimiccxr_test_set_multilabel_classification_metrics(chexp-calib-thresh-chest-imagenome-calib-thresh).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_multilabel_classification.py \\\n",
    "        --eval-dataset-name \"mimiccxr_test_set\" \\\n",
    "        --checkpoint-folder \"models/vqa/20230208_231030_mim+mim(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,1.0_medtok_chx_amp\" \\\n",
    "        --mimiccxr-preprocessed-test-data-filename \"mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4833,39148,4210956387659547011;eval_view_mode=front_single;report_eval_mode=chexpert-labels).pkl\" \\\n",
    "        --mimiccxr-preprocessed-train-data-filename \"mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl\" \\\n",
    "        --calibrate-thresholds \\\n",
    "        --batch-size 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   eval_dataset_name: mimiccxr_test_set\n",
      "   checkpoint_folder: models/vqa/20230108_144908_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 0\n",
      "   mimiccxr_preprocessed_test_data_filename: mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4833,39148,4210956387659547011;eval_view_mode=front_single;report_eval_mode=chexpert-labels).pkl\n",
      "   mimiccxr_preprocessed_train_data_filename: mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl\n",
      "   mimiccxr_qa_adapted_reports_filename: None\n",
      "   use_amp: False\n",
      "   calibrate_thresholds: True\n",
      "\n",
      "\u001b[34m----- Evaluating model ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230108_144908_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "checkpoint_names = ['checkpoint_58_chf1+chf1+cD+ema+gacc+orcc+qlf1+qlf1+wmmp=0.5927.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230108_144908_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp/checkpoint_58_chf1+chf1+cD+ema+gacc+orcc+qlf1+qlf1+wmmp=0.5927.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (256, 256), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module evaluator ...\u001b[0m\n",
      "Loading data from path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4833,39148,4210956387659547011;eval_view_mode=front_single;report_eval_mode=chexpert-labels).pkl ...\n",
      "data.keys() = dict_keys(['report_ids', 'images', 'questions', 'question_ids'])\n",
      "\tDone!\n",
      "batch_size = 160\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mAttaching metrics, timer and events to engines ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test set ...\u001b[0m\n",
      "len(mimiccxr_vision_evaluator.test_dataset) = 3041\n",
      "len(mimiccxr_vision_evaluator.test_dataloader) = 20\n",
      "Evaluating model ...\n",
      "chxlmacf1 0.47877, chxlmicf1 0.57878, chxlacc 0.72359, chxlrocaucmic 0.81739, chxlrocaucmac 0.76658, qlmacf1 0.21331, qlmicf1 0.40351, 7.11 secs\n",
      "\u001b[34mCalibrating thresholds using MIMICCXR validation dataset and CheXpert labels\u001b[0m\n",
      "Loading data from path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl ...\n",
      "data.keys() = dict_keys(['report_ids', 'images', 'questions', 'question_ids', 'answers', 'train_indices', 'val_indices', 'orientations', 'dicom_ids'])\n",
      "\tDone!\n",
      "batch_size = 160\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "Running model on MIMICCXR validation dataset ...\n",
      "chxlmacf1 0.46245, chxlmicf1 0.54869, chxlacc 0.76066, chxlrocaucmic 0.83302, chxlrocaucmac 0.78676, 3.46 secs\n",
      "pred_probs.shape: (1, 1708, 14)\n",
      "gt_labels.shape: (1708, 14)\n",
      "Searching optimal thresholds ...\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 106.25it/s]\n",
      "\u001b[34mf1(macro)=0.49189343249760414, f1(micro)=0.5919906166219839, score=1.083884049119588\u001b[0m\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 103.88it/s]\n",
      "\u001b[34mf1(macro)=0.49446064691570396, f1(micro)=0.5928463981280294, score=1.0873070450437334\u001b[0m\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 103.89it/s]\n",
      "\u001b[34mf1(macro)=0.49459983104172867, f1(micro)=0.5928833945873705, score=1.0874832256290992\u001b[0m\n",
      "\u001b[34mf1(macro)=0.49459983104172867, f1(micro)=0.5928833945873705, score=1.0874832256290992\u001b[0m\n",
      "thresholds.shape: (14,)\n",
      "thresholds: [0.61981758 0.44046119 0.44852825 0.62008462 0.38114821 0.67788649\n",
      " 0.6435953  0.55265039 0.47439717 0.8111569  0.55640491 0.69395775\n",
      " 0.80163476 0.41271598]\n",
      "Done!\n",
      "Multilabel classification metrics saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230108_144908_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp/mimiccxr_test_set_multilabel_classification_metrics(chexp-calib-thresh).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_multilabel_classification.py \\\n",
    "        --eval-dataset-name \"mimiccxr_test_set\" \\\n",
    "        --checkpoint-folder \"models/vqa/20230108_144908_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp\" \\\n",
    "        --mimiccxr-preprocessed-test-data-filename \"mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4833,39148,4210956387659547011;eval_view_mode=front_single;report_eval_mode=chexpert-labels).pkl\" \\\n",
    "        --mimiccxr-preprocessed-train-data-filename \"mimiccxr_preprocessed_train_data__(hash=278,2530331200862576790).pkl\" \\\n",
    "        --calibrate-thresholds \\\n",
    "        --batch-size 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from medvqa.utils.files import load_pickle\n",
    "tmp = load_pickle('/mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230108_144908_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.6_medtok_orien_chx_ql_amp/mimiccxr_test_set_multilabel_classification_metrics(chexp-calib-thresh).pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chxlabel_prf1', 'chxlabelacc', 'chxlabel_rocauc', 'qlabels_prf1'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['p', 'r', 'f1', 'p_micro_avg', 'r_micro_avg', 'f1_micro_avg', 'p_macro_avg', 'r_macro_avg', 'f1_macro_avg'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['chxlabel_prf1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6098383004506381"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['chxlabel_prf1']['f1_micro_avg']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
