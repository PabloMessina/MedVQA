{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 300\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: yolov8\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: yolov8l.pt\n",
      "   yolov8_model_alias: yolov8l\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   batch_size: 28\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 1.0\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230523_133812_mim_Image2ReportModel(yolov8l->TransfTextDec(posenc(learned),es=512,hs=512,nl=3,nh=4,dff=512))\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: True\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: yolov8\n",
      "  num_bbox_classes: 22\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.Detect                [22, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43646802 parameters, 43646786 gradients, 165.5 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "    Initializing VinBig classification task\n",
      "MultilabelClassifier_v3:\n",
      "  local_feat_dim: 512\n",
      "  global_feat_dim: 1024\n",
      "  hidden_dim: 128\n",
      "  num_regions: 169\n",
      "  num_labels: 28\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    for_vinbig: returning vinbig transform\n",
      "    len(_augmented_bbox_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "  Loaded 18000 bounding boxes\n",
      "  self.bboxes[0]: ([], [])\n",
      "  self.bboxes[-1]: ([], [])\n",
      "  self.bboxes[500]: ([], [])\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=12652, #neg=5348\n",
      "Other disease     , #pos=4945, #neg=13055\n",
      "Aortic enlargement, #pos=3287, #neg=14713\n",
      "Cardiomegaly      , #pos=2609, #neg=15391\n",
      "Pleural thickening, #pos=2150, #neg=15850\n",
      "Pulmonary fibrosis, #pos=1834, #neg=16166\n",
      "Lung Opacity      , #pos=1406, #neg=16594\n",
      "Other lesion      , #pos=1228, #neg=16772\n",
      "Pneumonia         , #pos=1163, #neg=16837\n",
      "Pleural effusion  , #pos=1143, #neg=16857\n",
      "Nodule/Mass       , #pos=1006, #neg=16994\n",
      "Tuberculosis      , #pos=914, #neg=17086\n",
      "Infiltration      , #pos=671, #neg=17329\n",
      "Calcification     , #pos=646, #neg=17354\n",
      "ILD               , #pos=607, #neg=17393\n",
      "Consolidation     , #pos=449, #neg=17551\n",
      "Lung tumor        , #pos=371, #neg=17629\n",
      "Atelectasis       , #pos=272, #neg=17728\n",
      "Mediastinal shift , #pos=170, #neg=17830\n",
      "Enlarged PA       , #pos=139, #neg=17861\n",
      "Pneumothorax      , #pos=114, #neg=17886\n",
      "Rib fracture      , #pos=101, #neg=17899\n",
      "Emphysema         , #pos=81, #neg=17919\n",
      "Lung cavity       , #pos=59, #neg=17941\n",
      "COPD              , #pos=37, #neg=17963\n",
      "Lung cyst         , #pos=34, #neg=17966\n",
      "Clavicle fracture , #pos=29, #neg=17971\n",
      "Edema             , #pos=13, #neg=17987\n",
      "len(train_indices) = 18000\n",
      "len(self.test_indices) = 3000\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_234516_vinbig_yolov8l\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_234516_vinbig_yolov8l/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_26_chou+chuc+chuc+chuc+chuc+cD+gacc+lfss+wmmp=0.7107.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230523_133812_mim_Image2ReportModel(yolov8l->TransfTextDec(posenc(learned),es=512,hs=512,nl=3,nh=4,dff=512))/checkpoint_26_chou+chuc+chuc+chuc+chuc+cD+gacc+lfss+wmmp=0.7107.pt\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.0.2.weight, required shape: torch.Size([22, 256, 1, 1]), loaded shape: torch.Size([36, 256, 1, 1])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.0.2.bias, required shape: torch.Size([22]), loaded shape: torch.Size([36])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.1.2.weight, required shape: torch.Size([22, 256, 1, 1]), loaded shape: torch.Size([36, 256, 1, 1])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.1.2.bias, required shape: torch.Size([22]), loaded shape: torch.Size([36])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.2.2.weight, required shape: torch.Size([22, 256, 1, 1]), loaded shape: torch.Size([36, 256, 1, 1])\n",
      "Skip loading parameter: raw_image_encoder.model.22.cv3.2.2.bias, required shape: torch.Size([22]), loaded shape: torch.Size([36])\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230525_234516_vinbig_yolov8l/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m14) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 13.92897, y8_loss 11.81498, y8box_loss 2.99946, y8cls_loss 5.60449, y8dfl_loss 3.21103, vnbgprcaucmic 0.17682, vnbgprcaucmac 0.14697, vnbgl_loss 13.58085, 138.44 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.00000, vnbgbbmf1 0.00000, vnbglaucmic 0.71932, vnbglaucmac 0.54692, vnbgprcaucmic 0.14847, vnbgprcaucmac 0.09910, 35.92 secs\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 12.50494, y8_loss 9.94231, y8box_loss 2.59092, y8cls_loss 4.75631, y8dfl_loss 2.59509, vnbgprcaucmic 0.29512, vnbgprcaucmac 0.17111, vnbgl_loss 11.46441, 132.91 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.11179, vnbgbbmf1 0.02012, vnbglaucmic 0.91129, vnbglaucmac 0.80397, vnbgprcaucmic 0.54775, vnbgprcaucmac 0.17385, 42.35 secs\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000022) ...\n",
      "loss 10.32000, y8_loss 7.20953, y8box_loss 2.13040, y8cls_loss 3.16332, y8dfl_loss 1.91581, vnbgprcaucmic 0.66882, vnbgprcaucmac 0.33648, vnbgl_loss 8.45730, 136.47 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.23485, vnbgbbmf1 0.09624, vnbglaucmic 0.94985, vnbglaucmac 0.89170, vnbgprcaucmic 0.67383, vnbgprcaucmac 0.30225, 41.09 secs\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 7.87979, y8_loss 5.91283, y8box_loss 1.85703, y8cls_loss 2.38777, y8dfl_loss 1.66803, vnbgprcaucmic 0.77775, vnbgprcaucmac 0.46165, vnbgl_loss 6.92481, 136.05 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.26282, vnbgbbmf1 0.15125, vnbglaucmic 0.89087, vnbglaucmac 0.88099, vnbgprcaucmic 0.47873, vnbgprcaucmac 0.36714, 41.21 secs\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000056) ...\n",
      "loss 6.13148, y8_loss 5.34006, y8box_loss 1.70565, y8cls_loss 2.07243, y8dfl_loss 1.56198, vnbgprcaucmic 0.83062, vnbgprcaucmac 0.58152, vnbgl_loss 6.20342, 137.48 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.31224, vnbgbbmf1 0.20663, vnbglaucmic 0.94603, vnbglaucmac 0.91047, vnbgprcaucmic 0.66348, vnbgprcaucmac 0.40667, 41.49 secs\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000032) ...\n",
      "loss 5.99901, y8_loss 5.02854, y8box_loss 1.61756, y8cls_loss 1.90864, y8dfl_loss 1.50234, vnbgprcaucmic 0.86188, vnbgprcaucmac 0.64672, vnbgl_loss 5.81454, 136.83 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.36883, vnbgbbmf1 0.26269, vnbglaucmic 0.97731, vnbglaucmac 0.93853, vnbgprcaucmic 0.82708, vnbgprcaucmac 0.49843, 41.89 secs\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000018) ...\n",
      "loss 5.65590, y8_loss 4.83139, y8box_loss 1.55820, y8cls_loss 1.81097, y8dfl_loss 1.46221, vnbgprcaucmic 0.88048, vnbgprcaucmac 0.69015, vnbgl_loss 5.55834, 137.15 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.44073, vnbgbbmf1 0.28695, vnbglaucmic 0.97863, vnbglaucmac 0.94455, vnbgprcaucmic 0.83497, vnbgprcaucmac 0.51893, 41.06 secs\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 5.62910, y8_loss 4.64809, y8box_loss 1.49661, y8cls_loss 1.72812, y8dfl_loss 1.42336, vnbgprcaucmic 0.89667, vnbgprcaucmac 0.73270, vnbgl_loss 5.32811, 136.34 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.44342, vnbgbbmf1 0.31507, vnbglaucmic 0.98524, vnbglaucmac 0.95189, vnbgprcaucmic 0.87091, vnbgprcaucmac 0.56892, 40.67 secs\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 5.09159, y8_loss 4.54983, y8box_loss 1.46120, y8cls_loss 1.68755, y8dfl_loss 1.40108, vnbgprcaucmic 0.90437, vnbgprcaucmac 0.74083, vnbgl_loss 5.20473, 135.62 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.47339, vnbgbbmf1 0.33807, vnbglaucmic 0.98773, vnbglaucmac 0.95679, vnbgprcaucmic 0.88849, vnbgprcaucmac 0.59874, 40.88 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 5.13971, y8_loss 4.51605, y8box_loss 1.45115, y8cls_loss 1.66259, y8dfl_loss 1.40231, vnbgprcaucmic 0.90705, vnbgprcaucmac 0.75186, vnbgl_loss 5.15853, 137.08 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.47253, vnbgbbmf1 0.33856, vnbglaucmic 0.98870, vnbglaucmac 0.95871, vnbgprcaucmic 0.89533, vnbgprcaucmac 0.60903, 40.87 secs\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 5.13298, y8_loss 4.46648, y8box_loss 1.43081, y8cls_loss 1.65737, y8dfl_loss 1.37831, vnbgprcaucmic 0.91036, vnbgprcaucmac 0.77099, vnbgl_loss 5.09706, 138.69 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vnbgbbiou 0.46625, vnbgbbmf1 0.34680, vnbglaucmic 0.98884, vnbglaucmac 0.95875, vnbgprcaucmic 0.89648, vnbgprcaucmac 0.61103, 40.98 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.86119, y8_loss 4.42634, y8box_loss 1.41142, y8cls_loss 1.64035, y8dfl_loss 1.37457, vnbgprcaucmic 0.91359, vnbgprcaucmac 0.76571, vnbgl_loss 5.05225, 134.97 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.47813, vnbgbbmf1 0.35076, vnbglaucmic 0.98898, vnbglaucmac 0.95923, vnbgprcaucmic 0.89742, vnbgprcaucmac 0.61694, 41.23 secs\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.59091, y8_loss 4.81415, y8box_loss 1.56712, y8cls_loss 1.77902, y8dfl_loss 1.46800, vnbgprcaucmic 0.88068, vnbgprcaucmac 0.71137, vnbgl_loss 5.50333, 136.21 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.12444, vnbgbbmf1 0.10299, vnbglaucmic 0.78872, vnbglaucmac 0.79733, vnbgprcaucmic 0.26293, vnbgprcaucmac 0.20809, 45.19 secs\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 5.76688, y8_loss 4.54370, y8box_loss 1.49341, y8cls_loss 1.63500, y8dfl_loss 1.41529, vnbgprcaucmic 0.90850, vnbgprcaucmac 0.77767, vnbgl_loss 5.15125, 140.95 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.07778, vnbgbbmf1 0.06357, vnbglaucmic 0.59651, vnbglaucmac 0.72817, vnbgprcaucmic 0.09995, vnbgprcaucmac 0.15087, 43.58 secs\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 5.03112, y8_loss 4.18601, y8box_loss 1.37608, y8cls_loss 1.46826, y8dfl_loss 1.34168, vnbgprcaucmic 0.93402, vnbgprcaucmac 0.84730, vnbgl_loss 4.69894, 136.89 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.32560, vnbgbbmf1 0.28113, vnbglaucmic 0.95684, vnbglaucmac 0.92598, vnbgprcaucmic 0.72448, vnbgprcaucmac 0.48206, 42.10 secs\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 4.89890, y8_loss 4.00859, y8box_loss 1.31412, y8cls_loss 1.38795, y8dfl_loss 1.30652, vnbgprcaucmic 0.94505, vnbgprcaucmac 0.88193, vnbgl_loss 4.47028, 135.45 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.58295, vnbgbbmf1 0.44335, vnbglaucmic 0.99145, vnbglaucmac 0.96719, vnbgprcaucmic 0.92068, vnbgprcaucmac 0.75325, 41.46 secs\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 4.05169, y8_loss 3.88114, y8box_loss 1.26121, y8cls_loss 1.33861, y8dfl_loss 1.28133, vnbgprcaucmic 0.95278, vnbgprcaucmac 0.89622, vnbgl_loss 4.31413, 137.79 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.55020, vnbgbbmf1 0.45769, vnbglaucmic 0.99448, vnbglaucmac 0.97067, vnbgprcaucmic 0.94548, vnbgprcaucmac 0.78797, 42.22 secs\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.91751, y8_loss 3.80332, y8box_loss 1.23673, y8cls_loss 1.30033, y8dfl_loss 1.26626, vnbgprcaucmic 0.95697, vnbgprcaucmac 0.90734, vnbgl_loss 4.22158, 141.59 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.57652, vnbgbbmf1 0.48937, vnbglaucmic 0.99539, vnbglaucmac 0.97210, vnbgprcaucmic 0.95339, vnbgprcaucmac 0.80791, 42.85 secs\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.69593, y8_loss 3.73128, y8box_loss 1.20510, y8cls_loss 1.27751, y8dfl_loss 1.24866, vnbgprcaucmic 0.95897, vnbgprcaucmac 0.91084, vnbgl_loss 4.13617, 139.28 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.56625, vnbgbbmf1 0.48546, vnbglaucmic 0.99556, vnbglaucmac 0.97226, vnbgprcaucmic 0.95487, vnbgprcaucmac 0.81002, 42.88 secs\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 4.05797, y8_loss 3.74340, y8box_loss 1.21130, y8cls_loss 1.28300, y8dfl_loss 1.24911, vnbgprcaucmic 0.96041, vnbgprcaucmac 0.91481, vnbgl_loss 4.14672, 139.77 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.57894, vnbgbbmf1 0.49081, vnbglaucmic 0.99564, vnbglaucmac 0.97249, vnbgprcaucmic 0.95572, vnbgprcaucmac 0.81413, 42.33 secs\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 4.28951, y8_loss 4.19906, y8box_loss 1.39147, y8cls_loss 1.46527, y8dfl_loss 1.34232, vnbgprcaucmic 0.92754, vnbgprcaucmac 0.84525, vnbgl_loss 4.69701, 140.91 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.40221, vnbgbbmf1 0.25701, vnbglaucmic 0.96319, vnbglaucmac 0.92459, vnbgprcaucmic 0.77684, vnbgprcaucmac 0.45970, 41.76 secs\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.97262, y8_loss 4.01660, y8box_loss 1.34510, y8cls_loss 1.35530, y8dfl_loss 1.31620, vnbgprcaucmic 0.94384, vnbgprcaucmac 0.88499, vnbgl_loss 4.46043, 143.47 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.37206, vnbgbbmf1 0.34323, vnbglaucmic 0.96874, vnbglaucmac 0.93876, vnbgprcaucmic 0.77294, vnbgprcaucmac 0.57931, 42.64 secs\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.93839, y8_loss 3.67748, y8box_loss 1.22265, y8cls_loss 1.20540, y8dfl_loss 1.24944, vnbgprcaucmic 0.96232, vnbgprcaucmac 0.93239, vnbgl_loss 4.04019, 138.59 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.52561, vnbgbbmf1 0.49714, vnbglaucmic 0.99289, vnbglaucmac 0.96954, vnbgprcaucmic 0.93188, vnbgprcaucmac 0.81028, 40.44 secs\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.86923, y8_loss 3.45912, y8box_loss 1.14192, y8cls_loss 1.11690, y8dfl_loss 1.20031, vnbgprcaucmic 0.97250, vnbgprcaucmac 0.95207, vnbgl_loss 3.77548, 137.27 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.59901, vnbgbbmf1 0.56308, vnbglaucmic 0.99668, vnbglaucmac 0.97501, vnbgprcaucmic 0.96349, vnbgprcaucmac 0.89333, 42.28 secs\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.60335, y8_loss 3.34606, y8box_loss 1.09469, y8cls_loss 1.07166, y8dfl_loss 1.17971, vnbgprcaucmic 0.97601, vnbgprcaucmac 0.95920, vnbgl_loss 3.64001, 136.98 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.66632, vnbgbbmf1 0.60798, vnbglaucmic 0.99785, vnbglaucmac 0.97721, vnbgprcaucmic 0.97577, vnbgprcaucmac 0.91911, 42.12 secs\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.07561, y8_loss 3.27949, y8box_loss 1.06881, y8cls_loss 1.04543, y8dfl_loss 1.16525, vnbgprcaucmic 0.97745, vnbgprcaucmac 0.96369, vnbgl_loss 3.55946, 137.43 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.66243, vnbgbbmf1 0.60429, vnbglaucmic 0.99806, vnbglaucmac 0.97753, vnbgprcaucmic 0.97808, vnbgprcaucmac 0.92409, 43.00 secs\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.28893, y8_loss 3.24985, y8box_loss 1.05633, y8cls_loss 1.03261, y8dfl_loss 1.16090, vnbgprcaucmic 0.97997, vnbgprcaucmac 0.96778, vnbgl_loss 3.52146, 136.28 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.66080, vnbgbbmf1 0.62255, vnbglaucmic 0.99825, vnbglaucmac 0.97783, vnbgprcaucmic 0.98005, vnbgprcaucmac 0.92661, 43.62 secs\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.48630, y8_loss 3.24483, y8box_loss 1.05355, y8cls_loss 1.02740, y8dfl_loss 1.16388, vnbgprcaucmic 0.98014, vnbgprcaucmac 0.96346, vnbgl_loss 3.51688, 139.18 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.66791, vnbgbbmf1 0.62030, vnbglaucmic 0.99830, vnbglaucmac 0.97797, vnbgprcaucmic 0.98060, vnbgprcaucmac 0.92971, 42.06 secs\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.27346, y8_loss 3.77004, y8box_loss 1.26940, y8cls_loss 1.23416, y8dfl_loss 1.26649, vnbgprcaucmic 0.95532, vnbgprcaucmac 0.90715, vnbgl_loss 4.14713, 138.86 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.08629, vnbgbbmf1 0.03052, vnbglaucmic 0.88140, vnbglaucmac 0.77176, vnbgprcaucmic 0.52625, vnbgprcaucmac 0.19887, 41.45 secs\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 4.05557, y8_loss 3.61674, y8box_loss 1.21652, y8cls_loss 1.16129, y8dfl_loss 1.23894, vnbgprcaucmic 0.96397, vnbgprcaucmac 0.93584, vnbgl_loss 3.95451, 137.07 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.45536, vnbgbbmf1 0.37922, vnbglaucmic 0.97953, vnbglaucmac 0.95034, vnbgprcaucmic 0.83666, vnbgprcaucmac 0.64831, 41.99 secs\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.81168, y8_loss 3.30143, y8box_loss 1.10636, y8cls_loss 1.02227, y8dfl_loss 1.17280, vnbgprcaucmic 0.97786, vnbgprcaucmac 0.96533, vnbgl_loss 3.56659, 135.32 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.56078, vnbgbbmf1 0.55661, vnbglaucmic 0.99580, vnbglaucmac 0.97461, vnbgprcaucmic 0.95337, vnbgprcaucmac 0.88424, 42.94 secs\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.55431, y8_loss 3.10498, y8box_loss 1.02543, y8cls_loss 0.94507, y8dfl_loss 1.13447, vnbgprcaucmic 0.98462, vnbgprcaucmac 0.97548, vnbgl_loss 3.33037, 136.95 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vnbgbbiou 0.65829, vnbgbbmf1 0.64921, vnbglaucmic 0.99857, vnbglaucmac 0.97875, vnbgprcaucmic 0.98257, vnbgprcaucmac 0.94330, 42.05 secs\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.26521, y8_loss 2.98267, y8box_loss 0.97450, y8cls_loss 0.90204, y8dfl_loss 1.10614, vnbgprcaucmic 0.98760, vnbgprcaucmac 0.98229, vnbgl_loss 3.18815, 137.68 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.69560, vnbgbbmf1 0.65590, vnbglaucmic 0.99865, vnbglaucmac 0.97928, vnbgprcaucmic 0.98413, vnbgprcaucmac 0.94701, 41.81 secs\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.09666, y8_loss 2.93808, y8box_loss 0.95458, y8cls_loss 0.88628, y8dfl_loss 1.09723, vnbgprcaucmic 0.98857, vnbgprcaucmac 0.98441, vnbgl_loss 3.13516, 134.22 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.72778, vnbgbbmf1 0.68231, vnbglaucmic 0.99933, vnbglaucmac 0.98041, vnbgprcaucmic 0.99147, vnbgprcaucmac 0.95952, 41.90 secs\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.41473, y8_loss 2.91820, y8box_loss 0.94216, y8cls_loss 0.88047, y8dfl_loss 1.09557, vnbgprcaucmic 0.98886, vnbgprcaucmac 0.98474, vnbgl_loss 3.11054, 136.55 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.73204, vnbgbbmf1 0.69595, vnbglaucmic 0.99946, vnbglaucmac 0.98062, vnbgprcaucmic 0.99306, vnbgprcaucmac 0.96194, 41.28 secs\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.46575, y8_loss 2.90696, y8box_loss 0.93989, y8cls_loss 0.87315, y8dfl_loss 1.09392, vnbgprcaucmic 0.98960, vnbgprcaucmac 0.98259, vnbgl_loss 3.09885, 137.09 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.73267, vnbgbbmf1 0.69676, vnbglaucmic 0.99946, vnbglaucmac 0.98064, vnbgprcaucmic 0.99314, vnbgprcaucmac 0.96220, 42.99 secs\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 3.01353, y8_loss 3.39155, y8box_loss 1.14305, y8cls_loss 1.05682, y8dfl_loss 1.19168, vnbgprcaucmic 0.97207, vnbgprcaucmac 0.95549, vnbgl_loss 3.66906, 139.49 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.20720, vnbgbbmf1 0.28139, vnbglaucmic 0.90750, vnbglaucmac 0.89139, vnbgprcaucmic 0.47063, vnbgprcaucmac 0.45093, 42.98 secs\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.90141, y8_loss 3.31031, y8box_loss 1.12755, y8cls_loss 1.00528, y8dfl_loss 1.17749, vnbgprcaucmic 0.97788, vnbgprcaucmac 0.96084, vnbgl_loss 3.56767, 137.21 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.58292, vnbgbbmf1 0.54405, vnbglaucmic 0.99361, vnbglaucmac 0.97129, vnbgprcaucmic 0.94276, vnbgprcaucmac 0.86774, 44.02 secs\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.15617, y8_loss 3.02382, y8box_loss 1.01462, y8cls_loss 0.89221, y8dfl_loss 1.11699, vnbgprcaucmic 0.98672, vnbgprcaucmac 0.98040, vnbgl_loss 3.22699, 137.34 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.59212, vnbgbbmf1 0.61688, vnbglaucmic 0.99615, vnbglaucmac 0.97606, vnbgprcaucmic 0.95882, vnbgprcaucmac 0.91022, 42.18 secs\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 3.09161, y8_loss 2.84637, y8box_loss 0.93794, y8cls_loss 0.82692, y8dfl_loss 1.08151, vnbgprcaucmic 0.99111, vnbgprcaucmac 0.98770, vnbgl_loss 3.01193, 137.66 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.67175, vnbgbbmf1 0.68365, vnbglaucmic 0.99899, vnbglaucmac 0.98023, vnbgprcaucmic 0.98753, vnbgprcaucmac 0.95894, 44.05 secs\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.00264, y8_loss 2.73259, y8box_loss 0.88867, y8cls_loss 0.78508, y8dfl_loss 1.05884, vnbgprcaucmic 0.99312, vnbgprcaucmac 0.98917, vnbgl_loss 2.88631, 138.19 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.77342, vnbgbbmf1 0.72642, vnbglaucmic 0.99955, vnbglaucmac 0.98118, vnbgprcaucmic 0.99446, vnbgprcaucmac 0.96925, 42.94 secs\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 3.33131, y8_loss 2.69591, y8box_loss 0.86962, y8cls_loss 0.77259, y8dfl_loss 1.05370, vnbgprcaucmic 0.99323, vnbgprcaucmac 0.99035, vnbgl_loss 2.84334, 138.07 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.79127, vnbgbbmf1 0.74236, vnbglaucmic 0.99974, vnbglaucmac 0.98144, vnbgprcaucmic 0.99673, vnbgprcaucmac 0.97250, 42.88 secs\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.11252, y8_loss 2.66215, y8box_loss 0.85490, y8cls_loss 0.76079, y8dfl_loss 1.04646, vnbgprcaucmic 0.99359, vnbgprcaucmac 0.98994, vnbgl_loss 2.80732, 137.08 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.79208, vnbgbbmf1 0.73779, vnbglaucmic 0.99976, vnbglaucmac 0.98151, vnbgprcaucmic 0.99706, vnbgprcaucmac 0.97377, 40.59 secs\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.74104, y8_loss 2.67649, y8box_loss 0.86003, y8cls_loss 0.76672, y8dfl_loss 1.04974, vnbgprcaucmic 0.99417, vnbgprcaucmac 0.99220, vnbgl_loss 2.81769, 138.86 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.79158, vnbgbbmf1 0.74288, vnbglaucmic 0.99977, vnbglaucmac 0.98152, vnbgprcaucmic 0.99718, vnbgprcaucmac 0.97408, 36.92 secs\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 2.56128, y8_loss 3.14629, y8box_loss 1.06578, y8cls_loss 0.93907, y8dfl_loss 1.14143, vnbgprcaucmic 0.98061, vnbgprcaucmac 0.96679, vnbgl_loss 3.37390, 134.76 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.19748, vnbgbbmf1 0.20062, vnbglaucmic 0.93007, vnbglaucmac 0.89522, vnbgprcaucmic 0.55672, vnbgprcaucmac 0.41368, 36.39 secs\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.43892, y8_loss 3.09098, y8box_loss 1.05036, y8cls_loss 0.90600, y8dfl_loss 1.13462, vnbgprcaucmic 0.98380, vnbgprcaucmac 0.97560, vnbgl_loss 3.30151, 132.12 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.63839, vnbgbbmf1 0.55467, vnbglaucmic 0.99260, vnbglaucmac 0.97131, vnbgprcaucmic 0.93220, vnbgprcaucmac 0.84204, 35.13 secs\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 3.26564, y8_loss 2.81824, y8box_loss 0.94058, y8cls_loss 0.80030, y8dfl_loss 1.07737, vnbgprcaucmic 0.99154, vnbgprcaucmac 0.98719, vnbgl_loss 2.97625, 130.41 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.66369, vnbgbbmf1 0.69357, vnbglaucmic 0.99768, vnbglaucmac 0.97830, vnbgprcaucmic 0.97437, vnbgprcaucmac 0.93884, 34.33 secs\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.87124, y8_loss 2.61771, y8box_loss 0.85257, y8cls_loss 0.72783, y8dfl_loss 1.03730, vnbgprcaucmic 0.99457, vnbgprcaucmac 0.99250, vnbgl_loss 2.74693, 128.36 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.80554, vnbgbbmf1 0.74048, vnbglaucmic 0.99967, vnbglaucmac 0.98156, vnbgprcaucmic 0.99572, vnbgprcaucmac 0.97418, 34.48 secs\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.91007, y8_loss 2.55778, y8box_loss 0.82843, y8cls_loss 0.70638, y8dfl_loss 1.02296, vnbgprcaucmic 0.99559, vnbgprcaucmac 0.99393, vnbgl_loss 2.67742, 129.97 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.81905, vnbgbbmf1 0.75902, vnbglaucmic 0.99987, vnbglaucmac 0.98187, vnbgprcaucmic 0.99817, vnbgprcaucmac 0.97746, 34.62 secs\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.46176, y8_loss 2.52075, y8box_loss 0.80932, y8cls_loss 0.69559, y8dfl_loss 1.01583, vnbgprcaucmic 0.99612, vnbgprcaucmac 0.99462, vnbgl_loss 2.63170, 128.94 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.82807, vnbgbbmf1 0.76810, vnbglaucmic 0.99988, vnbglaucmac 0.98188, vnbgprcaucmic 0.99827, vnbgprcaucmac 0.97760, 35.55 secs\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.83213, y8_loss 2.48074, y8box_loss 0.78939, y8cls_loss 0.68131, y8dfl_loss 1.01004, vnbgprcaucmic 0.99646, vnbgprcaucmac 0.99489, vnbgl_loss 2.58840, 127.74 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.82233, vnbgbbmf1 0.77674, vnbglaucmic 0.99992, vnbglaucmac 0.98193, vnbgprcaucmic 0.99877, vnbgprcaucmac 0.97848, 35.02 secs\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.39628, y8_loss 2.48485, y8box_loss 0.78450, y8cls_loss 0.68338, y8dfl_loss 1.01697, vnbgprcaucmic 0.99645, vnbgprcaucmac 0.99486, vnbgl_loss 2.59168, 126.62 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.82464, vnbgbbmf1 0.77089, vnbglaucmic 0.99992, vnbglaucmac 0.98194, vnbgprcaucmic 0.99881, vnbgprcaucmac 0.97869, 33.47 secs\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 2.84258, y8_loss 2.93037, y8box_loss 0.99002, y8cls_loss 0.84331, y8dfl_loss 1.09704, vnbgprcaucmic 0.98610, vnbgprcaucmac 0.97480, vnbgl_loss 3.12041, 128.24 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.22856, vnbgbbmf1 0.23415, vnbglaucmic 0.92817, vnbglaucmac 0.88714, vnbgprcaucmic 0.61862, vnbgprcaucmac 0.38789, 35.19 secs\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 3.73777, y8_loss 2.87819, y8box_loss 0.97543, y8cls_loss 0.81346, y8dfl_loss 1.08930, vnbgprcaucmic 0.98885, vnbgprcaucmac 0.98314, vnbgl_loss 3.05096, 128.54 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.61354, vnbgbbmf1 0.61467, vnbglaucmic 0.99316, vnbglaucmac 0.97383, vnbgprcaucmic 0.93345, vnbgprcaucmac 0.84980, 34.22 secs\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 2.92232, y8_loss 2.66036, y8box_loss 0.88732, y8cls_loss 0.73092, y8dfl_loss 1.04212, vnbgprcaucmic 0.99341, vnbgprcaucmac 0.99105, vnbgl_loss 2.79265, 128.07 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.74976, vnbgbbmf1 0.75250, vnbglaucmic 0.99949, vnbglaucmac 0.98131, vnbgprcaucmic 0.99404, vnbgprcaucmac 0.97358, 34.69 secs\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 2.51135, y8_loss 2.49743, y8box_loss 0.81125, y8cls_loss 0.67175, y8dfl_loss 1.01444, vnbgprcaucmic 0.99616, vnbgprcaucmac 0.99456, vnbgl_loss 2.60466, 126.91 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.80377, vnbgbbmf1 0.80105, vnbglaucmic 0.99980, vnbglaucmac 0.98177, vnbgprcaucmic 0.99782, vnbgprcaucmac 0.97838, 34.00 secs\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 2.15499, y8_loss 2.39843, y8box_loss 0.76544, y8cls_loss 0.64079, y8dfl_loss 0.99221, vnbgprcaucmic 0.99741, vnbgprcaucmac 0.99615, vnbgl_loss 2.49028, 127.89 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.83761, vnbgbbmf1 0.81045, vnbglaucmic 0.99988, vnbglaucmac 0.98193, vnbgprcaucmic 0.99886, vnbgprcaucmac 0.98028, 34.58 secs\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.48507, y8_loss 2.37130, y8box_loss 0.75030, y8cls_loss 0.63225, y8dfl_loss 0.98875, vnbgprcaucmic 0.99714, vnbgprcaucmac 0.99617, vnbgl_loss 2.46286, 127.97 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.85746, vnbgbbmf1 0.83051, vnbglaucmic 0.99991, vnbglaucmac 0.98197, vnbgprcaucmic 0.99906, vnbgprcaucmac 0.98047, 33.50 secs\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 2.42694, y8_loss 2.35206, y8box_loss 0.74288, y8cls_loss 0.62812, y8dfl_loss 0.98105, vnbgprcaucmic 0.99742, vnbgprcaucmac 0.99616, vnbgl_loss 2.44191, 126.83 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.86011, vnbgbbmf1 0.83841, vnbglaucmic 0.99993, vnbglaucmac 0.98200, vnbgprcaucmic 0.99928, vnbgprcaucmac 0.98078, 33.97 secs\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.05442, y8_loss 2.32309, y8box_loss 0.72783, y8cls_loss 0.61799, y8dfl_loss 0.97727, vnbgprcaucmic 0.99757, vnbgprcaucmac 0.99716, vnbgl_loss 2.40812, 125.62 secs\n",
      "(2) Validation stage ...\n",
      "vnbgbbiou 0.86083, vnbgbbmf1 0.83266, vnbglaucmic 0.99994, vnbglaucmac 0.98201, vnbgprcaucmic 0.99933, vnbgprcaucmac 0.98081, 33.71 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/report_gen/20230523_133812_mim_Image2ReportModel(yolov8l->TransfTextDec(posenc(learned),es=512,hs=512,nl=3,nh=4,dff=512))\" \\\n",
    "        --epochs 60 \\\n",
    "        --batches-per-epoch 300 \\\n",
    "        --batch-size 28 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-decay-and-cyclic-decay-args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "        --use-vinbig \\\n",
    "        --vinbig-training-data-mode \"all\" \\\n",
    "        --vinbig-use-validation \\\n",
    "        --vinbig-weight 1.0 \\\n",
    "        --predict-bboxes-vinbig \\\n",
    "        --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "        --raw-image-encoding \"yolov8\" \\\n",
    "        --yolov8-model-name-or-path \"yolov8l.pt\" \\\n",
    "        --yolov8-model-alias \"yolov8l\" \\\n",
    "        --image-size 416 416 \\\n",
    "        --image-local-feat-size 512 \\\n",
    "        --num-regions 169 \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 1\n",
      "   batches_per_epoch: 10\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: yolov8\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chexpert_mlc_version: None\n",
      "   chexpert_mlc_hidden_size: 128\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   chest_imagenome_mlc_version: None\n",
      "   chest_imagenome_mlc_hidden_size: 128\n",
      "   vinbig_mlc_hidden_size: 128\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: None\n",
      "   num_regions: 169\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   roi_align_output_size: None\n",
      "   yolov8_model_name_or_path: yolov8l.pt\n",
      "   yolov8_model_alias: yolov8l\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "   batch_size: 19\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   image_size: [416, 416]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 1.0\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: any_single\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: False\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: False\n",
      "   override_lr: False\n",
      "   train_mimiccxr: False\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: True\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: True\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: focal+bce+wbce-c\n",
      "   focal_loss_weight: 1\n",
      "   bce_loss_weight: 1\n",
      "   wbce_loss_weight: 1\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: False\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: False\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   pass_pred_bbox_coords_as_input: False\n",
      "   use_gt_bboxes_as_predictions: False\n",
      "   predict_bboxes_vinbig: True\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: yolov8\n",
      "  num_bbox_classes: 22\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.Detect                [22, [256, 512, 512]]         \n",
      "Model summary: 365 layers, 43646802 parameters, 43646786 gradients, 165.5 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "    Initializing VinBig classification task\n",
      "MultilabelClassifier_v3:\n",
      "  local_feat_dim: 512\n",
      "  global_feat_dim: 1024\n",
      "  hidden_dim: 128\n",
      "  num_regions: 169\n",
      "  num_labels: 28\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\n",
      "1e-06 3 0.0001 8 1e-06 0.0001 8 1e-06\n",
      "self.steps_to_restart = 8\n",
      "self.steps = -1\n",
      "self.initial_lr = 0.0001\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "Using focal+bce+wbce-c loss\n",
      "binary_loss_kwargs: {'focal_weight': 1, 'bce_weight': 1, 'wbce_weight': 1}\n",
      "Focal_BCE_WBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbce_weight = 0.3333333333333333\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating VinBig visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    for_vinbig: returning vinbig transform\n",
      "    len(_augmented_bbox_transforms) = 10\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.5\n",
      "    horizontal_flip_prob = 0\n",
      "    flip_image = False\n",
      "    Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "  Loaded 18000 bounding boxes\n",
      "  self.bboxes[0]: ([], [])\n",
      "  self.bboxes[-1]: ([], [])\n",
      "  self.bboxes[500]: ([], [])\n",
      "Generating train dataset and dataloader\n",
      "No finding        , #pos=12652, #neg=5348\n",
      "Other disease     , #pos=4945, #neg=13055\n",
      "Aortic enlargement, #pos=3287, #neg=14713\n",
      "Cardiomegaly      , #pos=2609, #neg=15391\n",
      "Pleural thickening, #pos=2150, #neg=15850\n",
      "Pulmonary fibrosis, #pos=1834, #neg=16166\n",
      "Lung Opacity      , #pos=1406, #neg=16594\n",
      "Other lesion      , #pos=1228, #neg=16772\n",
      "Pneumonia         , #pos=1163, #neg=16837\n",
      "Pleural effusion  , #pos=1143, #neg=16857\n",
      "Nodule/Mass       , #pos=1006, #neg=16994\n",
      "Tuberculosis      , #pos=914, #neg=17086\n",
      "Infiltration      , #pos=671, #neg=17329\n",
      "Calcification     , #pos=646, #neg=17354\n",
      "ILD               , #pos=607, #neg=17393\n",
      "Consolidation     , #pos=449, #neg=17551\n",
      "Lung tumor        , #pos=371, #neg=17629\n",
      "Atelectasis       , #pos=272, #neg=17728\n",
      "Mediastinal shift , #pos=170, #neg=17830\n",
      "Enlarged PA       , #pos=139, #neg=17861\n",
      "Pneumothorax      , #pos=114, #neg=17886\n",
      "Rib fracture      , #pos=101, #neg=17899\n",
      "Emphysema         , #pos=81, #neg=17919\n",
      "Lung cavity       , #pos=59, #neg=17941\n",
      "COPD              , #pos=37, #neg=17963\n",
      "Lung cyst         , #pos=34, #neg=17966\n",
      "Clavicle fracture , #pos=29, #neg=17971\n",
      "Edema             , #pos=13, #neg=17987\n",
      "len(train_indices) = 18000\n",
      "len(self.test_indices) = 3000\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/1\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "gt_labels.shape: torch.Size([19, 18, 1]), gt_bboxes.shape: torch.Size([19, 18, 4]), mask_gt.shape: torch.Size([19, 18, 1])\n",
      "gt_labels[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 16, 1]), gt_bboxes.shape: torch.Size([19, 16, 4]), mask_gt.shape: torch.Size([19, 16, 1])\n",
      "gt_labels[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 26, 1]), gt_bboxes.shape: torch.Size([19, 26, 4]), mask_gt.shape: torch.Size([19, 26, 1])\n",
      "gt_labels[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 18, 1]), gt_bboxes.shape: torch.Size([19, 18, 4]), mask_gt.shape: torch.Size([19, 18, 1])\n",
      "gt_labels[0] = tensor([[ 0.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [16.],\n",
      "        [16.],\n",
      "        [16.],\n",
      "        [16.],\n",
      "        [20.],\n",
      "        [20.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 20, 1]), gt_bboxes.shape: torch.Size([19, 20, 4]), mask_gt.shape: torch.Size([19, 20, 1])\n",
      "gt_labels[0] = tensor([[18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [18.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [ 0.],\n",
      "        [16.],\n",
      "        [16.],\n",
      "        [ 9.],\n",
      "        [20.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 31, 1]), gt_bboxes.shape: torch.Size([19, 31, 4]), mask_gt.shape: torch.Size([19, 31, 1])\n",
      "gt_labels[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 31, 1]), gt_bboxes.shape: torch.Size([19, 31, 4]), mask_gt.shape: torch.Size([19, 31, 1])\n",
      "gt_labels[0] = tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [10.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 19, 1]), gt_bboxes.shape: torch.Size([19, 19, 4]), mask_gt.shape: torch.Size([19, 19, 1])\n",
      "gt_labels[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 19, 1]), gt_bboxes.shape: torch.Size([19, 19, 4]), mask_gt.shape: torch.Size([19, 19, 1])\n",
      "gt_labels[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "gt_labels.shape: torch.Size([19, 18, 1]), gt_bboxes.shape: torch.Size([19, 18, 4]), mask_gt.shape: torch.Size([19, 18, 1])\n",
      "gt_labels[0] = tensor([[18.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [17.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.]], device='cuda:0')\n",
      "mask_gt[0] = tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "target_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "target_scores.shape: torch.Size([19, 3549, 22])\n",
      "target_scores_sum.shape: torch.Size([])\n",
      "fg_mask.shape: torch.Size([19, 3549])\n",
      "pred_scores.shape: torch.Size([19, 3549, 22])\n",
      "pred_bboxes.shape: torch.Size([19, 3549, 4])\n",
      "---\n",
      "pred_distri.shape: torch.Size([19, 3549, 64])\n",
      "anchor_points.shape: torch.Size([3549, 2])\n",
      "loss 13.70953, y8_loss 11.54383, y8box_loss 3.08657, y8cls_loss 5.65869, y8dfl_loss 2.79857, vnbgprcaucmic 0.11682, vnbgprcaucmac 0.14172, vnbgl_loss 13.39416, 5.54 secs\n",
      "(2) Validation stage ...\n",
      "^C\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "        --epochs 1 \\\n",
    "        --batches-per-epoch 10 \\\n",
    "        --batch-size 19 \\\n",
    "        --num-workers 3 \\\n",
    "        --iters-to-accumulate 4 \\\n",
    "        --optimizer-name \"adamw\" \\\n",
    "        --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "        --lr 1e-6 \\\n",
    "        --warmup-decay-and-cyclic-decay-args \"1e-6,3,1e-4,8,1e-6,1e-4,8,1e-6\" \\\n",
    "        --use-vinbig \\\n",
    "        --vinbig-training-data-mode \"all\" \\\n",
    "        --vinbig-use-validation \\\n",
    "        --vinbig-weight 1.0 \\\n",
    "        --predict-bboxes-vinbig \\\n",
    "        --binary-loss-name \"focal+bce+wbce-c\" \\\n",
    "        --raw-image-encoding \"yolov8\" \\\n",
    "        --yolov8-model-name-or-path \"yolov8l.pt\" \\\n",
    "        --yolov8-model-alias \"yolov8l\" \\\n",
    "        --image-size 416 416 \\\n",
    "        --image-local-feat-size 512 \\\n",
    "        --num-regions 169 \\\n",
    "        --img-aug-mode \"random-color-and-spatial\" \\\n",
    "        --use-amp \\\n",
    "        --no-save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
