{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 201\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: detectron2\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: COCO-Detection/retinanet_R_50_FPN_1x.yaml\n",
      "   num_regions: None\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,5,1e-4,7,1e-6,3e-5,7,1e-6\n",
      "   batch_size: 40\n",
      "   iters_to_accumulate: 3\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [512, 512]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "avg_coords.shape= (144,)\n",
      "source_image_size_mode: medium_512\n",
      "Loading config /home/pamessina/venv/lib/python3.6/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: detectron2\n",
      "Loading config /home/pamessina/venv/lib/python3.6/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "Building Detectron2 model\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.RETINANET.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "Detectron2 model successfully built\n",
      "Loading weights from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (324, 256, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (324,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mhead.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "Weights successfully loaded\n",
      "  Initializing auxiliary tasks\n",
      "MultiPurposeVisualModule: self.name=D2-CocoDet-retinanet-R-50-FPN-1x\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,5,1e-4,7,1e-6,3e-5,7,1e-6\n",
      "1e-06 5 0.0001 7 1e-06 3e-05 7 1e-06\n",
      "self.steps_to_restart = 7\n",
      "self.steps = -1\n",
      "self.initial_lr = 3e-05\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Using source image size mode: medium_512\n",
      "  0%|                                                | 0/227835 [00:00<?, ?it/s]image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n",
      "100%|████████████████████████████████| 227835/227835 [00:04<00:00, 50902.17it/s]\n",
      "max_idx_count: 368960\n",
      "idx: 234217\n",
      "** NOTE: 134743 images were skipped because they were not in the allowed DICOM IDs\n",
      "Using source image size mode: medium_512\n",
      "100%|██████████████████████████████| 227835/227835 [00:00<00:00, 1844324.84it/s]\n",
      "max_idx_count: 2991\n",
      "idx: 1934\n",
      "** NOTE: 1057 images were skipped because they were not in the allowed DICOM IDs\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_122709_mim_D2-CocoDet-retinanet-R-50-FPN-1x\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_122709_mim_D2-CocoDet-retinanet-R-50-FPN-1x/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_122709_mim_D2-CocoDet-retinanet-R-50-FPN-1x/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 17.86196, d2box_loss 4.53752, d2cls_loss 1.25794, 147.97 secs\n",
      "(2) Validation stage ...\n",
      "WARNING: Bbox MAE defaulting to 0 since self._count is 0\n",
      "WARNING: Bbox IOU defaulting to 0 since self._count is 0\n",
      "chestimgbbmf1 0.00000, chestimgbbiou 0.00000, chestimgbbmae 0.00000, 25.70 secs\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 9.29525, d2box_loss 3.31056, d2cls_loss 1.03079, 143.44 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.00033, chestimgbbiou 0.27209, chestimgbbmae 88.51000, 46.03 secs\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.80329, d2box_loss 3.25747, d2cls_loss 0.74587, 143.60 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.00380, chestimgbbiou 0.53911, chestimgbbmae 49.66633, 46.54 secs\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000016) ...\n",
      "loss 6.93313, d2box_loss 2.66873, d2cls_loss 0.53788, 142.80 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.04891, chestimgbbiou 0.71862, chestimgbbmae 17.46064, 50.10 secs\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000040) ...\n",
      "loss 0.58922, d2box_loss 2.10040, d2cls_loss 0.48446, 143.87 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.06226, chestimgbbiou 0.71631, chestimgbbmae 13.74471, 53.90 secs\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000100) ...\n",
      "loss 8.11888, d2box_loss 1.78433, d2cls_loss 0.44294, 144.02 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.06934, chestimgbbiou 0.70945, chestimgbbmae 14.76202, 54.47 secs\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000052) ...\n",
      "loss 0.56134, d2box_loss 1.55290, d2cls_loss 0.41208, 143.99 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.09166, chestimgbbiou 0.72567, chestimgbbmae 13.02733, 55.63 secs\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.46296, d2box_loss 1.25115, d2cls_loss 0.36322, 143.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.13079, chestimgbbiou 0.78149, chestimgbbmae 9.81804, 53.79 secs\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 7.21211, d2box_loss 1.28180, d2cls_loss 0.37049, 143.46 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.13679, chestimgbbiou 0.73450, chestimgbbmae 11.95807, 56.85 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 3.51451, d2box_loss 1.13199, d2cls_loss 0.35028, 144.67 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.14124, chestimgbbiou 0.74424, chestimgbbmae 11.41777, 57.24 secs\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.38838, d2box_loss 1.20287, d2cls_loss 0.36162, 143.69 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.14301, chestimgbbiou 0.75246, chestimgbbmae 10.92342, 56.38 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "Current run is terminating due to exception: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/fvcore/nn/focal_loss.py\", line 36, in sigmoid_focal_loss\n",
      "    targets = targets.float()\n",
      "    p = torch.sigmoid(inputs)\n",
      "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    p_t = p * targets + (1 - p) * (1 - targets)\n",
      "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/functional.py\", line 2982, in binary_cross_entropy_with_logits\n",
      "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
      "\n",
      "    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 920.00 MiB (GPU 0; 23.70 GiB total capacity; 20.39 GiB already allocated; 104.38 MiB free; 21.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "Engine run is terminating due to exception: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/fvcore/nn/focal_loss.py\", line 36, in sigmoid_focal_loss\n",
      "    targets = targets.float()\n",
      "    p = torch.sigmoid(inputs)\n",
      "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    p_t = p * targets + (1 - p) * (1 - targets)\n",
      "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/functional.py\", line 2982, in binary_cross_entropy_with_logits\n",
      "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
      "\n",
      "    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 920.00 MiB (GPU 0; 23.70 GiB total capacity; 20.39 GiB already allocated; 104.38 MiB free; 21.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../train_visual_module.py\", line 1418, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"../train_visual_module.py\", line 1317, in train_from_scratch\n",
      "    debug=debug)\n",
      "  File \"../train_visual_module.py\", line 836, in train_model\n",
      "    epoch_length = batches_per_epoch)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 775, in step_fn\n",
      "    output = step_fn__mimiccxr_chest_imagenome_detectron2(batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/vqa.py\", line 123, in step_fn__mimiccxr_chest_imagenome_detectron2\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 457, in forward\n",
      "    return self.raw_image_encoder(detectron2_input)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/detectron2/modeling/meta_arch/dense_detector.py\", line 101, in forward\n",
      "    return self.forward_training(images, features, predictions, gt_instances)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/detectron2/modeling/meta_arch/retinanet.py\", line 158, in forward_training\n",
      "    return self.losses(anchors, pred_logits, gt_labels, pred_anchor_deltas, gt_boxes)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/detectron2/modeling/meta_arch/retinanet.py\", line 194, in losses\n",
      "    reduction=\"sum\",\n",
      "RuntimeError: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript (most recent call last):\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/fvcore/nn/focal_loss.py\", line 36, in sigmoid_focal_loss\n",
      "    targets = targets.float()\n",
      "    p = torch.sigmoid(inputs)\n",
      "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
      "              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    p_t = p * targets + (1 - p) * (1 - targets)\n",
      "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
      "  File \"/home/pamessina/venv/lib/python3.6/site-packages/torch/nn/functional.py\", line 2982, in binary_cross_entropy_with_logits\n",
      "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
      "\n",
      "    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 920.00 MiB (GPU 0; 23.70 GiB total capacity; 20.39 GiB already allocated; 104.38 MiB free; 21.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "    --epochs 60 \\\n",
    "    --batches-per-epoch 201 \\\n",
    "    --batch-size 40 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 3 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-decay-and-cyclic-decay-args \"1e-6,5,1e-4,7,1e-6,3e-5,7,1e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "    --predict-bboxes-chest-imagenome \\\n",
    "    --clamp-bboxes-chest-imagenome \\\n",
    "    --use-chest-imagenome-decent-images-only \\\n",
    "    --raw-image-encoding \"detectron2\" \\\n",
    "    --detectron2-model-yaml \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\" \\\n",
    "    --image-size 512 512 \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 60\n",
      "   batches_per_epoch: 200\n",
      "   checkpoint_folder: None\n",
      "   visual_input_mode: raw-image\n",
      "   raw_image_encoding: detectron2\n",
      "   image_local_feat_size: 1024\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   freeze_image_encoder: False\n",
      "   imagenet_pretrained: False\n",
      "   visual_features_mlp_in_dim: None\n",
      "   visual_features_mlp_out_dim: None\n",
      "   visual_features_mlp_hidden_dims: None\n",
      "   iuxray_precomputed_visual_features_path: None\n",
      "   mimiccxr_precomputed_visual_features_path: None\n",
      "   chexpert_precomputed_visual_features_path: None\n",
      "   vinbig_precomputed_visual_features_path: None\n",
      "   clip_version: None\n",
      "   huggingface_model_name: None\n",
      "   chest_imagenome_bbox_hidden_size: 128\n",
      "   chest_imagenome_bbox_regressor_version: None\n",
      "   torchxrayvision_weights_name: None\n",
      "   detectron2_model_yaml: COCO-Detection/retinanet_R_50_FPN_1x.yaml\n",
      "   num_regions: None\n",
      "   roi_heads_batch_size_per_image: 128\n",
      "   rpn_batch_size_per_image: 128\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,5,8e-5,7,1e-6,3e-5,7,1e-6\n",
      "   batch_size: 25\n",
      "   iters_to_accumulate: 4\n",
      "   num_workers: 3\n",
      "   device: GPU\n",
      "   img_aug_mode: None\n",
      "   image_size: [512, 512]\n",
      "   horizontal_flip_prob: 0\n",
      "   mimiccxr_weight: 1.0\n",
      "   chexpert_weight: 0.3\n",
      "   cxr14_weight: 0.3\n",
      "   vinbig_weight: 0.3\n",
      "   iuxray_weight: 0.05\n",
      "   padchest_weight: 0.4\n",
      "   mimiccxr_view_mode: chest_imagenome\n",
      "   mimiccxr_balanced_sampling_mode: None\n",
      "   chest_imagenome_labels_filename: None\n",
      "   chest_imagenome_label_names_filename: None\n",
      "   use_chest_imagenome_decent_images_only: True\n",
      "   use_amp: True\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_122709_mim_D2-CocoDet-retinanet-R-50-FPN-1x\n",
      "   save: True\n",
      "   override_lr: False\n",
      "   train_mimiccxr: True\n",
      "   train_iuxray: False\n",
      "   train_chexpert: False\n",
      "   train_cxr14: False\n",
      "   train_vinbig: False\n",
      "   vinbig_training_data_mode: all\n",
      "   vinbig_use_validation: False\n",
      "   train_padchest: False\n",
      "   padchest_training_data_mode: train\n",
      "   padchest_use_validation: False\n",
      "   padchest_train_study_ids_path: None\n",
      "   padchest_val_study_ids_path: None\n",
      "   padchest_test_study_ids_path: None\n",
      "   binary_loss_name: bce\n",
      "   classify_tags: False\n",
      "   n_medical_tags: None\n",
      "   iuxray_medical_tags_per_report_filename: None\n",
      "   mimiccxr_medical_tags_per_report_filename: None\n",
      "   classify_orientation: False\n",
      "   classify_gender: False\n",
      "   classify_chexpert: False\n",
      "   iuxray_chexpert_labels_filename: None\n",
      "   mimiccxr_chexpert_labels_filename: None\n",
      "   classify_chest_imagenome: False\n",
      "   predict_bboxes_chest_imagenome: True\n",
      "   predict_labels_and_bboxes_chest_imagenome: False\n",
      "   clamp_bboxes_chest_imagenome: True\n",
      "   use_anaxnet_bbox_subset: False\n",
      "   chest_imagenome_bbox_loss_weight: 1.0\n",
      "   classify_questions: False\n",
      "   n_mined_questions: None\n",
      "   iuxray_question_labels_filename: None\n",
      "   mimiccxr_question_labels_filename: None\n",
      "   merge_findings: False\n",
      "\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chest_imagenome/chest_imagenome_train_average_bbox_coords(clamped)_decent_images_only(avg_coef_0.4_std_coef_0.5).pkl...\n",
      "avg_coords.shape= (144,)\n",
      "source_image_size_mode: medium_512\n",
      "Loading config /home/pamessina/venv/lib/python3.6/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mCreating instance of MultiPurposeVisualModule ...\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: detectron2\n",
      "Loading config /home/pamessina/venv/lib/python3.6/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "Building Detectron2 model\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.RETINANET.NUM_CLASSES overriden to 36\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE overriden to 128\n",
      "Detectron2 model successfully built\n",
      "Loading weights from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "Skip loading parameter 'head.cls_score.weight' to the model due to incompatible shapes: (720, 256, 3, 3) in the checkpoint but (324, 256, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'head.cls_score.bias' to the model due to incompatible shapes: (720,) in the checkpoint but (324,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mhead.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "Weights successfully loaded\n",
      "  Initializing auxiliary tasks\n",
      "MultiPurposeVisualModule: self.name=D2-CocoDet-retinanet-R-50-FPN-1x\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,5,8e-5,7,1e-6,3e-5,7,1e-6\n",
      "1e-06 5 8e-05 7 1e-06 3e-05 7 1e-06\n",
      "self.steps_to_restart = 7\n",
      "self.steps = -1\n",
      "self.initial_lr = 3e-05\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "get_engine(): shift_answer=False\n",
      "chest_imagenome_bbox_loss_weight:  1.0\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mCreating MIMIC-CXR visual module trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "get_image_transform()\n",
      "  Using detectron2 aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "Using source image size mode: medium_512\n",
      "  0%|                                                | 0/227835 [00:00<?, ?it/s]image_size_cache loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/image_size_cache.pkl\n",
      "100%|████████████████████████████████| 227835/227835 [00:04<00:00, 50826.99it/s]\n",
      "max_idx_count: 368960\n",
      "idx: 234217\n",
      "** NOTE: 134743 images were skipped because they were not in the allowed DICOM IDs\n",
      "Using source image size mode: medium_512\n",
      "100%|██████████████████████████████| 227835/227835 [00:00<00:00, 1864909.08it/s]\n",
      "max_idx_count: 2991\n",
      "idx: 1934\n",
      "** NOTE: 1057 images were skipped because they were not in the allowed DICOM IDs\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "NOTE: Using only validation metrics\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_131042_mim_D2-CocoDet-retinanet-R-50-FPN-1x\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_131042_mim_D2-CocoDet-retinanet-R-50-FPN-1x/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_11_chestimgbbmf1=0.1430.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_122709_mim_D2-CocoDet-retinanet-R-50-FPN-1x/checkpoint_11_chestimgbbmf1=0.1430.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint successfully loaded!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m13) \u001b[0m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_131042_mim_D2-CocoDet-retinanet-R-50-FPN-1x/metrics_logs.csv\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m14) \u001b[0m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 5.38763, d2box_loss 1.18639, d2cls_loss 0.38389, 94.17 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.14482, chestimgbbiou 0.74817, chestimgbbmae 11.09794, 55.10 secs\n",
      "\u001b[1m---- Epoch 2/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.28917, d2box_loss 1.11440, d2cls_loss 0.34462, 89.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.14329, chestimgbbiou 0.73517, chestimgbbmae 12.03499, 56.23 secs\n",
      "\u001b[1m---- Epoch 3/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 5.42767, d2box_loss 1.13575, d2cls_loss 0.34976, 90.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.14587, chestimgbbiou 0.73923, chestimgbbmae 11.57930, 58.59 secs\n",
      "\u001b[1m---- Epoch 4/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.24832, d2box_loss 1.05316, d2cls_loss 0.32782, 91.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.14737, chestimgbbiou 0.74988, chestimgbbmae 11.05107, 57.56 secs\n",
      "\u001b[1m---- Epoch 5/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.28474, d2box_loss 1.29441, d2cls_loss 0.37426, 89.39 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.12834, chestimgbbiou 0.73451, chestimgbbmae 12.01051, 57.59 secs\n",
      "\u001b[1m---- Epoch 6/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 5.61823, d2box_loss 1.42061, d2cls_loss 0.37513, 89.65 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.11709, chestimgbbiou 0.73032, chestimgbbmae 13.41099, 57.79 secs\n",
      "\u001b[1m---- Epoch 7/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000043) ...\n",
      "loss 0.38670, d2box_loss 1.32978, d2cls_loss 0.37001, 89.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.15682, chestimgbbiou 0.76617, chestimgbbmae 9.93222, 57.70 secs\n",
      "\u001b[1m---- Epoch 8/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000023) ...\n",
      "loss 0.36654, d2box_loss 1.14561, d2cls_loss 0.34188, 89.21 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.16385, chestimgbbiou 0.73979, chestimgbbmae 11.65368, 58.85 secs\n",
      "\u001b[1m---- Epoch 9/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000012) ...\n",
      "loss 0.33730, d2box_loss 1.18536, d2cls_loss 0.34720, 89.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18043, chestimgbbiou 0.75133, chestimgbbmae 10.56067, 57.99 secs\n",
      "\u001b[1m---- Epoch 10/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000007) ...\n",
      "loss 0.25959, d2box_loss 1.10683, d2cls_loss 0.34230, 89.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18507, chestimgbbiou 0.77059, chestimgbbmae 9.66818, 56.58 secs\n",
      "\u001b[1m---- Epoch 11/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.24534, d2box_loss 0.98153, d2cls_loss 0.31674, 89.26 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18428, chestimgbbiou 0.75381, chestimgbbmae 10.52105, 58.41 secs\n",
      "\u001b[1m---- Epoch 12/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.47140, d2box_loss 1.10100, d2cls_loss 0.33312, 89.68 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18744, chestimgbbiou 0.76499, chestimgbbmae 9.95758, 58.73 secs\n",
      "\u001b[1m---- Epoch 13/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.48743, d2box_loss 1.11556, d2cls_loss 0.32834, 89.72 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18824, chestimgbbiou 0.76610, chestimgbbmae 9.92193, 58.37 secs\n",
      "\u001b[1m---- Epoch 14/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.47840, d2box_loss 0.96744, d2cls_loss 0.32786, 89.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.17677, chestimgbbiou 0.75430, chestimgbbmae 10.44492, 58.02 secs\n",
      "\u001b[1m---- Epoch 15/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 4.78221, d2box_loss 1.12016, d2cls_loss 0.33823, 89.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18493, chestimgbbiou 0.76738, chestimgbbmae 9.71853, 58.12 secs\n",
      "\u001b[1m---- Epoch 16/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.34010, d2box_loss 0.95830, d2cls_loss 0.31042, 89.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.19433, chestimgbbiou 0.78254, chestimgbbmae 8.99990, 57.64 secs\n",
      "\u001b[1m---- Epoch 17/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.36279, d2box_loss 1.07444, d2cls_loss 0.33314, 89.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.19927, chestimgbbiou 0.78565, chestimgbbmae 8.90008, 57.32 secs\n",
      "\u001b[1m---- Epoch 18/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.31916, d2box_loss 1.02848, d2cls_loss 0.32707, 89.59 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20009, chestimgbbiou 0.77388, chestimgbbmae 9.42571, 58.57 secs\n",
      "\u001b[1m---- Epoch 19/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.35405, d2box_loss 1.16708, d2cls_loss 0.33833, 89.73 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.19964, chestimgbbiou 0.77209, chestimgbbmae 9.49493, 58.50 secs\n",
      "\u001b[1m---- Epoch 20/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.38793, d2box_loss 1.12042, d2cls_loss 0.33475, 89.54 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20160, chestimgbbiou 0.77648, chestimgbbmae 9.25722, 57.52 secs\n",
      "\u001b[1m---- Epoch 21/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.31542, d2box_loss 1.04042, d2cls_loss 0.34389, 89.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18943, chestimgbbiou 0.76990, chestimgbbmae 9.54378, 57.91 secs\n",
      "\u001b[1m---- Epoch 22/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.38412, d2box_loss 0.87997, d2cls_loss 0.30529, 90.07 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.19670, chestimgbbiou 0.76689, chestimgbbmae 9.98064, 59.39 secs\n",
      "\u001b[1m---- Epoch 23/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.36044, d2box_loss 1.17275, d2cls_loss 0.34061, 89.76 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20642, chestimgbbiou 0.77022, chestimgbbmae 9.60388, 58.64 secs\n",
      "\u001b[1m---- Epoch 24/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.23330, d2box_loss 0.97123, d2cls_loss 0.31079, 89.93 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21001, chestimgbbiou 0.78383, chestimgbbmae 8.75992, 58.10 secs\n",
      "\u001b[1m---- Epoch 25/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.39982, d2box_loss 1.00278, d2cls_loss 0.32402, 89.69 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21009, chestimgbbiou 0.77173, chestimgbbmae 9.38597, 58.85 secs\n",
      "\u001b[1m---- Epoch 26/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 3.98401, d2box_loss 0.99590, d2cls_loss 0.31631, 89.63 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21318, chestimgbbiou 0.78119, chestimgbbmae 8.92853, 58.69 secs\n",
      "\u001b[1m---- Epoch 27/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.35291, d2box_loss 1.10635, d2cls_loss 0.33601, 90.30 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20998, chestimgbbiou 0.77006, chestimgbbmae 9.56177, 59.42 secs\n",
      "\u001b[1m---- Epoch 28/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.25346, d2box_loss 1.09448, d2cls_loss 0.33107, 89.97 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18299, chestimgbbiou 0.77632, chestimgbbmae 9.29213, 58.84 secs\n",
      "\u001b[1m---- Epoch 29/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 6.19176, d2box_loss 1.04328, d2cls_loss 0.33113, 89.64 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20614, chestimgbbiou 0.77756, chestimgbbmae 9.17793, 58.90 secs\n",
      "\u001b[1m---- Epoch 30/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.31556, d2box_loss 0.98280, d2cls_loss 0.32286, 90.43 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20733, chestimgbbiou 0.76703, chestimgbbmae 9.70445, 59.23 secs\n",
      "\u001b[1m---- Epoch 31/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.30320, d2box_loss 1.17621, d2cls_loss 0.33797, 90.15 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21222, chestimgbbiou 0.76785, chestimgbbmae 9.73100, 59.38 secs\n",
      "\u001b[1m---- Epoch 32/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.30522, d2box_loss 0.93951, d2cls_loss 0.32376, 89.65 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21695, chestimgbbiou 0.77806, chestimgbbmae 9.12364, 58.81 secs\n",
      "\u001b[1m---- Epoch 33/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 4.04219, d2box_loss 0.99259, d2cls_loss 0.31780, 89.79 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22030, chestimgbbiou 0.78526, chestimgbbmae 8.68113, 56.99 secs\n",
      "\u001b[1m---- Epoch 34/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.37992, d2box_loss 1.03094, d2cls_loss 0.33181, 89.91 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21952, chestimgbbiou 0.78233, chestimgbbmae 8.83832, 58.76 secs\n",
      "\u001b[1m---- Epoch 35/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.30252, d2box_loss 1.04847, d2cls_loss 0.32941, 89.57 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20831, chestimgbbiou 0.80791, chestimgbbmae 8.03820, 56.83 secs\n",
      "\u001b[1m---- Epoch 36/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.43798, d2box_loss 1.02429, d2cls_loss 0.31775, 89.58 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21234, chestimgbbiou 0.78346, chestimgbbmae 8.77533, 58.59 secs\n",
      "\u001b[1m---- Epoch 37/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.22772, d2box_loss 0.92265, d2cls_loss 0.30547, 90.31 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20563, chestimgbbiou 0.72907, chestimgbbmae 12.43825, 61.46 secs\n",
      "\u001b[1m---- Epoch 38/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.23749, d2box_loss 0.92212, d2cls_loss 0.30802, 90.42 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22291, chestimgbbiou 0.78123, chestimgbbmae 8.84564, 58.96 secs\n",
      "\u001b[1m---- Epoch 39/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.32972, d2box_loss 1.02802, d2cls_loss 0.32490, 90.25 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22096, chestimgbbiou 0.77500, chestimgbbmae 9.26968, 59.05 secs\n",
      "\u001b[1m---- Epoch 40/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.26720, d2box_loss 0.95354, d2cls_loss 0.29649, 89.78 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22451, chestimgbbiou 0.77703, chestimgbbmae 9.10088, 58.64 secs\n",
      "\u001b[1m---- Epoch 41/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.29220, d2box_loss 0.93845, d2cls_loss 0.31214, 89.90 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22671, chestimgbbiou 0.78486, chestimgbbmae 8.67080, 58.57 secs\n",
      "\u001b[1m---- Epoch 42/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.40223, d2box_loss 0.99522, d2cls_loss 0.31913, 89.92 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18672, chestimgbbiou 0.76094, chestimgbbmae 10.50989, 58.98 secs\n",
      "\u001b[1m---- Epoch 43/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.28147, d2box_loss 1.09346, d2cls_loss 0.32850, 89.99 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21431, chestimgbbiou 0.78953, chestimgbbmae 8.49690, 59.64 secs\n",
      "\u001b[1m---- Epoch 44/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.28249, d2box_loss 0.99772, d2cls_loss 0.31724, 90.03 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22159, chestimgbbiou 0.78063, chestimgbbmae 9.00676, 59.14 secs\n",
      "\u001b[1m---- Epoch 45/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.31801, d2box_loss 1.00176, d2cls_loss 0.31425, 90.28 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23261, chestimgbbiou 0.79044, chestimgbbmae 8.40036, 59.63 secs\n",
      "\u001b[1m---- Epoch 46/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.22168, d2box_loss 0.93860, d2cls_loss 0.30938, 90.24 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23144, chestimgbbiou 0.77804, chestimgbbmae 9.09067, 60.16 secs\n",
      "\u001b[1m---- Epoch 47/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.22721, d2box_loss 1.04748, d2cls_loss 0.33301, 90.56 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23504, chestimgbbiou 0.79224, chestimgbbmae 8.31435, 59.36 secs\n",
      "\u001b[1m---- Epoch 48/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.83313, d2box_loss 1.03131, d2cls_loss 0.32282, 90.49 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23437, chestimgbbiou 0.78722, chestimgbbmae 8.54718, 58.79 secs\n",
      "\u001b[1m---- Epoch 49/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.40301, d2box_loss 1.10958, d2cls_loss 0.34370, 90.75 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.19336, chestimgbbiou 0.73056, chestimgbbmae 12.71209, 60.90 secs\n",
      "\u001b[1m---- Epoch 50/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.25583, d2box_loss 1.15074, d2cls_loss 0.33247, 90.22 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.20940, chestimgbbiou 0.76455, chestimgbbmae 9.90759, 59.71 secs\n",
      "\u001b[1m---- Epoch 51/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.34019, d2box_loss 1.02779, d2cls_loss 0.32269, 89.77 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23608, chestimgbbiou 0.80759, chestimgbbmae 7.78505, 57.77 secs\n",
      "\u001b[1m---- Epoch 52/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 6.09091, d2box_loss 1.02932, d2cls_loss 0.33528, 90.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23025, chestimgbbiou 0.78246, chestimgbbmae 8.83693, 59.24 secs\n",
      "\u001b[1m---- Epoch 53/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.25849, d2box_loss 1.01077, d2cls_loss 0.30864, 90.05 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23910, chestimgbbiou 0.79535, chestimgbbmae 8.15654, 58.40 secs\n",
      "\u001b[1m---- Epoch 54/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.39206, d2box_loss 0.97322, d2cls_loss 0.31917, 89.70 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23297, chestimgbbiou 0.77677, chestimgbbmae 9.14182, 58.96 secs\n",
      "\u001b[1m---- Epoch 55/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 3.65386, d2box_loss 0.94694, d2cls_loss 0.31604, 90.04 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23720, chestimgbbiou 0.78695, chestimgbbmae 8.55111, 58.75 secs\n",
      "\u001b[1m---- Epoch 56/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000030) ...\n",
      "loss 0.33935, d2box_loss 1.11681, d2cls_loss 0.32500, 90.67 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.21384, chestimgbbiou 0.78469, chestimgbbmae 8.78813, 70.07 secs\n",
      "\u001b[1m---- Epoch 57/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000017) ...\n",
      "loss 0.33400, d2box_loss 1.06930, d2cls_loss 0.33093, 92.09 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.18890, chestimgbbiou 0.71027, chestimgbbmae 13.93263, 63.63 secs\n",
      "\u001b[1m---- Epoch 58/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000010) ...\n",
      "loss 0.25518, d2box_loss 0.86771, d2cls_loss 0.29268, 90.82 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.22611, chestimgbbiou 0.77992, chestimgbbmae 8.98361, 59.82 secs\n",
      "\u001b[1m---- Epoch 59/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000005) ...\n",
      "loss 0.40892, d2box_loss 0.86778, d2cls_loss 0.29201, 90.36 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23903, chestimgbbiou 0.78849, chestimgbbmae 8.43217, 60.19 secs\n",
      "\u001b[1m---- Epoch 60/60\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.42302, d2box_loss 0.89796, d2cls_loss 0.30480, 90.10 secs\n",
      "(2) Validation stage ...\n",
      "chestimgbbmf1 0.23968, chestimgbbiou 0.78948, chestimgbbmae 8.42171, 59.04 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_visual_module.py \\\n",
    "    --pretrained-checkpoint-folder-path \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/visual_module/20230316_122709_mim_D2-CocoDet-retinanet-R-50-FPN-1x\" \\\n",
    "    --epochs 60 \\\n",
    "    --batches-per-epoch 200 \\\n",
    "    --batch-size 25 \\\n",
    "    --num-workers 3 \\\n",
    "    --iters-to-accumulate 4 \\\n",
    "    --optimizer-name \"adamw\" \\\n",
    "    --scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "    --lr 1e-6 \\\n",
    "    --warmup-decay-and-cyclic-decay-args \"1e-6,5,8e-5,7,1e-6,3e-5,7,1e-6\" \\\n",
    "    --use-mimiccxr \\\n",
    "    --mimiccxr-weight 1.0 \\\n",
    "    --mimiccxr-view-mode \"chest_imagenome\" \\\n",
    "    --predict-bboxes-chest-imagenome \\\n",
    "    --clamp-bboxes-chest-imagenome \\\n",
    "    --use-chest-imagenome-decent-images-only \\\n",
    "    --raw-image-encoding \"detectron2\" \\\n",
    "    --detectron2-model-yaml \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\" \\\n",
    "    --image-size 512 512 \\\n",
    "    --use-amp \\\n",
    "    --save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
