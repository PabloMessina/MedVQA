{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccb3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 1500\n",
      "   max_images_per_batch: 4\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 4.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino-maira-2\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 0.8\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 0.2\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR classification labels ...\u001b[0m\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "phrase_embeddings.dtype = float32\n",
      "len(phrases) = 28\n",
      "Compute phrase grounding masks and labels\n",
      "vinbig_bbox_names = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Abnormal finding']\n",
      "vinbig_labels = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'Abnormal finding']\n",
      "num_bbox_classes = 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.phrase_grounding_masks.shape = (18000, 23, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 23)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 5\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(sorted_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\taortic enlargement seen (Aortic enlargement)\n",
      "\tatelectasis seen (Atelectasis)\n",
      "\tcalcification seen (Calcification)\n",
      "\tcardiomegaly seen (Cardiomegaly)\n",
      "\tclavicle fracture seen (Clavicle fracture)\n",
      "\tconsolidation seen (Consolidation)\n",
      "\tedema seen (Edema)\n",
      "\temphysema seen (Emphysema)\n",
      "\tenlarged pulmonary artery seen (Enlarged PA)\n",
      "\tinterstitial lung disease seen (ILD)\n",
      "\tinfiltration seen (Infiltration)\n",
      "\tlung opacity seen (Lung Opacity)\n",
      "\tlung cavity seen (Lung cavity)\n",
      "\tlung cyst seen (Lung cyst)\n",
      "\tmediastinal shift seen (Mediastinal shift)\n",
      "\tnodule/mass seen (Nodule/Mass)\n",
      "\tother lesion seen (Other lesion)\n",
      "\tpleural effusion seen (Pleural effusion)\n",
      "\tpleural thickening seen (Pleural thickening)\n",
      "\tpneumothorax seen (Pneumothorax)\n",
      "\tpulmonary fibrosis seen (Pulmonary fibrosis)\n",
      "\trib fracture seen (Rib fracture)\n",
      "\tabnormal findings seen (Abnormal finding)\n",
      "\tcopd seen (COPD)\n",
      "\tlung tumor seen (Lung tumor)\n",
      "\tpneumonia seen (Pneumonia)\n",
      "\ttuberculosis seen (Tuberculosis)\n",
      "\tother disease seen (Other disease)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 36\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 919\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Lung Opacity: 2709\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4377\n",
      "Abnormal finding: 4522\n",
      "No labels: 10478\n",
      "Group sizes: [10478, 794, 341, 312, 286, 278, 258, 243, 241, 218, 215, 198, 159, 156, 122, 119, 114, 102, 91, 83, 79, 63, 50]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 794, weight = 893.8899020987899\n",
      "  len(indices) = 341, weight = 595.5934427021492\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 198, weight = 444.08258972130596\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 91, weight = 275.6141558688678\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 63, weight = 213.55551164361594\n",
      "  len(indices) = 50, weight = 179.7743872238934\n",
      "batch_size = 4\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 16\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    returning transform (not for vinbig)\n",
      "get_train_transform(): Using normal transforms\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (403416, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 133558.23it/s]\n",
      "Total number of images: 368960\n",
      "len(train_indices) = 368960\n",
      "avg_facts_per_image = 508.52087218126627\n",
      "train_num_facts_per_image = 30\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 4\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 92240\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 92240\n",
      "len(vinbig_trainer.train_dataloader) = 250000000000000000\n",
      "len(vinbig_trainer.val_dataloader) = 188\n",
      "len(_train_dataloaders) = 2\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [0.8, 0.2]\n",
      "merged_dataset_name = mim-facts+vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 2.43798, mimfg_phrcls_loss 2.01508, mimfg_prc_auc 0.07918, vbg_vgbbox_loss 1.26462, vbg_att_sup_loss 1.35940, vbg_phrcls_loss 1.50555, vbg_prc_auc 0.18751, 325.90 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.03483, vbg_prc_auc 0.09143, 114.06 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.3317, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.0792, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_vgbbox_loss: 0.4416, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_att_sup_loss: 0.4238, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.1875, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 3.1514, den = 14.0000, score = 0.2251\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mvbg_bbox_iou: 0.0348, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.0914, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 0.9492, den = 11.0000, score = 0.0863\u001b[0m\n",
      "\u001b[93mTrain score = 0.2251, Val score = 0.0863, Final score = 0.0932\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_miss+miuc+vbss+vbou+vbuc+vbss=0.0932.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 2.14353, mimfg_phrcls_loss 1.87985, mimfg_prc_auc 0.09708, vbg_vgbbox_loss 0.61039, vbg_att_sup_loss 1.36795, vbg_phrcls_loss 1.21992, vbg_prc_auc 0.19542, 339.48 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.06289, vbg_prc_auc 0.09140, 116.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_miss+miuc+vbss+vbou+vbuc+vbss=0.0967.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.89783, mimfg_phrcls_loss 1.65950, mimfg_prc_auc 0.45089, vbg_vgbbox_loss 0.44357, vbg_att_sup_loss 1.25185, vbg_phrcls_loss 1.15572, vbg_prc_auc 0.20853, 349.89 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.08141, vbg_prc_auc 0.11712, 118.42 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_3_miss+miuc+vbss+vbou+vbuc+vbss=0.1226.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.65627, mimfg_phrcls_loss 1.42730, mimfg_prc_auc 0.55496, vbg_vgbbox_loss 0.42151, vbg_att_sup_loss 1.07420, vbg_phrcls_loss 1.07641, vbg_prc_auc 0.20405, 356.01 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.09903, vbg_prc_auc 0.14977, 117.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_miss+miuc+vbss+vbou+vbuc+vbss=0.1529.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.46903, mimfg_phrcls_loss 1.31760, mimfg_prc_auc 0.62107, vbg_vgbbox_loss 0.31731, vbg_att_sup_loss 0.80708, vbg_phrcls_loss 0.95036, vbg_prc_auc 0.25649, 352.35 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.13557, vbg_prc_auc 0.20196, 117.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_miss+miuc+vbss+vbou+vbuc+vbss=0.2037.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.36910, mimfg_phrcls_loss 1.24288, mimfg_prc_auc 0.65985, vbg_vgbbox_loss 0.28251, vbg_att_sup_loss 0.71539, vbg_phrcls_loss 0.87609, vbg_prc_auc 0.30518, 355.60 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.14298, vbg_prc_auc 0.24562, 117.61 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_miss+miuc+vbss+vbou+vbuc+vbss=0.2442.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.32966, mimfg_phrcls_loss 1.21464, mimfg_prc_auc 0.68244, vbg_vgbbox_loss 0.26753, vbg_att_sup_loss 0.67494, vbg_phrcls_loss 0.84723, vbg_prc_auc 0.33532, 353.69 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15044, vbg_prc_auc 0.25731, 118.13 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_miss+miuc+vbss+vbou+vbuc+vbss=0.2562.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.30028, mimfg_phrcls_loss 1.18459, mimfg_prc_auc 0.69654, vbg_vgbbox_loss 0.26842, vbg_att_sup_loss 0.67031, vbg_phrcls_loss 0.82431, vbg_prc_auc 0.35478, 353.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.14755, vbg_prc_auc 0.26674, 118.33 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_miss+miuc+vbss+vbou+vbuc+vbss=0.2649.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.28764, mimfg_phrcls_loss 1.18007, mimfg_prc_auc 0.70293, vbg_vgbbox_loss 0.25890, vbg_att_sup_loss 0.64707, vbg_phrcls_loss 0.81192, vbg_prc_auc 0.35954, 354.11 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.15030, vbg_prc_auc 0.27221, 117.90 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_miss+miuc+vbss+vbou+vbuc+vbss=0.2701.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "   iteration 14775\r"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 1500 \\\n",
    "--max_images_per_batch 4 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 4 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino-maira-2\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\" \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\" \\\n",
    "--use_vinbig_with_modified_labels \\\n",
    "--vinbig_weight 0.2 \\\n",
    "--mimiccxr_facts_weight 0.8 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a094be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 200\n",
      "   batches_per_epoch: 600\n",
      "   max_images_per_batch: 4\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 4.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino-maira-2\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: None\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: False\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR classification labels ...\u001b[0m\n",
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "phrase_embeddings.dtype = float32\n",
      "len(phrases) = 28\n",
      "Compute phrase grounding masks and labels\n",
      "vinbig_bbox_names = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Abnormal finding']\n",
      "vinbig_labels = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'Abnormal finding']\n",
      "num_bbox_classes = 23\n",
      "self.phrase_grounding_masks.shape = (18000, 23, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 23)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 5\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(sorted_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\taortic enlargement seen (Aortic enlargement)\n",
      "\tatelectasis seen (Atelectasis)\n",
      "\tcalcification seen (Calcification)\n",
      "\tcardiomegaly seen (Cardiomegaly)\n",
      "\tclavicle fracture seen (Clavicle fracture)\n",
      "\tconsolidation seen (Consolidation)\n",
      "\tedema seen (Edema)\n",
      "\temphysema seen (Emphysema)\n",
      "\tenlarged pulmonary artery seen (Enlarged PA)\n",
      "\tinterstitial lung disease seen (ILD)\n",
      "\tinfiltration seen (Infiltration)\n",
      "\tlung opacity seen (Lung Opacity)\n",
      "\tlung cavity seen (Lung cavity)\n",
      "\tlung cyst seen (Lung cyst)\n",
      "\tmediastinal shift seen (Mediastinal shift)\n",
      "\tnodule/mass seen (Nodule/Mass)\n",
      "\tother lesion seen (Other lesion)\n",
      "\tpleural effusion seen (Pleural effusion)\n",
      "\tpleural thickening seen (Pleural thickening)\n",
      "\tpneumothorax seen (Pneumothorax)\n",
      "\tpulmonary fibrosis seen (Pulmonary fibrosis)\n",
      "\trib fracture seen (Rib fracture)\n",
      "\tabnormal findings seen (Abnormal finding)\n",
      "\tcopd seen (COPD)\n",
      "\tlung tumor seen (Lung tumor)\n",
      "\tpneumonia seen (Pneumonia)\n",
      "\ttuberculosis seen (Tuberculosis)\n",
      "\tother disease seen (Other disease)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 36\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 919\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Lung Opacity: 2709\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4377\n",
      "Abnormal finding: 4522\n",
      "No labels: 10478\n",
      "Group sizes: [10478, 794, 341, 312, 286, 278, 258, 243, 241, 218, 215, 198, 159, 156, 122, 119, 114, 102, 91, 83, 79, 63, 50]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 794, weight = 893.8899020987899\n",
      "  len(indices) = 341, weight = 595.5934427021492\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 198, weight = 444.08258972130596\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 91, weight = 275.6141558688678\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 63, weight = 213.55551164361594\n",
      "  len(indices) = 50, weight = 179.7743872238934\n",
      "batch_size = 4\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 16\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(vinbig_trainer.train_dataloader) = 250000000000000000\n",
      "len(vinbig_trainer.val_dataloader) = 188\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250211_211631_vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250211_211631_vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_139_miss+miuc+vbss+vbou+vbuc+vbss=0.4072.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/checkpoint_139_miss+miuc+vbss+vbou+vbuc+vbss=0.4072.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250211_211631_vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.91861, vbg_vgbbox_loss 0.16980, vbg_att_sup_loss 0.27123, vbg_phrcls_loss 0.47758, vbg_prc_auc 0.65546, 123.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22167, vbg_prc_auc 0.41296, 116.22 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mvbg_vgbbox_loss: 0.8549, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_att_sup_loss: 0.7866, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.6555, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 8.1961, den = 12.0000, score = 0.6830\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mvbg_bbox_iou: 0.2217, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.4130, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 4.3513, den = 11.0000, score = 0.3956\u001b[0m\n",
      "\u001b[93mTrain score = 0.6830, Val score = 0.3956, Final score = 0.4099\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_vbss+vbou+vbuc+vbss=0.4099.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.92053, vbg_vgbbox_loss 0.17197, vbg_att_sup_loss 0.27597, vbg_phrcls_loss 0.47259, vbg_prc_auc 0.66001, 121.57 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22015, vbg_prc_auc 0.40423, 116.92 secs\n",
      "\u001b[1m---- Epoch 3/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.91876, vbg_vgbbox_loss 0.16842, vbg_att_sup_loss 0.27504, vbg_phrcls_loss 0.47531, vbg_prc_auc 0.66021, 132.52 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22585, vbg_prc_auc 0.41204, 117.50 secs\n",
      "\u001b[1m---- Epoch 4/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.03687, vbg_vgbbox_loss 0.19088, vbg_att_sup_loss 0.31132, vbg_phrcls_loss 0.53468, vbg_prc_auc 0.58300, 140.10 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19052, vbg_prc_auc 0.36315, 116.63 secs\n",
      "\u001b[1m---- Epoch 5/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.94874, vbg_vgbbox_loss 0.17553, vbg_att_sup_loss 0.28045, vbg_phrcls_loss 0.49276, vbg_prc_auc 0.64041, 135.99 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21507, vbg_prc_auc 0.41478, 117.28 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_vbss+vbou+vbuc+vbss=0.4103.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.88505, vbg_vgbbox_loss 0.16644, vbg_att_sup_loss 0.26177, vbg_phrcls_loss 0.45684, vbg_prc_auc 0.68989, 133.68 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22447, vbg_prc_auc 0.41963, 116.36 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_vbss+vbou+vbuc+vbss=0.4174.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.85896, vbg_vgbbox_loss 0.16285, vbg_att_sup_loss 0.25584, vbg_phrcls_loss 0.44027, vbg_prc_auc 0.69683, 137.18 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22708, vbg_prc_auc 0.42143, 116.29 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_vbss+vbou+vbuc+vbss=0.4195.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.84195, vbg_vgbbox_loss 0.16060, vbg_att_sup_loss 0.24795, vbg_phrcls_loss 0.43340, vbg_prc_auc 0.71200, 138.56 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22506, vbg_prc_auc 0.42321, 116.35 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_vbss+vbou+vbuc+vbss=0.4215.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.84423, vbg_vgbbox_loss 0.16186, vbg_att_sup_loss 0.25094, vbg_phrcls_loss 0.43143, vbg_prc_auc 0.72390, 137.20 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22479, vbg_prc_auc 0.42291, 115.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_vbss+vbou+vbuc+vbss=0.4217.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.98503, vbg_vgbbox_loss 0.18235, vbg_att_sup_loss 0.28956, vbg_phrcls_loss 0.51311, vbg_prc_auc 0.62567, 134.18 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21424, vbg_prc_auc 0.41032, 113.37 secs\n",
      "\u001b[1m---- Epoch 11/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.91069, vbg_vgbbox_loss 0.17018, vbg_att_sup_loss 0.26934, vbg_phrcls_loss 0.47117, vbg_prc_auc 0.67263, 134.00 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22016, vbg_prc_auc 0.38309, 116.46 secs\n",
      "\u001b[1m---- Epoch 12/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.84092, vbg_vgbbox_loss 0.16074, vbg_att_sup_loss 0.24779, vbg_phrcls_loss 0.43239, vbg_prc_auc 0.71971, 135.35 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22436, vbg_prc_auc 0.42105, 114.25 secs\n",
      "\u001b[1m---- Epoch 13/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.81088, vbg_vgbbox_loss 0.15883, vbg_att_sup_loss 0.23507, vbg_phrcls_loss 0.41698, vbg_prc_auc 0.73458, 131.56 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23045, vbg_prc_auc 0.42235, 116.47 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_vbss+vbou+vbuc+vbss=0.4222.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.81467, vbg_vgbbox_loss 0.15952, vbg_att_sup_loss 0.23825, vbg_phrcls_loss 0.41690, vbg_prc_auc 0.73858, 135.47 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23031, vbg_prc_auc 0.42221, 113.95 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_vbss+vbou+vbuc+vbss=0.4223.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.94612, vbg_vgbbox_loss 0.18002, vbg_att_sup_loss 0.28142, vbg_phrcls_loss 0.48468, vbg_prc_auc 0.63777, 135.75 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21020, vbg_prc_auc 0.37941, 114.52 secs\n",
      "\u001b[1m---- Epoch 16/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.90329, vbg_vgbbox_loss 0.17159, vbg_att_sup_loss 0.26439, vbg_phrcls_loss 0.46731, vbg_prc_auc 0.69036, 135.74 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22341, vbg_prc_auc 0.38172, 115.68 secs\n",
      "\u001b[1m---- Epoch 17/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.81272, vbg_vgbbox_loss 0.15841, vbg_att_sup_loss 0.23779, vbg_phrcls_loss 0.41652, vbg_prc_auc 0.72044, 135.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21716, vbg_prc_auc 0.40923, 115.66 secs\n",
      "\u001b[1m---- Epoch 18/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.79636, vbg_vgbbox_loss 0.15992, vbg_att_sup_loss 0.23456, vbg_phrcls_loss 0.40187, vbg_prc_auc 0.75672, 135.33 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21705, vbg_prc_auc 0.41689, 114.34 secs\n",
      "\u001b[1m---- Epoch 19/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.77936, vbg_vgbbox_loss 0.15485, vbg_att_sup_loss 0.23076, vbg_phrcls_loss 0.39375, vbg_prc_auc 0.75579, 133.62 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21998, vbg_prc_auc 0.41976, 114.45 secs\n",
      "\u001b[1m---- Epoch 20/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.92806, vbg_vgbbox_loss 0.17910, vbg_att_sup_loss 0.26853, vbg_phrcls_loss 0.48043, vbg_prc_auc 0.65488, 135.80 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21738, vbg_prc_auc 0.40527, 114.52 secs\n",
      "\u001b[1m---- Epoch 21/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.85329, vbg_vgbbox_loss 0.16977, vbg_att_sup_loss 0.24636, vbg_phrcls_loss 0.43716, vbg_prc_auc 0.70743, 134.94 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21922, vbg_prc_auc 0.41365, 114.61 secs\n",
      "\u001b[1m---- Epoch 22/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.78268, vbg_vgbbox_loss 0.15660, vbg_att_sup_loss 0.22640, vbg_phrcls_loss 0.39967, vbg_prc_auc 0.75430, 132.23 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22296, vbg_prc_auc 0.41789, 113.94 secs\n",
      "\u001b[1m---- Epoch 23/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.76870, vbg_vgbbox_loss 0.15413, vbg_att_sup_loss 0.22658, vbg_phrcls_loss 0.38799, vbg_prc_auc 0.76783, 134.14 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22363, vbg_prc_auc 0.41743, 114.42 secs\n",
      "\u001b[1m---- Epoch 24/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.76613, vbg_vgbbox_loss 0.15564, vbg_att_sup_loss 0.22378, vbg_phrcls_loss 0.38671, vbg_prc_auc 0.77633, 137.29 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22712, vbg_prc_auc 0.41636, 113.77 secs\n",
      "\u001b[1m---- Epoch 25/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.90118, vbg_vgbbox_loss 0.17957, vbg_att_sup_loss 0.26257, vbg_phrcls_loss 0.45904, vbg_prc_auc 0.66672, 133.63 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22236, vbg_prc_auc 0.37444, 114.38 secs\n",
      "\u001b[1m---- Epoch 26/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.84323, vbg_vgbbox_loss 0.16358, vbg_att_sup_loss 0.24745, vbg_phrcls_loss 0.43220, vbg_prc_auc 0.72621, 133.02 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22651, vbg_prc_auc 0.39912, 113.60 secs\n",
      "\u001b[1m---- Epoch 27/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.76959, vbg_vgbbox_loss 0.15715, vbg_att_sup_loss 0.22835, vbg_phrcls_loss 0.38409, vbg_prc_auc 0.77749, 135.26 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22585, vbg_prc_auc 0.41783, 114.01 secs\n",
      "\u001b[1m---- Epoch 28/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.74422, vbg_vgbbox_loss 0.15274, vbg_att_sup_loss 0.21485, vbg_phrcls_loss 0.37663, vbg_prc_auc 0.79115, 135.94 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22958, vbg_prc_auc 0.42165, 113.30 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_vbss+vbou+vbuc+vbss=0.4240.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.73160, vbg_vgbbox_loss 0.15055, vbg_att_sup_loss 0.21577, vbg_phrcls_loss 0.36528, vbg_prc_auc 0.79928, 134.63 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22528, vbg_prc_auc 0.41481, 112.53 secs\n",
      "\u001b[1m---- Epoch 30/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.88890, vbg_vgbbox_loss 0.17594, vbg_att_sup_loss 0.25797, vbg_phrcls_loss 0.45500, vbg_prc_auc 0.68316, 132.13 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21269, vbg_prc_auc 0.40381, 113.09 secs\n",
      "\u001b[1m---- Epoch 31/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.82366, vbg_vgbbox_loss 0.16395, vbg_att_sup_loss 0.24013, vbg_phrcls_loss 0.41958, vbg_prc_auc 0.75099, 129.52 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21968, vbg_prc_auc 0.41533, 113.88 secs\n",
      "\u001b[1m---- Epoch 32/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.73782, vbg_vgbbox_loss 0.15471, vbg_att_sup_loss 0.21566, vbg_phrcls_loss 0.36744, vbg_prc_auc 0.79852, 133.22 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.22407, vbg_prc_auc 0.40326, 113.61 secs\n",
      "\u001b[1m---- Epoch 33/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.72923, vbg_vgbbox_loss 0.15240, vbg_att_sup_loss 0.21066, vbg_phrcls_loss 0.36618, vbg_prc_auc 0.79932, 133.32 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22396, vbg_prc_auc 0.40644, 112.55 secs\n",
      "\u001b[1m---- Epoch 34/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70943, vbg_vgbbox_loss 0.15312, vbg_att_sup_loss 0.20814, vbg_phrcls_loss 0.34817, vbg_prc_auc 0.82719, 133.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22440, vbg_prc_auc 0.41754, 112.51 secs\n",
      "\u001b[1m---- Epoch 35/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.84195, vbg_vgbbox_loss 0.16991, vbg_att_sup_loss 0.24131, vbg_phrcls_loss 0.43072, vbg_prc_auc 0.70901, 132.68 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.19348, vbg_prc_auc 0.34594, 113.79 secs\n",
      "\u001b[1m---- Epoch 36/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.78529, vbg_vgbbox_loss 0.16124, vbg_att_sup_loss 0.22953, vbg_phrcls_loss 0.39452, vbg_prc_auc 0.77434, 132.76 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21460, vbg_prc_auc 0.41132, 113.34 secs\n",
      "\u001b[1m---- Epoch 37/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.71509, vbg_vgbbox_loss 0.15284, vbg_att_sup_loss 0.20767, vbg_phrcls_loss 0.35457, vbg_prc_auc 0.80639, 130.76 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21902, vbg_prc_auc 0.38685, 111.59 secs\n",
      "\u001b[1m---- Epoch 38/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68594, vbg_vgbbox_loss 0.14876, vbg_att_sup_loss 0.20075, vbg_phrcls_loss 0.33643, vbg_prc_auc 0.83808, 131.52 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22047, vbg_prc_auc 0.39163, 111.31 secs\n",
      "\u001b[1m---- Epoch 39/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68679, vbg_vgbbox_loss 0.15024, vbg_att_sup_loss 0.20007, vbg_phrcls_loss 0.33648, vbg_prc_auc 0.84178, 132.34 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22015, vbg_prc_auc 0.40556, 111.68 secs\n",
      "\u001b[1m---- Epoch 40/200\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "^C iteration 23750\n",
      "Engine run is terminating due to exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1552, in <module>\n",
      "    train_from_scratch(**args)\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 1418, in train_from_scratch\n",
      "    return train_model(\n",
      "  File \"/home/pamessina/medvqa/medvqa/notebooks/../train_phrase_grounding.py\", line 926, in train_model\n",
      "    run_common_boilerplate_code_and_start_training(\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/utils.py\", line 137, in run_common_boilerplate_code_and_start_training\n",
      "    trainer_engine.run(train_dataloader, max_epochs=epochs, epoch_length=batches_per_epoch)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 892, in run\n",
      "    return self._internal_run()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 935, in _internal_run\n",
      "    return next(self._internal_run_generator)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 993, in _internal_run_as_gen\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 638, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 959, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/ignite/engine/engine.py\", line 1068, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 991, in step_fn\n",
      "    output = flag_to_step_fn[flag](batch)\n",
      "  File \"/home/pamessina/medvqa/medvqa/training/phrase_grounding.py\", line 516, in step_fn__vinbig_bbox_grounding\n",
      "    model_output = model(**model_kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/phrase_grounding/phrase_grounder.py\", line 371, in forward\n",
      "    output = super().forward(\n",
      "  File \"/home/pamessina/medvqa/medvqa/models/vision/visual_modules.py\", line 1001, in forward\n",
      "    tmp = self.raw_image_encoder(raw_images)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 633, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 452, in forward\n",
      "    layer_outputs = layer_module(hidden_states, layer_head_mask, output_attentions)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 408, in forward\n",
      "    layer_output = self.mlp(layer_output)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/transformers/models/dinov2/modeling_dinov2.py\", line 347, in forward\n",
      "    hidden_state = self.fc2(hidden_state)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/pamessina/venv2/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\" \\\n",
    "--epochs 200 \\\n",
    "--batches_per_epoch 600 \\\n",
    "--max_images_per_batch 4 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 4 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino-maira-2\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\" \\\n",
    "--use_vinbig_with_modified_labels \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85e57d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 30\n",
      "   batches_per_epoch: 1500\n",
      "   max_images_per_batch: 4\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 4.0\n",
      "   checkpoint_folder: models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_path: None\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino-maira-2\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp_with_bbox_regression\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 0.8\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 0.2\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: False\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: True\n",
      "   use_vinbig_for_test: True\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: True\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: True\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Resuming training ------\u001b[0m\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': None, 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "BoundingBoxRegressorSingleClass\n",
      "  local_feat_dim: 256\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating VinBig Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    for_vinbig: returning vinbig transform\n",
      "get_train_transform(): Using bbox-aware transforms for VinBigData\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR classification labels ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bounding boxes\n",
      "Anomalous bboxes found: 29 of 37367\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "Anomalous bboxes found: 0 of 2697\n",
      "\u001b[93m\u001b[1mNOTE: Improving VinDr-CXR bbox labels ...\u001b[0m\n",
      "class_id_offset: 0\n",
      "  Loaded 18000 bounding boxes\n",
      "Loding phrase_embeddings and phrases from /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl...\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "phrase_embeddings.dtype = float32\n",
      "len(phrases) = 28\n",
      "Compute phrase grounding masks and labels\n",
      "vinbig_bbox_names = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Abnormal finding']\n",
      "vinbig_labels = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease', 'Abnormal finding']\n",
      "num_bbox_classes = 23\n",
      "self.phrase_grounding_masks.shape = (18000, 23, 841)\n",
      "self.phrase_classification_labels.shape = (18000, 23)\n",
      "Append additional labels to phrase_classification_labels\n",
      "len(non_bbox_labels) = 5\n",
      "non_bbox_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other disease']\n",
      "self.phrase_classification_labels.shape = (18000, 28)\n",
      "Reorder phrases and phrase_embeddings\n",
      "len(phrases) = 28\n",
      "len(sorted_phrases) = 28\n",
      "phrase_embeddings.shape = (28, 128)\n",
      "\taortic enlargement seen (Aortic enlargement)\n",
      "\tatelectasis seen (Atelectasis)\n",
      "\tcalcification seen (Calcification)\n",
      "\tcardiomegaly seen (Cardiomegaly)\n",
      "\tclavicle fracture seen (Clavicle fracture)\n",
      "\tconsolidation seen (Consolidation)\n",
      "\tedema seen (Edema)\n",
      "\temphysema seen (Emphysema)\n",
      "\tenlarged pulmonary artery seen (Enlarged PA)\n",
      "\tinterstitial lung disease seen (ILD)\n",
      "\tinfiltration seen (Infiltration)\n",
      "\tlung opacity seen (Lung Opacity)\n",
      "\tlung cavity seen (Lung cavity)\n",
      "\tlung cyst seen (Lung cyst)\n",
      "\tmediastinal shift seen (Mediastinal shift)\n",
      "\tnodule/mass seen (Nodule/Mass)\n",
      "\tother lesion seen (Other lesion)\n",
      "\tpleural effusion seen (Pleural effusion)\n",
      "\tpleural thickening seen (Pleural thickening)\n",
      "\tpneumothorax seen (Pneumothorax)\n",
      "\tpulmonary fibrosis seen (Pulmonary fibrosis)\n",
      "\trib fracture seen (Rib fracture)\n",
      "\tabnormal findings seen (Abnormal finding)\n",
      "\tcopd seen (COPD)\n",
      "\tlung tumor seen (Lung tumor)\n",
      "\tpneumonia seen (Pneumonia)\n",
      "\ttuberculosis seen (Tuberculosis)\n",
      "\tother disease seen (Other disease)\n",
      "\u001b[1mGenerating train dataset and dataloader\u001b[0m\n",
      "len(train_indices) = 15000\n",
      "Edema: 13\n",
      "Clavicle fracture: 27\n",
      "Lung cyst: 33\n",
      "COPD: 36\n",
      "Lung cavity: 51\n",
      "Emphysema: 81\n",
      "Rib fracture: 90\n",
      "Pneumothorax: 96\n",
      "Enlarged PA: 131\n",
      "Mediastinal shift: 150\n",
      "Atelectasis: 187\n",
      "Lung tumor: 291\n",
      "Consolidation: 353\n",
      "ILD: 397\n",
      "Calcification: 458\n",
      "Infiltration: 613\n",
      "Tuberculosis: 750\n",
      "Nodule/Mass: 841\n",
      "Pneumonia: 919\n",
      "Pleural effusion: 1038\n",
      "Other lesion: 1154\n",
      "Pulmonary fibrosis: 1621\n",
      "Pleural thickening: 2010\n",
      "Cardiomegaly: 2316\n",
      "Lung Opacity: 2709\n",
      "Aortic enlargement: 3098\n",
      "Other disease: 4377\n",
      "Abnormal finding: 4522\n",
      "No labels: 10478\n",
      "Group sizes: [10478, 794, 341, 312, 286, 278, 258, 243, 241, 218, 215, 198, 159, 156, 122, 119, 114, 102, 91, 83, 79, 63, 50]\n",
      "  len(indices) = 10478, weight = 2381.9852437292775\n",
      "  len(indices) = 794, weight = 893.8899020987899\n",
      "  len(indices) = 341, weight = 595.5934427021492\n",
      "  len(indices) = 312, weight = 568.7753795323758\n",
      "  len(indices) = 286, weight = 543.3127950518186\n",
      "  len(indices) = 278, weight = 535.1778961104801\n",
      "  len(indices) = 258, weight = 514.1586596868186\n",
      "  len(indices) = 243, weight = 497.69925147612867\n",
      "  len(indices) = 241, weight = 495.4562099629317\n",
      "  len(indices) = 218, weight = 468.76865710351854\n",
      "  len(indices) = 215, weight = 465.15882500917724\n",
      "  len(indices) = 198, weight = 444.08258972130596\n",
      "  len(indices) = 159, weight = 391.0802349542582\n",
      "  len(indices) = 156, weight = 386.6879164039802\n",
      "  len(indices) = 122, weight = 332.9187999914028\n",
      "  len(indices) = 119, weight = 327.76937690454827\n",
      "  len(indices) = 114, weight = 319.0166061056533\n",
      "  len(indices) = 102, weight = 297.0647831080699\n",
      "  len(indices) = 91, weight = 275.6141558688678\n",
      "  len(indices) = 83, weight = 259.088791948487\n",
      "  len(indices) = 79, weight = 250.497443897163\n",
      "  len(indices) = 63, weight = 213.55551164361594\n",
      "  len(indices) = 50, weight = 179.7743872238934\n",
      "batch_size = 4\n",
      "\u001b[1mGenerating val dataset and dataloader\u001b[0m\n",
      "len(test_indices) = 3000\n",
      "batch_size = 16\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    augmentation_mode = random-color-and-spatial\n",
      "    default_prob = 0.35\n",
      "    returning transform (not for vinbig)\n",
      "get_train_transform(): Using normal transforms\n",
      "    Returning augmented transform with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "  Using bounding box aware transforms\n",
      "    Returning default transform (no augmentation)\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n",
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (403416, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 152210.66it/s]\n",
      "Total number of images: 368960\n",
      "len(train_indices) = 368960\n",
      "avg_facts_per_image = 508.52087218126627\n",
      "train_num_facts_per_image = 30\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 4\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 92240\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 92240\n",
      "len(vinbig_trainer.train_dataloader) = 250000000000000000\n",
      "len(vinbig_trainer.val_dataloader) = 188\n",
      "len(_train_dataloaders) = 2\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [0.8, 0.2]\n",
      "merged_dataset_name = mim-facts+vinbig\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_139_miss+miuc+vbss+vbou+vbuc+vbss=0.4072.pt', 'checkpoint_168_miss+miuc+vbss+vbou+vbuc+vbss=0.4491.pt']\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/checkpoint_168_miss+miuc+vbss+vbou+vbuc+vbss=0.4491.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 169/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.72471, mimfg_phrcls_loss 0.68397, mimfg_prc_auc 0.87916, vbg_vgbbox_loss 0.16122, vbg_att_sup_loss 0.25882, vbg_phrcls_loss 0.46765, vbg_prc_auc 0.68447, 298.58 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.23921, vbg_prc_auc 0.43659, 90.89 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.5938, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.8792, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_vgbbox_loss: 0.8612, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_att_sup_loss: 0.7944, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.6845, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 9.9733, den = 14.0000, score = 0.7124\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mvbg_bbox_iou: 0.2392, weight = 1.0\u001b[0m\n",
      "\u001b[93mvbg_prc_auc: 0.4366, weight = 10.0\u001b[0m\n",
      "\u001b[93mnum = 4.6051, den = 11.0000, score = 0.4186\u001b[0m\n",
      "\u001b[93mTrain score = 0.7124, Val score = 0.4186, Final score = 0.4333\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_169_miss+miuc+vbss+vbou+vbuc+vbss=0.4333.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 170/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.82774, mimfg_phrcls_loss 0.75528, mimfg_prc_auc 0.85198, vbg_vgbbox_loss 0.20628, vbg_att_sup_loss 0.33072, vbg_phrcls_loss 0.58057, vbg_prc_auc 0.53358, 307.29 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.18309, vbg_prc_auc 0.38990, 91.18 secs\n",
      "\u001b[1m---- Epoch 171/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.77553, mimfg_phrcls_loss 0.71869, mimfg_prc_auc 0.86810, vbg_vgbbox_loss 0.18931, vbg_att_sup_loss 0.29534, vbg_phrcls_loss 0.51823, vbg_prc_auc 0.64427, 307.65 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22037, vbg_prc_auc 0.40503, 92.50 secs\n",
      "\u001b[1m---- Epoch 172/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.74625, mimfg_phrcls_loss 0.69763, mimfg_prc_auc 0.87356, vbg_vgbbox_loss 0.17004, vbg_att_sup_loss 0.27756, vbg_phrcls_loss 0.49310, vbg_prc_auc 0.63762, 307.93 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22875, vbg_prc_auc 0.42708, 91.69 secs\n",
      "\u001b[1m---- Epoch 173/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.73169, mimfg_phrcls_loss 0.68894, mimfg_prc_auc 0.87318, vbg_vgbbox_loss 0.16506, vbg_att_sup_loss 0.26246, vbg_phrcls_loss 0.47519, vbg_prc_auc 0.67193, 308.53 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22807, vbg_prc_auc 0.43266, 93.50 secs\n",
      "\u001b[1m---- Epoch 174/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.73449, mimfg_phrcls_loss 0.69463, mimfg_prc_auc 0.87400, vbg_vgbbox_loss 0.17038, vbg_att_sup_loss 0.26188, vbg_phrcls_loss 0.46167, vbg_prc_auc 0.69590, 295.67 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22834, vbg_prc_auc 0.41768, 92.51 secs\n",
      "\u001b[1m---- Epoch 175/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.82093, mimfg_phrcls_loss 0.74801, mimfg_prc_auc 0.85593, vbg_vgbbox_loss 0.20723, vbg_att_sup_loss 0.33432, vbg_phrcls_loss 0.57106, vbg_prc_auc 0.56599, 308.96 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20493, vbg_prc_auc 0.38050, 94.88 secs\n",
      "\u001b[1m---- Epoch 176/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.77584, mimfg_phrcls_loss 0.71805, mimfg_prc_auc 0.86679, vbg_vgbbox_loss 0.17981, vbg_att_sup_loss 0.29810, vbg_phrcls_loss 0.52912, vbg_prc_auc 0.61875, 308.17 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21817, vbg_prc_auc 0.41539, 93.15 secs\n",
      "\u001b[1m---- Epoch 177/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.74777, mimfg_phrcls_loss 0.69896, mimfg_prc_auc 0.87591, vbg_vgbbox_loss 0.17118, vbg_att_sup_loss 0.27564, vbg_phrcls_loss 0.49619, vbg_prc_auc 0.66234, 307.29 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23122, vbg_prc_auc 0.42368, 92.07 secs\n",
      "\u001b[1m---- Epoch 178/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.74502, mimfg_phrcls_loss 0.70231, mimfg_prc_auc 0.87454, vbg_vgbbox_loss 0.16596, vbg_att_sup_loss 0.26792, vbg_phrcls_loss 0.48198, vbg_prc_auc 0.68812, 307.58 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23283, vbg_prc_auc 0.42894, 94.23 secs\n",
      "\u001b[1m---- Epoch 179/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.71450, mimfg_phrcls_loss 0.67346, mimfg_prc_auc 0.88382, vbg_vgbbox_loss 0.16378, vbg_att_sup_loss 0.25708, vbg_phrcls_loss 0.45780, vbg_prc_auc 0.71271, 307.76 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23313, vbg_prc_auc 0.43060, 92.65 secs\n",
      "\u001b[1m---- Epoch 180/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.81924, mimfg_phrcls_loss 0.74776, mimfg_prc_auc 0.85729, vbg_vgbbox_loss 0.20126, vbg_att_sup_loss 0.32755, vbg_phrcls_loss 0.57637, vbg_prc_auc 0.56842, 307.68 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20587, vbg_prc_auc 0.39628, 92.91 secs\n",
      "\u001b[1m---- Epoch 181/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.74665, mimfg_phrcls_loss 0.68962, mimfg_prc_auc 0.87290, vbg_vgbbox_loss 0.18023, vbg_att_sup_loss 0.28728, vbg_phrcls_loss 0.50728, vbg_prc_auc 0.63054, 306.73 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23330, vbg_prc_auc 0.41865, 93.13 secs\n",
      "\u001b[1m---- Epoch 182/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.73159, mimfg_phrcls_loss 0.68188, mimfg_prc_auc 0.87827, vbg_vgbbox_loss 0.16733, vbg_att_sup_loss 0.27623, vbg_phrcls_loss 0.48690, vbg_prc_auc 0.64984, 306.72 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21968, vbg_prc_auc 0.41349, 92.72 secs\n",
      "\u001b[1m---- Epoch 183/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.72111, mimfg_phrcls_loss 0.67524, mimfg_prc_auc 0.88122, vbg_vgbbox_loss 0.17093, vbg_att_sup_loss 0.26984, vbg_phrcls_loss 0.46380, vbg_prc_auc 0.69639, 309.67 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23019, vbg_prc_auc 0.44250, 92.86 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_183_miss+miuc+vbss+vbou+vbuc+vbss=0.4380.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 184/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70952, mimfg_phrcls_loss 0.66857, mimfg_prc_auc 0.87688, vbg_vgbbox_loss 0.16425, vbg_att_sup_loss 0.25635, vbg_phrcls_loss 0.45271, vbg_prc_auc 0.71205, 308.05 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22609, vbg_prc_auc 0.44109, 93.07 secs\n",
      "\u001b[1m---- Epoch 185/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.82501, mimfg_phrcls_loss 0.76406, mimfg_prc_auc 0.85381, vbg_vgbbox_loss 0.20195, vbg_att_sup_loss 0.31615, vbg_phrcls_loss 0.55069, vbg_prc_auc 0.58102, 305.80 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21224, vbg_prc_auc 0.40888, 94.19 secs\n",
      "\u001b[1m---- Epoch 186/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.76346, mimfg_phrcls_loss 0.71267, mimfg_prc_auc 0.86934, vbg_vgbbox_loss 0.17695, vbg_att_sup_loss 0.28467, vbg_phrcls_loss 0.50503, vbg_prc_auc 0.62779, 307.92 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23676, vbg_prc_auc 0.42392, 93.03 secs\n",
      "\u001b[1m---- Epoch 187/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.73682, mimfg_phrcls_loss 0.69061, mimfg_prc_auc 0.87510, vbg_vgbbox_loss 0.16944, vbg_att_sup_loss 0.27292, vbg_phrcls_loss 0.47931, vbg_prc_auc 0.68121, 307.76 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22819, vbg_prc_auc 0.44494, 93.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_187_miss+miuc+vbss+vbou+vbuc+vbss=0.4394.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 188/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.72810, mimfg_phrcls_loss 0.68547, mimfg_prc_auc 0.87640, vbg_vgbbox_loss 0.16360, vbg_att_sup_loss 0.26619, vbg_phrcls_loss 0.46880, vbg_prc_auc 0.68469, 307.99 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23126, vbg_prc_auc 0.44420, 93.37 secs\n",
      "\u001b[1m---- Epoch 189/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.73431, mimfg_phrcls_loss 0.69547, mimfg_prc_auc 0.87504, vbg_vgbbox_loss 0.17186, vbg_att_sup_loss 0.26129, vbg_phrcls_loss 0.45653, vbg_prc_auc 0.70501, 307.98 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23101, vbg_prc_auc 0.44664, 93.48 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_189_miss+miuc+vbss+vbou+vbuc+vbss=0.4420.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 190/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.81508, mimfg_phrcls_loss 0.75790, mimfg_prc_auc 0.85205, vbg_vgbbox_loss 0.19676, vbg_att_sup_loss 0.30018, vbg_phrcls_loss 0.54685, vbg_prc_auc 0.59892, 293.89 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.21712, vbg_prc_auc 0.41990, 94.18 secs\n",
      "\u001b[1m---- Epoch 191/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.76003, mimfg_phrcls_loss 0.71469, mimfg_prc_auc 0.87136, vbg_vgbbox_loss 0.17496, vbg_att_sup_loss 0.27314, vbg_phrcls_loss 0.49328, vbg_prc_auc 0.62896, 308.60 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23975, vbg_prc_auc 0.43045, 94.34 secs\n",
      "\u001b[1m---- Epoch 192/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72202, mimfg_phrcls_loss 0.67644, mimfg_prc_auc 0.87817, vbg_vgbbox_loss 0.16585, vbg_att_sup_loss 0.26743, vbg_phrcls_loss 0.47108, vbg_prc_auc 0.68148, 308.51 secs\n",
      "(2) Validation stage ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vbg_bbox_iou 0.24085, vbg_prc_auc 0.44056, 94.05 secs\n",
      "\u001b[1m---- Epoch 193/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.71592, mimfg_phrcls_loss 0.67562, mimfg_prc_auc 0.88116, vbg_vgbbox_loss 0.16872, vbg_att_sup_loss 0.25694, vbg_phrcls_loss 0.45145, vbg_prc_auc 0.71252, 307.52 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23706, vbg_prc_auc 0.44548, 95.61 secs\n",
      "\u001b[1m---- Epoch 194/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70726, mimfg_phrcls_loss 0.66951, mimfg_prc_auc 0.88048, vbg_vgbbox_loss 0.16533, vbg_att_sup_loss 0.24713, vbg_phrcls_loss 0.44577, vbg_prc_auc 0.73500, 304.95 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.24156, vbg_prc_auc 0.43199, 95.74 secs\n",
      "\u001b[1m---- Epoch 195/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.80753, mimfg_phrcls_loss 0.74752, mimfg_prc_auc 0.85542, vbg_vgbbox_loss 0.20047, vbg_att_sup_loss 0.30860, vbg_phrcls_loss 0.53850, vbg_prc_auc 0.59281, 305.38 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.20041, vbg_prc_auc 0.40324, 96.06 secs\n",
      "\u001b[1m---- Epoch 196/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.75034, mimfg_phrcls_loss 0.70167, mimfg_prc_auc 0.87285, vbg_vgbbox_loss 0.17470, vbg_att_sup_loss 0.27846, vbg_phrcls_loss 0.49186, vbg_prc_auc 0.64871, 305.37 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.22081, vbg_prc_auc 0.40875, 94.93 secs\n",
      "\u001b[1m---- Epoch 197/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72669, mimfg_phrcls_loss 0.68611, mimfg_prc_auc 0.87846, vbg_vgbbox_loss 0.16878, vbg_att_sup_loss 0.26202, vbg_phrcls_loss 0.45824, vbg_prc_auc 0.69658, 302.12 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23581, vbg_prc_auc 0.45115, 95.97 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_197_miss+miuc+vbss+vbou+vbuc+vbss=0.4460.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 198/198\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.70971, mimfg_phrcls_loss 0.67133, mimfg_prc_auc 0.87881, vbg_vgbbox_loss 0.16663, vbg_att_sup_loss 0.25440, vbg_phrcls_loss 0.44220, vbg_prc_auc 0.71641, 305.22 secs\n",
      "(2) Validation stage ...\n",
      "vbg_bbox_iou 0.23601, vbg_prc_auc 0.44118, 93.44 secs\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--checkpoint_folder \\\n",
    "\"models/phrase_grounding/20250210_234947_mim-facts+vinbig_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP_BBoxRegression,128,256,256-128)\" \\\n",
    "--epochs 30 \\\n",
    "--batches_per_epoch 1500 \\\n",
    "--max_images_per_batch 4 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 4 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino-maira-2\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp_with_bbox_regression\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--do_visual_grounding_with_bbox_regression \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\" \\\n",
    "--use_vinbig_for_train \\\n",
    "--use_vinbig_for_test \\\n",
    "--vinbig_phrase_embeddings_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/vinbig/label_phrase_embeddings__modified(hash=572,2522233010228708301).pkl\" \\\n",
    "--use_vinbig_with_modified_labels \\\n",
    "--vinbig_weight 0.2 \\\n",
    "--mimiccxr_facts_weight 0.8 \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
