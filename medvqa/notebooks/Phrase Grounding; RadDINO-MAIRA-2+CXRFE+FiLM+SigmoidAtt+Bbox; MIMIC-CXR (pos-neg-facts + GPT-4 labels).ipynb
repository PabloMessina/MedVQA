{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21105500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 80\n",
      "   batches_per_epoch: 3000\n",
      "   max_images_per_batch: 4\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 30\n",
      "   val_batch_size_factor: 3.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: rad-dino-huggingface\n",
      "   huggingface_model_name: microsoft/rad-dino-maira-2\n",
      "   num_regions: 841\n",
      "   image_local_feat_size: 768\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 29\n",
      "   regions_height: 29\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp__no_grounding\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 5\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [416, 416]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: False\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: rad-dino-huggingface\n",
      "  self.global_feat_size = 768\n",
      "  self.local_feat_size = 768\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 5, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.5307, 0.5307, 0.5307], std = [0.2583, 0.2583, 0.2583], image_size = [416, 416]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [416, 416]\n",
      "  mean = [0.5307, 0.5307, 0.5307]\n",
      "  std = [0.2583, 0.2583, 0.2583]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.5307, 0.5307, 0.5307], std = [0.2583, 0.2583, 0.2583], image_size = [416, 416]\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (403416, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 147159.10it/s]\n",
      "Total number of images: 377110\n",
      "len(train_indices) = 368960\n",
      "len(test_indices) = 8150\n",
      "len(set(train_indices) & set(test_indices)) = 0\n",
      "avg_facts_per_image = 508.52087218126627\n",
      "train_num_facts_per_image = 30\n",
      "avg_facts_per_image = 512.7754601226994\n",
      "test_num_facts_per_image = 30\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 4\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 92240\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 680\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 92240\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 680\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_195417_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_195417_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_17_mimfg_phrcls_loss+mimfg_prc_auc=0.5907.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/checkpoint_17_mimfg_phrcls_loss+mimfg_prc_auc=0.5907.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_195417_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.15843, mimfg_phrcls_loss 1.15843, mimfg_prc_auc 0.70271, 613.07 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.17908, mimfg_prc_auc 0.72301, 284.58 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.4633, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.7027, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.1660, den = 2.0000, score = 0.5830\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.4589, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.7230, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.1819, den = 2.0000, score = 0.5910\u001b[0m\n",
      "\u001b[93mTrain score = 0.5830, Val score = 0.5910, Final score = 0.5906\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_mimfg_phrcls_loss+mimfg_prc_auc=0.5906.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 1.15523, mimfg_phrcls_loss 1.15523, mimfg_prc_auc 0.70856, 614.27 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.15936, mimfg_prc_auc 0.72435, 283.98 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_mimfg_phrcls_loss+mimfg_prc_auc=0.5934.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 1.13086, mimfg_phrcls_loss 1.13086, mimfg_prc_auc 0.71718, 614.22 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.17354, mimfg_prc_auc 0.72549, 281.80 secs\n",
      "\u001b[1m---- Epoch 4/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.15893, mimfg_phrcls_loss 1.15893, mimfg_prc_auc 0.69602, 590.53 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.24980, mimfg_prc_auc 0.72951, 281.76 secs\n",
      "\u001b[1m---- Epoch 5/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 1.08430, mimfg_phrcls_loss 1.08430, mimfg_prc_auc 0.73132, 606.70 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.13246, mimfg_prc_auc 0.74400, 277.66 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_5_mimfg_phrcls_loss+mimfg_prc_auc=0.6064.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 6/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 1.06169, mimfg_phrcls_loss 1.06169, mimfg_prc_auc 0.74572, 612.36 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.10054, mimfg_prc_auc 0.75797, 277.75 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_mimfg_phrcls_loss+mimfg_prc_auc=0.6169.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 1.03969, mimfg_phrcls_loss 1.03969, mimfg_prc_auc 0.75709, 615.16 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.05634, mimfg_prc_auc 0.76567, 275.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_7_mimfg_phrcls_loss+mimfg_prc_auc=0.6259.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 8/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 1.01466, mimfg_phrcls_loss 1.01466, mimfg_prc_auc 0.76397, 591.74 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04057, mimfg_prc_auc 0.76996, 272.44 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_mimfg_phrcls_loss+mimfg_prc_auc=0.6300.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 1.00937, mimfg_phrcls_loss 1.00937, mimfg_prc_auc 0.76616, 611.66 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04248, mimfg_prc_auc 0.76989, 270.45 secs\n",
      "\u001b[1m---- Epoch 10/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.05922, mimfg_phrcls_loss 1.05922, mimfg_prc_auc 0.73915, 596.78 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.03860, mimfg_prc_auc 0.75353, 269.31 secs\n",
      "\u001b[1m---- Epoch 11/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 1.01996, mimfg_phrcls_loss 1.01996, mimfg_prc_auc 0.76243, 613.33 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.05840, mimfg_prc_auc 0.76328, 268.32 secs\n",
      "\u001b[1m---- Epoch 12/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.98457, mimfg_phrcls_loss 0.98457, mimfg_prc_auc 0.77370, 611.52 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.05195, mimfg_prc_auc 0.77295, 266.39 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_mimfg_phrcls_loss+mimfg_prc_auc=0.6306.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.98589, mimfg_phrcls_loss 0.98589, mimfg_prc_auc 0.77843, 613.32 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.01731, mimfg_prc_auc 0.77921, 268.31 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_mimfg_phrcls_loss+mimfg_prc_auc=0.6376.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.97506, mimfg_phrcls_loss 0.97506, mimfg_prc_auc 0.77783, 612.45 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.00780, mimfg_prc_auc 0.78074, 272.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_14_mimfg_phrcls_loss+mimfg_prc_auc=0.6395.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 15/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.02990, mimfg_phrcls_loss 1.02990, mimfg_prc_auc 0.75197, 606.81 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.01756, mimfg_prc_auc 0.75989, 266.99 secs\n",
      "\u001b[1m---- Epoch 16/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.98056, mimfg_phrcls_loss 0.98056, mimfg_prc_auc 0.77340, 609.47 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.97630, mimfg_prc_auc 0.77273, 265.62 secs\n",
      "\u001b[1m---- Epoch 17/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.96734, mimfg_phrcls_loss 0.96734, mimfg_prc_auc 0.78265, 610.27 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.00672, mimfg_prc_auc 0.78320, 271.48 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_17_mimfg_phrcls_loss+mimfg_prc_auc=0.6410.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 18/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.95823, mimfg_phrcls_loss 0.95823, mimfg_prc_auc 0.78774, 611.55 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.97635, mimfg_prc_auc 0.78747, 266.12 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_mimfg_phrcls_loss+mimfg_prc_auc=0.6469.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.93878, mimfg_phrcls_loss 0.93878, mimfg_prc_auc 0.79581, 610.66 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.96510, mimfg_prc_auc 0.78856, 270.16 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_19_mimfg_phrcls_loss+mimfg_prc_auc=0.6491.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 20/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 1.00005, mimfg_phrcls_loss 1.00005, mimfg_prc_auc 0.76404, 611.18 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.03805, mimfg_prc_auc 0.76675, 265.75 secs\n",
      "\u001b[1m---- Epoch 21/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.96712, mimfg_phrcls_loss 0.96712, mimfg_prc_auc 0.78068, 586.78 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.04131, mimfg_prc_auc 0.78727, 272.01 secs\n",
      "\u001b[1m---- Epoch 22/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.93603, mimfg_phrcls_loss 0.93603, mimfg_prc_auc 0.79372, 598.46 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.95869, mimfg_prc_auc 0.79161, 271.61 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_22_mimfg_phrcls_loss+mimfg_prc_auc=0.6513.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 23/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.92670, mimfg_phrcls_loss 0.92670, mimfg_prc_auc 0.79873, 614.86 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.96410, mimfg_prc_auc 0.79693, 271.41 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_mimfg_phrcls_loss+mimfg_prc_auc=0.6533.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.90575, mimfg_phrcls_loss 0.90575, mimfg_prc_auc 0.80458, 609.94 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.94397, mimfg_prc_auc 0.79785, 268.92 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_24_mimfg_phrcls_loss+mimfg_prc_auc=0.6566.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 25/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.96347, mimfg_phrcls_loss 0.96347, mimfg_prc_auc 0.77864, 591.58 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 1.02005, mimfg_prc_auc 0.75805, 267.84 secs\n",
      "\u001b[1m---- Epoch 26/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.92929, mimfg_phrcls_loss 0.92929, mimfg_prc_auc 0.79477, 613.92 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.99042, mimfg_prc_auc 0.79428, 268.25 secs\n",
      "\u001b[1m---- Epoch 27/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.90773, mimfg_phrcls_loss 0.90773, mimfg_prc_auc 0.80576, 597.18 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.94539, mimfg_prc_auc 0.80425, 265.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_27_mimfg_phrcls_loss+mimfg_prc_auc=0.6594.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 28/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.87651, mimfg_phrcls_loss 0.87651, mimfg_prc_auc 0.81362, 592.99 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.93715, mimfg_prc_auc 0.80414, 270.02 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_28_mimfg_phrcls_loss+mimfg_prc_auc=0.6608.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 29/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.89203, mimfg_phrcls_loss 0.89203, mimfg_prc_auc 0.80819, 613.39 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.92455, mimfg_prc_auc 0.80498, 269.53 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_29_mimfg_phrcls_loss+mimfg_prc_auc=0.6626.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 30/80\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "   iteration 88150\r"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250215_153529_mim-facts_PhraseGrounder(microsoft-rad-dino-maira-2,AdaptiveFiLM_MLP,128,256,256-128)\" \\\n",
    "--epochs 80 \\\n",
    "--batches_per_epoch 3000 \\\n",
    "--max_images_per_batch 4 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 30 \\\n",
    "--val_batch_size_factor 3 \\\n",
    "--raw_image_encoding \"rad-dino-huggingface\" \\\n",
    "--huggingface_model_name \"microsoft/rad-dino-maira-2\" \\\n",
    "--image_size 416 416 \\\n",
    "--image_local_feat_size 768 \\\n",
    "--num_regions 841 \\\n",
    "--regions_width 29 \\\n",
    "--regions_height 29 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp__no_grounding\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 5 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
